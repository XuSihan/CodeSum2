[{"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "String   tableOwner    =    session . getUser (  )  ;", "String   schemaName    =    schemaTableName . getSchemaName (  )  ;", "String   tableName    =    schemaTableName . getTableName (  )  ;", "Optional < Table >    table    =    transaction . getMetastore ( schemaName )  . getTable ( schemaName ,    tableName )  ;", "Table . Builder   tableBuilder    =    Table . builder ( table . get (  )  )  ;", "tableBuilder . getStorageBuilder (  )  . setBucketProperty ( bucketProperty )  ;", "PrincipalPrivileges   principalPrivileges    =    testingPrincipalPrivilege ( tableOwner )  ;", "transaction . getMetastore ( schemaName )  . replaceView ( schemaName ,    tableName ,    tableBuilder . build (  )  ,    principalPrivileges )  ;", "transaction . commit (  )  ;", "}", "}", "METHOD_END"], "methodName": ["alterBucketProperty"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "int   bucketCount    =     8  ;", "Set < Long >    expectedIds    =    LongStream . range (  0  ,    rowCount )  . filter (  (    x )     -  >    bucketIds . contains ( Math . toIntExact (  ( x    %    bucketCount )  )  )  )  . boxed (  )  . collect ( toImmutableSet (  )  )  ;", "Map < String ,    Integer >    columnIndex    =     . indexColumns ( columnHandles )  ;", "OptionalInt   idColumnIndex    =     ( columnIndex . containsKey (  \" id \"  )  )     ?    OptionalInt . of ( columnIndex . get (  \" id \"  )  )     :    OptionalInt . empty (  )  ;", "int   nameColumnIndex    =    columnIndex . get (  \" name \"  )  ;", "int   bucketColumnIndex    =    columnIndex . get ( HiveColumnHandle . BUCKET _ COLUMN _ NAME )  ;", "Map < Long ,    Integer >    idCount    =    new   HashMap <  >  (  )  ;", "for    ( MaterializedRow   row    :    result . getMaterializedRows (  )  )     {", "String   name    =     (  ( String )     ( row . getField ( nameColumnIndex )  )  )  ;", "int   bucket    =     (  ( int )     ( row . getField ( bucketColumnIndex )  )  )  ;", "idCount . compute ( Long . parseLong ( name )  ,     (    key ,    oldValue )     -  >    oldValue    =  =    null    ?     1     :    oldValue    +     1  )  ;", "assertEquals ( bucket ,     (  ( Integer . parseInt ( name )  )     %    bucketCount )  )  ;", "if    ( idColumnIndex . isPresent (  )  )     {", "long   id    =     (  ( long )     ( row . getField ( idColumnIndex . getAsInt (  )  )  )  )  ;", "assertEquals ( Integer . parseInt ( name )  ,    id )  ;", "}", "}", "assertEquals (  (  ( int )     ( idCount . values (  )  . stream (  )  . distinct (  )  . collect ( onlyElement (  )  )  )  )  ,     3  )  ;", "assertEquals ( idCount . keySet (  )  ,    expectedIds )  ;", "}", "METHOD_END"], "methodName": ["assertBucketTableEvolutionResult"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "SchemaTableName   tableName    =    temporaryTable (  \" empty _ file \"  )  ;", "try    {", "List < Column >    columns    =    ImmutableList . of ( new   Column (  \" test \"  ,    HiveType . HIVE _ STRING ,    Optional . empty (  )  )  )  ;", "createEmptyTable ( tableName ,    format ,    columns ,    ImmutableList . of (  )  )  ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =     . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "Table   table    =    transaction . getMetastore ( tableName . getSchemaName (  )  )  . getTable ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . orElseThrow ( AssertionError :  : new )  ;", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "Path   location    =    new   Path ( table . getStorage (  )  . getLocation (  )  )  ;", "assertTrue ( listDirectory ( context ,    location )  . isEmpty (  )  )  ;", "readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . of (  0  )  ,    Optional . of ( HiveStorageFormat . ORC )  )  ;", "FileSystem   fileSystem    =    hdfsEnvironment . getFileSystem ( context ,    location )  ;", "assertTrue ( fileSystem . createNewFile ( new   Path ( location ,     \" empty - file \"  )  )  )  ;", "assertEquals ( listDirectory ( context ,    location )  ,    ImmutableList . of (  \" empty - file \"  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . of (  1  )  ,    Optional . empty (  )  )  ;", "assertEquals ( result . getRowCount (  )  ,     0  )  ;", "}", "}    finally    {", "dropTable ( tableName )  ;", "}", "}", "METHOD_END"], "methodName": ["assertEmptyFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "Map < String ,     ?  >    actualById    =    uniqueIndex ( actualPartitions ,    HivePartition :  : getPartitionId )  ;", "for    ( Object   expected    :    expectedPartitions )     {", "Assertions . assertInstanceOf ( expected ,    HivePartition . class )  ;", "HivePartition   expectedPartition    =     (  ( HivePartition )     ( expected )  )  ;", "Object   actual    =    actualById . get ( expectedPartition . getPartitionId (  )  )  ;", "assertEquals ( actual ,    expected )  ;", "Assertions . assertInstanceOf ( actual ,    HivePartition . class )  ;", "HivePartition   actualPartition    =     (  ( HivePartition )     ( actual )  )  ;", "assertNotNull ( actualPartition ,     (  \" partition    \"     +     ( expectedPartition . getPartitionId (  )  )  )  )  ;", "assertEquals ( actualPartition . getPartitionId (  )  ,    expectedPartition . getPartitionId (  )  )  ;", "assertEquals ( actualPartition . getKeys (  )  ,    expectedPartition . getKeys (  )  )  ;", "assertEquals ( actualPartition . getTableName (  )  ,    expectedPartition . getTableName (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertExpectedPartitions"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertExpectedTableLayoutHandle ( actualTableLayout . getHandle (  )  ,    expectedTableLayout . getHandle (  )  )  ;", "assertEquals ( actualTableLayout . getPredicate (  )  ,    expectedTableLayout . getPredicate (  )  )  ;", "assertEquals ( actualTableLayout . getDiscretePredicates (  )  . isPresent (  )  ,    expectedTableLayout . getDiscretePredicates (  )  . isPresent (  )  )  ;", "actualTableLayout . getDiscretePredicates (  )  . ifPresent (  (    actual )     -  >     {", "DiscretePredicates   expected    =    expectedTableLayout . getDiscretePredicates (  )  . get (  )  ;", "assertEquals ( actual . getColumns (  )  ,    expected . getColumns (  )  )  ;", "assertEqualsIgnoreOrder ( actual . getPredicates (  )  ,    expected . getPredicates (  )  )  ;", "}  )  ;", "assertEquals ( actualTableLayout . getStreamPartitioningColumns (  )  ,    expectedTableLayout . getStreamPartitioningColumns (  )  )  ;", "assertEquals ( actualTableLayout . getLocalProperties (  )  ,    expectedTableLayout . getLocalProperties (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertExpectedTableLayout"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "Assertions . assertInstanceOf ( actualTableLayoutHandle ,    HiveTableLayoutHandle . class )  ;", "Assertions . assertInstanceOf ( expectedTableLayoutHandle ,    HiveTableLayoutHandle . class )  ;", "HiveTableLayoutHandle   actual    =     (  ( HiveTableLayoutHandle )     ( actualTableLayoutHandle )  )  ;", "HiveTableLayoutHandle   expected    =     (  ( HiveTableLayoutHandle )     ( expectedTableLayoutHandle )  )  ;", "assertExpectedPartitions ( actual . getPartitions (  )  . get (  )  ,    expected . getPartitions (  )  . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertExpectedTableLayoutHandle"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    {", "MaterializedResult   result    =    materializeSourceDataStream ( newSession (  )  ,    pageSource ,    HiveTestUtils . getTypes ( columnHandles )  )  ;", ". assertPageSourceType ( pageSource ,    hiveStorageFormat )  ;", "ImmutableMap < String ,    Integer >    columnIndex    =     . indexColumns ( tableMetadata )  ;", "long   rowNumber    =     0  ;", "long   completedBytes    =     0  ;", "for    ( MaterializedRow   row    :    result )     {", "try    {", ". assertValueTypes ( row ,    tableMetadata . getColumns (  )  )  ;", "}    catch    ( RuntimeException   e )     {", "throw   new   RuntimeException (  (  \" row    \"     +    rowNumber )  ,    e )  ;", "}", "rowNumber +  +  ;", "Integer   index ;", "Object   value ;", "index    =    columnIndex . get (  \" t _ string \"  )  ;", "value    =    row . getField ( index )  ;", "if    (  ( rowNumber    %     1  9  )     =  =     0  )     {", "assertNull ( value )  ;", "} else", "if    (  ( rowNumber    %     1  9  )     =  =     1  )     {", "assertEquals ( value ,     \"  \"  )  ;", "} else    {", "assertEquals ( value ,     \" test \"  )  ;", "}", "assertEquals ( row . getField ( columnIndex . get (  \" t _ tinyint \"  )  )  ,     (  ( byte )     (  1     +    rowNumber )  )  )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" t _ smallint \"  )  )  ,     (  ( short )     (  2     +    rowNumber )  )  )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" t _ int \"  )  )  ,     (  ( int )     (  3     +    rowNumber )  )  )  ;", "index    =    columnIndex . get (  \" t _ bigint \"  )  ;", "if    (  ( rowNumber    %     1  3  )     =  =     0  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "assertEquals ( row . getField ( index )  ,     (  4     +    rowNumber )  )  ;", "}", "assertEquals (  (  ( Float )     ( row . getField ( columnIndex . get (  \" t _ float \"  )  )  )  )  ,     (  5  .  1 F    +    rowNumber )  ,     0  .  0  0  1  )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" t _ double \"  )  )  ,     (  6  .  2     +    rowNumber )  )  ;", "index    =    columnIndex . get (  \" t _ boolean \"  )  ;", "if    (  ( rowNumber    %     3  )     =  =     2  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "assertEquals ( row . getField ( index )  ,     (  ( rowNumber    %     3  )     !  =     0  )  )  ;", "}", "index    =    columnIndex . get (  \" t _ timestamp \"  )  ;", "if    ( index    !  =    null )     {", "if    (  ( rowNumber    %     1  7  )     =  =     0  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "SqlTimestamp   expected    =    new   SqlTimestamp ( new   DateTime (  2  0  1  1  ,     5  ,     6  ,     7  ,     8  ,     9  ,     1  2  3  ,    timeZone )  . getMillis (  )  ,    TimeZoneKey . UTC _ KEY )  ;", "assertEquals ( row . getField ( index )  ,    expected )  ;", "}", "}", "index    =    columnIndex . get (  \" t _ binary \"  )  ;", "if    ( index    !  =    null )     {", "if    (  ( rowNumber    %     2  3  )     =  =     0  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "assertEquals ( row . getField ( index )  ,    new   SqlVarbinary (  \" test   binary \"  . getBytes ( StandardCharsets . UTF _  8  )  )  )  ;", "}", "}", "index    =    columnIndex . get (  \" t _ date \"  )  ;", "if    ( index    !  =    null )     {", "if    (  ( rowNumber    %     3  7  )     =  =     0  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "SqlDate   expected    =    new   SqlDate ( Math . toIntExact ( TimeUnit . MILLISECONDS . toDays ( new   DateTime (  2  0  1  3  ,     8  ,     9  ,     0  ,     0  ,     0  ,    UTC )  . getMillis (  )  )  )  )  ;", "assertEquals ( row . getField ( index )  ,    expected )  ;", "}", "}", "index    =    columnIndex . get (  \" t _ varchar \"  )  ;", "if    ( index    !  =    null )     {", "value    =    row . getField ( index )  ;", "if    (  ( rowNumber    %     3  9  )     =  =     0  )     {", "assertNull ( value )  ;", "} else", "if    (  ( rowNumber    %     3  9  )     =  =     1  )     {", "if    ( hiveStorageFormat    =  =     ( HiveStorageFormat . RCBINARY )  )     {", "assertNull ( value )  ;", "} else    {", "assertEquals ( value ,     \"  \"  )  ;", "}", "} else    {", "assertEquals ( value ,     \" test   varchar \"  )  ;", "}", "}", "index    =    columnIndex . get (  \" t _ char \"  )  ;", "if    ( index    !  =    null )     {", "value    =    row . getField ( index )  ;", "if    (  ( rowNumber    %     4  1  )     =  =     0  )     {", "assertNull ( value )  ;", "} else    {", "assertEquals ( value ,     (  ( rowNumber    %     4  1  )     =  =     1     ?     \"                                                                             \"     :     \" test   char                                                 \"  )  )  ;", "}", "}", "index    =    columnIndex . get (  \" t _ map \"  )  ;", "if    ( index    !  =    null )     {", "if    (  ( rowNumber    %     2  7  )     =  =     0  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "assertEquals ( row . getField ( index )  ,    ImmutableMap . of (  \" test   key \"  ,     \" test   value \"  )  )  ;", "}", "}", "index    =    columnIndex . get (  \" t _ array _ string \"  )  ;", "if    ( index    !  =    null )     {", "if    (  ( rowNumber    %     2  9  )     =  =     0  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "assertEquals ( row . getField ( index )  ,    ImmutableList . of (  \" abc \"  ,     \" xyz \"  ,     \" data \"  )  )  ;", "}", "}", "index    =    columnIndex . get (  \" t _ array _ struct \"  )  ;", "if    ( index    !  =    null )     {", "if    (  ( rowNumber    %     3  1  )     =  =     0  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "List < Object >    expected 1     =    ImmutableList . of (  \" test   abc \"  ,     0  .  1  )  ;", "List < Object >    expected 2     =    ImmutableList . of (  \" test   xyz \"  ,     0  .  2  )  ;", "assertEquals ( row . getField ( index )  ,    ImmutableList . of ( expected 1  ,    expected 2  )  )  ;", "}", "}", "index    =    columnIndex . get (  \" t _ struct \"  )  ;", "if    ( index    !  =    null )     {", "if    (  ( rowNumber    %     3  1  )     =  =     0  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "assertTrue (  (  ( row . getField ( index )  )    instanceof   List )  )  ;", "List   values    =     (  ( List )     ( row . getField ( index )  )  )  ;", "assertEquals ( values . size (  )  ,     2  )  ;", "assertEquals ( values . get (  0  )  ,     \" test   abc \"  )  ;", "assertEquals ( values . get (  1  )  ,     0  .  1  )  ;", "}", "}", "index    =    columnIndex . get (  \" t _ complex \"  )  ;", "if    ( index    !  =    null )     {", "if    (  ( rowNumber    %     3  3  )     =  =     0  )     {", "assertNull ( row . getField ( index )  )  ;", "} else    {", "List < Object >    expected 1     =    ImmutableList . of (  \" test   abc \"  ,     0  .  1  )  ;", "List < Object >    expected 2     =    ImmutableList . of (  \" test   xyz \"  ,     0  .  2  )  ;", "assertEquals ( row . getField ( index )  ,    ImmutableMap . of (  1  ,    ImmutableList . of ( expected 1  ,    expected 2  )  )  )  ;", "}", "}", "assertNull ( row . getField ( columnIndex . get (  \" new _ column \"  )  )  )  ;", "long   newCompletedBytes    =    pageSource . getCompletedBytes (  )  ;", "assertTrue (  ( newCompletedBytes    >  =    completedBytes )  )  ;", "assertTrue (  ( newCompletedBytes    <  =     ( hiveSplit . getLength (  )  )  )  )  ;", "completedBytes    =    newCompletedBytes ;", "}", "assertTrue (  ( completedBytes    <  =     ( hiveSplit . getLength (  )  )  )  )  ;", "assertEquals ( rowNumber ,     1  0  0  )  ;", "}    finally    {", "pageSource . close (  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertGetRecords"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    new   SchemaTableName ( database ,    tableName )  )  ;", "ConnectorTableMetadata   tableMetadata    =    metadata . getTableMetadata ( session ,    tableHandle )  ;", "HiveSplit   hiveSplit    =    getHiveSplit ( tableHandle )  ;", "List < ColumnHandle >    columnHandles    =    ImmutableList . copyOf ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "ConnectorPageSource   pageSource    =    pageSourceProvider . createPageSource ( transaction . getTransactionHandle (  )  ,    session ,    hiveSplit ,    columnHandles )  ;", "assertGetRecords ( hiveStorageFormat ,    tableMetadata ,    hiveSplit ,    pageSource ,    columnHandles )  ;", "}", "}", "METHOD_END"], "methodName": ["assertGetRecords"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "if    (  ( metadata . getTableHandle ( newSession (  )  ,    new   SchemaTableName ( database ,    tableName )  )  )     !  =    null )     {", "assertGetRecords ( tableName ,    hiveStorageFormat )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["assertGetRecordsOptional"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "if    ( pageSource   instanceof   RecordPageSource )     {", "RecordCursor   hiveRecordCursor    =     (  ( RecordPageSource )     ( pageSource )  )  . getCursor (  )  ;", "hiveRecordCursor    =     (  ( HiveRecordCursor )     ( hiveRecordCursor )  )  . getRegularColumnRecordCursor (  )  ;", "if    ( hiveRecordCursor   instanceof   HiveCoercionRecordCursor )     {", "hiveRecordCursor    =     (  ( HiveCoercionRecordCursor )     ( hiveRecordCursor )  )  . getRegularColumnRecordCursor (  )  ;", "}", "Assertions . assertInstanceOf ( hiveRecordCursor ,     . recordCursorType ( hiveStorageFormat )  ,    hiveStorageFormat . name (  )  )  ;", "} else    {", "Assertions . assertInstanceOf (  (  ( HivePageSource )     ( pageSource )  )  . getPageSource (  )  ,     . pageSourceType ( hiveStorageFormat )  ,    hiveStorageFormat . name (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertPageSourceType"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertTrue ( map . containsKey ( name )  )  ;", "ColumnMetadata   column    =    map . get ( name )  ;", "assertEquals ( column . getType (  )  ,    type ,    name )  ;", "assertEquals ( column . getExtraInfo (  )  ,    Util . columnExtraInfo ( partitionKey )  )  ;", "}", "METHOD_END"], "methodName": ["assertPrimitiveField"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "List < ConnectorSplit >    splits    =    getAllSplits ( tableHandle ,    TupleDomain . all (  )  )  ;", "assertEquals ( splits . size (  )  ,     3  2  )  ;", "Set < String >    paths    =    new   HashSet <  >  (  )  ;", "for    ( ConnectorSplit   split    :    splits )     {", "assertTrue ( paths . add (  (  ( Split )     ( split )  )  . getPath (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertTableIsBucketed"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "TableStatistics   tableStatistics    =    metadata . getTableStatistics ( session ,    tableHandle ,    Constraint . alwaysTrue (  )  )  ;", "assertFalse ( tableStatistics . getRowCount (  )  . isValueUnknown (  )  ,     \" row   count   is   unknown \"  )  ;", "Map < String ,    ColumnStatistics >    columnsStatistics    =    tableStatistics . getColumnStatistics (  )  . entrySet (  )  . stream (  )  . collect ( toImmutableMap (  (    entry )     -  >     (  ( HiveColumnHandle )     ( entry . getKey (  )  )  )  . getName (  )  ,    Map . Entry :  : getValue )  )  ;", "assertEquals ( columnsStatistics . keySet (  )  ,    expectedColumnStatsColumns ,     \" columns   with   statistics \"  )  ;", "columnsStatistics . forEach (  (    columnName ,    columnStatistics )     -  >     {", "assertFalse ( columnStatistics . getNullsFraction (  )  . isValueUnknown (  )  ,     (  \" unknown   nulls   fraction   for    \"     +    columnName )  )  ;", "RangeColumnStatistics   rangeColumnStatistics    =    columnStatistics . getOnlyRangeColumnStatistics (  )  ;", "assertFalse ( rangeColumnStatistics . getDistinctValuesCount (  )  . isValueUnknown (  )  ,     (  \" unknown   range   distinct   values   count   for    \"     +    columnName )  )  ;", "assertFalse ( rangeColumnStatistics . getFraction (  )  . isValueUnknown (  )  ,     (  \" unknown   range   non - null   fraction   for    \"     +    columnName )  )  ;", "}  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertTableStatsComputed"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "List < ColumnMetadata >    columns    =    ImmutableList . of ( new   ColumnMetadata (  \" dummy \"  ,    VarcharType . createUnboundedVarcharType (  )  )  )  ;", "ConnectorTableMetadata   tableMetadata    =    new   ConnectorTableMetadata ( tableName ,    columns ,    AbstractTestHiveClient . createTableProperties ( HiveStorageFormat . TEXTFILE )  )  ;", "ConnectorOutputTableHandle   handle    =    metadata . beginCreateTable ( session ,    tableMetadata ,    Optional . empty (  )  )  ;", "metadata . finishCreateTable ( session ,    handle ,    ImmutableList . of (  )  )  ;", "transaction . commit (  )  ;", "}", "}", "METHOD_END"], "methodName": ["createDummyTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "createEmptyTable ( schemaTableName ,    hiveStorageFormat ,    columns ,    partitionColumns ,    Optional . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["createEmptyTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "Path   targetPath ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "String   tableOwner    =    session . getUser (  )  ;", "String   schemaName    =    schemaTableName . getSchemaName (  )  ;", "String   tableName    =    schemaTableName . getTableName (  )  ;", "LocationService   locationService    =    getLocationService ( schemaName )  ;", "LocationHandle   locationHandle    =    locationService . forNewTable ( transaction . getMetastore ( schemaName )  ,    session ,    schemaName ,    tableName )  ;", "targetPath    =    locationService . targetPathRoot ( locationHandle )  ;", "Table . Builder   tableBuilder    =    Table . builder (  )  . setDatabaseName ( schemaName )  . setTableName ( tableName )  . setOwner ( tableOwner )  . setTableType ( MANAGED _ TABLE . name (  )  )  . setParameters ( ImmutableMap . of ( HiveMetadata . PRESTO _ VERSION _ NAME ,     . TEST _ SERVER _ VERSION ,    HiveMetadata . PRESTO _ QUERY _ ID _ NAME ,    session . getQueryId (  )  )  )  . setDataColumns ( columns )  . setPartitionColumns ( partitionColumns )  ;", "tableBuilder . getStorageBuilder (  )  . setLocation ( targetPath . toString (  )  )  . setStorageFormat ( StorageFormat . create ( hiveStorageFormat . getSerDe (  )  ,    hiveStorageFormat . getInputFormat (  )  ,    hiveStorageFormat . getOutputFormat (  )  )  )  . setBucketProperty ( bucketProperty )  . setSerdeParameters ( ImmutableMap . of (  )  )  ;", "PrincipalPrivileges   principalPrivileges    =    testingPrincipalPrivilege ( tableOwner )  ;", "transaction . getMetastore ( schemaName )  . createTable ( session ,    tableBuilder . build (  )  ,    principalPrivileges ,    Optional . empty (  )  ,    true )  ;", "transaction . commit (  )  ;", "}", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( newSession (  )  ,    schemaTableName . getSchemaName (  )  ,    schemaTableName . getTableName (  )  )  ;", "List < String >    targetDirectoryList    =    listDirectory ( context ,    targetPath )  ;", "assertEquals ( targetDirectoryList ,    ImmutableList . of (  )  )  ;", "}", "METHOD_END"], "methodName": ["createEmptyTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "String   tableOwner    =    session . getUser (  )  ;", "String   schemaName    =    schemaTableName . getSchemaName (  )  ;", "String   tableName    =    schemaTableName . getTableName (  )  ;", "return   Table . builder (  )  . setDatabaseName ( schemaName )  . setTableName ( tableName )  . setOwner ( tableOwner )  . setTableType ( MANAGED _ TABLE . name (  )  )  . setParameters ( ImmutableMap . of ( HiveMetadata . PRESTO _ VERSION _ NAME ,     . TEST _ SERVER _ VERSION ,    HiveMetadata . PRESTO _ QUERY _ ID _ NAME ,    queryId )  )  . setDataColumns ( columns )  . withStorage (  (    storage )     -  >    storage . setLocation ( targetPath . toString (  )  )  . setStorageFormat ( fromHiveStorageFormat ( ORC )  )  . setSerdeParameters ( ImmutableMap . of (  )  )  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["createSimpleTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   AbstractTestHiveClient . createTableProperties ( storageFormat ,    ImmutableList . of (  )  )  ;", "}", "METHOD_END"], "methodName": ["createTableProperties"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   ImmutableMap .  < String ,    Object > builder (  )  . put ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY ,    storageFormat )  . put ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY ,    ImmutableList . copyOf ( parititonedBy )  )  . put ( HiveTableProperties . BUCKETED _ BY _ PROPERTY ,    ImmutableList . of (  )  )  . put ( HiveTableProperties . BUCKET _ COUNT _ PROPERTY ,     0  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["createTableProperties"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "List < String >    partitionedBy    =    createTableColumns . stream (  )  . filter (  (    column )     -  >    column . getName (  )  . equals (  \" ds \"  )  )  . map ( ColumnMetadata :  : getName )  . collect ( Collectors . toList (  )  )  ;", "String   queryId ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "queryId    =    session . getQueryId (  )  ;", "ConnectorTableMetadata   tableMetadata    =    new   ConnectorTableMetadata ( tableName ,    createTableColumns ,     . createTableProperties ( storageFormat ,    partitionedBy )  )  ;", "metadata . createTable ( session ,    tableMetadata ,    false )  ;", "transaction . commit (  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "ConnectorTableMetadata   tableMetadata    =    metadata . getTableMetadata ( session ,    getTableHandle ( metadata ,    tableName )  )  ;", "List < ColumnMetadata >    expectedColumns    =    createTableColumns . stream (  )  . map (  (    column )     -  >    new   ColumnMetadata ( column . getName (  )  ,    column . getType (  )  ,    column . getComment (  )  ,    columnExtraInfo ( partitionedBy . contains ( column . getName (  )  )  )  ,    false )  )  . collect ( Collectors . toList (  )  )  ;", "assertEquals (  . filterNonHiddenColumnMetadata ( tableMetadata . getColumns (  )  )  ,    expectedColumns )  ;", "Table   table    =    transaction . getMetastore ( tableName . getSchemaName (  )  )  . getTable ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . get (  )  ;", "assertEquals ( table . getStorage (  )  . getStorageFormat (  )  . getInputFormat (  )  ,    storageFormat . getInputFormat (  )  )  ;", "assertEquals ( table . getParameters (  )  . get ( HiveMetadata . PRESTO _ VERSION _ NAME )  ,     . TEST _ SERVER _ VERSION )  ;", "assertEquals ( table . getParameters (  )  . get ( HiveMetadata . PRESTO _ QUERY _ ID _ NAME )  ,    queryId )  ;", "List < ColumnHandle >    columnHandles    =     . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . of ( storageFormat )  )  ;", "assertEquals ( result . getRowCount (  )  ,     0  )  ;", "}", "}", "METHOD_END"], "methodName": ["doCreateEmptyTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "String   queryId ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "queryId    =    session . getQueryId (  )  ;", "ConnectorTableMetadata   tableMetadata    =    new   ConnectorTableMetadata ( tableName ,     . CREATE _ TABLE _ COLUMNS ,     . createTableProperties ( storageFormat )  )  ;", "ConnectorOutputTableHandle   outputHandle    =    metadata . beginCreateTable ( session ,    tableMetadata ,    Optional . empty (  )  )  ;", "ConnectorPageSink   sink    =    pageSinkProvider . createPageSink ( transaction . getTransactionHandle (  )  ,    session ,    outputHandle )  ;", "sink . appendPage (  . CREATE _ TABLE _ DATA . toPage (  )  )  ;", "Collection < Slice >    fragments    =    MoreFutures . getFutureValue ( sink . finish (  )  )  ;", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "for    ( String   filePath    :    listAllDataFiles ( context ,    getStagingPathRoot ( outputHandle )  )  )     {", "assertTrue ( new   Path ( filePath )  . getName (  )  . startsWith ( getFilePrefix ( outputHandle )  )  )  ;", "}", "metadata . finishCreateTable ( session ,    outputHandle ,    fragments )  ;", "transaction . commit (  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =     . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "ConnectorTableMetadata   tableMetadata    =    metadata . getTableMetadata ( session ,    getTableHandle ( metadata ,    tableName )  )  ;", "assertEquals (  . filterNonHiddenColumnMetadata ( tableMetadata . getColumns (  )  )  ,     . CREATE _ TABLE _ COLUMNS )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . of ( storageFormat )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,     . CREATE _ TABLE _ DATA . getMaterializedRows (  )  )  ;", "Table   table    =    getMetastoreClient ( tableName . getSchemaName (  )  )  . getTable ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . get (  )  ;", "assertEquals ( table . getParameters (  )  . get ( HiveMetadata . PRESTO _ VERSION _ NAME )  ,     . TEST _ SERVER _ VERSION )  ;", "assertEquals ( table . getParameters (  )  . get ( HiveMetadata . PRESTO _ QUERY _ ID _ NAME )  ,    queryId )  ;", "}", "}", "METHOD_END"], "methodName": ["doCreateTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "String   viewData    =     \" test   data \"  ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "transaction . getMetadata (  )  . createView ( newSession (  )  ,    viewName ,    viewData ,    replace )  ;", "transaction . commit (  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "Map < SchemaTableName ,    ConnectorViewDefinition >    views    =    metadata . getViews ( newSession (  )  ,    viewName . toSchemaTablePrefix (  )  )  ;", "assertEquals ( views . size (  )  ,     1  )  ;", "assertEquals ( views . get ( viewName )  . getViewData (  )  ,    viewData )  ;", "assertTrue ( metadata . listViews ( newSession (  )  ,    viewName . getSchemaName (  )  )  . contains ( viewName )  )  ;", "}", "}", "METHOD_END"], "methodName": ["doCreateView"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "doCreateEmptyTable ( tableName ,    storageFormat ,    AbstractTestHiveClient . CREATE _ TABLE _ COLUMNS )  ;", "MaterializedResult . Builder   resultBuilder    =    MaterializedResult . resultBuilder ( HiveTestUtils . SESSION ,    AbstractTestHiveClient . CREATE _ TABLE _ DATA . getTypes (  )  )  ;", "for    ( int   i    =     0  ;    i    <     3  ;    i +  +  )     {", "insertData ( tableName ,    AbstractTestHiveClient . CREATE _ TABLE _ DATA )  ;", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =    AbstractTestHiveClient . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "ConnectorTableMetadata   tableMetadata    =    metadata . getTableMetadata ( session ,    getTableHandle ( metadata ,    tableName )  )  ;", "assertEquals ( AbstractTestHiveClient . filterNonHiddenColumnMetadata ( tableMetadata . getColumns (  )  )  ,    AbstractTestHiveClient . CREATE _ TABLE _ COLUMNS )  ;", "resultBuilder . rows ( AbstractTestHiveClient . CREATE _ TABLE _ DATA . getMaterializedRows (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . empty (  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    resultBuilder . build (  )  . getMaterializedRows (  )  )  ;", "}", "}", "Set < String >    existingFiles ;", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "existingFiles    =    listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "assertFalse ( existingFiles . isEmpty (  )  )  ;", "}", "Path   stagingPathRoot ;", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "ConnectorInsertTableHandle   insertTableHandle    =    metadata . beginInsert ( session ,    tableHandle )  ;", "ConnectorPageSink   sink    =    pageSinkProvider . createPageSink ( transaction . getTransactionHandle (  )  ,    session ,    insertTableHandle )  ;", "sink . appendPage ( AbstractTestHiveClient . CREATE _ TABLE _ DATA . toPage (  )  )  ;", "sink . appendPage ( AbstractTestHiveClient . CREATE _ TABLE _ DATA . toPage (  )  )  ;", "MoreFutures . getFutureValue ( sink . finish (  )  )  ;", "assertEquals ( listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ,    existingFiles )  ;", "stagingPathRoot    =    getStagingPathRoot ( insertTableHandle )  ;", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "Set < String >    tempFiles    =    listAllDataFiles ( context ,    stagingPathRoot )  ;", "assertTrue (  (  !  ( tempFiles . isEmpty (  )  )  )  )  ;", "for    ( String   filePath    :    tempFiles )     {", "assertTrue ( new   Path ( filePath )  . getName (  )  . startsWith ( getFilePrefix ( insertTableHandle )  )  )  ;", "}", "transaction . rollback (  )  ;", "}", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( newSession (  )  ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "assertTrue ( listAllDataFiles ( context ,    stagingPathRoot )  . isEmpty (  )  )  ;", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =    AbstractTestHiveClient . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . empty (  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    resultBuilder . build (  )  . getMaterializedRows (  )  )  ;", "assertEquals ( listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ,    existingFiles )  ;", "}", "}", "METHOD_END"], "methodName": ["doInsert"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "doCreateEmptyTable ( tableName ,    storageFormat ,    AbstractTestHiveClient . CREATE _ TABLE _ COLUMNS _ PARTITIONED )  ;", "MaterializedResult . Builder   resultBuilder    =    MaterializedResult . resultBuilder ( HiveTestUtils . SESSION ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getTypes (  )  )  ;", "for    ( int   i    =     0  ;    i    <     3  ;    i +  +  )     {", "insertData ( tableName ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA )  ;", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < String >    partitionNames    =    transaction . getMetastore ( tableName . getSchemaName (  )  )  . getPartitionNames ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . orElseThrow (  (  )     -  >    new   AssertionError (  (  \" Table   does   not   exist :     \"     +    tableName )  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( partitionNames ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getMaterializedRows (  )  . stream (  )  . map (  (    row )     -  >     \" ds =  \"     +     ( row . getField (  (  ( AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getTypes (  )  . size (  )  )     -     1  )  )  )  )  . collect ( Collectors . toList (  )  )  )  ;", "List < ColumnHandle >    columnHandles    =    AbstractTestHiveClient . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "resultBuilder . rows ( AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getMaterializedRows (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . of ( storageFormat )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    resultBuilder . build (  )  . getMaterializedRows (  )  )  ;", "}", "}", "Set < String >    existingFiles ;", "Path   stagingPathRoot ;", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "existingFiles    =    listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "assertFalse ( existingFiles . isEmpty (  )  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "ConnectorInsertTableHandle   insertTableHandle    =    metadata . beginInsert ( session ,    tableHandle )  ;", "stagingPathRoot    =    getStagingPathRoot ( insertTableHandle )  ;", "ConnectorPageSink   sink    =    pageSinkProvider . createPageSink ( transaction . getTransactionHandle (  )  ,    session ,    insertTableHandle )  ;", "sink . appendPage ( AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . toPage (  )  )  ;", "sink . appendPage ( AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . toPage (  )  )  ;", "MoreFutures . getFutureValue ( sink . finish (  )  )  ;", "assertEquals ( listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ,    existingFiles )  ;", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "Set < String >    tempFiles    =    listAllDataFiles ( context ,    getStagingPathRoot ( insertTableHandle )  )  ;", "assertTrue (  (  !  ( tempFiles . isEmpty (  )  )  )  )  ;", "for    ( String   filePath    :    tempFiles )     {", "assertTrue ( new   Path ( filePath )  . getName (  )  . startsWith ( getFilePrefix ( insertTableHandle )  )  )  ;", "}", "transaction . rollback (  )  ;", "}", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =    AbstractTestHiveClient . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    newSession (  )  ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . empty (  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    resultBuilder . build (  )  . getMaterializedRows (  )  )  ;", "assertEquals ( listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ,    existingFiles )  ;", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "assertTrue ( listAllDataFiles ( context ,    stagingPathRoot )  . isEmpty (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["doInsertIntoExistingPartition"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "doCreateEmptyTable ( tableName ,    storageFormat ,    AbstractTestHiveClient . CREATE _ TABLE _ COLUMNS _ PARTITIONED )  ;", "String   queryId    =    insertData ( tableName ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA )  ;", "Set < String >    existingFiles ;", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "List < String >    partitionNames    =    transaction . getMetastore ( tableName . getSchemaName (  )  )  . getPartitionNames ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . orElseThrow (  (  )     -  >    new   AssertionError (  (  \" Table   does   not   exist :     \"     +    tableName )  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( partitionNames ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getMaterializedRows (  )  . stream (  )  . map (  (    row )     -  >     \" ds =  \"     +     ( row . getField (  (  ( AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getTypes (  )  . size (  )  )     -     1  )  )  )  )  . collect ( Collectors . toList (  )  )  )  ;", "Map < String ,    Optional < Partition >  >    partitions    =    getMetastoreClient ( tableName . getSchemaName (  )  )  . getPartitionsByNames ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  ,    partitionNames )  ;", "assertEquals ( partitions . size (  )  ,    partitionNames . size (  )  )  ;", "for    ( String   partitionName    :    partitionNames )     {", "Partition   partition    =    partitions . get ( partitionName )  . get (  )  ;", "assertEquals ( partition . getParameters (  )  . get ( HiveMetadata . PRESTO _ VERSION _ NAME )  ,    AbstractTestHiveClient . TEST _ SERVER _ VERSION )  ;", "assertEquals ( partition . getParameters (  )  . get ( HiveMetadata . PRESTO _ QUERY _ ID _ NAME )  ,    queryId )  ;", "}", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =    AbstractTestHiveClient . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . of ( storageFormat )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getMaterializedRows (  )  )  ;", "existingFiles    =    listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "assertFalse ( existingFiles . isEmpty (  )  )  ;", "}", "Path   stagingPathRoot ;", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "ConnectorInsertTableHandle   insertTableHandle    =    metadata . beginInsert ( session ,    tableHandle )  ;", "stagingPathRoot    =    getStagingPathRoot ( insertTableHandle )  ;", "ConnectorPageSink   sink    =    pageSinkProvider . createPageSink ( transaction . getTransactionHandle (  )  ,    session ,    insertTableHandle )  ;", "sink . appendPage ( AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA _  2 ND . toPage (  )  )  ;", "MoreFutures . getFutureValue ( sink . finish (  )  )  ;", "assertEquals ( listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ,    existingFiles )  ;", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "Set < String >    tempFiles    =    listAllDataFiles ( context ,    getStagingPathRoot ( insertTableHandle )  )  ;", "assertTrue (  (  !  ( tempFiles . isEmpty (  )  )  )  )  ;", "for    ( String   filePath    :    tempFiles )     {", "assertTrue ( new   Path ( filePath )  . getName (  )  . startsWith ( getFilePrefix ( insertTableHandle )  )  )  ;", "}", "transaction . rollback (  )  ;", "}", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =    AbstractTestHiveClient . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    newSession (  )  ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . empty (  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getMaterializedRows (  )  )  ;", "assertEquals ( listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ,    existingFiles )  ;", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "assertTrue ( listAllDataFiles ( context ,    stagingPathRoot )  . isEmpty (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["doInsertIntoNewPartition"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "List < Column >    columns    =    ImmutableList . of ( new   Column (  \" dummy \"  ,    HiveType . valueOf (  \" uniontype < smallint , tinyint >  \"  )  ,    Optional . empty (  )  )  )  ;", "List < Column >    partitionColumns    =    ImmutableList . of ( new   Column (  \" name \"  ,    HiveType . HIVE _ STRING ,    Optional . empty (  )  )  )  ;", "createEmptyTable ( tableName ,    storageFormat ,    columns ,    partitionColumns )  ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "metadata . beginInsert ( session ,    tableHandle )  ;", "fail (  \" expected   failure \"  )  ;", "}    catch    ( PrestoException   e )     {", "assertThat ( e )  . hasMessageMatching (  \" Inserting   into   Hive   table    .  *    with   column   type   uniontype < smallint , tinyint >    not   supported \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["doInsertUnsupportedWriteType"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "doCreateEmptyTable ( tableName ,    storageFormat ,    AbstractTestHiveClient . CREATE _ TABLE _ COLUMNS _ PARTITIONED )  ;", "insertData ( tableName ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA )  ;", "MaterializedResult . Builder   expectedResultBuilder    =    MaterializedResult . resultBuilder ( HiveTestUtils . SESSION ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getTypes (  )  )  ;", "expectedResultBuilder . rows ( AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getMaterializedRows (  )  )  ;", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "List < String >    partitionNames    =    transaction . getMetastore ( tableName . getSchemaName (  )  )  . getPartitionNames ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . orElseThrow (  (  )     -  >    new   AssertionError (  (  \" Table   does   not   exist :     \"     +    tableName )  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( partitionNames ,    AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getMaterializedRows (  )  . stream (  )  . map (  (    row )     -  >     \" ds =  \"     +     ( row . getField (  (  ( AbstractTestHiveClient . CREATE _ TABLE _ PARTITIONED _ DATA . getTypes (  )  . size (  )  )     -     1  )  )  )  )  . collect ( Collectors . toList (  )  )  )  ;", "Set < String >    filesAfterInsert    =    listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "assertFalse ( filesAfterInsert . isEmpty (  )  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =    AbstractTestHiveClient . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . of ( storageFormat )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    expectedResultBuilder . build (  )  . getMaterializedRows (  )  )  ;", "}", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "HiveColumnHandle   dsColumnHandle    =     (  ( HiveColumnHandle )     ( metadata . getColumnHandles ( session ,    tableHandle )  . get (  \" ds \"  )  )  )  ;", "session    =    newSession (  )  ;", "TupleDomain < ColumnHandle >    tupleDomain    =    TupleDomain . fromFixedValues ( ImmutableMap . of ( dsColumnHandle ,    NullableValue . of ( VarcharType . createUnboundedVarcharType (  )  ,    Slices . utf 8 Slice (  \"  2  0  1  5  -  0  7  -  0  3  \"  )  )  )  )  ;", "Constraint < ColumnHandle >    constraint    =    new   Constraint ( tupleDomain ,    HiveMetadata . convertToPredicate ( tupleDomain )  )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( session ,    tableHandle ,    constraint ,    Optional . empty (  )  )  ;", "ConnectorTableLayoutHandle   tableLayoutHandle    =    getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  ;", "metadata . metadataDelete ( session ,    tableHandle ,    tableLayoutHandle )  ;", "transaction . commit (  )  ;", "}", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =    AbstractTestHiveClient . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "HiveColumnHandle   dsColumnHandle    =     (  ( HiveColumnHandle )     ( metadata . getColumnHandles ( session ,    tableHandle )  . get (  \" ds \"  )  )  )  ;", "int   dsColumnOrdinalPosition    =    columnHandles . indexOf ( dsColumnHandle )  ;", "session    =    newSession (  )  ;", "ImmutableList < MaterializedRow >    expectedRows    =    expectedResultBuilder . build (  )  . getMaterializedRows (  )  . stream (  )  . filter (  (    row )     -  >     !  (  \"  2  0  1  5  -  0  7  -  0  3  \"  . equals ( row . getField ( dsColumnOrdinalPosition )  )  )  )  . collect ( toImmutableList (  )  )  ;", "MaterializedResult   actualAfterDelete    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . of ( storageFormat )  )  ;", "Assertions . assertEqualsIgnoreOrder ( actualAfterDelete . getMaterializedRows (  )  ,    expectedRows )  ;", "}", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "HiveColumnHandle   dsColumnHandle    =     (  ( HiveColumnHandle )     ( metadata . getColumnHandles ( session ,    tableHandle )  . get (  \" ds \"  )  )  )  ;", "session    =    newSession (  )  ;", "TupleDomain < ColumnHandle >    tupleDomain 2     =    TupleDomain . withColumnDomains ( ImmutableMap . of ( dsColumnHandle ,    Domain . create ( ValueSet . ofRanges ( Range . range ( VarcharType . createUnboundedVarcharType (  )  ,    Slices . utf 8 Slice (  \"  2  0  1  5  -  0  7  -  0  1  \"  )  ,    true ,    Slices . utf 8 Slice (  \"  2  0  1  5  -  0  7  -  0  2  \"  )  ,    true )  )  ,    false )  )  )  ;", "Constraint < ColumnHandle >    constraint 2     =    new   Constraint ( tupleDomain 2  ,    HiveMetadata . convertToPredicate ( tupleDomain 2  )  )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults 2     =    metadata . getTableLayouts ( session ,    tableHandle ,    constraint 2  ,    Optional . empty (  )  )  ;", "ConnectorTableLayoutHandle   tableLayoutHandle 2     =    getOnlyElement ( tableLayoutResults 2  )  . getTableLayout (  )  . getHandle (  )  ;", "metadata . metadataDelete ( session ,    tableHandle ,    tableLayoutHandle 2  )  ;", "transaction . commit (  )  ;", "}", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =    ImmutableList . copyOf ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "session    =    newSession (  )  ;", "MaterializedResult   actualAfterDelete 2     =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . of ( storageFormat )  )  ;", "Assertions . assertEqualsIgnoreOrder ( actualAfterDelete 2  . getMaterializedRows (  )  ,    ImmutableList . of (  )  )  ;", "Set < String >    filesAfterDelete    =    listAllDataFiles ( transaction ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "assertTrue ( filesAfterDelete . isEmpty (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["doTestMetadataDelete"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "String   schemaName    =    schemaTableName . getSchemaName (  )  ;", "String   tableName    =    schemaTableName . getTableName (  )  ;", "doCreateEmptyTable ( schemaTableName ,    storageFormat ,    tableBefore )  ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    schemaTableName )  ;", "ConnectorInsertTableHandle   insertTableHandle    =    metadata . beginInsert ( session ,    tableHandle )  ;", "ConnectorPageSink   sink    =    pageSinkProvider . createPageSink ( transaction . getTransactionHandle (  )  ,    session ,    insertTableHandle )  ;", "sink . appendPage ( dataBefore . toPage (  )  )  ;", "Collection < Slice >    fragments    =    MoreFutures . getFutureValue ( sink . finish (  )  )  ;", "metadata . finishInsert ( session ,    insertTableHandle ,    fragments )  ;", "transaction . commit (  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    schemaTableName )  ;", "List < ColumnHandle >    columnHandles    =    metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  . stream (  )  . filter (  (    columnHandle )     -  >     !  (  (  ( HiveColumnHandle )     ( columnHandle )  )  . isHidden (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . empty (  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    dataBefore . getMaterializedRows (  )  )  ;", "transaction . commit (  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "PrincipalPrivileges   principalPrivileges    =    testingPrincipalPrivilege ( session . getUser (  )  )  ;", "Table   oldTable    =    transaction . getMetastore ( schemaName )  . getTable ( schemaName ,    tableName )  . get (  )  ;", "HiveTypeTranslator   hiveTypeTranslator    =    new   HiveTypeTranslator (  )  ;", "List < Column >    dataColumns    =    tableAfter . stream (  )  . filter (  (    columnMetadata )     -  >     !  ( columnMetadata . getName (  )  . equals (  \" ds \"  )  )  )  . map (  (    columnMetadata )     -  >    new   Column ( columnMetadata . getName (  )  ,    toHiveType ( hiveTypeTranslator ,    columnMetadata . getType (  )  )  ,    Optional . empty (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "Table . Builder   newTable    =    Table . builder ( oldTable )  . setDataColumns ( dataColumns )  ;", "transaction . getMetastore ( schemaName )  . replaceView ( schemaName ,    tableName ,    newTable . build (  )  ,    principalPrivileges )  ;", "transaction . commit (  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    schemaTableName )  ;", "List < ColumnHandle >    columnHandles    =    metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  . stream (  )  . filter (  (    columnHandle )     -  >     !  (  (  ( HiveColumnHandle )     ( columnHandle )  )  . isHidden (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . empty (  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    dataAfter . getMaterializedRows (  )  )  ;", "transaction . commit (  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    schemaTableName )  ;", "ConnectorInsertTableHandle   insertTableHandle    =    metadata . beginInsert ( session ,    tableHandle )  ;", "ConnectorPageSink   sink    =    pageSinkProvider . createPageSink ( transaction . getTransactionHandle (  )  ,    session ,    insertTableHandle )  ;", "sink . appendPage ( dataAfter . toPage (  )  )  ;", "Collection < Slice >    fragments    =    MoreFutures . getFutureValue ( sink . finish (  )  )  ;", "metadata . finishInsert ( session ,    insertTableHandle ,    fragments )  ;", "transaction . commit (  )  ;", "fail (  \" expected   exception \"  )  ;", "}    catch    ( PrestoException   e )     {", "assertEquals ( e . getErrorCode (  )  ,    HiveErrorCode . HIVE _ PARTITION _ SCHEMA _ MISMATCH . toErrorCode (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["doTestMismatchSchemaTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "Path   writePath    =    null ;", "Path   targetPath    =    null ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "try    {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "ConnectorSession   session ;", ". rollbackIfEquals ( tag ,     . TransactionDeleteInsertTestTag . ROLLBACK _ RIGHT _ AWAY )  ;", "session    =    newSession (  )  ;", "HiveColumnHandle   dsColumnHandle    =     (  ( HiveColumnHandle )     ( metadata . getColumnHandles ( session ,    tableHandle )  . get (  \" pk 2  \"  )  )  )  ;", "TupleDomain < ColumnHandle >    tupleDomain    =    TupleDomain . withColumnDomains ( ImmutableMap . of ( dsColumnHandle ,    domainToDrop )  )  ;", "Constraint < ColumnHandle >    constraint    =    new   Constraint ( tupleDomain ,    HiveMetadata . convertToPredicate ( tupleDomain )  )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( session ,    tableHandle ,    constraint ,    Optional . empty (  )  )  ;", "ConnectorTableLayoutHandle   tableLayoutHandle    =    getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  ;", "metadata . metadataDelete ( session ,    tableHandle ,    tableLayoutHandle )  ;", ". rollbackIfEquals ( tag ,     . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ DELETE )  ;", "session    =    newSession (  )  ;", "ConnectorInsertTableHandle   insertTableHandle    =    metadata . beginInsert ( session ,    tableHandle )  ;", ". rollbackIfEquals ( tag ,     . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ BEGIN _ INSERT )  ;", "writePath    =    getStagingPathRoot ( insertTableHandle )  ;", "targetPath    =    getTargetPathRoot ( insertTableHandle )  ;", "ConnectorPageSink   sink    =    pageSinkProvider . createPageSink ( transaction . getTransactionHandle (  )  ,    session ,    insertTableHandle )  ;", "sink . appendPage ( insertData . toPage (  )  )  ;", ". rollbackIfEquals ( tag ,     . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ APPEND _ PAGE )  ;", "Collection < Slice >    fragments    =    MoreFutures . getFutureValue ( sink . finish (  )  )  ;", ". rollbackIfEquals ( tag ,     . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ SINK _ FINISH )  ;", "metadata . finishInsert ( session ,    insertTableHandle ,    fragments )  ;", ". rollbackIfEquals ( tag ,     . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ FINISH _ INSERT )  ;", "assertEquals ( tag ,     . TransactionDeleteInsertTestTag . COMMIT )  ;", "if    ( conflictTrigger . isPresent (  )  )     {", "JsonCodec < PartitionUpdate >    partitionUpdateCodec    =    JsonCodec . jsonCodec ( PartitionUpdate . class )  ;", "List < PartitionUpdate >    partitionUpdates    =    fragments . stream (  )  . map ( Slice :  : getBytes )  . map ( partitionUpdateCodec :  : fromJson )  . collect ( Collectors . toList (  )  )  ;", "conflictTrigger . get (  )  . triggerConflict ( session ,    tableName ,    insertTableHandle ,    partitionUpdates )  ;", "}", "transaction . commit (  )  ;", "if    ( conflictTrigger . isPresent (  )  )     {", "assertTrue ( expectQuerySucceed )  ;", "conflictTrigger . get (  )  . verifyAndCleanup ( tableName )  ;", "}", "}    catch    (  . TestingRollbackException   e )     {", "transaction . rollback (  )  ;", "}    catch    ( PrestoException   e )     {", "assertFalse ( expectQuerySucceed )  ;", "if    ( conflictTrigger . isPresent (  )  )     {", "conflictTrigger . get (  )  . verifyAndCleanup ( tableName )  ;", "}", "}", "}", "if    (  ( writePath    !  =    null )     &  &     (  !  ( writePath . equals ( targetPath )  )  )  )     {", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( newSession (  )  ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "FileSystem   fileSystem    =    hdfsEnvironment . getFileSystem ( context ,    writePath )  ;", "assertFalse ( fileSystem . exists ( writePath )  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "List < String >    partitionNames    =    transaction . getMetastore ( tableName . getSchemaName (  )  )  . getPartitionNames ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . orElseThrow (  (  )     -  >    new   AssertionError (  (  \" Table   does   not   exist :     \"     +    tableName )  )  )  ;", "Assertions . assertEqualsIgnoreOrder ( partitionNames ,    expectedData . getMaterializedRows (  )  . stream (  )  . map (  (    row )     -  >    format (  \" pk 1  =  % s / pk 2  =  % s \"  ,    row . getField (  1  )  ,    row . getField (  2  )  )  )  . distinct (  )  . collect ( Collectors . toList (  )  )  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "List < ColumnHandle >    columnHandles    =     . filterNonHiddenColumnHandles ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "MaterializedResult   result    =    readTable ( transaction ,    tableHandle ,    columnHandles ,    session ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . of ( storageFormat )  )  ;", "Assertions . assertEqualsIgnoreOrder ( result . getMaterializedRows (  )  ,    expectedData . getMaterializedRows (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["doTestTransactionDeleteInsert"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   handle    =    metadata . getTableHandle ( session ,    table )  ;", "if    ( handle    =  =    null )     {", "return ;", "}", "metadata . dropTable ( session ,    handle )  ;", "try    {", "metadata . dropTable ( session ,    handle )  ;", "fail (  \" expected   NotFoundException \"  )  ;", "}    catch    ( TableNotFoundException   expected )     {", "}", "transaction . commit (  )  ;", "}    catch    ( Exception   e )     {", "Logger . get ( getClass (  )  )  . warn ( e ,     \" failed   to   drop   table \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["dropTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   columnHandles . stream (  )  . filter (  (    columnHandle )     -  >     !  (  (  ( HiveColumnHandle )     ( columnHandle )  )  . isHidden (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "}", "METHOD_END"], "methodName": ["filterNonHiddenColumnHandles"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   columnMetadatas . stream (  )  . filter (  (    columnMetadata )     -  >     !  ( columnMetadata . isHidden (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "}", "METHOD_END"], "methodName": ["filterNonHiddenColumnMetadata"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HiveTableLayoutHandle )     ( layoutHandle )  )  . getPartitions (  )  . orElseThrow (  (  )     -  >    new   AssertionError (  \" layout   has   no   partitions \"  )  )  ;", "}", "METHOD_END"], "methodName": ["getAllPartitions"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < ConnectorSplit >    splits    =    ImmutableList . builder (  )  ;", "while    (  !  ( splitSource . isFinished (  )  )  )     {", "splits . addAll ( MoreFutu . getFutureValue ( splitSource . getNextBatch ( NotPartitionedPartitionHandle . NOT _ PARTITIONED ,     1  0  0  0  )  )  . getSplits (  )  )  ;", "}", "return   splits . build (  )  ;", "}", "METHOD_END"], "methodName": ["getAllSplits"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( session ,    tableHandle ,    new   com . facebook . presto . spi . Constraint ( tupleDomain ,     (    bindings )     -  >    true )  ,    Optional . empty (  )  )  ;", "ConnectorTableLayoutHandle   layoutHandle    =    getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  ;", "return   AbstractTestHiveClient . getAllSplits ( splitManager . getSplits ( transaction . getTransactionHandle (  )  ,    session ,    layoutHandle ,    SplitSchedulingStrategy . UNGROUPED _ SCHEDULING )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getAllSplits"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HiveWritableTableHandle )     ( insertTableHandle )  )  . getFilePrefix (  )  ;", "}", "METHOD_END"], "methodName": ["getFilePrefix"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HiveWritableTableHandle )     ( outputTableHandle )  )  . getFilePrefix (  )  ;", "}", "METHOD_END"], "methodName": ["getFilePrefix"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "List < ConnectorSplit >    splits    =    getAllSplits ( tableHandle ,    TupleDomain . all (  )  )  ;", "assertEquals ( splits . size (  )  ,     1  )  ;", "return    (  ( Split )     ( getOnlyElement ( splits )  )  )  ;", "}", "METHOD_END"], "methodName": ["getHiveSplit"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   locationService ;", "}", "METHOD_END"], "methodName": ["getLocationService"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   metastoreClient ;", "}", "METHOD_END"], "methodName": ["getMetastoreClient"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HivePartition )     ( partition )  )  . getPartitionId (  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionId"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "int   splitCount    =     0  ;", "while    (  !  ( splitSource . isFinished (  )  )  )     {", "splitCount    +  =    MoreFutu . getFutureValue ( splitSource . getNextBatch ( NotPartitionedPartitionHandle . NOT _ PARTITIONED ,     1  0  0  0  )  )  . getSplits (  )  . size (  )  ;", "}", "return   splitCount ;", "}", "METHOD_END"], "methodName": ["getSplitCount"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "HiveInsertTableHandle   handle    =     (  ( HiveInsertTableHandle )     ( insertTableHandle )  )  ;", "return   getLocationService ( handle . getSchemaName (  )  )  . writePathRoot ( handle . getLocationHandle (  )  )  . orElseThrow (  (  )     -  >    new   AssertionError (  \" no   write   path   root \"  )  )  ;", "}", "METHOD_END"], "methodName": ["getStagingPathRoot"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "HiveOutputTableHandle   handle    =     (  ( HiveOutputTableHandle )     ( outputTableHandle )  )  ;", "return   getLocationService ( handle . getSchemaName (  )  )  . writePathRoot ( handle . getLocationHandle (  )  )  . orElseThrow (  (  )     -  >    new   AssertionError (  \" no   write   path   root \"  )  )  ;", "}", "METHOD_END"], "methodName": ["getStagingPathRoot"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "ConnectorTableHandle   handle    =    metadata . getTableHandle ( newSession (  )  ,    tableName )  ;", "checkArgum (  ( handle    !  =    null )  ,     \" table   not   found :     % s \"  ,    tableName )  ;", "return   handle ;", "}", "METHOD_END"], "methodName": ["getTableHandle"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "HiveInsertTableHandle   hiveInsertTableHandle    =     (  ( HiveInsertTableHandle )     ( insertTableHandle )  )  ;", "return   getLocationService ( hiveInsertTableHandle . getSchemaName (  )  )  . targetPathRoot ( hiveInsertTableHandle . getLocationHandle (  )  )  ;", "}", "METHOD_END"], "methodName": ["getTargetPathRoot"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "Builder < String ,    Integer >    index    =    ImmutableMap . builder (  )  ;", "int   i    =     0  ;", "for    ( ColumnMetadata   columnMetadata    :    tableMetadata . getColumns (  )  )     {", "index . put ( columnMetadata . getName (  )  ,    i )  ;", "i +  +  ;", "}", "return   index . build (  )  ;", "}", "METHOD_END"], "methodName": ["indexColumns"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "Builder < String ,    Integer >    index    =    ImmutableMap . builder (  )  ;", "int   i    =     0  ;", "for    ( ColumnHandle   columnHandle    :    columnHandles )     {", "olumnHandle   hiveColumnHandle    =     (  ( olumnHandle )     ( columnHandle )  )  ;", "index . put ( hiveColumnHandle . getName (  )  ,    i )  ;", "i +  +  ;", "}", "return   index . build (  )  ;", "}", "METHOD_END"], "methodName": ["indexColumns"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "Path   writePath ;", "Path   targetPath ;", "String   queryId ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableName )  ;", "ConnectorInsertTableHandle   insertTableHandle    =    metadata . beginInsert ( session ,    tableHandle )  ;", "queryId    =    session . getQueryId (  )  ;", "writePath    =    getStagingPathRoot ( insertTableHandle )  ;", "targetPath    =    getTargetPathRoot ( insertTableHandle )  ;", "ConnectorPageSink   sink    =    pageSinkProvider . createPageSink ( transaction . getTransactionHandle (  )  ,    session ,    insertTableHandle )  ;", "sink . appendPage ( data . toPage (  )  )  ;", "Collection < Slice >    fragments    =    MoreFutures . getFutureValue ( sink . finish (  )  )  ;", "metadata . finishInsert ( session ,    insertTableHandle ,    fragments )  ;", "transaction . commit (  )  ;", "}", "if    (  !  ( writePath . equals ( targetPath )  )  )     {", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( newSession (  )  ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "FileSystem   fileSystem    =    hdfsEnvironment . getFileSystem ( context ,    writePath )  ;", "assertFalse ( fileSystem . exists ( writePath )  )  ;", "}", "return   queryId ;", "}", "METHOD_END"], "methodName": ["insertData"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( newSession (  )  ,    schemaName ,    tableName )  ;", "Set < String >    existingFiles    =    new   HashSet <  >  (  )  ;", "for    ( String   location    :     . listAllDataPaths ( transaction . getMetastore ( schemaName )  ,    schemaName ,    tableName )  )     {", "existingFiles . addAll ( listAllDataFiles ( context ,    new   Path ( location )  )  )  ;", "}", "return   existingFiles ;", "}", "METHOD_END"], "methodName": ["listAllDataFiles"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "Set < String >    result    =    new   HashSet <  >  (  )  ;", "FileSystem   fileSystem    =    hdfsEnvironment . getFileSystem ( context ,    path )  ;", "if    ( fileSystem . exists ( path )  )     {", "for    ( FileStatus   fileStatus    :    fileSystem . listStatus ( path )  )     {", "if    ( fileStatus . getPath (  )  . getName (  )  . startsWith (  \"  . presto \"  )  )     {", "} else", "if    ( adoop . HadoopFileStatus . isFile ( fileStatus )  )     {", "result . add ( fileStatus . getPath (  )  . toString (  )  )  ;", "} else", "if    ( adoop . HadoopFileStatus . isDirectory ( fileStatus )  )     {", "result . addAll ( listAllDataFiles ( context ,    fileStatus . getPath (  )  )  )  ;", "}", "}", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["listAllDataFiles"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < String >    locations    =    ImmutableList . builder (  )  ;", "Table   table    =    metare . getTable ( schemaName ,    tableName )  . get (  )  ;", "if    (  ( table . getStorage (  )  . getLocation (  )  )     !  =    null )     {", "locations . add ( table . getStorage (  )  . getLocation (  )  )  ;", "}", "Optional < List < String >  >    partitionNames    =    metare . getPartitionNames ( schemaName ,    tableName )  ;", "if    ( partitionNames . isPresent (  )  )     {", "metare . getPartitionsByNames ( schemaName ,    tableName ,    partitionNames . get (  )  )  . values (  )  . stream (  )  . map ( Optional :  : get )  . map (  (    partition )     -  >    partition . getStorage (  )  . getLocation (  )  )  . filter (  (    location )     -  >     !  ( location . startsWith ( table . getStorage (  )  . getLocation (  )  )  )  )  . forEach ( locations :  : add )  ;", "}", "return   locations . build (  )  ;", "}", "METHOD_END"], "methodName": ["listAllDataPaths"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "FileSystem   fileSystem    =    hdfsEnvironment . getFileSystem ( context ,    path )  ;", "return   Arrays . stream ( fileSystem . listStatus ( path )  )  . map ( FileStatus :  : getPath )  . map ( Path :  : getName )  . filter (  (    name )     -  >     !  ( name . startsWith (  \"  \"  )  )  )  . collect ( Collectors . toList (  )  )  ;", "}", "METHOD_END"], "methodName": ["listDirectory"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   new   com . facebook . presto . testing . TestingConnectorSession ( new   HiveSessionProperties ( new   HiveClientConfig (  )  ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "}", "METHOD_END"], "methodName": ["newSession"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   new   AbstractTestHiveClient . HiveTransaction ( transactionManager ,    metadataFactory . create (  )  )  ;", "}", "METHOD_END"], "methodName": ["newTransaction"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "switch    ( hiveStorageFormat )     {", "case   RCTEXT    :", "case   RCBINARY    :", "return   RcFilePageSource . class ;", "case   ORC    :", "case   DWRF    :", "return   OrcPageSource . class ;", "case   PARQUET    :", "return   ParquetPageSource . class ;", "default    :", "throw   new   AssertionError (  (  \" File   type   does   not   use   a   PageSource :     \"     +    hiveStorageFormat )  )  ;", "}", "}", "METHOD_END"], "methodName": ["pageSourceType"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    transaction . getMetadata (  )  . getTableLayouts ( session ,    tableHandle ,    new   com . facebook . presto . spi . Constraint ( tupleDomain ,     (    bindings )     -  >    true )  ,    Optional . empty (  )  )  ;", "ConnectorTableLayoutHandle   layoutHandle    =    getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  ;", "List < ConnectorSplit >    splits    =     . getAllSplits ( splitManager . getSplits ( transaction . getTransactionHandle (  )  ,    session ,    layoutHandle ,    SplitSchedulingStrategy . UNGROUPED _ SCHEDULING )  )  ;", "if    ( expectedSplitCount . isPresent (  )  )     {", "assertEquals ( splits . size (  )  ,    expectedSplitCount . getAsInt (  )  )  ;", "}", "ImmutableList . Builder < MaterializedRow >    allRows    =    ImmutableList . builder (  )  ;", "for    ( ConnectorSplit   split    :    splits )     {", "try    ( ConnectorPageSource   pageSource    =    pageSourceProvider . createPageSource ( transaction . getTransactionHandle (  )  ,    session ,    split ,    columnHandles )  )     {", "expectedStorageFormat . ifPresent (  (    format )     -  >     . assertPageSourceType ( pageSource ,    format )  )  ;", "MaterializedResult   result    =    materializeSourceDataStream ( session ,    pageSource ,    HiveTestUtils . getTypes ( columnHandles )  )  ;", "allRows . addAll ( result . getMaterializedRows (  )  )  ;", "}", "}", "return   new   MaterializedResult ( allRows . build (  )  ,    HiveTestUtils . getTypes ( columnHandles )  )  ;", "}", "METHOD_END"], "methodName": ["readTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "switch    ( hiveStorageFormat )     {", "case   PARQUET    :", "return   ParqueRecordCursor . class ;", "}", "return   GenericHiveRecordCursor . class ;", "}", "METHOD_END"], "methodName": ["recordCursorType"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "if    ( expectedTag    =  =    tag )     {", "throw   new    . TestingRollbackException (  )  ;", "}", "}", "METHOD_END"], "methodName": ["rollbackIfEquals"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "HiveConnectorId   connectorId    =    new   HiveConnectorId (  \" hive - test \"  )  ;", "setupHive ( connectorId . toString (  )  ,    databaseName ,    hiveClientConfig . getTimeZone (  )  )  ;", "metastoreClient    =    hiveMetastore ;", "HdfsConfiguration   hdfsConfiguration    =    new   HiveHdfsConfiguration ( new   HdfsConfigurationUpdater ( hiveClientConfig )  )  ;", "hdfsEnvironment    =    new   HdfsEnvironment ( hdfsConfiguration ,    hiveClientConfig ,    new   NoHdfsAuthentication (  )  )  ;", "locationService    =    new   HiveLocationService ( hdfsEnvironment )  ;", "JsonCodec < PartitionUpdate >    partitionUpdateCodec    =    JsonCodec . jsonCodec ( PartitionUpdate . class )  ;", "metadataFactory    =    new   HiveMetadataFactory ( metastoreClient ,    hdfsEnvironment ,    new   HivePartitionManager ( HiveTestUtils . TYPE _ MANAGER ,    hiveClientConfig )  ,    timeZone ,     1  0  ,    true ,    false ,    true ,    false ,    true ,     1  0  0  0  ,    new   HiveClientConfig (  )  . getMaxPartitionsPerScan (  )  ,    HiveTestUtils . TYPE _ MANAGER ,    locationService ,    new   TableParameterCodec (  )  ,    partitionUpdateCodec ,    Executors . newFixedThreadPool (  2  )  ,    new   HiveTypeTranslator (  )  ,     . TEST _ SERVER _ VERSION )  ;", "transactionManager    =    new   HiveTransactionManager (  )  ;", "splitManager    =    new   HiveSplitManager (  (    transactionHandle )     -  >     (  ( HiveMetadata )     ( transactionManager . get ( transactionHandle )  )  )  . getMetastore (  )  ,    new   NamenodeStats (  )  ,    hdfsEnvironment ,    new   HadoopDirectoryLister (  )  ,    directExecutor (  )  ,    new   HiveCoercionPolicy ( HiveTestUtils . TYPE _ MANAGER )  ,    new   CounterStat (  )  ,     1  0  0  ,    hiveClientConfig . getMaxOutstandingSplitsSize (  )  ,    hiveClientConfig . getMinPartitionBatchSize (  )  ,    hiveClientConfig . getMaxPartitionBatchSize (  )  ,    hiveClientConfig . getMaxInitialSplits (  )  ,    hiveClientConfig . getSplitLoaderConcurrency (  )  ,    false )  ;", "pageSinkProvider    =    new   HivePageSinkProvider ( HiveTestUtils . getDefaultHiveFileWriterFactories ( hiveClientConfig )  ,    hdfsEnvironment ,    metastoreClient ,    new   com . facebook . presto . GroupByHashPageIndexerFactory (  . JOIN _ COMPILER )  ,    HiveTestUtils . TYPE _ MANAGER ,    new   HiveClientConfig (  )  ,    locationService ,    partitionUpdateCodec ,    new   TestingNodeManager (  \" fake - environment \"  )  ,    new   HiveEventClient (  )  ,    new   HiveSessionProperties ( hiveClientConfig ,    new   OrcFileWriterConfig (  )  )  ,    new   HiveWriterStats (  )  )  ;", "pageSourceProvider    =    new   HivePageSourceProvider ( hiveClientConfig ,    hdfsEnvironment ,    HiveTestUtils . getDefaultHiveRecordCursorProvider ( hiveClientConfig )  ,    HiveTestUtils . getDefaultHiveDataStreamFactories ( hiveClientConfig )  ,    HiveTestUtils . TYPE _ MANAGER )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "HiveClientConfig   hiveClientConfig    =    new   HiveClientConfig (  )  ;", "hiveClientConfig . setTimeZone ( timeZone )  ;", "String   proxy    =    System . getProperty (  \" hive . metastore . thrift . client . socks - proxy \"  )  ;", "if    ( proxy    !  =    null )     {", "hiveClientConfig . setMetastoreSocksProxy ( HostAndPort . fromString ( proxy )  )  ;", "}", "HiveCluster   hiveCluster    =    new   TestingHiveCluster ( hiveClientConfig ,    host ,    port )  ;", "ExtendedHiveMetastore   metastore    =    new   CachingHiveMetastore ( new   BridgingHiveMetastore ( new   ThriftHiveMetastore ( hiveCluster )  )  ,    executor ,    Duration . valueOf (  \"  1 m \"  )  ,    Duration . valueOf (  \"  1  5 s \"  )  ,     1  0  0  0  0  )  ;", "setup ( databaseName ,    hiveClientConfig ,    metastore )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "executor    =    Executors . newCachedThreadPool ( Threads . daemonThreadsNamed (  \" hive -  % s \"  )  )  ;", "}", "METHOD_END"], "methodName": ["setupClass"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "if    (  ( executor )     !  =    null )     {", "executor . shutdownNow (  )  ;", "executor    =    null ;", "}", "}", "METHOD_END"], "methodName": ["tearDown"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   AbstractTestHiveClient . temporaryTable ( database ,    tableName )  ;", "}", "METHOD_END"], "methodName": ["temporaryTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "String   randomName    =    UUID . randomUUID (  )  . toString (  )  . toLowerCase ( Locale . ENGLISH )  . replace (  \"  -  \"  ,     \"  \"  )  ;", "return   new   SchemaTableName ( database ,     (  (  (  (  . TEMPORARY _ TABLE _ PREFIX )     +    tableName )     +     \"  _  \"  )     +    randomName )  )  ;", "}", "METHOD_END"], "methodName": ["temporaryTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveStorageFormat   storageFormat    :    createTableFormats )     {", "SchemaTableName   temporaryBucketEvolutionTable    =    temporaryTable (  \" bucket _ evolution \"  )  ;", "try    {", "doTestBucketedTableEvolution ( storageFormat ,    temporaryBucketEvolutionTable )  ;", "}    finally    {", "dropTable ( temporaryBucketEvolutionTable )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testBucketedTableEvolution"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertEmptyFile ( HiveStorageFormat . DWRF )  ;", "}", "METHOD_END"], "methodName": ["testEmptyDwrfFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertEmptyFile ( HiveStorageFormat . ORC )  ;", "}", "METHOD_END"], "methodName": ["testEmptyOrcFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertEmptyFile ( HiveStorageFormat . RCBINARY )  ;", "}", "METHOD_END"], "methodName": ["testEmptyRcBinaryFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertEmptyFile ( HiveStorageFormat . RCTEXT )  ;", "}", "METHOD_END"], "methodName": ["testEmptyRcTextFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertEmptyFile ( HiveStorageFormat . SEQUENCEFILE )  ;", "}", "METHOD_END"], "methodName": ["testEmptySequenceFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveStorageFormat   storageFormat    :    createTableFormats )     {", "SchemaTableName   temporaryCreateEmptyTable    =    temporaryTable (  \" create _ empty \"  )  ;", "try    {", "doCreateEmptyTable ( temporaryCreateEmptyTable ,    storageFormat ,     . CREATE _ TABLE _ COLUMNS )  ;", "}    finally    {", "dropTable ( temporaryCreateEmptyTable )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testEmptyTableCreation"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertEmptyFile ( HiveStorageFormat . TEXTFILE )  ;", "}", "METHOD_END"], "methodName": ["testEmptyTextFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "Map < SchemaTableName ,    List < ColumnMetadata >  >    allColumns    =    metadata . listTableColumns ( newSession (  )  ,    new   SchemaTablePrefix (  )  )  ;", "assertTrue ( allColumns . containsKey ( tablePartitionFormat )  )  ;", "assertTrue ( allColumns . containsKey ( tableUnpartitioned )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetAllTableColumns"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "Map < SchemaTableName ,    List < ColumnMetadata >  >    allColumns    =    metadata . listTableColumns ( newSession (  )  ,    new   SchemaTablePrefix ( database )  )  ;", "assertTrue ( allColumns . containsKey ( tablePartitionFormat )  )  ;", "assertTrue ( allColumns . containsKey ( tableUnpartitioned )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetAllTableColumnsInSchema"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "List < SchemaTableName >    tables    =    metadata . listTables ( newSession (  )  ,    null )  ;", "assertTrue ( tables . contains ( tablePartitionFormat )  )  ;", "assertTrue ( tables . contains ( tableUnpartitioned )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetAllTableNames"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "List < String >    databases    =    metadata . listSchemaNames ( newSession (  )  )  ;", "assertTrue ( databases . contains ( database )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetDatabaseNames"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tablePartitionFormat )  ;", "List < ColumnHandle >    columnHandles    =    ImmutableList . copyOf ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "Map < String ,    Integer >    columnIndex    =    AbstractTestHiveClient . indexColumns ( columnHandles )  ;", "List < ConnectorSplit >    splits    =    getAllSplits ( tableHandle ,    TupleDomain . all (  )  )  ;", "assertEquals ( splits . size (  )  ,    partitionCount )  ;", "for    ( ConnectorSplit   split    :    splits )     {", "HiveSplit   hiveSplit    =     (  ( HiveSplit )     ( split )  )  ;", "List < HivePartitionKey >    partitionKeys    =    hiveSplit . getPartitionKeys (  )  ;", "String   ds    =    partitionKeys . get (  0  )  . getValue (  )  ;", "String   fileFormat    =    partitionKeys . get (  1  )  . getValue (  )  ;", "HiveStorageFormat   fileType    =    HiveStorageFormat . valueOf ( fileFormat . toUpperCase (  )  )  ;", "int   dummyPartition    =    Integer . parseInt ( partitionKeys . get (  2  )  . getValue (  )  )  ;", "long   rowNumber    =     0  ;", "try    ( ConnectorPageSource   pageSource    =    pageSourceProvider . createPageSource ( transaction . getTransactionHandle (  )  ,    session ,    hiveSplit ,    columnHandles )  )     {", "AbstractTestHiveClient . assertPageSourceType ( pageSource ,    fileType )  ;", "MaterializedResult   result    =    materializeSourceDataStream ( session ,    pageSource ,    HiveTestUtils . getTypes ( columnHandles )  )  ;", "for    ( MaterializedRow   row    :    result )     {", "rowNumber +  +  ;", "assertEquals ( row . getField ( columnIndex . get (  \" t _ double \"  )  )  ,     (  6  .  2     +    rowNumber )  )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" ds \"  )  )  ,    ds )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" file _ format \"  )  )  ,    fileFormat )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" dummy \"  )  )  ,    dummyPartition )  ;", "}", "}", "assertEquals ( rowNumber ,     1  0  0  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testGetPartialRecords"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tablePartitionFormat )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( newSession (  )  ,    tableHandle ,    Constraint . alwaysTrue (  )  ,    Optional . empty (  )  )  ;", "assertExpectedTableLayout ( getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  ,    tableLayout )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionNames"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "metadata . getTableLayouts ( newSession (  )  ,    invalidTableHandle ,    Constraint . alwaysTrue (  )  ,    Optional . empty (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionNamesException"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableUnpartitioned )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( newSession (  )  ,    tableHandle ,    Constraint . alwaysTrue (  )  ,    Optional . empty (  )  )  ;", "assertEquals ( getAllPartitions ( getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  )  . size (  )  ,     1  )  ;", "assertExpectedTableLayout ( getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  ,    unpartitionedTableLayout )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionNamesUnpartitioned"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tablePartitionFormat )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( session ,    tableHandle ,    Constraint . alwaysTrue (  )  ,    Optional . empty (  )  )  ;", "ConnectorSplitSource   splitSource    =    splitManager . getSplits ( transaction . getTransactionHandle (  )  ,    session ,    getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  ,    SplitSchedulingStrategy . UNGROUPED _ SCHEDULING )  ;", "assertEquals ( AbstractTestHiveClient . getSplitCount ( splitSource )  ,    partitionCount )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionSplitsBatch"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "splitManager . getSplits ( transaction . getTransactionHandle (  )  ,    newSession (  )  ,    invalidTableLayoutHandle ,    SplitSchedulingStrategy . UNGROUPED _ SCHEDULING )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionSplitsBatchInvalidTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableUnpartitioned )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( session ,    tableHandle ,    Constraint . alwaysTrue (  )  ,    Optional . empty (  )  )  ;", "ConnectorSplitSource   splitSource    =    splitManager . getSplits ( transaction . getTransactionHandle (  )  ,    session ,    getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  ,    SplitSchedulingStrategy . UNGROUPED _ SCHEDULING )  ;", "assertEquals ( AbstractTestHiveClient . getSplitCount ( splitSource )  ,     1  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionSplitsBatchUnpartitioned"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableNotReadable )  ;", "assertNotNull ( tableHandle )  ;", "ColumnHandle   dsColumn    =    metadata . getColumnHandles ( session ,    tableHandle )  . get (  \" ds \"  )  ;", "assertNotNull ( dsColumn )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( session ,    tableHandle ,    Constraint . alwaysTrue (  )  ,    Optional . empty (  )  )  ;", "try    {", "AbstractTestHiveClient . getSplitCount ( splitManager . getSplits ( transaction . getTransactionHandle (  )  ,    session ,    getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  ,    SplitSchedulingStrategy . UNGROUPED _ SCHEDULING )  )  ;", "fail (  \" Expected   HiveNotReadableException \"  )  ;", "}    catch    ( HiveNotReadableException   e )     {", "assertThat ( e )  . hasMessageMatching (  \" Table    \\  '  .  *  \\  \\  . presto _ test _ not _ readable \\  '    is   not   readable :    reason   for   not   readable \"  )  ;", "assertEquals ( e . getTableName (  )  ,    tableNotReadable )  ;", "assertEquals ( e . getPartition (  )  ,    Optional . empty (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionSplitsTableNotReadablePartition"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableOfflinePartition )  ;", "assertNotNull ( tableHandle )  ;", "ColumnHandle   dsColumn    =    metadata . getColumnHandles ( session ,    tableHandle )  . get (  \" ds \"  )  ;", "assertNotNull ( dsColumn )  ;", "Domain   domain    =    Domain . singleValue ( VarcharType . createUnboundedVarcharType (  )  ,    Slices . utf 8 Slice (  \"  2  0  1  2  -  1  2  -  3  0  \"  )  )  ;", "TupleDomain < ColumnHandle >    tupleDomain    =    TupleDomain . withColumnDomains ( ImmutableMap . of ( dsColumn ,    domain )  )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( session ,    tableHandle ,    new   com . facebook . presto . spi . Constraint ( tupleDomain ,     (    bindings )     -  >    true )  ,    Optional . empty (  )  )  ;", "try    {", "AbstractTestHiveClient . getSplitCount ( splitManager . getSplits ( transaction . getTransactionHandle (  )  ,    session ,    getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  ,    SplitSchedulingStrategy . UNGROUPED _ SCHEDULING )  )  ;", "fail (  \" Expected   PartitionOfflineException \"  )  ;", "}    catch    ( PartitionOfflineException   e )     {", "assertEquals ( e . getTableName (  )  ,    tableOfflinePartition )  ;", "assertEquals ( e . getPartition (  )  ,     \" ds =  2  0  1  2  -  1  2  -  3  0  \"  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionSplitsTableOfflinePartition"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "try    {", "getTableHandle ( metadata ,    tableOffline )  ;", "fail (  \" expected   TableOfflineException \"  )  ;", "}    catch    ( TableOfflineException   e )     {", "assertEquals ( e . getTableName (  )  ,    tableOffline )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionTableOffline"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tablePartitionFormat )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( newSession (  )  ,    tableHandle ,    Constraint . alwaysTrue (  )  ,    Optional . empty (  )  )  ;", "assertExpectedTableLayout ( getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  ,    tableLayout )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetPartitions"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "metadata . getTableLayouts ( newSession (  )  ,    invalidTableHandle ,    Constraint . alwaysTrue (  )  ,    Optional . empty (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetPartitionsException"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tablePartitionFormat )  ;", "ConnectorTableMetadata   tableMetadata    =    metadata . getTableMetadata ( session ,    tableHandle )  ;", "List < ColumnHandle >    columnHandles    =    ImmutableList . copyOf ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "Map < String ,    Integer >    columnIndex    =    AbstractTestHiveClient . indexColumns ( columnHandles )  ;", "List < ConnectorSplit >    splits    =    getAllSplits ( tableHandle ,    TupleDomain . all (  )  )  ;", "assertEquals ( splits . size (  )  ,    partitionCount )  ;", "for    ( ConnectorSplit   split    :    splits )     {", "HiveSplit   hiveSplit    =     (  ( HiveSplit )     ( split )  )  ;", "List < HivePartitionKey >    partitionKeys    =    hiveSplit . getPartitionKeys (  )  ;", "String   ds    =    partitionKeys . get (  0  )  . getValue (  )  ;", "String   fileFormat    =    partitionKeys . get (  1  )  . getValue (  )  ;", "HiveStorageFormat   fileType    =    HiveStorageFormat . valueOf ( fileFormat . toUpperCase (  )  )  ;", "int   dummyPartition    =    Integer . parseInt ( partitionKeys . get (  2  )  . getValue (  )  )  ;", "long   rowNumber    =     0  ;", "long   completedBytes    =     0  ;", "try    ( ConnectorPageSource   pageSource    =    pageSourceProvider . createPageSource ( transaction . getTransactionHandle (  )  ,    session ,    hiveSplit ,    columnHandles )  )     {", "MaterializedResult   result    =    materializeSourceDataStream ( session ,    pageSource ,    HiveTestUtils . getTypes ( columnHandles )  )  ;", "AbstractTestHiveClient . assertPageSourceType ( pageSource ,    fileType )  ;", "for    ( MaterializedRow   row    :    result )     {", "try    {", "AbstractTestHiveClient . assertValueTypes ( row ,    tableMetadata . getColumns (  )  )  ;", "}    catch    ( RuntimeException   e )     {", "throw   new   RuntimeException (  (  \" row    \"     +    rowNumber )  ,    e )  ;", "}", "rowNumber +  +  ;", "Object   value ;", "value    =    row . getField ( columnIndex . get (  \" t _ string \"  )  )  ;", "if    (  ( rowNumber    %     1  9  )     =  =     0  )     {", "assertNull ( value )  ;", "} else", "if    (  ( rowNumber    %     1  9  )     =  =     1  )     {", "assertEquals ( value ,     \"  \"  )  ;", "} else    {", "assertEquals ( value ,     \" test \"  )  ;", "}", "assertEquals ( row . getField ( columnIndex . get (  \" t _ tinyint \"  )  )  ,     (  ( byte )     (  1     +    rowNumber )  )  )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" t _ smallint \"  )  )  ,     (  ( short )     (  2     +    rowNumber )  )  )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" t _ int \"  )  )  ,     (  3     +     (  ( int )     ( rowNumber )  )  )  )  ;", "if    (  ( rowNumber    %     1  3  )     =  =     0  )     {", "assertNull ( row . getField ( columnIndex . get (  \" t _ bigint \"  )  )  )  ;", "} else    {", "assertEquals ( row . getField ( columnIndex . get (  \" t _ bigint \"  )  )  ,     (  4     +    rowNumber )  )  ;", "}", "assertEquals (  (  ( Float )     ( row . getField ( columnIndex . get (  \" t _ float \"  )  )  )  )  ,     (  5  .  1 F    +    rowNumber )  ,     0  .  0  0  1  )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" t _ double \"  )  )  ,     (  6  .  2     +    rowNumber )  )  ;", "if    (  ( rowNumber    %     3  )     =  =     2  )     {", "assertNull ( row . getField ( columnIndex . get (  \" t _ boolean \"  )  )  )  ;", "} else    {", "assertEquals ( row . getField ( columnIndex . get (  \" t _ boolean \"  )  )  ,     (  ( rowNumber    %     3  )     !  =     0  )  )  ;", "}", "assertEquals ( row . getField ( columnIndex . get (  \" ds \"  )  )  ,    ds )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" file _ format \"  )  )  ,    fileFormat )  ;", "assertEquals ( row . getField ( columnIndex . get (  \" dummy \"  )  )  ,    dummyPartition )  ;", "long   newCompletedBytes    =    pageSource . getCompletedBytes (  )  ;", "assertTrue (  ( newCompletedBytes    >  =    completedBytes )  )  ;", "assertTrue (  ( newCompletedBytes    <  =     ( hiveSplit . getLength (  )  )  )  )  ;", "completedBytes    =    newCompletedBytes ;", "}", "assertTrue (  ( completedBytes    <  =     ( hiveSplit . getLength (  )  )  )  )  ;", "assertEquals ( rowNumber ,     1  0  0  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["testGetRecords"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   connectorMetadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   table    =    getTableHandle ( connectorMetadata ,    tableUnpartitioned )  ;", "readTable ( transaction ,    table ,    ImmutableList . of ( invalidColumnHandle )  ,    newSession (  )  ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . empty (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetRecordsInvalidColumn"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableUnpartitioned )  ;", "List < ColumnHandle >    columnHandles    =    ImmutableList . copyOf ( metadata . getColumnHandles ( session ,    tableHandle )  . values (  )  )  ;", "Map < String ,    Integer >    columnIndex    =    AbstractTestHiveClient . indexColumns ( columnHandles )  ;", "List < ConnectorSplit >    splits    =    getAllSplits ( tableHandle ,    TupleDomain . all (  )  )  ;", "assertEquals ( splits . size (  )  ,     1  )  ;", "for    ( ConnectorSplit   split    :    splits )     {", "HiveSplit   hiveSplit    =     (  ( HiveSplit )     ( split )  )  ;", "assertEquals ( hiveSplit . getPartitionKeys (  )  ,    ImmutableList . of (  )  )  ;", "long   rowNumber    =     0  ;", "try    ( ConnectorPageSource   pageSource    =    pageSourceProvider . createPageSource ( transaction . getTransactionHandle (  )  ,    session ,    split ,    columnHandles )  )     {", "AbstractTestHiveClient . assertPageSourceType ( pageSource ,    HiveStorageFormat . TEXTFILE )  ;", "MaterializedResult   result    =    materializeSourceDataStream ( session ,    pageSource ,    HiveTestUtils . getTypes ( columnHandles )  )  ;", "for    ( MaterializedRow   row    :    result )     {", "rowNumber +  +  ;", "if    (  ( rowNumber    %     1  9  )     =  =     0  )     {", "assertNull ( row . getField ( columnIndex . get (  \" t _ string \"  )  )  )  ;", "} else", "if    (  ( rowNumber    %     1  9  )     =  =     1  )     {", "assertEquals ( row . getField ( columnIndex . get (  \" t _ string \"  )  )  ,     \"  \"  )  ;", "} else    {", "assertEquals ( row . getField ( columnIndex . get (  \" t _ string \"  )  )  ,     \" unpartitioned \"  )  ;", "}", "assertEquals ( row . getField ( columnIndex . get (  \" t _ tinyint \"  )  )  ,     (  ( byte )     (  1     +    rowNumber )  )  )  ;", "}", "}", "assertEquals ( rowNumber ,     1  0  0  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testGetRecordsUnpartitioned"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "List < SchemaTableName >    tables    =    metadata . listTables ( newSession (  )  ,    database )  ;", "assertTrue ( tables . contains ( tablePartitionFormat )  )  ;", "assertTrue ( tables . contains ( tableUnpartitioned )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetTableNames"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "assertNull ( metadata . getTableHandle ( newSession (  )  ,    invalidTable )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetTableSchemaException"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableNotReadable )  ;", "ConnectorTableMetadata   tableMetadata    =    metadata . getTableMetadata ( newSession (  )  ,    tableHandle )  ;", "Map < String ,    ColumnMetadata >    map    =    uniqueIndex ( tableMetadata . getColumns (  )  ,    ColumnMetadata :  : getName )  ;", "AbstractTestHiveClient . assertPrimitiveField ( map ,     \" t _ string \"  ,    VarcharType . createUnboundedVarcharType (  )  ,    false )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetTableSchemaNotReadablePartition"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "Map < SchemaTableName ,    List < ColumnMetadata >  >    columns    =    metadata . listTableColumns ( newSession (  )  ,    tableOffline . toSchemaTablePrefix (  )  )  ;", "assertEquals ( columns . size (  )  ,     1  )  ;", "Map < String ,    ColumnMetadata >    map    =    uniqueIndex ( getOnlyElement ( columns . values (  )  )  ,    ColumnMetadata :  : getName )  ;", "AbstractTestHiveClient . assertPrimitiveField ( map ,     \" t _ string \"  ,    VarcharType . createUnboundedVarcharType (  )  ,    false )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetTableSchemaOffline"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   tableHandle    =    getTableHandle ( metadata ,    tableOfflinePartition )  ;", "ConnectorTableMetadata   tableMetadata    =    metadata . getTableMetadata ( newSession (  )  ,    tableHandle )  ;", "Map < String ,    ColumnMetadata >    map    =    uniqueIndex ( tableMetadata . getColumns (  )  ,    ColumnMetadata :  : getName )  ;", "AbstractTestHiveClient . assertPrimitiveField ( map ,     \" t _ string \"  ,    VarcharType . createUnboundedVarcharType (  )  ,    false )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetTableSchemaOfflinePartition"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertTableStatsComputed ( tableBucketedStringInt ,    ImmutableSet . of (  \" t _ bigint \"  ,     \" t _ boolean \"  ,     \" t _ double \"  ,     \" t _ float \"  ,     \" t _ int \"  ,     \" t _ smallint \"  ,     \" t _ string \"  ,     \" t _ tinyint \"  ,     \" ds \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testGetTableStatsBucketedStringInt"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertTableStatsComputed ( tableUnpartitioned ,    ImmutableSet . of (  \" t _ string \"  ,     \" t _ tinyint \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testGetTableStatsUnpartitioned"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "try    {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "getTableHandle ( metadata ,    view )  ;", "fail (  \" Expected   HiveViewNotSupportedException \"  )  ;", "}    catch    ( HiveViewNotSupportedException   e )     {", "assertEquals ( e . getTableName (  )  ,    view )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testHiveViewsAreNotSupported"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "assertEquals ( metadata . listTableColumns ( newSession (  )  ,    new   com . facebook . presto . spi . SchemaTablePrefix ( view . getSchemaName (  )  ,    view . getTableName (  )  )  )  ,    ImmutableMap . of (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testHiveViewsHaveNoColumns"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveStorageFormat   storageFormat    :    createTableFormats )     {", "SchemaTableName   temporaryInsertTable    =    temporaryTable (  \" insert \"  )  ;", "try    {", "doInsert ( storageFormat ,    temporaryInsertTable )  ;", "}    finally    {", "dropTable ( temporaryInsertTable )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testInsert"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveStorageFormat   storageFormat    :    createTableFormats )     {", "SchemaTableName   temporaryInsertIntoExistingPartitionTable    =    temporaryTable (  \" insert _ existing _ partitioned \"  )  ;", "try    {", "doInsertIntoExistingPartition ( storageFormat ,    temporaryInsertIntoExistingPartitionTable )  ;", "}    finally    {", "dropTable ( temporaryInsertIntoExistingPartitionTable )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testInsertIntoExistingPartition"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveStorageFormat   storageFormat    :    createTableFormats )     {", "SchemaTableName   temporaryInsertIntoNewPartitionTable    =    temporaryTable (  \" insert _ new _ partitioned \"  )  ;", "try    {", "doInsertIntoNewPartition ( storageFormat ,    temporaryInsertIntoNewPartitionTable )  ;", "}    finally    {", "dropTable ( temporaryInsertIntoNewPartitionTable )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testInsertIntoNewPartition"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "SchemaTableName   temporaryInsertUnsupportedWriteType    =    temporaryTable (  \" insert _ unsupported _ type \"  )  ;", "try    {", "doInsertUnsupportedWriteType ( StorageFormat . ORC ,    temporaryInsertUnsupportedWriteType )  ;", "}    finally    {", "dropTable ( temporaryInsertUnsupportedWriteType )  ;", "}", "}", "METHOD_END"], "methodName": ["testInsertUnsupportedWriteType"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "assertNull ( metadata . getTableHandle ( session ,    new   SchemaTableName ( AbstractTestHiveClient . INVALID _ DATABASE ,    AbstractTestHiveClient . INVALID _ TABLE )  )  )  ;", "assertEquals ( metadata . listTables ( session ,    AbstractTestHiveClient . INVALID _ DATABASE )  ,    ImmutableList . of (  )  )  ;", "assertEquals ( metadata . listTableColumns ( session ,    new   SchemaTablePrefix ( AbstractTestHiveClient . INVALID _ DATABASE ,    AbstractTestHiveClient . INVALID _ TABLE )  )  ,    ImmutableMap . of (  )  )  ;", "assertEquals ( metadata . listViews ( session ,    AbstractTestHiveClient . INVALID _ DATABASE )  ,    ImmutableList . of (  )  )  ;", "assertEquals ( metadata . getViews ( session ,    new   SchemaTablePrefix ( AbstractTestHiveClient . INVALID _ DATABASE ,    AbstractTestHiveClient . INVALID _ TABLE )  )  ,    ImmutableMap . of (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testListUnknownSchema"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveStorageFormat   storageFormat    :    createTableFormats )     {", "SchemaTableName   temporaryMetadataDeleteTable    =    temporaryTable (  \" metadata _ delete \"  )  ;", "try    {", "doTestMetadataDelete ( storageFormat ,    temporaryMetadataDeleteTable )  ;", "}    finally    {", "dropTable ( temporaryMetadataDeleteTable )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testMetadataDelete"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveStorageFormat   storageFormat    :    createTableFormats )     {", "if    ( storageFormat    =  =     ( HiveStorageFormat . JSON )  )     {", "continue ;", "}", "SchemaTableName   temporaryMismatchSchemaTable    =    temporaryTable (  \" mismatch _ schema \"  )  ;", "try    {", "doTestMismatchSchemaTable ( temporaryMismatchSchemaTable ,    storageFormat ,     . MISMATCH _ SCHEMA _ TABLE _ BEFORE ,     . MISMATCH _ SCHEMA _ TABLE _ DATA _ BEFORE ,     . MISMATCH _ SCHEMA _ TABLE _ AFTER ,     . MISMATCH _ SCHEMA _ TABLE _ DATA _ AFTER )  ;", "}    finally    {", "dropTable ( temporaryMismatchSchemaTable )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testMismatchSchemaTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   table    =    getTableHandle ( metadata ,    tablePartitionSchemaChange )  ;", "readTable ( transaction ,    table ,    ImmutableList . of ( dsColumn )  ,    newSession (  )  ,    TupleDomain . all (  )  ,    OptionalInt . empty (  )  ,    Optional . empty (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testPartitionSchemaMismatch"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "SchemaTableName   temporaryRenameTableOld    =    temporaryTable (  \" rename _ old \"  )  ;", "SchemaTableName   temporaryRenameTableNew    =    temporaryTable (  \" rename _ new \"  )  ;", "try    {", "createDummyTable ( temporaryRenameTableOld )  ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "metadata . renameTable ( session ,    getTableHandle ( metadata ,    temporaryRenameTableOld )  ,    temporaryRenameTableNew )  ;", "transaction . commit (  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "assertNull ( metadata . getTableHandle ( session ,    temporaryRenameTableOld )  )  ;", "assertNotNull ( metadata . getTableHandle ( session ,    temporaryRenameTableNew )  )  ;", "}", "}    finally    {", "dropTable ( temporaryRenameTableOld )  ;", "dropTable ( temporaryRenameTableNew )  ;", "}", "}", "METHOD_END"], "methodName": ["testRenameTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveStorageFormat   storageFormat    :    createTableFormats )     {", "SchemaTableName   temporaryCreateTable    =    temporaryTable (  \" create \"  )  ;", "try    {", "doCreateTable ( temporaryCreateTable ,    storageFormat )  ;", "}    finally    {", "dropTable ( temporaryCreateTable )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testTableCreation"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "SchemaTableName   temporaryCreateRollbackTable    =    temporaryTable (  \" create _ rollback \"  )  ;", "try    {", "Path   stagingPathRoot ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableMetadata   tableMetadata    =    new   ConnectorTableMetadata ( temporaryCreateRollbackTable ,     . CREATE _ TABLE _ COLUMNS ,     . createTableProperties ( HiveStorageFormat . RCBINARY )  )  ;", "ConnectorOutputTableHandle   outputHandle    =    metadata . beginCreateTable ( session ,    tableMetadata ,    Optional . empty (  )  )  ;", "ConnectorPageSink   sink    =    pageSinkProvider . createPageSink ( transaction . getTransactionHandle (  )  ,    session ,    outputHandle )  ;", "sink . appendPage (  . CREATE _ TABLE _ DATA . toPage (  )  )  ;", "MoreFutures . getFutureValue ( sink . finish (  )  )  ;", "stagingPathRoot    =    getStagingPathRoot ( outputHandle )  ;", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    temporaryCreateRollbackTable . getSchemaName (  )  ,    temporaryCreateRollbackTable . getTableName (  )  )  ;", "assertFalse ( listAllDataFiles ( context ,    stagingPathRoot )  . isEmpty (  )  )  ;", "transaction . rollback (  )  ;", "}", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( newSession (  )  ,    temporaryCreateRollbackTable . getSchemaName (  )  ,    temporaryCreateRollbackTable . getTableName (  )  )  ;", "assertTrue ( listAllDataFiles ( context ,    stagingPathRoot )  . isEmpty (  )  )  ;", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "assertNull ( metadata . getTableHandle ( session ,    temporaryCreateRollbackTable )  )  ;", "}", "}    finally    {", "dropTable ( temporaryCreateRollbackTable )  ;", "}", "}", "METHOD_END"], "methodName": ["testTableCreationRollback"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorTableHandle   table    =    getTableHandle ( metadata ,    tableWithFooter )  ;", "try    {", "metadata . getTableLayouts ( session ,    table ,    new   com . facebook . presto . spi . Constraint ( TupleDomain . all (  )  ,     (    bindings )     -  >    true )  ,    Optional . empty (  )  )  ;", "fail (  \" expected   exception \"  )  ;", "}    catch    ( PrestoException   e )     {", "assertEquals ( e . getErrorCode (  )  ,    HiveErrorCode . HIVE _ UNSUPPORTED _ FORMAT . toErrorCode (  )  )  ;", "Assertions . assertContains ( e . getMessage (  )  ,     \" Table   with    ' skip . footer . line . count '    is   not   supported \"  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testTableWithFooter"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "doTestTransactionDeleteInsert ( HiveStorageFormat . RCBINARY ,    true ,    ImmutableList .  < AbstractTestHiveClient . TransactionDeleteInsertTestCase > builder (  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( false ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . ROLLBACK _ RIGHT _ AWAY ,    Optional . empty (  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( false ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ DELETE ,    Optional . empty (  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( false ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ BEGIN _ INSERT ,    Optional . empty (  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( false ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ APPEND _ PAGE ,    Optional . empty (  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( false ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ SINK _ FINISH ,    Optional . empty (  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( false ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . ROLLBACK _ AFTER _ FINISH _ INSERT ,    Optional . empty (  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( false ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . COMMIT ,    Optional . of ( new   AbstractTestHiveClient . AddPartitionFailure (  )  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( false ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . COMMIT ,    Optional . of ( new   AbstractTestHiveClient . DirectoryRenameFailure (  )  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( false ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . COMMIT ,    Optional . of ( new   AbstractTestHiveClient . FileRenameFailure (  )  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( true ,    false ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . COMMIT ,    Optional . of ( new   AbstractTestHiveClient . DropPartitionFailure (  )  )  )  )  . add ( new   AbstractTestHiveClient . TransactionDeleteInsertTestCase ( true ,    true ,    AbstractTestHiveClient . TransactionDeleteInsertTestTag . COMMIT ,    Optional . empty (  )  )  )  . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["testTransactionDeleteInsert"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertGetRecordsOptional (  \" presto _ test _ types _ orc \"  ,    HiveStorageFormat . ORC )  ;", "}", "METHOD_END"], "methodName": ["testTypesOrc"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertGetRecordsOptional (  \" presto _ test _ types _ parquet \"  ,    HiveStorageFormat . PARQUET )  ;", "}", "METHOD_END"], "methodName": ["testTypesParquet"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertGetRecords (  \" presto _ test _ types _ rcbinary \"  ,    HiveStorageFormat . RCBINARY )  ;", "}", "METHOD_END"], "methodName": ["testTypesRcBinary"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertGetRecords (  \" presto _ test _ types _ rctext \"  ,    HiveStorageFormat . RCTEXT )  ;", "}", "METHOD_END"], "methodName": ["testTypesRcText"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertGetRecords (  \" presto _ test _ types _ sequencefile \"  ,    HiveStorageFormat . SEQUENCEFILE )  ;", "}", "METHOD_END"], "methodName": ["testTypesSequenceFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "assertGetRecords (  \" presto _ test _ types _ textfile \"  ,    HiveStorageFormat . TEXTFILE )  ;", "}", "METHOD_END"], "methodName": ["testTypesTextFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "SchemaTableName   temporaryCreateView    =    temporaryTable (  \" create _ view \"  )  ;", "try    {", "verifyViewCreation ( temporaryCreateView )  ;", "}    finally    {", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "metadata . dropView ( newSession (  )  ,    temporaryCreateView )  ;", "transaction . commit (  )  ;", "}    catch    ( RuntimeException   e )     {", "}", "}", "}", "METHOD_END"], "methodName": ["testViewCreation"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   new   PrincipalPrivileges ( ImmutableMultimap .  < String ,    HivePrivilegeInfo > builder (  )  . put ( tableOwner ,    new   HivePrivilegeInfo ( HivePrivilegeInfo . HivePrivilege . SELECT ,    true )  )  . put ( tableOwner ,    new   HivePrivilegeInfo ( HivePrivilegeInfo . HivePrivilege . INSERT ,    true )  )  . put ( tableOwner ,    new   HivePrivilegeInfo ( HivePrivilegeInfo . HivePrivilege . UPDATE ,    true )  )  . put ( tableOwner ,    new   HivePrivilegeInfo ( HivePrivilegeInfo . HivePrivilege . DELETE ,    true )  )  . build (  )  ,    ImmutableMultimap . of (  )  )  ;", "}", "METHOD_END"], "methodName": ["testingPrincipalPrivilege"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "return   HiveTestUtils . rowType ( columns . stream (  )  . map (  (    col )     -  >    new   NamedTypeSignature ( format (  \" f _  % s \"  ,    col . getName (  )  )  ,    col . getType (  )  . getTypeSignature (  )  )  )  . collect ( Collectors . toList (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["toRowType"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "doCreateView ( temporaryCreateView ,    true )  ;", "doCreateView ( temporaryCreateView ,    true )  ;", "try    {", "doCreateView ( temporaryCreateView ,    false )  ;", "fail (  \" create   existing   should   fail \"  )  ;", "}    catch    ( ViewAlreadyExistsException   e )     {", "assertEquals ( e . getViewName (  )  ,    temporaryCreateView )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "metadata . dropView ( newSession (  )  ,    temporaryCreateView )  ;", "transaction . commit (  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "assertEquals ( metadata . getViews ( newSession (  )  ,    temporaryCreateView . toSchemaTablePrefix (  )  )  . size (  )  ,     0  )  ;", "assertFalse ( metadata . listViews ( newSession (  )  ,    temporaryCreateView . getSchemaName (  )  )  . contains ( temporaryCreateView )  )  ;", "}", "try    (  . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "metadata . dropView ( newSession (  )  ,    temporaryCreateView )  ;", "fail (  \" drop   non - existing   should   fail \"  )  ;", "}    catch    ( ViewNotFoundException   e )     {", "assertEquals ( e . getViewName (  )  ,    temporaryCreateView )  ;", "}", "doCreateView ( temporaryCreateView ,    false )  ;", "}", "METHOD_END"], "methodName": ["verifyViewCreation"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClient"}, {"methodBody": ["METHOD_START", "{", "try    {", "getMetastoreClient (  . TEST _ DB _ NAME )  . dropDatabase (  . TEST _ DB _ NAME )  ;", "}    finally    {", "deleteRecursively ( tempDir . toPath (  )  ,    ALLOW _ INSECURE )  ;", "}", "}", "METHOD_END"], "methodName": ["cleanup"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientLocal"}, {"methodBody": ["METHOD_START", "{", "tempDir    =    Files . createTempDir (  )  ;", "ExtendedHiveMetastore   metastore    =    createMetastore ( tempDir )  ;", "metastore . createDatabase ( Database . builder (  )  . setDatabaseName (  . TEST _ DB _ NAME )  . setOwnerName (  \" public \"  )  . setOwnerType ( PrincipalType . ROLE )  . build (  )  )  ;", "HiveClientConfig   hiveConfig    =    new   HiveClientConfig (  )  . setTimeZone (  \" America / Los _ Angeles \"  )  ;", "setup (  . TEST _ DB _ NAME ,    hiveConfig ,    metastore )  ;", "}", "METHOD_END"], "methodName": ["initialize"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientLocal"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "transaction . getMetastore ( table . getSchemaName (  )  )  . dropTable ( newSession (  )  ,    table . getSchemaName (  )  ,    table . getTableName (  )  )  ;", "transaction . commit (  )  ;", "}    catch    ( RuntimeException   e )     {", "}", "}", "METHOD_END"], "methodName": ["dropTable"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "ConnectorTableHandle   handle    =    metadata . getTableHandle ( newSession (  )  ,    tableName )  ;", "checkArgum (  ( handle    !  =    null )  ,     \" table   not   found :     % s \"  ,    tableName )  ;", "return   handle ;", "}", "METHOD_END"], "methodName": ["getTableHandle"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "Builder < String ,    Integer >    index    =    ImmutableMap . builder (  )  ;", "int   i    =     0  ;", "for    ( ColumnHandle   columnHandle    :    columnHandles )     {", "olumnHandle   hiveColumnHandle    =     (  ( olumnHandle )     ( columnHandle )  )  ;", "index . put ( hiveColumnHandle . getName (  )  ,    i )  ;", "i +  +  ;", "}", "return   index . build (  )  ;", "}", "METHOD_END"], "methodName": ["indexColumns"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "return   new   com . facebook . presto . testing . TestingConnectorSession ( new   HiveSessionProperties ( new   HiveClientConfig (  )  ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "}", "METHOD_END"], "methodName": ["newSession"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "return   new   AbstractTestHiveClient . HiveTransaction ( transactionManager ,    metadataFactory . create (  )  )  ;", "}", "METHOD_END"], "methodName": ["newTransaction"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "executor    =    Executors . newCachedThreadPool ( Threads . daemonThreadsNamed (  \" hive -  % s \"  )  )  ;", "}", "METHOD_END"], "methodName": ["setUp"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "this . writableBucket    =    writableBucket ;", "setupHive ( databaseName )  ;", "S 3 ConfigurationUpdater   s 3 Config    =    new   PrestoS 3 ConfigurationUpdater ( new   HiveS 3 Config (  )  . setS 3 AwsAccessKey ( awsAccessKey )  . setS 3 AwsSecretKey ( awsSecretKey )  )  ;", "HiveClientConfig   config    =    new   HiveClientConfig (  )  ;", "String   proxy    =    System . getProperty (  \" hive . metastore . thrift . client . socks - proxy \"  )  ;", "if    ( proxy    !  =    null )     {", "config . setMetastoreSocksProxy ( HostAndPort . fromString ( proxy )  )  ;", "}", "HiveConnectorId   connectorId    =    new   HiveConnectorId (  \" hive - test \"  )  ;", "HiveCluster   hiveCluster    =    new   TestingHiveCluster ( config ,    host ,    port )  ;", "ExecutorService   executor    =    Executors . newCachedThreadPool ( Threads . daemonThreadsNamed (  \" hive - s 3  -  % s \"  )  )  ;", "HdfsConfiguration   hdfsConfiguration    =    new   HiveHdfsConfiguration ( new   HdfsConfigurationUpdater ( config ,    s 3 Config )  )  ;", "HivePartitionManager   hivePartitionManager    =    new   HivePartitionManager ( HiveTestUtils . TYPE _ MANAGER ,    config )  ;", "hdfsEnvironment    =    new   HdfsEnvironment ( hdfsConfiguration ,    config ,    new   NoHdfsAuthentication (  )  )  ;", "metastoreClient    =    new    . TestingHiveMetastore ( new   BridgingHiveMetastore ( new   ThriftHiveMetastore ( hiveCluster )  )  ,    executor ,    config ,    writableBucket ,    hdfsEnvironment )  ;", "locationService    =    new   HiveLocationService ( hdfsEnvironment )  ;", "JsonCodec < PartitionUpdate >    partitionUpdateCodec    =    JsonCodec . jsonCodec ( PartitionUpdate . class )  ;", "metadataFactory    =    new   HiveMetadataFactory ( config ,    metastoreClient ,    hdfsEnvironment ,    hivePartitionManager ,    newDirectExecutorService (  )  ,    HiveTestUtils . TYPE _ MANAGER ,    locationService ,    new   TableParameterCodec (  )  ,    partitionUpdateCodec ,    new   HiveTypeTranslator (  )  ,    new   NodeVersion (  \" test _ version \"  )  )  ;", "transactionManager    =    new   HiveTransactionManager (  )  ;", "splitManager    =    new   HiveSplitManager (  (    transactionHandle )     -  >     (  ( HiveMetadata )     ( transactionManager . get ( transactionHandle )  )  )  . getMetastore (  )  ,    new   NamenodeStats (  )  ,    hdfsEnvironment ,    new   HadoopDirectoryLister (  )  ,    new   BoundedExecutor ( executor ,    config . getMaxSplitIteratorThreads (  )  )  ,    new   HiveCoercionPolicy ( HiveTestUtils . TYPE _ MANAGER )  ,    new   CounterStat (  )  ,    config . getMaxOutstandingSplits (  )  ,    config . getMaxOutstandingSplitsSize (  )  ,    config . getMinPartitionBatchSize (  )  ,    config . getMaxPartitionBatchSize (  )  ,    config . getMaxInitialSplits (  )  ,    config . getSplitLoaderConcurrency (  )  ,    config . getRecursiveDirWalkerEnabled (  )  )  ;", "pageSinkProvider    =    new   HivePageSinkProvider ( HiveTestUtils . getDefaultHiveFileWriterFactories ( config )  ,    hdfsEnvironment ,    metastoreClient ,    new   com . facebook . presto . GroupByHashPageIndexerFactory ( new   JoinCompiler (  )  )  ,    HiveTestUtils . TYPE _ MANAGER ,    new   HiveClientConfig (  )  ,    locationService ,    partitionUpdateCodec ,    new   TestingNodeManager (  \" fake - environment \"  )  ,    new   HiveEventClient (  )  ,    new   HiveSessionProperties ( config ,    new   OrcFileWriterConfig (  )  )  ,    new   HiveWriterStats (  )  )  ;", "pageSourceProvider    =    new   HivePageSourceProvider ( config ,    hdfsEnvironment ,    HiveTestUtils . getDefaultHiveRecordCursorProvider ( config )  ,    HiveTestUtils . getDefaultHiveDataStreamFactories ( config )  ,    HiveTestUtils . TYPE _ MANAGER )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "database    =    databaseName ;", "tableS 3     =    new   SchemaTableName ( database ,     \"  _ test _ s 3  \"  )  ;", "String   random    =    UUID . randomUUID (  )  . toString (  )  . toLowerCase ( Locale . ENGLISH )  . replace (  \"  -  \"  ,     \"  \"  )  ;", "temporaryCreateTable    =    new   SchemaTableName ( database ,     (  \" tmp _  _ test _ create _ s 3  _  \"     +    random )  )  ;", "}", "METHOD_END"], "methodName": ["setupHive"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "if    (  ( executor )     !  =    null )     {", "executor . shutdownNow (  )  ;", "executor    =    null ;", "}", "}", "METHOD_END"], "methodName": ["tearDown"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "Path   basePath    =    new   Path ( String . format (  \" s 3  :  /  /  % s /  \"  ,    writableBucket )  )  ;", "Path   tablePath    =    new   Path ( basePath ,     \" presto _ test _ s 3  \"  )  ;", "Path   filePath    =    new   Path ( tablePath ,     \" test 1  . csv \"  )  ;", "FileSystem   fs    =    hdfsEnvironment . getFileSystem (  . TESTING _ CONTEXT ,    basePath )  ;", "assertTrue ( isDirectory ( fs . getFileStatus ( basePath )  )  )  ;", "assertTrue ( isDirectory ( fs . getFileStatus ( tablePath )  )  )  ;", "assertFalse ( isDirectory ( fs . getFileStatus ( filePath )  )  )  ;", "assertFalse ( fs . exists ( new   Path ( basePath ,     \" foo \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testGetFileStatus"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "try    ( AbstractTestHiveClient . Transaction   transaction    =    newTransaction (  )  )     {", "ConnectorMetadata   metadata    =    transaction . getMetadata (  )  ;", "ConnectorSession   session    =    newSession (  )  ;", "ConnectorTableHandle   table    =    getTableHandle ( metadata ,    tableS 3  )  ;", "List < ColumnHandle >    columnHandles    =    ImmutableList . copyOf ( metadata . getColumnHandles ( session ,    table )  . values (  )  )  ;", "Map < String ,    Integer >    columnIndex    =     . indexColumns ( columnHandles )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    metadata . getTableLayouts ( session ,    table ,    new   com . facebook . presto . spi . Constraint ( TupleDomain . all (  )  ,     (    bindings )     -  >    true )  ,    Optional . empty (  )  )  ;", "HiveTableLayoutHandle   layoutHandle    =     (  ( HiveTableLayoutHandle )     ( getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  )  )  ;", "assertEquals ( layoutHandle . getPartitions (  )  . get (  )  . size (  )  ,     1  )  ;", "ConnectorSplitSource   splitSource    =    splitManager . getSplits ( transaction . getTransactionHandle (  )  ,    session ,    layoutHandle ,    SplitSchedulingStrategy . UNGROUPED _ SCHEDULING )  ;", "long   sum    =     0  ;", "for    ( ConnectorSplit   split    :    AbstractTestHiveClient . getAllSplits ( splitSource )  )     {", "try    ( ConnectorPageSource   pageSource    =    pageSourceProvider . createPageSource ( transaction . getTransactionHandle (  )  ,    session ,    split ,    columnHandles )  )     {", "MaterializedResult   result    =    materializeSourceDataStream ( session ,    pageSource ,    HiveTestUtils . getTypes ( columnHandles )  )  ;", "for    ( MaterializedRow   row    :    result )     {", "sum    +  =     (  ( Long )     ( row . getField ( columnIndex . get (  \" t _ bigint \"  )  )  )  )  ;", "}", "}", "}", "assertEquals ( sum ,     7  8  3  0  0  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetRecordsS3"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "Path   basePath    =    new   Path ( String . format (  \" s 3  :  /  /  % s / rename /  % s /  \"  ,    writableBucket ,    UUID . randomUUID (  )  )  )  ;", "FileSystem   fs    =    hdfsEnvironment . getFileSystem (  . TESTING _ CONTEXT ,    basePath )  ;", "assertFalse ( fs . exists ( basePath )  )  ;", "Path   path    =    new   Path ( basePath ,     \" foo . txt \"  )  ;", "assertTrue ( fs . createNewFile ( path )  )  ;", "assertTrue ( fs . exists ( path )  )  ;", "Path   newPath    =    new   Path ( basePath ,     \" bar . txt \"  )  ;", "assertFalse ( fs . exists ( newPath )  )  ;", "assertTrue ( fs . rename ( path ,    newPath )  )  ;", "assertFalse ( fs . exists ( path )  )  ;", "assertTrue ( fs . exists ( newPath )  )  ;", "assertTrue ( fs . createNewFile ( path )  )  ;", "assertFalse ( fs . rename ( path ,    newPath )  )  ;", "assertTrue ( fs . exists ( path )  )  ;", "assertTrue ( fs . rename ( path ,    path )  )  ;", "assertTrue ( fs . exists ( path )  )  ;", "assertTrue ( fs . delete ( path ,    false )  )  ;", "assertFalse ( fs . exists ( path )  )  ;", "Path   source    =    new   Path ( basePath ,     \" source \"  )  ;", "assertTrue ( fs . createNewFile ( new   Path ( source ,     \" test . txt \"  )  )  )  ;", "Path   target    =    new   Path ( basePath ,     \" target \"  )  ;", "assertFalse ( fs . exists ( target )  )  ;", "assertTrue ( fs . rename ( source ,    target )  )  ;", "assertFalse ( fs . exists ( source )  )  ;", "assertTrue ( fs . exists ( target )  )  ;", "assertTrue ( fs . createNewFile ( new   Path ( source ,     \" test . txt \"  )  )  )  ;", "assertTrue ( fs . rename ( source ,    target )  )  ;", "assertFalse ( fs . exists ( source )  )  ;", "target    =    new   Path ( target ,     \" source \"  )  ;", "assertTrue ( fs . exists ( target )  )  ;", "assertTrue ( fs . exists ( new   Path ( target ,     \" test . txt \"  )  )  )  ;", "target    =    new   Path ( basePath ,     \" target \"  )  ;", "assertTrue ( fs . exists ( target )  )  ;", "assertTrue ( fs . delete ( target ,    true )  )  ;", "assertFalse ( fs . exists ( target )  )  ;", "fs . delete ( basePath ,    true )  ;", "}", "METHOD_END"], "methodName": ["testRename"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveStorageFormat   storageFormat    :    HiveStorageFormat . values (  )  )     {", "try    {", "doCreateTable ( temporaryCreateTable ,    storageFormat )  ;", "}    finally    {", "dropTable ( temporaryCreateTable )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testTableCreation"], "fileName": "com.facebook.presto.hive.AbstractTestHiveClientS3"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( keys . length )     =  =     ( values . length )  )  ,     \" array   lengths   don ' t   match \"  )  ;", "Map < K ,    V >    map    =    new   HashMap <  >  (  )  ;", "int   len    =    keys . length ;", "for    ( int   i    =     0  ;    i    <    len ;    i +  +  )     {", "map . put ( keys [ i ]  ,    values [ i ]  )  ;", "}", "return   map ;", "}", "METHOD_END"], "methodName": ["asMap"], "fileName": "com.facebook.presto.hive.AbstractTestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( AbstractTestHiveFileFormats . blockToSlice ( actual )  ,    AbstractTestHiveFileFormats . blockToSlice ( expected )  ,    message )  ;", "}", "METHOD_END"], "methodName": ["assertBlockEquals"], "fileName": "com.facebook.presto.hive.AbstractTestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "SliceOutput   sliceOutput    =    new   DynamicSliceOutput (  1  0  0  0  )  ;", "BlockSerdeUtil . writeBlock ( sliceOutput ,    block )  ;", "return   sliceOutput . slice (  )  ;", "}", "METHOD_END"], "methodName": ["blockToSlice"], "fileName": "com.facebook.presto.hive.AbstractTestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "try    {", "MaterializedResult   result    =    materializeSourceDataStream ( HiveTestUtils . SESSION ,    pageSource ,    types )  ;", "assertEquals ( result . getMaterializedRows (  )  . size (  )  ,    rowCount )  ;", "for    ( MaterializedRow   row    :    result )     {", "for    ( int   i    =     0  ,    testColumnsSize    =    testColumns . size (  )  ;    i    <    testColumnsSize ;    i +  +  )     {", ". TestColumn   testColumn    =    testColumns . get ( i )  ;", "Type   type    =    types . get ( i )  ;", "Object   actualValue    =    row . getField ( i )  ;", "Object   expectedValue    =    testColumn . getExpectedValue (  )  ;", "if    ( expectedValue   instanceof   Slice )     {", "expectedValue    =     (  ( Slice )     ( expectedValue )  )  . toStringUtf 8  (  )  ;", "}", "if    (  ( actualValue    =  =    null )     |  |     ( expectedValue    =  =    null )  )     {", "assertEquals ( actualValue ,    expectedValue ,     (  \" Wrong   value   for   column    \"     +     ( testColumn . getName (  )  )  )  )  ;", "} else", "if    ( testColumn . getObjectInspector (  )  . getTypeName (  )  . equals (  \" float \"  )  )     {", "assertEquals (  (  ( float )     ( actualValue )  )  ,     (  ( float )     ( expectedValue )  )  ,     . EPSILON ,     (  \" Wrong   value   for   column    \"     +     ( testColumn . getName (  )  )  )  )  ;", "} else", "if    ( testColumn . getObjectInspector (  )  . getTypeName (  )  . equals (  \" double \"  )  )     {", "assertEquals (  (  ( double )     ( actualValue )  )  ,     (  ( double )     ( expectedValue )  )  ,     . EPSILON ,     (  \" Wrong   value   for   column    \"     +     ( testColumn . getName (  )  )  )  )  ;", "} else", "if    ( testColumn . getObjectInspector (  )  . getTypeName (  )  . equals (  \" date \"  )  )     {", "com . facebook . presto . spi . type . SqlDate   expectedDate    =    new   com . facebook . presto . spi . type . SqlDate (  (  ( Long )     ( expectedValue )  )  . intValue (  )  )  ;", "assertEquals ( actualValue ,    expectedDate ,     (  \" Wrong   value   for   column    \"     +     ( testColumn . getName (  )  )  )  )  ;", "} else", "if    (  (  ( testColumn . getObjectInspector (  )  . getTypeName (  )  . equals (  \" int \"  )  )     |  |     ( testColumn . getObjectInspector (  )  . getTypeName (  )  . equals (  \" smallint \"  )  )  )     |  |     ( testColumn . getObjectInspector (  )  . getTypeName (  )  . equals (  \" tinyint \"  )  )  )     {", "assertEquals ( actualValue ,    expectedValue )  ;", "} else", "if    ( testColumn . getObjectInspector (  )  . getTypeName (  )  . equals (  \" timestamp \"  )  )     {", "com . facebook . presto . spi . type . SqlTimestamp   expectedTimestamp    =    new   com . facebook . presto . spi . type . SqlTimestamp (  (  ( Long )     ( expectedValue )  )  ,    HiveTestUtils . SESSION . getTimeZoneKey (  )  )  ;", "assertEquals ( actualValue ,    expectedTimestamp ,     (  \" Wrong   value   for   column    \"     +     ( testColumn . getName (  )  )  )  )  ;", "} else", "if    ( testColumn . getObjectInspector (  )  . getTypeName (  )  . startsWith (  \" char \"  )  )     {", "assertEquals ( actualValue ,    padEnd (  (  ( String )     ( expectedValue )  )  ,     (  ( com . facebook . presto . spi . type . CharType )     ( type )  )  . getLength (  )  ,     '     '  )  ,     (  \" Wrong   value   for   column    \"     +     ( testColumn . getName (  )  )  )  )  ;", "} else", "if    (  ( testColumn . getObjectInspector (  )  . getCategory (  )  )     =  =     ( PRIMITIVE )  )     {", "if    ( expectedValue   instanceof   Slice )     {", "expectedValue    =     (  ( Slice )     ( expectedValue )  )  . toStringUtf 8  (  )  ;", "}", "if    ( actualValue   instanceof   Slice )     {", "actualValue    =     (  ( Slice )     ( actualValue )  )  . toStringUtf 8  (  )  ;", "}", "if    ( actualValue   instanceof   com . facebook . presto . spi . type . SqlVarbinary )     {", "actualValue    =    new   String (  (  ( com . facebook . presto . spi . type . SqlVarbinary )     ( actualValue )  )  . getBytes (  )  ,    UTF _  8  )  ;", "}", "if    ( actualValue   instanceof   com . facebook . presto . spi . type . SqlDecimal )     {", "actualValue    =    new   BigDecimal ( actualValue . toString (  )  )  ;", "}", "assertEquals ( actualValue ,    expectedValue ,     (  \" Wrong   value   for   column    \"     +     ( testColumn . getName (  )  )  )  )  ;", "} else    {", "com . facebook . presto . spi . block . BlockBuilder   builder    =    type . createBlockBuilder ( null ,     1  )  ;", "type . writeObject ( builder ,    expectedValue )  ;", "expectedValue    =    type . getObjectValue ( HiveTestUtils . SESSION ,    builder . build (  )  ,     0  )  ;", "assertEquals ( actualValue ,    expectedValue ,     (  \" Wrong   value   for   column    \"     +     ( testColumn . getName (  )  )  )  )  ;", "}", "}", "}", "}    finally    {", "pageSource . close (  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkPageSource"], "fileName": "com.facebook.presto.hive.AbstractTestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "testColumns    =    ImmutableList . copyOf ( filter ( testColumns ,    not ( AbstractTestHiveFileFormats . TestColumn :  : isPartitionKey )  )  )  ;", "List < Type >    types    =    testColumns . stream (  )  . map ( AbstractTestHiveFileFormats . TestColumn :  : getType )  . map ( HiveType :  : valueOf )  . map (  (    type )     -  >    type . getType ( HiveTestUtils . TYPE _ MANAGER )  )  . collect ( Collectors . toList (  )  )  ;", "PageBuilder   pageBuilder    =    new   PageBuilder ( types )  ;", "for    ( int   rowNumber    =     0  ;    rowNumber    <    numRows ;    rowNumber +  +  )     {", "pageBuilder . declarePosition (  )  ;", "for    ( int   columnNumber    =     0  ;    columnNumber    <     ( testColumns . size (  )  )  ;    columnNumber +  +  )     {", "SerDeUtils . serializeObject ( types . get ( columnNumber )  ,    pageBuilder . getBlockBuilder ( columnNumber )  ,    testColumns . get ( columnNumber )  . getWriteValue (  )  ,    testColumns . get ( columnNumber )  . getObjectInspector (  )  ,    false )  ;", "}", "}", "Page   page    =    pageBuilder . build (  )  ;", "JobConf   jobConf    =    new   JobConf (  )  ;", "HdfsConfigurationUpdater . configureCompression ( jobConf ,    compressionCodec )  ;", "Properties   tableProperties    =    new   Properties (  )  ;", "tableProperties . setProperty (  \" columns \"  ,    Joiner . on (  '  ,  '  )  . join ( transform ( testColumns ,    AbstractTestHiveFileFormats . TestColumn :  : getName )  )  )  ;", "tableProperties . setProperty (  \" columns . types \"  ,    Joiner . on (  '  ,  '  )  . join ( transform ( testColumns ,    AbstractTestHiveFileFormats . TestColumn :  : getType )  )  )  ;", "Optional < HiveFileWriter >    fileWriter    =    fileWriterFactory . createFileWriter ( new   Path ( filePath )  ,    testColumns . stream (  )  . map ( AbstractTestHiveFileFormats . TestColumn :  : getName )  . collect ( Collectors . toList (  )  )  ,    StorageFormat . fromHiveStorageFormat ( storageFormat )  ,    tableProperties ,    jobConf ,    session )  ;", "HiveFileWriter   hiveFileWriter    =    fileWriter . orElseThrow (  (  )     -  >    new   IllegalArgumentException (  \" fileWriterFactory \"  )  )  ;", "hiveFileWriter . appendRows ( page )  ;", "hiveFileWriter . commit (  )  ;", "return   new   FileSplit ( new   Path ( filePath )  ,     0  ,    new   File ( filePath )  . length (  )  ,    new   String [  0  ]  )  ;", "}", "METHOD_END"], "methodName": ["createTestFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "HiveOutputFormat <  ?  ,     ?  >    outputFormat    =    AbstractTestHiveFileFormats . newInstance ( storageFormat . getOutputFormat (  )  ,    HiveOutputFormat . class )  ;", "@ SuppressWarnings (  \" deprecation \"  )", "SerDe   serDe    =    AbstractTestHiveFileFormats . newInstance ( storageFormat . getSerDe (  )  ,    SerDe . class )  ;", "testColumns    =    ImmutableList . copyOf ( filter ( testColumns ,    not ( AbstractTestHiveFileFormats . TestColumn :  : isPartitionKey )  )  )  ;", "Properties   tableProperties    =    new   Properties (  )  ;", "tableProperties . setProperty (  \" columns \"  ,    Joiner . on (  '  ,  '  )  . join ( transform ( testColumns ,    AbstractTestHiveFileFormats . TestColumn :  : getName )  )  )  ;", "tableProperties . setProperty (  \" columns . types \"  ,    Joiner . on (  '  ,  '  )  . join ( transform ( testColumns ,    AbstractTestHiveFileFormats . TestColumn :  : getType )  )  )  ;", "serDe . initialize ( new   Configuration (  )  ,    tableProperties )  ;", "JobConf   jobConf    =    new   JobConf (  )  ;", "HdfsConfigurationUpdater . configureCompression ( jobConf ,    compressionCodec )  ;", "RecordWriter   recordWriter    =    outputFormat . getHiveRecordWriter ( jobConf ,    new   Path ( filePath )  ,    Text . class ,     ( compressionCodec    !  =     ( HiveCompressionCodec . NONE )  )  ,    tableProperties ,     (  )     -  >     {", "}  )  ;", "try    {", "serDe . initialize ( new   Configuration (  )  ,    tableProperties )  ;", "SettableStructObjectInspector   objectInspector    =    ObjectInspectorFactory . getStandardStructObjectInspector ( ImmutableList . copyOf ( transform ( testColumns ,    AbstractTestHiveFileFormats . TestColumn :  : getName )  )  ,    ImmutableList . copyOf ( transform ( testColumns ,    AbstractTestHiveFileFormats . TestColumn :  : getObjectInspector )  )  )  ;", "Object   row    =    objectInspector . create (  )  ;", "List < StructField >    fields    =    ImmutableList . copyOf ( objectInspector . getAllStructFieldRefs (  )  )  ;", "for    ( int   rowNumber    =     0  ;    rowNumber    <    numRows ;    rowNumber +  +  )     {", "for    ( int   i    =     0  ;    i    <     ( testColumns . size (  )  )  ;    i +  +  )     {", "Object   writeValue    =    testColumns . get ( i )  . getWriteValue (  )  ;", "if    ( writeValue   instanceof   Slice )     {", "writeValue    =     (  ( Slice )     ( writeValue )  )  . getBytes (  )  ;", "}", "objectInspector . setStructFieldData ( row ,    fields . get ( i )  ,    writeValue )  ;", "}", "Writable   record    =    serDe . serialize ( row ,    objectInspector )  ;", "recordWriter . write ( record )  ;", "}", "}    finally    {", "recordWriter . close ( false )  ;", "}", "Path   path    =    new   Path ( filePath )  ;", "path . getFileSystem ( new   Configuration (  )  )  . setVerifyChecksum ( true )  ;", "File   file    =    new   File ( filePath )  ;", "return   new   FileSplit ( path ,     0  ,    file . length (  )  ,    new   String [  0  ]  )  ;", "}", "METHOD_END"], "methodName": ["createTestFile"], "fileName": "com.facebook.presto.hive.AbstractTestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < HiveColumnHandle >    columns    =    new   ArrayList <  >  (  )  ;", "int   nextHiveColumnIndex    =     0  ;", "for    ( int   i    =     0  ;    i    <     ( testColumns . size (  )  )  ;    i +  +  )     {", ". TestColumn   testColumn    =    testColumns . get ( i )  ;", "int   columnIndex    =     ( testColumn . isPartitionKey (  )  )     ?     -  1     :    nextHiveColumnIndex +  +  ;", "HiveType   hiveType    =    HiveType . valueOf ( testColumn . getObjectInspector (  )  . getTypeName (  )  )  ;", "columns . add ( new   HiveColumnHandle ( testColumn . getName (  )  ,    hiveType ,    hiveType . getTypeSignature (  )  ,    columnIndex ,     ( testColumn . isPartitionKey (  )     ?    HiveColumnHandle . ColumnType . PARTITION _ KEY    :    HiveColumnHandle . ColumnType . REGULAR )  ,    Optional . empty (  )  )  )  ;", "}", "return   columns ;", "}", "METHOD_END"], "methodName": ["getColumnHandles"], "fileName": "com.facebook.presto.hive.AbstractTestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "return   HiveStorageFormat . class . getClassLoader (  )  . loadClass ( className )  . asSubclass ( superType )  . newInstance (  )  ;", "}", "METHOD_END"], "methodName": ["newInstance"], "fileName": "com.facebook.presto.hive.AbstractTestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "ListenableFuture <  ?  >    lastResult    =    BackgroundHiveSplitLoader . COMPLETED _ FUTURE ;", "for    ( InputSplit   inputSplit    :    targetSplits )     {", "Optional < InternalHiveSplit >    internalHiveSplit    =    splitFactory . createInternalHiveSplit (  (  ( FileSplit )     ( inputSplit )  )  )  ;", "if    ( internalHiveSplit . isPresent (  )  )     {", "lastResult    =    hiveSplitSource . addToQueue ( internalHiveSplit . get (  )  )  ;", "}", "if    ( stopped )     {", "return   BackgroundHiveSplitLoader . COMPLETED _ FUTURE ;", "}", "}", "return   lastResult ;", "}", "METHOD_END"], "methodName": ["addSplitsToSource"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "return   Streams . stream ( new   HiveFileIterator ( path ,    fileSystem ,    directoryLister ,    namenodeStats ,     ( recursiveDirWalkerEnabled    ?    HiveFileIterator . NestedDirectoryPolicy . RECURSE    :    HiveFileIterator . NestedDirectoryPolicy . IGNORED )  )  )  . map ( splitFactory :  : createInternalHiveSplit )  . filter ( Optional :  : isPresent )  . map ( Optional :  : get )  . iterator (  )  ;", "}", "METHOD_END"], "methodName": ["createInternalHiveSplitIterator"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "int   tableBucketCount    =    bucketSplitInfo . getBucketCount (  )  ;", "int   partitionBucketCount    =     ( bucketConversion . isPresent (  )  )     ?    bucketConversion . get (  )  . getPartitionBucketCount (  )     :    tableBucketCount ;", "ArrayList < LocatedFileStatus >    files    =    new   ArrayList <  >  ( partitionBucketCount )  ;", "try    {", "Iterators . addAll ( files ,    new   HiveFileIterator ( path ,    fileSystem ,    directoryLister ,    namenodeStats ,    HiveFileIterator . NestedDirectoryPolicy . FAIL )  )  ;", "}    catch    ( HiveFileIterator . NestedDirectoryNotAllowedException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ INVALID _ BUCKET _ FILES ,    String . format (  \" Hive   table    '  % s '    is   corrupt .    Found   sub - directory   in   bucket   directory   for   partition :     % s \"  ,    new   SchemaTableName ( table . getDatabaseName (  )  ,    table . getTableName (  )  )  ,    splitFactory . getPartitionName (  )  )  )  ;", "}", "if    (  ( files . size (  )  )     !  =    partitionBucketCount )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ INVALID _ BUCKET _ FILES ,    String . format (  \" Hive   table    '  % s '    is   corrupt .    The   number   of   files   in   the   directory    (  % s )    does   not   match   the   declared   bucket   count    (  % s )    for   partition :     % s \"  ,    new   SchemaTableName ( table . getDatabaseName (  )  ,    table . getTableName (  )  )  ,    files . size (  )  ,    partitionBucketCount ,    splitFactory . getPartitionName (  )  )  )  ;", "}", "files . sort ( null )  ;", "List < InternalHiveSplit >    splitList    =    new   ArrayList <  >  (  )  ;", "for    ( int   bucketNumber    =     0  ;    bucketNumber    <     ( Math . max ( tableBucketCount ,    partitionBucketCount )  )  ;    bucketNumber +  +  )     {", "int   partitionBucketNumber    =    bucketNumber    %    partitionBucketCount ;", "int   tableBucketNumber    =    bucketNumber    %    tableBucketCount ;", "if    ( bucketSplitInfo . isBucketEnabled ( tableBucketNumber )  )     {", "LocatedFileStatus   file    =    files . get ( partitionBucketNumber )  ;", "splitFactory . createInternalHiveSplit ( file ,    tableBucketNumber )  . ifPresent ( splitList :  : add )  ;", "}", "}", "return   splitList ;", "}", "METHOD_END"], "methodName": ["getBucketedSplits"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( partition . isPresent (  )  )  )     {", "return   ImmutableList . of (  )  ;", "}", "ImmutableList . Builder < HivePartitionKey >    partitionKeys    =    ImmutableList . builder (  )  ;", "List < Column >    keys    =    table . getPartitionColumns (  )  ;", "List < String >    values    =    partition . get (  )  . getValues (  )  ;", "HiveUtil . checkCondition (  (  ( keys . size (  )  )     =  =     ( values . size (  )  )  )  ,    HiveErrorCode . HIVE _ INVALID _ METADATA ,     \" Expected    % s   partition   key   values ,    but   got    % s \"  ,    keys . size (  )  ,    values . size (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( keys . size (  )  )  ;    i +  +  )     {", "String   name    =    keys . get ( i )  . getName (  )  ;", "HiveType   hiveType    =    keys . get ( i )  . getType (  )  ;", "if    (  !  ( hiveType . isSupportedType (  )  )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Unsupported   Hive   type    % s   found   in   partition   keys   of   table    % s .  % s \"  ,    hiveType ,    table . getDatabaseName (  )  ,    table . getTableName (  )  )  )  ;", "}", "String   value    =    values . get ( i )  ;", "HiveUtil . checkCondition (  ( value    !  =    null )  ,    HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,     \" partition   key   value   cannot   be   null   for   field :     % s \"  ,    name )  ;", "partitionKeys . add ( new   HivePartitionKey ( name ,    value )  )  ;", "}", "return   partitionKeys . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionKeys"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( partition . isPresent (  )  )  )     {", "return   table . getStorage (  )  . getLocation (  )  ;", "}", "return   partition . get (  )  . getStorage (  )  . getLocation (  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionLocation"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( partition . isPresent (  )  )  )     {", "return   MetastoreUtil . getchema ( table )  ;", "}", "return   MetastoreUtil . getchema ( partition . get (  )  ,    table )  ;", "}", "METHOD_END"], "methodName": ["getPartitionSchema"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "try    {", "FileStatus [  ]    symlinks    =    fileSystem . listStatus ( symlinkDir ,    HIDDEN _ FILES _ PATH _ FILTER )  ;", "List < Path >    targets    =    new   ArrayList <  >  (  )  ;", "for    ( FileStatus   symlink    :    symlinks )     {", "try    ( BufferedReader   reader    =    new   BufferedReader ( new   InputStreamReader ( fileSystem . open ( symlink . getPath (  )  )  ,    StandardCharsets . UTF _  8  )  )  )     {", "CharStreams . readLines ( reader )  . stream (  )  . map ( Path :  : new )  . forEach ( targets :  : add )  ;", "}", "}", "return   targets ;", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ BAD _ DATA ,     (  \" Error   parsing   symlinks   from :     \"     +    symlinkDir )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["getTargetPathsFromSymlink"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "int   headerCount    =    HiveUtil . getHeaderCount ( schema )  ;", "if    ( headerCount    >     0  )     {", "jobConf . setLong (  \" mapreduce . input . fileinputformat . split . minsize \"  ,    Long . MAX _ VALUE )  ;", "}", "}", "METHOD_END"], "methodName": ["handleFileHeader"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "taskExecutionLock . readLock (  )  . lock (  )  ;", "try    {", "if    (  (  !  ( partitions . isEmpty (  )  )  )     |  |     (  !  ( fileIterators . isEmpty (  )  )  )  )     {", "return ;", "}", "}    catch    ( Exception   e )     {", "hSource . fail ( e )  ;", "checkState ( stopped ,     \" Task   is   not   marked   as   stopped   even   though   it   failed \"  )  ;", "return ;", "}    finally    {", "taskExecutionLock . readLock (  )  . unlock (  )  ;", "}", "taskExecutionLock . writeLock (  )  . lock (  )  ;", "try    {", "if    (  ( partitions . isEmpty (  )  )     &  &     ( fileIterators . isEmpty (  )  )  )     {", "hSource . noMoreSplits (  )  ;", "}", "}    catch    ( Exception   e )     {", "hSource . fail ( e )  ;", "checkState ( stopped ,     \" Task   is   not   marked   as   stopped   even   though   it   failed \"  )  ;", "}    finally    {", "taskExecutionLock . writeLock (  )  . unlock (  )  ;", "}", "}", "METHOD_END"], "methodName": ["invokeNoMoreSplitsIfNecessary"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "String   partitionName    =    partition . getHivePartition (  )  . getPartitionId (  )  ;", "Properties   schema    =     . getPartitionSchema ( table ,    partition . getPartition (  )  )  ;", "List < HivePartitionKey >    partitionKeys    =     . getPartitionKeys ( table ,    partition . getPartition (  )  )  ;", "TupleDomain < HiveColumnHandle >    effectivePredicate    =     (  ( TupleDomain < HiveColumnHandle >  )     ( compactEffectivePredicate )  )  ;", "Path   path    =    new   Path (  . getPartitionLocation ( table ,    partition . getPartition (  )  )  )  ;", "Configuration   configuration    =    hdfsEnvironment . getConfiguration ( hdfsContext ,    path )  ;", "InputFormat <  ?  ,     ?  >    inputFormat    =    HiveUtil . getInputFormat ( configuration ,    schema ,    false )  ;", "FileSystem   fs    =    hdfsEnvironment . getFileSystem ( hdfsContext ,    path )  ;", "if    ( inputFormat   instanceof   SymlinkTextInputFormat )     {", "if    ( tableBucketInfo . isPresent (  )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Bucketed   table   in   SymlinkTextInputFormat   is   not   yet   supported \"  )  ;", "}", "ListenableFuture <  ?  >    lastResult    =     . COMPLETED _ FUTURE ;", "for    ( Path   targetPath    :     . getTargetPathsFromSymlink ( fs ,    path )  )     {", "TextInputFormat   targetInputFormat    =    new   TextInputFormat (  )  ;", "FileSystem   targetFilesystem    =    hdfsEnvironment . getFileSystem ( hdfsContext ,    targetPath )  ;", "JobConf   targetJob    =    ConfigurationUtils . toJobConf ( targetFilesystem . getConf (  )  )  ;", "handleFileHeader ( schema ,    targetJob )  ;", "targetJob . setInputFormat ( TextInputFormat . class )  ;", "targetInputFormat . configure ( targetJob )  ;", "FileInputFormat . setInputPaths ( targetJob ,    targetPath )  ;", "InputSplit [  ]    targetSplits    =    targetInputFormat . getSplits ( targetJob ,     0  )  ;", "InternalHiveSplitFactory   splitFactory    =    new   InternalHiveSplitFactory ( targetFilesystem ,    partitionName ,    inputFormat ,    schema ,    partitionKeys ,    effectivePredicate ,    partition . getColumnCoercions (  )  ,    Optional . empty (  )  ,    HiveSessionProperties . isForceLocalScheduling ( session )  )  ;", "lastResult    =    addSplitsToSource ( targetSplits ,    splitFactory )  ;", "if    ( stopped )     {", "return    . COMPLETED _ FUTURE ;", "}", "}", "return   lastResult ;", "}", "Optional < HiveSplit . BucketConversion >    bucketConversion    =    Optional . empty (  )  ;", "boolean   bucketConversionRequiresWorkerParticipation    =    false ;", "if    ( partition . getPartition (  )  . isPresent (  )  )     {", "Optional < HiveBucketProperty >    partitionBucketProperty    =    partition . getPartition (  )  . get (  )  . getStorage (  )  . getBucketProperty (  )  ;", "if    (  ( tableBucketInfo . isPresent (  )  )     &  &     ( partitionBucketProperty . isPresent (  )  )  )     {", "int   tableBucketCount    =    tableBucketInfo . get (  )  . getBucketCount (  )  ;", "int   partitionBucketCount    =    partitionBucketProperty . get (  )  . getBucketCount (  )  ;", "if    ( tableBucketCount    !  =    partitionBucketCount )     {", "bucketConversion    =    Optional . of ( new   HiveSplit . BucketConversion ( tableBucketCount ,    partitionBucketCount ,    tableBucketInfo . get (  )  . getBucketColumns (  )  )  )  ;", "if    ( tableBucketCount    >    partitionBucketCount )     {", "bucketConversionRequiresWorkerParticipation    =    true ;", "}", "}", "}", "}", "InternalHiveSplitFactory   splitFactory    =    new   InternalHiveSplitFactory ( fs ,    partitionName ,    inputFormat ,    schema ,    partitionKeys ,    effectivePredicate ,    partition . getColumnCoercions (  )  ,     ( bucketConversionRequiresWorkerParticipation    ?    bucketConversion    :    Optional . empty (  )  )  ,    HiveSessionProperties . isForceLocalScheduling ( session )  )  ;", "if    (  (  . shouldUseFileSplitsFromInputFormat ( inputFormat )  )     |  |     (  ( HiveUtil . getHeaderCount ( schema )  )     >     0  )  )     {", "if    ( tableBucketInfo . isPresent (  )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,     (  \" Presto   cannot   read   bucketed   partition   in   an   input   format   with   UseFileSplitsFromInputFormat   annotation :     \"     +     ( inputFormat . getClass (  )  . getSimpleName (  )  )  )  )  ;", "}", "JobConf   jobConf    =    ConfigurationUtils . toJobConf ( configuration )  ;", "handleFileHeader ( schema ,    jobConf )  ;", "FileInputFormat . setInputPaths ( jobConf ,    path )  ;", "InputSplit [  ]    splits    =    inputFormat . getSplits ( jobConf ,     0  )  ;", "return   addSplitsToSource ( splits ,    splitFactory )  ;", "}", "if    ( tableBucketInfo . isPresent (  )  )     {", "return   hiveSplitSource . addToQueue ( getBucketedSplits ( path ,    fs ,    splitFactory ,    tableBucketInfo . get (  )  ,    bucketConversion )  )  ;", "}", "fileIterators . addLast ( createInternalHiveSplitIterator ( path ,    fs ,    splitFactory )  )  ;", "return    . COMPLETED _ FUTURE ;", "}", "METHOD_END"], "methodName": ["loadPartition"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "Iterator < InternalHiveSplit >    splits    =    fileIterators . poll (  )  ;", "if    ( splits    =  =    null )     {", "HivePartitionMetadata   partition    =    partitions . poll (  )  ;", "if    ( partition    =  =    null )     {", "return    . COMPLETED _ FUTURE ;", "}", "return   loadPartition ( partition )  ;", "}", "while    (  ( splits . hasNext (  )  )     &  &     (  !  ( stopped )  )  )     {", "ListenableFuture <  ?  >    future    =    hiveSplitSource . addToQueue ( splits . next (  )  )  ;", "if    (  !  ( future . isDone (  )  )  )     {", "fileIterators . addFirst ( splits )  ;", "return   future ;", "}", "}", "return    . COMPLETED _ FUTURE ;", "}", "METHOD_END"], "methodName": ["loadSplits"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "return   Arrays . stream ( inputFormat . getClass (  )  . getAnnotations (  )  )  . map ( Annotation :  : annotationType )  . map ( Class :  : getSimpleName )  . anyMatch (  (    name )     -  >    name . equals (  \" UseFileSplitsFromInputFormat \"  )  )  ;", "}", "METHOD_END"], "methodName": ["shouldUseFileSplitsFromInputFormat"], "fileName": "com.facebook.presto.hive.BackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "return    !  ( iterator . hasNext (  )  )  ;", "}", "METHOD_END"], "methodName": ["isEmpty"], "fileName": "com.facebook.presto.hive.ConcurrentLazyQueue"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( iterator . hasNext (  )  )  )     {", "return   null ;", "}", "return   iterator . next (  )  ;", "}", "METHOD_END"], "methodName": ["poll"], "fileName": "com.facebook.presto.hive.ConcurrentLazyQueue"}, {"methodBody": ["METHOD_START", "{", "maxCombinedBytesPerRow . add ( bytes )  ;", "}", "METHOD_END"], "methodName": ["addMaxCombinedBytesPerRow"], "fileName": "com.facebook.presto.hive.FileFormatDataSourceStats"}, {"methodBody": ["METHOD_START", "{", "return   time 0 Bto 1  0  0 KB ;", "}", "METHOD_END"], "methodName": ["get0Bto100KB"], "fileName": "com.facebook.presto.hive.FileFormatDataSourceStats"}, {"methodBody": ["METHOD_START", "{", "return   time 1  0  0 KBto 1 MB ;", "}", "METHOD_END"], "methodName": ["get100KBto1MB"], "fileName": "com.facebook.presto.hive.FileFormatDataSourceStats"}, {"methodBody": ["METHOD_START", "{", "return   time 1  0 MBPlus ;", "}", "METHOD_END"], "methodName": ["get10MBPlus"], "fileName": "com.facebook.presto.hive.FileFormatDataSourceStats"}, {"methodBody": ["METHOD_START", "{", "return   time 1 MBto 1  0 MB ;", "}", "METHOD_END"], "methodName": ["get1MBto10MB"], "fileName": "com.facebook.presto.hive.FileFormatDataSourceStats"}, {"methodBody": ["METHOD_START", "{", "return   maxCombinedBytesPerRow ;", "}", "METHOD_END"], "methodName": ["getMaxCombinedBytesPerRow"], "fileName": "com.facebook.presto.hive.FileFormatDataSourceStats"}, {"methodBody": ["METHOD_START", "{", "return   readBytes ;", "}", "METHOD_END"], "methodName": ["getReadBytes"], "fileName": "com.facebook.presto.hive.FileFormatDataSourceStats"}, {"methodBody": ["METHOD_START", "{", "readBytes . add ( bytes )  ;", "if    ( bytes    <     (  1  0  0     *     1  0  2  4  )  )     {", "time 0 Bto 1  0  0 KB . add ( nanos ,    TimeUnit . NANOSECONDS )  ;", "} else", "if    ( bytes    <     (  1  0  2  4     *     1  0  2  4  )  )     {", "time 1  0  0 KBto 1 MB . add ( nanos ,    TimeUnit . NANOSECONDS )  ;", "} else", "if    ( bytes    <     (  (  1  0     *     1  0  2  4  )     *     1  0  2  4  )  )     {", "time 1 MBto 1  0 MB . add ( nanos ,    TimeUnit . NANOSECONDS )  ;", "} else    {", "time 1  0 MBPlus . add ( nanos ,    TimeUnit . NANOSECONDS )  ;", "}", "}", "METHOD_END"], "methodName": ["readDataBytesPerSecond"], "fileName": "com.facebook.presto.hive.FileFormatDataSourceStats"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Date )     {", "long   storageTime    =     (  ( Date )     ( value )  )  . getTime (  )  ;", "long   utcMillis    =    storageTime    +     ( DateTimeZone . getDefault (  )  . getOffset ( storageTime )  )  ;", "return   TimeUnit . MILLISECONDS . toDays ( utcMillis )  ;", "}", "if    ( value   instanceof   Timestamp )     {", "long   parsedJvmMillis    =     (  ( Timestamp )     ( value )  )  . getTime (  )  ;", "DateTimeZone   jvmTimeZone    =    DateTimeZone . getDefault (  )  ;", "long   Millis    =    jvmTimeZone . convertUTCToLocal ( parsedJvmMillis )  ;", "long   utcMillis    =    TimeZone . convertLocalToUTC ( Millis ,    false )  ;", "return   utcMillis ;", "}", "if    ( value   instanceof   Float )     {", "return   Float . floatToRawIntBits (  (  ( Float )     ( value )  )  )  ;", "}", "return    (  ( Number )     ( value )  )  . longValue (  )  ;", "}", "METHOD_END"], "methodName": ["getLongExpressedValue"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "loaded [ column ]     =    true ;", "Object   fieldData    =    rowInspector . getStructFieldData ( rowData ,    structFields [ column ]  )  ;", "if    ( fieldData    =  =    null )     {", "nulls [ column ]     =    true ;", "} else    {", "Object   fieldValue    =     (  ( PrimitiveObjectInspector )     ( fieldInspectors [ column ]  )  )  . getPrimitiveJavaObject ( fieldData )  ;", ". checkState (  ( fieldValue    !  =    null )  ,     \" fieldValue   should   not   be   null \"  )  ;", "booleans [ column ]     =     (  ( Boolean )     ( fieldValue )  )  ;", "nulls [ column ]     =    false ;", "}", "}", "METHOD_END"], "methodName": ["parseBooleanColumn"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "loaded [ column ]     =    true ;", "Object   fieldData    =    rowInspector . getStructFieldData ( rowData ,    structFields [ column ]  )  ;", "if    ( fieldData    =  =    null )     {", "nulls [ column ]     =    true ;", "} else    {", "Object   fieldValue    =     (  ( PrimitiveObjectInspector )     ( fieldInspectors [ column ]  )  )  . getPrimitiveJavaObject ( fieldData )  ;", ". checkState (  ( fieldValue    !  =    null )  ,     \" fieldValue   should   not   be   null \"  )  ;", "HiveDecimal   decimal    =     (  ( HiveDecimal )     ( fieldValue )  )  ;", "DecimalType   columnType    =     (  ( DecimalType )     ( types [ column ]  )  )  ;", "BigInteger   unscaledDecimal    =    Decimals . rescale ( decimal . unscaledValue (  )  ,    decimal . scale (  )  ,    columnType . getScale (  )  )  ;", "if    ( columnType . isShort (  )  )     {", "longs [ column ]     =    unscaledDecimal . longValue (  )  ;", "} else    {", "slices [ column ]     =    Decimals . encodeUnscaledValue ( unscaledDecimal )  ;", "}", "nulls [ column ]     =    false ;", "}", "}", "METHOD_END"], "methodName": ["parseDecimalColumn"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "loaded [ column ]     =    true ;", "Object   fieldData    =    rowInspector . getStructFieldData ( rowData ,    structFields [ column ]  )  ;", "if    ( fieldData    =  =    null )     {", "nulls [ column ]     =    true ;", "} else    {", "Object   fieldValue    =     (  ( PrimitiveObjectInspector )     ( fieldInspectors [ column ]  )  )  . getPrimitiveJavaObject ( fieldData )  ;", ". checkState (  ( fieldValue    !  =    null )  ,     \" fieldValue   should   not   be   null \"  )  ;", "doubles [ column ]     =     (  ( Number )     ( fieldValue )  )  . doubleValue (  )  ;", "nulls [ column ]     =    false ;", "}", "}", "METHOD_END"], "methodName": ["parseDoubleColumn"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "loaded [ column ]     =    true ;", "Object   fieldData    =    rowInspector . getStructFieldData ( rowData ,    structFields [ column ]  )  ;", "if    ( fieldData    =  =    null )     {", "nulls [ column ]     =    true ;", "} else    {", "Object   fieldValue    =     (  ( PrimitiveObjectInspector )     ( fieldInspectors [ column ]  )  )  . getPrimitiveJavaObject ( fieldData )  ;", ". checkState (  ( fieldValue    !  =    null )  ,     \" fieldValue   should   not   be   null \"  )  ;", "longs [ column ]     =     . getLongExpressedValue ( fieldValue ,    hiveStorageTimeZone )  ;", "nulls [ column ]     =    false ;", "}", "}", "METHOD_END"], "methodName": ["parseLongColumn"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "loaded [ column ]     =    true ;", "Object   fieldData    =    rowInspector . getStructFieldData ( rowData ,    structFields [ column ]  )  ;", "if    ( fieldData    =  =    null )     {", "nulls [ column ]     =    true ;", "} else    {", "objects [ column ]     =    SerDeUtils . getBlockObject ( types [ column ]  ,    fieldData ,    fieldInspectors [ column ]  )  ;", "nulls [ column ]     =    false ;", "}", "}", "METHOD_END"], "methodName": ["parseObjectColumn"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "loaded [ column ]     =    true ;", "Object   fieldData    =    rowInspector . getStructFieldData ( rowData ,    structFields [ column ]  )  ;", "if    ( fieldData    =  =    null )     {", "nulls [ column ]     =    true ;", "} else    {", "Object   fieldValue    =     (  ( PrimitiveObjectInspector )     ( fieldInspectors [ column ]  )  )  . getPrimitiveWritableObject ( fieldData )  ;", ". checkState (  ( fieldValue    !  =    null )  ,     \" fieldValue   should   not   be   null \"  )  ;", "BinaryComparable   hiveValue ;", "if    ( fieldValue   instanceof   Text )     {", "hiveValue    =     (  ( Text )     ( fieldValue )  )  ;", "} else", "if    ( fieldValue   instanceof   BytesWritable )     {", "hiveValue    =     (  ( BytesWritable )     ( fieldValue )  )  ;", "} else", "if    ( fieldValue   instanceof   HiveVarcharWritable )     {", "hiveValue    =     (  ( HiveVarcharWritable )     ( fieldValue )  )  . getTextValue (  )  ;", "} else", "if    ( fieldValue   instanceof   HiveCharWritable )     {", "hiveValue    =     (  ( HiveCharWritable )     ( fieldValue )  )  . getTextValue (  )  ;", "} else    {", "throw   new   IllegalStateException (  (  \" unsupported   string   field   type :     \"     +     ( fieldValue . getClass (  )  . getName (  )  )  )  )  ;", "}", "Slice   value    =    Slices . wrappedBuffer ( hiveValue . getBytes (  )  ,     0  ,    hiveValue . getLength (  )  )  ;", "Type   type    =    types [ column ]  ;", "if    ( Varchars . isVarcharType ( type )  )     {", "value    =    Varchars . truncateToLength ( value ,    type )  ;", "}", "if    ( Chars . isCharType ( type )  )     {", "value    =    Chars . truncateToLengthAndTrimSpaces ( value ,    type )  ;", "}", "slices [ column ]     =    Slices . copyOf ( value )  ;", "nulls [ column ]     =    false ;", "}", "}", "METHOD_END"], "methodName": ["parseStringColumn"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "try    {", "long   newCompletedBytes    =     (  ( long )     (  ( totalBytes )     *     ( rReader . getProgress (  )  )  )  )  ;", "completedBytes    =    Math . min ( totalBytes ,    Math . max ( completedBytes ,    newCompletedBytes )  )  ;", "}    catch    ( IOException   ignored )     {", "}", "}", "METHOD_END"], "methodName": ["updateCompletedBytes"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( types [ fieldId ]  . getJavaType (  )  . equals ( type )  )  )     {", "throw   new   IllegalArgumentException ( String . format (  \" Expected   field   to   be    % s ,    actual    % s    ( field    % s )  \"  ,    type ,    types [ fieldId ]  ,    fieldId )  )  ;", "}", "}", "METHOD_END"], "methodName": ["validateType"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "return    (  ( RecordReader <  ?  ,     ?    extends   Writable >  )     ( recordReader )  )  ;", "}", "METHOD_END"], "methodName": ["genericRecordReader"], "fileName": "com.facebook.presto.hive.GenericHiveRecordCursorProvider"}, {"methodBody": ["METHOD_START", "{", "boolean   compression    =    compressionCodec    !  =     ( HiveCompressionCodec . NONE )  ;", "c . setBoolean ( varname ,    compression )  ;", "c . setBoolean (  \" mapred . output . compress \"  ,    compression )  ;", "c . setBoolean ( COMPRESS ,    compression )  ;", "c . set ( HIVE _ ORC _ DEFAULT _ COMPRESS . varname ,    compressionCodec . getOrcCompressionKind (  )  . name (  )  )  ;", "c . set ( HIVE _ ORC _ COMPRESSION . varname ,    compressionCodec . getOrcCompressionKind (  )  . name (  )  )  ;", "c . set ( COMPRESSION . getPropName (  )  ,    compressionCodec . getOrcCompressionKind (  )  . name (  )  )  ;", "if    ( compressionCodec . getCodec (  )  . isPresent (  )  )     {", "c . set (  \" mapred . output . compression . codec \"  ,    compressionCodec . getCodec (  )  . get (  )  . getName (  )  )  ;", "c . set ( COMPRESS _ CODEC ,    compressionCodec . getCodec (  )  . get (  )  . getName (  )  )  ;", "} else    {", "c . unset (  \" mapred . output . compression . codec \"  )  ;", "c . unset ( COMPRESS _ CODEC )  ;", "}", "c . set ( ParquetOutputFormat . COMPRESSION ,    compressionCodec . getParquetCompressionCodec (  )  . name (  )  )  ;", "c . set ( COMPRESS _ TYPE ,    BLOCK . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["configureCompression"], "fileName": "com.facebook.presto.hive.HdfsConfigurationUpdater"}, {"methodBody": ["METHOD_START", "{", "Configuration   result    =    new   Configuration ( false )  ;", "if    ( resourcePaths    =  =    null )     {", "return   result ;", "}", "for    ( String   resourcePath    :    resourcePaths )     {", "Configuration   resourceProperties    =    new   Configuration ( false )  ;", "resourceProperties . addResource ( new   Path ( resourcePath )  )  ;", "tils . copy ( resourceProperties ,    result )  ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["readConfiguration"], "fileName": "com.facebook.presto.hive.HdfsConfigurationUpdater"}, {"methodBody": ["METHOD_START", "{", "ConfigurationUtils . copy ( resourcesConfiguration ,    config )  ;", "config . setClass (  \" topology . node . switch . mapping . impl \"  ,     . NoOpDNSToSwitchMapping . class ,    DNSToSwitchMapping . class )  ;", "if    (  ( socksProxy )     !  =    null )     {", "config . setClass (  \" hadoop . rpc . socket . factory . class . default \"  ,    SocksSocketFactory . class ,    SocketFactory . class )  ;", "config . set (  \" hadoop . socks . server \"  ,    socksProxy . toString (  )  )  ;", "}", "if    (  ( domainSocketPath )     !  =    null )     {", "config . setStrings (  \" dfs . domain . socket . path \"  ,    domainSocketPath )  ;", "}", "if    (  !  ( config . get (  \" dfs . domain . socket . path \"  ,     \"  \"  )  . trim (  )  . isEmpty (  )  )  )     {", "config . setBooleanIfUnset (  \" dfs . client . read . shortcircuit \"  ,    true )  ;", "}", "config . setInt (  \" dfs . socket . timeout \"  ,    Math . toIntExact ( dfsTimeout . toMillis (  )  )  )  ;", "config . setInt (  \" ipc . ping . interval \"  ,    Math . toIntExact ( ipcPingInterval . toMillis (  )  )  )  ;", "config . setInt (  \" ipc . client . connect . timeout \"  ,    Math . toIntExact ( dfsConnectTimeout . toMillis (  )  )  )  ;", "config . setInt (  \" ipc . client . connect . max . retries \"  ,    dfsConnectMaxRetries )  ;", "config . setInt (  \" fs . cache . max - size \"  ,    fileSystemMaxCacheSize )  ;", ". configureCompression ( config ,    compressionCodec )  ;", "s 3 ConfigurationUpdater . updateConfiguration ( config )  ;", "}", "METHOD_END"], "methodName": ["updateConfiguration"], "fileName": "com.facebook.presto.hive.HdfsConfigurationUpdater"}, {"methodBody": ["METHOD_START", "{", "return   hdfsAuthentication . doAs ( user ,    action )  ;", "}", "METHOD_END"], "methodName": ["doAs"], "fileName": "com.facebook.presto.hive.HdfsEnvironment"}, {"methodBody": ["METHOD_START", "{", "hdfsAuthentication . doAs ( user ,    action )  ;", "}", "METHOD_END"], "methodName": ["doAs"], "fileName": "com.facebook.presto.hive.HdfsEnvironment"}, {"methodBody": ["METHOD_START", "{", "return   hdfsConfiguration . getConfiguration ( context ,    path . toUri (  )  )  ;", "}", "METHOD_END"], "methodName": ["getConfiguration"], "fileName": "com.facebook.presto.hive.HdfsEnvironment"}, {"methodBody": ["METHOD_START", "{", "return   getFileSystem ( context . getIdentity (  )  . getUser (  )  ,    path ,    getConfiguration ( context ,    path )  )  ;", "}", "METHOD_END"], "methodName": ["getFileSystem"], "fileName": "com.facebook.presto.hive.HdfsEnvironment"}, {"methodBody": ["METHOD_START", "{", "return   hdfsAuthentication . doAs ( user ,     (  )     -  >     {", "FileSystem   fileSystem    =    path . getFileSystem ( configuration )  ;", "fileSystem . setVerifyChecksum ( verifyChecksum )  ;", "return   fileSystem ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["getFileSystem"], "fileName": "com.facebook.presto.hive.HdfsEnvironment"}, {"methodBody": ["METHOD_START", "{", "Session   session    =    testSessionBuilder (  )  . setCatalog (  \" hive \"  )  . setSchema (  \" tpch \"  )  . build (  )  ;", "LocalQueryRunner   localQueryRunner    =    new   LocalQueryRunner ( session )  ;", "localQueryRunner . createCatalog (  \" tpch \"  ,    new   TpchConnectorFactory (  1  )  ,    ImmutableMap . of (  )  )  ;", "File   hiveDir    =    new   File ( tempDir ,     \" hive _ data \"  )  ;", "TestingHiveMetastore   metastore    =    new   TestingHiveMetastore ( hiveDir )  ;", "metastore . createDatabase ( Database . builder (  )  . setDatabaseName (  \" tpch \"  )  . setOwnerName (  \" public \"  )  . setOwnerType ( PrincipalType . ROLE )  . build (  )  )  ;", "HiveConnectorFactory   hiveConnectorFactory    =    new   HiveConnectorFactory (  \" hive \"  ,     . class . getClassLoader (  )  ,    metastore )  ;", "Map < String ,    String >    hiveCatalogConfig    =    ImmutableMap .  < String ,    String > builder (  )  . put (  \" hive . max - split - size \"  ,     \"  1  0 GB \"  )  . build (  )  ;", "localQueryRunner . createCatalog (  \" hive \"  ,    hiveConnectorFactory ,    hiveCatalogConfig )  ;", "localQueryRunner . execute (  \" CREATE   TABLE   orders   AS   SELECT    *    FROM   tpch . sf 1  . orders \"  )  ;", "localQueryRunner . execute (  \" CREATE   TABLE   lineitem   AS   SELECT    *    FROM   tpch . sf 1  . lineitem \"  )  ;", "return   localQueryRunner ;", "}", "METHOD_END"], "methodName": ["createLocalQueryRunner"], "fileName": "com.facebook.presto.hive.HiveBenchmarkQueryRunner"}, {"methodBody": ["METHOD_START", "{", "String   outputDirectory    =    Objects . requireNonNull ( System . getProperty (  \" outputDirectory \"  )  ,     \" Must   specify    - DoutputDirectory =  .  .  .  \"  )  ;", "File   tempDir    =    Files . createTempDir (  )  ;", "try    ( LocalQueryRunner   localQueryRunner    =     . createLocalQueryRunner ( tempDir )  )     {", "new   com . facebook . presto . benchmark . BenchmarkSuite ( localQueryRunner ,    outputDirectory )  . runAllBenchmarks (  )  ;", "}    finally    {", "deleteRecursively ( tempDir . toPath (  )  ,    ALLOW _ INSECURE )  ;", "}", "}", "METHOD_END"], "methodName": ["main"], "fileName": "com.facebook.presto.hive.HiveBenchmarkQueryRunner"}, {"methodBody": ["METHOD_START", "{", "return    (  (  (  (  ( length    =  =     5  )     &  &     (  ( HiveBooleanParser . toUpperCase ( bytes [  ( start    +     0  )  ]  )  )     =  =     ' F '  )  )     &  &     (  ( HiveBooleanParser . toUpperCase ( bytes [  ( start    +     1  )  ]  )  )     =  =     ' A '  )  )     &  &     (  ( HiveBooleanParser . toUpperCase ( bytes [  ( start    +     2  )  ]  )  )     =  =     ' L '  )  )     &  &     (  ( HiveBooleanParser . toUpperCase ( bytes [  ( start    +     3  )  ]  )  )     =  =     ' S '  )  )     &  &     (  ( HiveBooleanParser . toUpperCase ( bytes [  ( start    +     4  )  ]  )  )     =  =     ' E '  )  ;", "}", "METHOD_END"], "methodName": ["isFalse"], "fileName": "com.facebook.presto.hive.HiveBooleanParser"}, {"methodBody": ["METHOD_START", "{", "return    ( b    >  =     ' a '  )     &  &     ( b    <  =     ' z '  )  ;", "}", "METHOD_END"], "methodName": ["isLowerCase"], "fileName": "com.facebook.presto.hive.HiveBooleanParser"}, {"methodBody": ["METHOD_START", "{", "return    (  (  (  ( length    =  =     4  )     &  &     (  ( HiveBooleanParser . toUpperCase ( bytes [  ( start    +     0  )  ]  )  )     =  =     ' T '  )  )     &  &     (  ( HiveBooleanParser . toUpperCase ( bytes [  ( start    +     1  )  ]  )  )     =  =     ' R '  )  )     &  &     (  ( HiveBooleanParser . toUpperCase ( bytes [  ( start    +     2  )  ]  )  )     =  =     ' U '  )  )     &  &     (  ( HiveBooleanParser . toUpperCase ( bytes [  ( start    +     3  )  ]  )  )     =  =     ' E '  )  ;", "}", "METHOD_END"], "methodName": ["isTrue"], "fileName": "com.facebook.presto.hive.HiveBooleanParser"}, {"methodBody": ["METHOD_START", "{", "if    ( HiveBooleanParser . isTrue ( bytes ,    start ,    length )  )     {", "return   true ;", "}", "if    ( HiveBooleanParser . isFalse ( bytes ,    start ,    length )  )     {", "return   false ;", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["parseHiveBoolean"], "fileName": "com.facebook.presto.hive.HiveBooleanParser"}, {"methodBody": ["METHOD_START", "{", "return   HiveBooleanParser . isLowerCase ( b )     ?     (  ( byte )     ( b    -     3  2  )  )     :    b ;", "}", "METHOD_END"], "methodName": ["toUpperCase"], "fileName": "com.facebook.presto.hive.HiveBooleanParser"}, {"methodBody": ["METHOD_START", "{", "return   bucketCount ;", "}", "METHOD_END"], "methodName": ["getBucketCount"], "fileName": "com.facebook.presto.hive.HiveBucketHandle"}, {"methodBody": ["METHOD_START", "{", "return   columns ;", "}", "METHOD_END"], "methodName": ["getColumns"], "fileName": "com.facebook.presto.hive.HiveBucketHandle"}, {"methodBody": ["METHOD_START", "{", "return   new   HiveBucketProperty ( columns . stream (  )  . map ( HiveColumnHandle :  : getName )  . collect ( Collectors . toList (  )  )  ,    bucketCount )  ;", "}", "METHOD_END"], "methodName": ["toBucketProperty"], "fileName": "com.facebook.presto.hive.HiveBucketHandle"}, {"methodBody": ["METHOD_START", "{", "boolean   bucketColsSet    =     ( storageDescriptor . isSetBucketCols (  )  )     &  &     (  !  ( storageDescriptor . getBucketCols (  )  . isEmpty (  )  )  )  ;", "boolean   numBucketsSet    =     ( storageDescriptor . isSetNumBuckets (  )  )     &  &     (  ( storageDescriptor . getNumBuckets (  )  )     >     0  )  ;", "if    (  ! numBucketsSet )     {", "return   Optional . empty (  )  ;", "}", "if    (  ! bucketColsSet )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ INVALID _ METADATA ,     (  \" Table / partition   metadata   has    ' numBuckets '    set ,    but    ' bucketCols '    is   not   set :     \"     +    tablePartitionName )  )  ;", "}", "return   Optional . of ( new    ( storageDescriptor . getBucketCols (  )  ,    storageDescriptor . getNumBuckets (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["fromStorageDescriptor"], "fileName": "com.facebook.presto.hive.HiveBucketProperty"}, {"methodBody": ["METHOD_START", "{", "return   bucketCount ;", "}", "METHOD_END"], "methodName": ["getBucketCount"], "fileName": "com.facebook.presto.hive.HiveBucketProperty"}, {"methodBody": ["METHOD_START", "{", "return   bucketedBy ;", "}", "METHOD_END"], "methodName": ["getBucketedBy"], "fileName": "com.facebook.presto.hive.HiveBucketProperty"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( types . size (  )  )     =  =     ( page . getChannelCount (  )  )  )  )  ;", "int   result    =     0  ;", "for    ( int   i    =     0  ;    i    <     ( page . getChannelCount (  )  )  ;    i +  +  )     {", "int   fieldHash    =     . hash ( types . get ( i )  ,    page . getBlock ( i )  ,    position )  ;", "result    =     ( result    *     3  1  )     +    fieldHash ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["getBucketHashCode"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( types . size (  )  )     =  =     ( values . length )  )  )  ;", "int   result    =     0  ;", "for    ( int   i    =     0  ;    i    <     ( values . length )  ;    i +  +  )     {", "int   fieldHash    =     . hash ( types . get ( i )  ,    values [ i ]  )  ;", "result    =     ( result    *     3  1  )     +    fieldHash ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["getBucketHashCode"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "if    ( bindings . isEmpty (  )  )     {", "return   OptionalInt . empty (  )  ;", "}", "List < String >    bucketColumns    =    table . getStorage (  )  . getBucketProperty (  )  . get (  )  . getBucketedBy (  )  ;", "Map < String ,    HiveType >    hiveTypes    =    new   HashMap <  >  (  )  ;", "for    ( Column   column    :    table . getDataColumns (  )  )     {", "hiveTypes . put ( column . getName (  )  ,    column . getType (  )  )  ;", "}", "for    ( String   column    :    bucketColumns )     {", "if    (  !  (  . SUPPORTED _ TYPES _ FOR _ BUCKET _ FILTER . contains ( hiveTypes . get ( column )  )  )  )     {", "return   OptionalInt . empty (  )  ;", "}", "}", "Map < String ,    Object >    bucketBindings    =    new   HashMap <  >  (  )  ;", "for    ( Map . Entry < ColumnHandle ,    NullableValue >    entry    :    bindings . entrySet (  )  )     {", "HiveColumnHandle   colHandle    =     (  ( HiveColumnHandle )     ( entry . getKey (  )  )  )  ;", "if    (  (  !  ( entry . getValue (  )  . isNull (  )  )  )     &  &     ( bucketColumns . contains ( colHandle . getName (  )  )  )  )     {", "bucketBindings . put ( colHandle . getName (  )  ,    entry . getValue (  )  . getValue (  )  )  ;", "}", "}", "if    (  ( bucketBindings . size (  )  )     !  =     ( bucketColumns . size (  )  )  )     {", "return   OptionalInt . empty (  )  ;", "}", "ImmutableList . Builder < TypeInfo >    typeInfos    =    ImmutableList . builder (  )  ;", "Object [  ]    values    =    new   Object [ bucketColumns . size (  )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( bucketColumns . size (  )  )  ;    i +  +  )     {", "String   column    =    bucketColumns . get ( i )  ;", "typeInfos . add ( hiveTypes . get ( column )  . getTypeInfo (  )  )  ;", "values [ i ]     =    bucketBindings . get ( column )  ;", "}", "return   OptionalInt . of (  . getHiveBucket ( table . getStorage (  )  . getBucketProperty (  )  . get (  )  . getBucketCount (  )  ,    typeInfos . build (  )  ,    values )  )  ;", "}", "METHOD_END"], "methodName": ["getHiveBucket"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HiveBucketing . getBucketHashCode ( types ,    page ,    position )  )     &     ( Integer . MAX _ VALUE )  )     %    bucketCount ;", "}", "METHOD_END"], "methodName": ["getHiveBucket"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HiveBucketing . getBucketHashCode ( types ,    values )  )     &     ( Integer . MAX _ VALUE )  )     %    bucketCount ;", "}", "METHOD_END"], "methodName": ["getHiveBucket"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( table . getStorage (  )  . getBucketProperty (  )  . isPresent (  )  )  )     {", "return   Optional . empty (  )  ;", "}", "Optional < Map < ColumnHandle ,    NullableValue >  >    bindings    =    TupleDomain . extractFixedValues ( effectivePredicate )  ;", "if    (  !  ( bindings . isPresent (  )  )  )     {", "return   Optional . empty (  )  ;", "}", "OptionalInt   singleBucket    =     . getHiveBucket ( table ,    bindings . get (  )  )  ;", "if    ( singleBucket . isPresent (  )  )     {", "return   Optional . of ( new    . HiveBucketFilter ( ImmutableSet . of ( singleBucket . getAsInt (  )  )  )  )  ;", "}", "if    (  !  ( effectivePredicate . getDomains (  )  . isPresent (  )  )  )     {", "return   Optional . empty (  )  ;", "}", "Optional < Domain >    domain    =    effectivePredicate . getDomains (  )  . get (  )  . entrySet (  )  . stream (  )  . filter (  (    entry )     -  >     (  ( HiveColumnHandle )     ( entry . getKey (  )  )  )  . getName (  )  . equals ( BUCKET _ COLUMN _ NAME )  )  . findFirst (  )  . map ( Map . Entry :  : getValue )  ;", "if    (  !  ( domain . isPresent (  )  )  )     {", "return   Optional . empty (  )  ;", "}", "ValueSet   values    =    domain . get (  )  . getValues (  )  ;", "ImmutableSet . Builder < Integer >    builder    =    ImmutableSet . builder (  )  ;", "int   bucketCount    =    table . getStorage (  )  . getBucketProperty (  )  . get (  )  . getBucketCount (  )  ;", "for    ( int   i    =     0  ;    i    <    bucketCount ;    i +  +  )     {", "if    ( values . containsValue (  (  ( long )     ( i )  )  )  )     {", "builder . add ( i )  ;", "}", "}", "return   Optional . of ( new    . HiveBucketFilter ( builder . build (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getHiveBucketFilter"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "Optional < HiveBucketProperty >    hiveBucketProperty    =    table . getStorage (  )  . getBucketProperty (  )  ;", "if    (  !  ( hiveBucketProperty . isPresent (  )  )  )     {", "return   Optional . empty (  )  ;", "}", "Map < String ,    HiveColumnHandle >    map    =    HiveUtil . getRegularColumnHandles ( table )  . stream (  )  . collect ( Collectors . toMap ( HiveColumnHandle :  : getName ,    Function . identity (  )  )  )  ;", "ImmutableList . Builder < HiveColumnHandle >    bucketColumns    =    ImmutableList . builder (  )  ;", "for    ( String   bucketColumnName    :    hiveBucketProperty . get (  )  . getBucketedBy (  )  )     {", "HiveColumnHandle   bucketColumnHandle    =    map . get ( bucketColumnName )  ;", "if    ( bucketColumnHandle    =  =    null )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ INVALID _ METADATA ,    String . format (  \" Table    '  % s .  % s '    is   bucketed   on   non - existent   column    '  % s '  \"  ,    table . getDatabaseName (  )  ,    table . getTableName (  )  ,    bucketColumnName )  )  ;", "}", "bucketColumns . add ( bucketColumnHandle )  ;", "}", "return   Optional . of ( new   HiveBucketHandle ( bucketColumns . build (  )  ,    hiveBucketProperty . get (  )  . getBucketCount (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getHiveBucketHandle"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "if    ( block . isNull ( position )  )     {", "return    0  ;", "}", "switch    ( type . getCategory (  )  )     {", "case   PRIMITIVE    :", "{", "PrimitiveTypeInfo   typeInfo    =     (  ( PrimitiveTypeInfo )     ( type )  )  ;", "PrimitiveObjectInspector . PrimitiveCategory   primitiveCategory    =    typeInfo . getPrimitiveCategory (  )  ;", "Type   prestoType    =    Objects . requireNonNull ( HiveType . getPrimitiveType ( typeInfo )  )  ;", "switch    ( primitiveCategory )     {", "case   BOOLEAN    :", "return   prestoType . getBoolean ( block ,    position )     ?     1     :     0  ;", "case   BYTE    :", "return   SignedBytes . checkedCast ( prestoType . getLong ( block ,    position )  )  ;", "case   SHORT    :", "return   Shorts . checkedCast ( prestoType . getLong ( block ,    position )  )  ;", "case   INT    :", "return   Math . toIntExact ( prestoType . getLong ( block ,    position )  )  ;", "case   LONG    :", "long   bigintValue    =    prestoType . getLong ( block ,    position )  ;", "return    (  ( int )     (  ( bigintValue    >  >  >     3  2  )     ^    bigintValue )  )  ;", "case   FLOAT    :", "return    (  ( int )     ( prestoType . getLong ( block ,    position )  )  )  ;", "case   DOUBLE    :", "long   doubleValue    =    Double . doubleToLongBits ( prestoType . getDouble ( block ,    position )  )  ;", "return    (  ( int )     (  ( doubleValue    >  >  >     3  2  )     ^    doubleValue )  )  ;", "case   STRING    :", "return    . hashBytes (  0  ,    prestoType . getSlice ( block ,    position )  )  ;", "case   VARCHAR    :", "return    . hashBytes (  1  ,    prestoType . getSlice ( block ,    position )  )  ;", "case   DATE    :", "long   days    =    prestoType . getLong ( block ,    position )  ;", "return   Math . toIntExact ( days )  ;", "case   TIMESTAMP    :", "long   millisSinceEpoch    =    prestoType . getLong ( block ,    position )  ;", "long   secondsAndNanos    =     (  ( Math . floorDiv ( millisSinceEpoch ,     1  0  0  0 L )  )     <  <     3  0  )     +     ( Math . floorMod ( millisSinceEpoch ,     1  0  0  0  )  )  ;", "return    (  ( int )     (  ( secondsAndNanos    >  >  >     3  2  )     ^    secondsAndNanos )  )  ;", "default    :", "throw   new   UnsupportedOperationException (  (  (  \" Computation   of   Hive   bucket   hashCode   is   not   supported   for   Hive   primitive   category :     \"     +     ( primitiveCategory . toString (  )  )  )     +     \"  .  \"  )  )  ;", "}", "}", "case   LIST    :", "{", "Block   elementsBlock    =    block . getObject ( position ,    Block . class )  ;", "return    . hashOfList (  (  ( ListTypeInfo )     ( type )  )  ,    elementsBlock )  ;", "}", "case   MAP    :", "{", "Block   elementsBlock    =    block . getObject ( position ,    Block . class )  ;", "return    . hashOfMap (  (  ( MapTypeInfo )     ( type )  )  ,    elementsBlock )  ;", "}", "default    :", "throw   new   UnsupportedOperationException (  (  (  \" Computation   of   Hive   bucket   hashCode   is   not   supported   for   Hive   category :     \"     +     ( type . getCategory (  )  . toString (  )  )  )     +     \"  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["hash"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "if    ( value    =  =    null )     {", "return    0  ;", "}", "switch    ( type . getCategory (  )  )     {", "case   PRIMITIVE    :", "{", "PrimitiveTypeInfo   typeInfo    =     (  ( PrimitiveTypeInfo )     ( type )  )  ;", "PrimitiveObjectInspector . PrimitiveCategory   primitiveCategory    =    typeInfo . getPrimitiveCategory (  )  ;", "Type   prestoType    =    Objects . requireNonNull ( HiveType . getPrimitiveType ( typeInfo )  )  ;", "switch    ( primitiveCategory )     {", "case   BOOLEAN    :", "return    (  ( boolean )     ( value )  )     ?     1     :     0  ;", "case   BYTE    :", "return   SignedBytes . checkedCast (  (  ( long )     ( value )  )  )  ;", "case   SHORT    :", "return   Shorts . checkedCast (  (  ( long )     ( value )  )  )  ;", "case   INT    :", "return   Math . toIntExact (  (  ( long )     ( value )  )  )  ;", "case   LONG    :", "long   bigintValue    =     (  ( long )     ( value )  )  ;", "return    (  ( int )     (  ( bigintValue    >  >  >     3  2  )     ^    bigintValue )  )  ;", "case   FLOAT    :", "return    (  ( int )     (  ( long )     ( value )  )  )  ;", "case   DOUBLE    :", "long   doubleValue    =    Double . doubleToLongBits (  (  ( double )     ( value )  )  )  ;", "return    (  ( int )     (  ( doubleValue    >  >  >     3  2  )     ^    doubleValue )  )  ;", "case   STRING    :", "return    . hashBytes (  0  ,     (  ( Slice )     ( value )  )  )  ;", "case   VARCHAR    :", "return    . hashBytes (  1  ,     (  ( Slice )     ( value )  )  )  ;", "case   DATE    :", "long   days    =     (  ( long )     ( value )  )  ;", "return   Math . toIntExact ( days )  ;", "case   TIMESTAMP    :", "long   millisSinceEpoch    =     (  ( long )     ( value )  )  ;", "long   secondsAndNanos    =     (  ( Math . floorDiv ( millisSinceEpoch ,     1  0  0  0 L )  )     <  <     3  0  )     +     ( Math . floorMod ( millisSinceEpoch ,     1  0  0  0  )  )  ;", "return    (  ( int )     (  ( secondsAndNanos    >  >  >     3  2  )     ^    secondsAndNanos )  )  ;", "default    :", "throw   new   UnsupportedOperationException (  (  (  \" Computation   of   Hive   bucket   hashCode   is   not   supported   for   Hive   primitive   category :     \"     +     ( primitiveCategory . toString (  )  )  )     +     \"  .  \"  )  )  ;", "}", "}", "case   LIST    :", "{", "return    . hashOfList (  (  ( ListTypeInfo )     ( type )  )  ,     (  ( Block )     ( value )  )  )  ;", "}", "case   MAP    :", "{", "return    . hashOfMap (  (  ( MapTypeInfo )     ( type )  )  ,     (  ( Block )     ( value )  )  )  ;", "}", "default    :", "throw   new   UnsupportedOperationException (  (  (  \" Computation   of   Hive   bucket   hashCode   is   not   supported   for   Hive   category :     \"     +     ( type . getCategory (  )  . toString (  )  )  )     +     \"  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["hash"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "int   result    =    initialValue ;", "for    ( int   i    =     0  ;    i    <     ( bytes . length (  )  )  ;    i +  +  )     {", "result    =     ( result    *     3  1  )     +     ( bytes . getByte ( i )  )  ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["hashBytes"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "TypeInfo   elementTypeInfo    =    type . getListElementTypeInfo (  )  ;", "int   result    =     0  ;", "for    ( int   i    =     0  ;    i    <     ( singleListBlock . getPositionCount (  )  )  ;    i +  +  )     {", "result    =     ( result    *     3  1  )     +     (  . hash ( elementTypeInfo ,    singleListBlock ,    i )  )  ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["hashOfList"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "TypeInfo   keyTypeInfo    =    type . getMapKeyTypeInfo (  )  ;", "TypeInfo   valueTypeInfo    =    type . getMapValueTypeInfo (  )  ;", "int   result    =     0  ;", "for    ( int   i    =     0  ;    i    <     ( singleMapBlock . getPositionCount (  )  )  ;    i    +  =     2  )     {", "result    +  =     (  . hash ( keyTypeInfo ,    singleMapBlock ,    i )  )     ^     (  . hash ( valueTypeInfo ,    singleMapBlock ,     ( i    +     1  )  )  )  ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["hashOfMap"], "fileName": "com.facebook.presto.hive.HiveBucketing"}, {"methodBody": ["METHOD_START", "{", "return   allowCorruptWritesForTesting ;", "}", "METHOD_END"], "methodName": ["getAllowCorruptWritesForTesting"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   createsOfNonManagedTablesEnabled ;", "}", "METHOD_END"], "methodName": ["getCreatesOfNonManagedTablesEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   DateTimeZone . forTimeZone ( TimeZone . getTimeZone ( timeZone )  )  ;", "}", "METHOD_END"], "methodName": ["getDateTimeZone"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   dfsConnectMaxRetries ;", "}", "METHOD_END"], "methodName": ["getDfsConnectMaxRetries"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   dfsConnectTimeout ;", "}", "METHOD_END"], "methodName": ["getDfsConnectTimeout"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   dfsTimeout ;", "}", "METHOD_END"], "methodName": ["getDfsTimeout"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   domainCompactionThreshold ;", "}", "METHOD_END"], "methodName": ["getDomainCompactionThreshold"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   domainSocketPath ;", "}", "METHOD_END"], "methodName": ["getDomainSocketPath"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   fileSystemMaxCacheSize ;", "}", "METHOD_END"], "methodName": ["getFileSystemMaxCacheSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   hdfsAuthenticationType ;", "}", "METHOD_END"], "methodName": ["getHdfsAuthenticationType"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   hiveCompressionCodec ;", "}", "METHOD_END"], "methodName": ["getHiveCompressionCodec"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   hiveMetastoreAuthenticationType ;", "}", "METHOD_END"], "methodName": ["getHiveMetastoreAuthenticationType"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   hiveStorageFormat ;", "}", "METHOD_END"], "methodName": ["getHiveStorageFormat"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   ipcPingInterval ;", "}", "METHOD_END"], "methodName": ["getIpcPingInterval"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxConcurrentFileRenames ;", "}", "METHOD_END"], "methodName": ["getMaxConcurrentFileRenames"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "if    (  ( maxInitialSplitSize )     =  =    null )     {", "return   new   io . airlift . units . DataSize (  (  ( maxSplitSize . getValue (  )  )     /     2  )  ,    maxSplitSize . getUnit (  )  )  ;", "}", "return   maxInitialSplitSize ;", "}", "METHOD_END"], "methodName": ["getMaxInitialSplitSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxInitialSplits ;", "}", "METHOD_END"], "methodName": ["getMaxInitialSplits"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxMetastoreRefreshThreads ;", "}", "METHOD_END"], "methodName": ["getMaxMetastoreRefreshThreads"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxOutstandingSplits ;", "}", "METHOD_END"], "methodName": ["getMaxOutstandingSplits"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxOutstandingSplitsSize ;", "}", "METHOD_END"], "methodName": ["getMaxOutstandingSplitsSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxPartitionBatchSize ;", "}", "METHOD_END"], "methodName": ["getMaxPartitionBatchSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxPartitionsPerScan ;", "}", "METHOD_END"], "methodName": ["getMaxPartitionsPerScan"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxPartitionsPerWriter ;", "}", "METHOD_END"], "methodName": ["getMaxPartitionsPerWriter"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxSplitIteratorThreads ;", "}", "METHOD_END"], "methodName": ["getMaxSplitIteratorThreads"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxSplitSize ;", "}", "METHOD_END"], "methodName": ["getMaxSplitSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   metastoreCacheMaximumSize ;", "}", "METHOD_END"], "methodName": ["getMetastoreCacheMaximumSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   metastoreCacheTtl ;", "}", "METHOD_END"], "methodName": ["getMetastoreCacheTtl"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   metastoreRefreshInterval ;", "}", "METHOD_END"], "methodName": ["getMetastoreRefreshInterval"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   metastoreSocksProxy ;", "}", "METHOD_END"], "methodName": ["getMetastoreSocksProxy"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   metastoreTimeout ;", "}", "METHOD_END"], "methodName": ["getMetastoreTimeout"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   minPartitionBatchSize ;", "}", "METHOD_END"], "methodName": ["getMinPartitionBatchSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   orcDefaultBloomFilterFpp ;", "}", "METHOD_END"], "methodName": ["getOrcDefaultBloomFilterFpp"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   orcMaxBufferSize ;", "}", "METHOD_END"], "methodName": ["getOrcMaxBufferSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   orcMaxMergeDistance ;", "}", "METHOD_END"], "methodName": ["getOrcMaxMergeDistance"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   orcMaxReadBlockSize ;", "}", "METHOD_END"], "methodName": ["getOrcMaxReadBlockSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   orcStreamBufferSize ;", "}", "METHOD_END"], "methodName": ["getOrcStreamBufferSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   perTransactionMetastoreCacheMaximumSize ;", "}", "METHOD_END"], "methodName": ["getPerTransactionMetastoreCacheMaximumSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   recursiveDirWalkerEnabled ;", "}", "METHOD_END"], "methodName": ["getRecursiveDirWalkerEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   resourceConfigFiles ;", "}", "METHOD_END"], "methodName": ["getResourceConfigFiles"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   s 3 FileSystemType ;", "}", "METHOD_END"], "methodName": ["getS3FileSystemType"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   splitLoaderConcurrency ;", "}", "METHOD_END"], "methodName": ["getSplitLoaderConcurrency"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   timeZone ;", "}", "METHOD_END"], "methodName": ["getTimeZone"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   writeValidationThreads ;", "}", "METHOD_END"], "methodName": ["getWriteValidationThreads"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   writesToNonManagedTablesEnabled ;", "}", "METHOD_END"], "methodName": ["getWritesToNonManagedTablesEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   assumeCanonicalPartitionKeys ;", "}", "METHOD_END"], "methodName": ["isAssumeCanonicalPartitionKeys"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   bucketExecutionEnabled ;", "}", "METHOD_END"], "methodName": ["isBucketExecutionEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   bucketWritingEnabled ;", "}", "METHOD_END"], "methodName": ["isBucketWritingEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   forceLocalScheduling ;", "}", "METHOD_END"], "methodName": ["isForceLocalScheduling"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   hdfsImpersonationEnabled ;", "}", "METHOD_END"], "methodName": ["isHdfsImpersonationEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   immutablePartitions ;", "}", "METHOD_END"], "methodName": ["isImmutablePartitions"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   orcBloomFiltersEnabled ;", "}", "METHOD_END"], "methodName": ["isOrcBloomFiltersEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   orcLazyReadSmallRanges ;", "}", "METHOD_END"], "methodName": ["isOrcLazyReadSmallRanges"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   orcOptimizedWriterEnabled ;", "}", "METHOD_END"], "methodName": ["isOrcOptimizedWriterEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   orcWriterValidate ;", "}", "METHOD_END"], "methodName": ["isOrcWriterValidate"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   parquetOptimizedReaderEnabled ;", "}", "METHOD_END"], "methodName": ["isParquetOptimizedReaderEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   parquetPredicatePushdownEnabled ;", "}", "METHOD_END"], "methodName": ["isParquetPredicatePushdownEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   rcfileOptimizedWriterEnabled ;", "}", "METHOD_END"], "methodName": ["isRcfileOptimizedWriterEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   rcfileWriterValidate ;", "}", "METHOD_END"], "methodName": ["isRcfileWriterValidate"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   respectTableFormat ;", "}", "METHOD_END"], "methodName": ["isRespectTableFormat"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   skipDeletionForAlter ;", "}", "METHOD_END"], "methodName": ["isSkipDeletionForAlter"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   tableStatisticsEnabled ;", "}", "METHOD_END"], "methodName": ["isTableStatisticsEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   useOrcColumnNames ;", "}", "METHOD_END"], "methodName": ["isUseOrcColumnNames"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   useParquetColumnNames ;", "}", "METHOD_END"], "methodName": ["isUseParquetColumnNames"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   verifyChecksum ;", "}", "METHOD_END"], "methodName": ["isVerifyChecksum"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . allowCorruptWritesForTesting    =    allowCorruptWritesForTesting ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setAllowCorruptWritesForTesting"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . assumeCanonicalPartitionKeys    =    assumeCanonicalPartitionKeys ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setAssumeCanonicalPartitionKeys"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . bucketExecutionEnabled    =    bucketExecutionEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setBucketExecutionEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . bucketWritingEnabled    =    bucketWritingEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setBucketWritingEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . createsOfNonManagedTablesEnabled    =    createsOfNonManagedTablesEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setCreatesOfNonManagedTablesEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . dfsConnectMaxRetries    =    dfsConnectMaxRetries ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setDfsConnectMaxRetries"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . dfsConnectTimeout    =    dfsConnectTimeout ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setDfsConnectTimeout"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . dfsTimeout    =    dfsTimeout ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setDfsTimeout"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . domainCompactionThreshold    =    domainCompactionThreshold ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setDomainCompactionThreshold"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . domainSocketPath    =    domainSocketPath ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setDomainSocketPath"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . fileSystemMaxCacheSize    =    fileSystemMaxCacheSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setFileSystemMaxCacheSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . forceLocalScheduling    =    forceLocalScheduling ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setForceLocalScheduling"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . hdfsAuthenticationType    =    hdfsAuthenticationType ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHdfsAuthenticationType"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . hdfsImpersonationEnabled    =    hdfsImpersonationEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHdfsImpersonationEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . hiveCompressionCodec    =    hiveCompressionCodec ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHiveCompressionCodec"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . hiveMetastoreAuthenticationType    =    hiveMetastoreAuthenticationType ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHiveMetastoreAuthenticationType"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . hiveStorageFormat    =    hiveStorageFormat ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHiveStorageFormat"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . immutablePartitions    =    immutablePartitions ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setImmutablePartitions"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . ipcPingInterval    =    pingInterval ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setIpcPingInterval"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxConcurrentFileRenames    =    maxConcurrentFileRenames ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxConcurrentFileRenames"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxInitialSplitSize    =    maxInitialSplitSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxInitialSplitSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxInitialSplits    =    maxInitialSplits ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxInitialSplits"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxMetastoreRefreshThreads    =    maxMetastoreRefreshThreads ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxMetastoreRefreshThreads"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxOutstandingSplits    =    maxOutstandingSplits ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxOutstandingSplits"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxOutstandingSplitsSize    =    maxOutstandingSplits ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxOutstandingSplitsSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxPartitionBatchSize    =    maxPartitionBatchSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxPartitionBatchSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxPartitionsPerScan    =    maxPartitionsPerScan ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxPartitionsPerScan"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxPartitionsPerWriter    =    maxPartitionsPerWriter ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxPartitionsPerWriter"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxSplitIteratorThreads    =    maxSplitIteratorThreads ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxSplitIteratorThreads"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxSplitSize    =    maxSplitSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxSplitSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . metastoreCacheMaximumSize    =    metastoreCacheMaximumSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMetastoreCacheMaximumSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . metastoreCacheTtl    =    metastoreCacheTtl ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMetastoreCacheTtl"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . metastoreRefreshInterval    =    metastoreRefreshInterval ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMetastoreRefreshInterval"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . metastoreSocksProxy    =    metastoreSocksProxy ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMetastoreSocksProxy"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . metastoreTimeout    =    metastoreTimeout ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMetastoreTimeout"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . minPartitionBatchSize    =    minPartitionBatchSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMinPartitionBatchSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . orcBloomFiltersEnabled    =    orcBloomFiltersEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setOrcBloomFiltersEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . orcDefaultBloomFilterFpp    =    orcDefaultBloomFilterFpp ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setOrcDefaultBloomFilterFpp"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . orcLazyReadSmallRanges    =    orcLazyReadSmallRanges ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setOrcLazyReadSmallRanges"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . orcMaxBufferSize    =    orcMaxBufferSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setOrcMaxBufferSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . orcMaxMergeDistance    =    orcMaxMergeDistance ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setOrcMaxMergeDistance"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . orcMaxReadBlockSize    =    orcMaxReadBlockSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setOrcMaxReadBlockSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . orcOptimizedWriterEnabled    =    orcOptimizedWriterEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setOrcOptimizedWriterEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . orcStreamBufferSize    =    orcStreamBufferSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setOrcStreamBufferSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . orcWriterValidate    =    orcWriterValidate ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setOrcWriterValidate"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . parquetOptimizedReaderEnabled    =    parquetOptimizedReaderEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setParquetOptimizedReaderEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . parquetPredicatePushdownEnabled    =    parquetPredicatePushdownEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setParquetPredicatePushdownEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . perTransactionMetastoreCacheMaximumSize    =    perTransactionMetastoreCacheMaximumSize ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setPerTransactionMetastoreCacheMaximumSize"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . rcfileOptimizedWriterEnabled    =    rcfileOptimizedWriterEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setRcfileOptimizedWriterEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . rcfileWriterValidate    =    rcfileWriterValidate ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setRcfileWriterValidate"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . recursiveDirWalkerEnabled    =    recursiveDirWalkerEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setRecursiveDirWalkerEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . resourceConfigFiles    =     ( files    =  =    null )     ?    null    :    HiveClientConfig . SPLITTER . splitToList ( files )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setResourceConfigFiles"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . resourceConfigFiles    =     ( files    =  =    null )     ?    null    :    ImmutableList . copyOf ( files )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setResourceConfigFiles"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . respectTableFormat    =    respectTableFormat ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setRespectTableFormat"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . s 3 FileSystemType    =    s 3 FileSystemType ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3FileSystemType"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . skipDeletionForAlter    =    skipDeletionForAlter ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setSkipDeletionForAlter"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . splitLoaderConcurrency    =    splitLoaderConcurrency ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setSplitLoaderConcurrency"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . tableStatisticsEnabled    =    tableStatisticsEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setTableStatisticsEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . timeZone    =     ( id    !  =    null )     ?    id    :    TimeZone . getDefault (  )  . getID (  )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setTimeZone"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . useOrcColumnNames    =    useOrcColumnNames ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setUseOrcColumnNames"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . useParquetColumnNames    =    useParquetColumnNames ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setUseParquetColumnNames"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . verifyChecksum    =    verifyChecksum ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setVerifyChecksum"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . writeValidationThreads    =    writeValidationThreads ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setWriteValidationThreads"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "this . writesToNonManagedTablesEnabled    =    writesToNonManagedTablesEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setWritesToNonManagedTablesEnabled"], "fileName": "com.facebook.presto.hive.HiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "return   Executors . newFixedThreadPool ( hiveClientConfig . getMaxMetastoreRefreshThreads (  )  ,    Threads . daemonThreadsNamed (  (  (  \" hive - metastore -  \"     +    hiveClientId )     +     \"  -  % s \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["createCachingHiveMetastoreExecutor"], "fileName": "com.facebook.presto.hive.HiveClientModule"}, {"methodBody": ["METHOD_START", "{", "return   Executors . newCachedThreadPool ( Threads . daemonThreadsNamed (  (  (  \" hive -  \"     +    hiveClientId )     +     \"  -  % s \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["createHiveClientExecutor"], "fileName": "com.facebook.presto.hive.HiveClientModule"}, {"methodBody": ["METHOD_START", "{", "return    (    transactionHandle )     -  >     (  ( HiveMetadata )     ( transactionManager . get ( transactionHandle )  )  )  . getMetastore (  )  ;", "}", "METHOD_END"], "methodName": ["createMetastoreGetter"], "fileName": "com.facebook.presto.hive.HiveClientModule"}, {"methodBody": ["METHOD_START", "{", "if    (  (  !  ( fromHiveType . getCategory (  )  . equals ( LIST )  )  )     |  |     (  !  ( toHiveType . getCategory (  )  . equals ( LIST )  )  )  )     {", "return   false ;", "}", "HiveType   fromElementType    =    HiveType . valueOf (  (  ( ListTypeInfo )     ( fromHiveType . getTypeInfo (  )  )  )  . getListElementTypeInfo (  )  . getTypeName (  )  )  ;", "HiveType   toElementType    =    HiveType . valueOf (  (  ( ListTypeInfo )     ( toHiveType . getTypeInfo (  )  )  )  . getListElementTypeInfo (  )  . getTypeName (  )  )  ;", "return    ( fromElementType . equals ( toElementType )  )     |  |     ( cane ( fromElementType ,    toElementType )  )  ;", "}", "METHOD_END"], "methodName": ["canCoerceForList"], "fileName": "com.facebook.presto.hive.HiveCoercionPolicy"}, {"methodBody": ["METHOD_START", "{", "if    (  (  !  ( fromHiveType . getCategory (  )  . equals ( MAP )  )  )     |  |     (  !  ( toHiveType . getCategory (  )  . equals ( MAP )  )  )  )     {", "return   false ;", "}", "HiveType   fromKeyType    =    HiveType . valueOf (  (  ( MapTypeInfo )     ( fromHiveType . getTypeInfo (  )  )  )  . getMapKeyTypeInfo (  )  . getTypeName (  )  )  ;", "HiveType   fromValueType    =    HiveType . valueOf (  (  ( MapTypeInfo )     ( fromHiveType . getTypeInfo (  )  )  )  . getMapValueTypeInfo (  )  . getTypeName (  )  )  ;", "HiveType   toKeyType    =    HiveType . valueOf (  (  ( MapTypeInfo )     ( toHiveType . getTypeInfo (  )  )  )  . getMapKeyTypeInfo (  )  . getTypeName (  )  )  ;", "HiveType   toValueType    =    HiveType . valueOf (  (  ( MapTypeInfo )     ( toHiveType . getTypeInfo (  )  )  )  . getMapValueTypeInfo (  )  . getTypeName (  )  )  ;", "return    (  ( fromKeyType . equals ( toKeyType )  )     |  |     ( cane ( fromKeyType ,    toKeyType )  )  )     &  &     (  ( fromValueType . equals ( toValueType )  )     |  |     ( cane ( fromValueType ,    toValueType )  )  )  ;", "}", "METHOD_END"], "methodName": ["canCoerceForMap"], "fileName": "com.facebook.presto.hive.HiveCoercionPolicy"}, {"methodBody": ["METHOD_START", "{", "if    (  (  !  ( fromHiveType . getCategory (  )  . equals ( STRUCT )  )  )     |  |     (  !  ( toHiveType . getCategory (  )  . equals ( STRUCT )  )  )  )     {", "return   false ;", "}", "List < String >    fromFieldNames    =     (  ( StructTypeInfo )     ( fromHiveType . getTypeInfo (  )  )  )  . getAllStructFieldNames (  )  ;", "List < String >    toFieldNames    =     (  ( StructTypeInfo )     ( toHiveType . getTypeInfo (  )  )  )  . getAllStructFieldNames (  )  ;", "List < HiveType >    fromFieldTypes    =    HiveUtil . extractStructFieldTypes ( fromHiveType )  ;", "List < HiveType >    toFieldTypes    =    HiveUtil . extractStructFieldTypes ( toHiveType )  ;", "for    ( int   i    =     0  ;    i    <     ( Math . min ( fromFieldTypes . size (  )  ,    toFieldTypes . size (  )  )  )  ;    i +  +  )     {", "if    (  !  ( fromFieldNames . get ( i )  . equals ( toFieldNames . get ( i )  )  )  )     {", "return   false ;", "}", "if    (  (  !  ( fromFieldTypes . get ( i )  . equals ( toFieldTypes . get ( i )  )  )  )     &  &     (  !  ( cane ( fromFieldTypes . get ( i )  ,    toFieldTypes . get ( i )  )  )  )  )     {", "return   false ;", "}", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["canCoerceForStruct"], "fileName": "com.facebook.presto.hive.HiveCoercionPolicy"}, {"methodBody": ["METHOD_START", "{", "Type   fromType    =    typeManager . getType ( fromHiveType . getTypeSignature (  )  )  ;", "Type   toType    =    typeManager . getType ( toHiveType . getTypeSignature (  )  )  ;", "if    (  ( toType   instanceof   VarcharType )     &  &     (  (  (  ( fromHiveType . equals ( HiveType . HIVE _ BYTE )  )     |  |     ( fromHiveType . equals ( HiveType . HIVE _ SHORT )  )  )     |  |     ( fromHiveType . equals ( HiveType . HIVE _ INT )  )  )     |  |     ( fromHiveType . equals ( HiveType . HIVE _ LONG )  )  )  )     {", "return   new    . IntegerNumberToVarcharCoercer (  )  ;", "} else", "if    (  ( fromType   instanceof   VarcharType )     &  &     (  (  (  ( toHiveType . equals ( HiveType . HIVE _ BYTE )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ SHORT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ INT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ LONG )  )  )  )     {", "return   new    . VarcharToIntegerNumberCoercer ( toHiveType )  ;", "} else", "if    (  (  (  ( fromHiveType . equals ( HiveType . HIVE _ BYTE )  )     &  &     ( toHiveType . equals ( HiveType . HIVE _ SHORT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ INT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ LONG )  )  )     {", "return   new    . IntegerNumberUpscaleCoercer (  )  ;", "} else", "if    (  (  ( fromHiveType . equals ( HiveType . HIVE _ SHORT )  )     &  &     ( toHiveType . equals ( HiveType . HIVE _ INT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ LONG )  )  )     {", "return   new    . IntegerNumberUpscaleCoercer (  )  ;", "} else", "if    (  ( fromHiveType . equals ( HiveType . HIVE _ INT )  )     &  &     ( toHiveType . equals ( HiveType . HIVE _ LONG )  )  )     {", "return   new    . IntegerNumberUpscaleCoercer (  )  ;", "} else", "if    (  ( fromHiveType . equals ( HiveType . HIVE _ FLOAT )  )     &  &     ( toHiveType . equals ( HiveType . HIVE _ DOUBLE )  )  )     {", "return   new    . FloatToDoubleCoercer (  )  ;", "} else", "if    (  ( HiveUtil . isArrayType ( fromType )  )     &  &     ( HiveUtil . isArrayType ( toType )  )  )     {", "return   new    . ListCoercer ( typeManager ,    fromHiveType ,    toHiveType ,    bridgingRecordCursor )  ;", "} else", "if    (  ( HiveUtil . isMapType ( fromType )  )     &  &     ( HiveUtil . isMapType ( toType )  )  )     {", "return   new    . MapCoercer ( typeManager ,    fromHiveType ,    toHiveType ,    bridgingRecordCursor )  ;", "} else", "if    (  ( HiveUtil . isRowType ( fromType )  )     &  &     ( HiveUtil . isRowType ( toType )  )  )     {", "return   new    . StructCoercer ( typeManager ,    fromHiveType ,    toHiveType ,    bridgingRecordCursor )  ;", "}", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Unsupported   coercion   from    % s   to    % s \"  ,    fromHiveType ,    toHiveType )  )  ;", "}", "METHOD_END"], "methodName": ["createCoercer"], "fileName": "com.facebook.presto.hive.HiveCoercionRecordCursor"}, {"methodBody": ["METHOD_START", "{", "return   delegate ;", "}", "METHOD_END"], "methodName": ["getRegularColumnRecordCursor"], "fileName": "com.facebook.presto.hive.HiveCoercionRecordCursor"}, {"methodBody": ["METHOD_START", "{", "Class <  ?  >    fromJavaType    =    fromType . getJavaType (  )  ;", "if    ( fromJavaType    =  =     ( long . class )  )     {", "bridgingRecordCursor . setValue ( fromType . getLong ( block ,    position )  )  ;", "} else", "if    ( fromJavaType    =  =     ( double . class )  )     {", "bridgingRecordCursor . setValue ( fromType . getDouble ( block ,    position )  )  ;", "} else", "if    ( fromJavaType    =  =     ( boolean . class )  )     {", "bridgingRecordCursor . setValue ( fromType . getBoolean ( block ,    position )  )  ;", "} else", "if    ( fromJavaType    =  =     ( io . airlift . slice . Slice . class )  )     {", "bridgingRecordCursor . setValue ( fromType . getSlice ( block ,    position )  )  ;", "} else", "if    ( fromJavaType    =  =     ( Block . class )  )     {", "bridgingRecordCursor . setValue ( fromType . getObject ( block ,    position )  )  ;", "} else    {", "bridgingRecordCursor . setValue ( null )  ;", "}", "coercer . reset (  )  ;", "Class <  ?  >    toJaveType    =    toType . getJavaType (  )  ;", "if    ( coercer . isNull ( bridgingRecordCursor ,     0  )  )     {", "blockBuilder . appendNull (  )  ;", "} else", "if    ( toJaveType    =  =     ( long . class )  )     {", "toType . writeLong ( blockBuilder ,    coercer . getLong ( bridgingRecordCursor ,     0  )  )  ;", "} else", "if    ( toJaveType    =  =     ( double . class )  )     {", "toType . writeDouble ( blockBuilder ,    coercer . getDouble ( bridgingRecordCursor ,     0  )  )  ;", "} else", "if    ( toJaveType    =  =     ( boolean . class )  )     {", "toType . writeBoolean ( blockBuilder ,    coercer . getBoolean ( bridgingRecordCursor ,     0  )  )  ;", "} else", "if    ( toJaveType    =  =     ( io . airlift . slice . Slice . class )  )     {", "toType . writeSlice ( blockBuilder ,    coercer . getSlice ( bridgingRecordCursor ,     0  )  )  ;", "} else", "if    ( toJaveType    =  =     ( Block . class )  )     {", "toType . writeObject ( blockBuilder ,    coercer . getObject ( bridgingRecordCursor ,     0  )  )  ;", "} else    {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Unsupported   coercion   from    % s   to    % s \"  ,    fromType . getDisplayName (  )  ,    toType . getDisplayName (  )  )  )  ;", "}", "coercer . reset (  )  ;", "bridgingRecordCursor . close (  )  ;", "}", "METHOD_END"], "methodName": ["rewriteBlock"], "fileName": "com.facebook.presto.hive.HiveCoercionRecordCursor"}, {"methodBody": ["METHOD_START", "{", "return   new   HiveColumnHandle ( HiveColumnHandle . BUCKET _ COLUMN _ NAME ,    HiveColumnHandle . BUCKET _ HIVE _ TYPE ,    HiveColumnHandle . BUCKET _ TYPE _ SIGNATURE ,    HiveColumnHandle . BUCKET _ COLUMN _ INDEX ,    HiveColumnHandle . ColumnType . SYNTHESIZED ,    Optional . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["bucketColumnHandle"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return   new   com . facebook . presto . spi . ColumnMetadata ( name ,    typeManager . getType ( typeName )  ,    null ,    isHidden (  )  )  ;", "}", "METHOD_END"], "methodName": ["getColumnMetadata"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return   columnType ;", "}", "METHOD_END"], "methodName": ["getColumnType"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return   comment ;", "}", "METHOD_END"], "methodName": ["getComment"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return   hiveColumnIndex ;", "}", "METHOD_END"], "methodName": ["getHiveColumnIndex"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return   hiveType ;", "}", "METHOD_END"], "methodName": ["getHiveType"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return   name ;", "}", "METHOD_END"], "methodName": ["getName"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return   typeName ;", "}", "METHOD_END"], "methodName": ["getTypeSignature"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return    ( column . getHiveColumnIndex (  )  )     =  =     ( HiveColumnHandle . BUCKET _ COLUMN _ INDEX )  ;", "}", "METHOD_END"], "methodName": ["isBucketColumnHandle"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return    ( columnType )     =  =     ( HiveColumnHandle . ColumnType . SYNTHESIZED )  ;", "}", "METHOD_END"], "methodName": ["isHidden"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return    ( columnType )     =  =     ( HiveColumnHandle . ColumnType . PARTITION _ KEY )  ;", "}", "METHOD_END"], "methodName": ["isPartitionKey"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return    ( column . getHiveColumnIndex (  )  )     =  =     ( HiveColumnHandle . PATH _ COLUMN _ INDEX )  ;", "}", "METHOD_END"], "methodName": ["isPathColumnHandle"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return   new   HiveColumnHandle ( HiveColumnHandle . PATH _ COLUMN _ NAME ,    HiveColumnHandle . PATH _ HIVE _ TYPE ,    HiveColumnHandle . PATH _ TYPE _ SIGNATURE ,    HiveColumnHandle . PATH _ COLUMN _ INDEX ,    HiveColumnHandle . ColumnType . SYNTHESIZED ,    Optional . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["pathColumnHandle"], "fileName": "com.facebook.presto.hive.HiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "return   codec ;", "}", "METHOD_END"], "methodName": ["getCodec"], "fileName": "com.facebook.presto.hive.HiveCompressionCodec"}, {"methodBody": ["METHOD_START", "{", "return   orcCompressionKind ;", "}", "METHOD_END"], "methodName": ["getOrcCompressionKind"], "fileName": "com.facebook.presto.hive.HiveCompressionCodec"}, {"methodBody": ["METHOD_START", "{", "return   parquetCompressionCodec ;", "}", "METHOD_END"], "methodName": ["getParquetCompressionCodec"], "fileName": "com.facebook.presto.hive.HiveCompressionCodec"}, {"methodBody": ["METHOD_START", "{", "BigDecimal   parsed    =    new   BigDecimal ( new   String ( bytes ,    start ,    length ,    StandardCharsets . UTF _  8  )  )  ;", "if    (  ( parsed . scale (  )  )     >     ( columnType . getScale (  )  )  )     {", "parsed    =    parsed . setScale ( columnType . getScale (  )  ,    RoundingMode . HALF _ UP )  ;", "}", "return   Decimals . rescale ( parsed ,    columnType )  ;", "}", "METHOD_END"], "methodName": ["parseHiveDecimal"], "fileName": "com.facebook.presto.hive.HiveDecimalParser"}, {"methodBody": ["METHOD_START", "{", "return   Optional . empty (  )  ;", "}", "METHOD_END"], "methodName": ["getVerificationTask"], "fileName": "com.facebook.presto.hive.HiveFileWriter"}, {"methodBody": ["METHOD_START", "{", "return   partitionIds ;", "}", "METHOD_END"], "methodName": ["getPartitionIds"], "fileName": "com.facebook.presto.hive.HiveInputInfo"}, {"methodBody": ["METHOD_START", "{", "return   truncated ;", "}", "METHOD_END"], "methodName": ["isTruncated"], "fileName": "com.facebook.presto.hive.HiveInputInfo"}, {"methodBody": ["METHOD_START", "{", "return    !  ( HiveWriteUtils . isS 3 FileSystem ( context ,    hdfsEnvironment ,    path )  )  ;", "}", "METHOD_END"], "methodName": ["shouldUseTemporaryDirectory"], "fileName": "com.facebook.presto.hive.HiveLocationService"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  !  ( partitions . isEmpty (  )  )  )  ,     \" partitions   cannot   be   empty \"  )  ;", "boolean   hasNull    =    false ;", "List < Object >    nonNullValues    =    new   ArrayList <  >  (  )  ;", "Type   type    =    null ;", "for    ( HivePartition   partition    :    partitions )     {", "NullableValue   value    =    partition . getKeys (  )  . get ( column )  ;", "if    ( value    =  =    null )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ UNKNOWN _ ERROR ,    String . format (  \" Partition    % s   does   not   have   a   value   for   partition   column    % s \"  ,    partition ,    column )  )  ;", "}", "if    ( value . isNull (  )  )     {", "hasNull    =    true ;", "} else    {", "nonNullValues . add ( value . getValue (  )  )  ;", "}", "if    ( type    =  =    null )     {", "type    =    value . getType (  )  ;", "}", "}", "if    (  !  ( nonNullValues . isEmpty (  )  )  )     {", "Domain   domain    =    Domain . multipleValues ( type ,    nonNullValues )  ;", "if    ( hasNull )     {", "return   domain . union ( Domain . onlyNull ( type )  )  ;", "}", "return   domain ;", "}", "return   Domain . onlyNull ( type )  ;", "}", "METHOD_END"], "methodName": ["buildColumnDomain"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "return   new   PrincipalPrivileges ( ImmutableMultimap .  < String ,    HivePrivilegeInfo > builder (  )  . put ( tableOwner ,    new   HivePrivilegeInfo ( HivePrivilegeInfo . HivePrivilege . SELECT ,    true )  )  . put ( tableOwner ,    new   HivePrivilegeInfo ( HivePrivilegeInfo . HivePrivilege . INSERT ,    true )  )  . put ( tableOwner ,    new   HivePrivilegeInfo ( HivePrivilegeInfo . HivePrivilege . UPDATE ,    true )  )  . put ( tableOwner ,    new   HivePrivilegeInfo ( HivePrivilegeInfo . HivePrivilege . DELETE ,    true )  )  . build (  )  ,    ImmutableMultimap . of (  )  )  ;", "}", "METHOD_END"], "methodName": ["buildInitialPrivilegeSet"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "return   Partition . builder (  )  . setDatabaseName ( table . getDatabaseName (  )  )  . setTableName ( table . getTableName (  )  )  . setColumns ( table . getDataColumns (  )  )  . setValues ( HivePartitionManager . extractPartitionKeyValues ( partitionUpdate . getName (  )  )  )  . setParameters ( ImmutableMap .  < String ,    String > builder (  )  . put ( HiveMetadata . PRESTO _ VERSION _ NAME ,    prestoVersion )  . put ( HiveMetadata . PRESTO _ QUERY _ ID _ NAME ,    session . getQueryId (  )  )  . build (  )  )  . withStorage (  (    storage )     -  >    storage . setStorageFormat (  ( isRespectTableFormat ( session )     ?    table . getStorage (  )  . getStorageFormat (  )     :    fromHiveStorageFormat ( HiveSessionProperties . getHiveStorageFormat ( session )  )  )  )  . setLocation ( partitionUpdate . getTargetPath (  )  . toString (  )  )  . setBucketProperty ( table . getStorage (  )  . getBucketProperty (  )  )  . setSerdeParameters ( table . getStorage (  )  . getSerdeParameters (  )  )  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["buildPartitionObject"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    HiveColumnHandle >    columnHandlesByName    =    Maps . uniqueIndex ( columnHandles ,    HiveColumnHandle :  : getName )  ;", "List < Column >    partitionColumns    =    partitionedBy . stream (  )  . map ( columnHandlesByName :  : get )  . map (  (    column )     -  >    new   Column ( column . getName (  )  ,    column . getHiveType (  )  ,    column . getComment (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "Set < String >    partitionColumnNames    =    ImmutableSet . copyOf ( partitionedBy )  ;", "ImmutableList . Builder < Column >    columns    =    ImmutableList . builder (  )  ;", "for    ( HiveColumnHandle   columnHandle    :    columnHandles )     {", "String   name    =    columnHandle . getName (  )  ;", "HiveType   type    =    columnHandle . getHiveType (  )  ;", "if    (  !  ( partitionColumnNames . contains ( name )  )  )     {", "verify (  (  !  ( columnHandle . isPartitionKey (  )  )  )  ,     \" Column   handles   are   not   consistent   with   partitioned   by   property \"  )  ;", "columns . add ( new   Column ( name ,    type ,    columnHandle . getComment (  )  )  )  ;", "} else    {", "verify ( columnHandle . isPartitionKey (  )  ,     \" Column   handles   are   not   consistent   with   partitioned   by   property \"  )  ;", "}", "}", "Builder < String ,    String >    tableParameters    =    ImmutableMap .  < String ,    String > builder (  )  . put (  . PRESTO _ VERSION _ NAME ,    prestoVersion )  . put (  . PRESTO _ QUERY _ ID _ NAME ,    queryId )  . putAll ( additionalTableParameters )  ;", "if    ( external )     {", "tableParameters . put (  \" EXTERNAL \"  ,     \" TRUE \"  )  ;", "}", "Table . Builder   tableBuilder    =    Table . builder (  )  . setDatabaseName ( schemaName )  . setTableName ( tableName )  . setOwner ( tableOwner )  . setTableType (  ( external    ?    EXTERNAL _ TABLE    :    MANAGED _ TABLE )  . name (  )  )  . setDataColumns ( columns . build (  )  )  . setPartitionColumns ( partitionColumns )  . setParameters ( tableParameters . build (  )  )  ;", "tableBuilder . getStorageBuilder (  )  . setStorageFormat ( StorageFormat . fromHiveStorageFormat ( hiveStorageFormat )  )  . setBucketProperty ( bucketProperty )  . setLocation ( targetPath . toString (  )  )  ;", "return   tableBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["buildTableObject"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < String >    columnNames    =    ImmutableList . builder (  )  ;", "table . getPartitionColumns (  )  . stream (  )  . map ( Column :  : getName )  . forEach ( columnNames :  : add )  ;", "table . getDataColumns (  )  . stream (  )  . map ( Column :  : getName )  . forEach ( columnNames :  : add )  ;", "List < String >    allColumnNames    =    columnNames . build (  )  ;", "if    (  ( allColumnNames . size (  )  )     >     ( Sets . newHashSet ( allColumnNames )  . size (  )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ INVALID _ METADATA ,    String . format (  \" Hive   metadata   for   table    % s   is   invalid :    Table   descriptor   contains   duplicate   columns \"  ,    table . getTableName (  )  )  )  ;", "}", "List < Column >    tableColumns    =    table . getDataColumns (  )  ;", "Builder < String ,    Optional < String >  >    builder    =    ImmutableMap . builder (  )  ;", "for    ( Column   field    :    concat ( tableColumns ,    table . getPartitionColumns (  )  )  )     {", "if    (  (  ( field . getComment (  )  )     !  =    null )     &  &     (  !  ( Optional . of (  \" from   deserializer \"  )  . equals ( field . getComment (  )  )  )  )  )     {", "builder . put ( field . getName (  )  ,    field . getComment (  )  )  ;", "} else    {", "builder . put ( field . getName (  )  ,    Optional . empty (  )  )  ;", "}", "}", "builder . put ( HiveColumnHandle . PATH _ COLUMN _ NAME ,    Optional . empty (  )  )  ;", "if    ( table . getStorage (  )  . getBucketProperty (  )  . isPresent (  )  )     {", "builder . put ( HiveColumnHandle . BUCKET _ COLUMN _ NAME ,    Optional . empty (  )  )  ;", "}", "Map < String ,    Optional < String >  >    columnComment    =    builder . build (  )  ;", "return    (    handle )     -  >    new   Column ( handle . getName (  )  ,    typeManager . getType ( handle . getTypeSignature (  )  )  ,    columnComment . get ( handle . getName (  )  )  . orElse ( null )  ,    HiveUtil . columnExtraInfo ( handle . isPartitionKey (  )  )  ,    handle . isHidden (  )  )  ;", "}", "METHOD_END"], "methodName": ["columnMetadataGetter"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "metastore . commit (  )  ;", "}", "METHOD_END"], "methodName": ["commit"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "if    (  ( partitionUpdate . getFileNames (  )  . size (  )  )     =  =    bucketCount )     {", "return   ImmutableList . of (  )  ;", "}", "HdfsEnvironment . HdfsContext   hdfsContext    =    new   HdfsEnvironment . HdfsContext ( session ,    table . getDatabaseName (  )  ,    table . getTableName (  )  )  ;", "JobConf   conf    =    ConfigurationUtils . toJobConf ( hdfsEnvironment . getConfiguration ( hdfsContext ,    targetPath )  )  ;", "String   fileExtension    =    WriterFactory . getFileExtension ( conf ,    StorageFormat . fromStorageFormat ( storageFormat )  )  ;", "Set < String >    fileNames    =    ImmutableSet . copyOf ( partitionUpdate . getFileNames (  )  )  ;", "ImmutableList . Builder < String >    missingFileNamesBuilder    =    ImmutableList . builder (  )  ;", "for    ( int   i    =     0  ;    i    <    bucketCount ;    i +  +  )     {", "String   fileName    =     ( WriterFactory . computeBucketedFileName ( filePrefix ,    i )  )     +    fileExtension ;", "if    (  !  ( fileNames . contains ( fileName )  )  )     {", "missingFileNamesBuilder . add ( fileName )  ;", "}", "}", "List < String >    missingFileNames    =    missingFileNamesBuilder . build (  )  ;", "verify (  (  (  ( fileNames . size (  )  )     +     ( missingFileNames . size (  )  )  )     =  =    bucketCount )  )  ;", "return   missingFileNames ;", "}", "METHOD_END"], "methodName": ["computeFileNamesForMissingBuckets"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < PartitionUpdate >    partitionUpdatesForMissingBucketsBuilder    =    ImmutableList . builder (  )  ;", "StorageFormat   storageFormat    =     ( table . getPartitionColumns (  )  . isEmpty (  )  )     ?    handle . getTableStorageFormat (  )     :    handle . getPartitionStorageFormat (  )  ;", "for    ( PartitionUpdate   partitionUpdate    :    partitionUpdates )     {", "int   bucketCount    =    handle . getBucketProperty (  )  . get (  )  . getBucketCount (  )  ;", "List < String >    fileNamesForMissingBuckets    =    computeFileNamesForMissingBuckets ( session ,    table ,    storageFormat ,    partitionUpdate . getTargetPath (  )  ,    handle . getFilePrefix (  )  ,    bucketCount ,    partitionUpdate )  ;", "partitionUpdatesForMissingBucketsBuilder . add ( new   PartitionUpdate ( partitionUpdate . getName (  )  ,    partitionUpdate . isNew (  )  ,    partitionUpdate . getWritePath (  )  ,    partitionUpdate . getTargetPath (  )  ,    fileNamesForMissingBuckets )  )  ;", "}", "return   partitionUpdatesForMissingBucketsBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["computePartitionUpdatesForMissingBuckets"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "return    (    bindings )     -  >    tupleDomain . contains ( TupleDomain . fromFixedValues ( bindings )  )  ;", "}", "METHOD_END"], "methodName": ["convertToPredicate"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "JobConf   conf    =    ConfigurationUtils . toJobConf ( hdfsEnvironment . getConfiguration ( new   HdfsEnvironment . HdfsContext ( session ,    table . getDatabaseName (  )  ,    table . getTableName (  )  )  ,    path )  )  ;", "Properties   schema ;", "StorageFormat   format ;", "if    ( partition . isPresent (  )  )     {", "schema    =    MetastoreUtil . getHiveSchema ( partition . get (  )  ,    table )  ;", "format    =    partition . get (  )  . getStorage (  )  . getStorageFormat (  )  ;", "} else    {", "schema    =    MetastoreUtil . getHiveSchema ( table )  ;", "format    =    table . getStorage (  )  . getStorageFormat (  )  ;", "}", "for    ( String   fileName    :    fileNames )     {", ". writeEmptyFile ( new   Path ( path ,    fileName )  ,    conf ,    schema ,    format . getSerDe (  )  ,    format . getOutputFormat (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["createEmptyFile"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "SchemaTableName   schemaTableName    =    tableMetadata . getTable (  )  ;", "String   schemaName    =    schemaTableName . getSchemaName (  )  ;", "String   tableName    =    schemaTableName . getTableName (  )  ;", "List < String >    partitionedBy    =    HiveTableProperties . getPartitionedBy ( tableMetadata . getProperties (  )  )  ;", "Optional < HiveBucketProperty >    bucketProperty    =    HiveTableProperties . getBucketProperty ( tableMetadata . getProperties (  )  )  ;", "if    (  ( bucketProperty . isPresent (  )  )     &  &     (  !  ( bucketWritingEnabled )  )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Writing   to   bucketed   Hive   table   has   been   temporarily   disabled \"  )  ;", "}", "List < HiveColumnHandle >    columnHandles    =    HiveMetadata . getColumnHandles ( tableMetadata ,    ImmutableSet . copyOf ( partitionedBy )  ,    typeTranslator )  ;", "HiveStorageFormat   hiveStorageFormat    =    HiveSessionProperties . getHiveStorageFormat ( tableMetadata . getProperties (  )  )  ;", "Map < String ,    String >    tableProperties    =    getTableProperties ( tableMetadata )  ;", "hiveStorageFormat . validateColumns ( columnHandles )  ;", "Path   targetPath ;", "boolean   external ;", "String   externalLocation    =    HiveTableProperties . getExternalLocation ( tableMetadata . getProperties (  )  )  ;", "if    ( externalLocation    !  =    null )     {", "if    (  !  ( createsOfNonManagedTablesEnabled )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Cannot   create   non - managed   Hive   table \"  )  ;", "}", "external    =    true ;", "targetPath    =    getExternalPath ( new   HdfsEnvironment . HdfsContext ( session ,    schemaName ,    tableName )  ,    externalLocation )  ;", "} else    {", "external    =    false ;", "LocationHandle   locationHandle    =    locationService . forNewTable ( metastore ,    session ,    schemaName ,    tableName )  ;", "targetPath    =    locationService . targetPathRoot ( locationHandle )  ;", "}", "Table   table    =    HiveMetadata . buildTableObject ( session . getQueryId (  )  ,    schemaName ,    tableName ,    session . getUser (  )  ,    columnHandles ,    hiveStorageFormat ,    partitionedBy ,    bucketProperty ,    tableProperties ,    targetPath ,    external ,    prestoVersion )  ;", "PrincipalPrivileges   principalPrivileges    =    HiveMetadata . buildInitialPrivilegeSet ( table . getOwner (  )  )  ;", "metastore . createTable ( session ,    table ,    principalPrivileges ,    Optional . empty (  )  ,    ignoreExisting )  ;", "}", "METHOD_END"], "methodName": ["createHiveTable"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "if    ( partitions . isEmpty (  )  )     {", "turn   TupleDomain . none (  )  ;", "}", "turn   withColumnDomains ( partitionColumns . stam (  )  . collect ( Collectors . toMap ( Function . identity (  )  ,     (    column )     -  >    buildColumnDomain ( column ,    partitions )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["createPredicate"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "StorageFormat   storageFormat    =    table . getStorage (  )  . getStorageFormat (  )  ;", "String   outputFormat    =    storageFormat . getOutputFormat (  )  ;", "String   serde    =    storageFormat . getSerDe (  )  ;", "for    ( HiveStorageFormat   format    :    HiveStorageFormat . values (  )  )     {", "if    (  ( format . getOutputFormat (  )  . equals ( outputFormat )  )     &  &     ( format . getSerDe (  )  . equals ( serde )  )  )     {", "return   format ;", "}", "}", "throw   new   PException ( HiveErrorCode . HIVE _ UNSUPPORTED _ FORMAT ,    String . format (  \" Output   format    % s   with   SerDe    % s   is   not   supported \"  ,    outputFormat ,    serde )  )  ;", "}", "METHOD_END"], "methodName": ["extractHiveStorageFormat"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "HiveMetadata . validatePartitionColumns ( tableMetadata )  ;", "HiveMetadata . validateBucketColumns ( tableMetadata )  ;", "ImmutableList . Builder < HiveColumnHandle >    columnHandles    =    ImmutableList . builder (  )  ;", "int   ordinal    =     0  ;", "for    ( ColumnMetadata   column    :    tableMetadata . getColumns (  )  )     {", "HiveColumnHandle . ColumnType   columnType ;", "if    ( partitionColumnNames . contains ( column . getName (  )  )  )     {", "columnType    =    HiveColumnHandle . ColumnType . PARTITION _ KEY ;", "} else", "if    ( column . isHidden (  )  )     {", "columnType    =    HiveColumnHandle . ColumnType . SYNTHESIZED ;", "} else    {", "columnType    =    HiveColumnHandle . ColumnType . REGULAR ;", "}", "columnHandles . add ( new   HiveColumnHandle ( column . getName (  )  ,    HiveType . toHiveType ( typeTranslator ,    column . getType (  )  )  ,    column . getType (  )  . getTypeSignature (  )  ,    ordinal ,    columnType ,    Optional . ofNullable ( column . getComment (  )  )  )  )  ;", "ordinal +  +  ;", "}", "return   columnHandles . build (  )  ;", "}", "METHOD_END"], "methodName": ["getColumnHandles"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "try    {", "Path   path    =    new   Path ( location )  ;", "if    (  !  ( hdfsEnvironment . getFileSystem ( context ,    path )  . isDirectory ( path )  )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . INVALID _ TABLE _ PROPERTY ,     \" External   location   must   be   a   directory \"  )  ;", "}", "return   path ;", "}    catch    ( IllegalArgumentException    |    IOException   e )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . INVALID _ TABLE _ PROPERTY ,     \" External   location   is   not   a   valid   file   system   URI \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["getExternalPath"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "return   metastore ;", "}", "METHOD_END"], "methodName": ["getMetastore"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "if    ( layoutHandle . getPartitions (  )  . isPresent (  )  )     {", "return   layoutHandle . getPartitions (  )  . get (  )  ;", "} else    {", "TupleDomain < ColumnHandle >    promisedPredicate    =    layoutHandle . getPromisedPredicate (  )  ;", "Predicate < Map < ColumnHandle ,    NullableValue >  >    predicate    =    HiveMetadata . convertToPredicate ( promisedPredicate )  ;", "List < ConnectorTableLayoutResult >    tableLayoutResults    =    getTableLayouts ( session ,    tableHandle ,    new   spi . Constraint ( promisedPredicate ,    predicate )  ,    Optional . empty (  )  )  ;", "return    (  ( HiveTableLayoutHandle )     ( Iterables . getOnlyElement ( tableLayoutResults )  . getTableLayout (  )  . getHandle (  )  )  )  . getPartitions (  )  . get (  )  ;", "}", "}", "METHOD_END"], "methodName": ["getOrComputePartitions"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "Table   sourceTable    =    metastore . getTable ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . get (  )  ;", "return   Util . getPartitionKeyColumnHandles ( sourceTable )  ;", "}", "METHOD_END"], "methodName": ["getPartitionColumns"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HivePartition >    partitionList    =    ImmutableList . builder (  )  ;", "int   count    =     0  ;", "Iterator < HivePartition >    iterator    =    partitions . getPartitions (  )  ;", "while    ( iterator . hasNext (  )  )     {", "HivePartition   partition    =    iterator . next (  )  ;", "if    ( count    =  =     ( maxPartitions )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ EXCEEDED _ PARTITION _ LIMIT ,    String . format (  \" Query   over   table    '  % s '    can   potentially   read   more   than    % s   partitions \"  ,    partition . getTableName (  )  ,    maxPartitions )  )  ;", "}", "partitionList . add ( partition )  ;", "count +  +  ;", "}", "return   partitionList . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionsAsList"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "HivePartitionResult   partitions    =    partitionManager . getPartitions ( metastore ,    tableHandle ,    constraint )  ;", "return   getPartitionsAsList ( partitions )  ;", "}", "METHOD_END"], "methodName": ["getPartitionsAsList"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "SchemaTableName   sourceTableName    =    HiveMetadata . getSourceTableNameForPartitionsTable ( tableName )  ;", "HiveTableHandle   sourceTableHandle    =    getTableHandle ( session ,    sourceTableName )  ;", "if    ( sourceTableHandle    =  =    null )     {", "return   Optional . empty (  )  ;", "}", "List < HiveColumnHandle >    partitionColumns    =    getPartitionColumns ( sourceTableName )  ;", "if    ( partitionColumns . isEmpty (  )  )     {", "return   Optional . empty (  )  ;", "}", "List < Type >    partitionColumnTypes    =    partitionColumns . stream (  )  . map ( HiveColumnHandle :  : getTypeSignature )  . map ( typeManager :  : getType )  . collect ( toImmutableList (  )  )  ;", "List < ColumnMetadata >    partitionSystemTableColumns    =    partitionColumns . stream (  )  . map (  (    column )     -  >    new   ColumnMetadata ( column . getName (  )  ,    typeManager . getType ( column . getTypeSignature (  )  )  ,    column . getComment (  )  . orElse ( null )  ,    column . isHidden (  )  )  )  . collect ( toImmutableList (  )  )  ;", "Map < Integer ,    HiveColumnHandle >    fieldIdToColumnHandle    =    IntStream . range (  0  ,    partitionColumns . size (  )  )  . boxed (  )  . collect ( toImmutableMap ( Function . identity (  )  ,    partitionColumns :  : get )  )  ;", "SystemTable   partitionsSystemTable    =    new   SystemTable (  )     {", "@ Override", "public   Distribution   getDistribution (  )     {", "return   Distribution . SINGLE _ COORDINATOR ;", "}", "@ Override", "public   ConnectorTableMetadata   getTableMetadata (  )     {", "return   new   ConnectorTableMetadata ( tableName ,    partitionSystemTableColumns )  ;", "}", "@ Override", "public   RecordCursor   cursor ( ConnectorTransactionHandle   transactionHandle ,    ConnectorSession   session ,    TupleDomain < Integer >    constraint )     {", "TupleDomain < ColumnHandle >    targetTupleDomain    =    constraint . transform ( fieldIdToColumnHandle :  : get )  ;", "Predicate < Map < ColumnHandle ,    NullableValue >  >    targetPredicate    =    HiveMetadata . convertToPredicate ( targetTupleDomain )  ;", "Constraint < ColumnHandle >    targetConstraint    =    new   Constraint ( targetTupleDomain ,    targetPredicate )  ;", "Iterable < List < Object >  >    records    =     (  )     -  >    stream ( partitionManager . getPartitions ( metastore ,    sourceTableHandle ,    targetConstraint )  . getPartitions (  )  )  . map (  (    hivePartition )     -  >     (  ( List < Object >  )     ( IntStream . range (  0  ,    partitionColumns . size (  )  )  . mapToObj ( fieldIdToColumnHandle :  : get )  . map (  (    columnHandle )     -  >    hivePartition . getKeys (  )  . get ( columnHandle )  . getValue (  )  )  . collect ( toImmutableList (  )  )  )  )  )  . iterator (  )  ;", "return   new   spi . InMemoryRecordSet ( partitionColumnTypes ,    records )  . cursor (  )  ;", "}", "}  ;", "return   Optional . of ( partitionsSystemTable )  ;", "}", "METHOD_END"], "methodName": ["getPartitionsSystemTable"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "checkArgument ( HiveMetadata . isPartitionsSystemTable ( tableName )  ,     \" not   a   partitions   table   name \"  )  ;", "return   new   SchemaTableName ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  . substring (  0  ,     (  ( tableName . getTableName (  )  . length (  )  )     -     ( HiveMetadata . PARTITIONS _ TABLE _ SUFFIX . length (  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getSourceTableNameForPartitionsTable"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "Builder < String ,    String >    tableProperties    =    ImmutableMap . builder (  )  ;", "tableProperties . putAll ( tableParameterCodec . encode ( tableMetadata . getProperties (  )  )  )  ;", "List < String >    columns    =    HiveTableProperties . getOrcBloomFilterColumns ( tableMetadata . getProperties (  )  )  ;", "if    (  ( columns    !  =    null )     &  &     (  !  ( columns . isEmpty (  )  )  )  )     {", "tableProperties . put (  . ORC _ BLOOM _ FILTER _ COLUMNS _ KEY ,    Joiner . on (  \"  ,  \"  )  . join ( columns )  )  ;", "tableProperties . put (  . ORC _ BLOOM _ FILTER _ FPP _ KEY ,    String . valueOf ( HiveTableProperties . getOrcBloomFilterFpp ( tableMetadata . getProperties (  )  )  )  )  ;", "}", "tableMetadata . getComment (  )  . ifPresent (  (    value )     -  >    tableProperties . put (  . TABLE _ COMMENT ,    value )  )  ;", "return   tableProperties . build (  )  ;", "}", "METHOD_END"], "methodName": ["getTableProperties"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "return    ( tableName . getTableName (  )  . endsWith ( HiveMetadata . PARTITIONS _ TABLE _ SUFFIX )  )     &  &     (  ( tableName . getTableName (  )  . length (  )  )     >     ( HiveMetadata . PARTITIONS _ TABLE _ SUFFIX . length (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["isPartitionsSystemTable"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "if    ( schemaNameOrNull    =  =    null )     {", "turn   listSchemaNames ( session )  ;", "}", "turn   ImmutableList . of ( schemaNameOrNull )  ;", "}", "METHOD_END"], "methodName": ["listSchemas"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( prefix . getSchemaName (  )  )     =  =    null )     |  |     (  ( prefix . getTableName (  )  )     =  =    null )  )     {", "return   listTables ( session ,    prefix . getSchemaName (  )  )  ;", "}", "return   ImmutableList . of ( new   spi . SchemaTableName ( prefix . getSchemaName (  )  ,    prefix . getTableName (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["listTables"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "metastore . rollback (  )  ;", "}", "METHOD_END"], "methodName": ["rollback"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "Optional < HiveBucketProperty >    bucketProperty    =    HiveTableProperties . getBucketProperty ( tableMetadata . getProperties (  )  )  ;", "if    (  !  ( bucketProperty . isPresent (  )  )  )     {", "return ;", "}", "Set < String >    allColumns    =    tableMetadata . getColumns (  )  . stream (  )  . map ( ColumnMetadata :  : getName )  . collect ( Collectors . toSet (  )  )  ;", "List < String >    bucketedBy    =    bucketProperty . get (  )  . getBucketedBy (  )  ;", "if    (  !  ( allColumns . containsAll ( bucketedBy )  )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . INVALID _ TABLE _ PROPERTY ,    String . format (  \" Bucketing   columns    % s   not   present   in   schema \"  ,    Sets . difference ( ImmutableSet . copyOf ( bucketedBy )  ,    ImmutableSet . copyOf ( allColumns )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["validateBucketColumns"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "List < String >    partitionedBy    =    HiveTableProperties . getPartitionedBy ( tableMetadata . getProperties (  )  )  ;", "List < String >    allColumns    =    tableMetadata . getColumns (  )  . stream (  )  . map ( ColumnMetadata :  : getName )  . collect ( Collectors . toList (  )  )  ;", "if    (  !  ( allColumns . containsAll ( partitionedBy )  )  )     {", "throw   new   PrestoException ( spi . StandardErrorCode . INVALID _ TABLE _ PROPERTY ,    String . format (  \" Partition   columns    % s   not   present   in   schema \"  ,    Sets . difference ( ImmutableSet . copyOf ( partitionedBy )  ,    ImmutableSet . copyOf ( allColumns )  )  )  )  ;", "}", "if    (  ( allColumns . size (  )  )     =  =     ( partitionedBy . size (  )  )  )     {", "throw   new   PrestoException ( spi . StandardErrorCode . INVALID _ TABLE _ PROPERTY ,     \" Table   contains   only   partition   columns \"  )  ;", "}", "if    (  !  ( allColumns . subList (  (  ( allColumns . size (  )  )     -     ( partitionedBy . size (  )  )  )  ,    allColumns . size (  )  )  . equals ( partitionedBy )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ COLUMN _ ORDER _ MISMATCH ,     (  \" Partition   keys   must   be   the   last   columns   in   the   table   and   in   the   same   order   as   the   table   properties :     \"     +    partitionedBy )  )  ;", "}", "}", "METHOD_END"], "methodName": ["validatePartitionColumns"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "if    (  (  !  ( allowCorruptWritesForTesting )  )     &  &     (  !  ( timeZone . equals ( DateTimeZone . getDefault (  )  )  )  )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ TIMEZONE _ MISMATCH ,    String . format (  \" To   write   Hive   data ,    your   JVM   timezone   must   match   the   Hive   storage   timezone .    Add    - Duser . timezone =  % s   to   your   JVM   arguments .  \"  ,    timeZone . getID (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["verifyJvmTimeZone"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "HiveWriteUtils . initializeSerializer ( conf ,    properties ,    serDe )  ;", "FileSinkOperator . RecordWriter   recordWriter    =    HiveWriteUtils . createRecordWriter ( target ,    conf ,    properties ,    outputFormatName )  ;", "try    {", "recordWriter . close ( false )  ;", "}    catch    ( IOException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ WRITER _ CLOSE _ ERROR ,     \" Error   write   empty   file   to   Hive \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["writeEmptyFile"], "fileName": "com.facebook.presto.hive.HiveMetadata"}, {"methodBody": ["METHOD_START", "{", "SemiTransactionalHiveMetastore   metastore    =    new   SemiTransactionalHiveMetastore ( hdfsEnvironment ,    CachingHiveMetastore . memoizeMetastore ( this . metastore ,    perTransactionCacheMaximumSize )  ,    renameExecution ,    skipDeletionForAlter )  ;", "return   new    ( metastore ,    hdfsEnvironment ,    partitionManager ,    timeZone ,    allowCorruptWritesForTesting ,    bucketWritingEnabled ,    writesToNonManagedTablesEnabled ,    createsOfNonManagedTablesEnabled ,    typeManager ,    locationService ,    tableParameterCodec ,    partitionUpdateCodec ,    typeTranslator ,    prestoVersion ,    new   MetastoreHiveStatisticsProvider ( typeManager ,    metastore ,    timeZone )  ,    maxPartitions )  ;", "}", "METHOD_END"], "methodName": ["create"], "fileName": "com.facebook.presto.hive.HiveMetadataFactory"}, {"methodBody": ["METHOD_START", "{", "List < T >    list    =    new   ArrayList <  >  ( items )  ;", "Collecs . shuffle ( list )  ;", "return   list ;", "}", "METHOD_END"], "methodName": ["shuffle"], "fileName": "com.facebook.presto.hive.HiveNodePartitioningProvider"}, {"methodBody": ["METHOD_START", "{", "return   partition . isPresent (  )     ?    String . format (  \" Table    '  % s '    partition    '  % s '    is   not   readable :     % s \"  ,    tableName ,    partition . get (  )  ,    message )     :    String . format (  \" Table    '  % s '    is   not   readable :     % s \"  ,    tableName ,    message )  ;", "}", "METHOD_END"], "methodName": ["composeMessage"], "fileName": "com.facebook.presto.hive.HiveNotReadableException"}, {"methodBody": ["METHOD_START", "{", "return   partition ;", "}", "METHOD_END"], "methodName": ["getPartition"], "fileName": "com.facebook.presto.hive.HiveNotReadableException"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.HiveNotReadableException"}, {"methodBody": ["METHOD_START", "{", "return   additionalTableParameters ;", "}", "METHOD_END"], "methodName": ["getAdditionalTableParameters"], "fileName": "com.facebook.presto.hive.HiveOutputTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   partitionedBy ;", "}", "METHOD_END"], "methodName": ["getPartitionedBy"], "fileName": "com.facebook.presto.hive.HiveOutputTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   tableOwner ;", "}", "METHOD_END"], "methodName": ["getTableOwner"], "fileName": "com.facebook.presto.hive.HiveOutputTableHandle"}, {"methodBody": ["METHOD_START", "{", "if    (  ( bucketFunction )     =  =    null )     {", "return   null ;", "}", "IntArrayBlockBuilder   bucketColumnBuilder    =    new   IntArrayBlockBuilder ( null ,    page . getPositionCount (  )  )  ;", "Page   bucketColumnsPage    =     . extractColumns ( page ,    bucketColumns )  ;", "for    ( int   position    =     0  ;    position    <     ( page . getPositionCount (  )  )  ;    position +  +  )     {", "int   bucket    =    bucketFunction . getBucket ( bucketColumnsPage ,    position )  ;", "bucketColumnBuilder . writeInt ( bucket )  ;", "}", "return   bucketColumnBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["buildBucketBlock"], "fileName": "com.facebook.presto.hive.HivePageSink"}, {"methodBody": ["METHOD_START", "{", "Optional < Exception >    rollbackException    =    Optional . empty (  )  ;", "for    ( HiveWriter   writer    :    writers )     {", "if    ( writer    !  =    null )     {", "try    {", "writer . rollback (  )  ;", "}    catch    ( Exception   e )     {", ". log . warn (  \" exception    '  % s '    while   rollback   on    % s \"  ,    e ,    writer )  ;", "rollbackException    =    Optional . of ( e )  ;", "}", "}", "}", "if    ( rollbackException . isPresent (  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ WRITER _ CLOSE _ ERROR ,     \" Error   rolling   back   write   to   Hive \"  ,    rollbackException . get (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["doAbort"], "fileName": "com.facebook.presto.hive.HivePageSink"}, {"methodBody": ["METHOD_START", "{", "while    (  ( page . getPositionCount (  )  )     >     ( HivePageSink . MAX _ PAGE _ POSITIONS )  )     {", "Page   chunk    =    page . getRegion (  0  ,    HivePageSink . MAX _ PAGE _ POSITIONS )  ;", "page    =    page . getRegion ( HivePageSink . MAX _ PAGE _ POSITIONS ,     (  ( page . getPositionCount (  )  )     -     ( HivePageSink . MAX _ PAGE _ POSITIONS )  )  )  ;", "writePage ( chunk )  ;", "}", "writePage ( page )  ;", "}", "METHOD_END"], "methodName": ["doAppend"], "fileName": "com.facebook.presto.hive.HivePageSink"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < Slice >    partitionUpdates    =    ImmutableList . builder (  )  ;", "List < Callable < Object >  >    verificationTasks    =    new   ArrayList <  >  (  )  ;", "for    ( Writer   writer    :    writers )     {", "writer . commit (  )  ;", "PartitionUpdate   partitionUpdate    =    writer . getPartitionUpdate (  )  ;", "partitionUpdates . add ( Slices . wrappedBuffer ( partitionUpdateCodec . toJsonBytes ( partitionUpdate )  )  )  ;", "writer . getVerificationTask (  )  . map ( Executors :  : callable )  . ifPresent ( verificationTasks :  : add )  ;", "}", "List < Slice >    result    =    partitionUpdates . build (  )  ;", "writtenBytes    =    writers . stream (  )  . mapToLong ( Writer :  : getWrittenBytes )  . sum (  )  ;", "if    ( verificationTasks . isEmpty (  )  )     {", "return   Futures . immediateFuture ( result )  ;", "}", "try    {", "List < ListenableFuture <  ?  >  >    futures    =    writeVerificationExecutor . invokeAll ( verificationTasks )  . stream (  )  . map (  (    future )     -  >     (  ( ListenableFuture <  ?  >  )     ( future )  )  )  . collect ( Collectors . toList (  )  )  ;", "return   Futures . transform ( Futures . allAsList ( futures )  ,     (    input )     -  >    result )  ;", "}    catch    ( InterruptedException   e )     {", "Thread . currentThread (  )  . interrupt (  )  ;", "throw   new   RuntimeException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["doFinish"], "fileName": "com.facebook.presto.hive.HivePageSink"}, {"methodBody": ["METHOD_START", "{", "Block [  ]    blocks    =    new   Block [ columns . length ]  ;", "for    ( int   i    =     0  ;    i    <     ( columns . length )  ;    i +  +  )     {", "int   dataColumn    =    columns [ i ]  ;", "blocks [ i ]     =    page . getBlock ( dataColumn )  ;", "}", "return   new    ( page . getPositionCount (  )  ,    blocks )  ;", "}", "METHOD_END"], "methodName": ["extractColumns"], "fileName": "com.facebook.presto.hive.HivePageSink"}, {"methodBody": ["METHOD_START", "{", "Block [  ]    blocks    =    new   Block [ dataColumnInputIndex . length ]  ;", "for    ( int   i    =     0  ;    i    <     ( dataColumnInputIndex . length )  ;    i +  +  )     {", "int   dataColumn    =    dataColumnInputIndex [ i ]  ;", "blocks [ i ]     =    page . getBlock ( dataColumn )  ;", "}", "return   new    ( page . getPositionCount (  )  ,    blocks )  ;", "}", "METHOD_END"], "methodName": ["getDataPage"], "fileName": "com.facebook.presto.hive.HivePageSink"}, {"methodBody": ["METHOD_START", "{", "Page   partitionColumns    =    HivePageSink . extractColumns ( page ,    partitionColumnsInputIndex )  ;", "Block   bucketBlock    =    buildBucketBlock ( page )  ;", "int [  ]    writerIndexes    =    pagePartitioner . partitionPage ( partitionColumns ,    bucketBlock )  ;", "if    (  ( pagePartitioner . getMaxIndex (  )  )     >  =     ( maxOpenWriters )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ TOO _ MANY _ OPEN _ PARTITIONS ,     \" Too   many   open   partitions \"  )  ;", "}", "while    (  ( writers . size (  )  )     <  =     ( pagePartitioner . getMaxIndex (  )  )  )     {", "writers . add ( null )  ;", "HivePageSink . WriterPositions   newWriterPositions    =    new   HivePageSink . WriterPositions (  )  ;", "systemMemoryUsage    +  =    SizeOf . sizeOf ( newWriterPositions . getPositionsArray (  )  )  ;", "writerPositions . add ( newWriterPositions )  ;", "}", "for    ( int   position    =     0  ;    position    <     ( page . getPositionCount (  )  )  ;    position +  +  )     {", "int   writerIndex    =    writerIndexes [ position ]  ;", "if    (  ( writers . get ( writerIndex )  )     !  =    null )     {", "continue ;", "}", "OptionalInt   bucketNumber    =    OptionalInt . empty (  )  ;", "if    ( bucketBlock    !  =    null )     {", "bucketNumber    =    OptionalInt . of ( bucketBlock . getInt ( position ,     0  )  )  ;", "}", "HiveWriter   writer    =    writerFactory . createWriter ( partitionColumns ,    position ,    bucketNumber )  ;", "writers . set ( writerIndex ,    writer )  ;", "}", "verify (  (  ( writers . size (  )  )     =  =     (  ( pagePartitioner . getMaxIndex (  )  )     +     1  )  )  )  ;", "verify (  (  !  ( writers . contains ( null )  )  )  )  ;", "return   writerIndexes ;", "}", "METHOD_END"], "methodName": ["getWriterIndexes"], "fileName": "com.facebook.presto.hive.HivePageSink"}, {"methodBody": ["METHOD_START", "{", "int [  ]    writerIndexes    =    getWriterIndexes ( page )  ;", "for    ( int   position    =     0  ;    position    <     ( page . getPositionCount (  )  )  ;    position +  +  )     {", "int   writerIndex    =    writerIndexes [ position ]  ;", "writerPositions . get ( writerIndex )  . add ( position )  ;", "}", "Page   dataPage    =    getDataPage ( page )  ;", "IntSet   writersUsed    =    new   IntArraySet ( writerIndexes )  ;", "for    ( IntIterator   iterator    =    writersUsed . iterator (  )  ;    iterator . hasNext (  )  ;  )     {", "int   writerIndex    =    iterator . nextInt (  )  ;", "HivePageSink . WriterPositions   currentWriterPositions    =    writerPositions . get ( writerIndex )  ;", "if    ( currentWriterPositions . isEmpty (  )  )     {", "continue ;", "}", "Page   pageForWriter    =    dataPage ;", "if    (  ( currentWriterPositions . size (  )  )     !  =     ( dataPage . getPositionCount (  )  )  )     {", "Block [  ]    blocks    =    new   Block [ dataPage . getChannelCount (  )  ]  ;", "for    ( int   channel    =     0  ;    channel    <     ( dataPage . getChannelCount (  )  )  ;    channel +  +  )     {", "blocks [ channel ]     =    new   spi . block . DictionaryBlock ( currentWriterPositions . size (  )  ,    dataPage . getBlock ( channel )  ,    currentWriterPositions . getPositionsArray (  )  )  ;", "}", "pageForWriter    =    new   Page ( currentWriterPositions . size (  )  ,    blocks )  ;", "}", "HiveWriter   writer    =    writers . get ( writerIndex )  ;", "long   currentWritten    =    writer . getWrittenBytes (  )  ;", "long   currentMemory    =    writer . getSystemMemoryUsage (  )  ;", "writer . append ( pageForWriter )  ;", "writtenBytes    +  =     ( writer . getWrittenBytes (  )  )     -    currentWritten ;", "systemMemoryUsage    +  =     ( writer . getSystemMemoryUsage (  )  )     -    currentMemory ;", "currentWriterPositions . clear (  )  ;", "}", "}", "METHOD_END"], "methodName": ["writePage"], "fileName": "com.facebook.presto.hive.HivePageSink"}, {"methodBody": ["METHOD_START", "{", "OptionalInt   bucketCount    =     ( handle . getBucketProperty (  )  . isPresent (  )  )     ?    OptionalInt . of ( handle . getBucketProperty (  )  . get (  )  . getBucketCount (  )  )     :    OptionalInt . empty (  )  ;", "HiveWriterFactory   writerFactory    =    new   HiveWriterFactory ( fileWriterFactories ,    handle . getSchemaName (  )  ,    handle . getTableName (  )  ,    isCreateTable ,    handle . getInputColumns (  )  ,    handle . getTableStorageFormat (  )  ,    handle . getPartitionStorageFormat (  )  ,    bucketCount ,    handle . getLocationHandle (  )  ,    locationService ,    handle . getFilePrefix (  )  ,    new   MetadataProvider ( handle . getPageSinkMetadata (  )  ,    metastore )  ,    typeManager ,    hdfsEnvironment ,    immutablePartitions ,    session ,    nodeManager ,    eventClient ,    hiveSessionProperties ,    hiveWriterStats )  ;", "return   new    ( writerFactory ,    handle . getInputColumns (  )  ,    handle . getBucketProperty (  )  ,    pageIndexerFactory ,    typeManager ,    hdfsEnvironment ,    maxOpenPartitions ,    writeVerificationExecutor ,    partitionUpdateCodec ,    session )  ;", "}", "METHOD_END"], "methodName": ["createPageSink"], "fileName": "com.facebook.presto.hive.HivePageSinkProvider"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( throwable ,     \" throwable   is   null \"  )  ;", "try    {", "close (  )  ;", "}    catch    ( RuntimeException   e )     {", "if    ( throwable    !  =    e )     {", "throwable . addSupsed ( e )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["closeWithSuppression"], "fileName": "com.facebook.presto.hive.HivePageSource"}, {"methodBody": ["METHOD_START", "{", "Type   fromType    =    typeManager . getType ( fromHiveType . getTypeSignature (  )  )  ;", "Type   toType    =    typeManager . getType ( toHiveType . getTypeSignature (  )  )  ;", "if    (  ( toType   instanceof   VarcharType )     &  &     (  (  (  ( fromHiveType . equals ( HiveType . HIVE _ BYTE )  )     |  |     ( fromHiveType . equals ( HiveType . HIVE _ SHORT )  )  )     |  |     ( fromHiveType . equals ( HiveType . HIVE _ INT )  )  )     |  |     ( fromHiveType . equals ( HiveType . HIVE _ LONG )  )  )  )     {", "return   new   HivePageSource . IntegerNumberToVarcharCoercer ( fromType ,    toType )  ;", "} else", "if    (  ( fromType   instanceof   VarcharType )     &  &     (  (  (  ( toHiveType . equals ( HiveType . HIVE _ BYTE )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ SHORT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ INT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ LONG )  )  )  )     {", "return   new   HivePageSource . VarcharToIntegerNumberCoercer ( fromType ,    toType )  ;", "} else", "if    (  (  (  ( fromHiveType . equals ( HiveType . HIVE _ BYTE )  )     &  &     ( toHiveType . equals ( HiveType . HIVE _ SHORT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ INT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ LONG )  )  )     {", "return   new   HivePageSource . IntegerNumberUpscaleCoercer ( fromType ,    toType )  ;", "} else", "if    (  (  ( fromHiveType . equals ( HiveType . HIVE _ SHORT )  )     &  &     ( toHiveType . equals ( HiveType . HIVE _ INT )  )  )     |  |     ( toHiveType . equals ( HiveType . HIVE _ LONG )  )  )     {", "return   new   HivePageSource . IntegerNumberUpscaleCoercer ( fromType ,    toType )  ;", "} else", "if    (  ( fromHiveType . equals ( HiveType . HIVE _ INT )  )     &  &     ( toHiveType . equals ( HiveType . HIVE _ LONG )  )  )     {", "return   new   HivePageSource . IntegerNumberUpscaleCoercer ( fromType ,    toType )  ;", "} else", "if    (  ( fromHiveType . equals ( HiveType . HIVE _ FLOAT )  )     &  &     ( toHiveType . equals ( HiveType . HIVE _ DOUBLE )  )  )     {", "return   new   HivePageSource . FloatToDoubleCoercer (  )  ;", "} else", "if    (  ( HiveUtil . isArrayType ( fromType )  )     &  &     ( HiveUtil . isArrayType ( toType )  )  )     {", "return   new   HivePageSource . ListCoercer ( typeManager ,    fromHiveType ,    toHiveType )  ;", "} else", "if    (  ( HiveUtil . isMapType ( fromType )  )     &  &     ( HiveUtil . isMapType ( toType )  )  )     {", "return   new   HivePageSource . MapCoercer ( typeManager ,    fromHiveType ,    toHiveType )  ;", "} else", "if    (  ( HiveUtil . isRowType ( fromType )  )     &  &     ( HiveUtil . isRowType ( toType )  )  )     {", "return   new   HivePageSource . StructCoercer ( typeManager ,    fromHiveType ,    toHiveType )  ;", "}", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Unsupported   coercion   from    % s   to    % s \"  ,    fromHiveType ,    toHiveType )  )  ;", "}", "METHOD_END"], "methodName": ["createCoercer"], "fileName": "com.facebook.presto.hive.HivePageSource"}, {"methodBody": ["METHOD_START", "{", "Block [  ]    blocks    =    new   Block [ columns . length ]  ;", "for    ( int   i    =     0  ;    i    <     ( columns . length )  ;    i +  +  )     {", "int   dataColumn    =    columns [ i ]  ;", "blocks [ i ]     =    page . getBlock ( dataColumn )  ;", "}", "return   new    ( page . getPositionCount (  )  ,    blocks )  ;", "}", "METHOD_END"], "methodName": ["extractColumns"], "fileName": "com.facebook.presto.hive.HivePageSource"}, {"methodBody": ["METHOD_START", "{", "return   delegate ;", "}", "METHOD_END"], "methodName": ["getPageSource"], "fileName": "com.facebook.presto.hive.HivePageSource"}, {"methodBody": ["METHOD_START", "{", "List < HivePageSourceProvider . ColumnMapping >    columnMappings    =    HivePageSourceProvider . ColumnMapping . buildColumnMappings ( partitionKeys ,    hiveColumns ,    bucketConversion . map ( HiveSplit . BucketConversion :  : getBucketColumnHandles )  . orElse ( ImmutableList . of (  )  )  ,    columnCoercions ,    path ,    bucketNumber )  ;", "List < HivePageSourceProvider . ColumnMapping >    regularAndInterimColumnMappings    =    HivePageSourceProvider . ColumnMapping . extractRegularAndInterimColumnMappings ( columnMappings )  ;", "Optional < HivePageSourceProvider . BucketAdaptation >    bucketAdaptation    =    bucketConversion . map (  (    conversion )     -  >     {", "Map < Integer ,    HivePageSourceProvider . ColumnMapping >    hiveIndexToBlockIndex    =    uniqueIndex ( regularAndInterimColumnMappings ,     (    columnMapping )     -  >    columnMapping . getHiveColumnHandle (  )  . getHiveColumnIndex (  )  )  ;", "int [  ]    bucketColumnIndices    =    conversion . getBucketColumnHandles (  )  . stream (  )  . mapToInt (  (    columnHandle )     -  >    hiveIndexToBlockIndex . get ( columnHandle . getHiveColumnIndex (  )  )  . getIndex (  )  )  . toArray (  )  ;", "List < HiveType >    bucketColumnHiveTypes    =    conversion . getBucketColumnHandles (  )  . stream (  )  . map (  (    columnHandle )     -  >    hiveIndexToBlockIndex . get ( columnHandle . getHiveColumnIndex (  )  )  . getHiveColumnHandle (  )  . getHiveType (  )  )  . collect ( toImmutableList (  )  )  ;", "return   new   HivePageSourceProvider . BucketAdaptation ( bucketColumnIndices ,    bucketColumnHiveTypes ,    conversion . getTableBucketCount (  )  ,    conversion . getPartitionBucketCount (  )  ,    bucketNumber . getAsInt (  )  )  ;", "}  )  ;", "for    ( HivePageSourceFactory   pageSourceFactory    :    pageSourceFactories )     {", "Optional <  ?    extends   ConnectorPageSource >    pageSource    =    pageSourceFactory . createPageSource ( configuration ,    session ,    path ,    start ,    length ,    fileSize ,    schema ,    HivePageSourceProvider . ColumnMapping . toColumnHandles ( regularAndInterimColumnMappings ,    true )  ,    effectivePredicate ,    hiveStorageTimeZone )  ;", "if    ( pageSource . isPresent (  )  )     {", "return   Optional . of ( new   HivePageSource ( columnMappings ,    bucketAdaptation ,    hiveStorageTimeZone ,    typeManager ,    pageSource . get (  )  )  )  ;", "}", "}", "for    ( HiveRecordCursorProvider   provider    :    cursorProviders )     {", "boolean   doCoercion    =     !  ( provider   instanceof   GenericHiveRecordCursorProvider )  ;", "Optional < RecordCursor >    cursor    =    provider . createRecordCursor ( configuration ,    session ,    path ,    start ,    length ,    fileSize ,    schema ,    HivePageSourceProvider . ColumnMapping . toColumnHandles ( regularAndInterimColumnMappings ,    doCoercion )  ,    effectivePredicate ,    hiveStorageTimeZone ,    typeManager )  ;", "if    ( cursor . isPresent (  )  )     {", "RecordCursor   delegate    =    cursor . get (  )  ;", "if    ( bucketAdaptation . isPresent (  )  )     {", "delegate    =    new   HiveBucketAdapterRecordCursor ( bucketAdaptation . get (  )  . getBucketColumnIndices (  )  ,    bucketAdaptation . get (  )  . getBucketColumnHiveTypes (  )  ,    bucketAdaptation . get (  )  . getTableBucketCount (  )  ,    bucketAdaptation . get (  )  . getPartitionBucketCount (  )  ,    bucketAdaptation . get (  )  . getBucketToKeep (  )  ,    typeManager ,    delegate )  ;", "}", "if    ( doCoercion )     {", "delegate    =    new   HiveCoercionRecordCursor ( regularAndInterimColumnMappings ,    typeManager ,    delegate )  ;", "}", "HiveRecordCursor   hiveRecordCursor    =    new   HiveRecordCursor ( columnMappings ,    hiveStorageTimeZone ,    typeManager ,    delegate )  ;", "List < Type >    columnTypes    =    hiveColumns . stream (  )  . map (  (    input )     -  >    typeManager . getType ( input . getTypeSignature (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "return   Optional . of ( new   com . facebook . presto . spi . RecordPageSource ( columnTypes ,    hiveRecordCursor )  )  ;", "}", "}", "return   Optional . empty (  )  ;", "}", "METHOD_END"], "methodName": ["createHivePageSource"], "fileName": "com.facebook.presto.hive.HivePageSourceProvider"}, {"methodBody": ["METHOD_START", "{", "return   keys ;", "}", "METHOD_END"], "methodName": ["getKeys"], "fileName": "com.facebook.presto.hive.HivePartition"}, {"methodBody": ["METHOD_START", "{", "return   partitionId ;", "}", "METHOD_END"], "methodName": ["getPartitionId"], "fileName": "com.facebook.presto.hive.HivePartition"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.HivePartition"}, {"methodBody": ["METHOD_START", "{", "return   bucket ;", "}", "METHOD_END"], "methodName": ["getBucket"], "fileName": "com.facebook.presto.hive.HivePartitionHandle"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HivePartitionKey . INSTANCE _ SIZE )     +     (  ( name . length (  )  )     *     ( Character . BYTES )  )  )     +     (  ( value . length (  )  )     *     ( Character . BYTES )  )  ;", "}", "METHOD_END"], "methodName": ["getEstimatedSizeInBytes"], "fileName": "com.facebook.presto.hive.HivePartitionKey"}, {"methodBody": ["METHOD_START", "{", "return   name ;", "}", "METHOD_END"], "methodName": ["getName"], "fileName": "com.facebook.presto.hive.HivePartitionKey"}, {"methodBody": ["METHOD_START", "{", "return   value ;", "}", "METHOD_END"], "methodName": ["getValue"], "fileName": "com.facebook.presto.hive.HivePartitionKey"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < String >    values    =    ImmutableList . builder (  )  ;", "boolean   inKey    =    true ;", "int   valueStart    =     -  1  ;", "for    ( int   i    =     0  ;    i    <     ( pName . length (  )  )  ;    i +  +  )     {", "char   current    =    pName . charAt ( i )  ;", "if    ( inKey )     {", "checkArgument (  ( current    !  =     '  /  '  )  ,     \" Invalid   p   spec :     % s \"  ,    pName )  ;", "if    ( current    =  =     '  =  '  )     {", "inKey    =    false ;", "valueStart    =    i    +     1  ;", "}", "} else", "if    ( current    =  =     '  /  '  )     {", "checkArgument (  ( valueStart    !  =     (  -  1  )  )  ,     \" Invalid   p   spec :     % s \"  ,    pName )  ;", "values . add ( FileUtils . unescapePathName ( pName . substring ( valueStart ,    i )  )  )  ;", "inKey    =    true ;", "valueStart    =     -  1  ;", "}", "}", "checkArgument (  (  ! inKey )  ,     \" Invalid   p   spec :     % s \"  ,    pName )  ;", "values . add ( FileUtils . unescapePathName ( pName . substring ( valueStart ,    pName . length (  )  )  )  )  ;", "return   values . build (  )  ;", "}", "METHOD_END"], "methodName": ["extractPartitionKeyValues"], "fileName": "com.facebook.presto.hive.HivePartitionManager"}, {"methodBody": ["METHOD_START", "{", "checkArgument ( effectivePredicate . getDomains (  )  . isPresent (  )  )  ;", "List < String >    filter    =    new   ArrayList <  >  (  )  ;", "for    ( HiveColumnHandle   partitionKey    :    partitionKeys )     {", "Domain   domain    =    effectivePredicate . getDomains (  )  . get (  )  . get ( partitionKey )  ;", "if    (  ( domain    !  =    null )     &  &     ( domain . isNullableSingleValue (  )  )  )     {", "Object   value    =    domain . getNullableSingleValue (  )  ;", "Type   type    =    domain . getType (  )  ;", "if    ( value    =  =    null )     {", "filter . add ( HivePartitionKey . HIVE _ DEFAULT _ DYNAMIC _ PARTITION )  ;", "} else", "if    ( type   instanceof   spi . type . CharType )     {", "io . airlift . slice . Slice   slice    =     (  ( io . airlift . slice . Slice )     ( value )  )  ;", "filter . add ( spi . type . Chars . padSpaces ( slice ,    type )  . toStringUtf 8  (  )  )  ;", "} else", "if    ( type   instanceof   spi . type . VarcharType )     {", "io . airlift . slice . Slice   slice    =     (  ( io . airlift . slice . Slice )     ( value )  )  ;", "filter . add ( slice . toStringUtf 8  (  )  )  ;", "} else", "if    (  !  ( assumeCanonicalPartitionKeys )  )     {", "filter . add ( HivePartitionManager . PARTITION _ VALUE _ WILDCARD )  ;", "} else", "if    (  ( type   instanceof   spi . type . DecimalType )     &  &     (  !  (  (  ( spi . type . DecimalType )     ( type )  )  . isShort (  )  )  )  )     {", "io . airlift . slice . Slice   slice    =     (  ( io . airlift . slice . Slice )     ( value )  )  ;", "filter . add ( spi . type . Decimals . toString ( slice ,     (  ( spi . type . DecimalType )     ( type )  )  . getScale (  )  )  )  ;", "} else", "if    (  ( type   instanceof   spi . type . DecimalType )     &  &     (  (  ( spi . type . DecimalType )     ( type )  )  . isShort (  )  )  )     {", "filter . add ( spi . type . Decimals . toString (  (  ( long )     ( value )  )  ,     (  ( spi . type . DecimalType )     ( type )  )  . getScale (  )  )  )  ;", "} else", "if    ( type   instanceof   spi . type . DateType )     {", "DateTimeFormatter   dateTimeFormatter    =    date (  )  . withZoneUTC (  )  ;", "filter . add ( dateTimeFormatter . print ( toMillis (  (  ( long )     ( value )  )  )  )  )  ;", "} else", "if    ( type   instanceof   spi . type . TimestampType )     {", "filter . add ( HivePartitionManager . PARTITION _ VALUE _ WILDCARD )  ;", "} else", "if    (  (  (  (  (  (  ( type   instanceof   spi . type . TinyintType )     |  |     ( type   instanceof   spi . type . SmallintType )  )     |  |     ( type   instanceof   spi . type . IntegerType )  )     |  |     ( type   instanceof   spi . type . BigintType )  )     |  |     ( type   instanceof   spi . type . DoubleType )  )     |  |     ( type   instanceof   spi . type . RealType )  )     |  |     ( type   instanceof   spi . type . BooleanType )  )     {", "filter . add ( value . toString (  )  )  ;", "} else    {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Unsupported   partition   key   type :     % s \"  ,    type . getDisplayName (  )  )  )  ;", "}", "} else    {", "filter . add ( HivePartitionManager . PARTITION _ VALUE _ WILDCARD )  ;", "}", "}", "return   metastore . getPartitionNamesByParts ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  ,    filter )  . orElseThrow (  (  )     -  >    new   TableNotFoundException ( tableName )  )  ;", "}", "METHOD_END"], "methodName": ["getFilteredPartitionNames"], "fileName": "com.facebook.presto.hive.HivePartitionManager"}, {"methodBody": ["METHOD_START", "{", "HiveTableHandle   hiveTableHandle    =     (  ( HiveTableHandle )     ( tableHandle )  )  ;", "TupleDomain < ColumnHandle >    effectivePredicate    =    constraint . getSummary (  )  ;", "SchemaTableName   tableName    =    hiveTableHandle . getSchemaTableName (  )  ;", "Table   table    =    getTable ( metastore ,    tableName )  ;", "if    (  !  ( table . getParameters (  )  . getOrDefault (  \" skip . footer . line . count \"  ,     \"  0  \"  )  . equals (  \"  0  \"  )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ UNSUPPORTED _ FORMAT ,     \" Table   with    ' skip . footer . line . count '    is   not   supported \"  )  ;", "}", "Optional < HiveBucketHandle >    hiveBucketHandle    =    HiveBucketing . getHiveBucketHandle ( table )  ;", "List < HiveColumnHandle >    partitionColumns    =    HiveUtil . getPartitionKeyColumnHandles ( table )  ;", "if    ( effectivePredicate . isNone (  )  )     {", "return   new   HivePartitionResult ( partitionColumns ,    ImmutableList . of (  )  ,    TupleDomain . none (  )  ,    TupleDomain . none (  )  ,    TupleDomain . none (  )  ,    hiveBucketHandle ,    Optional . empty (  )  )  ;", "}", "Optional < HiveBucketing . HiveBucketFilter >    bucketFilter    =    HiveBucketing . getHiveBucketFilter ( table ,    effectivePredicate )  ;", "TupleDomain < HiveColumnHandle >    compactEffectivePredicate    =     . toCompactTupleDomain ( effectivePredicate ,    domainCompactionThreshold )  ;", "if    ( partitionColumns . isEmpty (  )  )     {", "return   new   HivePartitionResult ( partitionColumns ,    ImmutableList . of ( new   HivePartition ( tableName )  )  ,    compactEffectivePredicate ,    effectivePredicate ,    TupleDomain . none (  )  ,    hiveBucketHandle ,    bucketFilter )  ;", "}", "List < Type >    partitionTypes    =    partitionColumns . stream (  )  . map (  (    column )     -  >    typeManager . getType ( column . getTypeSignature (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "List < String >    partitionNames    =    getFilteredPartitionNames ( metastore ,    tableName ,    partitionColumns ,    effectivePredicate )  ;", "Iterable < HivePartition >    partitionsIterable    =     (  )     -  >    partitionNames . stream (  )  . map (  (    partitionName )     -  >    parseValuesAndFilterPartition ( tableName ,    partitionName ,    partitionColumns ,    partitionTypes ,    constraint )  )  . filter ( Optional :  : isPresent )  . map ( Optional :  : get )  . iterator (  )  ;", "TupleDomain < ColumnHandle >    remainingTupleDomain    =    TupleDomain . withColumnDomains ( Maps . filterKeys ( effectivePredicate . getDomains (  )  . get (  )  ,    not ( Predicates . in ( partitionColumns )  )  )  )  ;", "TupleDomain < ColumnHandle >    enforcedTupleDomain    =    TupleDomain . withColumnDomains ( Maps . filterKeys ( effectivePredicate . getDomains (  )  . get (  )  ,    Predicates . in ( partitionColumns )  )  )  ;", "return   new   HivePartitionResult ( partitionColumns ,    partitionsIterable ,    compactEffectivePredicate ,    remainingTupleDomain ,    enforcedTupleDomain ,    hiveBucketHandle ,    bucketFilter )  ;", "}", "METHOD_END"], "methodName": ["getPartitions"], "fileName": "com.facebook.presto.hive.HivePartitionManager"}, {"methodBody": ["METHOD_START", "{", "Optional < Table >    target    =    metastore . getTable ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  ;", "if    (  !  ( target . isPresent (  )  )  )     {", "throw   new   spi . TableNotFoundException ( tableName )  ;", "}", "Table   table    =    target . get (  )  ;", "MetastoreUtil . verifyOnline ( tableName ,    Optional . empty (  )  ,    MetastoreUtil . getProtectMode ( table )  ,    table . getParameters (  )  )  ;", "return   table ;", "}", "METHOD_END"], "methodName": ["getTable"], "fileName": "com.facebook.presto.hive.HivePartitionManager"}, {"methodBody": ["METHOD_START", "{", "List < String >    keys    =    HivePartitionManager . extractPartitionKeyValues ( partitionId )  ;", "Map < ColumnHandle ,    Domain >    domains    =    constraint . getSummary (  )  . getDomains (  )  . get (  )  ;", "Builder < ColumnHandle ,    NullableValue >    builder    =    ImmutableMap . builder (  )  ;", "for    ( int   i    =     0  ;    i    <     ( partitionColumns . size (  )  )  ;    i +  +  )     {", "HiveColumnHandle   column    =    partitionColumns . get ( i )  ;", "NullableValue   parsedValue    =    HiveUtil . parsePartitionValue ( partitionId ,    keys . get ( i )  ,    partitionColumnTypes . get ( i )  ,    timeZone )  ;", "Domain   allowedDomain    =    domains . get ( column )  ;", "if    (  ( allowedDomain    !  =    null )     &  &     (  !  ( allowedDomain . includesNullableValue ( parsedValue . getValue (  )  )  )  )  )     {", "return   Optional . empty (  )  ;", "}", "builder . put ( column ,    parsedValue )  ;", "}", "Map < ColumnHandle ,    NullableValue >    values    =    builder . build (  )  ;", "if    (  !  ( constraint . predicate (  )  . test ( values )  )  )     {", "return   Optional . empty (  )  ;", "}", "return   Optional . of ( new   HivePartition ( tableName ,    partitionId ,    values )  )  ;", "}", "METHOD_END"], "methodName": ["parseValuesAndFilterPartition"], "fileName": "com.facebook.presto.hive.HivePartitionManager"}, {"methodBody": ["METHOD_START", "{", "Builder < HiveColumnHandle ,    Domain >    builder    =    ImmutableMap . builder (  )  ;", "effectivePredicate . getDomains (  )  . ifPresent (  (    domains )     -  >     {", "for    ( Entry < ColumnHandle ,    Domain >    entry    :    domains . entrySet (  )  )     {", "HiveColumnHandle   hiveColumnHandle    =     (  ( HiveColumnHandle )     ( entry . getKey (  )  )  )  ;", "ValueSet   values    =    entry . getValue (  )  . getValues (  )  ;", "ValueSet   compactValueSet    =    values . getValuesProcessor (  )  .  < Optional < ValueSet >  > transform (  (    ranges )     -  >     ( ranges . getRangeCount (  )  )     >    threshold    ?    of ( ValueSet . ofRanges ( ranges . getSpan (  )  )  )     :    empty (  )  ,     (    discreteValues )     -  >     ( discreteValues . getValues (  )  . size (  )  )     >    threshold    ?    of ( ValueSet . all ( values . getType (  )  )  )     :    empty (  )  ,     (    allOrNone )     -  >    empty (  )  )  . orElse ( values )  ;", "builder . put ( hiveColumnHandle ,    Domain . create ( compactValueSet ,    entry . getValue (  )  . isNullAllowed (  )  )  )  ;", "}", "}  )  ;", "return   TupleDomain . withColumnDomains ( builder . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["toCompactTupleDomain"], "fileName": "com.facebook.presto.hive.HivePartitionManager"}, {"methodBody": ["METHOD_START", "{", "return   columnCoercions ;", "}", "METHOD_END"], "methodName": ["getColumnCoercions"], "fileName": "com.facebook.presto.hive.HivePartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   hivePartition ;", "}", "METHOD_END"], "methodName": ["getHivePartition"], "fileName": "com.facebook.presto.hive.HivePartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   partition ;", "}", "METHOD_END"], "methodName": ["getPartition"], "fileName": "com.facebook.presto.hive.HivePartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   bucketFilter ;", "}", "METHOD_END"], "methodName": ["getBucketFilter"], "fileName": "com.facebook.presto.hive.HivePartitionResult"}, {"methodBody": ["METHOD_START", "{", "return   bucketHandle ;", "}", "METHOD_END"], "methodName": ["getBucketHandle"], "fileName": "com.facebook.presto.hive.HivePartitionResult"}, {"methodBody": ["METHOD_START", "{", "return   compactEffectivePredicate ;", "}", "METHOD_END"], "methodName": ["getCompactEffectivePredicate"], "fileName": "com.facebook.presto.hive.HivePartitionResult"}, {"methodBody": ["METHOD_START", "{", "return   enforcedConstraint ;", "}", "METHOD_END"], "methodName": ["getEnforcedConstraint"], "fileName": "com.facebook.presto.hive.HivePartitionResult"}, {"methodBody": ["METHOD_START", "{", "return   partitionColumns ;", "}", "METHOD_END"], "methodName": ["getPartitionColumns"], "fileName": "com.facebook.presto.hive.HivePartitionResult"}, {"methodBody": ["METHOD_START", "{", "return   partitions . iterator (  )  ;", "}", "METHOD_END"], "methodName": ["getPartitions"], "fileName": "com.facebook.presto.hive.HivePartitionResult"}, {"methodBody": ["METHOD_START", "{", "return   unenforcedConstraint ;", "}", "METHOD_END"], "methodName": ["getUnenforcedConstraint"], "fileName": "com.facebook.presto.hive.HivePartitionResult"}, {"methodBody": ["METHOD_START", "{", "return   bucketCount ;", "}", "METHOD_END"], "methodName": ["getBucketCount"], "fileName": "com.facebook.presto.hive.HivePartitioningHandle"}, {"methodBody": ["METHOD_START", "{", "return   hiveTypes ;", "}", "METHOD_END"], "methodName": ["getHiveTypes"], "fileName": "com.facebook.presto.hive.HivePartitioningHandle"}, {"methodBody": ["METHOD_START", "{", "ClassLoader   classLoader    =    Thread . currentThread (  )  . getContextClassLoader (  )  ;", "if    ( classLoader    =  =    null )     {", "classLoader    =     . class . getClassLoader (  )  ;", "}", "return   classLoader ;", "}", "METHOD_END"], "methodName": ["getClassLoader"], "fileName": "com.facebook.presto.hive.HivePlugin"}, {"methodBody": ["METHOD_START", "{", "long   start    =    System . nanoTime (  )  ;", ". log . info (  \" Running   import   for    % s \"  ,    table . getObjectName (  )  )  ;", "@ Language (  \" SQL \"  )", "String   sql ;", "switch    ( table . getObjectName (  )  )     {", "case    \" part \"     :", "case    \" partsupp \"     :", "case    \" supplier \"     :", "case    \" nation \"     :", "case    \" region \"     :", "sql    =    String . format (  \" CREATE   TABLE    % s   AS   SELECT    *    FROM    % s \"  ,    table . getObjectName (  )  ,    table )  ;", "break ;", "case    \" lineitem \"     :", "sql    =    String . format (  \" CREATE   TABLE    % s   WITH    ( bucketed _ by = array [  ' orderkey '  ]  ,    bucket _ count =  1  1  )    AS   SELECT    *    FROM    % s \"  ,    table . getObjectName (  )  ,    table )  ;", "break ;", "case    \" customer \"     :", "sql    =    String . format (  \" CREATE   TABLE    % s   WITH    ( bucketed _ by = array [  ' custkey '  ]  ,    bucket _ count =  1  1  )    AS   SELECT    *    FROM    % s \"  ,    table . getObjectName (  )  ,    table )  ;", "break ;", "case    \" orders \"     :", "sql    =    String . format (  \" CREATE   TABLE    % s   WITH    ( bucketed _ by = array [  ' custkey '  ]  ,    bucket _ count =  1  1  )    AS   SELECT    *    FROM    % s \"  ,    table . getObjectName (  )  ,    table )  ;", "break ;", "default    :", "throw   new   UnsupportedOperationException (  )  ;", "}", "long   rows    =     (  ( Long )     ( queryRunner . execute ( session ,    sql )  . getMaterializedRows (  )  . get (  0  )  . getField (  0  )  )  )  ;", ". log . info (  \" Imported    % s   rows   for    % s   in    % s \"  ,    rows ,    table . getObjectName (  )  ,    nanosSince ( start )  . convertToMostSuccinctTimeUnit (  )  )  ;", "}", "METHOD_END"], "methodName": ["copyTableBucketed"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "HiveQueryRunner . log . info (  \" Loading   data   from    % s .  % s .  .  .  \"  ,    sourceCatalog ,    sourceSchema )  ;", "long   startTime    =    System . nanoTime (  )  ;", "for    ( io . airlift . tpch . TpchTable <  ?  >    table    :    tables )     {", "HiveQueryRunner . copyTableBucketed ( queryRunner ,    new   metadata . QualifiedObjectName ( sourceCatalog ,    sourceSchema ,    table . getTableName (  )  . toLowerCase ( Locale . ENGLISH )  )  ,    session )  ;", "}", "HiveQueryRunner . log . info (  \" Loading   from    % s .  % s   complete   in    % s \"  ,    sourceCatalog ,    sourceSchema ,    nanosSince ( startTime )  . toString ( TimeUnit . SECONDS )  )  ;", "}", "METHOD_END"], "methodName": ["copyTpchTablesBucketed"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "return   testSessionBuilder (  )  . setCatalog ( HiveQueryRunner . HIVE _ BUCKETED _ CATALOG )  . setSchema ( HiveQueryRunner . TPCH _ BUCKETED _ SCHEMA )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["createBucketedSession"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "return   Database . builder (  )  . setDatabaseName ( name )  . setOwnerName (  \" public \"  )  . setOwnerType ( PrincipalType . ROLE )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["createDatabaseMetastoreObject"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "return   HiveQueryRunner . createQueryRunner ( ImmutableList . copyOf ( tables )  )  ;", "}", "METHOD_END"], "methodName": ["createQueryRunner"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "return   HiveQueryRunner . createQueryRunner ( tables ,    ImmutableMap . of (  )  )  ;", "}", "METHOD_END"], "methodName": ["createQueryRunner"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "return   HiveQueryRunner . createQueryRunner ( tables ,    extraProperties ,     \" sql - standard \"  ,    ImmutableMap . of (  )  )  ;", "}", "METHOD_END"], "methodName": ["createQueryRunner"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( DateTimeZone . getDefault (  )  ,    HiveQueryRunner . TIME _ ZONE ,     \" Timezone   not   configured   correctly .    Add    - Duser . timezone = Asia / Katmandu   to   your   JVM   arguments \"  )  ;", "DistributedQueryRunner   queryRunner    =    new   DistributedQueryRunner ( HiveQueryRunner . createSession (  )  ,     4  ,    extraProperties )  ;", "try    {", "queryRunner . installPlugin ( new   TpchPlugin (  )  )  ;", "queryRunner . createCatalog (  \" tpch \"  ,     \" tpch \"  )  ;", "File   baseDir    =    queryRunner . getCoordinator (  )  . getBaseDataDir (  )  . resolve (  \" hive _ data \"  )  . toFile (  )  ;", "HiveClientConfig   hiveClientConfig    =    new   HiveClientConfig (  )  ;", "HdfsConfiguration   hdfsConfiguration    =    new   HiveHdfsConfiguration ( new   HdfsConfigurationUpdater ( hiveClientConfig )  )  ;", "HdfsEnvironment   hdfsEnvironment    =    new   HdfsEnvironment ( hdfsConfiguration ,    hiveClientConfig ,    new   NoHdfsAuthentication (  )  )  ;", "FileHiveMetastore   metastore    =    new   FileHiveMetastore ( hdfsEnvironment ,    baseDir . toURI (  )  . toString (  )  ,     \" test \"  )  ;", "metastore . createDatabase ( HiveQueryRunner . createDatabaseMetastoreObject ( HiveQueryRunner . TPCH _ SCHEMA )  )  ;", "metastore . createDatabase ( HiveQueryRunner . createDatabaseMetastoreObject ( HiveQueryRunner . TPCH _ BUCKETED _ SCHEMA )  )  ;", "queryRunner . installPlugin ( new   HivePlugin ( HiveQueryRunner . HIVE _ CATALOG ,    metastore )  )  ;", "Map < String ,    String >    hiveProperties    =    ImmutableMap .  < String ,    String > builder (  )  . putAll ( extraHiveProperties )  . put (  \" hive . time - zone \"  ,    HiveQueryRunner . TIME _ ZONE . getID (  )  )  . put (  \" hive . security \"  ,    security )  . put (  \" hive . max - partitions - per - scan \"  ,     \"  1  0  0  0  \"  )  . put (  \" hive . assume - canonical - partition - keys \"  ,     \" true \"  )  . build (  )  ;", "Map < String ,    String >    hiveBucketedProperties    =    ImmutableMap .  < String ,    String > builder (  )  . putAll ( hiveProperties )  . put (  \" hive . max - initial - split - size \"  ,     \"  1  0 kB \"  )  . put (  \" hive . max - split - size \"  ,     \"  1  0 kB \"  )  . put (  \" hive . storage - format \"  ,     \" TEXTFILE \"  )  . put (  \" hive . compression - codec \"  ,     \" NONE \"  )  . build (  )  ;", "queryRunner . createCatalog ( HiveQueryRunner . HIVE _ CATALOG ,    HiveQueryRunner . HIVE _ CATALOG ,    hiveProperties )  ;", "queryRunner . createCatalog ( HiveQueryRunner . HIVE _ BUCKETED _ CATALOG ,    HiveQueryRunner . HIVE _ CATALOG ,    hiveBucketedProperties )  ;", "copyTpchTables ( queryRunner ,     \" tpch \"  ,    TINY _ SCHEMA _ NAME ,    HiveQueryRunner . createSession (  )  ,    tables )  ;", "HiveQueryRunner . copyTpchTablesBucketed ( queryRunner ,     \" tpch \"  ,    TINY _ SCHEMA _ NAME ,    HiveQueryRunner . createBucketedSession (  )  ,    tables )  ;", "return   queryRunner ;", "}    catch    ( Exception   e )     {", "queryRunner . close (  )  ;", "throw   e ;", "}", "}", "METHOD_END"], "methodName": ["createQueryRunner"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "return   testSessionBuilder (  )  . setCatalog ( HiveQueryRunner . HIVE _ CATALOG )  . setSchema ( HiveQueryRunner . TPCH _ SCHEMA )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["createSession"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "Logging . initialize (  )  ;", "DistributedQueryRunner   queryRunner    =     . createQueryRunner ( io . airlift . tpch . TpchTable . getTables (  )  ,    ImmutableMap . of (  \" http - server . http . port \"  ,     \"  8  0  8  0  \"  )  )  ;", "Thread . sleep (  1  0  )  ;", "Logger   log    =    Logger . get ( DistributedQueryRunner . class )  ;", "log . info (  \"  =  =  =  =  =  =  =  =    SERVER   STARTED    =  =  =  =  =  =  =  =  \"  )  ;", "log . info (  \"  \\ n =  =  =  =  \\ n % s \\ n =  =  =  =  \"  ,    queryRunner . getCoordinator (  )  . getBaseUrl (  )  )  ;", "}", "METHOD_END"], "methodName": ["main"], "fileName": "com.facebook.presto.hive.HiveQueryRunner"}, {"methodBody": ["METHOD_START", "{", "return   partition . isPresent (  )     ?    String . format (  \" Table    '  % s '    partition    '  % s '    is   read - only \"  ,    tableName ,    partition . get (  )  )     :    String . format (  \" Table    '  % s '    is   read - only \"  ,    tableName )  ;", "}", "METHOD_END"], "methodName": ["composeMessage"], "fileName": "com.facebook.presto.hive.HiveReadOnlyException"}, {"methodBody": ["METHOD_START", "{", "return   partition ;", "}", "METHOD_END"], "methodName": ["getPartition"], "fileName": "com.facebook.presto.hive.HiveReadOnlyException"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.HiveReadOnlyException"}, {"methodBody": ["METHOD_START", "{", "return   delegate ;", "}", "METHOD_END"], "methodName": ["getRegularColumnRecordCursor"], "fileName": "com.facebook.presto.hive.HiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "return   Optional . ofNullable (  (  ( String )     ( schemaProperties . get ( HiveSchemaProperties . LOCATION _ PROPERTY )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getLocation"], "fileName": "com.facebook.presto.hive.HiveSchemaProperties"}, {"methodBody": ["METHOD_START", "{", "return   new   com . facebook . presto . spi . session . PropertyMetadata ( name ,    description ,    VarcharType . createUnboundedVarcharType (  )  ,    DataSize . class ,    defaultValue ,    hidden ,     (    value )     -  >    DataSize . valueOf (  (  ( String )     ( value )  )  )  ,    DataSize :  : toString )  ;", "}", "METHOD_END"], "methodName": ["dataSizeSessionProperty"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   HiveStorageFormat . valueOf ( session . getProperty ( HiveSessionProperties . HIVE _ STORAGE _ FORMAT ,    String . class )  . toUpperCase ( Locale . ENGLISH )  )  ;", "}", "METHOD_END"], "methodName": ["getHiveStorageFormat"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . MAX _ INITIAL _ SPLIT _ SIZE ,    DataSize . class )  ;", "}", "METHOD_END"], "methodName": ["getMaxInitialSplitSize"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . MAX _ SPLIT _ SIZE ,    DataSize . class )  ;", "}", "METHOD_END"], "methodName": ["getMaxSplitSize"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ LAZY _ READ _ SMALL _ RANGES ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["getOrcLazyReadSmallRanges"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ MAX _ BUFFER _ SIZE ,    DataSize . class )  ;", "}", "METHOD_END"], "methodName": ["getOrcMaxBufferSize"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ MAX _ MERGE _ DISTANCE ,    DataSize . class )  ;", "}", "METHOD_END"], "methodName": ["getOrcMaxMergeDistance"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ MAX _ READ _ BLOCK _ SIZE ,    DataSize . class )  ;", "}", "METHOD_END"], "methodName": ["getOrcMaxReadBlockSize"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ OPTIMIZED _ WRITER _ MAX _ STRIPE _ SIZE ,    DataSize . class )  ;", "}", "METHOD_END"], "methodName": ["getOrcOptimizedWriterMaxStripeSize"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ STREAM _ BUFFER _ SIZE ,    DataSize . class )  ;", "}", "METHOD_END"], "methodName": ["getOrcStreamBufferSize"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ STRING _ STATISTICS _ LIMIT ,    DataSize . class )  ;", "}", "METHOD_END"], "methodName": ["getOrcStringStatisticsLimit"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   sessionProperties ;", "}", "METHOD_END"], "methodName": ["getSessionProperties"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . BUCKET _ EXECUTION _ ENABLED ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isBucketExecutionEnabled"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . FORCE _ LOCAL _ SCHEDULING ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isForceLocalScheduling"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ BLOOM _ FILTERS _ ENABLED ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isOrcBloomFiltersEnabled"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ OPTIMIZED _ WRITER _ ENABLED ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isOrcOptimizedWriterEnabled"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . ORC _ OPTIMIZED _ WRITER _ VALIDATE ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isOrcOptimizedWriterValidate"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . PARQUET _ OPTIMIZED _ READER _ ENABLED ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isParquetOptimizedReaderEnabled"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . PARQUET _ PREDICATE _ PUSHDOWN _ ENABLED ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isParquetPredicatePushdownEnabled"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . RCFILE _ OPTIMIZED _ WRITER _ ENABLED ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isRcfileOptimizedWriterEnabled"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . RCFILE _ OPTIMIZED _ WRITER _ VALIDATE ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isRcfileOptimizedWriterValidate"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . RESPECT _ TABLE _ FORMAT ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isRespectTableFormat"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   session . getProperty ( HiveSessionProperties . STATISTICS _ ENABLED ,    Boolean . class )  ;", "}", "METHOD_END"], "methodName": ["isStatisticsEnabled"], "fileName": "com.facebook.presto.hive.HiveSessionProperties"}, {"methodBody": ["METHOD_START", "{", "return   bucketConversion ;", "}", "METHOD_END"], "methodName": ["getBucketConversion"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   bucketNumber ;", "}", "METHOD_END"], "methodName": ["getBucketNumber"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   columnCoercions ;", "}", "METHOD_END"], "methodName": ["getColumnCoercions"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   database ;", "}", "METHOD_END"], "methodName": ["getDatabase"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   effectivePredicate ;", "}", "METHOD_END"], "methodName": ["getEffectivePredicate"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   fileSize ;", "}", "METHOD_END"], "methodName": ["getFileSize"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   length ;", "}", "METHOD_END"], "methodName": ["getLength"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   partitionKeys ;", "}", "METHOD_END"], "methodName": ["getPartitionKeys"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   partitionName ;", "}", "METHOD_END"], "methodName": ["getPartitionName"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   path ;", "}", "METHOD_END"], "methodName": ["getPath"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   schema ;", "}", "METHOD_END"], "methodName": ["getSchema"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   start ;", "}", "METHOD_END"], "methodName": ["getStart"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   table ;", "}", "METHOD_END"], "methodName": ["getTable"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   forceLocalScheduling ;", "}", "METHOD_END"], "methodName": ["isForceLocalScheduling"], "fileName": "com.facebook.presto.hive.HiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   highMemorySplitSourceCounter ;", "}", "METHOD_END"], "methodName": ["getHighMemorySplitSource"], "fileName": "com.facebook.presto.hive.HiveSplitManager"}, {"methodBody": ["METHOD_START", "{", "if    ( hivePartitions . isEmpty (  )  )     {", "return   ImmutableList . of (  )  ;", "}", "if    (  ( hivePartitions . size (  )  )     =  =     1  )     {", "HivePartition   firstPartition    =    getOnlyElement ( hivePartitions )  ;", "if    ( firstPartition . getPartitionId (  )  . equals ( HivePartition . UNPARTITIONED _ ID )  )     {", "return   ImmutableList . of ( new   HivePartitionMetadata ( firstPartition ,    Optional . empty (  )  ,    ImmutableMap . of (  )  )  )  ;", "}", "}", "Iterable < List < HivePartition >  >    partitionNameBatches    =     . partitionExponentially ( hivePartitions ,    minPartitionBatchSize ,    maxPartitionBatchSize )  ;", "Iterable < List < HivePartitionMetadata >  >    partitionBatches    =    transform ( partitionNameBatches ,     (    partitionBatch )     -  >     {", "Map < String ,    Optional < Partition >  >    batch    =    metastore . getPartitionsByNames ( tableName . getSchemaName (  )  ,    tableName . getTableName (  )  ,    Lists . transform ( partitionBatch ,    HivePartition :  : getPartitionId )  )  ;", "Builder < String ,    Partition >    partitionBuilder    =    ImmutableMap . builder (  )  ;", "for    ( Entry < String ,    Optional < Partition >  >    entry    :    batch . entrySet (  )  )     {", "if    (  !  ( entry . getValue (  )  . isPresent (  )  )  )     {", "throw   new   PrestoException ( HIVE _ PARTITION _ DROPPED _ DURING _ QUERY ,     (  \" Partition   no   longer   exists :     \"     +     ( entry . getKey (  )  )  )  )  ;", "}", "partitionBuilder . put ( entry . getKey (  )  ,    entry . getValue (  )  . get (  )  )  ;", "}", "Map < String ,    Partition >    partitions    =    partitionBuilder . build (  )  ;", "if    (  ( partitionBatch . size (  )  )     !  =     ( partitions . size (  )  )  )     {", "throw   new   PrestoException ( GENERIC _ INTERNAL _ ERROR ,    format (  \" Expected    % s   partitions   but   found    % s \"  ,    partitionBatch . size (  )  ,    partitions . size (  )  )  )  ;", "}", "ImmutableList . Builder < HivePartitionMetadata >    results    =    ImmutableList . builder (  )  ;", "for    ( HivePartition   hivePartition    :    partitionBatch )     {", "Partition   partition    =    partitions . get ( hivePartition . getPartitionId (  )  )  ;", "if    ( partition    =  =    null )     {", "throw   new   PrestoException ( GENERIC _ INTERNAL _ ERROR ,     (  \" Partition   not   loaded :     \"     +    hivePartition )  )  ;", "}", "String   partName    =    makePartName ( table . getPartitionColumns (  )  ,    partition . getValues (  )  )  ;", "verifyOnline ( tableName ,    Optional . of ( partName )  ,    getProtectMode ( partition )  ,    table . getParameters (  )  )  ;", "String   partitionNotReadable    =    partition . getParameters (  )  . get (  . OBJECT _ NOT _ READABLE )  ;", "if    (  !  ( isNullOrEmpty ( partitionNotReadable )  )  )     {", "throw   new   HiveNotReadableException ( tableName ,    Optional . of ( partName )  ,    partitionNotReadable )  ;", "}", "List < Column >    tableColumns    =    table . getDataColumns (  )  ;", "List < Column >    partitionColumns    =    partition . getColumns (  )  ;", "if    (  ( tableColumns    =  =    null )     |  |     ( partitionColumns    =  =    null )  )     {", "throw   new   PrestoException ( HIVE _ INVALID _ METADATA ,    format (  \" Table    '  % s '    or   partition    '  % s '    has   null   columns \"  ,    tableName ,    partName )  )  ;", "}", "Builder < Integer ,    HiveTypeName >    columnCoercions    =    ImmutableMap . builder (  )  ;", "for    ( int   i    =     0  ;    i    <     ( min ( partitionColumns . size (  )  ,    tableColumns . size (  )  )  )  ;    i +  +  )     {", "HiveType   tableType    =    tableColumns . get ( i )  . getType (  )  ;", "HiveType   partitionType    =    partitionColumns . get ( i )  . getType (  )  ;", "if    (  !  ( tableType . equals ( partitionType )  )  )     {", "if    (  !  ( coercionPolicy . canCoerce ( partitionType ,    tableType )  )  )     {", "throw   new   PrestoException ( HIVE _ PARTITION _ SCHEMA _ MISMATCH ,    format (  (  \"  \"     +     (  (  (  \" There   is   a   mismatch   between   the   table   and   partition   schemas .     \"     +     \" The   types   are   incompatible   and   cannot   be   coerced .     \"  )     +     \" The   column    '  % s '    in   table    '  % s '    is   declared   as   type    '  % s '  ,     \"  )     +     \" but   partition    '  % s '    declared   column    '  % s '    as   type    '  % s '  .  \"  )  )  ,    tableColumns . get ( i )  . getName (  )  ,    tableName ,    tableType ,    partName ,    partitionColumns . get ( i )  . getName (  )  ,    partitionType )  )  ;", "}", "columnCoercions . put ( i ,    partitionType . getHiveTypeName (  )  )  ;", "}", "}", "if    ( bucketProperty . isPresent (  )  )     {", "Optional < HiveBucketProperty >    partitionBucketProperty    =    partition . getStorage (  )  . getBucketProperty (  )  ;", "if    (  !  ( partitionBucketProperty . isPresent (  )  )  )     {", "throw   new   PrestoException ( HIVE _ PARTITION _ SCHEMA _ MISMATCH ,    format (  \" Hive   table    (  % s )    is   bucketed   but   partition    (  % s )    is   not   bucketed \"  ,    hivePartition . getTableName (  )  ,    hivePartition . getPartitionId (  )  )  )  ;", "}", "int   tableBucketCount    =    bucketProperty . get (  )  . getBucketCount (  )  ;", "int   partitionBucketCount    =    partitionBucketProperty . get (  )  . getBucketCount (  )  ;", "List < String >    tableBucketColumns    =    bucketProperty . get (  )  . getBucketedBy (  )  ;", "List < String >    partitionBucketColumns    =    partitionBucketProperty . get (  )  . getBucketedBy (  )  ;", "if    (  (  !  ( tableBucketColumns . equals ( partitionBucketColumns )  )  )     |  |     (  !  ( isBucketCountCompatible ( tableBucketCount ,    partitionBucketCount )  )  )  )     {", "throw   new   PrestoException ( HIVE _ PARTITION _ SCHEMA _ MISMATCH ,    format (  \" Hive   table    (  % s )    bucketing    ( columns =  % s ,    buckets =  % s )    is   not   compatible   with   partition    (  % s )    bucketing    ( columns =  % s ,    buckets =  % s )  \"  ,    hivePartition . getTableName (  )  ,    tableBucketColumns ,    tableBucketCount ,    hivePartition . getPartitionId (  )  ,    partitionBucketColumns ,    partitionBucketCount )  )  ;", "}", "}", "results . add ( new   HivePartitionMetadata ( hivePartition ,    Optional . of ( partition )  ,    columnCoercions . build (  )  )  )  ;", "}", "return   results . build (  )  ;", "}  )  ;", "return   concat ( partitionBatches )  ;", "}", "METHOD_END"], "methodName": ["getPartitionMetadata"], "fileName": "com.facebook.presto.hive.HiveSplitManager"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( tableBucketCount    >     0  )     &  &     ( partitionBucketCount    >     0  )  )  )  ;", "int   lar    =    Math . max ( tableBucketCount ,    partitionBucketCount )  ;", "int   smaller    =    Math . min ( tableBucketCount ,    partitionBucketCount )  ;", "if    (  ( lar    %    smaller )     !  =     0  )     {", "return   false ;", "}", "if    (  ( Inte . bitCount (  ( lar    /    smaller )  )  )     !  =     1  )     {", "return   false ;", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["isBucketCountCompatible"], "fileName": "com.facebook.presto.hive.HiveSplitManager"}, {"methodBody": ["METHOD_START", "{", "return    (  )     -  >    new   com . google . common . collect . AbstractIterator < List < T >  >  (  )     {", "private   int   currentSize    =    minBatchSize ;", "private   final   Iterator < T >    iterator    =    values . iterator (  )  ;", "@ Override", "protected   List < T >    computeNext (  )     {", "if    (  !  ( iterator . hasNext (  )  )  )     {", "return   endOfData (  )  ;", "}", "int   count    =     0  ;", "ImmutableList . Builder < T >    builder    =    ImmutableList . builder (  )  ;", "while    (  ( iterator . hasNext (  )  )     &  &     ( count    <     ( currentSize )  )  )     {", "builder . add ( iterator . next (  )  )  ;", "+  + count ;", "}", "currentSize    =    Math . min ( maxBatchSize ,     (  ( currentSize )     *     2  )  )  ;", "return   builder . build (  )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["partitionExponentially"], "fileName": "com.facebook.presto.hive.HiveSplitManager"}, {"methodBody": ["METHOD_START", "{", "if    (  ( stateReference . get (  )  . getKind (  )  )     !  =     ( HiveSplitSource . StateKind . INITIAL )  )     {", "return   immediateFuture ( null )  ;", "}", "if    (  ( estimatedSplitSizeInBytes . addAndGet ( split . getEstimatedSizeInBytes (  )  )  )     >     ( maxOutstandingSplitsBytes )  )     {", "if    ( loggedHighMemoryWarning . compareAndSet ( false ,    true )  )     {", "highMemorySplitSourceCounter . update (  1  )  ;", "HiveSplitSource . log . warn (  \" Split   buffering   for    % s .  % s   in   query    % s   exceeded   memory   limit    (  % s )  .     % s   splits   are   buffered .  \"  ,    databaseName ,    tableName ,    queryId ,    succinctBytes ( maxOutstandingSplitsBytes )  ,    getBufferedInternalSplitCount (  )  )  ;", "}", "throw   new   spi . PrestoException ( spi . StandardErrorCode . GENERIC _ INTERNAL _ ERROR ,    String . format (  \" Split   buffering   for    % s .  % s   exceeded   memory   limit    (  % s )  .     % s   splits   are   buffered .  \"  ,    databaseName ,    tableName ,    succinctBytes ( maxOutstandingSplitsBytes )  ,    getBufferedInternalSplitCount (  )  )  )  ;", "}", "bufferedInternalSplitCount . incrementAndGet (  )  ;", "OptionalInt   bucketNumber    =    split . getBucketNumber (  )  ;", "return   queues . offer ( bucketNumber ,    split )  ;", "}", "METHOD_END"], "methodName": ["addToQueue"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "ListenableFuture <  ?  >    lastResult    =    immediateFuture ( null )  ;", "for    ( Internal   split    :    splits )     {", "lastResult    =    addToQueue ( split )  ;", "}", "return   lastResult ;", "}", "METHOD_END"], "methodName": ["addToQueue"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "AtomicReference < HiveSplitSource . State >    stateReference    =    new   AtomicReference <  >  ( HiveSplitSource . State . initial (  )  )  ;", "return   new   HiveSplitSource ( session ,    databaseName ,    tableName ,    compactEffectivePredicate ,    new   HiveSplitSource . PerBucket (  )     {", "private   final   AsyncQueue < InternalHiveSplit >    queue    =    new   AsyncQueue <  >  ( maxOutstandingSplits ,    executor )  ;", "@ Override", "public   ListenableFuture <  ?  >    offer ( OptionalInt   bucketNumber ,    InternalHiveSplit   connectorSplit )     {", "return   queue . offer ( connectorSplit )  ;", "}", "@ Override", "public    < O >    ListenableFuture < O >    borrowBatchAsync ( OptionalInt   bucketNumber ,    int   maxSize ,    Function < List < InternalHiveSplit >  ,    AsyncQueue . BorrowResult < InternalHiveSplit ,    O >  >    function )     {", "checkArgument (  (  !  ( bucketNumber . isPresent (  )  )  )  )  ;", "return   queue . borrowBatchAsync ( maxSize ,    function )  ;", "}", "@ Override", "public   void   finish (  )     {", "queue . finish (  )  ;", "}", "@ Override", "public   boolean   isFinished ( OptionalInt   bucketNumber )     {", "checkArgument (  (  !  ( bucketNumber . isPresent (  )  )  )  )  ;", "return   queue . isFinished (  )  ;", "}", "}  ,    maxInitialSplits ,    maxOutstandingSplitsSize ,    splitLoader ,    stateReference ,    highMemorySplitSourceCounter )  ;", "}", "METHOD_END"], "methodName": ["allAtOnce"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "AtomicReference < HiveSplitSource . State >    stateReference    =    new   AtomicReference <  >  ( HiveSplitSource . State . initial (  )  )  ;", "return   new   HiveSplitSource ( session ,    databaseName ,    tableName ,    compactEffectivePredicate ,    new   HiveSplitSource . PerBucket (  )     {", "private   final   Map < Integer ,    AsyncQueue < InternalHiveSplit >  >    queues    =    new   ConcurrentHashMap <  >  (  )  ;", "@ Override", "public   ListenableFuture <  ?  >    offer ( OptionalInt   bucketNumber ,    InternalHiveSplit   connectorSplit )     {", "AsyncQueue < InternalHiveSplit >    queue    =    queueFor ( bucketNumber )  ;", "queue . offer ( connectorSplit )  ;", "return   immediateFuture ( null )  ;", "}", "@ Override", "public    < O >    ListenableFuture < O >    borrowBatchAsync ( OptionalInt   bucketNumber ,    int   maxSize ,    Function < List < InternalHiveSplit >  ,    AsyncQueue . BorrowResult < InternalHiveSplit ,    O >  >    function )     {", "return   queueFor ( bucketNumber )  . borrowBatchAsync ( maxSize ,    function )  ;", "}", "@ Override", "public   void   finish (  )     {", "queues . values (  )  . forEach ( AsyncQueue :  : finish )  ;", "}", "@ Override", "public   boolean   isFinished ( OptionalInt   bucketNumber )     {", "return   queueFor ( bucketNumber )  . isFinished (  )  ;", "}", "public   AsyncQueue < InternalHiveSplit >    queueFor ( OptionalInt   bucketNumber )     {", "checkArgument ( bucketNumber . isPresent (  )  )  ;", "return   queues . computeIfAbsent ( bucketNumber . getAsInt (  )  ,     (    ignored )     -  >     {", "if    (  ( stateReference . get (  )  . getKind (  )  )     !  =     ( HiveSplitSource . StateKind . INITIAL )  )     {", "throw   new   IllegalStateException (  )  ;", "}", "return   new   AsyncQueue <  >  ( estimatedOutstandingSplitsPerBucket ,    executor )  ;", "}  )  ;", "}", "}  ,    maxInitialSplits ,    maxOutstandingSplitsSize ,    splitLoader ,    stateReference ,    highMemorySplitSourceCounter )  ;", "}", "METHOD_END"], "methodName": ["bucketed"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "if    ( HiveSplitSource . setIf ( stateReference ,    HiveSplitSource . State . failed ( e )  ,     (    state )     -  >     ( state . getKind (  )  )     =  =     ( HiveSplitSource . StateKind . INITIAL )  )  )     {", "splitLoader . stop (  )  ;", "queues . finish (  )  ;", "}", "}", "METHOD_END"], "methodName": ["fail"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "return   bufferedInternalSplitCount . get (  )  ;", "}", "METHOD_END"], "methodName": ["getBufferedInternalSplitCount"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "if    ( HiveSplitSource . setIf ( stateReference ,    HiveSplitSource . State . noMoreSplits (  )  ,     (    state )     -  >     ( state . getKind (  )  )     =  =     ( HiveSplitSource . StateKind . INITIAL )  )  )     {", "splitLoader . stop (  )  ;", "queues . finish (  )  ;", "}", "}", "METHOD_END"], "methodName": ["noMoreSplits"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "if    ( throwable   instanceof   PrestoException )     {", "throw    (  ( PrestoException )     ( throwable )  )  ;", "}", "if    ( throwable   instanceof   FileNotFoundException )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ FILE _ NOT _ FOUND ,    throwable )  ;", "}", "throw   new   PrestoException ( HiveErrorCode . HIVE _ UNKNOWN _ ERROR ,    throwable )  ;", "}", "METHOD_END"], "methodName": ["propagatePrestoException"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "while    ( true )     {", "T   current    =    atomicReference . get (  )  ;", "if    (  !  ( dicate . test ( current )  )  )     {", "return   false ;", "}", "if    ( atomicReference . compareAndSet ( current ,    newValue )  )     {", "return   true ;", "}", "}", "}", "METHOD_END"], "methodName": ["setIf"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "if    ( partitionHandle    =  =     ( NotPartitionedPartitionHandle . NOT _ PARTITIONED )  )     {", "return   OptionalInt . empty (  )  ;", "}", "return   OptionalInt . of (  (  ( PartitionHandle )     ( partitionHandle )  )  . getBucket (  )  )  ;", "}", "METHOD_END"], "methodName": ["toBucketNumber"], "fileName": "com.facebook.presto.hive.HiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "return   estimatedWriterSystemMemoryUsage ;", "}", "METHOD_END"], "methodName": ["getEstimatedWriterSystemMemoryUsage"], "fileName": "com.facebook.presto.hive.HiveStorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   inputFormat ;", "}", "METHOD_END"], "methodName": ["getInputFormat"], "fileName": "com.facebook.presto.hive.HiveStorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   outputFormat ;", "}", "METHOD_END"], "methodName": ["getOutputFormat"], "fileName": "com.facebook.presto.hive.HiveStorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   serde ;", "}", "METHOD_END"], "methodName": ["getSerDe"], "fileName": "com.facebook.presto.hive.HiveStorageFormat"}, {"methodBody": ["METHOD_START", "{", "return    (  ( MapTypeInfo )     ( typeInfo )  )  ;", "}", "METHOD_END"], "methodName": ["mapTypeInfo"], "fileName": "com.facebook.presto.hive.HiveStorageFormat"}, {"methodBody": ["METHOD_START", "{", "return    (  ( PrimitiveTypeInfo )     ( typeInfo )  )  ;", "}", "METHOD_END"], "methodName": ["primitiveTypeInfo"], "fileName": "com.facebook.presto.hive.HiveStorageFormat"}, {"methodBody": ["METHOD_START", "{", "if    (  ( type . getCategory (  )  )     =  =     ( Category . MAP )  )     {", "TypeInfo   keyType    =    HiveStorageFormat . mapTypeInfo ( type )  . getMapKeyTypeInfo (  )  ;", "if    (  (  ( keyType . getCategory (  )  )     !  =     ( Category . PRIMITIVE )  )     |  |     (  ( HiveStorageFormat . primitiveTypeInfo ( keyType )  . getPrimitiveCategory (  )  )     !  =     ( PrimitiveCategory . STRING )  )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Column    % s   has   a   non - varchar   map   key ,    which   is   not   supported   by   Avro \"  ,    columnName )  )  ;", "}", "} else", "if    (  ( type . getCategory (  )  )     =  =     ( Category . PRIMITIVE )  )     {", "PrimitiveCategory   primitive    =    HiveStorageFormat . primitiveTypeInfo ( type )  . getPrimitiveCategory (  )  ;", "if    ( primitive    =  =     ( PrimitiveCategory . BYTE )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Column    % s   is   tinyint ,    which   is   not   supported   by   Avro .    Use   integer   instead .  \"  ,    columnName )  )  ;", "}", "if    ( primitive    =  =     ( PrimitiveCategory . SHORT )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Column    % s   is   smallint ,    which   is   not   supported   by   Avro .    Use   integer   instead .  \"  ,    columnName )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["validateAvroType"], "fileName": "com.facebook.presto.hive.HiveStorageFormat"}, {"methodBody": ["METHOD_START", "{", "if    (  ( this )     =  =     ( HiveStorageFormat . AVRO )  )     {", "for    ( HiveColumnHandle   handle    :    handles )     {", "if    (  !  ( handle . isPartitionKey (  )  )  )     {", "HiveStorageFormat . validateAvroType ( handle . getHiveType (  )  . getTypeInfo (  )  ,    handle . getName (  )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["validateColumns"], "fileName": "com.facebook.presto.hive.HiveStorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   schemaName ;", "}", "METHOD_END"], "methodName": ["getSchemaName"], "fileName": "com.facebook.presto.hive.HiveTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   new   SchemaTableName ( schemaName ,    tableName )  ;", "}", "METHOD_END"], "methodName": ["getSchemaTableName"], "fileName": "com.facebook.presto.hive.HiveTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.HiveTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   bucketFilter ;", "}", "METHOD_END"], "methodName": ["getBucketFilter"], "fileName": "com.facebook.presto.hive.HiveTableLayoutHandle"}, {"methodBody": ["METHOD_START", "{", "return   bucketHandle ;", "}", "METHOD_END"], "methodName": ["getBucketHandle"], "fileName": "com.facebook.presto.hive.HiveTableLayoutHandle"}, {"methodBody": ["METHOD_START", "{", "return   compactEffectivePredicate ;", "}", "METHOD_END"], "methodName": ["getCompactEffectivePredicate"], "fileName": "com.facebook.presto.hive.HiveTableLayoutHandle"}, {"methodBody": ["METHOD_START", "{", "return   partitionColumns ;", "}", "METHOD_END"], "methodName": ["getPartitionColumns"], "fileName": "com.facebook.presto.hive.HiveTableLayoutHandle"}, {"methodBody": ["METHOD_START", "{", "return   Optional . ofNullable ( partitions )  ;", "}", "METHOD_END"], "methodName": ["getPartitions"], "fileName": "com.facebook.presto.hive.HiveTableLayoutHandle"}, {"methodBody": ["METHOD_START", "{", "return   promisedPredicate ;", "}", "METHOD_END"], "methodName": ["getPromisedPredicate"], "fileName": "com.facebook.presto.hive.HiveTableLayoutHandle"}, {"methodBody": ["METHOD_START", "{", "return   schemaTableName ;", "}", "METHOD_END"], "methodName": ["getSchemaTableName"], "fileName": "com.facebook.presto.hive.HiveTableLayoutHandle"}, {"methodBody": ["METHOD_START", "{", "List < String >    bucketedBy    =    HiveTableProperties . getBucketedBy ( tableProperties )  ;", "int   bucketCount    =     (  ( Integer )     ( tableProperties . get ( HiveTableProperties . BUCKET _ COUNT _ PROPERTY )  )  )  ;", "if    (  ( bucketedBy . isEmpty (  )  )     &  &     ( bucketCount    =  =     0  )  )     {", "return   Optional . empty (  )  ;", "}", "if    ( bucketCount    <     0  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . INVALID _ TABLE _ PROPERTY ,    String . format (  \"  % s   must   be   greater   than   zero \"  ,    HiveTableProperties . BUCKET _ COUNT _ PROPERTY )  )  ;", "}", "if    (  ( bucketedBy . isEmpty (  )  )     |  |     ( bucketCount    =  =     0  )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . INVALID _ TABLE _ PROPERTY ,    String . format (  \"  % s   and    % s   must   be   specified   together \"  ,    HiveTableProperties . BUCKETED _ BY _ PROPERTY ,    HiveTableProperties . BUCKET _ COUNT _ PROPERTY )  )  ;", "}", "return   Optional . of ( new   HiveBucketProperty ( bucketedBy ,    bucketCount )  )  ;", "}", "METHOD_END"], "methodName": ["getBucketProperty"], "fileName": "com.facebook.presto.hive.HiveTableProperties"}, {"methodBody": ["METHOD_START", "{", "return    (  ( List < String >  )     ( tableProperties . get ( HiveTableProperties . BUCKETED _ BY _ PROPERTY )  )  )  ;", "}", "METHOD_END"], "methodName": ["getBucketedBy"], "fileName": "com.facebook.presto.hive.HiveTableProperties"}, {"methodBody": ["METHOD_START", "{", "return    (  ( String )     ( tableProperties . get ( HiveTableProperties . EXTERNAL _ LOCATION _ PROPERTY )  )  )  ;", "}", "METHOD_END"], "methodName": ["getExternalLocation"], "fileName": "com.facebook.presto.hive.HiveTableProperties"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HiveStorageFormat )     ( tableProperties . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  )  )  ;", "}", "METHOD_END"], "methodName": ["getHiveStorageFormat"], "fileName": "com.facebook.presto.hive.HiveTableProperties"}, {"methodBody": ["METHOD_START", "{", "return    (  ( List < String >  )     ( tableProperties . get ( HiveTableProperties . ORC _ BLOOM _ FILTER _ COLUMNS )  )  )  ;", "}", "METHOD_END"], "methodName": ["getOrcBloomFilterColumns"], "fileName": "com.facebook.presto.hive.HiveTableProperties"}, {"methodBody": ["METHOD_START", "{", "return    (  ( Double )     ( tableProperties . get ( HiveTableProperties . ORC _ BLOOM _ FILTER _ FPP )  )  )  ;", "}", "METHOD_END"], "methodName": ["getOrcBloomFilterFpp"], "fileName": "com.facebook.presto.hive.HiveTableProperties"}, {"methodBody": ["METHOD_START", "{", "return    (  ( List < String >  )     ( tableProperties . get ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY )  )  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionedBy"], "fileName": "com.facebook.presto.hive.HiveTableProperties"}, {"methodBody": ["METHOD_START", "{", "return   tableProperties ;", "}", "METHOD_END"], "methodName": ["getTableProperties"], "fileName": "com.facebook.presto.hive.HiveTableProperties"}, {"methodBody": ["METHOD_START", "{", "return    (  ( ArrayType )     ( HiveTestUtils . TYPE _ MANAGER . getParameterizedType ( ARRAY ,    ImmutableList . of ( TypeSignatureParameter . of ( elementType . getTypeSignature (  )  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["arrayType"], "fileName": "com.facebook.presto.hive.HiveTestUtils"}, {"methodBody": ["METHOD_START", "{", "return   HiveTestUtils . createTestHdfsEnvironment ( config ,    new   PrestoS 3 ConfigurationUpdater ( new   HiveS 3 Config (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["createTestHdfsEnvironment"], "fileName": "com.facebook.presto.hive.HiveTestUtils"}, {"methodBody": ["METHOD_START", "{", "HdfsConfiguration   hdfsConfig    =    new   HiveHdfsConfiguration ( new   HdfsConfigurationUpdater ( hiveConfig ,    s 3 Config )  )  ;", "return   new   HdfsEnvironment ( hdfsConfig ,    hiveConfig ,    new   NoHdfsAuthentication (  )  )  ;", "}", "METHOD_END"], "methodName": ["createTestHdfsEnvironment"], "fileName": "com.facebook.presto.hive.HiveTestUtils"}, {"methodBody": ["METHOD_START", "{", "FileFormatDataSourceStats   stats    =    new   FileFormatDataSourceStats (  )  ;", "HdfsEnvironment   testHdfsEnvironment    =     . createTestHdfsEnvironment ( hiveClientConfig )  ;", "return   ImmutableSet .  < HivePageSourceFactory > builder (  )  . add ( new   RcFilePageSourceFactory (  . TYPE _ MANAGER ,    testHdfsEnvironment ,    stats )  )  . add ( new   OrcPageSourceFactory (  . TYPE _ MANAGER ,    hiveClientConfig ,    testHdfsEnvironment ,    stats )  )  . add ( new   DwrfPageSourceFactory (  . TYPE _ MANAGER ,    testHdfsEnvironment ,    stats )  )  . add ( new   ParquetPageSourceFactory (  . TYPE _ MANAGER ,    hiveClientConfig ,    testHdfsEnvironment )  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getDefaultHiveDataStreamFactories"], "fileName": "com.facebook.presto.hive.HiveTestUtils"}, {"methodBody": ["METHOD_START", "{", "HdfsEnvironment   testHdfsEnvironment    =    HiveTestUtils . createTestHdfsEnvironment ( hiveClientConfig )  ;", "return   ImmutableSet .  < HiveFileWriterFactory > builder (  )  . add ( new   RcFileFileWriterFactory ( testHdfsEnvironment ,    HiveTestUtils . TYPE _ MANAGER ,    new   NodeVersion (  \" test _ version \"  )  ,    hiveClientConfig ,    new   FileFormatDataSourceStats (  )  )  )  . add ( new   OrcFileWriterFactory ( testHdfsEnvironment ,    HiveTestUtils . TYPE _ MANAGER ,    new   NodeVersion (  \" test _ version \"  )  ,    hiveClientConfig ,    new   FileFormatDataSourceStats (  )  ,    new   OrcFileWriterConfig (  )  )  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getDefaultHiveFileWriterFactories"], "fileName": "com.facebook.presto.hive.HiveTestUtils"}, {"methodBody": ["METHOD_START", "{", "HdfsEnvironment   testHdfsEnvironment    =    HiveTestUtils . createTestHdfsEnvironment ( hiveClientConfig )  ;", "return   ImmutableSet .  < HiveRecordCursorProvider > builder (  )  . add ( new   ParquetRecordCursorProvider ( hiveClientConfig ,    testHdfsEnvironment )  )  . add ( new   GenericHiveRecordCursorProvider ( testHdfsEnvironment )  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getDefaultHiveRecordCursorProvider"], "fileName": "com.facebook.presto.hive.HiveTestUtils"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < Type >    types    =    ImmutableList . builder (  )  ;", "for    ( ColumnHandle   columnHandle    :    columnHandles )     {", "types . add (  . TYPE _ MANAGER . getType (  (  ( HiveColumnHandle )     ( columnHandle )  )  . getTypeSignature (  )  )  )  ;", "}", "return   types . build (  )  ;", "}", "METHOD_END"], "methodName": ["getTypes"], "fileName": "com.facebook.presto.hive.HiveTestUtils"}, {"methodBody": ["METHOD_START", "{", "return    (  ( MapType )     ( HiveTestUtils . TYPE _ MANAGER . getParameterizedType ( MAP ,    ImmutableList . of ( TypeSignatureParameter . of ( keyType . getTypeSignature (  )  )  ,    TypeSignatureParameter . of ( valueType . getTypeSignature (  )  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["mapType"], "fileName": "com.facebook.presto.hive.HiveTestUtils"}, {"methodBody": ["METHOD_START", "{", "return    (  ( RowType )     ( HiveTestUtils . TYPE _ MANAGER . getParameterizedType ( ROW ,    ImmutableList . copyOf ( elementTypeSignatures . stream (  )  . map ( TypeSignatureParameter :  : of )  . collect ( Collectors . toList (  )  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["rowType"], "fileName": "com.facebook.presto.hive.HiveTestUtils"}, {"methodBody": ["METHOD_START", "{", "return   uuid ;", "}", "METHOD_END"], "methodName": ["getUuid"], "fileName": "com.facebook.presto.hive.HiveTransactionHandle"}, {"methodBody": ["METHOD_START", "{", "return   transactions . get ( transactionHandle )  ;", "}", "METHOD_END"], "methodName": ["get"], "fileName": "com.facebook.presto.hive.HiveTransactionManager"}, {"methodBody": ["METHOD_START", "{", "ConnectorMetadata   previousValue    =    transactions . putIfAbsent ( transactionHandle ,    metadata )  ;", "checkState (  ( previousValue    =  =    null )  )  ;", "}", "METHOD_END"], "methodName": ["put"], "fileName": "com.facebook.presto.hive.HiveTransactionManager"}, {"methodBody": ["METHOD_START", "{", "return   transactions . remove ( transactionHandle )  ;", "}", "METHOD_END"], "methodName": ["remove"], "fileName": "com.facebook.presto.hive.HiveTransactionManager"}, {"methodBody": ["METHOD_START", "{", "return   typeInfo . getCategory (  )  ;", "}", "METHOD_END"], "methodName": ["getCategory"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "return   hiveTypeName ;", "}", "METHOD_END"], "methodName": ["getHiveTypeName"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "switch    ( typeInfo . getPrimitiveCategory (  )  )     {", "case   spi . type . BooleanType . BOOLEAN    :", "return   spi . type . BooleanType . BOOLEAN ;", "case   BYTE    :", "return   spi . type . TinyintType . TINYINT ;", "case   SHORT    :", "return   spi . type . SmallintType . SMALLINT ;", "case   INT    :", "return   spi . type . IntegerType . INTEGER ;", "case   LONG    :", "return   spi . type . BigintType . BIGINT ;", "case   FLOAT    :", "return   spi . type . RealType . REAL ;", "case   spi . type . DoubleType . DOUBLE    :", "return   spi . type . DoubleType . DOUBLE ;", "case   STRING    :", "return   VarcharType . createUnboundedVarcharType (  )  ;", "case   VARCHAR    :", "return   VarcharType . createVarcharType (  (  ( VarcharTypeInfo )     ( typeInfo )  )  . getLength (  )  )  ;", "case   CHAR    :", "return   CharType . createCharType (  (  ( CharTypeInfo )     ( typeInfo )  )  . getLength (  )  )  ;", "case   spi . type . DateType . DATE    :", "return   spi . type . DateType . DATE ;", "case   spi . type . TimestampType . TIMESTAMP    :", "return   spi . type . TimestampType . TIMESTAMP ;", "case   BINARY    :", "return   VarbinaryType . VARBINARY ;", "case   DECIMAL    :", "DecimalTypeInfo   decimalTypeInfo    =     (  ( DecimalTypeInfo )     ( typeInfo )  )  ;", "return   DecimalType . createDecimalType ( decimalTypeInfo . precision (  )  ,    decimalTypeInfo . scale (  )  )  ;", "default    :", "return   null ;", "}", "}", "METHOD_END"], "methodName": ["getPrimitiveType"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "return   typeManager . getType ( getTypeSignature (  )  )  ;", "}", "METHOD_END"], "methodName": ["getType"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "return   typeInfo ;", "}", "METHOD_END"], "methodName": ["getTypeInfo"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "return   HiveType . getTypeSignature ( typeInfo )  ;", "}", "METHOD_END"], "methodName": ["getTypeSignature"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "switch    ( typeInfo . getCategory (  )  )     {", "case   PRIMITIVE    :", "Type   primitiveType    =    HiveType . getPrimitiveType (  (  ( PrimitiveTypeInfo )     ( typeInfo )  )  )  ;", "if    ( primitiveType    =  =    null )     {", "break ;", "}", "return   primitiveType . getTypeSignature (  )  ;", "case   MAP    :", "MapTypeInfo   mapTypeInfo    =     (  ( MapTypeInfo )     ( typeInfo )  )  ;", "TypeSignature   keyType    =    HiveType . getTypeSignature ( mapTypeInfo . getMapKeyTypeInfo (  )  )  ;", "TypeSignature   valueType    =    HiveType . getTypeSignature ( mapTypeInfo . getMapValueTypeInfo (  )  )  ;", "return   new   TypeSignature ( StandardTypes . MAP ,    ImmutableList . of ( TypeSignatureParameter . of ( keyType )  ,    TypeSignatureParameter . of ( valueType )  )  )  ;", "case   LIST    :", "ListTypeInfo   listTypeInfo    =     (  ( ListTypeInfo )     ( typeInfo )  )  ;", "TypeSignature   elementType    =    HiveType . getTypeSignature ( listTypeInfo . getListElementTypeInfo (  )  )  ;", "return   new   TypeSignature ( StandardTypes . ARRAY ,    ImmutableList . of ( TypeSignatureParameter . of ( elementType )  )  )  ;", "case   STRUCT    :", "StructTypeInfo   structTypeInfo    =     (  ( StructTypeInfo )     ( typeInfo )  )  ;", "List < TypeInfo >    structFieldTypeInfos    =    structTypeInfo . getAllStructFieldTypeInfos (  )  ;", "List < String >    structFieldNames    =    structTypeInfo . getAllStructFieldNames (  )  ;", "if    (  ( structFieldTypeInfos . size (  )  )     !  =     ( structFieldNames . size (  )  )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ INVALID _ METADATA ,    String . format (  \" Invalid   Hive   struct   type :     % s \"  ,    typeInfo )  )  ;", "}", "ImmutableList . Builder < TypeSignatureParameter >    typeSignatureBuilder    =    ImmutableList . builder (  )  ;", "for    ( int   i    =     0  ;    i    <     ( structFieldTypeInfos . size (  )  )  ;    i +  +  )     {", "TypeSignature   typeSignature    =    HiveType . getTypeSignature ( structFieldTypeInfos . get ( i )  )  ;", "String   rowFieldName    =    structFieldNames . get ( i )  . toLowerCase ( Locale . US )  ;", "typeSignatureBuilder . add ( TypeSignatureParameter . of ( new   spi . type . NamedTypeSignature ( rowFieldName ,    typeSignature )  )  )  ;", "}", "return   new   TypeSignature ( StandardTypes . ROW ,    typeSignatureBuilder . build (  )  )  ;", "}", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Unsupported   Hive   type :     % s \"  ,    typeInfo )  )  ;", "}", "METHOD_END"], "methodName": ["getTypeSignature"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "return   HiveType . isSupportedType ( getTypeInfo (  )  )  ;", "}", "METHOD_END"], "methodName": ["isSupportedType"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "switch    ( typeInfo . getCategory (  )  )     {", "case   PRIMITIVE    :", "return    (  . getPrimitiveType (  (  ( PrimitiveTypeInfo )     ( typeInfo )  )  )  )     !  =    null ;", "case   MAP    :", "MapTypeInfo   mapTypeInfo    =     (  ( MapTypeInfo )     ( typeInfo )  )  ;", "return    (  . isSupportedType ( mapTypeInfo . getMapKeyTypeInfo (  )  )  )     &  &     (  . isSupportedType ( mapTypeInfo . getMapValueTypeInfo (  )  )  )  ;", "case   LIST    :", "ListTypeInfo   listTypeInfo    =     (  ( ListTypeInfo )     ( typeInfo )  )  ;", "return    . isSupportedType ( listTypeInfo . getListElementTypeInfo (  )  )  ;", "case   STRUCT    :", "StructTypeInfo   structTypeInfo    =     (  ( StructTypeInfo )     ( typeInfo )  )  ;", "return   structTypeInfo . getAllStructFieldTypeInfos (  )  . stream (  )  . allMatch (  :  : isSupportedType )  ;", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isSupportedType"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( typeTranslator ,     \" typeTranslator   is   null \"  )  ;", "Objects . requireNonNull ( type ,     \" type   is   null \"  )  ;", "return   new    ( typeTranslator . translate ( type )  )  ;", "}", "METHOD_END"], "methodName": ["toHiveType"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( typeInfo ,     \" typeInfo   is   null \"  )  ;", "return   new    ( typeInfo )  ;", "}", "METHOD_END"], "methodName": ["toHiveType"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( hiveTypes ,     \" hiveTypes   is   null \"  )  ;", "return   ImmutableList . copyOf ( getTypeInfosFromTypeString ( hiveTypes )  . stream (  )  . map (  :  : to )  . collect ( Collectors . toList (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["toHiveTypes"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( hiveTypeName ,     \" hiveTypeName   is   null \"  )  ;", "return    . to ( getTypeInfoFromTypeString ( hiveTypeName )  )  ;", "}", "METHOD_END"], "methodName": ["valueOf"], "fileName": "com.facebook.presto.hive.HiveType"}, {"methodBody": ["METHOD_START", "{", "return    ( HiveTypeName . INSTANCE _ SIZE )     +     (  ( value . length (  )  )     *     ( Character . BYTES )  )  ;", "}", "METHOD_END"], "methodName": ["getEstimatedSizeInBytes"], "fileName": "com.facebook.presto.hive.HiveTypeName"}, {"methodBody": ["METHOD_START", "{", "return   HiveType . valueOf ( value )  ;", "}", "METHOD_END"], "methodName": ["toHiveType"], "fileName": "com.facebook.presto.hive.HiveTypeName"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   Long . parseLong ( value )  ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for   BIGINT   partition   key :     % s \"  ,    value ,    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["bigintPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "if    ( value . equalsIgnoreCase (  \" true \"  )  )     {", "return   true ;", "}", "if    ( value . equalsIgnoreCase (  \" false \"  )  )     {", "return   false ;", "}", "throw   new   PException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for   BOOLEAN   partition   key :     % s \"  ,    value ,    name )  )  ;", "}", "METHOD_END"], "methodName": ["booleanPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "Slice   partitionKey    =    Chars . trimTrailingSpaces ( Slices . utf 8 Slice ( value )  )  ;", "CharType   charType    =     (  ( CharType )     ( columnType )  )  ;", "if    (  ( SliceUtf 8  . countCodePoints ( partitionKey )  )     >     ( charType . getLength (  )  )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for    % s   partition   key :     % s \"  ,    value ,    columnType . toString (  )  ,    name )  )  ;", "}", "return   partitionKey ;", "}", "METHOD_END"], "methodName": ["charPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "if    (  ! condition )     {", "throw   new   spi . PrestoException ( errorCode ,    String . format ( formatString ,    args )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkCondition"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( recordCursor ,     \" recordCursor   is   null \"  )  ;", "Objects . requireNonNull ( throwable ,     \" throwable   is   null \"  )  ;", "try    {", "recordCursor . close (  )  ;", "}    catch    ( RuntimeException   e )     {", "if    ( throwable    !  =    e )     {", "throwable . addSupsed ( e )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["closeWithSuppression"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   partitionKey    ?     \" partition   key \"     :    null ;", "}", "METHOD_END"], "methodName": ["columnExtraInfo"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   clazz . getConstructor (  )  . newInstance (  )  ;", "}    catch    ( ReflectOperationException   e )     {", "throw   new   RuntimeException (  (  \" error   creating   deserializer :     \"     +     ( clazz . getName (  )  )  )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["createDeserializer"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "List < HiveColumnHandle >    readColumns    =    ImmutableList . copyOf ( filter ( columns ,     (    column )     -  >     ( column . getColumnType (  )  )     =  =     ( REGULAR )  )  )  ;", "List < Integer >    readHiveColumnIndexes    =    ImmutableList . copyOf ( transform ( readColumns ,    HiveColumnHandle :  : getHiveColumnIndex )  )  ;", "HiveUtil . setReadColumns ( configuration ,    readHiveColumnIndexes )  ;", "InputFormat <  ?  ,     ?  >    inputFormat    =    HiveUtil . getInputFormat ( configuration ,    schema ,    true )  ;", "JobConf   jobConf    =    ConfigurationUtils . toJobConf ( configuration )  ;", "FileSplit   fileSplit    =    new   FileSplit ( path ,    start ,    length ,     (  ( String [  ]  )     ( null )  )  )  ;", "schema . stringPropertyNames (  )  . stream (  )  . filter (  (    name )     -  >    name . startsWith (  \" serialization .  \"  )  )  . forEach (  (    name )     -  >    jobConf . set ( name ,    schema . getProperty ( name )  )  )  ;", "List < String >    codecs    =    newArrayList ( Splitter . on (  \"  ,  \"  )  . trimResults (  )  . omitEmptyStrings (  )  . split ( jobConf . get (  \" io . compression . codecs \"  ,     \"  \"  )  )  )  ;", "if    (  !  ( codecs . contains ( LzoCodec . class . getName (  )  )  )  )     {", "codecs . add (  0  ,    LzoCodec . class . getName (  )  )  ;", "}", "if    (  !  ( codecs . contains ( LzopCodec . class . getName (  )  )  )  )     {", "codecs . add (  0  ,    LzopCodec . class . getName (  )  )  ;", "}", "jobConf . set (  \" io . compression . codecs \"  ,    codecs . stream (  )  . collect ( Collectors . joining (  \"  ,  \"  )  )  )  ;", "try    {", "RecordReader < WritableComparable ,    Writable >    recordReader    =     (  ( RecordReader < WritableComparable ,    Writable >  )     ( inputFormat . getRecordReader ( fileSplit ,    jobConf ,    NULL )  )  )  ;", "int   headerCount    =    HiveUtil . getHeaderCount ( schema )  ;", "if    ( headerCount    >     0  )     {", "Utilities . skipHeader ( recordReader ,    headerCount ,    recordReader . createKey (  )  ,    recordReader . createValue (  )  )  ;", "}", "return   recordReader ;", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ CANNOT _ OPEN _ SPLIT ,    String . format (  \" Error   opening   Hive   split    % s    ( offset =  % s ,    length =  % s )    using    % s :     % s \"  ,    path ,    start ,    length ,    HiveUtil . getInputFormatName ( schema )  ,    firstNonNull ( e . getMessage (  )  ,    e . getClass (  )  . getName (  )  )  )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["createRecordReader"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "return    . parseHiveDate ( value )  ;", "}    catch    ( IllegalArgumentException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for   DATE   partition   key :     % s \"  ,    value ,    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["datePartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "if    ( value . endsWith ( HiveUtil . BIG _ DECIMAL _ POSTFIX )  )     {", "value    =    value . substring (  0  ,     (  ( value . length (  )  )     -     ( HiveUtil . BIG _ DECIMAL _ POSTFIX . length (  )  )  )  )  ;", "}", "BigDecimal   decimal    =    new   BigDecimal ( value )  ;", "decimal    =    decimal . setScale ( type . getScale (  )  ,    BigDecimal . ROUND _ UNNECESSARY )  ;", "if    (  ( decimal . precision (  )  )     >     ( type . getPrecision (  )  )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for    % s   partition   key :     % s \"  ,    value ,    type . toString (  )  ,    name )  )  ;", "}", "return   decimal ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for    % s   partition   key :     % s \"  ,    value ,    type . toString (  )  ,    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["decimalPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "HiveUtil . checkCondition ( data . startsWith ( HiveUtil . VIEW _ PREFIX )  ,    HiveErrorCode . HIVE _ INVALID _ VIEW _ DATA ,     \" View   data   missing   prefix :     % s \"  ,    data )  ;", "HiveUtil . checkCondition ( data . endsWith ( HiveUtil . VIEW _ SUFFIX )  ,    HiveErrorCode . HIVE _ INVALID _ VIEW _ DATA ,     \" View   data   missing   suffix :     % s \"  ,    data )  ;", "data    =    data . substring ( HiveUtil . VIEW _ PREFIX . length (  )  )  ;", "data    =    data . substring (  0  ,     (  ( data . length (  )  )     -     ( HiveUtil . VIEW _ SUFFIX . length (  )  )  )  )  ;", "return   new   String ( Base 6  4  . getDecoder (  )  . decode ( data )  ,    StandardCharsets . UTF _  8  )  ;", "}", "METHOD_END"], "methodName": ["decodeViewData"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   Double . parseDouble ( value )  ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for   DOUBLE   partition   key :     % s \"  ,    value ,    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["doublePartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HiveUtil . VIEW _ PREFIX )     +     ( Base 6  4  . getEncoder (  )  . encodeToString ( data . getBytes ( StandardCharsets . UTF _  8  )  )  )  )     +     ( HiveUtil . VIEW _ SUFFIX )  ;", "}", "METHOD_END"], "methodName": ["encodeViewData"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return    (  ( StructTypeInfo )     ( hiveType . getTypeInfo (  )  )  )  . getAllStructFieldTypeInfos (  )  . stream (  )  . map (  (    typeInfo )     -  >    HiveType . valueOf ( typeInfo . getTypeName (  )  )  )  . collect ( toImmutableList (  )  )  ;", "}", "METHOD_END"], "methodName": ["extractStructFieldTypes"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   Float . floatToRawIntBits ( Float . parseFloat ( value )  )  ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for   FLOAT   partition   key :     % s \"  ,    value ,    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["floatPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   HiveUtil . getDecimalType ( hiveType . getHiveTypeName (  )  . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["getDecimalType"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "Matcher   matcher    =    HiveUtil . SUPPORTED _ DECIMAL _ TYPE . matcher ( hiveTypeName )  ;", "if    ( matcher . matches (  )  )     {", "int   precision    =    Integer . parseInt ( matcher . group ( HiveUtil . DECIMAL _ PRECISION _ GROUP )  )  ;", "int   scale    =    Integer . parseInt ( matcher . group ( HiveUtil . DECIMAL _ SCALE _ GROUP )  )  ;", "return   Optional . of ( DecimalType . createDecimalType ( precision ,    scale )  )  ;", "} else    {", "return   Optional . empty (  )  ;", "}", "}", "METHOD_END"], "methodName": ["getDecimalType"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "String   name    =    HiveUtil . getDeserializerClassName ( schema )  ;", "Deserializer   deserializer    =    HiveUtil . createDeserializer ( HiveUtil . getDeserializerClass ( name )  )  ;", "HiveUtil . initializeDeserializer ( deserializer ,    schema )  ;", "return   deserializer ;", "}", "METHOD_END"], "methodName": ["getDeserializer"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "if    (  \" parquet . hive . serde . ParquetHiveSerDe \"  . equals ( name )  )     {", "return   ParquetHiveSerDe . class ;", "}", "try    {", "return   Class . forName ( name ,    true ,    JavaUtils . getClassLoader (  )  )  . asSubclass ( Deserializer . class )  ;", "}    catch    ( ClassNotFoundException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ SERDE _ NOT _ FOUND ,     (  \" deserializer   does   not   exist :     \"     +    name )  )  ;", "}    catch    ( ClassCastException   e )     {", "throw   new   RuntimeException (  (  \" invalid   deserializer   class :     \"     +    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getDeserializerClass"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "String   name    =    schema . getProperty ( serdeConstants . SERIALIZATION _ LIB )  ;", ". checkCondition (  ( name    !  =    null )  ,    HiveErrorCode . HIVE _ INVALID _ METADATA ,     \" Table   or   partition   is   missing   Hive   deserializer   property :     % s \"  ,    serdeConstants . SERIALIZATION _ LIB )  ;", "return   name ;", "}", "METHOD_END"], "methodName": ["getDeserializerClassName"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "String   headerCount    =    schema . getProperty (  \" skip . header . line . count \"  ,     \"  0  \"  )  ;", "try    {", "return   Integer . parseInt ( headerCount )  ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ INVALID _ METADATA ,     (  \" Invalid   value   for   skip . header . line . count   property :     \"     +    headerCount )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getHeaderCount"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "String   inputFormatName    =    HiveUtil . getInputFormatName ( schema )  ;", "try    {", "JobConf   jobConf    =    ConfigurationUtils . toJobConf ( configuration )  ;", "Class <  ?    extends   InputFormat <  ?  ,     ?  >  >    inputFormatClass    =    HiveUtil . getInputFormatClass ( jobConf ,    inputFormatName )  ;", "if    ( symlinkTarget    &  &     ( inputFormatClass    =  =     ( SymlinkTextInputFormat . class )  )  )     {", "inputFormatClass    =    TextInputFormat . class ;", "}", "return   ReflectionUtils . newInstance ( inputFormatClass ,    jobConf )  ;", "}    catch    ( ClassNotFoundException    |    RuntimeException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ UNSUPPORTED _ FORMAT ,     (  \" Unable   to   create   input   format    \"     +    inputFormatName )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["getInputFormat"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "if    (  (  \" parquet . hive . DeprecatedParquetInputFormat \"  . equals ( inputFormatName )  )     |  |     (  \" parquet . hive . MapredParquetInputFormat \"  . equals ( inputFormatName )  )  )     {", "return   MapredParquetInputFormat . class ;", "}", "Class <  ?  >    clazz    =    conf . getClassByName ( inputFormatName )  ;", "return    (  ( Class <  ?    extends   InputFormat <  ?  ,     ?  >  >  )     ( clazz . asSubclass ( InputFormat . class )  )  )  ;", "}", "METHOD_END"], "methodName": ["getInputFormatClass"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HiveColumnHandle >    columns    =    ImmutableList . builder (  )  ;", "List < Column >    partitionKeys    =    table . getPartitionColumns (  )  ;", "for    ( Column   field    :    partitionKeys )     {", "HiveType   hiveType    =    field . getType (  )  ;", "if    (  !  ( hiveType . isSupportedType (  )  )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Unsupported   Hive   type    % s   found   in   partition   keys   of   table    % s .  % s \"  ,    hiveType ,    table . getDatabaseName (  )  ,    table . getTableName (  )  )  )  ;", "}", "columns . add ( new   HiveColumnHandle ( field . getName (  )  ,    hiveType ,    hiveType . getTypeSignature (  )  ,     (  -  1  )  ,    HiveColumnHandle . ColumnType . PARTITION _ KEY ,    field . getComment (  )  )  )  ;", "}", "return   columns . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionKeyColumnHandles"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "if    ( partitionKey    !  =    null )     {", "return   partitionKey . getValue (  )  ;", "}", "if    ( HiveColumnHandle . isPathColumnHandle ( columnHandle )  )     {", "return   path . toString (  )  ;", "}", "if    ( HiveColumnHandle . isBucketColumnHandle ( columnHandle )  )     {", "return   String . valueOf ( bucketNumber . getAsInt (  )  )  ;", "}", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,     (  \" unsupported   hidden   column :     \"     +    columnHandle )  )  ;", "}", "METHOD_END"], "methodName": ["getPrefilledColumnValue"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HiveColumnHandle >    columns    =    ImmutableList . builder (  )  ;", "int   hiveColumnIndex    =     0  ;", "for    ( Column   field    :    table . getDataColumns (  )  )     {", "HiveType   hiveType    =    field . getType (  )  ;", "if    ( hiveType . isSupportedType (  )  )     {", "columns . add ( new   HiveColumnHandle ( field . getName (  )  ,    hiveType ,    hiveType . getTypeSignature (  )  ,    hiveColumnIndex ,    HiveColumnHandle . ColumnType . REGULAR ,    field . getComment (  )  )  )  ;", "}", "hiveColumnIndex +  +  ;", "}", "return   columns . build (  )  ;", "}", "METHOD_END"], "methodName": ["getRegularColumnHandles"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   HiveUtil . getTableObjectInspector ( HiveUtil . getDeserializer ( schema )  )  ;", "}", "METHOD_END"], "methodName": ["getTableObjectInspector"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "ObjectInspector   inspector    =    derializer . getObjectInspector (  )  ;", "checkArgument (  (  ( inspector . getCategory (  )  )     =  =     ( ObjectInspector . Category . STRUCT )  )  ,     \" expected   STRUCT :     % s \"  ,    inspector . getCategory (  )  )  ;", "return    (  ( StructObjectInspector )     ( inspector )  )  ;", "}    catch    ( SerDeException   e )     {", "throw   new   RuntimeException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["getTableObjectInspector"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   HiveUtil . getTableObjectInspector ( MetastoreUtil . getHiveSchema ( table )  )  . getAllStructFieldRefs (  )  ;", "}", "METHOD_END"], "methodName": ["getTableStructFields"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HiveColumnHandle >    columns    =    ImmutableList . builder (  )  ;", "columns . addAll (  . getRegularColumnHandles ( table )  )  ;", "columns . addAll (  . getPartitionKeyColumnHandles ( table )  )  ;", "columns . add ( HiveColumnHandle . pathColumnHandle (  )  )  ;", "if    ( table . getStorage (  )  . getBucketProperty (  )  . isPresent (  )  )     {", "columns . add ( HiveColumnHandle . bucketColumnHandle (  )  )  ;", "}", "return   columns . build (  )  ;", "}", "METHOD_END"], "methodName": ["hiveColumnHandles"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "deserializer . initialize ( new   Configuration ( lse )  ,    schema )  ;", "}    catch    ( SerDeException   e )     {", "throw   new   RuntimeException (  (  \" error   initializing   deserializer :     \"     +     ( deserializer . getClass (  )  . getName (  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["initializeDeserializer"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   Integer . parseInt ( value )  ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for   INTEGER   partition   key :     % s \"  ,    value ,    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["integerPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   type . getTypeSignature (  )  . getBase (  )  . equals ( ARRAY )  ;", "}", "METHOD_END"], "methodName": ["isArrayType"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   HiveUtil . getDeserializerClassName ( schema )  . equals ( deserializerClass . getName (  )  )  ;", "}", "METHOD_END"], "methodName": ["isDeserializerClass"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return    (  (  ( bytes . length )     =  =     2  )     &  &     (  ( bytes [  0  ]  )     =  =     '  \\  \\  '  )  )     &  &     (  ( bytes [  1  ]  )     =  =     ' N '  )  ;", "}", "METHOD_END"], "methodName": ["isHiveNull"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   type . getTypeSignature (  )  . getBase (  )  . equals ( MAP )  ;", "}", "METHOD_END"], "methodName": ["isMapType"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return    \" true \"  . equals ( table . getParameters (  )  . get ( HiveUtil . PRESTO _ VIEW _ FLAG )  )  ;", "}", "METHOD_END"], "methodName": ["isPrestoView"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   type . getTypeSignature (  )  . getBase (  )  . equals ( ROW )  ;", "}", "METHOD_END"], "methodName": ["isRowType"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "if    ( inputFormat . getClass (  )  . getSimpleName (  )  . equals (  \" OrcInputFormat \"  )  )     {", "return   true ;", "}", "Method   method    =    null ;", "for    ( Class <  ?  >    clazz    =    inputFormat . getClass (  )  ;    clazz    !  =    null ;    clazz    =    clazz . getSuperclass (  )  )     {", "try    {", "method    =    clazz . getDeclaredMethod (  \" isSplitable \"  ,    FileSystem . class ,    Path . class )  ;", "break ;", "}    catch    ( NoSuchMethodException   ignored )     {", "}", "}", "if    ( method    =  =    null )     {", "return   false ;", "}", "try    {", "method . setAccessible ( true )  ;", "return    (  ( lean )     ( method . invoke ( inputFormat ,    fileSystem ,    path )  )  )  ;", "}    catch    ( InvocationTargetException    |    IllegalAccessException   e )     {", "throw   new   RuntimeException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["isSplittable"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return    (  (  ( hiveType . getCategory (  )  )     =  =     ( ObjectInspector . Category . LIST )  )     |  |     (  ( hiveType . getCategory (  )  )     =  =     ( ObjectInspector . Category . MAP )  )  )     |  |     (  ( hiveType . getCategory (  )  )     =  =     ( ObjectInspector . Category . STRUCT )  )  ;", "}", "METHOD_END"], "methodName": ["isStructuralType"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "String   baseName    =    type . getTypeSignature (  )  . getBase (  )  ;", "return    (  ( baseName . equals ( MAP )  )     |  |     ( baseName . equals ( ARRAY )  )  )     |  |     ( baseName . equals ( ROW )  )  ;", "}", "METHOD_END"], "methodName": ["isStructuralType"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   Decimals . encodeUnscaledValue ( HiveUtil . decimalPartitionKey ( value ,    type ,    name )  . unscaledValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["longDecimalPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "long   millis    =    HiveUtil . HIVE _ DATE _ PARSER . parseMillis ( value )  ;", "return   TimeUnit . MILLISECONDS . toDays ( millis )  ;", "}", "METHOD_END"], "methodName": ["parseHiveDate"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   HiveUtil . HIVE _ TIMESTAMP _ PARSER . withZone ( timeZone )  . parseMillis ( value )  ;", "}", "METHOD_END"], "methodName": ["parseHiveTimestamp"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HiveTableHandle )     ( tableHandle )  )  . getSchemaTableName (  )  ;", "}", "METHOD_END"], "methodName": ["schemaTableName"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "configuration . set ( ColumnProjectionUtils . READ _ COLUMN _ IDS _ CONF _ STR ,    Joiner . on (  '  ,  '  )  . join ( readHiveColumnIndexes )  )  ;", "configuration . setBoolean ( ColumnProjectionUtils . READ _ ALL _ COLUMNS ,    false )  ;", "}", "METHOD_END"], "methodName": ["setReadColumns"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   HiveUtil . decimalPartitionKey ( value ,    type ,    name )  . unscaledValue (  )  . longValue (  )  ;", "}", "METHOD_END"], "methodName": ["shortDecimalPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   Short . parseShort ( value )  ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for   SMALLINT   partition   key :     % s \"  ,    value ,    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["smallintPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "return    . parseHiveTimestamp ( value ,    zone )  ;", "}    catch    ( IllegalArgumentException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for   TIMESTAMP   partition   key :     % s \"  ,    value ,    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["timestampPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   Byte . parseByte ( value )  ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for   TINYINT   partition   key :     % s \"  ,    value ,    name )  )  ;", "}", "}", "METHOD_END"], "methodName": ["tinyintPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < String >    resultBuilder    =    ImmutableList . builder (  )  ;", "int   start    =     0  ;", "while    ( true )     {", "while    (  ( start    <     ( partitionName . length (  )  )  )     &  &     (  ( partitionName . charAt ( start )  )     !  =     '  =  '  )  )     {", "start +  +  ;", "}", "start +  +  ;", "int   end    =    start ;", "while    (  ( end    <     ( partitionName . length (  )  )  )     &  &     (  ( partitionName . charAt ( end )  )     !  =     '  /  '  )  )     {", "end +  +  ;", "}", "if    ( start    >     ( partitionName . length (  )  )  )     {", "break ;", "}", "resultBuilder . add ( unescapePathName ( partitionName . substring ( start ,    end )  )  )  ;", "start    =    end    +     1  ;", "}", "return   resultBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["toPartitionValues"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "Slice   partitionKey    =    Slices . utf 8 Slice ( value )  ;", "VarcharType   varcharType    =     (  ( VarcharType )     ( columnType )  )  ;", "if    (  ( SliceUtf 8  . countCodePoints ( partitionKey )  )     >     ( varcharType . getLength (  )  )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,    String . format (  \" Invalid   partition   value    '  % s '    for    % s   partition   key :     % s \"  ,    value ,    columnType . toString (  )  ,    name )  )  ;", "}", "return   partitionKey ;", "}", "METHOD_END"], "methodName": ["varcharPartitionKey"], "fileName": "com.facebook.presto.hive.HiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.HiveViewNotSupportedException"}, {"methodBody": ["METHOD_START", "{", "return   bucketProperty ;", "}", "METHOD_END"], "methodName": ["getBucketProperty"], "fileName": "com.facebook.presto.hive.HiveWritableTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   filePrefix ;", "}", "METHOD_END"], "methodName": ["getFilePrefix"], "fileName": "com.facebook.presto.hive.HiveWritableTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   inputColumns ;", "}", "METHOD_END"], "methodName": ["getInputColumns"], "fileName": "com.facebook.presto.hive.HiveWritableTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   locationHandle ;", "}", "METHOD_END"], "methodName": ["getLocationHandle"], "fileName": "com.facebook.presto.hive.HiveWritableTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   pageSinkMetadata ;", "}", "METHOD_END"], "methodName": ["getPageSinkMetadata"], "fileName": "com.facebook.presto.hive.HiveWritableTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   partitionStorageFormat ;", "}", "METHOD_END"], "methodName": ["getPartitionStorageFormat"], "fileName": "com.facebook.presto.hive.HiveWritableTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   schemaName ;", "}", "METHOD_END"], "methodName": ["getSchemaName"], "fileName": "com.facebook.presto.hive.HiveWritableTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.HiveWritableTableHandle"}, {"methodBody": ["METHOD_START", "{", "return   tableStorageFormat ;", "}", "METHOD_END"], "methodName": ["getTableStorageFormat"], "fileName": "com.facebook.presto.hive.HiveWritableTableHandle"}, {"methodBody": ["METHOD_START", "{", "HiveWriteUtils . checkWritable ( new   SchemaTableName ( partition . getDatabaseName (  )  ,    partition . getTableName (  )  )  ,    Optional . of ( partitionName )  ,    MetastoreUtil . getProtectMode ( partition )  ,    partition . getParameters (  )  ,    partition . getStorage (  )  )  ;", "}", "METHOD_END"], "methodName": ["checkPartitionIsWritable"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "String   tablePartitionDescription    =     (  \" Table    '  \"     +    tableName )     +     \"  '  \"  ;", "if    ( partitionName . isPresent (  )  )     {", "tablePartitionDescription    +  =     (  \"    partition    '  \"     +     ( partitionName . get (  )  )  )     +     \"  '  \"  ;", "}", "MetastoreUtil . verifyOnline ( tableName ,    partitionName ,    protectMode ,    parameters )  ;", "if    ( protectMode . readOnly )     {", "throw   new   HiveReadOnlyException ( tableName ,    partitionName )  ;", "}", "if    ( storage . isSorted (  )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Inserting   into   bucketed   sorted   tables   is   not   supported .     % s \"  ,    tablePartitionDescription )  )  ;", "}", "if    ( storage . isSkewed (  )  )     {", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" Inserting   into   bucketed   tables   with   skew   is   not   supported .     % s \"  ,    tablePartitionDescription )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkWritable"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "if    (  !  ( hdfsEnvironment . getFileSystem ( context ,    path )  . mkdirs ( path ,    HiveWriteUtils . ALL _ PERMISSIONS )  )  )     {", "throw   new   IOException (  \" mkdirs   returned   false \"  )  ;", "}", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,     (  \" Failed   to   create   directory :     \"     +    path )  ,    e )  ;", "}", "try    {", "hdfsEnvironment . getFileSystem ( context ,    path )  . setPermission ( path ,    HiveWriteUtils . ALL _ PERMISSIONS )  ;", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,     (  \" Failed   to   set   permission   on   directory :     \"     +    path )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["createDirectory"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( type . equals ( BOOLEAN )  )     {", "return   new    . BooleanFieldSetter ( rowInspector ,    row ,    field )  ;", "}", "if    ( type . equals ( BIGINT )  )     {", "return   new    . BigintFieldBuilder ( rowInspector ,    row ,    field )  ;", "}", "if    ( type . equals ( INTEGER )  )     {", "return   new    . IntFieldSetter ( rowInspector ,    row ,    field )  ;", "}", "if    ( type . equals ( SMALLINT )  )     {", "return   new    . SmallintFieldSetter ( rowInspector ,    row ,    field )  ;", "}", "if    ( type . equals ( TINYINT )  )     {", "return   new    . TinyintFieldSetter ( rowInspector ,    row ,    field )  ;", "}", "if    ( type . equals ( REAL )  )     {", "return   new    . FloatFieldSetter ( rowInspector ,    row ,    field )  ;", "}", "if    ( type . equals ( DOUBLE )  )     {", "return   new    . DoubleFieldSetter ( rowInspector ,    row ,    field )  ;", "}", "if    ( type   instanceof   VarcharType )     {", "return   new    . VarcharFieldSetter ( rowInspector ,    row ,    field ,    type )  ;", "}", "if    ( type   instanceof   CharType )     {", "return   new    . CharFieldSetter ( rowInspector ,    row ,    field ,    type )  ;", "}", "if    ( type . equals ( VARBINARY )  )     {", "return   new    . BinaryFieldSetter ( rowInspector ,    row ,    field )  ;", "}", "if    ( type . equals ( DATE )  )     {", "return   new    . DateFieldSetter ( rowInspector ,    row ,    field )  ;", "}", "if    ( type . equals ( TIMESTAMP )  )     {", "return   new    . TimestampFieldSetter ( rowInspector ,    row ,    field )  ;", "}", "if    ( type   instanceof   DecimalType )     {", "DecimalType   decimalType    =     (  ( DecimalType )     ( type )  )  ;", "return   new    . DecimalFieldSetter ( rowInspector ,    row ,    field ,    decimalType )  ;", "}", "if    ( HiveUtil . isArrayType ( type )  )     {", "return   new    . ArrayFieldSetter ( rowInspector ,    row ,    field ,    type . getTypeParameters (  )  . get (  0  )  )  ;", "}", "if    ( HiveUtil . isMapType ( type )  )     {", "return   new    . MapFieldSetter ( rowInspector ,    row ,    field ,    type . getTypeParameters (  )  . get (  0  )  ,    type . getTypeParameters (  )  . get (  1  )  )  ;", "}", "if    ( HiveUtil . isRowType ( type )  )     {", "return   new    . RowFieldSetter ( rowInspector ,    row ,    field ,    type . getTypeParameters (  )  )  ;", "}", "throw   new   IllegalArgumentException (  (  \" unsupported   type :     \"     +    type )  )  ;", "}", "METHOD_END"], "methodName": ["createFieldSetter"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "boolean   compress    =    HiveConf . getBoolVar ( conf ,    COMPRESSRESULT )  ;", "if    ( outputFormatName . equals ( RCFileOutputFormat . class . getName (  )  )  )     {", "return    . createRcFileWriter ( target ,    conf ,    properties ,    compress )  ;", "}", "Object   writer    =    Class . forName ( outputFormatName )  . getConstructor (  )  . newInstance (  )  ;", "return    (  ( HiveOutputFormat <  ?  ,     ?  >  )     ( writer )  )  . getHiveRecordWriter ( conf ,    target ,    Text . class ,    compress ,    properties ,    NULL )  ;", "}    catch    ( IOException    |    ReflectiveOperationException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ WRITER _ DATA _ ERROR ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["createRecordWriter"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "String   temporaryPrefix    =     \"  / tmp / presto -  \"     +     ( context . getIdentity (  )  . getUser (  )  )  ;", "if    (  . isViewFileSystem ( context ,    hdfsEnvironment ,    targetPath )  )     {", "temporaryPrefix    =     \"  . hive - staging \"  ;", "}", "Path   temporaryRoot    =    new   Path ( targetPath ,    temporaryPrefix )  ;", "Path   temporaryPath    =    new   Path ( temporaryRoot ,    UUID . randomUUID (  )  . toString (  )  )  ;", ". createDirectory ( context ,    hdfsEnvironment ,    temporaryPath )  ;", "return   temporaryPath ;", "}", "METHOD_END"], "methodName": ["createTemporaryPath"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "return   metastore . getDatabase ( database )  . orElseThrow (  (  )     -  >    new   SchemaNotFoundException ( database )  )  ;", "}", "METHOD_END"], "methodName": ["getDatabase"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( block . isNull ( position )  )     {", "return   null ;", "}", "if    ( BOOLEAN . equals ( type )  )     {", "return   type . getBoolean ( block ,    position )  ;", "}", "if    ( BIGINT . equals ( type )  )     {", "return   type . getLong ( block ,    position )  ;", "}", "if    ( INTEGER . equals ( type )  )     {", "return    (  ( int )     ( type . getLong ( block ,    position )  )  )  ;", "}", "if    ( SMALLINT . equals ( type )  )     {", "return    (  ( short )     ( type . getLong ( block ,    position )  )  )  ;", "}", "if    ( TINYINT . equals ( type )  )     {", "return    (  ( byte )     ( type . getLong ( block ,    position )  )  )  ;", "}", "if    ( REAL . equals ( type )  )     {", "return   Float . intBitsToFloat (  (  ( int )     ( type . getLong ( block ,    position )  )  )  )  ;", "}", "if    ( DOUBLE . equals ( type )  )     {", "return   type . getDouble ( block ,    position )  ;", "}", "if    ( type   instanceof   VarcharType )     {", "return   new   Text ( type . getSlice ( block ,    position )  . getBytes (  )  )  ;", "}", "if    ( type   instanceof   CharType )     {", "CharType   charType    =     (  ( CharType )     ( type )  )  ;", "return   new   Text ( padEnd ( type . getSlice ( block ,    position )  . toStringUtf 8  (  )  ,    charType . getLength (  )  ,     '     '  )  )  ;", "}", "if    ( VARBINARY . equals ( type )  )     {", "return   type . getSlice ( block ,    position )  . getBytes (  )  ;", "}", "if    ( DATE . equals ( type )  )     {", "long   days    =    type . getLong ( block ,    position )  ;", "return   new   Date ( UTC . getMillisKeepLocal ( DateTimeZone . getDefault (  )  ,    TimeUnit . DAYS . toMillis ( days )  )  )  ;", "}", "if    ( TIMESTAMP . equals ( type )  )     {", "long   millisUtc    =    type . getLong ( block ,    position )  ;", "return   new   Timestamp ( millisUtc )  ;", "}", "if    ( type   instanceof   DecimalType )     {", "DecimalType   decimalType    =     (  ( DecimalType )     ( type )  )  ;", "return   HiveWriteUtils . getHiveDecimal ( decimalType ,    block ,    position )  ;", "}", "if    ( HiveUtil . isArrayType ( type )  )     {", "Type   elementType    =    type . getTypeParameters (  )  . get (  0  )  ;", "Block   arrayBlock    =    block . getObject ( position ,    Block . class )  ;", "List < Object >    list    =    new   ArrayList ( arrayBlock . getPositionCount (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( arrayBlock . getPositionCount (  )  )  ;    i +  +  )     {", "Object   element    =    HiveWriteUtils . getField ( elementType ,    arrayBlock ,    i )  ;", "list . add ( element )  ;", "}", "return   Collections . unmodifiableList ( list )  ;", "}", "if    ( HiveUtil . isMapType ( type )  )     {", "Type   keyType    =    type . getTypeParameters (  )  . get (  0  )  ;", "Type   valueType    =    type . getTypeParameters (  )  . get (  1  )  ;", "Block   mapBlock    =    block . getObject ( position ,    Block . class )  ;", "Map < Object ,    Object >    map    =    new   HashMap <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( mapBlock . getPositionCount (  )  )  ;    i    +  =     2  )     {", "Object   key    =    HiveWriteUtils . getField ( keyType ,    mapBlock ,    i )  ;", "Object   value    =    HiveWriteUtils . getField ( valueType ,    mapBlock ,     ( i    +     1  )  )  ;", "map . put ( key ,    value )  ;", "}", "return   Collections . unmodifiableMap ( map )  ;", "}", "if    ( HiveUtil . isRowType ( type )  )     {", "Block   rowBlock    =    block . getObject ( position ,    Block . class )  ;", "List < Type >    fieldTypes    =    type . getTypeParameters (  )  ;", "HiveUtil . checkCondition (  (  ( fieldTypes . size (  )  )     =  =     ( rowBlock . getPositionCount (  )  )  )  ,    GENERIC _ INTERNAL _ ERROR ,     \" Expected   row   value   field   count   does   not   match   type   field   count \"  )  ;", "List < Object >    row    =    new   ArrayList ( rowBlock . getPositionCount (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( rowBlock . getPositionCount (  )  )  ;    i +  +  )     {", "Object   element    =    HiveWriteUtils . getField ( fieldTypes . get ( i )  ,    rowBlock ,    i )  ;", "row . add ( element )  ;", "}", "return   Collections . unmodifiableList ( row )  ;", "}", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,     (  \" unsupported   type :     \"     +    type )  )  ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "BigInteger   unscaledValue ;", "if    ( decimalType . isShort (  )  )     {", "unscaledValue    =    BigInteger . valueOf ( decimalType . getLong ( block ,    position )  )  ;", "} else    {", "unscaledValue    =    Decimals . decodeUnscaledValue ( decimalType . getSlice ( block ,    position )  )  ;", "}", "return   Decimal . create ( unscaledValue ,    decimalType . getScale (  )  )  ;", "}", "METHOD_END"], "methodName": ["getHiveDecimal"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( type . equals ( BOOLEAN )  )     {", "return   PrimitiveObjectInspectorFactory . javaBooleanObjectInspector ;", "} else", "if    ( type . equals ( BigintType . BIGINT )  )     {", "return   PrimitiveObjectInspectorFactory . javaLongObjectInspector ;", "} else", "if    ( type . equals ( IntegerType . INTEGER )  )     {", "return   PrimitiveObjectInspectorFactory . javaIntObjectInspector ;", "} else", "if    ( type . equals ( SmallintType . SMALLINT )  )     {", "return   PrimitiveObjectInspectorFactory . javaShortObjectInspector ;", "} else", "if    ( type . equals ( TinyintType . TINYINT )  )     {", "return   PrimitiveObjectInspectorFactory . javaByteObjectInspector ;", "} else", "if    ( type . equals ( RealType . REAL )  )     {", "return   PrimitiveObjectInspectorFactory . javaFloatObjectInspector ;", "} else", "if    ( type . equals ( DoubleType . DOUBLE )  )     {", "return   PrimitiveObjectInspectorFactory . javaDoubleObjectInspector ;", "} else", "if    ( type   instanceof   spi . type . VarcharType )     {", "return   PrimitiveObjectInspectorFactory . writableStringObjectInspector ;", "} else", "if    ( type   instanceof   spi . type . CharType )     {", "return   PrimitiveObjectInspectorFactory . writableHiveCharObjectInspector ;", "} else", "if    ( type . equals ( VarbinaryType . VARBINARY )  )     {", "return   PrimitiveObjectInspectorFactory . javaByteArrayObjectInspector ;", "} else", "if    ( type . equals ( DateType . DATE )  )     {", "return   PrimitiveObjectInspectorFactory . javaDateObjectInspector ;", "} else", "if    ( type . equals ( TimestampType . TIMESTAMP )  )     {", "return   PrimitiveObjectInspectorFactory . javaTimestampObjectInspector ;", "} else", "if    ( type   instanceof   spi . type . DecimalType )     {", "spi . type . DecimalType   decimalType    =     (  ( spi . type . DecimalType )     ( type )  )  ;", "return   PrimitiveObjectInspectorFactory . getPrimitiveJavaObjectInspector ( new   DecimalTypeInfo ( decimalType . getPrecision (  )  ,    decimalType . getScale (  )  )  )  ;", "} else", "if    ( HiveUtil . isArrayType ( type )  )     {", "return   getStandardListObjectInspector ( HiveWriteUtils . getJavaObjectInspector ( type . getTypeParameters (  )  . get (  0  )  )  )  ;", "} else", "if    ( HiveUtil . isMapType ( type )  )     {", "ObjectInspector   keyObjectInspector    =    HiveWriteUtils . getJavaObjectInspector ( type . getTypeParameters (  )  . get (  0  )  )  ;", "ObjectInspector   valueObjectInspector    =    HiveWriteUtils . getJavaObjectInspector ( type . getTypeParameters (  )  . get (  1  )  )  ;", "return   getStandardMapObjectInspector ( keyObjectInspector ,    valueObjectInspector )  ;", "} else", "if    ( HiveUtil . isRowType ( type )  )     {", "return   getStandardStructObjectInspector ( type . getTypeSignature (  )  . getParameters (  )  . stream (  )  . map (  (    parameter )     -  >    parameter . getNamedTypeSignature (  )  . getName (  )  . get (  )  )  . collect ( toList (  )  )  ,    type . getTypeParameters (  )  . stream (  )  . map ( HiveWriteUtils :  : getJavaObjectInspector )  . collect ( toList (  )  )  )  ;", "}", "throw   new   IllegalArgumentException (  (  \" unsupported   type :     \"     +    type )  )  ;", "}", "METHOD_END"], "methodName": ["getJavaObjectInspector"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( fileSystem   instanceof   FilterFileSystem )     {", "return    . getRawFileSystem (  (  ( FilterFileSystem )     ( fileSystem )  )  . getRawFileSystem (  )  )  ;", "}", "return   fileSystem ;", "}", "METHOD_END"], "methodName": ["getRawFileSystem"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( type . equals ( BOOLEAN )  )     {", "return   PrimitiveObjectInspectorFactory . writableBooleanObjectInspector ;", "}", "if    ( type . equals ( BIGINT )  )     {", "return   PrimitiveObjectInspectorFactory . writableLongObjectInspector ;", "}", "if    ( type . equals ( INTEGER )  )     {", "return   PrimitiveObjectInspectorFactory . writableIntObjectInspector ;", "}", "if    ( type . equals ( SMALLINT )  )     {", "return   PrimitiveObjectInspectorFactory . writableShortObjectInspector ;", "}", "if    ( type . equals ( TINYINT )  )     {", "return   PrimitiveObjectInspectorFactory . writableByteObjectInspector ;", "}", "if    ( type . equals ( REAL )  )     {", "return   PrimitiveObjectInspectorFactory . writableFloatObjectInspector ;", "}", "if    ( type . equals ( DOUBLE )  )     {", "return   PrimitiveObjectInspectorFactory . writableDoubleObjectInspector ;", "}", "if    ( type   instanceof   VarcharType )     {", "VarcharType   varcharType    =     (  ( VarcharType )     ( type )  )  ;", "int   varcharLength    =    varcharType . getLength (  )  ;", "if    ( varcharLength    <  =     ( HiveVarchar . MAX _ VARCHAR _ LENGTH )  )     {", "return   PrimitiveObjectInspectorFactory . getPrimitiveWritableObjectInspector ( getVarcharTypeInfo ( varcharLength )  )  ;", "} else", "if    ( varcharLength    =  =     ( VarcharType . UNBOUNDED _ LENGTH )  )     {", "return   PrimitiveObjectInspectorFactory . writableStringObjectInspector ;", "}", "}", "if    ( Chars . isCharType ( type )  )     {", "CharType   charType    =     (  ( CharType )     ( type )  )  ;", "int   charLength    =    charType . getLength (  )  ;", "return   PrimitiveObjectInspectorFactory . getPrimitiveWritableObjectInspector ( getCharTypeInfo ( charLength )  )  ;", "}", "if    ( type . equals ( VARBINARY )  )     {", "return   PrimitiveObjectInspectorFactory . writableBinaryObjectInspector ;", "}", "if    ( type . equals ( DATE )  )     {", "return   PrimitiveObjectInspectorFactory . writableDateObjectInspector ;", "}", "if    ( type . equals ( TIMESTAMP )  )     {", "return   PrimitiveObjectInspectorFactory . writableTimestampObjectInspector ;", "}", "if    ( type   instanceof   DecimalType )     {", "DecimalType   decimalType    =     (  ( DecimalType )     ( type )  )  ;", "return   PrimitiveObjectInspectorFactory . getPrimitiveWritableObjectInspector ( new   DecimalTypeInfo ( decimalType . getPrecision (  )  ,    decimalType . getScale (  )  )  )  ;", "}", "if    (  (  ( HiveUtil . isArrayType ( type )  )     |  |     ( HiveUtil . isMapType ( type )  )  )     |  |     ( HiveUtil . isRowType ( type )  )  )     {", "return    . getJavaObjectInspector ( type )  ;", "}", "throw   new   IllegalArgumentException (  (  \" unsupported   type :     \"     +    type )  )  ;", "}", "METHOD_END"], "methodName": ["getRowColumnInspector"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "return   types . stream (  )  . map ( HiveWriteUtils :  : getRowColumnInspector )  . collect ( Collectors . toList (  )  )  ;", "}", "METHOD_END"], "methodName": ["getRowColumnInspectors"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "Optional < String >    location    =    HiveWriteUtils . getDatabase ( metastore ,    schemaName )  . getLocation (  )  ;", "if    (  (  !  ( location . isPresent (  )  )  )     |  |     ( location . get (  )  . isEmpty (  )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ DATABASE _ LOCATION _ ERROR ,    String . format (  \" Database    '  % s '    location   is   not   set \"  ,    schemaName )  )  ;", "}", "Path   databasePath    =    new   Path ( location . get (  )  )  ;", "if    (  !  ( HiveWriteUtils . isS 3 FileSystem ( context ,    hdfsEnvironment ,    databasePath )  )  )     {", "if    (  !  ( HiveWriteUtils . pathExists ( context ,    hdfsEnvironment ,    databasePath )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ DATABASE _ LOCATION _ ERROR ,    String . format (  \" Database    '  % s '    location   does   not   exist :     % s \"  ,    schemaName ,    databasePath )  )  ;", "}", "if    (  !  ( HiveWriteUtils . isDirectory ( context ,    hdfsEnvironment ,    databasePath )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ DATABASE _ LOCATION _ ERROR ,    String . format (  \" Database    '  % s '    location   is   not   a   directory :     % s \"  ,    schemaName ,    databasePath )  )  ;", "}", "}", "return   new   Path ( databasePath ,    tableName )  ;", "}", "METHOD_END"], "methodName": ["getTableDefaultLocation"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "Serializer   ult    =     (  ( Serializer )     ( Class . forName ( serializerName )  . getConstructor (  )  . newInstance (  )  )  )  ;", "ult . initialize ( conf ,    properties )  ;", "return   ult ;", "}    catch    ( SerDeException    |    ReflectiveOperationException   e )     {", "throw   Throwables . propagate ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["initializeSerializer"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   hdfsEnvironment . getFileSystem ( context ,    path )  . isDirectory ( path )  ;", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,     (  \" Failed   checking   path :     \"     +    path )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["isDirectory"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "return    ( HiveWriteUtils . getRawFileSystem ( hdfsEnvironment . getFileSystem ( context ,    path )  )  )    instanceof   PrestoS 3 FileSystem ;", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,     (  \" Failed   checking   path :     \"     +    path )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["isS3FileSystem"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   HiveWriteUtils . getRawFileSystem ( hdfsEnvironment . getFileSystem ( context ,    path )  )  . getClass (  )  . getName (  )  . equals (  \" ViewFileSystem \"  )  ;", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,     (  \" Failed   checking   path :     \"     +    path )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["isViewFileSystem"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "switch    ( primitiveCategory )     {", "case   BOOLEAN    :", "case   LONG    :", "case   INT    :", "case   SHORT    :", "case   BYTE    :", "case   FLOAT    :", "case   DOUBLE    :", "case   STRING    :", "case   DATE    :", "case   TIMESTAMP    :", "case   BINARY    :", "case   DECIMAL    :", "case   VARCHAR    :", "case   CHAR    :", "return   true ;", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isWritablePrimitiveType"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "return   HiveWriteUtils . isWritableType ( hiveType . getTypeInfo (  )  )  ;", "}", "METHOD_END"], "methodName": ["isWritableType"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "switch    ( typeInfo . getCategory (  )  )     {", "case   PRIMITIVE    :", "PrimitiveCategory   primitiveCategory    =     (  ( PrimitiveTypeInfo )     ( typeInfo )  )  . getPrimitiveCategory (  )  ;", "return    . isWritablePrimitiveType ( primitiveCategory )  ;", "case   MAP    :", "MapTypeInfo   mapTypeInfo    =     (  ( MapTypeInfo )     ( typeInfo )  )  ;", "return    (  . isWritableType ( mapTypeInfo . getMapKeyTypeInfo (  )  )  )     &  &     (  . isWritableType ( mapTypeInfo . getMapValueTypeInfo (  )  )  )  ;", "case   LIST    :", "ListTypeInfo   listTypeInfo    =     (  ( ListTypeInfo )     ( typeInfo )  )  ;", "return    . isWritableType ( listTypeInfo . getListElementTypeInfo (  )  )  ;", "case   STRUCT    :", "StructTypeInfo   structTypeInfo    =     (  ( StructTypeInfo )     ( typeInfo )  )  ;", "return   structTypeInfo . getAllStructFieldTypeInfos (  )  . stream (  )  . allMatch (  :  : isWritableType )  ;", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isWritableType"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   hdfsEnvironment . getFileSystem ( context ,    path )  . exists ( path )  ;", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,     (  \" Failed   checking   path :     \"     +    path )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["pathExists"], "fileName": "com.facebook.presto.hive.HiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "hiveWriterStats . addInputPageSizesInBytes ( dataPage . getRetainedSizeInBytes (  )  )  ;", "fileWriter . appendRows ( dataPage )  ;", "rowCount    +  =    dataPage . getPositionCount (  )  ;", "}", "METHOD_END"], "methodName": ["append"], "fileName": "com.facebook.presto.hive.HiveWriter"}, {"methodBody": ["METHOD_START", "{", "fileWriter . commit (  )  ;", "onCommit . accept ( this )  ;", "}", "METHOD_END"], "methodName": ["commit"], "fileName": "com.facebook.presto.hive.HiveWriter"}, {"methodBody": ["METHOD_START", "{", "return   new   PartitionUpdate ( partitionName . orElse (  \"  \"  )  ,    isNew ,    writePath ,    targetPath ,    ImmutableList . of ( fileName )  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionUpdate"], "fileName": "com.facebook.presto.hive.HiveWriter"}, {"methodBody": ["METHOD_START", "{", "return   rowCount ;", "}", "METHOD_END"], "methodName": ["getRowCount"], "fileName": "com.facebook.presto.hive.HiveWriter"}, {"methodBody": ["METHOD_START", "{", "return   fileWriter . getSystemMemoryUsage (  )  ;", "}", "METHOD_END"], "methodName": ["getSystemMemoryUsage"], "fileName": "com.facebook.presto.hive.HiveWriter"}, {"methodBody": ["METHOD_START", "{", "return   fileWriter . getVerificationTask (  )  ;", "}", "METHOD_END"], "methodName": ["getVerificationTask"], "fileName": "com.facebook.presto.hive.HiveWriter"}, {"methodBody": ["METHOD_START", "{", "return   fileWriter . getWrittenBytes (  )  ;", "}", "METHOD_END"], "methodName": ["getWrittenBytes"], "fileName": "com.facebook.presto.hive.HiveWriter"}, {"methodBody": ["METHOD_START", "{", "fileWriter . rollback (  )  ;", "}", "METHOD_END"], "methodName": ["rollback"], "fileName": "com.facebook.presto.hive.HiveWriter"}, {"methodBody": ["METHOD_START", "{", "return    ( filePrefix    +     \"  _ bucket -  \"  )     +     ( Strings . padStart ( Integer . toString ( bucket )  ,    HiveWriterFactory . BUCKET _ NUMBER _ PADDING ,     '  0  '  )  )  ;", "}", "METHOD_END"], "methodName": ["computeBucketedFileName"], "fileName": "com.facebook.presto.hive.HiveWriterFactory"}, {"methodBody": ["METHOD_START", "{", "if    (  (  !  ( HiveConf . getBoolVar ( conf ,    COMPRESSRESULT )  )  )     |  |     (  !  ( HiveIgnoreKeyTextOutputFormat . class . getName (  )  . equals ( storageFormat . getOutputFormat (  )  )  )  )  )     {", "return    \"  \"  ;", "}", "String   compressionCodecClass    =    conf . get (  \" mapred . output . compression . codec \"  )  ;", "if    ( compressionCodecClass    =  =    null )     {", "return   new   DefaultCodec (  )  . getDefaultExtension (  )  ;", "}", "try    {", "Class <  ?    extends   CompressionCodec >    codecClass    =    conf . getClassByName ( compressionCodecClass )  . asSubclass ( CompressionCodec . class )  ;", "return   ReflectionUtil . newInstance ( codecClass ,    conf )  . getDefaultExtension (  )  ;", "}    catch    ( ClassNotFoundException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ UNSUPPORTED _ FORMAT ,     (  \" Compression   codec   not   found :     \"     +    compressionCodecClass )  ,    e )  ;", "}    catch    ( RuntimeException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ UNSUPPORTED _ FORMAT ,     (  \" Failed   to   load   compression   codec :     \"     +    compressionCodecClass )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["getFileExtension"], "fileName": "com.facebook.presto.hive.HiveWriterFactory"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < String >    partitionValues    =    ImmutableList . builder (  )  ;", "for    ( int   field    =     0  ;    field    <     ( partitionColumns . getChannelCount (  )  )  ;    field +  +  )     {", "Object   value    =    HiveWriteUtils . getField ( partitionColumnTypes . get ( field )  ,    partitionColumns . getBlock ( field )  ,    position )  ;", "if    ( value    =  =    null )     {", "partitionValues . add ( HivePartitionKey . HIVE _ DEFAULT _ DYNAMIC _ PARTITION )  ;", "} else    {", "String   valueString    =    value . toString (  )  ;", "if    (  !  ( CharMatcher . inRange (  (  ( char )     (  3  2  )  )  ,     (  ( char )     (  1  2  6  )  )  )  . matchesAllOf ( valueString )  )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ,     (  \" Hive   partition   keys   can   only   contain   printable   ASCII   characters    (  0 x 2  0     -     0 x 7 E )  .    Invalid   value :     \"     +     ( base 1  6  (  )  . withSeparator (  \"     \"  ,     2  )  . encode ( valueString . getBytes ( StandardCharsets . UTF _  8  )  )  )  )  )  ;", "}", "partitionValues . add ( valueString )  ;", "}", "}", "return   partitionValues . build (  )  ;", "}", "METHOD_END"], "methodName": ["toPartitionValues"], "fileName": "com.facebook.presto.hive.HiveWriterFactory"}, {"methodBody": ["METHOD_START", "{", "inputPageSizeInBytes . add ( bytes )  ;", "}", "METHOD_END"], "methodName": ["addInputPageSizesInBytes"], "fileName": "com.facebook.presto.hive.HiveWriterStats"}, {"methodBody": ["METHOD_START", "{", "return   inputPageSizeInBytes ;", "}", "METHOD_END"], "methodName": ["getInputPageSizeInBytes"], "fileName": "com.facebook.presto.hive.HiveWriterStats"}, {"methodBody": ["METHOD_START", "{", "return   partitionNames ;", "}", "METHOD_END"], "methodName": ["getInfo"], "fileName": "com.facebook.presto.hive.HiveWrittenPartitions"}, {"methodBody": ["METHOD_START", "{", "checkState (  (  !  ( isDone (  )  )  )  ,     \" All   blocks   have   been   consumed \"  )  ;", "return   blocks . get ( currentBlockIndex )  ;", "}", "METHOD_END"], "methodName": ["currentBlock"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   bucketConversion ;", "}", "METHOD_END"], "methodName": ["getBucketConversion"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   bucketNumber ;", "}", "METHOD_END"], "methodName": ["getBucketNumber"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   columnCoercions ;", "}", "METHOD_END"], "methodName": ["getColumnCoercions"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   end ;", "}", "METHOD_END"], "methodName": ["getEnd"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "int   result    =    InternalHiveSplit . INSTANCE _ SIZE ;", "result    +  =     ( path . length (  )  )     *     ( Character . BYTES )  ;", "result    +  =    SizeOf . sizeOfObjectArray ( partitionKeys . size (  )  )  ;", "for    ( HivePartitionKey   partitionKey    :    partitionKeys )     {", "result    +  =    partitionKey . getEstimatedSizeInBytes (  )  ;", "}", "result    +  =    SizeOf . sizeOfObjectArray ( blocks . size (  )  )  ;", "for    ( InternalHiveSplit . InternalHiveBlock   block    :    blocks )     {", "result    +  =    block . getEstimatedSizeInBytes (  )  ;", "}", "result    +  =     ( partitionName . length (  )  )     *     ( Character . BYTES )  ;", "result    +  =    SizeOf . sizeOfObjectArray ( columnCoercions . size (  )  )  ;", "for    ( HiveTypeName   hiveTypeName    :    columnCoercions . values (  )  )     {", "result    +  =     ( InternalHiveSplit . INTEGER _ INSTANCE _ SIZE )     +     ( hiveTypeName . getEstimatedSizeInBytes (  )  )  ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["getEstimatedSizeInBytes"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   fileSize ;", "}", "METHOD_END"], "methodName": ["getFileSize"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   partitionKeys ;", "}", "METHOD_END"], "methodName": ["getPartitionKeys"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   partitionName ;", "}", "METHOD_END"], "methodName": ["getPartitionName"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   path ;", "}", "METHOD_END"], "methodName": ["getPath"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   schema ;", "}", "METHOD_END"], "methodName": ["getSchema"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   start ;", "}", "METHOD_END"], "methodName": ["getStart"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "start    +  =    value ;", "if    (  ( start )     =  =     ( currentBlock (  )  . getEnd (  )  )  )     {", "( currentBlockIndex )  +  +  ;", "if    ( isDone (  )  )     {", "return ;", "}", "verify (  (  ( start )     =  =     ( currentBlock (  )  . getStart (  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["increaseStart"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return    ( currentBlockIndex )     =  =     ( blocks . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["isDone"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   forceLocalScheduling ;", "}", "METHOD_END"], "methodName": ["isForceLocalScheduling"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   splittable ;", "}", "METHOD_END"], "methodName": ["isSplittable"], "fileName": "com.facebook.presto.hive.InternalHiveSplit"}, {"methodBody": ["METHOD_START", "{", "return   isExistingTable ;", "}", "METHOD_END"], "methodName": ["getJsonSerializableIsExistingTable"], "fileName": "com.facebook.presto.hive.LocationHandle"}, {"methodBody": ["METHOD_START", "{", "return   targetPath . toString (  )  ;", "}", "METHOD_END"], "methodName": ["getJsonSerializableTargetPath"], "fileName": "com.facebook.presto.hive.LocationHandle"}, {"methodBody": ["METHOD_START", "{", "return   writePath . map ( Path :  : toString )  ;", "}", "METHOD_END"], "methodName": ["getJsonSerializableWritePath"], "fileName": "com.facebook.presto.hive.LocationHandle"}, {"methodBody": ["METHOD_START", "{", "return   targetPath ;", "}", "METHOD_END"], "methodName": ["getTargetPath"], "fileName": "com.facebook.presto.hive.LocationHandle"}, {"methodBody": ["METHOD_START", "{", "return   writePath ;", "}", "METHOD_END"], "methodName": ["getWritePath"], "fileName": "com.facebook.presto.hive.LocationHandle"}, {"methodBody": ["METHOD_START", "{", "return   isExistingTable ;", "}", "METHOD_END"], "methodName": ["isExistingTable"], "fileName": "com.facebook.presto.hive.LocationHandle"}, {"methodBody": ["METHOD_START", "{", "return   listLocatedStatus ;", "}", "METHOD_END"], "methodName": ["getListLocatedStatus"], "fileName": "com.facebook.presto.hive.NamenodeStats"}, {"methodBody": ["METHOD_START", "{", "return   remoteIteratorNext ;", "}", "METHOD_END"], "methodName": ["getRemoteIteratorNext"], "fileName": "com.facebook.presto.hive.NamenodeStats"}, {"methodBody": ["METHOD_START", "{", "return   options . getDictionaryMaxMemory (  )  ;", "}", "METHOD_END"], "methodName": ["getDictionaryMaxMemory"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "return   options . getMaxCompressionBufferSize (  )  ;", "}", "METHOD_END"], "methodName": ["getMaxCompressionBufferSize"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "return   options . getRowGroupMaxRowCount (  )  ;", "}", "METHOD_END"], "methodName": ["getRowGroupMaxRowCount"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "return   options . getMaxStringStatisticsLimit (  )  ;", "}", "METHOD_END"], "methodName": ["getStringStatisticsLimit"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "return   options . getStripeMaxRowCount (  )  ;", "}", "METHOD_END"], "methodName": ["getStripeMaxRowCount"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "return   options . getStripeMaxSize (  )  ;", "}", "METHOD_END"], "methodName": ["getStripeMaxSize"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "return   options . getStripeMinRowCount (  )  ;", "}", "METHOD_END"], "methodName": ["getStripeMinRowCount"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "options    =    options . withDictionaryMaxMemory ( dictionaryMaxMemory )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setDictionaryMaxMemory"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "options    =    options . withMaxCompressionBufferSize ( maxCompressionBufferSize )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxCompressionBufferSize"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "options    =    options . withRowGroupMaxRowCount ( rowGroupMaxRowCount )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setRowGroupMaxRowCount"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "options    =    options . withMaxStringStatisticsLimit ( stringStatisticsLimit )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setStringStatisticsLimit"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "options    =    options . withStripeMaxRowCount ( stripeMaxRowCount )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setStripeMaxRowCount"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "options    =    options . withStripeMaxSize ( stripeMaxSize )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setStripeMaxSize"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "options    =    options . withStripeMinRowCount ( stripeMinRowCount )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setStripeMinRowCount"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "return   options ;", "}", "METHOD_END"], "methodName": ["toOrcWriterOptions"], "fileName": "com.facebook.presto.hive.OrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "String   compressionName    =    schema . getProperty ( COMPRESSION . getPropName (  )  )  ;", "if    ( compressionName    =  =    null )     {", "compressionName    =    configuration . get (  \" hive . exec . orc . default . compress \"  )  ;", "}", "if    ( compressionName    =  =    null )     {", "return   CompressionKind . ZLIB ;", "}", "CompressionKind   compression ;", "try    {", "compression    =    CompressionKind . valueOf ( compressionName . toUpperCase ( Locale . ENGLISH )  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ UNSUPPORTED _ FORMAT ,     (  (  (  \" Unknown    \"     +    orcEncoding )     +     \"    compression   type    \"  )     +    compressionName )  )  ;", "}", "return   compression ;", "}", "METHOD_END"], "methodName": ["getCompression"], "fileName": "com.facebook.presto.hive.OrcFileWriterFactory"}, {"methodBody": ["METHOD_START", "{", "return   stats ;", "}", "METHOD_END"], "methodName": ["getStats"], "fileName": "com.facebook.presto.hive.OrcFileWriterFactory"}, {"methodBody": ["METHOD_START", "{", "return   partitionValues ;", "}", "METHOD_END"], "methodName": ["getPartitionValues"], "fileName": "com.facebook.presto.hive.PartitionNotFoundException"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.PartitionNotFoundException"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   resultBuilder    =    new   StringBuilder (  )  . append (  \" Table    '  \"  )  . append ( tableName )  . append (  \"  '  \"  )  . append (  \"    partition    '  \"  )  . append ( partitionName )  . append (  \"  '  \"  )  . append (  \"    is   offline \"  )  ;", "if    ( forPresto )     {", "resultBuilder . append (  \"    for   Presto \"  )  ;", "}", "if    (  !  ( isNullOrEmpty ( offlineMessage )  )  )     {", "resultBuilder . append (  \"  :     \"  )  . append ( offlineMessage )  ;", "}", "return   resultBuilder . toString (  )  ;", "}", "METHOD_END"], "methodName": ["formatMessage"], "fileName": "com.facebook.presto.hive.PartitionOfflineException"}, {"methodBody": ["METHOD_START", "{", "return   partition ;", "}", "METHOD_END"], "methodName": ["getPartition"], "fileName": "com.facebook.presto.hive.PartitionOfflineException"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.PartitionOfflineException"}, {"methodBody": ["METHOD_START", "{", "return   columnStatistics ;", "}", "METHOD_END"], "methodName": ["getColumnStatistics"], "fileName": "com.facebook.presto.hive.PartitionStatistics"}, {"methodBody": ["METHOD_START", "{", "return   fileCount ;", "}", "METHOD_END"], "methodName": ["getFileCount"], "fileName": "com.facebook.presto.hive.PartitionStatistics"}, {"methodBody": ["METHOD_START", "{", "return   rawDataSize ;", "}", "METHOD_END"], "methodName": ["getRawDataSize"], "fileName": "com.facebook.presto.hive.PartitionStatistics"}, {"methodBody": ["METHOD_START", "{", "return   rowCount ;", "}", "METHOD_END"], "methodName": ["getRowCount"], "fileName": "com.facebook.presto.hive.PartitionStatistics"}, {"methodBody": ["METHOD_START", "{", "return   totalSize ;", "}", "METHOD_END"], "methodName": ["getTotalSize"], "fileName": "com.facebook.presto.hive.PartitionStatistics"}, {"methodBody": ["METHOD_START", "{", "return   columnStatsAcurate ;", "}", "METHOD_END"], "methodName": ["isColumnStatsAcurate"], "fileName": "com.facebook.presto.hive.PartitionStatistics"}, {"methodBody": ["METHOD_START", "{", "return   fileNames ;", "}", "METHOD_END"], "methodName": ["getFileNames"], "fileName": "com.facebook.presto.hive.PartitionUpdate"}, {"methodBody": ["METHOD_START", "{", "return   targetPath . toString (  )  ;", "}", "METHOD_END"], "methodName": ["getJsonSerializableTargetPath"], "fileName": "com.facebook.presto.hive.PartitionUpdate"}, {"methodBody": ["METHOD_START", "{", "return   writePath . toString (  )  ;", "}", "METHOD_END"], "methodName": ["getJsonSerializableWritePath"], "fileName": "com.facebook.presto.hive.PartitionUpdate"}, {"methodBody": ["METHOD_START", "{", "return   name ;", "}", "METHOD_END"], "methodName": ["getName"], "fileName": "com.facebook.presto.hive.PartitionUpdate"}, {"methodBody": ["METHOD_START", "{", "return   targetPath ;", "}", "METHOD_END"], "methodName": ["getTargetPath"], "fileName": "com.facebook.presto.hive.PartitionUpdate"}, {"methodBody": ["METHOD_START", "{", "return   writePath ;", "}", "METHOD_END"], "methodName": ["getWritePath"], "fileName": "com.facebook.presto.hive.PartitionUpdate"}, {"methodBody": ["METHOD_START", "{", "return   isNew ;", "}", "METHOD_END"], "methodName": ["isNew"], "fileName": "com.facebook.presto.hive.PartitionUpdate"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < PartitionUpdate >    partitionUpdates    =    ImmutableList . builder (  )  ;", "for    ( Collection < PartitionUpdate >    partitionGroup    :    Multimaps . index ( unMergedUpdates ,    PartitionUpdate :  : getName )  . asMap (  )  . values (  )  )     {", "PartitionUpdate   firstPartition    =    partitionGroup . iterator (  )  . next (  )  ;", "ImmutableList . Builder < String >    allFileNames    =    ImmutableList . builder (  )  ;", "for    ( PartitionUpdate   partition    :    partitionGroup )     {", "if    (  (  (  ( partition . isNew (  )  )     !  =     ( firstPartition . isNew (  )  )  )     |  |     (  !  ( partition . getWritePath (  )  . equals ( firstPartition . getWritePath (  )  )  )  )  )     |  |     (  !  ( partition . getTargetPath (  )  . equals ( firstPartition . getTargetPath (  )  )  )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ CONCURRENT _ MODIFICATION _ DETECTED ,    String . format (  \" Partition    % s   was   added   or   modified   during   INSERT \"  ,    firstPartition . getName (  )  )  )  ;", "}", "allFileNames . addAll ( partition . getFileNames (  )  )  ;", "}", "partitionUpdates . add ( new   PartitionUpdate ( firstPartition . getName (  )  ,    firstPartition . isNew (  )  ,    firstPartition . getWritePath (  )  ,    firstPartition . getTargetPath (  )  ,    allFileNames . build (  )  )  )  ;", "}", "return   partitionUpdates . build (  )  ;", "}", "METHOD_END"], "methodName": ["mergePartitionUpdates"], "fileName": "com.facebook.presto.hive.PartitionUpdate"}, {"methodBody": ["METHOD_START", "{", "for    ( int   field    =     0  ;    field    <     ( fieldCount )  ;    field +  +  )     {", "Block   block    =    dataPage . getBlock ( field )  ;", "if    ( block . isNull ( position )  )     {", "tableInspector . setStructFieldData ( row ,    structFields . get ( field )  ,    null )  ;", "} else    {", "setters [ field ]  . setField ( block ,    position )  ;", "}", "}", "try    {", "record . write ( serializer . serialize ( row ,    tableInspector )  )  ;", "}    catch    ( SerDeException    |    IOException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ WRITER _ DATA _ ERROR ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["appendRow"], "fileName": "com.facebook.presto.hive.RecordFileWriter"}, {"methodBody": ["METHOD_START", "{", "return   new   RetryDriver ( maxAttempts ,    minSleepTime ,    maxSleepTime ,    scaleFactor ,    maxRetryTime ,    exceptionMapper ,    exceptionWhiteList ,    retryRunnable )  ;", "}", "METHOD_END"], "methodName": ["exceptionMapper"], "fileName": "com.facebook.presto.hive.RetryDriver"}, {"methodBody": ["METHOD_START", "{", "return   new   RetryDriver ( maxAttempts ,    minSleepTime ,    maxSleepTime ,    scaleFactor ,    maxRetryTime ,    exceptionMapper ,    exceptionWhiteList ,    retryRunnable )  ;", "}", "METHOD_END"], "methodName": ["exponentialBackoff"], "fileName": "com.facebook.presto.hive.RetryDriver"}, {"methodBody": ["METHOD_START", "{", "return   new   RetryDriver ( maxAttempts ,    minSleepTime ,    maxSleepTime ,    scaleFactor ,    maxRetryTime ,    exceptionMapper ,    exceptionWhiteList ,    retryRunnable )  ;", "}", "METHOD_END"], "methodName": ["maxAttempts"], "fileName": "com.facebook.presto.hive.RetryDriver"}, {"methodBody": ["METHOD_START", "{", "return   new   RetryDriver ( maxAttempts ,    minSleepTime ,    maxSleepTime ,    scaleFactor ,    maxRetryTime ,    exceptionMapper ,    exceptionWhiteList ,    Optional . ofNullable ( retryRunnable )  )  ;", "}", "METHOD_END"], "methodName": ["onRetry"], "fileName": "com.facebook.presto.hive.RetryDriver"}, {"methodBody": ["METHOD_START", "{", "return   new   RetryDriver (  )  ;", "}", "METHOD_END"], "methodName": ["retry"], "fileName": "com.facebook.presto.hive.RetryDriver"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( callableName ,     \" callableName   is   null \"  )  ;", "Objects . requireNonNull ( callable ,     \" callable   is   null \"  )  ;", "long   startTime    =    System . nanoTime (  )  ;", "int   attempt    =     0  ;", "while    ( true )     {", "attempt +  +  ;", "if    ( attempt    >     1  )     {", "retryRunnable . ifPresent ( Runnable :  : run )  ;", "}", "try    {", "return   callable . call (  )  ;", "}    catch    ( Exception   e )     {", "e    =    exceptionMapper . apply ( e )  ;", "for    ( Class <  ?    extends   Exception >    clazz    :    exceptionWhiteList )     {", "if    ( clazz . isInstance ( e )  )     {", "throw   e ;", "}", "}", "if    (  ( attempt    >  =     ( maxAttempts )  )     |  |     (  ( Duration . nanosSince ( startTime )  . compareTo ( maxRetryTime )  )     >  =     0  )  )     {", "throw   e ;", "}", ". log . debug (  \" Failed   on   executing    % s   with   attempt    % d ,    will   retry .    Exception :     % s \"  ,    callableName ,    attempt ,    e . getMessage (  )  )  ;", "int   delayInMs    =     (  ( int )     ( Math . min (  (  ( minSleepTime . toMillis (  )  )     *     ( Math . pow ( scaleFactor ,     ( attempt    -     1  )  )  )  )  ,    maxSleepTime . toMillis (  )  )  )  )  ;", "int   jitter    =    ThreadLocalRandom . current (  )  . nextInt ( Math . max (  1  ,     (  ( int )     ( delayInMs    *     0  .  1  )  )  )  )  ;", "try    {", "TimeUnit . MILLISECONDS . sleep (  ( delayInMs    +    jitter )  )  ;", "}    catch    ( InterruptedException   ie )     {", "Thread . currentThread (  )  . interrupt (  )  ;", "throw   new   RuntimeException ( ie )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["run"], "fileName": "com.facebook.presto.hive.RetryDriver"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( classes ,     \" classes   is   null \"  )  ;", "List < Class <  ?    extends   Exception >  >    exceptions    =    ImmutableList .  < Class <  ?    extends   Exception >  > builder (  )  . addAll ( exceptionWhiteList )  . addAll ( Arrays . asList ( classes )  )  . build (  )  ;", "return   new    ( maxAttempts ,    minSleepTime ,    maxSleepTime ,    scaleFactor ,    maxRetryTime ,    exceptionMapper ,    exceptions ,    retryRunnable )  ;", "}", "METHOD_END"], "methodName": ["stopOn"], "fileName": "com.facebook.presto.hive.RetryDriver"}, {"methodBody": ["METHOD_START", "{", "return   stopOn ( NullPointerException . class ,    IllegalStateException . class ,    IllegalArgumentException . class )  ;", "}", "METHOD_END"], "methodName": ["stopOnIllegalExceptions"], "fileName": "com.facebook.presto.hive.RetryDriver"}, {"methodBody": ["METHOD_START", "{", "return   schemaName ;", "}", "METHOD_END"], "methodName": ["getSchemaName"], "fileName": "com.facebook.presto.hive.SchemaAlreadyExistsException"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.TableAlreadyExistsException"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   resultBuilder    =    new   StringBuilder (  )  . append (  \" Table    '  \"  )  . append ( tableName )  . append (  \"  '  \"  )  . append (  \"    is   offline \"  )  ;", "if    ( forPresto )     {", "resultBuilder . append (  \"    for   Presto \"  )  ;", "}", "if    (  !  ( isNullOrEmpty ( offlineMessage )  )  )     {", "resultBuilder . append (  \"  :     \"  )  . append ( offlineMessage )  ;", "}", "return   resultBuilder . toString (  )  ;", "}", "METHOD_END"], "methodName": ["formatMessage"], "fileName": "com.facebook.presto.hive.TableOfflineException"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.TableOfflineException"}, {"methodBody": ["METHOD_START", "{", "return   ImmutableMap . of (  )  ;", "}", "METHOD_END"], "methodName": ["decode"], "fileName": "com.facebook.presto.hive.TableParameterCodec"}, {"methodBody": ["METHOD_START", "{", "return   ImmutableMap . of (  )  ;", "}", "METHOD_END"], "methodName": ["encode"], "fileName": "com.facebook.presto.hive.TableParameterCodec"}, {"methodBody": ["METHOD_START", "{", "return   TestBackgroundHiveSplitLoader . backgroundHiveSplitLoader ( files ,    tupleDomain ,    Optional . empty (  )  ,    TestBackgroundHiveSplitLoader . SIMPLE _ TABLE ,    Optional . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["backgroundHiveSplitLoader"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "List < HivePartitionMetadata >    hivePartitionMetadatas    =    ImmutableList . of ( new   HivePartitionMetadata ( new   HivePartition ( new   SchemaTableName (  \" testSchema \"  ,     \" table _ name \"  )  )  ,    Optional . empty (  )  ,    ImmutableMap . of (  )  )  )  ;", "ConnectorSession   connectorSession    =    new   com . facebook . presto . testing . TestingConnectorSession ( new   HiveSessionProperties ( new   HiveClientConfig (  )  . setMaxSplitSize ( new   io . airlift . units . DataSize (  1  .  0  ,    GIGABYTE )  )  ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "return   new   BackgroundHiveSplitLoader ( table ,    hivePartitionMetadatas ,    compactEffectivePredicate ,    BackgroundHiveSplitLoader . BucketSplitInfo . createBucketSplitInfo ( bucketHandle ,    hiveBucketFilter )  ,    connectorSession ,    new    . TestingHdfsEnvironment (  )  ,    new   NamenodeStats (  )  ,    new    . TestingDirectoryLister ( files )  ,     . EXECUTOR ,     2  ,    false )  ;", "}", "METHOD_END"], "methodName": ["backgroundHiveSplitLoader"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "ConnectorSession   connectorSession    =    new   com . facebook . presto . testing . TestingConnectorSession ( new   HiveSessionProperties ( new   HiveClientConfig (  )  . setMaxSplitSize ( new   io . airlift . units . DataSize (  1  .  0  ,    GIGABYTE )  )  ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "return   new   BackgroundHiveSplitLoader (  . SIMPLE _ TABLE ,     . createPartitionMetadataWithOfflinePartitions (  )  ,    TupleDomain . all (  )  ,    BackgroundHiveSplitLoader . BucketSplitInfo . createBucketSplitInfo ( Optional . empty (  )  ,    Optional . empty (  )  )  ,    connectorSession ,    new    . TestingHdfsEnvironment (  )  ,    new   NamenodeStats (  )  ,    new    . TestingDirectoryLister (  . TEST _ FILES )  ,    directExecutor (  )  ,     2  ,    false )  ;", "}", "METHOD_END"], "methodName": ["backgroundHiveSplitLoaderOfflinePartitions"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "return    (  )     -  >    new   com . google . common . collect . AbstractIterator < HivePartitionMetadata >  (  )     {", "private   int   position    =     -  1  ;", "@ Override", "protected   HivePartitionMetadata   computeNext (  )     {", "( position )  +  +  ;", "switch    ( position )     {", "case    0     :", "return   new   HivePartitionMetadata ( new   HivePartition ( new   SchemaTableName (  \" testSchema \"  ,     \" table _ name \"  )  )  ,    Optional . empty (  )  ,    ImmutableMap . of (  )  )  ;", "case    1     :", "throw   new   RuntimeException (  \" OFFLINE \"  )  ;", "default    :", "return   endOfData (  )  ;", "}", "}", "}  ;", "}", "METHOD_END"], "methodName": ["createPartitionMetadataWithOfflinePartitions"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "return   TestBackgroundHiveSplitLoader . drainSplits ( source )  . stream (  )  . map ( HiveSplit :  : getPath )  . collect ( toImmutableList (  )  )  ;", "}", "METHOD_END"], "methodName": ["drain"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HiveSplit >    splits    =    ImmutableList . builder (  )  ;", "while    (  !  ( source . isFinished (  )  )  )     {", "source . getNextBatch ( NotPartitionedPartitionHandle . NOT _ PARTITIONED ,     1  0  0  )  . get (  )  . getSplits (  )  . stream (  )  . map ( HiveSplit . class :  : cast )  . forEach ( splits :  : add )  ;", "}", "return   splits . build (  )  ;", "}", "METHOD_END"], "methodName": ["drainSplits"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "return   HiveSplitSource . allAtOnce ( HiveTestUtils . SESSION ,    TestBackgroundHiveSplitLoader . SIMPLE _ TABLE . getDatabaseName (  )  ,    TestBackgroundHiveSplitLoader . SIMPLE _ TABLE . getTableName (  )  ,    compactEffectivePredicate ,     1  ,     1  ,    new   io . airlift . units . DataSize (  3  2  ,    MEGABYTE )  ,    backgroundHiveSplitLoader ,    TestBackgroundHiveSplitLoader . EXECUTOR ,    new   CounterStat (  )  )  ;", "}", "METHOD_END"], "methodName": ["hiveSplitSource"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "return   new   LocatedFileStatus (  0 L ,    false ,     0  ,     0 L ,     0 L ,     0 L ,    null ,    null ,    null ,    null ,    path ,    new   BlockLocation [  ]  {    new   BlockLocation (  )     }  )  ;", "}", "METHOD_END"], "methodName": ["locatedFileStatus"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "return   new   LocatedFileStatus (  0 L ,    false ,     0  ,     0 L ,     0 L ,     0 L ,    null ,    null ,    null ,    null ,    path ,    new   BlockLocation [  ]  {        }  )  ;", "}", "METHOD_END"], "methodName": ["locatedFileStatusWithNoBlocks"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "Table . Builder   tableBuilder    =    Table . builder (  )  ;", "tableBuilder . getStorageBuilder (  )  . setStorageFormat ( StorageFormat . create (  \" hive . orc . OrcSerde \"  ,     \" RCFileInputFormat \"  ,     \" RCFileInputFormat \"  )  )  . setLocation (  \" hdfs :  /  / VOL 1  :  9  0  0  0  / db _ name / table _ name \"  )  . setSkewed ( false )  . setBucketProperty ( bucketProperty )  . setSorted ( false )  ;", "return   tableBuilder . setDatabaseName (  \" test _ dbname \"  )  . setOwner (  \" testOwner \"  )  . setTableName (  \" test _ table \"  )  . setTableType ( MANAGED _ TABLE . toString (  )  )  . setDataColumns ( ImmutableList . of ( new   Column (  \" col 1  \"  ,    HiveType . HIVE _ STRING ,    Optional . empty (  )  )  )  )  . setParameters ( ImmutableMap . of (  )  )  . setPartitionColumns ( partitionColumns )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["table"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "BackgroundHiveSplitLoader   backgroundHiveSplitLoader    =    TestBackgroundHiveSplitLoader . backgroundHiveSplitLoader ( ImmutableList . of ( TestBackgroundHiveSplitLoader . locatedFileStatusWithNoBlocks ( TestBackgroundHiveSplitLoader . RETURNED _ PATH )  )  ,    TupleDomain . none (  )  )  ;", "HiveSplitSource   hiveSplitSource    =    TestBackgroundHiveSplitLoader . hiveSplitSource ( backgroundHiveSplitLoader ,    TupleDomain . none (  )  )  ;", "backgroundHiveSplitLoader . start ( hiveSplitSource )  ;", "List < HiveSplit >    splits    =    TestBackgroundHiveSplitLoader . drainSplits ( hiveSplitSource )  ;", "assertEquals ( splits . size (  )  ,     1  )  ;", "assertEquals ( splits . get (  0  )  . getPath (  )  ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH . toString (  )  )  ;", "assertEquals ( splits . get (  0  )  . getLength (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testEmptyFileWithNoBlocks"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "BackgroundHiveSplitLoader   backgroundHiveSplitLoader    =    TestBackgroundHiveSplitLoader . backgroundHiveSplitLoaderOfflinePartitions (  )  ;", "HiveSplitSource   hiveSplitSource    =    TestBackgroundHiveSplitLoader . hiveSplitSource ( backgroundHiveSplitLoader ,    TupleDomain . all (  )  )  ;", "backgroundHiveSplitLoader . start ( hiveSplitSource )  ;", "assertThrows ( RuntimeException . class ,     (  )     -  >    drain ( hiveSplitSource )  )  ;", "assertThrows ( RuntimeException . class ,     (  )     -  >    hiveSplitSource . isFinished (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoHangIfPartitionIsOffline"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "BackgroundHiveSplitLoader   backgroundHiveSplitLoader    =    TestBackgroundHiveSplitLoader . backgroundHiveSplitLoader ( TestBackgroundHiveSplitLoader . TEST _ FILES ,    TupleDomain . none (  )  )  ;", "HiveSplitSource   hiveSplitSource    =    TestBackgroundHiveSplitLoader . hiveSplitSource ( backgroundHiveSplitLoader ,    TupleDomain . none (  )  )  ;", "backgroundHiveSplitLoader . start ( hiveSplitSource )  ;", "assertEquals ( TestBackgroundHiveSplitLoader . drain ( hiveSplitSource )  . size (  )  ,     2  )  ;", "}", "METHOD_END"], "methodName": ["testNoPathFilter"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "BackgroundHiveSplitLoader   backgroundHiveSplitLoader    =    TestBackgroundHiveSplitLoader . backgroundHiveSplitLoader ( TestBackgroundHiveSplitLoader . TEST _ FILES ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH _ DOMAIN )  ;", "HiveSplitSource   hiveSplitSource    =    TestBackgroundHiveSplitLoader . hiveSplitSource ( backgroundHiveSplitLoader ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH _ DOMAIN )  ;", "backgroundHiveSplitLoader . start ( hiveSplitSource )  ;", "List < String >    paths    =    TestBackgroundHiveSplitLoader . drain ( hiveSplitSource )  ;", "assertEquals ( paths . size (  )  ,     1  )  ;", "assertEquals ( paths . get (  0  )  ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPathFilter"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "BackgroundHiveSplitLoader   backgroundHiveSplitLoader    =    TestBackgroundHiveSplitLoader . backgroundHiveSplitLoader ( TestBackgroundHiveSplitLoader . TEST _ FILES ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH _ DOMAIN ,    Optional . empty (  )  ,    TestBackgroundHiveSplitLoader . PARTITIONED _ TABLE ,    Optional . of ( new   HiveBucketHandle ( HiveUtil . getRegularColumnHandles ( TestBackgroundHiveSplitLoader . PARTITIONED _ TABLE )  ,    TestBackgroundHiveSplitLoader . BUCKET _ COUNT )  )  )  ;", "HiveSplitSource   hiveSplitSource    =    TestBackgroundHiveSplitLoader . hiveSplitSource ( backgroundHiveSplitLoader ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH _ DOMAIN )  ;", "backgroundHiveSplitLoader . start ( hiveSplitSource )  ;", "List < String >    paths    =    TestBackgroundHiveSplitLoader . drain ( hiveSplitSource )  ;", "assertEquals ( paths . size (  )  ,     1  )  ;", "assertEquals ( paths . get (  0  )  ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPathFilterBucketedPartitionedTable"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "BackgroundHiveSplitLoader   backgroundHiveSplitLoader    =    TestBackgroundHiveSplitLoader . backgroundHiveSplitLoader ( TestBackgroundHiveSplitLoader . TEST _ FILES ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH _ DOMAIN ,    Optional . of ( new   HiveBucketing . HiveBucketFilter ( ImmutableSet . of (  0  ,     1  )  )  )  ,    TestBackgroundHiveSplitLoader . PARTITIONED _ TABLE ,    Optional . of ( new   HiveBucketHandle ( TestBackgroundHiveSplitLoader . BUCKET _ COLUMN _ HANDLES ,    TestBackgroundHiveSplitLoader . BUCKET _ COUNT )  )  )  ;", "HiveSplitSource   hiveSplitSource    =    TestBackgroundHiveSplitLoader . hiveSplitSource ( backgroundHiveSplitLoader ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH _ DOMAIN )  ;", "backgroundHiveSplitLoader . start ( hiveSplitSource )  ;", "List < String >    paths    =    TestBackgroundHiveSplitLoader . drain ( hiveSplitSource )  ;", "assertEquals ( paths . size (  )  ,     1  )  ;", "assertEquals ( paths . get (  0  )  ,    TestBackgroundHiveSplitLoader . RETURNED _ PATH . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPathFilterOneBucketMatchPartitionedTable"], "fileName": "com.facebook.presto.hive.TestBackgroundHiveSplitLoader"}, {"methodBody": ["METHOD_START", "{", "return   HiveBooleanParser . parseHiveBoolean ( s . getBytes ( StandardCharsets . US _ ASCII )  ,     0  ,    s . length (  )  )  ;", "}", "METHOD_END"], "methodName": ["parseBoolean"], "fileName": "com.facebook.presto.hive.TestHiveBooleanParser"}, {"methodBody": ["METHOD_START", "{", "assertTrue ( TestHiveBooleanParser . parseBoolean (  \" true \"  )  )  ;", "assertTrue ( TestHiveBooleanParser . parseBoolean (  \" TRUE \"  )  )  ;", "assertTrue ( TestHiveBooleanParser . parseBoolean (  \" tRuE \"  )  )  ;", "assertFalse ( TestHiveBooleanParser . parseBoolean (  \" false \"  )  )  ;", "assertFalse ( TestHiveBooleanParser . parseBoolean (  \" FALSE \"  )  )  ;", "assertFalse ( TestHiveBooleanParser . parseBoolean (  \" fAlSe \"  )  )  ;", "assertNull ( TestHiveBooleanParser . parseBoolean (  \" true    \"  )  )  ;", "assertNull ( TestHiveBooleanParser . parseBoolean (  \"    true \"  )  )  ;", "assertNull ( TestHiveBooleanParser . parseBoolean (  \" false    \"  )  )  ;", "assertNull ( TestHiveBooleanParser . parseBoolean (  \"    false \"  )  )  ;", "assertNull ( TestHiveBooleanParser . parseBoolean (  \" t \"  )  )  ;", "assertNull ( TestHiveBooleanParser . parseBoolean (  \" f \"  )  )  ;", "assertNull ( TestHiveBooleanParser . parseBoolean (  \"  \"  )  )  ;", "assertNull ( TestHiveBooleanParser . parseBoolean (  \" blah \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testParse"], "fileName": "com.facebook.presto.hive.TestHiveBooleanParser"}, {"methodBody": ["METHOD_START", "{", "TypeUtils . writeNativeValue ( type ,    blockBuilder ,    TestHiveBucketing . toNativeContainerValue ( type ,    hiveValue )  )  ;", "}", "METHOD_END"], "methodName": ["appendToBlockBuilder"], "fileName": "com.facebook.presto.hive.TestHiveBucketing"}, {"methodBody": ["METHOD_START", "{", "TestHiveBucketing . assertBucketEquals ( ImmutableList . of ( hiveTypeStrings )  ,    Arrays . asList ( hiveValues )  )  ;", "}", "METHOD_END"], "methodName": ["assertBucketEquals"], "fileName": "com.facebook.presto.hive.TestHiveBucketing"}, {"methodBody": ["METHOD_START", "{", "List < HiveType >    hiveTypes    =    hiveTypeStrings . stream (  )  . map ( HiveType :  : valueOf )  . collect ( toImmutableList (  )  )  ;", "List < TypeInfo >    hiveTypeInfos    =    hiveTypes . stream (  )  . map ( HiveType :  : getTypeInfo )  . collect ( toImmutableList (  )  )  ;", "for    ( int   bucketCount    :    new   int [  ]  {     1  ,     2  ,     5  0  0  ,     9  9  7     }  )     {", "int   actual    =     . computeActual ( hiveTypeStrings ,    hiveValues ,    bucketCount ,    hiveTypes ,    hiveTypeInfos )  ;", "int   expected    =     . computeExpected ( hiveTypeStrings ,    hiveValues ,    bucketCount ,    hiveTypeInfos )  ;", "assertEquals ( actual ,    expected )  ;", "}", "}", "METHOD_END"], "methodName": ["assertBucketEquals"], "fileName": "com.facebook.presto.hive.TestHiveBucketing"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < Block >    blockListBuilder    =    ImmutableList . builder (  )  ;", "Object [  ]    nativeContainerValues    =    new   Object [ hiveValues . size (  )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( hiveTypeStrings . size (  )  )  ;    i +  +  )     {", "Object   hiveValue    =    hiveValues . get ( i )  ;", "Type   type    =    hiveTypes . get ( i )  . getType ( HiveTestUtils . TYPE _ MANAGER )  ;", "BlockBuilder   blockBuilder    =    type . createBlockBuilder ( null ,     3  )  ;", "blockBuilder . appendNull (  )  ;", "blockBuilder . appendNull (  )  ;", "TestHiveBucketing . appendToBlockBuilder ( type ,    hiveValue ,    blockBuilder )  ;", "Block   block    =    blockBuilder . build (  )  ;", "blockListBuilder . add ( block )  ;", "nativeContainerValues [ i ]     =    TestHiveBucketing . toNativeContainerValue ( type ,    hiveValue )  ;", "}", "ImmutableList < Block >    blockList    =    blockListBuilder . build (  )  ;", "int   result 1     =    HiveBucketing . getHiveBucket ( bucketCount ,    hiveTypeInfos ,    new   spi . Page ( blockList . toArray ( new   Block [ blockList . size (  )  ]  )  )  ,     2  )  ;", "int   result 2     =    HiveBucketing . getHiveBucket ( bucketCount ,    hiveTypeInfos ,    nativeContainerValues )  ;", "assertEquals ( result 1  ,    result 2  ,     \" Overloads   of   getHiveBucket   produced   different   result \"  )  ;", "return   result 1  ;", "}", "METHOD_END"], "methodName": ["computeActual"], "fileName": "com.facebook.presto.hive.TestHiveBucketing"}, {"methodBody": ["METHOD_START", "{", "Builder < Map . Entry < ObjectInspector ,    Object >  >    columnBindingsBuilder    =    ImmutableList . builder (  )  ;", "for    ( int   i    =     0  ;    i    <     ( hiveTypeStrings . size (  )  )  ;    i +  +  )     {", "Object   javaValue    =    hiveValues . get ( i )  ;", "columnBindingsBuilder . add ( Maps . immutableEntry ( TypeInfoUtils . getStandardJavaObjectInspectorFromTypeInfo ( hiveTypeInfos . get ( i )  )  ,    javaValue )  )  ;", "}", "return    . getHiveBucket ( columnBindingsBuilder . build (  )  ,    bucketCount )  ;", "}", "METHOD_END"], "methodName": ["computeExpected"], "fileName": "com.facebook.presto.hive.TestHiveBucketing"}, {"methodBody": ["METHOD_START", "{", "GenericUDFHash   udf    =    new   GenericUDFHash (  )  ;", "ObjectInspector [  ]    objectInspectors    =    new   ObjectInspector [ columnBindings . size (  )  ]  ;", "GenericUDF [  ]    deferredObjects    =    new   GenericUDF . DeferredObject [ columnBindings . size (  )  ]  ;", "int   i    =     0  ;", "for    ( Map . Entry < ObjectInspector ,    Object >    entry    :    columnBindings )     {", "objectInspectors [ i ]     =    entry . getKey (  )  ;", "if    (  (  ( entry . getValue (  )  )     !  =    null )     &  &     (  ( entry . getKey (  )  )    instanceof   JavaHiveVarcharObjectInspector )  )     {", "JavaHiveVarcharObjectInspector   varcharObjectInspector    =     (  ( JavaHiveVarcharObjectInspector )     ( entry . getKey (  )  )  )  ;", "deferredObjects [ i ]     =    new   GenericUDF . DeferredJavaObject ( new   HiveVarchar (  (  ( String )     ( entry . getValue (  )  )  )  ,    varcharObjectInspector . getMaxLength (  )  )  )  ;", "} else    {", "deferredObjects [ i ]     =    new   GenericUDF . DeferredJavaObject ( entry . getValue (  )  )  ;", "}", "i +  +  ;", "}", "ObjectInspector   udfInspector    =    udf . initialize ( objectInspectors )  ;", "IntObjectInspector   inspector    =     (  ( IntObjectInspector )     ( udfInspector )  )  ;", "Object   result    =    udf . evaluate ( deferredObjects )  ;", "HiveKeyey    =    new   HiveKey (  )  ;", "ey . setHashCode ( inspector . get ( result )  )  ;", "return   new   DefaultHivePartitioner (  )  . getBucketey ,    null ,    bucketCount )  ;", "}", "METHOD_END"], "methodName": ["getHiveBucket"], "fileName": "com.facebook.presto.hive.TestHiveBucketing"}, {"methodBody": ["METHOD_START", "{", "TestHiveBucketing . assertBucketEquals (  \" boolean \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" boolean \"  ,    true )  ;", "TestHiveBucketing . assertBucketEquals (  \" boolean \"  ,    false )  ;", "TestHiveBucketing . assertBucketEquals (  \" tinyint \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" tinyint \"  ,     (  ( byte )     (  5  )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" tinyint \"  ,    Byte . MIN _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" tinyint \"  ,    Byte . MAX _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" smallint \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" smallint \"  ,     (  ( short )     (  3  0  0  )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" smallint \"  ,    Short . MIN _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" smallint \"  ,    Short . MAX _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" int \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" int \"  ,     3  0  0  0  0  0  )  ;", "TestHiveBucketing . assertBucketEquals (  \" int \"  ,    Integer . MIN _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" int \"  ,    Integer . MAX _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" bigint \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" bigint \"  ,     3  0  0  0  0  0  0  0  0  0  0  0 L )  ;", "TestHiveBucketing . assertBucketEquals (  \" bigint \"  ,    Long . MIN _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" bigint \"  ,    Long . MAX _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" float \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" float \"  ,     1  2  .  3  4 F )  ;", "TestHiveBucketing . assertBucketEquals (  \" float \"  ,     (  -  ( Float . MAX _ VALUE )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" float \"  ,    Float . MIN _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" float \"  ,    Float . POSITIVE _ INFINITY )  ;", "TestHiveBucketing . assertBucketEquals (  \" float \"  ,    Float . NEGATIVE _ INFINITY )  ;", "TestHiveBucketing . assertBucketEquals (  \" double \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" double \"  ,     1  2  .  3  4  )  ;", "TestHiveBucketing . assertBucketEquals (  \" double \"  ,     (  -  ( Double . MAX _ VALUE )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" double \"  ,    Double . MIN _ VALUE )  ;", "TestHiveBucketing . assertBucketEquals (  \" double \"  ,    Double . POSITIVE _ INFINITY )  ;", "TestHiveBucketing . assertBucketEquals (  \" double \"  ,    Double . NEGATIVE _ INFINITY )  ;", "TestHiveBucketing . assertBucketEquals (  \" varchar (  1  5  )  \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" varchar (  1  5  )  \"  ,     \"  \"  )  ;", "TestHiveBucketing . assertBucketEquals (  \" varchar (  1  5  )  \"  ,     \" test   string \"  )  ;", "TestHiveBucketing . assertBucketEquals (  \" varchar (  1  5  )  \"  ,     \"  \\ u 5 f 3 a \\ u 5  9  2  7  \\ u 7  6  8  4 Presto \\ u 5 f 1  5  \\ u 6  4 ce \"  )  ;", "TestHiveBucketing . assertBucketEquals (  \" varchar (  1  5  )  \"  ,     \"  \\ ud 8  4  3  \\ udffc \\ ud 8  4  3  \\ udffd \\ ud 8  4  3  \\ udffe \\ ud 8  4  3  \\ udfff \"  )  ;", "TestHiveBucketing . assertBucketEquals (  \" string \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" string \"  ,     \"  \"  )  ;", "TestHiveBucketing . assertBucketEquals (  \" string \"  ,     \" test   string \"  )  ;", "TestHiveBucketing . assertBucketEquals (  \" string \"  ,     \"  \\ u 5 f 3 a \\ u 5  9  2  7  \\ u 7  6  8  4 Presto \\ u 5 f 1  5  \\ u 6  4 ce \"  )  ;", "TestHiveBucketing . assertBucketEquals (  \" string \"  ,     \"  \\ ud 8  4  3  \\ udffc \\ ud 8  4  3  \\ udffd \\ ud 8  4  3  \\ udffe \\ ud 8  4  3  \\ udfff \"  )  ;", "TestHiveBucketing . assertBucketEquals (  \" date \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" date \"  ,    new   DateWritable ( Math . toIntExact ( LocalDate . of (  1  9  7  0  ,     1  ,     1  )  . toEpochDay (  )  )  )  . get (  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" date \"  ,    new   DateWritable ( Math . toIntExact ( LocalDate . of (  2  0  1  5  ,     1  1  ,     1  9  )  . toEpochDay (  )  )  )  . get (  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" date \"  ,    new   DateWritable ( Math . toIntExact ( LocalDate . of (  1  9  5  0  ,     1  1  ,     1  9  )  . toEpochDay (  )  )  )  . get (  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" timestamp \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" timestamp \"  ,    new   Timestamp (  (  1  0  0  0     *     ( LocalDateTime . of (  1  9  7  0  ,     1  ,     1  ,     0  ,     0  ,     0  ,     0  )  . toEpochSecond ( ZoneOffset . UTC )  )  )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" timestamp \"  ,    new   Timestamp (  (  1  0  0  0     *     ( LocalDateTime . of (  1  9  6  9  ,     1  2  ,     3  1  ,     2  3  ,     5  9  ,     5  9  ,     9  9  9  0  0  0  0  0  0  )  . toEpochSecond ( ZoneOffset . UTC )  )  )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" timestamp \"  ,    new   Timestamp (  (  1  0  0  0     *     ( LocalDateTime . of (  1  9  5  0  ,     1  1  ,     1  9  ,     1  2  ,     3  4  ,     5  6  ,     7  8  9  0  0  0  0  0  0  )  . toEpochSecond ( ZoneOffset . UTC )  )  )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" timestamp \"  ,    new   Timestamp (  (  1  0  0  0     *     ( LocalDateTime . of (  2  0  1  5  ,     1  1  ,     1  9  ,     7  ,     6  ,     5  ,     4  3  2  0  0  0  0  0  0  )  . toEpochSecond ( ZoneOffset . UTC )  )  )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" array < double >  \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" array < boolean >  \"  ,    ImmutableList . of (  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" array < smallint >  \"  ,    ImmutableList . of (  (  ( short )     (  5  )  )  ,     (  ( short )     (  8  )  )  ,     (  ( short )     (  1  3  )  )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" array < string >  \"  ,    ImmutableList . of (  \" test 1  \"  ,     \" test 2  \"  ,     \" test 3  \"  ,     \" test 4  \"  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" map < float , date >  \"  ,    null )  ;", "TestHiveBucketing . assertBucketEquals (  \" map < double , timestamp >  \"  ,    ImmutableMap . of (  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" map < string , bigint >  \"  ,    ImmutableMap . of (  \" key \"  ,     1  2  3 L ,     \" key 2  \"  ,     1  2  3  4  5  6  7  8  9 L ,     \" key 3  \"  ,     (  -  1  2  3  4  5  6 L )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" array < array < bigint >  >  \"  ,    ImmutableList . of ( ImmutableList . of (  1  0 L ,     2  0 L )  ,    ImmutableList . of (  (  -  1  0 L )  ,     (  -  2  0 L )  )  ,    Arrays . asList (  (  ( Object )     ( null )  )  )  )  )  ;", "TestHiveBucketing . assertBucketEquals (  \" map < array < double >  , map < int , timestamp >  >  \"  ,    ImmutableMap . of ( ImmutableList . of (  1  2  .  3  ,     4  5  .  7  )  ,    ImmutableMap . of (  1  2  3  ,    new   Timestamp (  1  2  3  4  5  6  7  8  9  0  0  0  0 L )  )  )  )  ;", "TestHiveBucketing . assertBucketEquals ( ImmutableList . of (  \" float \"  ,     \" array < smallint >  \"  ,     \" map < string , bigint >  \"  )  ,    ImmutableList . of (  1  2  .  3  4 F ,    ImmutableList . of (  (  ( short )     (  5  )  )  ,     (  ( short )     (  8  )  )  ,     (  ( short )     (  1  3  )  )  )  ,    ImmutableMap . of (  \" key \"  ,     1  2  3 L )  )  )  ;", "TestHiveBucketing . assertBucketEquals ( ImmutableList . of (  \" double \"  ,     \" array < smallint >  \"  ,     \" boolean \"  ,     \" map < string , bigint >  \"  ,     \" tinyint \"  )  ,    Arrays . asList ( null ,    ImmutableList . of (  (  ( short )     (  5  )  )  ,     (  ( short )     (  8  )  )  ,     (  ( short )     (  1  3  )  )  )  ,    null ,    ImmutableMap . of (  \" key \"  ,     1  2  3 L )  ,    null )  )  ;", "}", "METHOD_END"], "methodName": ["testHashingCompare"], "fileName": "com.facebook.presto.hive.TestHiveBucketing"}, {"methodBody": ["METHOD_START", "{", "String   typeBase    =    type . getTypeSignature (  )  . getBase (  )  ;", "if    ( hiveValue    =  =    null )     {", "return   null ;", "}", "switch    ( typeBase )     {", "case   StandardTypes . ARRAY    :", "{", "BlockBuilder   blockBuilder    =    type . createBlockBuilder ( null ,     1  )  ;", "BlockBuilder   subBlockBuilder    =    blockBuilder . beginBlockEntry (  )  ;", "for    ( Object   subElement    :     (  ( Iterable <  ?  >  )     ( hiveValue )  )  )     {", ". appendToBlockBuilder ( type . getTypeParameters (  )  . get (  0  )  ,    subElement ,    subBlockBuilder )  ;", "}", "blockBuilder . closeEntry (  )  ;", "return   type . getObject ( blockBuilder ,     0  )  ;", "}", "case   StandardTypes . ROW    :", "{", "BlockBuilder   blockBuilder    =    type . createBlockBuilder ( null ,     1  )  ;", "BlockBuilder   subBlockBuilder    =    blockBuilder . beginBlockEntry (  )  ;", "int   field    =     0  ;", "for    ( Object   subElement    :     (  ( Iterable <  ?  >  )     ( hiveValue )  )  )     {", ". appendToBlockBuilder ( type . getTypeParameters (  )  . get ( field )  ,    subElement ,    subBlockBuilder )  ;", "field +  +  ;", "}", "blockBuilder . closeEntry (  )  ;", "return   type . getObject ( blockBuilder ,     0  )  ;", "}", "case   StandardTypes . MAP    :", "{", "BlockBuilder   blockBuilder    =    type . createBlockBuilder ( null ,     1  )  ;", "BlockBuilder   subBlockBuilder    =    blockBuilder . beginBlockEntry (  )  ;", "for    ( Map . Entry <  ?  ,     ?  >    entry    :     (  ( Map <  ?  ,     ?  >  )     ( hiveValue )  )  . entrySet (  )  )     {", ". appendToBlockBuilder ( type . getTypeParameters (  )  . get (  0  )  ,    entry . getKey (  )  ,    subBlockBuilder )  ;", ". appendToBlockBuilder ( type . getTypeParameters (  )  . get (  1  )  ,    entry . getValue (  )  ,    subBlockBuilder )  ;", "}", "blockBuilder . closeEntry (  )  ;", "return   type . getObject ( blockBuilder ,     0  )  ;", "}", "case   StandardTypes . BOOLEAN    :", "return   hiveValue ;", "case   StandardTypes . TINYINT    :", "return    (  ( long )     (  ( byte )     ( hiveValue )  )  )  ;", "case   StandardTypes . SMALLINT    :", "return    (  ( long )     (  ( short )     ( hiveValue )  )  )  ;", "case   StandardTypes . INTEGER    :", "return    (  ( long )     (  ( int )     ( hiveValue )  )  )  ;", "case   StandardTypes . BIGINT    :", "return   hiveValue ;", "case   StandardTypes . REAL    :", "return    (  ( long )     ( Float . floatToRawIntBits (  (  ( float )     ( hiveValue )  )  )  )  )  ;", "case   StandardTypes . DOUBLE    :", "return   hiveValue ;", "case   StandardTypes . VARCHAR    :", "return   Slices . utf 8 Slice ( hiveValue . toString (  )  )  ;", "case   StandardTypes . DATE    :", "long   daysSinceEpochInLocalZone    =     (  ( Date )     ( hiveValue )  )  . toLocalDate (  )  . toEpochDay (  )  ;", "assertEquals ( daysSinceEpochInLocalZone ,    DateWritable . dateToDays (  (  ( Date )     ( hiveValue )  )  )  )  ;", "return   daysSinceEpochInLocalZone ;", "case   StandardTypes . TIMESTAMP    :", "Instant   instant    =     (  ( Timestamp )     ( hiveValue )  )  . toInstant (  )  ;", "long   epochSecond    =    instant . getEpochSecond (  )  ;", "int   nano    =    instant . getNano (  )  ;", "assertEquals (  ( nano    %     1  0  0  0  0  0  0  )  ,     0  )  ;", "return    ( epochSecond    *     1  0  0  0  )     +     ( nano    /     1  0  0  0  0  0  0  )  ;", "default    :", "throw   new   UnsupportedOperationException (  \" unknown   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["toNativeContainerValue"], "fileName": "com.facebook.presto.hive.TestHiveBucketing"}, {"methodBody": ["METHOD_START", "{", "ConfigAssertions . assertRecordedDefaults ( ConfigAssertions . recordDefaults ( HiveClientConfig . class )  . setTimeZone ( TimeZone . getDefault (  )  . getID (  )  )  . setMaxSplitSize ( new   io . airlift . units . DataSize (  6  4  ,    Unit . MEGABYTE )  )  . setMaxPartitionsPerScan (  1  0  0  0  0  0  )  . setMaxOutstandingSplits (  1  0  0  0  )  . setMaxOutstandingSplitsSize ( new   io . airlift . units . DataSize (  2  5  6  ,    Unit . MEGABYTE )  )  . setMaxSplitIteratorThreads (  1  0  0  0  )  . setAllowCorruptWritesForTesting ( false )  . setMetastoreCacheTtl ( new   Duration (  0  ,    TimeUnit . SECONDS )  )  . setMetastoreRefreshInterval ( new   Duration (  0  ,    TimeUnit . SECONDS )  )  . setMetastoreCacheMaximumSize (  1  0  0  0  0  )  . setPerTransactionMetastoreCacheMaximumSize (  1  0  0  0  )  . setMaxMetastoreRefreshThreads (  1  0  0  )  . setMetastoreSocksProxy ( null )  . setMetastoreTimeout ( new   Duration (  1  0  ,    TimeUnit . SECONDS )  )  . setMinPartitionBatchSize (  1  0  )  . setMaxPartitionBatchSize (  1  0  0  )  . setMaxInitialSplits (  2  0  0  )  . setMaxInitialSplitSize ( new   io . airlift . units . DataSize (  3  2  ,    Unit . MEGABYTE )  )  . setSplitLoaderConcurrency (  4  )  . setDomainCompactionThreshold (  1  0  0  )  . setForceLocalScheduling ( false )  . setMaxConcurrentFileRenames (  2  0  )  . setRecursiveDirWalkerEnabled ( false )  . setDfsTimeout ( new   Duration (  6  0  ,    TimeUnit . SECONDS )  )  . setIpcPingInterval ( new   Duration (  1  0  ,    TimeUnit . SECONDS )  )  . setDfsConnectTimeout ( new   Duration (  5  0  0  ,    TimeUnit . MILLISECONDS )  )  . setDfsConnectMaxRetries (  5  )  . setVerifyChecksum ( true )  . setDomainSocketPath ( null )  . setS 3 FileSystemType ( S 3 FileSystemType . PRESTO )  . setResourceConfigFiles (  (  ( String )     ( null )  )  )  . setHiveStorageFormat ( HiveStorageFormat . RCBINARY )  . setHiveCompressionCodec ( HiveCompressionCodec . GZIP )  . setRespectTableFormat ( true )  . setImmutablePartitions ( false )  . setMaxPartitionsPerWriter (  1  0  0  )  . setWriteValidationThreads (  1  6  )  . setUseParquetColumnNames ( false )  . setUseOrcColumnNames ( false )  . setParquetPredicatePushdownEnabled ( false )  . setParquetOptimizedReaderEnabled ( false )  . setAssumeCanonicalPartitionKeys ( false )  . setOrcBloomFiltersEnabled ( false )  . setOrcDefaultBloomFilterFpp (  0  .  0  5  )  . setOrcMaxMergeDistance ( new   io . airlift . units . DataSize (  1  ,    Unit . MEGABYTE )  )  . setOrcMaxBufferSize ( new   io . airlift . units . DataSize (  8  ,    Unit . MEGABYTE )  )  . setOrcStreamBufferSize ( new   io . airlift . units . DataSize (  8  ,    Unit . MEGABYTE )  )  . setOrcMaxReadBlockSize ( new   io . airlift . units . DataSize (  1  6  ,    Unit . MEGABYTE )  )  . setOrcLazyReadSmallRanges ( true )  . setRcfileOptimizedWriterEnabled ( true )  . setRcfileWriterValidate ( false )  . setOrcOptimizedWriterEnabled ( false )  . setOrcWriterValidate ( true )  . setHiveMetastoreAuthenticationType ( HiveClientConfig . HiveMetastoreAuthenticationType . NONE )  . setHdfsAuthenticationType ( HiveClientConfig . HdfsAuthenticationType . NONE )  . setHdfsImpersonationEnabled ( false )  . setSkipDeletionForAlter ( false )  . setBucketExecutionEnabled ( true )  . setBucketWritingEnabled ( true )  . setFileSystemMaxCacheSize (  1  0  0  0  )  . setTableStatisticsEnabled ( true )  . setWritesToNonManagedTablesEnabled ( false )  . setCreatesOfNonManagedTablesEnabled ( true )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "com.facebook.presto.hive.TestHiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . time - zone \"  ,    TestHiveUtil . nonDefaultTimeZone (  )  . getID (  )  )  . put (  \" hive . max - split - size \"  ,     \"  2  5  6 MB \"  )  . put (  \" hive . max - partitions - per - scan \"  ,     \"  1  2  3  \"  )  . put (  \" hive . max - outstanding - splits \"  ,     \"  1  0  \"  )  . put (  \" hive . max - outstanding - splits - size \"  ,     \"  3  2 MB \"  )  . put (  \" hive . max - split - iterator - threads \"  ,     \"  1  0  \"  )  . put (  \" hive . allow - corrupt - writes - for - testing \"  ,     \" true \"  )  . put (  \" hive . metastore - cache - ttl \"  ,     \"  2 h \"  )  . put (  \" hive . metastore - refresh - interval \"  ,     \"  3  0 m \"  )  . put (  \" hive . metastore - cache - maximum - size \"  ,     \"  5  0  0  0  \"  )  . put (  \" hive . per - transaction - metastore - cache - maximum - size \"  ,     \"  5  0  0  \"  )  . put (  \" hive . metastore - refresh - max - threads \"  ,     \"  2  5  0  0  \"  )  . put (  \" hive . metastore . thrift . client . socks - proxy \"  ,     \" localhost :  1  0  8  0  \"  )  . put (  \" hive . metastore - timeout \"  ,     \"  2  0 s \"  )  . put (  \" hive . metastore . partition - batch - size . min \"  ,     \"  1  \"  )  . put (  \" hive . metastore . partition - batch - size . max \"  ,     \"  1  0  0  0  \"  )  . put (  \" hive . dfs . ipc - ping - interval \"  ,     \"  3  4 s \"  )  . put (  \" hive . dfs - timeout \"  ,     \"  3  3 s \"  )  . put (  \" hive . dfs . connect . timeout \"  ,     \"  2  0 s \"  )  . put (  \" hive . dfs . connect . max - retries \"  ,     \"  1  0  \"  )  . put (  \" hive . dfs . verify - checksum \"  ,     \" false \"  )  . put (  \" hive . dfs . domain - socket - path \"  ,     \"  / foo \"  )  . put (  \" hive . s 3  - file - system - type \"  ,     \" EMRFS \"  )  . put (  \" hive . config . resources \"  ,     \"  / foo . xml ,  / bar . xml \"  )  . put (  \" hive . max - initial - splits \"  ,     \"  1  0  \"  )  . put (  \" hive . max - initial - split - size \"  ,     \"  1  6 MB \"  )  . put (  \" hive . split - loader - concurrency \"  ,     \"  1  \"  )  . put (  \" hive . domain - compaction - threshold \"  ,     \"  4  2  \"  )  . put (  \" hive . recursive - directories \"  ,     \" true \"  )  . put (  \" hive . storage - format \"  ,     \" SEQUENCEFILE \"  )  . put (  \" hive . compression - codec \"  ,     \" NONE \"  )  . put (  \" hive . respect - table - format \"  ,     \" false \"  )  . put (  \" hive . immutable - partitions \"  ,     \" true \"  )  . put (  \" hive . max - partitions - per - writers \"  ,     \"  2  2  2  \"  )  . put (  \" hive . write - validation - threads \"  ,     \"  1  1  \"  )  . put (  \" hive . force - local - scheduling \"  ,     \" true \"  )  . put (  \" hive . max - concurrent - file - renames \"  ,     \"  1  0  0  \"  )  . put (  \" hive . assume - canonical - partition - keys \"  ,     \" true \"  )  . put (  \" hive . parquet . use - column - names \"  ,     \" true \"  )  . put (  \" hive . orc . use - column - names \"  ,     \" true \"  )  . put (  \" hive . parquet - predicate - pushdown . enabled \"  ,     \" true \"  )  . put (  \" hive . parquet - optimized - reader . enabled \"  ,     \" true \"  )  . put (  \" hive . orc . bloom - filters . enabled \"  ,     \" true \"  )  . put (  \" hive . orc . default - bloom - filter - fpp \"  ,     \"  0  .  9  6  \"  )  . put (  \" hive . orc . max - merge - distance \"  ,     \"  2  2 kB \"  )  . put (  \" hive . orc . max - buffer - size \"  ,     \"  4  4 kB \"  )  . put (  \" hive . orc . stream - buffer - size \"  ,     \"  5  5 kB \"  )  . put (  \" hive . orc . max - read - block - size \"  ,     \"  6  6 kB \"  )  . put (  \" hive . orc . lazy - read - small - ranges \"  ,     \" false \"  )  . put (  \" hive . rcfile - optimized - writer . enabled \"  ,     \" false \"  )  . put (  \" hive . rcfile . writer . validate \"  ,     \" true \"  )  . put (  \" hive . orc . optimized - writer . enabled \"  ,     \" true \"  )  . put (  \" hive . orc . writer . validate \"  ,     \" false \"  )  . put (  \" hive . metastore . authentication . type \"  ,     \" KERBEROS \"  )  . put (  \" hive . hdfs . authentication . type \"  ,     \" KERBEROS \"  )  . put (  \" hive . hdfs . impersonation . enabled \"  ,     \" true \"  )  . put (  \" hive . skip - deletion - for - alter \"  ,     \" true \"  )  . put (  \" hive . bucket - execution \"  ,     \" false \"  )  . put (  \" hive . bucket - writing \"  ,     \" false \"  )  . put (  \" hive . fs . cache . max - size \"  ,     \"  1  0  1  0  \"  )  . put (  \" hive . table - statistics - enabled \"  ,     \" false \"  )  . put (  \" hive . non - managed - table - writes - enabled \"  ,     \" true \"  )  . put (  \" hive . non - managed - table - creates - enabled \"  ,     \" false \"  )  . build (  )  ;", "expected    =    new    (  )  . setTimeZone ( TestHiveUtil . nonDefaultTimeZone (  )  . toTimeZone (  )  . getID (  )  )  . setMaxSplitSize ( new   io . airlift . units . DataSize (  2  5  6  ,    Unit . MEGABYTE )  )  . setMaxPartitionsPerScan (  1  2  3  )  . setMaxOutstandingSplits (  1  0  )  . setMaxOutstandingSplitsSize ( new   io . airlift . units . DataSize (  3  2  ,    Unit . MEGABYTE )  )  . setMaxSplitIteratorThreads (  1  0  )  . setAllowCorruptWritesForTesting ( true )  . setMetastoreCacheTtl ( new   Duration (  2  ,    TimeUnit . HOURS )  )  . setMetastoreRefreshInterval ( new   Duration (  3  0  ,    TimeUnit . MINUTES )  )  . setMetastoreCacheMaximumSize (  5  0  0  0  )  . setPerTransactionMetastoreCacheMaximumSize (  5  0  0  )  . setMaxMetastoreRefreshThreads (  2  5  0  0  )  . setMetastoreSocksProxy ( HostAndPort . fromParts (  \" localhost \"  ,     1  0  8  0  )  )  . setMetastoreTimeout ( new   Duration (  2  0  ,    TimeUnit . SECONDS )  )  . setMinPartitionBatchSize (  1  )  . setMaxPartitionBatchSize (  1  0  0  0  )  . setMaxInitialSplits (  1  0  )  . setMaxInitialSplitSize ( new   io . airlift . units . DataSize (  1  6  ,    Unit . MEGABYTE )  )  . setSplitLoaderConcurrency (  1  )  . setDomainCompactionThreshold (  4  2  )  . setForceLocalScheduling ( true )  . setMaxConcurrentFileRenames (  1  0  0  )  . setRecursiveDirWalkerEnabled ( true )  . setIpcPingInterval ( new   Duration (  3  4  ,    TimeUnit . SECONDS )  )  . setDfsTimeout ( new   Duration (  3  3  ,    TimeUnit . SECONDS )  )  . setDfsConnectTimeout ( new   Duration (  2  0  ,    TimeUnit . SECONDS )  )  . setDfsConnectMaxRetries (  1  0  )  . setVerifyChecksum ( false )  . setResourceConfigFiles ( ImmutableList . of (  \"  / foo . xml \"  ,     \"  / bar . xml \"  )  )  . setHiveStorageFormat ( HiveStorageFormat . SEQUENCEFILE )  . setHiveCompressionCodec ( HiveCompressionCodec . NONE )  . setRespectTableFormat ( false )  . setImmutablePartitions ( true )  . setMaxPartitionsPerWriter (  2  2  2  )  . setWriteValidationThreads (  1  1  )  . setDomainSocketPath (  \"  / foo \"  )  . setS 3 FileSystemType ( S 3 FileSystemType . EMRFS )  . setUseParquetColumnNames ( true )  . setUseOrcColumnNames ( true )  . setParquetPredicatePushdownEnabled ( true )  . setParquetOptimizedReaderEnabled ( true )  . setAssumeCanonicalPartitionKeys ( true )  . setOrcBloomFiltersEnabled ( true )  . setOrcDefaultBloomFilterFpp (  0  .  9  6  )  . setOrcMaxMergeDistance ( new   io . airlift . units . DataSize (  2  2  ,    Unit . KILOBYTE )  )  . setOrcMaxBufferSize ( new   io . airlift . units . DataSize (  4  4  ,    Unit . KILOBYTE )  )  . setOrcStreamBufferSize ( new   io . airlift . units . DataSize (  5  5  ,    Unit . KILOBYTE )  )  . setOrcMaxReadBlockSize ( new   io . airlift . units . DataSize (  6  6  ,    Unit . KILOBYTE )  )  . setOrcLazyReadSmallRanges ( false )  . setRcfileOptimizedWriterEnabled ( false )  . setRcfileWriterValidate ( true )  . setOrcOptimizedWriterEnabled ( true )  . setOrcWriterValidate ( false )  . setHiveMetastoreAuthenticationType (  . HiveMetastoreAuthenticationType . KERBEROS )  . setHdfsAuthenticationType (  . HdfsAuthenticationType . KERBEROS )  . setHdfsImpersonationEnabled ( true )  . setSkipDeletionForAlter ( true )  . setBucketExecutionEnabled ( false )  . setBucketWritingEnabled ( false )  . setFileSystemMaxCacheSize (  1  0  1  0  )  . setTableStatisticsEnabled ( false )  . setWritesToNonManagedTablesEnabled ( true )  . setCreatesOfNonManagedTablesEnabled ( false )  ;", "ConfigAssertions . assertFullMapping ( properties ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMappings"], "fileName": "com.facebook.presto.hive.TestHiveClientConfig"}, {"methodBody": ["METHOD_START", "{", "HiveColumnHandle   hiddenColumn    =    HiveColumnHandle . pathColumnHandle (  )  ;", "testRoundTrip ( hiddenColumn )  ;", "}", "METHOD_END"], "methodName": ["testHiddenColumn"], "fileName": "com.facebook.presto.hive.TestHiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "HiveColumnHandle   expectedRegularColumn    =    new   HiveColumnHandle (  \" name \"  ,    HiveType . HIVE _ FLOAT ,    TypeSignature . parseTypeSignature ( DOUBLE )  ,     8  8  ,    HiveColumnHandle . ColumnType . REGULAR ,    Optional . empty (  )  )  ;", "testRoundTrip ( expectedRegularColumn )  ;", "}", "METHOD_END"], "methodName": ["testPartitionKeyColumn"], "fileName": "com.facebook.presto.hive.TestHiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "HiveColumnHandle   expectedPartitionColumn    =    new   HiveColumnHandle (  \" name \"  ,    HiveType . HIVE _ FLOAT ,    TypeSignature . parseTypeSignature ( DOUBLE )  ,     8  8  ,    HiveColumnHandle . ColumnType . PARTITION _ KEY ,    Optional . empty (  )  )  ;", "testRoundTrip ( expectedPartitionColumn )  ;", "}", "METHOD_END"], "methodName": ["testRegularColumn"], "fileName": "com.facebook.presto.hive.TestHiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "String   json    =    codec . toJson ( expected )  ;", "actual    =    codec . fromJson ( json )  ;", "assertEquals ( actual . getName (  )  ,    expected . getName (  )  )  ;", "assertEquals ( actual . getHiveType (  )  ,    expected . getHiveType (  )  )  ;", "assertEquals ( actual . getHiveColumnIndex (  )  ,    expected . getHiveColumnIndex (  )  )  ;", "assertEquals ( actual . isPartitionKey (  )  ,    expected . isPartitionKey (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoundTrip"], "fileName": "com.facebook.presto.hive.TestHiveColumnHandle"}, {"methodBody": ["METHOD_START", "{", "HiveConnectorFactory   connectorFactory    =    new   HiveConnectorFactory (  \" hive - test \"  ,    HiveConnector . class . getClassLoader (  )  ,    null )  ;", "Map < String ,    String >    config    =    ImmutableMap .  < String ,    String > builder (  )  . put (  \" hive . metastore . uri \"  ,    metastoreUri )  . build (  )  ;", "Connector   connector    =    connectorFactory . create (  \" hive - test \"  ,    config ,    new   TestingConnectorContext (  )  )  ;", "ConnectorTransactionHandle   transaction    =    connector . beginTransaction ( READ _ UNCOMMITTED ,    true )  ;", "Assertions . assertInstanceOf ( connector . getMetadata ( transaction )  ,    ClassLoaderSafeConnectorMetadata . class )  ;", "Assertions . assertInstanceOf ( connector . getSplitManager (  )  ,    ClassLoaderSafeConnectorSplitManager . class )  ;", "Assertions . assertInstanceOf ( connector . getPageSourceProvider (  )  ,    ConnectorPageSourceProvider . class )  ;", "connector . commit ( transaction )  ;", "}", "METHOD_END"], "methodName": ["assertCreateConnector"], "fileName": "com.facebook.presto.hive.TestHiveConnectorFactory"}, {"methodBody": ["METHOD_START", "{", "try    {", ". assertCreateConnector ( metastoreUri )  ;", "fail (  (  \" expected   connector   creation   to   fail :  \"     +    metastoreUri )  )  ;", "}    catch    ( RuntimeException   e )     {", "Assertions . assertContains ( e . getMessage (  )  ,    exceptionString )  ;", "}", "}", "METHOD_END"], "methodName": ["assertCreateConnectorFails"], "fileName": "com.facebook.presto.hive.TestHiveConnectorFactory"}, {"methodBody": ["METHOD_START", "{", "TestHiveConnectorFactory . assertCreateConnector (  \" thrift :  /  / localhost :  1  2  3  4  \"  )  ;", "TestHiveConnectorFactory . assertCreateConnector (  \" thrift :  /  / localhost :  1  2  3  4  , thrift :  /  /  1  9  2  .  0  .  2  .  3  :  5  6  7  8  \"  )  ;", "TestHiveConnectorFactory . assertCreateConnectorFails (  \" abc \"  ,     \" metastoreUri   scheme   is   missing :    abc \"  )  ;", "TestHiveConnectorFactory . assertCreateConnectorFails (  \" thrift :  /  /  :  8  0  9  0  \"  ,     \" metastoreUri   host   is   missing :    thrift :  /  /  :  8  0  9  0  \"  )  ;", "TestHiveConnectorFactory . assertCreateConnectorFails (  \" thrift :  /  / localhost \"  ,     \" metastoreUri   port   is   missing :    thrift :  /  / localhost \"  )  ;", "TestHiveConnectorFactory . assertCreateConnectorFails (  \" abc :  :  \"  ,     \" metastoreUri   scheme   must   be   thrift :    abc :  :  \"  )  ;", "TestHiveConnectorFactory . assertCreateConnectorFails (  \"  \"  ,     \" metastoreUris   must   specify   at   least   one   URI \"  )  ;", "TestHiveConnectorFactory . assertCreateConnectorFails (  \" thrift :  /  / localhost :  1  2  3  4  , thrift :  /  / test -  1  \"  ,     \" metastoreUri   port   is   missing :    thrift :  /  / test -  1  \"  )  ;", "}", "METHOD_END"], "methodName": ["testGetClient"], "fileName": "com.facebook.presto.hive.TestHiveConnectorFactory"}, {"methodBody": ["METHOD_START", "{", "byte [  ]    bytes    =    input . getBytes ( StandardCharsets . US _ ASCII )  ;", "BigDecimal   parsed    =     . parseHiveDecimal ( bytes ,     0  ,    bytes . length ,    DecimalType . createDecimalType ( precision ,    scale )  )  ;", "assertEquals ( parsed ,    expected )  ;", "}", "METHOD_END"], "methodName": ["checkParseDecimal"], "fileName": "com.facebook.presto.hive.TestHiveDecimalParser"}, {"methodBody": ["METHOD_START", "{", "checkParseDecimal (  \"  3  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  3  .  0  \"  )  )  ;", "checkParseDecimal (  \"  3  .  1  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  3  .  1  \"  )  )  ;", "checkParseDecimal (  \"  3  .  1  1  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  3  .  1  \"  )  )  ;", "checkParseDecimal (  \"  3  .  1  6  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  3  .  2  \"  )  )  ;", "checkParseDecimal (  \"  3  .  1  5  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  3  .  2  \"  )  )  ;", "checkParseDecimal (  \"  3  .  2  5  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  3  .  3  \"  )  )  ;", "checkParseDecimal (  \"  -  3  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  -  3  .  0  \"  )  )  ;", "checkParseDecimal (  \"  -  3  .  1  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  -  3  .  1  \"  )  )  ;", "checkParseDecimal (  \"  -  3  .  1  1  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  -  3  .  1  \"  )  )  ;", "checkParseDecimal (  \"  -  3  .  1  6  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  -  3  .  2  \"  )  )  ;", "checkParseDecimal (  \"  -  3  .  1  5  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  -  3  .  2  \"  )  )  ;", "checkParseDecimal (  \"  -  3  .  2  5  \"  ,     2  ,     1  ,    new   BigDecimal (  \"  -  3  .  3  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseDecimal"], "fileName": "com.facebook.presto.hive.TestHiveDecimalParser"}, {"methodBody": ["METHOD_START", "{", "return   testSessionBuilder (  )  . setCatalog ( queryRunner . getDefaultSession (  )  . getCatalog (  )  . get (  )  )  . setSchema ( queryRunner . getDefaultSession (  )  . getSchema (  )  . get (  )  )  . setIdentity ( new   Identity ( user ,    Optional . empty (  )  )  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getSession"], "fileName": "com.facebook.presto.hive.TestHiveFileBasedSecurity"}, {"methodBody": ["METHOD_START", "{", "String   path    =    this . getClass (  )  . getResource (  \" security . json \"  )  . getPath (  )  ;", "queryRunner    =    HiveQueryRunner . createQueryRunner ( io . airlift . tpch . TpchTable . getTables (  )  ,    ImmutableMap . of (  )  ,     \" file \"  ,    ImmutableMap . of (  \" security . config - file \"  ,    path )  )  ;", "}", "METHOD_END"], "methodName": ["setUp"], "fileName": "com.facebook.presto.hive.TestHiveFileBasedSecurity"}, {"methodBody": ["METHOD_START", "{", "queryRunner . close (  )  ;", "}", "METHOD_END"], "methodName": ["tearDown"], "fileName": "com.facebook.presto.hive.TestHiveFileBasedSecurity"}, {"methodBody": ["METHOD_START", "{", "Session   admin    =    getSession (  \" user \"  )  ;", "queryRunner . exte ( admin ,     \" SELECT    *    FROM   orders \"  )  ;", "}", "METHOD_END"], "methodName": ["testAdminCanRead"], "fileName": "com.facebook.presto.hive.TestHiveFileBasedSecurity"}, {"methodBody": ["METHOD_START", "{", "Session   bob    =    getSession (  \" bob \"  )  ;", "queryRunner . exte ( bob ,     \" SELECT    *    FROM   orders \"  )  ;", "}", "METHOD_END"], "methodName": ["testNonAdminCannotRead"], "fileName": "com.facebook.presto.hive.TestHiveFileBasedSecurity"}, {"methodBody": ["METHOD_START", "{", "return   new   TestHiveFileFormats . FileFormatAssertion ( hiveStorageFormat . name (  )  )  . withStorageFormat ( hiveStorageFormat )  ;", "}", "METHOD_END"], "methodName": ["assertThatFileFormat"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "return   AbstractTestHiveFileFormats . TEST _ COLUMNS . stream (  )  . filter (  (    column )     -  >     (  !  ( column . getName (  )  . startsWith (  \" t _ map _  \"  )  )  )     |  |     ( column . getName (  )  . equals (  \" t _ map _ string \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . endsWith (  \"  _ smallint \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . endsWith (  \"  _ tinyint \"  )  )  )  . collect ( Collectors . toList (  )  )  ;", "}", "METHOD_END"], "methodName": ["getTestColumnsSupportedByAvro"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "return   AbstractTestHiveFileFormats . TEST _ COLUMNS . stream (  )  . filter (  (    column )     -  >     !  ( ImmutableSet . of (  \" t _ null _ array _ int \"  ,     \" t _ array _ empty \"  ,     \" t _ map _ null _ key \"  ,     \" t _ map _ null _ key _ complex _ value \"  ,     \" t _ map _ null _ key _ complex _ key _ value \"  )  . contains ( column . getName (  )  )  )  )  . filter (  (    column )     -  >     ( column . isPartitionKey (  )  )     |  |     (  (  (  !  ( TestHiveFileFormats . hasType ( column . getObjectInspector (  )  ,    DATE )  )  )     &  &     (  !  ( TestHiveFileFormats . hasType ( column . getObjectInspector (  )  ,    SHORT )  )  )  )     &  &     (  !  ( TestHiveFileFormats . hasType ( column . getObjectInspector (  )  ,    BYTE )  )  )  )  )  . collect ( Collectors . toList (  )  )  ;", "}", "METHOD_END"], "methodName": ["getTestColumnsSupportedByParquet"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "if    ( objectInspector   instanceof   PrimitiveObjectInspector )     {", "PrimitiveObjectInspector   primitiveInspector    =     (  ( PrimitiveObjectInspector )     ( objectInspector )  )  ;", "PrimitiveCategory   primitiveCategory    =    primitiveInspector . getPrimitiveCategory (  )  ;", "for    ( PrimitiveCategory   type    :    types )     {", "if    ( primitiveCategory    =  =    type )     {", "return   true ;", "}", "}", "return   false ;", "}", "if    ( objectInspector   instanceof   ListObjectInspector )     {", "ListObjectInspector   listInspector    =     (  ( ListObjectInspector )     ( objectInspector )  )  ;", "return    . hasType ( listInspector . getListElementObjectInspector (  )  ,    types )  ;", "}", "if    ( objectInspector   instanceof   MapObjectInspector )     {", "MapObjectInspector   mapInspector    =     (  ( MapObjectInspector )     ( objectInspector )  )  ;", "return    (  . hasType ( mapInspector . getMapKeyObjectInspector (  )  ,    types )  )     |  |     (  . hasType ( mapInspector . getMapValueObjectInspector (  )  ,    types )  )  ;", "}", "if    ( objectInspector   instanceof   StructObjectInspector )     {", "for    ( StructField   field    :     (  ( StructObjectInspector )     ( objectInspector )  )  . getAllStructFieldRefs (  )  )     {", "if    (  . hasType ( field . getFieldObjectInspector (  )  ,    types )  )     {", "return   true ;", "}", "}", "return   false ;", "}", "throw   new   IllegalArgumentException (  (  \" Unknown   object   inspector   type    \"     +    objectInspector )  )  ;", "}", "METHOD_END"], "methodName": ["hasType"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "return   new   Object [  ]  [  ]  {    new   Object [  ]  {     0     }  ,    new   Object [  ]  {     1  0  0  0     }     }  ;", "}", "METHOD_END"], "methodName": ["rowCountProvider"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( TimeZone . getDefault (  )  . getID (  )  ,     \" Asia / Katmandu \"  ,     \" Timezone   not   configured   correctly .    Add    - Duser . timezone = Asia / Katmandu   to   your   JVM   arguments \"  )  ;", "}", "METHOD_END"], "methodName": ["setUp"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "assertThatFileFormat ( HiveStorageFormat . AVRO )  . withColumns ( TestHiveFileFormats . getTestColumnsSupportedByAvro (  )  )  . withRowsCount ( rowCount )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testAvro"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    AbstractTestHiveFileFormats . TEST _ COLUMNS . stream (  )  . filter (  (    testColumn )     -  >     !  ( TestHiveFileFormats . hasType ( testColumn . getObjectInspector (  )  ,    DATE ,    VARCHAR ,    CHAR ,    DECIMAL )  )  )  . collect ( Collectors . toList (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . DWRF )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . isReadableByPageSource ( new   DwrfPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  )  ;", "}", "METHOD_END"], "methodName": ["testDwrf"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "TestingConnectorSession   session    =    new   TestingConnectorSession ( new   HiveSessionProperties ( new   HiveClientConfig (  )  . setOrcOptimizedWriterEnabled ( true )  ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "List < Abstract . TestColumn >    testColumns    =    Abstract . TEST _ COLUMNS . stream (  )  . filter (  (    testColumn )     -  >     !  (  . hasType ( testColumn . getObjectInspector (  )  ,    DATE ,    VARCHAR ,    CHAR ,    DECIMAL )  )  )  . filter (  (    testColumn )     -  >     (  (  !  ( testColumn . getName (  )  . equals (  \" t _ map _ null _ key \"  )  )  )     &  &     (  !  ( testColumn . getName (  )  . equals (  \" t _ map _ null _ key _ complex _ value \"  )  )  )  )     &  &     (  !  ( testColumn . getName (  )  . equals (  \" t _ map _ null _ key _ complex _ key _ value \"  )  )  )  )  . collect ( Collectors . toList (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . DWRF )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . withSession ( session )  . withFileWriterFactory ( new   OrcFileWriterFactory ( HiveTestUtils . HDFS _ ENVIRONMENT ,    HiveTestUtils . TYPE _ MANAGER ,    new   NodeVersion (  \" test \"  )  ,     . HIVE _ STORAGE _ TIME _ ZONE ,     . STATS ,    new   OrcWriterOptions (  )  )  )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  . isReadableByPageSource ( new   DwrfPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,     . STATS )  )  ;", "}", "METHOD_END"], "methodName": ["testDwrfOptimizedWriter"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "AbstractTestHiveFileFormats . TestColumn   partitionColumn    =    new   AbstractTestHiveFileFormats . TestColumn (  \" partition _ column \"  ,    PrimitiveObjectInspectorFactory . getPrimitiveJavaObjectInspector ( new   VarcharTypeInfo (  3  )  )  ,     \" test \"  ,    Slices . utf 8 Slice (  \" tes \"  )  ,    true )  ;", "AbstractTestHiveFileFormats . TestColumn   varcharColumn    =    new   AbstractTestHiveFileFormats . TestColumn (  \" varchar _ column \"  ,    PrimitiveObjectInspectorFactory . getPrimitiveJavaObjectInspector ( new   VarcharTypeInfo (  3  )  )  ,    new   HiveVarchar (  \" tes \"  ,     3  )  ,    Slices . utf 8 Slice (  \" tes \"  )  )  ;", "List < AbstractTestHiveFileFormats . TestColumn >    columns    =    ImmutableList . of ( partitionColumn ,    varcharColumn )  ;", "HiveErrorCode   expectedErrorCode    =    HiveErrorCode . HIVE _ INVALID _ PARTITION _ VALUE ;", "String   expectedMessage    =     \" Invalid   partition   value    ' test '    for   varchar (  3  )    partition   key :    partition _ column \"  ;", "assertThatFileFormat ( HiveStorageFormat . RCTEXT )  . withColumns ( columns )  . isFailingForPageSource ( new   RcFilePageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  ,    expectedErrorCode ,    expectedMessage )  . isFailingForRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  ,    expectedErrorCode ,    expectedMessage )  ;", "assertThatFileFormat ( HiveStorageFormat . RCBINARY )  . withColumns ( columns )  . isFailingForPageSource ( new   RcFilePageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  ,    expectedErrorCode ,    expectedMessage )  . isFailingForRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  ,    expectedErrorCode ,    expectedMessage )  ;", "assertThatFileFormat ( HiveStorageFormat . ORC )  . withColumns ( columns )  . isFailingForPageSource ( new   OrcPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  ,    expectedErrorCode ,    expectedMessage )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withColumns ( columns )  . withSession ( TestHiveFileFormats . parquetCursorSession )  . isFailingForRecordCursor ( new   ParquetRecordCursorProvider ( false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  ,    expectedErrorCode ,    expectedMessage )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withColumns ( columns )  . withSession ( TestHiveFileFormats . parquetCursorPushdownSession )  . isFailingForRecordCursor ( new   ParquetRecordCursorProvider ( false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  ,    expectedErrorCode ,    expectedMessage )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withColumns ( columns )  . withSession ( TestHiveFileFormats . parquetPageSourceSession )  . isFailingForPageSource ( new   ParquetPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  ,    expectedErrorCode ,    expectedMessage )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withColumns ( columns )  . withSession ( TestHiveFileFormats . parquetPageSourcePushdown )  . isFailingForPageSource ( new   ParquetPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  ,    expectedErrorCode ,    expectedMessage )  ;", "assertThatFileFormat ( HiveStorageFormat . SEQUENCEFILE )  . withColumns ( columns )  . isFailingForRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  ,    expectedErrorCode ,    expectedMessage )  ;", "assertThatFileFormat ( HiveStorageFormat . TEXTFILE )  . withColumns ( columns )  . isFailingForRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  ,    expectedErrorCode ,    expectedMessage )  ;", "}", "METHOD_END"], "methodName": ["testFailForLongVarcharPartitionColumn"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    AbstractTestHiveFileFormats . TEST _ COLUMNS . stream (  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ binary \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ tinyint \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ smallint \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ int \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ bigint \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ float \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ double \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ null _ key \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ null _ key _ complex _ key _ value \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ null _ key _ complex _ value \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ decimal _ precision _  3  8  \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ decimal _ precision _  3  8  \"  )  )  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ array _ decimal _ precision _  3  8  \"  )  )  )  . collect ( Collectors . toList (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . JSON )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testJson"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "assertThatFileFormat ( HiveStorageFormat . ORC )  . withColumns ( AbstractTestHiveFileFormats . TEST _ COLUMNS )  . withRowsCount ( rowCount )  . isReadableByPageSource ( new   OrcPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  )  ;", "}", "METHOD_END"], "methodName": ["testOrc"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "TestingConnectorSession   session    =    new   TestingConnectorSession ( new   HiveSessionProperties ( new   HiveClientConfig (  )  . setOrcOptimizedWriterEnabled ( true )  ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "List < Abstract . TestColumn >    testColumns    =    Abstract . TEST _ COLUMNS . stream (  )  . filter (  (    testColumn )     -  >     (  (  !  ( testColumn . getName (  )  . equals (  \" t _ map _ null _ key \"  )  )  )     &  &     (  !  ( testColumn . getName (  )  . equals (  \" t _ map _ null _ key _ complex _ value \"  )  )  )  )     &  &     (  !  ( testColumn . getName (  )  . equals (  \" t _ map _ null _ key _ complex _ key _ value \"  )  )  )  )  . collect ( Collectors . toList (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . ORC )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . withSession ( session )  . withFileWriterFactory ( new   OrcFileWriterFactory ( HiveTestUtils . HDFS _ ENVIRONMENT ,    HiveTestUtils . TYPE _ MANAGER ,    new   NodeVersion (  \" test \"  )  ,     . HIVE _ STORAGE _ TIME _ ZONE ,     . STATS ,    new   OrcWriterOptions (  )  )  )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  . isReadableByPageSource ( new   OrcPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT ,     . STATS )  )  ;", "}", "METHOD_END"], "methodName": ["testOrcOptimizedWriter"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "TestingConnectorSession   session    =    new   TestingConnectorSession ( new   HiveSessionProperties ( new   HiveClientConfig (  )  ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . ORC )  . withWriteColumns ( Abstract . TEST _ COLUMNS )  . withRowsCount ( rowCount )  . withReadColumns ( Lists . reverse ( Abstract . TEST _ COLUMNS )  )  . withSession ( session )  . isReadableByPageSource ( new   OrcPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    true ,    HiveTestUtils . HDFS _ ENVIRONMENT ,     . STATS )  )  ;", "}", "METHOD_END"], "methodName": ["testOrcUseColumnNames"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    TestHiveFileFormats . getTestColumnsSupportedByParquet (  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . withSession ( TestHiveFileFormats . parquetCursorSession )  . isReadableByRecordCursor ( new   ParquetRecordCursorProvider ( false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . withSession ( TestHiveFileFormats . parquetCursorPushdownSession )  . isReadableByRecordCursor ( new   ParquetRecordCursorProvider ( false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testParquet"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    writeColumns    =    ImmutableList . of ( new   AbstractTestHiveFileFormats . TestColumn (  \" column _ name \"  ,    PrimitiveObjectInspectorFactory . javaStringObjectInspector ,     \" test \"  ,    Slices . utf 8 Slice (  \" test \"  )  ,    false )  )  ;", "List < AbstractTestHiveFileFormats . TestColumn >    readColumns    =    ImmutableList . of ( new   AbstractTestHiveFileFormats . TestColumn (  \" Column _ Name \"  ,    PrimitiveObjectInspectorFactory . javaStringObjectInspector ,     \" test \"  ,    Slices . utf 8 Slice (  \" test \"  )  ,    false )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( writeColumns )  . withReadColumns ( readColumns )  . withRowsCount ( rowCount )  . withSession ( TestHiveFileFormats . parquetCursorSession )  . isReadableByRecordCursor ( new   ParquetRecordCursorProvider ( true ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( writeColumns )  . withReadColumns ( readColumns )  . withRowsCount ( rowCount )  . withSession ( TestHiveFileFormats . parquetCursorPushdownSession )  . isReadableByRecordCursor ( new   ParquetRecordCursorProvider ( true ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testParquetCaseInsensitiveColumnLookup"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    TestHiveFileFormats . getTestColumnsSupportedByParquet (  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withColumns ( testColumns )  . withSession ( TestHiveFileFormats . parquetPageSourceSession )  . withRowsCount ( rowCount )  . isReadableByPageSource ( new   ParquetPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withColumns ( testColumns )  . withSession ( TestHiveFileFormats . parquetPageSourcePushdown )  . withRowsCount ( rowCount )  . isReadableByPageSource ( new   ParquetPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testParquetPageSource"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    writeColumns    =    TestHiveFileFormats . getTestColumnsSupportedByParquet (  )  ;", "boolean   useParquetColumnNames    =    false ;", "List < AbstractTestHiveFileFormats . TestColumn >    readColumns    =    writeColumns . stream (  )  . map (  (    column )     -  >    new   AbstractTestHiveFileFormats . TestColumn (  (  ( column . getName (  )  )     +     \"  _ new \"  )  ,    column . getObjectInspector (  )  ,    column . getWriteValue (  )  ,    column . getExpectedValue (  )  ,    column . isPartitionKey (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( writeColumns )  . withReadColumns ( readColumns )  . withSession ( TestHiveFileFormats . parquetPageSourceSession )  . withRowsCount ( rowCount )  . isReadableByPageSource ( new   ParquetPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    useParquetColumnNames ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "useParquetColumnNames    =    true ;", "readColumns    =    Lists . reverse ( writeColumns )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( writeColumns )  . withReadColumns ( readColumns )  . withSession ( TestHiveFileFormats . parquetPageSourceSession )  . isReadableByPageSource ( new   ParquetPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    useParquetColumnNames ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testParquetPageSourceSchemaEvolution"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    writeColumns    =    TestHiveFileFormats . getTestColumnsSupportedByParquet (  )  ;", "List < AbstractTestHiveFileFormats . TestColumn >    readColumns    =    Lists . reverse ( writeColumns )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( writeColumns )  . withReadColumns ( readColumns )  . withRowsCount ( rowCount )  . withSession ( TestHiveFileFormats . parquetCursorSession )  . isReadableByRecordCursor ( new   ParquetRecordCursorProvider ( true ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( writeColumns )  . withReadColumns ( readColumns )  . withRowsCount ( rowCount )  . withSession ( TestHiveFileFormats . parquetCursorPushdownSession )  . isReadableByRecordCursor ( new   ParquetRecordCursorProvider ( true ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testParquetUseColumnNames"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    AbstractTestHiveFileFormats . TEST _ COLUMNS . stream (  )  . filter (  (    testColumn )     -  >     {", "String   name    =    testColumn . getName (  )  ;", "return    (  !  ( name . equals (  \" t _ map _ null _ key _ complex _ key _ value \"  )  )  )     &  &     (  !  ( name . equals (  \" t _ empty _ varchar \"  )  )  )  ;", "}  )  . collect ( Collectors . toList (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . RCBINARY )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testRCBinary"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    ImmutableList . copyOf ( filter ( AbstractTestHiveFileFormats . TEST _ COLUMNS ,     (    testColumn )     -  >     {", "return    (  !  ( testColumn . getName (  )  . equals (  \" t _ struct _ null \"  )  )  )     &  &     (  !  ( testColumn . getName (  )  . equals (  \" t _ map _ null _ key _ complex _ key _ value \"  )  )  )  ;", "}  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . RCTEXT )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testRCText"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    AbstractTestHiveFileFormats . TEST _ COLUMNS . stream (  )  . filter (  (    testColumn )     -  >     !  ( testColumn . getName (  )  . equals (  \" t _ empty _ varchar \"  )  )  )  . filter ( TestHiveFileFormats :  : withoutNullMapKeyTests )  . collect ( Collectors . toList (  )  )  ;", "TestingConnectorSession   session    =    new   TestingConnectorSession ( new   HiveSessionProperties ( new   HiveClientConfig (  )  . setRcfileOptimizedWriterEnabled ( true )  ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . RCBINARY )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . withSession ( session )  . withFileWriterFactory ( new   RcFileFileWriterFactory ( HiveTestUtils . HDFS _ ENVIRONMENT ,    HiveTestUtils . TYPE _ MANAGER ,    new   NodeVersion (  \" test \"  )  ,    TestHiveFileFormats . HIVE _ STORAGE _ TIME _ ZONE ,    TestHiveFileFormats . STATS )  )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  . isReadableByPageSource ( new   RcFilePageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  )  ;", "}", "METHOD_END"], "methodName": ["testRcBinaryOptimizedWriter"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    AbstractTestHiveFileFormats . TEST _ COLUMNS . stream (  )  . filter (  (    testColumn )     -  >     !  ( testColumn . getName (  )  . equals (  \" t _ empty _ varchar \"  )  )  )  . collect ( Collectors . toList (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . RCBINARY )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . isReadableByPageSource ( new   RcFilePageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  )  ;", "}", "METHOD_END"], "methodName": ["testRcBinaryPageSource"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    AbstractTestHiveFileFormats . TEST _ COLUMNS . stream (  )  . filter ( TestHiveFileFormats :  : withoutNullMapKeyTests )  . collect ( toImmutableList (  )  )  ;", "TestingConnectorSession   session    =    new   TestingConnectorSession ( new   HiveSessionProperties ( new   HiveClientConfig (  )  . setRcfileOptimizedWriterEnabled ( true )  ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . RCTEXT )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . withSession ( session )  . withFileWriterFactory ( new   RcFileFileWriterFactory ( HiveTestUtils . HDFS _ ENVIRONMENT ,    HiveTestUtils . TYPE _ MANAGER ,    new   NodeVersion (  \" test \"  )  ,    TestHiveFileFormats . HIVE _ STORAGE _ TIME _ ZONE ,    TestHiveFileFormats . STATS )  )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  . isReadableByPageSource ( new   RcFilePageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  )  ;", "}", "METHOD_END"], "methodName": ["testRcTextOptimizedWriter"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "assertThatFileFormat ( HiveStorageFormat . RCTEXT )  . withColumns ( AbstractTestHiveFileFormats . TEST _ COLUMNS )  . withRowsCount ( rowCount )  . isReadableByPageSource ( new   RcFilePageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  )  ;", "}", "METHOD_END"], "methodName": ["testRcTextPageSource"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "List < AbstractTestHiveFileFormats . TestColumn >    testColumns    =    AbstractTestHiveFileFormats . TEST _ COLUMNS . stream (  )  . filter (  (    column )     -  >     !  ( column . getName (  )  . equals (  \" t _ map _ null _ key _ complex _ key _ value \"  )  )  )  . collect ( Collectors . toList (  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . TEXTFILE )  . withColumns ( testColumns )  . withRowsCount ( rowCount )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testTextFile"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "AbstractTestHiveFileFormats . TestColumn   writeColumn    =    new   AbstractTestHiveFileFormats . TestColumn (  \" varchar _ column \"  ,    PrimitiveObjectInspectorFactory . getPrimitiveJavaObjectInspector ( new   VarcharTypeInfo (  4  )  )  ,    new   HiveVarchar (  \" test \"  ,     4  )  ,    Slices . utf 8 Slice (  \" test \"  )  )  ;", "AbstractTestHiveFileFormats . TestColumn   readColumn    =    new   AbstractTestHiveFileFormats . TestColumn (  \" varchar _ column \"  ,    PrimitiveObjectInspectorFactory . getPrimitiveJavaObjectInspector ( new   VarcharTypeInfo (  3  )  )  ,    new   HiveVarchar (  \" tes \"  ,     3  )  ,    Slices . utf 8 Slice (  \" tes \"  )  )  ;", "assertThatFileFormat ( HiveStorageFormat . RCTEXT )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . isReadableByPageSource ( new   RcFilePageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . RCBINARY )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . isReadableByPageSource ( new   RcFilePageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . ORC )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . isReadableByPageSource ( new   OrcPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT ,    TestHiveFileFormats . STATS )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . withSession ( TestHiveFileFormats . parquetCursorSession )  . isReadableByRecordCursor ( new   ParquetRecordCursorProvider ( false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . withSession ( TestHiveFileFormats . parquetCursorPushdownSession )  . isReadableByRecordCursor ( new   ParquetRecordCursorProvider ( false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . withSession ( TestHiveFileFormats . parquetPageSourceSession )  . isReadableByPageSource ( new   ParquetPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . PARQUET )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . withSession ( TestHiveFileFormats . parquetPageSourcePushdown )  . isReadableByPageSource ( new   ParquetPageSourceFactory ( HiveTestUtils . TYPE _ MANAGER ,    false ,    HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . AVRO )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . SEQUENCEFILE )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "assertThatFileFormat ( HiveStorageFormat . TEXTFILE )  . withWriteColumns ( ImmutableList . of ( writeColumn )  )  . withReadColumns ( ImmutableList . of ( readColumn )  )  . isReadableByRecordCursor ( new   GenericHiveRecordCursorProvider ( HiveTestUtils . HDFS _ ENVIRONMENT )  )  ;", "}", "METHOD_END"], "methodName": ["testTruncateVarcharColumn"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "String   name    =    testColumn . getName (  )  ;", "return    (  (  !  ( name . equals (  \" t _ map _ null _ key \"  )  )  )     &  &     (  !  ( name . equals (  \" t _ map _ null _ key _ complex _ key _ value \"  )  )  )  )     &  &     (  !  ( name . equals (  \" t _ map _ null _ key _ complex _ value \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["withoutNullMapKeyTests"], "fileName": "com.facebook.presto.hive.TestHiveFileFormats"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( tableMetadata . getColumn ( columnName )  . getType (  )  ,    canonicalizeType ( expectedType )  )  ;", "}", "METHOD_END"], "methodName": ["assertColumnType"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "MaterializedResult   results    =    getQueryRunner (  )  . execute ( getSession (  )  ,    query )  . toTestTypes (  )  ;", "assertEquals ( results . getRowCount (  )  ,     1  )  ;", "assertEquals ( results . getMaterializedRows (  )  . get (  0  )  . getFieldCount (  )  ,     1  )  ;", "assertNotNull ( results . getMaterializedRows (  )  . get (  0  )  . getField (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["assertOneNotNullResult"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "HiveType   hiveType    =    HiveType . toHiveType ( typeTranslator ,    type )  ;", "return   HivUtils . TYPE _ MANAGER . getType ( hiveType . getTypeSignature (  )  )  ;", "}", "METHOD_END"], "methodName": ["canonicalizeType"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "TypeSignature   typeSignature    =    TypeSignature . parseTypeSignature ( type )  ;", "return   canonicalizeType ( HivUtils . TYPE _ MANAGER . getType ( typeSignature )  )  . toString (  )  ;", "}", "METHOD_END"], "methodName": ["canonicalizeTypeName"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "if    ( insertOperationsSupported ( storageFormat . getFormat (  )  )  )     {", "createPartitionedTable ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["createPartitionedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  \"  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" CREATE   TABLE   test _ partitioned _ table    (  \"     +     \"        _ string   VARCHAR \"  )     +     \"  ,        _ varchar   VARCHAR (  6  5  5  3  5  )  \"  )     +     \"  ,     _ char   CHAR (  1  0  )  \"  )     +     \"  ,     _ bigint   BIGINT \"  )     +     \"  ,     _ ier   INTEGER \"  )     +     \"  ,     _ smallint   SMALLINT \"  )     +     \"  ,     _ tinyint   TINYINT \"  )     +     \"  ,     _ real   REAL \"  )     +     \"  ,     _ double   DOUBLE \"  )     +     \"  ,     _ boolean   BOOLEAN \"  )     +     \"  ,     _ decimal _ short   DECIMAL (  3  ,  2  )  \"  )     +     \"  ,     _ decimal _ long   DECIMAL (  3  0  ,  1  0  )  \"  )     +     \"  ,     _ partition _ string   VARCHAR \"  )     +     \"  ,     _ partition _ varchar   VARCHAR (  6  5  5  3  5  )  \"  )     +     \"  ,     _ partition _ char   CHAR (  1  0  )  \"  )     +     \"  ,     _ partition _ tinyint   TINYINT \"  )     +     \"  ,     _ partition _ smallint   SMALLINT \"  )     +     \"  ,     _ partition _ ier   INTEGER \"  )     +     \"  ,     _ partition _ bigint   BIGINT \"  )     +     \"  ,     _ partition _ boolean   BOOLEAN \"  )     +     \"  ,     _ partition _ decimal _ short   DECIMAL (  3  ,  2  )  \"  )     +     \"  ,     _ partition _ decimal _ long   DECIMAL (  3  0  ,  1  0  )  \"  )     +     \"  ,     _ partition _ date   DATE \"  )     +     \"  ,     _ partition _ timestamp   TIMESTAMP \"  )     +     \"  )     \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partitioned _ by    =    ARRAY [     '  _ partition _ string '  ,     '  _ partition _ varchar '  ,     '  _ partition _ char '  ,     '  _ partition _ tinyint '  ,     '  _ partition _ smallint '  ,     '  _ partition _ ier '  ,     '  _ partition _ bigint '  ,     '  _ partition _ boolean '  ,     '  _ partition _ decimal _ short '  ,     '  _ partition _ decimal _ long '  ,     '  _ partition _ date '  ,     '  _ partition _ timestamp '  ]  \"  )     +     \"  )     \"  ;", "if    ( storageFormat    =  =     ( HiveStorageFormat . AVRO )  )     {", "createTable    =    createTable . replace (  \"     _ smallint   SMALLINT ,  \"  ,     \"     _ smallint   INTEGER ,  \"  )  ;", "createTable    =    createTable . replace (  \"     _ tinyint   TINYINT ,  \"  ,     \"     _ tinyint   INTEGER ,  \"  )  ;", "}", "assertUpdate ( session ,    createTable )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,     \" test _ partitioned _ table \"  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "List < String >    partitionedBy    =    ImmutableList . of (  \"  _ partition _ string \"  ,     \"  _ partition _ varchar \"  ,     \"  _ partition _ char \"  ,     \"  _ partition _ tinyint \"  ,     \"  _ partition _ smallint \"  ,     \"  _ partition _ ier \"  ,     \"  _ partition _ bigint \"  ,     \"  _ partition _ boolean \"  ,     \"  _ partition _ decimal _ short \"  ,     \"  _ partition _ decimal _ long \"  ,     \"  _ partition _ date \"  ,     \"  _ partition _ timestamp \"  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY )  ,    partitionedBy )  ;", "for    ( ColumnMetadata   columnMetadata    :    tableMetadata . getColumns (  )  )     {", "boolean   partitionKey    =    partitionedBy . contains ( columnMetadata . getName (  )  )  ;", "assertEquals ( columnMetadata . getExtraInfo (  )  ,    HiveUtil . columnExtraInfo ( partitionKey )  )  ;", "}", "assertColumnType ( tableMetadata ,     \"  _ string \"  ,    VarcharType . createUnboundedVarcharType (  )  )  ;", "assertColumnType ( tableMetadata ,     \"  _ varchar \"  ,    VarcharType . createVarcharType (  6  5  5  3  5  )  )  ;", "assertColumnType ( tableMetadata ,     \"  _ char \"  ,    CharType . createCharType (  1  0  )  )  ;", "assertColumnType ( tableMetadata ,     \"  _ partition _ string \"  ,    VarcharType . createUnboundedVarcharType (  )  )  ;", "assertColumnType ( tableMetadata ,     \"  _ partition _ varchar \"  ,    VarcharType . createVarcharType (  6  5  5  3  5  )  )  ;", "MaterializedResult   result    =    computeActual (  \" SELECT    *    from   test _ partitioned _ table \"  )  ;", "assertEquals ( result . getRowCount (  )  ,     0  )  ;", "@ Language (  \" SQL \"  )", "String   select    =     \"  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" SELECT \"     +     \"     ' foo '     _ string \"  )     +     \"  ,     ' bar '     _ varchar \"  )     +     \"  ,    CAST (  ' boo '    AS   CHAR (  1  0  )  )     _ char \"  )     +     \"  ,    CAST (  1    AS   BIGINT )     _ bigint \"  )     +     \"  ,     2     _ ier \"  )     +     \"  ,    CAST    (  3    AS   SMALLINT )     _ smallint \"  )     +     \"  ,    CAST    (  4    AS   TINYINT )     _ tinyint \"  )     +     \"  ,    CAST (  '  1  2  3  .  4  5  '    AS   REAL )     _ real \"  )     +     \"  ,    CAST (  '  3  .  1  4  '    AS   DOUBLE )     _ double \"  )     +     \"  ,    true    _ boolean \"  )     +     \"  ,    CAST (  '  3  .  1  4  '    AS   DECIMAL (  3  ,  2  )  )     _ decimal _ short \"  )     +     \"  ,    CAST (  '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '    AS   DECIMAL (  3  0  ,  1  0  )  )     _ decimal _ long \"  )     +     \"  ,     ' foo '     _ partition _ string \"  )     +     \"  ,     ' bar '     _ partition _ varchar \"  )     +     \"  ,    CAST (  ' boo '    AS   CHAR (  1  0  )  )     _ partition _ char \"  )     +     \"  ,    CAST (  1    AS   TINYINT )     _ partition _ tinyint \"  )     +     \"  ,    CAST (  1    AS   SMALLINT )     _ partition _ smallint \"  )     +     \"  ,     1     _ partition _ ier \"  )     +     \"  ,    CAST    (  1    AS   BIGINT )     _ partition _ bigint \"  )     +     \"  ,    true    _ partition _ boolean \"  )     +     \"  ,    CAST (  '  3  .  1  4  '    AS   DECIMAL (  3  ,  2  )  )     _ partition _ decimal _ short \"  )     +     \"  ,    CAST (  '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '    AS   DECIMAL (  3  0  ,  1  0  )  )     _ partition _ decimal _ long \"  )     +     \"  ,    CAST (  '  2  0  1  7  -  0  5  -  0  1  '    AS   DATE )     _ partition _ date \"  )     +     \"  ,    CAST (  '  2  0  1  7  -  0  5  -  0  1     1  0  :  1  2  :  3  4  '    AS   TIMESTAMP )     _ partition _ timestamp \"  )  ;", "if    ( storageFormat    =  =     ( HiveStorageFormat . AVRO )  )     {", "select    =    select . replace (  \"    CAST    (  3    AS   SMALLINT )     _ smallint ,  \"  ,     \"     3     _ smallint ,  \"  )  ;", "select    =    select . replace (  \"    CAST    (  4    AS   TINYINT )     _ tinyint ,  \"  ,     \"     4     _ tinyint ,  \"  )  ;", "}", "assertUpdate ( session ,     (  \" INSERT   INTO   test _ partitioned _ table    \"     +    select )  ,     1  )  ;", "assertQuery ( session ,     \" SELECT    *    from   test _ partitioned _ table \"  ,    select )  ;", "assertQuery ( session ,     (  \" SELECT    *    from   test _ partitioned _ table   WHERE \"     +     (  (  (  (  (  (  (  (  (  (  (  \"     ' foo '     =     _ partition _ string \"     +     \"    AND    ' bar '     =     _ partition _ varchar \"  )     +     \"    AND   CAST (  ' boo '    AS   CHAR (  1  0  )  )     =     _ partition _ char \"  )     +     \"    AND   CAST (  1    AS   TINYINT )     =     _ partition _ tinyint \"  )     +     \"    AND   CAST (  1    AS   SMALLINT )     =     _ partition _ smallint \"  )     +     \"    AND    1     =     _ partition _ ier \"  )     +     \"    AND   CAST (  1    AS   BIGINT )     =     _ partition _ bigint \"  )     +     \"    AND   true    =     _ partition _ boolean \"  )     +     \"    AND   CAST (  '  3  .  1  4  '    AS   DECIMAL (  3  ,  2  )  )     =     _ partition _ decimal _ short \"  )     +     \"    AND   CAST (  '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '    AS   DECIMAL (  3  0  ,  1  0  )  )     =     _ partition _ decimal _ long \"  )     +     \"    AND   CAST (  '  2  0  1  7  -  0  5  -  0  1  '    AS   DATE )     =     _ partition _ date \"  )     +     \"    AND   CAST (  '  2  0  1  7  -  0  5  -  0  1     1  0  :  1  2  :  3  4  '    AS   TIMESTAMP )     =     _ partition _ timestamp \"  )  )  ,    select )  ;", "assertUpdate ( session ,     \" DROP   TABLE   test _ partitioned _ table \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,     \" test _ partitioned _ table \"  )  )  ;", "}", "METHOD_END"], "methodName": ["createPartitionedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "createPartitionedTableAs ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["createPartitionedTableAs"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  \"  \"     +     (  (  \" CREATE   TABLE   test _ create _ partied _ table _ as    \"     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partied _ by    =    ARRAY [     ' SHIP _ PRIORITY '  ,     ' ORDER _ STATUS '     ]  \"  )     +     \"  )     \"  )     +     \" AS    \"  )     +     \" SELECT   orderkey   AS   order _ key ,    shippriority   AS   ship _ priority ,    orderstatus   AS   order _ status    \"  )     +     \" FROM   tpch . tiny . orders \"  ;", "assertUpdate ( session ,    createTable ,     \" SELECT   count (  *  )    from   orders \"  )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,     \" test _ create _ partied _ table _ as \"  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" ship _ priority \"  ,     \" order _ status \"  )  )  ;", "List <  ?  >    partis    =    getPartis (  \" test _ create _ partied _ table _ as \"  )  ;", "assertEquals ( partis . size (  )  ,     3  )  ;", "assertQuery ( session ,     \" SELECT    *    from   test _ create _ partied _ table _ as \"  ,     \" SELECT   orderkey ,    shippriority ,    orderstatus   FROM   orders \"  )  ;", "assertUpdate ( session ,     \" DROP   TABLE   test _ create _ partied _ table _ as \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,     \" test _ create _ partied _ table _ as \"  )  )  ;", "}", "METHOD_END"], "methodName": ["createPartitionedTableAs"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "if    ( insertOperationsSupported ( storageFormat . getFormat (  )  )  )     {", "createTableAs ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["createTableAs"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   select    =     \" SELECT \"     +     (  (  (  (  (  (  (  (  (  (  \"     ' foo '     _ varchar \"     +     \"  ,    CAST (  ' bar '    AS   CHAR (  1  0  )  )     _ char \"  )     +     \"  ,    CAST    (  1    AS   BIGINT )     _ bigint \"  )     +     \"  ,     2     _ ier \"  )     +     \"  ,    CAST    (  3    AS   SMALLINT )     _ smallint \"  )     +     \"  ,    CAST    (  4    AS   TINYINT )     _ tinyint \"  )     +     \"  ,    CAST    (  '  1  2  3  .  4  5  '    as   REAL )     _ real \"  )     +     \"  ,    CAST (  '  3  .  1  4  '    AS   DOUBLE )     _ double \"  )     +     \"  ,    true    _ boolean \"  )     +     \"  ,    CAST (  '  3  .  1  4  '    AS   DECIMAL (  3  ,  2  )  )     _ decimal _ short \"  )     +     \"  ,    CAST (  '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '    AS   DECIMAL (  3  0  ,  1  0  )  )     _ decimal _ long \"  )  ;", "if    ( storageFormat    =  =     ( HiveStorageFormat . AVRO )  )     {", "select    =    select . replace (  \"    CAST    (  3    AS   SMALLINT )     _ smallint ,  \"  ,     \"     3     _ smallint ,  \"  )  ;", "select    =    select . replace (  \"    CAST    (  4    AS   TINYINT )     _ tinyint ,  \"  ,     \"     4     _ tinyint ,  \"  )  ;", "}", "String   createTableAs    =    String . format (  \" CREATE   TABLE   test _ format _ table   WITH    ( format    =     '  % s '  )    AS    % s \"  ,    storageFormat ,    select )  ;", "assertUpdate ( session ,    createTableAs ,     1  )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,     \" test _ format _ table \"  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "assertColumnType ( tableMetadata ,     \"  _ varchar \"  ,    VarcharType . createVarcharType (  3  )  )  ;", "assertColumnType ( tableMetadata ,     \"  _ char \"  ,    CharType . createCharType (  1  0  )  )  ;", "assertQuery ( session ,     \" SELECT    _ ier ,     _ varchar ,     _ ier   from   test _ format _ table \"  ,     \" SELECT    2  ,     ' foo '  ,     2  \"  )  ;", "assertQuery ( session ,     \" SELECT    *    from   test _ format _ table \"  ,    select )  ;", "assertUpdate ( session ,     \" DROP   TABLE   test _ format _ table \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,     \" test _ format _ table \"  )  )  ;", "}", "METHOD_END"], "methodName": ["createTableAs"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "createTableLike (  \"  \"  ,    false )  ;", "createTableLike (  \" EXCLUDING   PROPERTIES \"  ,    false )  ;", "createTableLike (  \" INCLUDING   PROPERTIES \"  ,    true )  ;", "}", "METHOD_END"], "methodName": ["createTableLike"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   query    =     \"  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  \" CREATE   TABLE   test _ types _ table   AS    \"     +     \" SELECT \"  )     +     \"     ' foo '     _ varchar \"  )     +     \"  ,    cast (  ' bar '    as   varbinary )     _ varbinary \"  )     +     \"  ,    cast (  1    as   bigint )     _ bigint \"  )     +     \"  ,     2     _ ier \"  )     +     \"  ,    CAST (  '  3  .  1  4  '    AS   DOUBLE )     _ double \"  )     +     \"  ,    true    _ boolean \"  )     +     \"  ,    DATE    '  1  9  8  0  -  0  5  -  0  7  '     _ date \"  )     +     \"  ,    TIMESTAMP    '  1  9  8  0  -  0  5  -  0  7     1  1  :  2  2  :  3  3  .  4  5  6  '     _ timestamp \"  )     +     \"  ,    CAST (  '  3  .  1  4  '    AS   DECIMAL (  3  ,  2  )  )     _ decimal _ short \"  )     +     \"  ,    CAST (  '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '    AS   DECIMAL (  3  0  ,  1  0  )  )     _ decimal _ long \"  )     +     \"  ,    CAST (  ' bar '    AS   CHAR (  1  0  )  )     _ char \"  )  ;", "assertUpdate ( query ,     1  )  ;", "MaterializedResult   results    =    getQueryRunner (  )  . execute ( getSession (  )  ,     \" SELECT    *    FROM   test _ types _ table \"  )  . toTestTypes (  )  ;", "assertEquals ( results . getRowCount (  )  ,     1  )  ;", "MaterializedRow   row    =    results . getMaterializedRows (  )  . get (  0  )  ;", "assertEquals ( row . getField (  0  )  ,     \" foo \"  )  ;", "assertEquals ( row . getField (  1  )  ,     \" bar \"  . getBytes ( StandardCharsets . UTF _  8  )  )  ;", "assertEquals ( row . getField (  2  )  ,     1 L )  ;", "assertEquals ( row . getField (  3  )  ,     2  )  ;", "assertEquals ( row . getField (  4  )  ,     3  .  1  4  )  ;", "assertEquals ( row . getField (  5  )  ,    true )  ;", "assertEquals ( row . getField (  6  )  ,    LocalDate . of (  1  9  8  0  ,     5  ,     7  )  )  ;", "assertEquals ( row . getField (  7  )  ,    LocalDateTime . of (  1  9  8  0  ,     5  ,     7  ,     1  1  ,     2  2  ,     3  3  ,     4  5  6  0  0  0  0  0  0  )  )  ;", "assertEquals ( row . getField (  8  )  ,    new   BigDecimal (  \"  3  .  1  4  \"  )  )  ;", "assertEquals ( row . getField (  9  )  ,    new   BigDecimal (  \"  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  \"  )  )  ;", "assertEquals ( row . getField (  1  0  )  ,     \" bar                      \"  )  ;", "assertUpdate (  \" DROP   TABLE   test _ types _ table \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( getSession (  )  ,     \" test _ types _ table \"  )  )  ;", "}", "METHOD_END"], "methodName": ["createTableWithEveryType"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  (  (  \" CREATE   TABLE   test _ path    \"     +     (  \" WITH    (  \"     +     \" format    =     '  \"  )  )     +    storageFormat )     +     \"  '  ,  \"  )     +     \" partitioned _ by    =    ARRAY [  ' col 1  '  ]  \"  )     +     \"  )    AS    \"  )     +     \" SELECT    *    FROM    ( VALUES    \"  )     +     \"  (  0  ,     0  )  ,     (  3  ,     0  )  ,     (  6  ,     0  )  ,     \"  )     +     \"  (  1  ,     1  )  ,     (  4  ,     1  )  ,     (  7  ,     1  )  ,     \"  )     +     \"  (  2  ,     2  )  ,     (  5  ,     2  )     \"  )     +     \"     )    t ( col 0  ,    col 1  )     \"  ;", "assertUpdate ( session ,    createTable ,     8  )  ;", "assertTrue ( getQueryRunner (  )  . tableExists ( getSession (  )  ,     \" test _ path \"  )  )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,     \" test _ path \"  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "List < String >    columnNames    =    ImmutableList . of (  \" col 0  \"  ,     \" col 1  \"  ,    HiveColumnHandle . PATH _ COLUMN _ NAME )  ;", "List < ColumnMetadata >    columnMetadatas    =    tableMetadata . getColumns (  )  ;", "assertEquals ( columnMetadatas . size (  )  ,    columnNames . size (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( columnMetadatas . size (  )  )  ;    i +  +  )     {", "ColumnMetadata   columnMetadata    =    columnMetadatas . get ( i )  ;", "assertEquals ( columnMetadata . getName (  )  ,    columnNames . get ( i )  )  ;", "if    ( columnMetadata . getName (  )  . equals ( HiveColumnHandle . PATH _ COLUMN _ NAME )  )     {", "assertTrue ( columnMetadata . isHidden (  )  )  ;", "}", "}", "assertEquals ( getPartitions (  \" test _ path \"  )  . size (  )  ,     3  )  ;", "MaterializedResult   results    =    computeActual ( session ,    String . format (  \" SELECT    *  ,     \\  \"  % s \\  \"    FROM   test _ path \"  ,    HiveColumnHandle . PATH _ COLUMN _ NAME )  )  ;", "Map < er ,    String >    partitionPathMap    =    new   HashMap <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( results . getRowCount (  )  )  ;    i +  +  )     {", "MaterializedRow   row    =    results . getMaterializedRows (  )  . get ( i )  ;", "int   col 0     =     (  ( int )     ( row . getField (  0  )  )  )  ;", "int   col 1     =     (  ( int )     ( row . getField (  1  )  )  )  ;", "String   pathName    =     (  ( String )     ( row . getField (  2  )  )  )  ;", "String   parentDirectory    =    new   Path ( pathName )  . getParent (  )  . toString (  )  ;", "assertTrue (  (  ( pathName . length (  )  )     >     0  )  )  ;", "assertEquals (  (  ( int )     ( col 0     %     3  )  )  ,    col 1  )  ;", "if    ( partitionPathMap . containsKey ( col 1  )  )     {", "assertEquals ( partitionPathMap . get ( col 1  )  ,    parentDirectory )  ;", "} else    {", "partitionPathMap . put ( col 1  ,    parentDirectory )  ;", "}", "}", "assertEquals ( partitionPathMap . size (  )  ,     3  )  ;", "assertUpdate ( session ,     \" DROP   TABLE   test _ path \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,     \" test _ path \"  )  )  ;", "}", "METHOD_END"], "methodName": ["doTestPathHiddenColumn"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "Session   session    =    getSession (  )  ;", "ImmutableList . Builder <  . TestingHiveStorageFormat >    formats    =    ImmutableList . builder (  )  ;", "for    ( HiveStorageFormat   hiveStorageFormat    :    HiveStorageFormat . values (  )  )     {", "formats . add ( new    . TestingHiveStorageFormat ( session ,    hiveStorageFormat )  )  ;", "}", "formats . add ( new    . TestingHiveStorageFormat ( Session . builder ( session )  . setCatalogSessionProperty ( session . getCatalog (  )  . get (  )  ,     \" orc _ optimized _ writer _ enabled \"  ,     \" true \"  )  . build (  )  ,    HiveStorageFormat . ORC )  )  ;", "formats . add ( new    . TestingHiveStorageFormat ( Session . builder ( session )  . setCatalogSessionProperty ( session . getCatalog (  )  . get (  )  ,     \" orc _ optimized _ writer _ enabled \"  ,     \" true \"  )  . build (  )  ,    HiveStorageFormat . DWRF )  )  ;", "formats . add ( new    . TestingHiveStorageFormat ( Session . builder ( session )  . setCatalogSessionProperty ( session . getCatalog (  )  . get (  )  ,     \" parquet _ optimized _ reader _ enabled \"  ,     \" true \"  )  . build (  )  ,    HiveStorageFormat . PARQUET )  )  ;", "return   formats . build (  )  ;", "}", "METHOD_END"], "methodName": ["getAllTestingHiveStorageFormat"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "return    (  ( int )     ( getHiveTableProperty ( tableName ,     ( HiveTableLayoutHandle   table )     -  >    table . getBucketHandle (  )  . get (  )  . getBucketCount (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getBucketCount"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "Session   session    =    getSession (  )  ;", "Metadata   metadata    =     (  ( DistributedQueryRunner )     ( getQueryRunner (  )  )  )  . getCoordinator (  )  . getMetadata (  )  ;", "return   transaction ( getQueryRunner (  )  . getTransactionManager (  )  ,    getQueryRunner (  )  . getAccessControl (  )  )  . readOnly (  )  . execute ( session ,     (    transacession )     -  >     {", "Optional < TableHandle >    tableHandle    =    metadata . getTableHandle ( transacession ,    new   QualifiedObjectName ( catalog ,    TPCH _ SCHEMA ,    tableName )  )  ;", "assertTrue ( tableHandle . isPresent (  )  )  ;", "List < TableLayoutResult >    layouts    =    metadata . getLayouts ( transacession ,    tableHandle . get (  )  ,    Constraint . alwaysTrue (  )  ,    empty (  )  )  ;", "TableLayout   layout    =    getOnlyElement ( layouts )  . getLayout (  )  ;", "return   propertyGetter . apply (  (  ( HiveTableLayoutHandle )     ( layout . getHandle (  )  . getConnectorHandle (  )  )  )  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["getHiveTableProperty"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "return   Session . builder ( getSession (  )  )  . setSystemProperty (  \" task _ writer _ count \"  ,     \"  4  \"  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getParallelWriteSession"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "return   tableLayoutHandle . getPartitions (  )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["getPartitions"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "return    (  ( List <  ?  >  )     ( getHiveTableProperty ( tableName ,     ( HiveTableLayoutHandle   table )     -  >    getPartitions ( table )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getPartitions"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "Session   session    =    getSession (  )  ;", "Metadata   metadata    =     (  ( DistributedQueryRunner )     ( getQueryRunner (  )  )  )  . getCoordinator (  )  . getMetadata (  )  ;", "return   transaction ( getQueryRunner (  )  . getTransactionManager (  )  ,    getQueryRunner (  )  . getAccessControl (  )  )  . readOnly (  )  . execute ( session ,     (    transacession )     -  >     {", "Optional < TableHandle >    tableHandle    =    metadata . getTableHandle ( transacession ,    new   QualifiedObjectName ( catalog ,    schema ,    tableName )  )  ;", "assertTrue ( tableHandle . isPresent (  )  )  ;", "return   metadata . getTableMetadata ( transacession ,    tableHandle . get (  )  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["getTableMetadata"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "return   storageFormat    !  =     ( HiveStorageFormat . DWRF )  ;", "}", "METHOD_END"], "methodName": ["insertOperationsSupported"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "insertPartitionedTable ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["insertPartitionedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  \"  \"     +     (  (  (  (  (  (  (  \" CREATE   TABLE   test _ insert _ partied _ table    \"     +     \"  (  \"  )     +     \"       ORDER _ KEY   BIGINT ,  \"  )     +     \"       SHIP _ PRIORITY   INTEGER ,  \"  )     +     \"       ORDER _ STATUS   VARCHAR \"  )     +     \"  )     \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partied _ by    =    ARRAY [     ' SHIP _ PRIORITY '  ,     ' ORDER _ STATUS '     ]  \"  )     +     \"  )     \"  ;", "assertUpdate ( session ,    createTable )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,     \" test _ insert _ partied _ table \"  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" ship _ priority \"  ,     \" order _ status \"  )  )  ;", "assertQuery ( session ,     \" SHOW   PARTITIONS   FROM   test _ insert _ partied _ table \"  ,     \" SELECT   shippriority ,    orderstatus   FROM   orders   LIMIT    0  \"  )  ;", "assertUpdate ( session ,     (  \"  \"     +     (  (  \" INSERT   INTO   test _ insert _ partied _ table    \"     +     \" SELECT   orderkey ,    shippriority ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders \"  )  )  ,     \" SELECT   count (  *  )    from   orders \"  )  ;", "List <  ?  >    partis    =    getPartis (  \" test _ insert _ partied _ table \"  )  ;", "assertEquals ( partis . size (  )  ,     3  )  ;", "assertQuery ( session ,     \" SELECT    *    from   test _ insert _ partied _ table \"  ,     \" SELECT   orderkey ,    shippriority ,    orderstatus   FROM   orders \"  )  ;", "assertQuery ( session ,     \" SHOW   PARTITIONS   FROM   test _ insert _ partied _ table \"  ,     \" SELECT   DISTINCT   shippriority ,    orderstatus   FROM   orders \"  )  ;", "assertQuery ( session ,     \" SHOW   PARTITIONS   FROM   test _ insert _ partied _ table   ORDER   BY   order _ status   LIMIT    2  \"  ,     \" SELECT   DISTINCT   shippriority ,    orderstatus   FROM   orders   ORDER   BY   orderstatus   LIMIT    2  \"  )  ;", "assertQuery ( session ,     \" SHOW   PARTITIONS   FROM   test _ insert _ partied _ table   WHERE   order _ status    =     ' O '  \"  ,     \" SELECT   DISTINCT   shippriority ,    orderstatus   FROM   orders   WHERE   orderstatus    =     ' O '  \"  )  ;", "assertQueryFails ( session ,     \" SHOW   PARTITIONS   FROM   test _ insert _ partied _ table   WHERE   no _ such _ column    =     1  \"  ,     \" line    \\  \\ S *  :    Column    \\  ' no _ such _ column \\  '    cannot   be   resolved \"  )  ;", "assertQueryFails ( session ,     \" SHOW   PARTITIONS   FROM   test _ insert _ partied _ table   WHERE   orderkey    =     1  \"  ,     \" line    \\  \\ S *  :    Column    \\  ' orderkey \\  '    cannot   be   resolved \"  )  ;", "assertUpdate ( session ,     \" DROP   TABLE   test _ insert _ partied _ table \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,     \" test _ insert _ partied _ table \"  )  )  ;", "}", "METHOD_END"], "methodName": ["insertPartitionedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "if    ( insertOperationsSupported ( storageFormat . getFormat (  )  )  )     {", "insertTable ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["insertTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  \"  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" CREATE   TABLE   test _ insert _ format _ table    \"     +     \"  (  \"  )     +     \"        _ string   VARCHAR ,  \"  )     +     \"        _ varchar   VARCHAR (  6  5  5  3  5  )  ,  \"  )     +     \"        _ char   CHAR (  1  0  )  ,  \"  )     +     \"        _ bigint   BIGINT ,  \"  )     +     \"        _ ier   INTEGER ,  \"  )     +     \"        _ smallint   SMALLINT ,  \"  )     +     \"        _ tinyint   TINYINT ,  \"  )     +     \"        _ real   REAL ,  \"  )     +     \"        _ double   DOUBLE ,  \"  )     +     \"        _ boolean   BOOLEAN ,  \"  )     +     \"        _ decimal _ short   DECIMAL (  3  ,  2  )  ,  \"  )     +     \"        _ decimal _ long   DECIMAL (  3  0  ,  1  0  )  \"  )     +     \"  )     \"  )     +     \" WITH    ( format    =     '  \"  )  )     +    storageFormat )     +     \"  '  )     \"  ;", "if    ( storageFormat    =  =     ( HiveStorageFormat . AVRO )  )     {", "createTable    =    createTable . replace (  \"     _ smallint   SMALLINT ,  \"  ,     \"     _ smallint   INTEGER ,  \"  )  ;", "createTable    =    createTable . replace (  \"     _ tinyint   TINYINT ,  \"  ,     \"     _ tinyint   INTEGER ,  \"  )  ;", "}", "assertUpdate ( session ,    createTable )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,     \" test _ insert _ format _ table \"  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "assertColumnType ( tableMetadata ,     \"  _ string \"  ,    VarcharType . createUnboundedVarcharType (  )  )  ;", "assertColumnType ( tableMetadata ,     \"  _ varchar \"  ,    VarcharType . createVarcharType (  6  5  5  3  5  )  )  ;", "assertColumnType ( tableMetadata ,     \"  _ char \"  ,    CharType . createCharType (  1  0  )  )  ;", "@ Language (  \" SQL \"  )", "String   select    =     \" SELECT \"     +     (  (  (  (  (  (  (  (  (  (  (  \"     ' foo '     _ string \"     +     \"  ,     ' bar '     _ varchar \"  )     +     \"  ,    CAST (  ' boo '    AS   CHAR (  1  0  )  )     _ char \"  )     +     \"  ,     1     _ bigint \"  )     +     \"  ,    CAST (  4  2    AS   INTEGER )     _ ier \"  )     +     \"  ,    CAST (  4  3    AS   SMALLINT )     _ smallint \"  )     +     \"  ,    CAST (  4  4    AS   TINYINT )     _ tinyint \"  )     +     \"  ,    CAST (  '  1  2  3  .  4  5  '    AS   REAL )     _ real \"  )     +     \"  ,    CAST (  '  3  .  1  4  '    AS   DOUBLE )     _ double \"  )     +     \"  ,    true    _ boolean \"  )     +     \"  ,    CAST (  '  3  .  1  4  '    AS   DECIMAL (  3  ,  2  )  )     _ decimal _ short \"  )     +     \"  ,    CAST (  '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '    AS   DECIMAL (  3  0  ,  1  0  )  )     _ decimal _ long \"  )  ;", "if    ( storageFormat    =  =     ( HiveStorageFormat . AVRO )  )     {", "select    =    select . replace (  \"    CAST    (  4  3    AS   SMALLINT )     _ smallint ,  \"  ,     \"     3     _ smallint ,  \"  )  ;", "select    =    select . replace (  \"    CAST    (  4  4    AS   TINYINT )     _ tinyint ,  \"  ,     \"     4     _ tinyint ,  \"  )  ;", "}", "assertUpdate ( session ,     (  \" INSERT   INTO   test _ insert _ format _ table    \"     +    select )  ,     1  )  ;", "assertQuery ( session ,     \" SELECT    *    from   test _ insert _ format _ table \"  ,    select )  ;", "assertUpdate ( session ,     \" INSERT   INTO   test _ insert _ format _ table    (  _ tinyint ,     _ smallint ,     _ ier ,     _ bigint ,     _ real ,     _ double )    SELECT   CAST (  1    AS   TINYINT )  ,    CAST (  2    AS   SMALLINT )  ,     3  ,     4  ,    cast (  1  4  .  3 E 0    as   REAL )  ,     1  4  .  3 E 0  \"  ,     1  )  ;", "assertQuery ( session ,     \" SELECT    *    from   test _ insert _ format _ table   where    _ bigint    =     4  \"  ,     \" SELECT   null ,    null ,    null ,     4  ,     3  ,     2  ,     1  ,     1  4  .  3  ,     1  4  .  3  ,    null ,    null ,    null \"  )  ;", "assertQuery ( session ,     \" SELECT    *    from   test _ insert _ format _ table   where    _ real    =    CAST (  1  4  .  3    as   REAL )  \"  ,     \" SELECT   null ,    null ,    null ,     4  ,     3  ,     2  ,     1  ,     1  4  .  3  ,     1  4  .  3  ,    null ,    null ,    null \"  )  ;", "assertUpdate ( session ,     \" INSERT   INTO   test _ insert _ format _ table    (  _ double ,     _ bigint )    SELECT    2  .  7  2 E 0  ,     3  \"  ,     1  )  ;", "assertQuery ( session ,     \" SELECT    *    from   test _ insert _ format _ table   where    _ bigint    =     3  \"  ,     \" SELECT   null ,    null ,    null ,     3  ,    null ,    null ,    null ,    null ,     2  .  7  2  ,    null ,    null ,    null \"  )  ;", "assertUpdate ( session ,     \" INSERT   INTO   test _ insert _ format _ table    (  _ decimal _ short ,     _ decimal _ long )    SELECT   DECIMAL    '  2  .  7  2  '  ,    DECIMAL    '  9  8  7  6  5  4  3  2  1  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '  \"  ,     1  )  ;", "assertQuery ( session ,     \" SELECT    *    from   test _ insert _ format _ table   where    _ decimal _ long    =    DECIMAL    '  9  8  7  6  5  4  3  2  1  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '  \"  ,     \" SELECT   null ,    null ,    null ,    null ,    null ,    null ,    null ,    null ,    null ,    null ,     2  .  7  2  ,     9  8  7  6  5  4  3  2  1  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  \"  )  ;", "assertUpdate ( session ,     \" DROP   TABLE   test _ insert _ format _ table \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,     \" test _ insert _ format _ table \"  )  )  ;", "}", "METHOD_END"], "methodName": ["insertTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "throw   new   TestHiveIntegrationSmokeTest . RollbackException (  )  ;", "}", "METHOD_END"], "methodName": ["rollback"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   TABLE   tmp _ array 1    AS   SELECT   ARRAY [  1  ,     2  ,    NULL ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  2  ]    FROM   tmp _ array 1  \"  ,     \" SELECT    2  \"  )  ;", "assertQuery (  \" SELECT   col [  3  ]    FROM   tmp _ array 1  \"  ,     \" SELECT   NULL \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 2    AS   SELECT   ARRAY [  1  .  0 E 0  ,     2  .  5 E 0  ,     3  .  5 E 0  ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  2  ]    FROM   tmp _ array 2  \"  ,     \" SELECT    2  .  5  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 3    AS   SELECT   ARRAY [  ' puppies '  ,     ' kittens '  ,    NULL ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  2  ]    FROM   tmp _ array 3  \"  ,     \" SELECT    ' kittens '  \"  )  ;", "assertQuery (  \" SELECT   col [  3  ]    FROM   tmp _ array 3  \"  ,     \" SELECT   NULL \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 4    AS   SELECT   ARRAY [ TRUE ,    NULL ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  1  ]    FROM   tmp _ array 4  \"  ,     \" SELECT   TRUE \"  )  ;", "assertQuery (  \" SELECT   col [  2  ]    FROM   tmp _ array 4  \"  ,     \" SELECT   NULL \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 5    AS   SELECT   ARRAY [ ARRAY [  1  ,     2  ]  ,    NULL ,    ARRAY [  3  ,     4  ]  ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  1  ]  [  2  ]    FROM   tmp _ array 5  \"  ,     \" SELECT    2  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 6    AS   SELECT   ARRAY [ ARRAY [  \\  '  \\  \" hi \\  \"  \\  '  ]  ,    NULL ,    ARRAY [  \\  ' puppies \\  '  ]  ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  1  ]  [  1  ]    FROM   tmp _ array 6  \"  ,     \" SELECT    \\  '  \\  \" hi \\  \"  \\  '  \"  )  ;", "assertQuery (  \" SELECT   col [  3  ]  [  1  ]    FROM   tmp _ array 6  \"  ,     \" SELECT    ' puppies '  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 7    AS   SELECT   ARRAY [ ARRAY [ INTEGER '  1  '  ,    INTEGER '  2  '  ]  ,    NULL ,    ARRAY [ INTEGER '  3  '  ,    INTEGER '  4  '  ]  ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  1  ]  [  2  ]    FROM   tmp _ array 7  \"  ,     \" SELECT    2  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 8    AS   SELECT   ARRAY [ ARRAY [ SMALLINT '  1  '  ,    SMALLINT '  2  '  ]  ,    NULL ,    ARRAY [ SMALLINT '  3  '  ,    SMALLINT '  4  '  ]  ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  1  ]  [  2  ]    FROM   tmp _ array 8  \"  ,     \" SELECT    2  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 9    AS   SELECT   ARRAY [ ARRAY [ TINYINT '  1  '  ,    TINYINT '  2  '  ]  ,    NULL ,    ARRAY [ TINYINT '  3  '  ,    TINYINT '  4  '  ]  ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  1  ]  [  2  ]    FROM   tmp _ array 9  \"  ,     \" SELECT    2  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 1  0    AS   SELECT   ARRAY [ ARRAY [ DECIMAL    '  3  .  1  4  '  ]  ]    AS   col 1  ,    ARRAY [ ARRAY [ DECIMAL    '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '  ]  ]    AS   col 2  \"  ,     1  )  ;", "assertQuery (  \" SELECT   col 1  [  1  ]  [  1  ]    FROM   tmp _ array 1  0  \"  ,     \" SELECT    3  .  1  4  \"  )  ;", "assertQuery (  \" SELECT   col 2  [  1  ]  [  1  ]    FROM   tmp _ array 1  0  \"  ,     \" SELECT    1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 1  3    AS   SELECT   ARRAY [ ARRAY [ REAL '  1  .  2  3  4  '  ,    REAL '  2  .  3  4  5  '  ]  ,    NULL ,    ARRAY [ REAL '  3  .  4  5  6  '  ,    REAL '  4  .  5  6  7  '  ]  ]    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  1  ]  [  2  ]    FROM   tmp _ array 1  3  \"  ,     \" SELECT    2  .  3  4  5  \"  )  ;", "}", "METHOD_END"], "methodName": ["testArrays"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertQueryFails (  \" CREATE   TABLE   test _ avro _ types    ( x   map ( bigint ,    bigint )  )    WITH    ( format    =     ' AVRO '  )  \"  ,     \" Column   x   has   a   non - varchar   map   key ,    which   is   not   supported   by   Avro \"  )  ;", "assertQueryFails (  \" CREATE   TABLE   test _ avro _ types    ( x   tinyint )    WITH    ( format    =     ' AVRO '  )  \"  ,     \" Column   x   is   tinyint ,    which   is   not   supported   by   Avro .    Use   ier   instead .  \"  )  ;", "assertQueryFails (  \" CREATE   TABLE   test _ avro _ types    ( x   smallint )    WITH    ( format    =     ' AVRO '  )  \"  ,     \" Column   x   is   smallint ,    which   is   not   supported   by   Avro .    Use   ier   instead .  \"  )  ;", "assertQueryFails (  \" CREATE   TABLE   test _ avro _ types   WITH    ( format    =     ' AVRO '  )    AS   SELECT   cast (  4  2    AS   smallint )    z \"  ,     \" Column   z   is   smallint ,    which   is   not   supported   by   Avro .    Use   ier   instead .  \"  )  ;", "}", "METHOD_END"], "methodName": ["testAvroTypeValidation"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   createTable    =     \" CREATE   TABLE   test _ bucket _ hidden _ column    \"     +     (  (  (  (  (  (  (  (  \" WITH    (  \"     +     \" bucketed _ by    =    ARRAY [  ' col 0  '  ]  ,  \"  )     +     \" bucket _ count    =     2  \"  )     +     \"  )    AS    \"  )     +     \" SELECT    *    FROM    ( VALUES    \"  )     +     \"  (  0  ,     1  1  )  ,     (  1  ,     1  2  )  ,     (  2  ,     1  3  )  ,     \"  )     +     \"  (  3  ,     1  4  )  ,     (  4  ,     1  5  )  ,     (  5  ,     1  6  )  ,     \"  )     +     \"  (  6  ,     1  7  )  ,     (  7  ,     1  8  )  ,     (  8  ,     1  9  )  \"  )     +     \"     )    t    ( col 0  ,    col 1  )     \"  )  ;", "assertUpdate ( createTable ,     9  )  ;", "assertTrue ( getQueryRunner (  )  . tableExists ( getSession (  )  ,     \" test _ bucket _ hidden _ column \"  )  )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    QueryRunner . TPCH _ SCHEMA ,     \" test _ bucket _ hidden _ column \"  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( TableProperties . BUCKETED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" col 0  \"  )  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( TableProperties . BUCKET _ COUNT _ PROPERTY )  ,     2  )  ;", "List < String >    columnNames    =    ImmutableList . of (  \" col 0  \"  ,     \" col 1  \"  ,    ColumnHandle . PATH _ COLUMN _ NAME ,    ColumnHandle . BUCKET _ COLUMN _ NAME )  ;", "List < ColumnMetadata >    columnMetadatas    =    tableMetadata . getColumns (  )  ;", "assertEquals ( columnMetadatas . size (  )  ,    columnNames . size (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( columnMetadatas . size (  )  )  ;    i +  +  )     {", "ColumnMetadata   columnMetadata    =    columnMetadatas . get ( i )  ;", "assertEquals ( columnMetadata . getName (  )  ,    columnNames . get ( i )  )  ;", "if    ( columnMetadata . getName (  )  . equals ( ColumnHandle . BUCKET _ COLUMN _ NAME )  )     {", "assertTrue ( columnMetadata . isHidden (  )  )  ;", "}", "}", "assertEquals ( getBucketCount (  \" test _ bucket _ hidden _ column \"  )  ,     2  )  ;", "MaterializedResult   results    =    computeActual ( String . format (  \" SELECT    *  ,     \\  \"  %  1  $ s \\  \"    FROM   test _ bucket _ hidden _ column   WHERE    \\  \"  %  1  $ s \\  \"     =     1  \"  ,    ColumnHandle . BUCKET _ COLUMN _ NAME )  )  ;", "for    ( int   i    =     0  ;    i    <     ( results . getRowCount (  )  )  ;    i +  +  )     {", "MaterializedRow   row    =    results . getMaterializedRows (  )  . get ( i )  ;", "int   col 0     =     (  ( int )     ( row . getField (  0  )  )  )  ;", "int   col 1     =     (  ( int )     ( row . getField (  1  )  )  )  ;", "int   bucket    =     (  ( int )     ( row . getField (  2  )  )  )  ;", "assertEquals ( col 1  ,     ( col 0     +     1  1  )  )  ;", "assertTrue (  (  ( col 1     %     2  )     =  =     0  )  )  ;", "assertEquals ( bucket ,     ( col 0     %     2  )  )  ;", "}", "assertEquals ( results . getRowCount (  )  ,     4  )  ;", "assertUpdate (  \" DROP   TABLE   test _ bucket _ hidden _ column \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( getSession (  )  ,     \" test _ bucket _ hidden _ column \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBucketHiddenColumn"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   bucketedCatalog    =    bucketedSession . getCatalog (  )  . get (  )  ;", "String   bucketedSchema    =    bucketedSession . getSchema (  )  . get (  )  ;", "TableMetadata   ordersTableMetadata    =    getTableMetadata ( bucketedCatalog ,    bucketedSchema ,     \" orders \"  )  ;", "assertEquals ( ordersTableMetadata . getMetadata (  )  . getProperties (  )  . get ( TableProperties . BUCKETED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" custkey \"  )  )  ;", "assertEquals ( ordersTableMetadata . getMetadata (  )  . getProperties (  )  . get ( TableProperties . BUCKET _ COUNT _ PROPERTY )  ,     1  1  )  ;", "TableMetadata   customerTableMetadata    =    getTableMetadata ( bucketedCatalog ,    bucketedSchema ,     \" customer \"  )  ;", "assertEquals ( customerTableMetadata . getMetadata (  )  . getProperties (  )  . get ( TableProperties . BUCKETED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" custkey \"  )  )  ;", "assertEquals ( customerTableMetadata . getMetadata (  )  . getProperties (  )  . get ( TableProperties . BUCKET _ COUNT _ PROPERTY )  ,     1  1  )  ;", "}", "METHOD_END"], "methodName": ["testBucketedCatalog"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertQuery ( bucketedSession ,     \" select   count (  *  )    a   from   orders   t 1    join   orders   t 2    on   t 1  . custkey = t 2  . custkey \"  )  ;", "assertQuery ( bucketedSession ,     \" select   count (  *  )    a   from   orders   t 1    join   customer   t 2    on   t 1  . custkey = t 2  . custkey \"  ,     \" SELECT   count (  *  )    from   orders \"  )  ;", "assertQuery ( bucketedSession ,     \" select   count ( distinct   custkey )    from   orders \"  )  ;", "assertQuery ( Session . builder ( bucketedSession )  . setSystemProperty (  \" task _ writer _ count \"  ,     \"  1  \"  )  . build (  )  ,     \" SELECT   custkey ,    COUNT (  *  )    FROM   orders   GROUP   BY   custkey \"  )  ;", "assertQuery ( Session . builder ( bucketedSession )  . setSystemProperty (  \" task _ writer _ count \"  ,     \"  4  \"  )  . build (  )  ,     \" SELECT   custkey ,    COUNT (  *  )    FROM   orders   GROUP   BY   custkey \"  )  ;", "}", "METHOD_END"], "methodName": ["testBucketedExecution"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ cast _ null _ to _ column _ types \"  ;", "Session   session    =    Session . builder ( getSession (  )  )  . setCatalogSessionProperty ( catalog ,     \" orc _ optimized _ writer _ enabled \"  ,     \" true \"  )  . build (  )  ;", "assertUpdate ( session ,     (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     (  \"  )     +     \"       col 1    bigint ,  \"  )     +     \"       col 2    map ( bigint ,    bigint )  ,  \"  )     +     \"       parti _ key   varchar )  \"  )     +     \" WITH    (  \"  )     +     \"       format    =     ' ORC '  ,     \"  )     +     \"       partied _ by    =    ARRAY [     ' parti _ key '     ]     \"  )     +     \"  )  \"  )  )  ;", "assertUpdate ( session ,    String . format (  \" INSERT   INTO    % s    ( col 1  )    VALUES    (  1  )  ,     (  2  )  ,     (  3  )  \"  ,    tableName )  ,     3  )  ;", "assertUpdate (  (  \" DROP   TABLE    \"     +    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testCastNullToColumnTypes"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  (  \" CREATE   TABLE   tmp _ complex 1    AS   SELECT    \"     +     \" ARRAY    [ MAP ( ARRAY [  ' a '  ,     ' b '  ]  ,    ARRAY [  2  .  0 E 0  ,     4  .  0 E 0  ]  )  ,    MAP ( ARRAY [  ' c '  ,     ' d '  ]  ,    ARRAY [  1  2  .  0 E 0  ,     1  4  .  0 E 0  ]  )  ]    AS   a \"  )  ,     1  )  ;", "assertQuery (  \" SELECT   a [  1  ]  [  ' a '  ]  ,    a [  2  ]  [  ' d '  ]    FROM   tmp _ complex 1  \"  ,     \" SELECT    2  .  0  ,     1  4  .  0  \"  )  ;", "}", "METHOD_END"], "methodName": ["testComplex"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "File   tempDir    =    createTempDir (  )  ;", "File   dataFile    =    new   File ( tempDir ,     \" test . txt \"  )  ;", "Files . write (  \" hello \\ nworld \\ n \"  ,    dataFile ,    StandardCharsets . UTF _  8  )  ;", "@ Language (  \" SQL \"  )", "String   createTableSql    =    String . format (  (  \"  \"     +     (  (  (  (  (  (  \" CREATE   TABLE    % s .  % s . test _ create _ external    (  \\ n \"     +     \"          name   varchar \\ n \"  )     +     \"  )  \\ n \"  )     +     \" WITH    (  \\ n \"  )     +     \"          external _ loc    =     \\  '  % s \\  '  ,  \\ n \"  )     +     \"          format    =     \\  ' TEXTFILE \\  '  \\ n \"  )     +     \"  )  \"  )  )  ,    getSession (  )  . getCatalog (  )  . get (  )  ,    getSession (  )  . getSchema (  )  . get (  )  ,    new   Path ( tempDir . toURI (  )  . toASCIIString (  )  )  . toString (  )  )  ;", "assertUpdate ( createTableSql )  ;", "MaterializedResult   actual    =    computeActual (  \" SHOW   CREATE   TABLE   test _ create _ external \"  )  ;", "assertEquals ( actual . getOnlyValue (  )  ,    createTableSql )  ;", "actual    =    computeActual (  \" SELECT   name   FROM   test _ create _ external \"  )  ;", "assertEquals ( actual . getOnlyColumnAsSet (  )  ,    ImmutableSet . of (  \" hello \"  ,     \" world \"  )  )  ;", "assertUpdate (  \" DROP   TABLE   test _ create _ external \"  )  ;", "assertFile ( dataFile )  ;", "deleteRecursively ( tempDir . toPath (  )  ,    ALLOW _ INSECURE )  ;", "}", "METHOD_END"], "methodName": ["testCreateExternalTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "testCreateInvalidBucketedTable ( HiveStorageFormat . RCBINARY )  ;", "}", "METHOD_END"], "methodName": ["testCreateInvalidBucketedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ create _ invalid _ bucketed _ table \"  ;", "try    {", "computeActual (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     (  \"  )     +     \"       a   BIGINT ,  \"  )     +     \"       b   DOUBLE ,  \"  )     +     \"       p   VARCHAR \"  )     +     \"  )    WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partied _ by    =    ARRAY [     ' p '     ]  ,     \"  )     +     \" bucketed _ by    =    ARRAY [     ' a '  ,     ' c '     ]  ,     \"  )     +     \" bucket _ count    =     1  1     \"  )     +     \"  )  \"  )  )  ;", "fail (  )  ;", "}    catch    ( Excep   e )     {", "assertEquals ( e . getMessage (  )  ,     \" Bucketing   columns    [ c ]    not   present   in   schema \"  )  ;", "}", "try    {", "computeActual (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partied _ by    =    ARRAY [     ' orderstatus '     ]  ,     \"  )     +     \" bucketed _ by    =    ARRAY [     ' custkey '  ,     ' custkey 3  '     ]  ,     \"  )     +     \" bucket _ count    =     1  1     \"  )     +     \"  )     \"  )     +     \" AS    \"  )     +     \" SELECT   custkey ,    custkey   AS   custkey 2  ,    comment ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders \"  )  )  ;", "fail (  )  ;", "}    catch    ( Excep   e )     {", "assertEquals ( e . getMessage (  )  ,     \" INSERT   must   write   all   distribu   columns :     [ custkey ,    custkey 3  ]  \"  )  ;", "}", "assertFalse ( getQueryRunner (  )  . tableExists ( getSession (  )  ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateInvalidBucketedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "testCreatePartitionedBucketedTableAs ( HiveStorageFormat . RCBINARY )  ;", "}", "METHOD_END"], "methodName": ["testCreatePartitionedBucketedTableAs"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ create _ partitioned _ bucketed _ table _ as \"  ;", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partitioned _ by    =    ARRAY [     ' orderstatus '     ]  ,     \"  )     +     \" bucketed _ by    =    ARRAY [     ' custkey '  ,     ' custkey 2  '     ]  ,     \"  )     +     \" bucket _ count    =     1  1     \"  )     +     \"  )     \"  )     +     \" AS    \"  )     +     \" SELECT   custkey ,    custkey   AS   custkey 2  ,    comment ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders \"  ;", "assertUpdate ( getParallelWriteSession (  )  ,    createTable ,     \" SELECT   count (  *  )    from   orders \"  )  ;", "verifyPartitionedBucketedTable ( storageFormat ,    tableName )  ;", "assertUpdate (  (  \" DROP   TABLE    \"     +    tableName )  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( getSession (  )  ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testCreatePartitionedBucketedTableAs"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "testCreatePartitionedBucketedTableAsFewRows ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreatePartitionedBucketedTableAsFewRows"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ create _ partitioned _ bucketed _ table _ as _ few _ rows \"  ;", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partitioned _ by    =    ARRAY [     ' partition _ key '     ]  ,     \"  )     +     \" bucketed _ by    =    ARRAY [     ' bucket _ key '     ]  ,     \"  )     +     \" bucket _ count    =     1  1     \"  )     +     \"  )     \"  )     +     \" AS    \"  )     +     \" SELECT    *     \"  )     +     \" FROM    (  \"  )     +     \" VALUES    \"  )     +     \"        ( VARCHAR    ' a '  ,    VARCHAR    ' b '  ,    VARCHAR    ' c '  )  ,     \"  )     +     \"        (  ' aa '  ,     ' bb '  ,     ' cc '  )  ,     \"  )     +     \"        (  ' aaa '  ,     ' bbb '  ,     ' ccc '  )  \"  )     +     \"  )    t ( bucket _ key ,    col ,    partition _ key )  \"  ;", "assertUpdate ( getParallelWriteSession (  )  ,    createTable ,     3  )  ;", "verifyPartitionedBucketedTableAsFewRows ( storageFormat ,    tableName )  ;", "try    {", "assertUpdate ( session ,     (  (  \" INSERT   INTO    \"     +    tableName )     +     \"    VALUES    (  ' a 0  '  ,     ' b 0  '  ,     ' c '  )  \"  )  ,     1  )  ;", "fail (  \" expected   failure \"  )  ;", "}    catch    ( Exception   e )     {", "assertEquals ( e . getMessage (  )  ,     \" Cannot   insert   into   existing   partition   of   bucketed   Hive   table :    partition _ key = c \"  )  ;", "}", "assertUpdate ( session ,     (  \" DROP   TABLE    \"     +    tableName )  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testCreatePartitionedBucketedTableAsFewRows"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "testCreatePartitionedBucketedTableAsWithUnionAll ( HiveStorageFormat . RCBINARY )  ;", "}", "METHOD_END"], "methodName": ["testCreatePartitionedBucketedTableAsWithUnionAll"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ create _ partitioned _ bucketed _ table _ as _ with _ union _ all \"  ;", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partitioned _ by    =    ARRAY [     ' orderstatus '     ]  ,     \"  )     +     \" bucketed _ by    =    ARRAY [     ' custkey '  ,     ' custkey 2  '     ]  ,     \"  )     +     \" bucket _ count    =     1  1     \"  )     +     \"  )     \"  )     +     \" AS    \"  )     +     \" SELECT   custkey ,    custkey   AS   custkey 2  ,    comment ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders    \"  )     +     \" WHERE   length ( comment )     %     2     =     0     \"  )     +     \" UNION   ALL    \"  )     +     \" SELECT   custkey ,    custkey   AS   custkey 2  ,    comment ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders    \"  )     +     \" WHERE   length ( comment )     %     2     =     1  \"  ;", "assertUpdate ( getParallelWriteSession (  )  ,    createTable ,     \" SELECT   count (  *  )    from   orders \"  )  ;", "verifyPartitionedBucketedTable ( storageFormat ,    tableName )  ;", "assertUpdate (  (  \" DROP   TABLE    \"     +    tableName )  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( getSession (  )  ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testCreatePartitionedBucketedTableAsWithUnionAll"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  (  \"  \"     +     (  (  (  (  \" CREATE   TABLE   test _ create _ table _ as _ invalid _ column _ ordering    \"     +     \" WITH    ( partitioned _ by    =    ARRAY [  ' SHIP _ PRIORITY '  ,     ' ORDER _ STATUS '  ]  )     \"  )     +     \" AS    \"  )     +     \" SELECT   shippriority   AS   ship _ priority ,    orderkey   AS   order _ key ,    orderstatus   AS   order _ status    \"  )     +     \" FROM   tpch . tiny . orders \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreatePartitionedTableAsInvalidColumnOrdering"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  (  \"  \"     +     (  (  \" CREATE   TABLE   test _ create _ table _ invalid _ column _ ordering \\ n \"     +     \"  ( grape   bigint ,    apple   varchar ,    orange   bigint ,    pear   varchar )  \\ n \"  )     +     \" WITH    ( partitioned _ by    =    ARRAY [  ' apple '  ]  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreatePartitionedTableInvalidColumnOrdering"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  (  \"  \"     +     (  (  \" CREATE   TABLE   test _ create _ table _ nonexistent _ partition _ columns \\ n \"     +     \"  ( grape   bigint ,    apple   varchar ,    orange   bigint ,    pear   varchar )  \\ n \"  )     +     \" WITH    ( partitioned _ by    =    ARRAY [  ' dragonfruit '  ]  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateTableNonExistentPartitionColumns"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   TABLE   test _ create _ table _ non _ supported _ varchar _ column    ( apple   varchar (  6  5  5  3  6  )  )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testCreateTableNonSupportedVarcharColumn"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  (  \"  \"     +     (  (  \" CREATE   TABLE   test _ create _ table _ only _ partition _ columns \\ n \"     +     \"  ( grape   bigint ,    apple   varchar ,    orange   bigint ,    pear   varchar )  \\ n \"  )     +     \" WITH    ( partitioned _ by    =    ARRAY [  ' grape '  ,     ' apple '  ,     ' orange '  ,     ' pear '  ]  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateTableOnlyPartitionColumns"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   TABLE   test _ delete _ unpartitioned   AS   SELECT   orderstatus   FROM   tpch . tiny . orders \"  ,     \" SELECT   count (  *  )    from   orders \"  )  ;", "assertUpdate (  \" DELETE   FROM   test _ delete _ unpartitioned \"  )  ;", "MaterializedResult   result    =    computeActual (  \" SELECT    *    from   test _ delete _ unpartitioned \"  )  ;", "assertEquals ( result . getRowCount (  )  ,     0  )  ;", "assertUpdate (  \" DROP   TABLE   test _ delete _ unpartitioned \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( getSession (  )  ,     \" test _ delete _ unpartitioned \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteFromUnpartitionedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   createTable    =     \"  \"     +     (  (  (  (  (  \" CREATE   TABLE   test _ drop _ column \\ n \"     +     \" WITH    (  \\ n \"  )     +     \"       partied _ by    =    ARRAY    [  \\  ' orderstatus \\  '  ]  \\ n \"  )     +     \"  )  \\ n \"  )     +     \" AS \\ n \"  )     +     \" SELECT   custkey ,    orderkey ,    orderstatus   FROM   orders \"  )  ;", "assertUpdate ( createTable ,     \" SELECT   count (  *  )    FROM   orders \"  )  ;", "assertQuery (  \" SELECT   orderkey ,    orderstatus   FROM   test _ drop _ column \"  ,     \" SELECT   orderkey ,    orderstatus   FROM   orders \"  )  ;", "assertQueryFails (  \" ALTER   TABLE   test _ drop _ column   DROP   COLUMN    \\  \"  $ path \\  \"  \"  ,     \"  .  *    Cannot   drop   hidden   column \"  )  ;", "assertQueryFails (  \" ALTER   TABLE   test _ drop _ column   DROP   COLUMN   orderstatus \"  ,     \" Cannot   drop   parti   columns \"  )  ;", "assertUpdate (  \" ALTER   TABLE   test _ drop _ column   DROP   COLUMN   orderkey \"  )  ;", "assertQueryFails (  \" ALTER   TABLE   test _ drop _ column   DROP   COLUMN   custkey \"  ,     \" Cannot   drop   the   only   non - parti   column   in   a   table \"  )  ;", "assertQuery (  \" SELECT    *    FROM   test _ drop _ column \"  ,     \" SELECT   custkey ,    orderstatus   FROM   orders \"  )  ;", "assertUpdate (  \" DROP   TABLE   test _ drop _ column \"  )  ;", "}", "METHOD_END"], "methodName": ["testDropColumn"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "try    {", "assertUpdate (  (  \" CREATE   TABLE   test _ grouped _ join 1  \\ n \"     +     (  \" WITH    ( bucket _ count    =     1  3  ,    bucketed _ by    =    ARRAY [  \\  ' key 1  \\  '  ]  )    AS \\ n \"     +     \" SELECT   orderkey   key 1  ,    ment   value 1    FROM   orders \"  )  )  ,     1  5  0  0  0  )  ;", "assertUpdate (  (  \" CREATE   TABLE   test _ grouped _ join 2  \\ n \"     +     (  \" WITH    ( bucket _ count    =     1  3  ,    bucketed _ by    =    ARRAY [  \\  ' key 2  \\  '  ]  )    AS \\ n \"     +     \" SELECT   orderkey   key 2  ,    ment   value 2    FROM   orders \"  )  )  ,     1  5  0  0  0  )  ;", "assertUpdate (  (  \" CREATE   TABLE   test _ grouped _ join 3  \\ n \"     +     (  \" WITH    ( bucket _ count    =     1  3  ,    bucketed _ by    =    ARRAY [  \\  ' key 3  \\  '  ]  )    AS \\ n \"     +     \" SELECT   orderkey   key 3  ,    ment   value 3    FROM   orders \"  )  )  ,     1  5  0  0  0  )  ;", "assertUpdate (  (  \" CREATE   TABLE   test _ grouped _ joinN   AS \\ n \"     +     \" SELECT   orderkey   keyN ,    ment   valueN   FROM   orders \"  )  ,     1  5  0  0  0  )  ;", "assertUpdate (  (  \" CREATE   TABLE   test _ grouped _ joinDual \\ n \"     +     (  \" WITH    ( bucket _ count    =     1  3  ,    bucketed _ by    =    ARRAY [  \\  ' keyD \\  '  ]  )    AS \\ n \"     +     \" SELECT   orderkey   keyD ,    ment   valueD   FROM   orders   CROSS   JOIN   UNNEST ( repeat ( NULL ,     2  )  )  \"  )  )  ,     3  0  0  0  0  )  ;", "Session   notColocated    =    Session . builder ( getSession (  )  )  . setSystemProperty ( SystemSessionProperties . COLOCATED _ JOIN ,     \" false \"  )  . build (  )  ;", "Session   colocatedAllGroupsAtOnce    =    Session . builder ( getSession (  )  )  . setSystemProperty ( SystemSessionProperties . COLOCATED _ JOIN ,     \" true \"  )  . setSystemProperty ( SystemSessionProperties . CONCURRENT _ LIFESPANS _ PER _ NODE ,     \"  -  1  \"  )  . build (  )  ;", "Session   colocatedOneGroupAtATime    =    Session . builder ( getSession (  )  )  . setSystemProperty ( SystemSessionProperties . COLOCATED _ JOIN ,     \" true \"  )  . setSystemProperty ( SystemSessionProperties . CONCURRENT _ LIFESPANS _ PER _ NODE ,     \"  1  \"  )  . build (  )  ;", "@ Language (  \" SQL \"  )", "String   joinThreeBucketedTable    =     \" SELECT   key 1  ,    value 1  ,    key 2  ,    value 2  ,    key 3  ,    value 3  \\ n \"     +     (  (  (  (  \" FROM   test _ grouped _ join 1  \\ n \"     +     \" JOIN   test _ grouped _ join 2  \\ n \"  )     +     \" ON   key 1     =    key 2  \\ n \"  )     +     \" JOIN   test _ grouped _ join 3  \\ n \"  )     +     \" ON   key 2     =    key 3  \"  )  ;", "@ Language (  \" SQL \"  )", "String   joinThreeMixedTable    =     \" SELECT   key 1  ,    value 1  ,    key 2  ,    value 2  ,    keyN ,    valueN \\ n \"     +     (  (  (  (  \" FROM   test _ grouped _ join 1  \\ n \"     +     \" JOIN   test _ grouped _ join 2  \\ n \"  )     +     \" ON   key 1     =    key 2  \\ n \"  )     +     \" JOIN   test _ grouped _ joinN \\ n \"  )     +     \" ON   key 2     =    keyN \"  )  ;", "@ Language (  \" SQL \"  )", "String   expectedJoinQuery    =     \" SELECT   orderkey ,    ment ,    orderkey ,    ment ,    orderkey ,    ment   from   orders \"  ;", "@ Language (  \" SQL \"  )", "String   leftJoinBucketedTable    =     \" SELECT   key 1  ,    value 1  ,    key 2  ,    value 2  \\ n \"     +     (  (  \" FROM   test _ grouped _ join 1  \\ n \"     +     \" LEFT   JOIN    ( SELECT    *    FROM   test _ grouped _ join 2    WHERE   key 2     %     2     =     0  )  \\ n \"  )     +     \" ON   key 1     =    key 2  \"  )  ;", "@ Language (  \" SQL \"  )", "String   rightJoinBucketedTable    =     \" SELECT   key 1  ,    value 1  ,    key 2  ,    value 2  \\ n \"     +     (  (  \" FROM    ( SELECT    *    FROM   test _ grouped _ join 2    WHERE   key 2     %     2     =     0  )  \\ n \"     +     \" RIGHT   JOIN   test _ grouped _ join 1  \\ n \"  )     +     \" ON   key 1     =    key 2  \"  )  ;", "@ Language (  \" SQL \"  )", "String   expectedOuterJoinQuery    =     \" SELECT   orderkey ,    ment ,    CASE   mod ( orderkey ,     2  )    WHEN    0    THEN   orderkey   END ,    CASE   mod ( orderkey ,     2  )    WHEN    0    THEN   ment   END   from   orders \"  ;", "assertQuery ( notColocated ,    joinThreeBucketedTable ,    expectedJoinQuery )  ;", "assertQuery ( notColocated ,    leftJoinBucketedTable ,    expectedOuterJoinQuery )  ;", "assertQuery ( notColocated ,    rightJoinBucketedTable ,    expectedOuterJoinQuery )  ;", "assertQuery ( colocatedAllGroupsAtOnce ,    joinThreeBucketedTable ,    expectedJoinQuery )  ;", "assertQuery ( colocatedAllGroupsAtOnce ,    joinThreeMixedTable ,    expectedJoinQuery )  ;", "assertQuery ( colocatedOneGroupAtATime ,    joinThreeBucketedTable ,    expectedJoinQuery )  ;", "assertQuery ( colocatedOneGroupAtATime ,    joinThreeMixedTable ,    expectedJoinQuery )  ;", "assertQuery ( colocatedAllGroupsAtOnce ,    leftJoinBucketedTable ,    expectedOuterJoinQuery )  ;", "assertQuery ( colocatedAllGroupsAtOnce ,    rightJoinBucketedTable ,    expectedOuterJoinQuery )  ;", "assertQuery ( colocatedOneGroupAtATime ,    leftJoinBucketedTable ,    expectedOuterJoinQuery )  ;", "assertQuery ( colocatedOneGroupAtATime ,    rightJoinBucketedTable ,    expectedOuterJoinQuery )  ;", "@ Language (  \" SQL \"  )", "String   groupBySingleBucketedTable    =     \" SELECT \\ n \"     +     (  (  (  (  \"       keyD ,  \\ n \"     +     \"       count ( valueD )  \\ n \"  )     +     \" FROM \\ n \"  )     +     \"       test _ grouped _ joinDual \\ n \"  )     +     \" GROUP   BY   keyD \"  )  ;", "@ Language (  \" SQL \"  )", "String   expectedSingleGroupByQuery    =     \" SELECT   orderkey ,     2    from   orders \"  ;", "@ Language (  \" SQL \"  )", "String   groupByThreeBucketedTable    =     \" SELECT \\ n \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"       key \\ n \"     +     \"  ,    arbitrary ( value 1  )  \\ n \"  )     +     \"  ,    arbitrary ( value 2  )  \\ n \"  )     +     \"  ,    arbitrary ( value 3  )  \\ n \"  )     +     \" FROM    (  \\ n \"  )     +     \"       SELECT   key 1    key ,    value 1  ,    NULL   value 2  ,    NULL   value 3  \\ n \"  )     +     \"       FROM   test _ grouped _ join 1  \\ n \"  )     +     \" UNION   ALL \\ n \"  )     +     \"       SELECT   key 2    key ,    NULL   value 1  ,    value 2  ,    NULL   value 3  \\ n \"  )     +     \"       FROM   test _ grouped _ join 2  \\ n \"  )     +     \"       WHERE   key 2     %     2     =     0  \\ n \"  )     +     \" UNION   ALL \\ n \"  )     +     \"       SELECT   key 3    key ,    NULL   value 1  ,    NULL   value 2  ,    value 3  \\ n \"  )     +     \"       FROM   test _ grouped _ join 3  \\ n \"  )     +     \"       WHERE   key 3     %     3     =     0  \\ n \"  )     +     \"  )  \\ n \"  )     +     \" GROUP   BY   key \"  )  ;", "@ Language (  \" SQL \"  )", "String   groupByThreeMixedTable    =     \" SELECT \\ n \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"       key \\ n \"     +     \"  ,    arbitrary ( value 1  )  \\ n \"  )     +     \"  ,    arbitrary ( value 2  )  \\ n \"  )     +     \"  ,    arbitrary ( valueN )  \\ n \"  )     +     \" FROM    (  \\ n \"  )     +     \"       SELECT   key 1    key ,    value 1  ,    NULL   value 2  ,    NULL   valueN \\ n \"  )     +     \"       FROM   test _ grouped _ join 1  \\ n \"  )     +     \" UNION   ALL \\ n \"  )     +     \"       SELECT   key 2    key ,    NULL   value 1  ,    value 2  ,    NULL   valueN \\ n \"  )     +     \"       FROM   test _ grouped _ join 2  \\ n \"  )     +     \"       WHERE   key 2     %     2     =     0  \\ n \"  )     +     \" UNION   ALL \\ n \"  )     +     \"       SELECT   keyN   key ,    NULL   value 1  ,    NULL   value 2  ,    valueN \\ n \"  )     +     \"       FROM   test _ grouped _ joinN \\ n \"  )     +     \"       WHERE   keyN    %     3     =     0  \\ n \"  )     +     \"  )  \\ n \"  )     +     \" GROUP   BY   key \"  )  ;", "@ Language (  \" SQL \"  )", "String   expectedThreeGroupByQuery    =     \" SELECT   orderkey ,    ment ,    CASE   mod ( orderkey ,     2  )    WHEN    0    THEN   ment   END ,    CASE   mod ( orderkey ,     3  )    WHEN    0    THEN   ment   END   from   orders \"  ;", "assertQuery ( notColocated ,    groupBySingleBucketedTable ,    expectedSingleGroupByQuery )  ;", "assertQuery ( notColocated ,    groupByThreeBucketedTable ,    expectedThreeGroupByQuery )  ;", "assertQuery ( colocatedAllGroupsAtOnce ,    groupBySingleBucketedTable ,    expectedSingleGroupByQuery )  ;", "assertQuery ( colocatedOneGroupAtATime ,    groupBySingleBucketedTable ,    expectedSingleGroupByQuery )  ;", "assertQuery ( colocatedAllGroupsAtOnce ,    groupByThreeBucketedTable ,    expectedThreeGroupByQuery )  ;", "assertQuery ( colocatedOneGroupAtATime ,    groupByThreeBucketedTable ,    expectedThreeGroupByQuery )  ;", "assertQuery ( colocatedOneGroupAtATime ,    groupByThreeMixedTable ,    expectedThreeGroupByQuery )  ;", "}    finally    {", "assertUpdate (  \" DROP   TABLE   IF   EXISTS   test _ grouped _ join 1  \"  )  ;", "assertUpdate (  \" DROP   TABLE   IF   EXISTS   test _ grouped _ join 2  \"  )  ;", "assertUpdate (  \" DROP   TABLE   IF   EXISTS   test _ grouped _ join 3  \"  )  ;", "assertUpdate (  \" DROP   TABLE   IF   EXISTS   test _ grouped _ joinN \"  )  ;", "assertUpdate (  \" DROP   TABLE   IF   EXISTS   test _ grouped _ joinDual \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGroupedJoin"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "testInsertPartitionedBucketedTable ( HiveStorageFormat . RCBINARY )  ;", "}", "METHOD_END"], "methodName": ["testInsertPartitionedBucketedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ insert _ partitioned _ bucketed _ table \"  ;", "assertUpdate (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     (  \"  )     +     \"       custkey   bigint ,  \"  )     +     \"       custkey 2    bigint ,  \"  )     +     \"       comment   varchar ,  \"  )     +     \"       orderstatus   varchar )  \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partitioned _ by    =    ARRAY [     ' orderstatus '     ]  ,     \"  )     +     \" bucketed _ by    =    ARRAY [     ' custkey '  ,     ' custkey 2  '     ]  ,     \"  )     +     \" bucket _ count    =     1  1  )  \"  )  )  ;", "ImmutableList < String >    orderStatusList    =    ImmutableList . of (  \" F \"  ,     \" O \"  ,     \" P \"  )  ;", "for    ( int   i    =     0  ;    i    <     ( orderStatusList . size (  )  )  ;    i +  +  )     {", "String   orderStatus    =    orderStatusList . get ( i )  ;", "assertUpdate ( getParallelWriteSession (  )  ,    String . format (  (  (  (  (  (  \" INSERT   INTO    \"     +    tableName )     +     \"     \"  )     +     \" SELECT   custkey ,    custkey   AS   custkey 2  ,    comment ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders    \"  )     +     \" WHERE   orderstatus    =     '  % s '  \"  )  ,    orderStatus )  ,    String . format (  \" SELECT   count (  *  )    from   orders   where   orderstatus    =     '  % s '  \"  ,    orderStatus )  )  ;", "}", "verifyPartitionedBucketedTable ( storageFormat ,    tableName )  ;", "assertUpdate (  (  \" DROP   TABLE    \"     +    tableName )  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( getSession (  )  ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testInsertPartitionedBucketedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "testInsertPartitionedBucketedTableFewRows ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testInsertPartitionedBucketedTableFewRows"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ insert _ partitioned _ bucketed _ table _ few _ rows \"  ;", "assertUpdate ( session ,     (  (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     (  \"  )     +     \"       bucket _ key   varchar ,  \"  )     +     \"       col   varchar ,  \"  )     +     \"       partition _ key   varchar )  \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partitioned _ by    =    ARRAY [     ' partition _ key '     ]  ,     \"  )     +     \" bucketed _ by    =    ARRAY [     ' bucket _ key '     ]  ,     \"  )     +     \" bucket _ count    =     1  1  )  \"  )  )  ;", "assertUpdate ( getParallelWriteSession (  )  ,     (  (  (  (  (  (  \" INSERT   INTO    \"     +    tableName )     +     \"     \"  )     +     \" VALUES    \"  )     +     \"        ( VARCHAR    ' a '  ,    VARCHAR    ' b '  ,    VARCHAR    ' c '  )  ,     \"  )     +     \"        (  ' aa '  ,     ' bb '  ,     ' cc '  )  ,     \"  )     +     \"        (  ' aaa '  ,     ' bbb '  ,     ' ccc '  )  \"  )  ,     3  )  ;", "verifyPartitionedBucketedTableAsFewRows ( storageFormat ,    tableName )  ;", "try    {", "assertUpdate ( session ,     \" INSERT   INTO   test _ insert _ partitioned _ bucketed _ table _ few _ rows   VALUES    (  ' a 0  '  ,     ' b 0  '  ,     ' c '  )  \"  ,     1  )  ;", "fail (  \" expected   failure \"  )  ;", "}    catch    ( Exception   e )     {", "assertEquals ( e . getMessage (  )  ,     \" Cannot   insert   into   existing   partition   of   bucketed   Hive   table :    partition _ key = c \"  )  ;", "}", "assertUpdate ( session ,     \" DROP   TABLE   test _ insert _ partitioned _ bucketed _ table _ few _ rows \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testInsertPartitionedBucketedTableFewRows"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "testInsertPartitionedBucketedTableWithUnionAll ( HiveStorageFormat . RCBINARY )  ;", "}", "METHOD_END"], "methodName": ["testInsertPartitionedBucketedTableWithUnionAll"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ insert _ partitioned _ bucketed _ table _ with _ union _ all \"  ;", "assertUpdate (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     (  \"  )     +     \"       custkey   bigint ,  \"  )     +     \"       custkey 2    bigint ,  \"  )     +     \"       comment   varchar ,  \"  )     +     \"       orderstatus   varchar )  \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partitioned _ by    =    ARRAY [     ' orderstatus '     ]  ,     \"  )     +     \" bucketed _ by    =    ARRAY [     ' custkey '  ,     ' custkey 2  '     ]  ,     \"  )     +     \" bucket _ count    =     1  1  )  \"  )  )  ;", "ImmutableList < String >    orderStatusList    =    ImmutableList . of (  \" F \"  ,     \" O \"  ,     \" P \"  )  ;", "for    ( int   i    =     0  ;    i    <     ( orderStatusList . size (  )  )  ;    i +  +  )     {", "String   orderStatus    =    orderStatusList . get ( i )  ;", "assertUpdate ( getParallelWriteSession (  )  ,    String . format (  (  (  (  (  (  (  (  (  (  \" INSERT   INTO    \"     +    tableName )     +     \"     \"  )     +     \" SELECT   custkey ,    custkey   AS   custkey 2  ,    comment ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders    \"  )     +     \" WHERE   orderstatus    =     '  % s '    and   length ( comment )     %  %     2     =     0     \"  )     +     \" UNION   ALL    \"  )     +     \" SELECT   custkey ,    custkey   AS   custkey 2  ,    comment ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders    \"  )     +     \" WHERE   orderstatus    =     '  % s '    and   length ( comment )     %  %     2     =     1  \"  )  ,    orderStatus ,    orderStatus )  ,    String . format (  \" SELECT   count (  *  )    from   orders   where   orderstatus    =     '  % s '  \"  ,    orderStatus )  )  ;", "}", "verifyPartitionedBucketedTable ( storageFormat ,    tableName )  ;", "assertUpdate (  (  \" DROP   TABLE    \"     +    tableName )  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( getSession (  )  ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testInsertPartitionedBucketedTableWithUnionAll"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "testInsertPartitionedTableExistingPartition ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testInsertPartitionedTableExistingPartition"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ insert _ partitioned _ table _ existing _ partition \"  ;", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     \"  )     +     \"  (  \"  )     +     \"       order _ key   BIGINT ,  \"  )     +     \"       comment   VARCHAR ,  \"  )     +     \"       order _ status   VARCHAR \"  )     +     \"  )     \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partitioned _ by    =    ARRAY [     ' order _ status '     ]  \"  )     +     \"  )     \"  ;", "assertUpdate ( session ,    createTable )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,    tableName )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" order _ status \"  )  )  ;", "for    ( int   i    =     0  ;    i    <     3  ;    i +  +  )     {", "assertUpdate ( session ,    String . format (  (  (  (  (  (  \" INSERT   INTO    \"     +    tableName )     +     \"     \"  )     +     \" SELECT   orderkey ,    comment ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders    \"  )     +     \" WHERE   orderkey    %  %     3     =     % d \"  )  ,    i )  ,    String . format (  \" SELECT   count (  *  )    from   orders   where   orderkey    %  %     3     =     % d \"  ,    i )  )  ;", "}", "List <  ?  >    partitions    =    getPartitions ( tableName )  ;", "assertEquals ( partitions . size (  )  ,     3  )  ;", "assertQuery ( session ,     (  \" SELECT    *    from    \"     +    tableName )  ,     \" SELECT   orderkey ,    comment ,    orderstatus   FROM   orders \"  )  ;", "assertUpdate ( session ,     (  \" DROP   TABLE    \"     +    tableName )  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testInsertPartitionedTableExistingPartition"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "testInsertUnpartitionedTable ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testInsertUnpartitionedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ insert _ unpartitioned _ table \"  ;", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     \"  )     +     \"  (  \"  )     +     \"       order _ key   BIGINT ,  \"  )     +     \"       comment   VARCHAR ,  \"  )     +     \"       order _ status   VARCHAR \"  )     +     \"  )     \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  \"  )     +     \"  )     \"  ;", "assertUpdate ( session ,    createTable )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,    tableName )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "for    ( int   i    =     0  ;    i    <     3  ;    i +  +  )     {", "assertUpdate ( session ,    String . format (  (  (  (  (  (  \" INSERT   INTO    \"     +    tableName )     +     \"     \"  )     +     \" SELECT   orderkey ,    comment ,    orderstatus    \"  )     +     \" FROM   tpch . tiny . orders    \"  )     +     \" WHERE   orderkey    %  %     3     =     % d \"  )  ,    i )  ,    String . format (  \" SELECT   count (  *  )    from   orders   where   orderkey    %  %     3     =     % d \"  ,    i )  )  ;", "}", "assertQuery ( session ,     (  \" SELECT    *    from    \"     +    tableName )  ,     \" SELECT   orderkey ,    comment ,    orderstatus   FROM   orders \"  )  ;", "assertUpdate ( session ,     (  \" DROP   TABLE    \"     +    tableName )  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testInsertUnpartitionedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   TABLE   invalid _ partition _ value    ( a   int ,    b   varchar )    WITH    ( partitioned _ by    =    ARRAY [  ' b '  ]  )  \"  )  ;", "assertQueryFails (  \" INSERT   INTO   invalid _ partition _ value   VALUES    (  4  ,     ' test '     |  |    chr (  1  3  )  )  \"  ,     \"  \\  \\ QHive   partition   keys   can   only   contain   printable   ASCII   characters    (  0 x 2  0     -     0 x 7 E )  .    Invalid   value :     7  4     6  5     7  3     7  4     0 D \\  \\ E \"  )  ;", "assertUpdate (  \" DROP   TABLE   invalid _ partition _ value \"  )  ;", "assertQueryFails (  \" CREATE   TABLE   invalid _ partition _ value    ( a ,    b )    WITH    ( partitioned _ by    =    ARRAY [  ' b '  ]  )    AS   SELECT    4  ,    chr (  9  7  3  1  )  \"  ,     \"  \\  \\ QHive   partition   keys   can   only   contain   printable   ASCII   characters    (  0 x 2  0     -     0 x 7 E )  .    Invalid   value :    E 2     9  8     8  3  \\  \\ E \"  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidPartitionValue"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   TABLE   tmp _ map 1    AS   SELECT   MAP ( ARRAY [  0  ,  1  ]  ,    ARRAY [  2  , NULL ]  )    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  0  ]    FROM   tmp _ map 1  \"  ,     \" SELECT    2  \"  )  ;", "assertQuery (  \" SELECT   col [  1  ]    FROM   tmp _ map 1  \"  ,     \" SELECT   NULL \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 2    AS   SELECT   MAP ( ARRAY [ INTEGER '  1  '  ]  ,    ARRAY [ INTEGER '  2  '  ]  )    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [ INTEGER '  1  '  ]    FROM   tmp _ map 2  \"  ,     \" SELECT    2  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 3    AS   SELECT   MAP ( ARRAY [ SMALLINT '  1  '  ]  ,    ARRAY [ SMALLINT '  2  '  ]  )    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [ SMALLINT '  1  '  ]    FROM   tmp _ map 3  \"  ,     \" SELECT    2  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 4    AS   SELECT   MAP ( ARRAY [ TINYINT '  1  '  ]  ,    ARRAY [ TINYINT '  2  '  ]  )    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [ TINYINT '  1  '  ]    FROM   tmp _ map 4  \"  ,     \" SELECT    2  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 5    AS   SELECT   MAP ( ARRAY [  1  .  0  ]  ,    ARRAY [  2  .  5  ]  )    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  1  .  0  ]    FROM   tmp _ map 5  \"  ,     \" SELECT    2  .  5  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 6    AS   SELECT   MAP ( ARRAY [  ' puppies '  ]  ,    ARRAY [  ' kittens '  ]  )    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  ' puppies '  ]    FROM   tmp _ map 6  \"  ,     \" SELECT    ' kittens '  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 7    AS   SELECT   MAP ( ARRAY [ TRUE ]  ,    ARRAY [ FALSE ]  )    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [ TRUE ]    FROM   tmp _ map 7  \"  ,     \" SELECT   FALSE \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 8    AS   SELECT   MAP ( ARRAY [ DATE    '  2  0  1  4  -  0  9  -  3  0  '  ]  ,    ARRAY [ DATE    '  2  0  1  4  -  0  9  -  2  9  '  ]  )    AS   col \"  ,     1  )  ;", "assertOneNotNullResult (  \" SELECT   col [ DATE    '  2  0  1  4  -  0  9  -  3  0  '  ]    FROM   tmp _ map 8  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 9    AS   SELECT   MAP ( ARRAY [ TIMESTAMP    '  2  0  0  1  -  0  8  -  2  2     0  3  :  0  4  :  0  5  .  3  2  1  '  ]  ,    ARRAY [ TIMESTAMP    '  2  0  0  1  -  0  8  -  2  2     0  3  :  0  4  :  0  5  .  3  2  1  '  ]  )    AS   col \"  ,     1  )  ;", "assertOneNotNullResult (  \" SELECT   col [ TIMESTAMP    '  2  0  0  1  -  0  8  -  2  2     0  3  :  0  4  :  0  5  .  3  2  1  '  ]    FROM   tmp _ map 9  \"  )  ;", "assertUpdate (  (  \" CREATE   TABLE   tmp _ map 1  0    AS   SELECT   MAP ( ARRAY [ DECIMAL    '  3  .  1  4  '  ,    DECIMAL    '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '  ]  ,     \"     +     \" ARRAY [ DECIMAL    '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '  ,    DECIMAL    '  3  .  0  1  2  3  4  5  6  7  8  9  '  ]  )    AS   col \"  )  ,     1  )  ;", "assertQuery (  \" SELECT   col [ DECIMAL    '  3  .  1  4  '  ]  ,    col [ DECIMAL    '  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  '  ]    FROM   tmp _ map 1  0  \"  ,     \" SELECT    1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9  0  .  0  1  2  3  4  5  6  7  8  9  ,     3  .  0  1  2  3  4  5  6  7  8  9  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 1  1    AS   SELECT   MAP ( ARRAY [ REAL '  1  .  2  3  4  '  ]  ,    ARRAY [ REAL '  2  .  3  4  5  '  ]  )    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [ REAL '  1  .  2  3  4  '  ]    FROM   tmp _ map 1  1  \"  ,     \" SELECT    2  .  3  4  5  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ map 1  2    AS   SELECT   MAP ( ARRAY [  1  .  0 E 0  ]  ,    ARRAY [ ARRAY [  1  ,     2  ]  ]  )    AS   col \"  ,     1  )  ;", "assertQuery (  \" SELECT   col [  1  .  0  ]  [  2  ]    FROM   tmp _ map 1  2  \"  ,     \" SELECT    2  \"  )  ;", "}", "METHOD_END"], "methodName": ["testMaps"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  \"  \"     +     (  (  (  (  (  (  \" CREATE   TABLE   test _ metadata _ delete    \"     +     \"  (  \"  )     +     \"       ORDER _ KEY   BIGINT ,  \"  )     +     \"       LINE _ NUMBER   INTEGER ,  \"  )     +     \"       LINE _ STATUS   VARCHAR \"  )     +     \"  )     \"  )     +     \" WITH    (  \"  )  )     +     ( TableProperties . PARTITIONED _ BY _ PROPERTY )  )     +     \"     =    ARRAY [     ' LINE _ NUMBER '  ,     ' LINE _ STATUS '     ]  \"  )     +     \"  )     \"  ;", "assertUpdate ( createTable )  ;", "assertUpdate (  (  \"  \"     +     (  (  \" INSERT   INTO   test _ metadata _ delete    \"     +     \" SELECT   orderkey ,    linenumber ,    linestatus    \"  )     +     \" FROM   tpch . tiny . lineitem \"  )  )  ,     \" SELECT   count (  *  )    from   lineitem \"  )  ;", "assertUpdate (  \" DELETE   FROM   test _ metadata _ delete   WHERE   LINE _ STATUS =  ' F '    and   LINE _ NUMBER = CAST (  3    AS   INTEGER )  \"  )  ;", "assertQuery (  \" SELECT    *    from   test _ metadata _ delete \"  ,     \" SELECT   orderkey ,    linenumber ,    linestatus   FROM   lineitem   WHERE   linestatus <  >  ' F '    or   linenumber <  >  3  \"  )  ;", "assertUpdate (  \" DELETE   FROM   test _ metadata _ delete   WHERE   LINE _ STATUS =  ' O '  \"  )  ;", "assertQuery (  \" SELECT    *    from   test _ metadata _ delete \"  ,     \" SELECT   orderkey ,    linenumber ,    linestatus   FROM   lineitem   WHERE   linestatus <  >  ' O '    and   linenumber <  >  3  \"  )  ;", "try    {", "getQueryRunner (  )  . execute (  \" DELETE   FROM   test _ metadata _ delete   WHERE   ORDER _ KEY =  1  \"  )  ;", "fail (  \" expected   exception \"  )  ;", "}    catch    ( RuntimeException   e )     {", "assertEquals ( e . getMessage (  )  ,     \" This   connector   only   supports   delete   where   one   or   more   partitions   are   deleted   entirely \"  )  ;", "}", "assertQuery (  \" SELECT    *    from   test _ metadata _ delete \"  ,     \" SELECT   orderkey ,    linenumber ,    linestatus   FROM   lineitem   WHERE   linestatus <  >  ' O '    and   linenumber <  >  3  \"  )  ;", "assertUpdate (  \" DROP   TABLE   test _ metadata _ delete \"  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( getSession (  )  ,     \" test _ metadata _ delete \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMetadataDelete"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   TABLE   char _ order _ by    ( c _ char   char (  2  )  )  \"  )  ;", "assertUpdate (  (  \" INSERT   INTO   char _ order _ by    ( c _ char )    VALUES \"     +     (  (  \"  ( CAST (  ' a '    as   CHAR (  2  )  )  )  ,  \"     +     \"  ( CAST (  \\  ' a \\ u 0  0  0  0  \\  '    as   CHAR (  2  )  )  )  ,  \"  )     +     \"  ( CAST (  ' a       '    as   CHAR (  2  )  )  )  \"  )  )  ,     3  )  ;", "MaterializedResult   actual    =    puteActual ( getSession (  )  ,     \" SELECT    *    FROM   char _ order _ by   ORDER   BY   c _ char   ASC \"  )  ;", "assertUpdate (  \" DROP   TABLE   char _ order _ by \"  )  ;", "MaterializedResult   expected    =    resultBuilder ( getSession (  )  ,    CharType . createCharType (  2  )  )  . row (  \" a \\ u 0  0  0  0  \"  )  . row (  \" a    \"  )  . row (  \" a    \"  )  . build (  )  ;", "assertEquals ( actual ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testOrderByChar"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    =    new   TestHiveIntegrationSmokeTest . TestingHiveStorageFormat ( getSession (  )  ,    HiveStorageFormat . DWRF )  ;", "testPartitionPerScanLimit ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPartitionPerScanLimit"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ partition _ per _ scan _ limit \"  ;", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     \"  )     +     \"  (  \"  )     +     \"       foo   VARCHAR ,  \"  )     +     \"       part   BIGINT \"  )     +     \"  )     \"  )     +     \" WITH    (  \"  )     +     \" format    =     '  \"  )     +    storageFormat )     +     \"  '  ,     \"  )     +     \" partitioned _ by    =    ARRAY [     ' part '     ]  \"  )     +     \"  )     \"  ;", "assertUpdate ( session ,    createTable )  ;", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,    tableName )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" part \"  )  )  ;", "for    ( int   i    =     0  ;    i    <     1  2  ;    i +  +  )     {", "int   partStart    =    i    *     1  0  0  ;", "int   partEnd    =     (  ( i    +     1  )     *     1  0  0  )     -     1  ;", "@ Language (  \" SQL \"  )", "String   insertPartitions    =     (  (  (  (  (  (  (  (  \"  \"     +     \" INSERT   INTO    \"  )     +    tableName )     +     \"     \"  )     +     \" SELECT    ' bar '    foo ,    part    \"  )     +     \" FROM   UNNEST ( SEQUENCE (  \"  )     +    partStart )     +     \"  ,     \"  )     +    partEnd )     +     \"  )  )    AS   TMP ( part )  \"  ;", "assertUpdate ( session ,    insertPartitions ,     1  0  0  )  ;", "}", "assertQuery ( session ,     (  (  \" SHOW   PARTITIONS   FROM    \"     +    tableName )     +     \"    WHERE   part    >     4  9  0    and   part    <  =     5  0  0  \"  )  ,     \" VALUES    4  9  1  ,     4  9  2  ,     4  9  3  ,     4  9  4  ,     4  9  5  ,     4  9  6  ,     4  9  7  ,     4  9  8  ,     4  9  9  ,     5  0  0  \"  )  ;", "assertQuery ( session ,     (  (  \" SHOW   PARTITIONS   FROM    \"     +    tableName )     +     \"    WHERE   part    <     0  \"  )  ,     \" SELECT   null   WHERE   false \"  )  ;", "assertQuery ( session ,     (  \" SHOW   PARTITIONS   FROM    \"     +    tableName )  ,     (  \" VALUES    \"     +     ( LongStream . range (  0  ,     1  2  0  0  )  . mapToObj ( String :  : valueOf )  . collect ( Collectors . joining (  \"  ,  \"  )  )  )  )  )  ;", "assertQuery ( session ,     (  (  \" SELECT    *    FROM    \\  \"  \"     +    tableName )     +     \"  $ partitions \\  \"  \"  )  ,     (  \" VALUES    \"     +     ( LongStream . range (  0  ,     1  2  0  0  )  . mapToObj ( String :  : valueOf )  . collect ( Collectors . joining (  \"  ,  \"  )  )  )  )  )  ;", "assertQuery ( session ,     (  (  \" SELECT   count ( foo )    FROM    \"     +    tableName )     +     \"    WHERE   part    <     1  0  0  0  \"  )  ,     \" SELECT    1  0  0  0  \"  )  ;", "assertQuery ( session ,     (  (  \" SELECT   count ( foo )    FROM    \"     +    tableName )     +     \"    WHERE   part    >  =     1  0  0  0    AND   part    <     1  2  0  0  \"  )  ,     \" SELECT    2  0  0  \"  )  ;", "assertQueryFails ( session ,     (  (  \" SELECT    *    from    \"     +    tableName )     +     \"    WHERE   part    <     1  0  0  1  \"  )  ,    String . format (  \" Query   over   table    ' tpch .  % s '    can   potentially   read   more   than    1  0  0  0    partitions \"  ,    tableName )  )  ;", "assertQueryFails ( session ,     (  \" SELECT    *    from    \"     +    tableName )  ,    String . format (  \" Query   over   table    ' tpch .  % s '    can   potentially   read   more   than    1  0  0  0    partitions \"  ,    tableName )  )  ;", "assertUpdate ( session ,     (  \" DROP   TABLE    \"     +    tableName )  )  ;", "assertFalse ( getQueryRunner (  )  . tableExists ( session ,    tableName )  )  ;", "}", "METHOD_END"], "methodName": ["testPartitionPerScanLimit"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "for    ( TestHiveIntegrationSmokeTest . TestingHiveStorageFormat   storageFormat    :    getAllTestingHiveStorageFormat (  )  )     {", "doTestPathHiddenColumn ( storageFormat . getSession (  )  ,    storageFormat . getFormat (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testPathHiddenColumn"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   TABLE   test _ table _ with _ char    ( a   char (  2  0  )  )  \"  )  ;", "try    {", "assertUpdate (  (  \" INSERT   INTO   test _ table _ with _ char    ( a )    VALUES \"     +     (  (  (  \"  ( cast (  ' aaa '    as   char (  2  0  )  )  )  ,  \"     +     \"  ( cast (  ' bbb '    as   char (  2  0  )  )  )  ,  \"  )     +     \"  ( cast (  ' bbc '    as   char (  2  0  )  )  )  ,  \"  )     +     \"  ( cast (  ' bbd '    as   char (  2  0  )  )  )  \"  )  )  ,     4  )  ;", "assertQuery (  \" SELECT   a ,    a    <  =     ' bbc '    FROM   test _ table _ with _ char \"  ,     (  \" VALUES    ( cast (  ' aaa '    as   char (  2  0  )  )  ,    true )  ,     \"     +     (  (  \"  ( cast (  ' bbb '    as   char (  2  0  )  )  ,    true )  ,     \"     +     \"  ( cast (  ' bbc '    as   char (  2  0  )  )  ,    false )  ,     \"  )     +     \"  ( cast (  ' bbd '    as   char (  2  0  )  )  ,    false )  \"  )  )  )  ;", "assertQuery (  \" SELECT   a   FROM   test _ table _ with _ char   WHERE   a    <  =     ' bbc '  \"  ,     (  \" VALUES   cast (  ' aaa '    as   char (  2  0  )  )  ,     \"     +     \" cast (  ' bbb '    as   char (  2  0  )  )  \"  )  )  ;", "}    finally    {", "assertUpdate (  \" DROP   TABLE   test _ table _ with _ char \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testPredicatePushDownToTableScan"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "testRcTextCharDecoding ( false )  ;", "testRcTextCharDecoding ( true )  ;", "}", "METHOD_END"], "methodName": ["testRcTextCharDecoding"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   catalog    =    getSession (  )  . getCatalog (  )  . get (  )  ;", "Session   session    =    Session . builder ( getSession (  )  )  . setCatalogSessionProperty ( catalog ,    SessionProperties . RCFILE _ OPTIMIZED _ WRITER _ ENABLED ,    Boolean . toString ( rcFileOptimizedWriterEnabled )  )  . build (  )  ;", "assertUpdate ( session ,     \" CREATE   TABLE   test _ table _ with _ char _ rc   WITH    ( format    =     ' RCTEXT '  )    AS   SELECT   CAST (  ' khaki '    AS   CHAR (  7  )  )    char _ column \"  ,     1  )  ;", "try    {", "assertQuery ( session ,     \" SELECT    *    FROM   test _ table _ with _ char _ rc   WHERE   char _ column    =     ' khaki       '  \"  ,     \" VALUES    ( CAST (  ' khaki '    AS   CHAR (  7  )  )  )  \"  )  ;", "}    finally    {", "assertUpdate ( session ,     \" DROP   TABLE   test _ table _ with _ char _ rc \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRcTextCharDecoding"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "@ Language (  \" SQL \"  )", "String   createTable    =     \"  \"     +     (  (  (  (  (  \" CREATE   TABLE   test _ rename _ column \\ n \"     +     \" WITH    (  \\ n \"  )     +     \"       partied _ by    =    ARRAY    [  \\  ' orderstatus \\  '  ]  \\ n \"  )     +     \"  )  \\ n \"  )     +     \" AS \\ n \"  )     +     \" SELECT   orderkey ,    orderstatus   FROM   orders \"  )  ;", "assertUpdate ( createTable ,     \" SELECT   count (  *  )    FROM   orders \"  )  ;", "assertUpdate (  \" ALTER   TABLE   test _ rename _ column   RENAME   COLUMN   orderkey   TO   new _ orderkey \"  )  ;", "assertQuery (  \" SELECT   new _ orderkey ,    orderstatus   FROM   test _ rename _ column \"  ,     \" SELECT   orderkey ,    orderstatus   FROM   orders \"  )  ;", "assertQueryFails (  \" ALTER   TABLE   test _ rename _ column   RENAME   COLUMN    \\  \"  $ path \\  \"    TO   test \"  ,     \"  .  *    Cannot   rename   hidden   column \"  )  ;", "assertQueryFails (  \" ALTER   TABLE   test _ rename _ column   RENAME   COLUMN   orderstatus   TO   new _ orderstatus \"  ,     \" Renaming   parti   columns   is   not   supported \"  )  ;", "assertQuery (  \" SELECT   new _ orderkey ,    orderstatus   FROM   test _ rename _ column \"  ,     \" SELECT   orderkey ,    orderstatus   FROM   orders \"  )  ;", "assertUpdate (  \" DROP   TABLE   test _ rename _ column \"  )  ;", "}", "METHOD_END"], "methodName": ["testRenameColumn"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   TABLE   tmp _ row 1    AS   SELECT   cast ( row ( CAST (  1    as   BIGINT )  ,    CAST ( NULL   as   BIGINT )  )    AS   row ( col 0    bigint ,    col 1    bigint )  )    AS   a \"  ,     1  )  ;", "assertQuery (  \" SELECT   a . col 0  ,    a . col 1    FROM   tmp _ row 1  \"  ,     \" SELECT    1  ,    cast ( null   as   bigint )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testRows"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "try    {", "assertUpdate ( Session . builder ( getSession (  )  )  . setSystemProperty (  \" scale _ writers \"  ,     \" true \"  )  . setSystemProperty (  \" writer _ min _ size \"  ,     \"  3  2 MB \"  )  . build (  )  ,     \" CREATE   TABLE   scale _ writers _ small   AS   SELECT    *    FROM   tpch . tiny . orders \"  ,     (  ( long )     ( puteActual (  \" SELECT   count (  *  )    FROM   tpch . tiny . orders \"  )  . getOnlyValue (  )  )  )  )  ;", "assertEquals ( puteActual (  \" SELECT   count ( DISTINCT    \\  \"  $ path \\  \"  )    FROM   scale _ writers _ small \"  )  . getOnlyValue (  )  ,     1 L )  ;", "assertUpdate ( Session . builder ( getSession (  )  )  . setSystemProperty (  \" scale _ writers \"  ,     \" true \"  )  . setSystemProperty (  \" writer _ min _ size \"  ,     \"  4 MB \"  )  . build (  )  ,     \" CREATE   TABLE   scale _ writers _ large   WITH    ( format    =     ' RCBINARY '  )    AS   SELECT    *    FROM   tpch . sf 2  . orders \"  ,     (  ( long )     ( puteActual (  \" SELECT   count (  *  )    FROM   tpch . sf 2  . orders \"  )  . getOnlyValue (  )  )  )  )  ;", "assertEquals ( puteActual (  \" SELECT   count ( DISTINCT    \\  \"  $ path \\  \"  )    FROM   scale _ writers _ large \"  )  ,    puteActual (  \" SELECT   count (  *  )    FROM   system . runtime . nodes \"  )  )  ;", "}    finally    {", "assertUpdate (  \" DROP   TABLE   IF   EXISTS   scale _ writers _ large \"  )  ;", "assertUpdate (  \" DROP   TABLE   IF   EXISTS   scale _ writers _ small \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testScaleWriters"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   SCHEMA   new _ schema \"  )  ;", "assertUpdate (  \" CREATE   TABLE   new _ schema . t    ( x   bigint )  \"  )  ;", "assertQueryFails (  \" DROP   SCHEMA   new _ schema \"  ,     \" Schema   not   empty :    new _ schema \"  )  ;", "assertUpdate (  \" DROP   TABLE   new _ schema . t \"  )  ;", "assertUpdate (  \" DROP   SCHEMA   new _ schema \"  )  ;", "}", "METHOD_END"], "methodName": ["testSchemaOperations"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ show _ columns _ from _ partitions \"  ;", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     \"  )     +     \"  (  \"  )     +     \"       foo   VARCHAR ,  \"  )     +     \"       part 1    BIGINT ,  \"  )     +     \"       part 2    VARCHAR \"  )     +     \"  )     \"  )     +     \" WITH    (  \"  )     +     \" partitioned _ by    =    ARRAY [     ' part 1  '  ,     ' part 2  '     ]  \"  )     +     \"  )     \"  ;", "assertUpdate ( getSession (  )  ,    createTable )  ;", "assertQuery ( getSession (  )  ,     (  (  \" SHOW   COLUMNS   FROM    \\  \"  \"     +    tableName )     +     \"  $ partitions \\  \"  \"  )  ,     \" VALUES    (  ' part 1  '  ,     ' bigint '  ,     '  '  ,     '  '  )  ,     (  ' part 2  '  ,     ' varchar '  ,     '  '  ,     '  '  )  \"  )  ;", "assertQueryFails ( getSession (  )  ,     \" SHOW   COLUMNS   FROM    \\  \"  $ partitions \\  \"  \"  ,     \"  .  * Table    \\  '  .  *  \\  \\  . tpch \\  \\  .  \\  \\  $ partitions \\  '    does   not   exist \"  )  ;", "assertQueryFails ( getSession (  )  ,     \" SHOW   COLUMNS   FROM    \\  \" orders $ partitions \\  \"  \"  ,     \"  .  * Table    \\  '  .  *  \\  \\  . tpch \\  \\  . orders \\  \\  $ partitions \\  '    does   not   exist \"  )  ;", "assertQueryFails ( getSession (  )  ,     \" SHOW   COLUMNS   FROM    \\  \" blah $ partitions \\  \"  \"  ,     \"  .  * Table    \\  '  .  *  \\  \\  . tpch \\  \\  . blah \\  \\  $ partitions \\  '    does   not   exist \"  )  ;", "}", "METHOD_END"], "methodName": ["testShowColumnsFromPartitions"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  (  \"  \"     +     (  (  \" CREATE   TABLE   test _ show _ columns _ partition _ key \\ n \"     +     \"  ( grape   bigint ,    orange   bigint ,    pear   varchar (  6  5  5  3  5  )  ,    mango   integer ,    lychee   smallint ,    kiwi   tinyint ,    apple   varchar ,    pineapple   varchar (  6  5  5  3  5  )  )  \\ n \"  )     +     \" WITH    ( partitioned _ by    =    ARRAY [  ' apple '  ,     ' pineapple '  ]  )  \"  )  )  )  ;", "MaterializedResult   actual    =    computeActual (  \" SHOW   COLUMNS   FROM   test _ show _ columns _ partition _ key \"  )  ;", "Type   unboundedVarchar    =    canonicalizeType ( VarcharType . VARCHAR )  ;", "MaterializedResult   expected    =    resultBuilder ( getSession (  )  ,    unboundedVarchar ,    unboundedVarchar ,    unboundedVarchar ,    unboundedVarchar )  . row (  \" grape \"  ,    canonicalizeTypeName (  \" bigint \"  )  ,     \"  \"  ,     \"  \"  )  . row (  \" orange \"  ,    canonicalizeTypeName (  \" bigint \"  )  ,     \"  \"  ,     \"  \"  )  . row (  \" pear \"  ,    canonicalizeTypeName (  \" varchar (  6  5  5  3  5  )  \"  )  ,     \"  \"  ,     \"  \"  )  . row (  \" mango \"  ,    canonicalizeTypeName (  \" integer \"  )  ,     \"  \"  ,     \"  \"  )  . row (  \" lychee \"  ,    canonicalizeTypeName (  \" smallint \"  )  ,     \"  \"  ,     \"  \"  )  . row (  \" kiwi \"  ,    canonicalizeTypeName (  \" tinyint \"  )  ,     \"  \"  ,     \"  \"  )  . row (  \" apple \"  ,    canonicalizeTypeName (  \" varchar \"  )  ,     \" partition   key \"  ,     \"  \"  )  . row (  \" pineapple \"  ,    canonicalizeTypeName (  \" varchar (  6  5  5  3  5  )  \"  )  ,     \" partition   key \"  ,     \"  \"  )  . build (  )  ;", "assertEquals ( actual ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testShowColumnsPartitionKey"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   createTableSql    =    String . format (  (  \"  \"     +     (  (  (  (  (  (  (  (  (  \" CREATE   TABLE    % s .  % s .  % s    (  \\ n \"     +     \"          c 1    bigint ,  \\ n \"  )     +     \"          c 2    double ,  \\ n \"  )     +     \"           \\  \" c    3  \\  \"    varchar ,  \\ n \"  )     +     \"           \\  \" c \\  '  4  \\  \"    array ( bigint )  ,  \\ n \"  )     +     \"          c 5    map ( bigint ,    varchar )  \\ n \"  )     +     \"  )  \\ n \"  )     +     \" WITH    (  \\ n \"  )     +     \"          format    =     \\  ' RCBINARY \\  '  \\ n \"  )     +     \"  )  \"  )  )  ,    getSession (  )  . getCatalog (  )  . get (  )  ,    getSession (  )  . getSchema (  )  . get (  )  ,     \" test _ show _ create _ table \"  )  ;", "assertUpdate ( createTableSql )  ;", "MaterializedResult   actualResult    =    computeActual (  \" SHOW   CREATE   TABLE   test _ show _ create _ table \"  )  ;", "assertEquals ( getOnlyElement ( actualResult . getOnlyColumnAsSet (  )  )  ,    createTableSql )  ;", "createTableSql    =    String . format (  (  \"  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  \" CREATE   TABLE    % s .  % s .  % s    (  \\ n \"     +     \"          c 1    bigint ,  \\ n \"  )     +     \"           \\  \" c    2  \\  \"    varchar ,  \\ n \"  )     +     \"           \\  \" c \\  '  3  \\  \"    array ( bigint )  ,  \\ n \"  )     +     \"          c 4    map ( bigint ,    varchar )    COMMENT    \\  ' comment   test 4  \\  '  ,  \\ n \"  )     +     \"          c 5    double   COMMENT    \\  ' comment   test 5  \\  '  \\ n )  \\ n \"  )     +     \" COMMENT    \\  ' test \\  '  \\ n \"  )     +     \" WITH    (  \\ n \"  )     +     \"          format    =     \\  ' ORC \\  '  ,  \\ n \"  )     +     \"          orc _ bloom _ filter _ columns    =    ARRAY [  \\  ' c 1  \\  '  ,  \\  ' c 2  \\  '  ]  ,  \\ n \"  )     +     \"          orc _ bloom _ filter _ fpp    =     7 E -  1  ,  \\ n \"  )     +     \"          partied _ by    =    ARRAY [  \\  ' c 4  \\  '  ,  \\  ' c 5  \\  '  ]  \\ n \"  )     +     \"  )  \"  )  )  ,    getSession (  )  . getCatalog (  )  . get (  )  ,    getSession (  )  . getSchema (  )  . get (  )  ,     \"  \\  \" test _ show _ create _ table \\  '  2  \\  \"  \"  )  ;", "assertUpdate ( createTableSql )  ;", "actualResult    =    computeActual (  \" SHOW   CREATE   TABLE    \\  \" test _ show _ create _ table \\  '  2  \\  \"  \"  )  ;", "assertEquals ( getOnlyElement ( actualResult . getOnlyColumnAsSet (  )  )  ,    createTableSql )  ;", "}", "METHOD_END"], "methodName": ["testShowCreateTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "String   tableName    =     \" test _ show _ partitions _ from _ partitions \"  ;", "@ Language (  \" SQL \"  )", "String   createTable    =     (  (  (  (  (  (  (  (  (  (  \"  \"     +     \" CREATE   TABLE    \"  )     +    tableName )     +     \"     \"  )     +     \"  (  \"  )     +     \"       foo   VARCHAR ,  \"  )     +     \"       part 1    BIGINT ,  \"  )     +     \"       part 2    VARCHAR \"  )     +     \"  )     \"  )     +     \" WITH    (  \"  )     +     \" partitioned _ by    =    ARRAY [     ' part 1  '  ,     ' part 2  '     ]  \"  )     +     \"  )     \"  ;", "assertUpdate ( getSession (  )  ,    createTable )  ;", "assertQueryFails ( getSession (  )  ,     (  (  \" SHOW   PARTITIONS   FROM    \\  \"  \"     +    tableName )     +     \"  $ partitions \\  \"  \"  )  ,     \"  .  * Table   does   not   have   partition   columns :     .  *  \\  \\  . tpch . test _ show _ partitions _ from _ partitions \\  \\  $ partitions \"  )  ;", "assertQueryFails ( getSession (  )  ,     \" SHOW   PARTITIONS   FROM    \\  \" non _ existent $ partitions \\  \"  \"  ,     \"  .  * Table    \\  '  .  *  \\  \\  . tpch \\  \\  . non _ existent \\  \\  $ partitions \\  '    does   not   exist \"  )  ;", "}", "METHOD_END"], "methodName": ["testShowPartitionsFromPartitionsSystemTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "assertUpdate (  \" CREATE   TABLE   tmp _ array 1  1    AS   SELECT   ARRAY [ DATE    '  2  0  1  4  -  0  9  -  3  0  '  ]    AS   col \"  ,     1  )  ;", "assertOneNotNullResult (  \" SELECT   col [  1  ]    FROM   tmp _ array 1  1  \"  )  ;", "assertUpdate (  \" CREATE   TABLE   tmp _ array 1  2    AS   SELECT   ARRAY [ TIMESTAMP    '  2  0  0  1  -  0  8  -  2  2     0  3  :  0  4  :  0  5  .  3  2  1  '  ]    AS   col \"  ,     1  )  ;", "assertOneNotNullResult (  \" SELECT   col [  1  ]    FROM   tmp _ array 1  2  \"  )  ;", "}", "METHOD_END"], "methodName": ["testTemporalArrays"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "Object   partitionByProperty    =    tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY )  ;", "if    ( hasPartition )     {", "assertEquals ( partitionByProperty ,    partitionKeys )  ;", "for    ( ColumnMetadata   columnMetadata    :    tableMetadata . getColumns (  )  )     {", "boolean   partitionKey    =    partitionKeys . contains ( columnMetadata . getName (  )  )  ;", "assertEquals ( columnMetadata . getExtraInfo (  )  ,    HiveUtil . columnExtraInfo ( partitionKey )  )  ;", "}", "} else    {", "assertNull ( partitionByProperty )  ;", "}", "}", "METHOD_END"], "methodName": ["verifyPartition"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,    tableName )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" orderstatus \"  )  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . BUCKETED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" custkey \"  ,     \" custkey 2  \"  )  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . BUCKET _ COUNT _ PROPERTY )  ,     1  1  )  ;", "List <  ?  >    partitions    =    getPartitions ( tableName )  ;", "assertEquals ( partitions . size (  )  ,     3  )  ;", "assertQuery (  (  \" SELECT    *    from    \"     +    tableName )  ,     \" SELECT   custkey ,    custkey ,    comment ,    orderstatus   FROM   orders \"  )  ;", "for    ( int   i    =     1  ;    i    <  =     3  0  ;    i +  +  )     {", "assertQuery ( String . format (  (  (  \" SELECT    *    from    \"     +    tableName )     +     \"    where   custkey    =     % d   and   custkey 2     =     % d \"  )  ,    i ,    i )  ,    String . format (  \" SELECT   custkey ,    custkey ,    comment ,    orderstatus   FROM   orders   where   custkey    =     % d \"  ,    i )  )  ;", "}", "try    {", "assertUpdate (  (  (  \" INSERT   INTO    \"     +    tableName )     +     \"    VALUES    (  1  ,     1  ,     ' comment '  ,     ' O '  )  \"  )  ,     1  )  ;", "fail (  \" expected   failure \"  )  ;", "}    catch    ( Exception   e )     {", "assertEquals ( e . getMessage (  )  ,     \" Cannot   insert   into   existing   partition   of   bucketed   Hive   table :    orderstatus = O \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["verifyPartitionedBucketedTable"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "TableMetadata   tableMetadata    =    getTableMetadata ( catalog ,    HiveQueryRunner . TPCH _ SCHEMA ,    tableName )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . STORAGE _ FORMAT _ PROPERTY )  ,    storageFormat )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . PARTITIONED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" partition _ key \"  )  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . BUCKETED _ BY _ PROPERTY )  ,    ImmutableList . of (  \" bucket _ key \"  )  )  ;", "assertEquals ( tableMetadata . getMetadata (  )  . getProperties (  )  . get ( HiveTableProperties . BUCKET _ COUNT _ PROPERTY )  ,     1  1  )  ;", "List <  ?  >    partitions    =    getPartitions ( tableName )  ;", "assertEquals ( partitions . size (  )  ,     3  )  ;", "MaterializedResult   actual    =    computeActual (  (  \" SELECT    *    from    \"     +    tableName )  )  ;", "MaterializedResult   expected    =    resultBuilder ( getSession (  )  ,    canonicalizeType ( VarcharType . createUnboundedVarcharType (  )  )  ,    canonicalizeType ( VarcharType . createUnboundedVarcharType (  )  )  ,    canonicalizeType ( VarcharType . createUnboundedVarcharType (  )  )  )  . row (  \" a \"  ,     \" b \"  ,     \" c \"  )  . row (  \" aa \"  ,     \" bb \"  ,     \" cc \"  )  . row (  \" aaa \"  ,     \" bbb \"  ,     \" ccc \"  )  . build (  )  ;", "assertEqualsIgnoreOrder ( actual . getMaterializedRows (  )  ,    expected . getMaterializedRows (  )  )  ;", "}", "METHOD_END"], "methodName": ["verifyPartitionedBucketedTableAsFewRows"], "fileName": "com.facebook.presto.hive.TestHiveIntegrationSmokeTest"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HivePartition >    partitions    =    ImmutableList . builder (  )  ;", "for    ( int   i    =     0  ;    i    <     5  ;    i +  +  )     {", "partitions . add ( new   HivePartition ( new   SchemaTableName (  \" test \"  ,     \" test \"  )  ,    Integer . toString ( i )  ,    ImmutableMap . of (  . TEST _ COLUMN _ HANDLE ,    NullableValue . of ( VARCHAR ,    Slices . utf 8 Slice ( Integer . toString ( i )  )  )  )  )  )  ;", "}", "partitions . add ( new   HivePartition ( new   SchemaTableName (  \" test \"  ,     \" test \"  )  ,     \" null \"  ,    ImmutableMap . of (  . TEST _ COLUMN _ HANDLE ,    NullableValue . asNull ( VARCHAR )  )  )  )  ;", "HiveMetadata . createPredicate ( ImmutableList . of (  . TEST _ COLUMN _ HANDLE )  ,    partitions . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateMixedPredicate"], "fileName": "com.facebook.presto.hive.TestHiveMetadata"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HivePartition >    partitions    =    ImmutableList . builder (  )  ;", "for    ( int   i    =     0  ;    i    <     5  ;    i +  +  )     {", "partitions . add ( new   HivePartition ( new   SchemaTableName (  \" test \"  ,     \" test \"  )  ,    Integer . toString ( i )  ,    ImmutableMap . of (  . TEST _ COLUMN _ HANDLE ,    NullableValue . asNull ( VARCHAR )  )  )  )  ;", "}", "HiveMetadata . createPredicate ( ImmutableList . of (  . TEST _ COLUMN _ HANDLE )  ,    partitions . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateOnlyNullsPredicate"], "fileName": "com.facebook.presto.hive.TestHiveMetadata"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HivePartition >    partitions    =    ImmutableList . builder (  )  ;", "for    ( int   i    =     0  ;    i    <     5  0  0  0  ;    i +  +  )     {", "partitions . add ( new   HivePartition ( new   SchemaTableName (  \" test \"  ,     \" test \"  )  ,    Integer . toString ( i )  ,    ImmutableMap . of (  . TEST _ COLUMN _ HANDLE ,    NullableValue . of ( VARCHAR ,    Slices . utf 8 Slice ( Integer . toString ( i )  )  )  )  )  )  ;", "}", "HiveMetadata . createPredicate ( ImmutableList . of (  . TEST _ COLUMN _ HANDLE )  ,    partitions . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreatePredicate"], "fileName": "com.facebook.presto.hive.TestHiveMetadata"}, {"methodBody": ["METHOD_START", "{", "LocationHandle   locationHandle    =    new   LocationHandle ( outputPath ,    Optional . of ( outputPath )  ,    false )  ;", "HiveOutputTableHandle   handle    =    new   HiveOutputTableHandle ( TestHivePageSink . SCHEMA _ NAME ,    TestHivePageSink . TABLE _ NAME ,    TestHivePageSink . getColumnHandles (  )  ,     \" test \"  ,    new   HivePageSinkMetadata ( new   SchemaTableName ( TestHivePageSink . SCHEMA _ NAME ,    TestHivePageSink . TABLE _ NAME )  ,    metastore . getTable ( TestHivePageSink . SCHEMA _ NAME ,    TestHivePageSink . TABLE _ NAME )  ,    ImmutableMap . of (  )  )  ,    locationHandle ,    config . getHiveStorageFormat (  )  ,    config . getHiveStorageFormat (  )  ,    ImmutableList . of (  )  ,    Optional . empty (  )  ,     \" test \"  ,    ImmutableMap . of (  )  )  ;", "JsonCodec < PartitionUpdate >    partitionUpdateCodec    =    JsonCodec . jsonCodec ( PartitionUpdate . class )  ;", "HdfsEnvironment   hdfsEnvironment    =    HiveTestUtils . createTestHdfsEnvironment ( config )  ;", "HivePageSinkProvider   provider    =    new   HivePageSinkProvider ( HiveTestUtils . getDefaultHiveFileWriterFactories ( config )  ,    hdfsEnvironment ,    metastore ,    new   GroupByHashPageIndexerFactory ( new   JoinCompiler (  )  )  ,    HiveTestUtils . TYPE _ MANAGER ,    config ,    new   HiveLocationService ( hdfsEnvironment )  ,    partitionUpdateCodec ,    new   TestingNodeManager (  \" fake - environment \"  )  ,    new   HiveEventClient (  )  ,    new   HiveSessionProperties ( config ,    new   OrcFileWriterConfig (  )  )  ,    stats )  ;", "return   provider . createPageSink ( transaction ,    TestHivePageSink . getSession ( config )  ,    handle )  ;", "}", "METHOD_END"], "methodName": ["createPageSink"], "fileName": "com.facebook.presto.hive.TestHivePageSink"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HiveColumnHandle >    handles    =    ImmutableList . builder (  )  ;", "List < LineItemColumn >    columns    =     . getTestColumns (  )  ;", "for    ( int   i    =     0  ;    i    <     ( columns . size (  )  )  ;    i +  +  )     {", "LineItemColumn   column    =    columns . get ( i )  ;", "HiveType   hiveType    =     . getHiveType ( column . getType (  )  )  ;", "handles . add ( new   HiveColumnHandle ( column . getColumnName (  )  ,    hiveType ,    hiveType . getTypeSignature (  )  ,    i ,    HiveColumnHandle . ColumnType . REGULAR ,    Optional . empty (  )  )  )  ;", "}", "return   handles . build (  )  ;", "}", "METHOD_END"], "methodName": ["getColumnHandles"], "fileName": "com.facebook.presto.hive.TestHivePageSink"}, {"methodBody": ["METHOD_START", "{", "switch    ( type . getBase (  )  )     {", "case   IDENTIFIER    :", "return   HiveType . HIVE _ LONG ;", "case   spi . type . IntegerType . INTEGER    :", "return   HiveType . HIVE _ INT ;", "case   spi . type . DateType . DATE    :", "return   HiveType . HIVE _ DATE ;", "case   spi . type . DoubleType . DOUBLE    :", "return   HiveType . HIVE _ DOUBLE ;", "case   VARCHAR    :", "return   HiveType . HIVE _ STRING ;", "default    :", "throw   new   UnsupportedOperationException (  )  ;", "}", "}", "METHOD_END"], "methodName": ["getHiveType"], "fileName": "com.facebook.presto.hive.TestHivePageSink"}, {"methodBody": ["METHOD_START", "{", "return   new   com . facebook . presto . testing . TestingConnectorSession ( new   HiveSessionProperties ( config ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "}", "METHOD_END"], "methodName": ["getSession"], "fileName": "com.facebook.presto.hive.TestHivePageSink"}, {"methodBody": ["METHOD_START", "{", "return   Stream . of ( LineItemColumn . values (  )  )  . filter (  (    column )     -  >     !  ( column . getType (  )  . equals ( TpchColumnTypes . DATE )  )  )  . collect ( Collectors . toList (  )  )  ;", "}", "METHOD_END"], "methodName": ["getTestColumns"], "fileName": "com.facebook.presto.hive.TestHivePageSink"}, {"methodBody": ["METHOD_START", "{", "return    (  (  (  ( tempDir . getAbsolutePath (  )  )     +     \"  /  \"  )     +     ( config . getHiveStorageFormat (  )  . name (  )  )  )     +     \"  .  \"  )     +     ( config . getHiveCompressionCodec (  )  . name (  )  )  ;", "}", "METHOD_END"], "methodName": ["makeFileName"], "fileName": "com.facebook.presto.hive.TestHivePageSink"}, {"methodBody": ["METHOD_START", "{", "HiveClientConfig   config    =    new   HiveClientConfig (  )  ;", "File   tempDir    =    Files . createTempDir (  )  ;", "try    {", "ExtendedHiveMetastore   metastore    =    new   TestingHiveMetastore ( new   File ( tempDir ,     \" metastore \"  )  )  ;", "for    ( HiveStorageFormat   format    :    HiveStorageFormat . values (  )  )     {", "config . setHiveStorageFormat ( format )  ;", "config . setHiveCompressionCodec ( HiveCompressionCodec . NONE )  ;", "long   uncompressedLength    =     . writeTestFile ( config ,    metastore ,     . makeFileName ( tempDir ,    config )  )  ;", "Assertions . assertGreaterThan ( uncompressedLength ,     0 L )  ;", "for    ( HiveCompressionCodec   codec    :    HiveCompressionCodec . values (  )  )     {", "if    ( codec    =  =     ( HiveCompressionCodec . NONE )  )     {", "continue ;", "}", "config . setHiveCompressionCodec ( codec )  ;", "long   length    =     . writeTestFile ( config ,    metastore ,     . makeFileName ( tempDir ,    config )  )  ;", "assertTrue (  ( uncompressedLength    >    length )  ,    String . format (  \"  % s   with    % s   compressed   to    % s   which   is   not   less   than    % s \"  ,    format ,    codec ,    length ,    uncompressedLength )  )  ;", "}", "}", "}    finally    {", "deleteRecursively ( tempDir . toPath (  )  ,    ALLOW _ INSECURE )  ;", "}", "}", "METHOD_END"], "methodName": ["testAllFormats"], "fileName": "com.facebook.presto.hive.TestHivePageSink"}, {"methodBody": ["METHOD_START", "{", "MaterializedResult . Builder   resultBuilder    =    MaterializedResult . resultBuilder ( session ,    types )  ;", "for    (    output    :    pages )     {", "resultBuilder . page ( output )  ;", "}", "return   resultBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["toMaterializedResult"], "fileName": "com.facebook.presto.hive.TestHivePageSink"}, {"methodBody": ["METHOD_START", "{", "return   MoreFutures . getFutureValue ( source . getNextBatch ( NotPartitionedPartitionHandle . NOT _ PARTITIONED ,    maxSize )  )  . getSplits (  )  ;", "}", "METHOD_END"], "methodName": ["getSplits"], "fileName": "com.facebook.presto.hive.TestHiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "HiveSplitSource   hiveSplitSource    =    HiveSplitSource . allAtOnce ( HiveTestUtils . SESSION ,     \" database \"  ,     \" table \"  ,    TupleDomain . all (  )  ,     1  0  ,     1  0  ,    new   io . airlift . units . DataSize (  1  ,    MEGABYTE )  ,    new   TestHiveSplitSource . TestingHiveSplitLoader (  )  ,    Executors . newFixedThreadPool (  5  )  ,    new   CounterStat (  )  )  ;", "for    ( int   i    =     0  ;    i    <     5  ;    i +  +  )     {", "hiveSplitSource . addToQueue ( new   TestHiveSplitSource . TestSplit ( i )  )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     ( i    +     1  )  )  ;", "}", "assertEquals ( TestHiveSplitSource . getSplits ( hiveSplitSource ,     1  )  . size (  )  ,     1  )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     4  )  ;", "hiveSplitSource . fail ( new   RuntimeException (  \" test \"  )  )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     4  )  ;", "try    {", "TestHiveSplitSource . getSplits ( hiveSplitSource ,     1  )  ;", "fail (  \" expected   RuntimeException \"  )  ;", "}    catch    ( RuntimeException   e )     {", "assertEquals ( e . getMessage (  )  ,     \" test \"  )  ;", "}", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     4  )  ;", "hiveSplitSource . addToQueue ( new   TestHiveSplitSource . TestSplit (  9  9  )  )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     4  )  ;", "hiveSplitSource . fail ( new   RuntimeException (  \" another   failure \"  )  )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     4  )  ;", "try    {", "TestHiveSplitSource . getSplits ( hiveSplitSource ,     1  )  ;", "fail (  \" expected   RuntimeException \"  )  ;", "}    catch    ( RuntimeException   e )     {", "assertEquals ( e . getMessage (  )  ,     \" test \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testFail"], "fileName": "com.facebook.presto.hive.TestHiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "HiveSplitSource   hiveSplitSource    =    HiveSplitSource . allAtOnce ( HiveTestUtils . SESSION ,     \" database \"  ,     \" table \"  ,    TupleDomain . all (  )  ,     1  0  ,     1  0  ,    new   io . airlift . units . DataSize (  1  ,    MEGABYTE )  ,    new   TestHiveSplitSource . TestingHiveSplitLoader (  )  ,    Executors . newFixedThreadPool (  5  )  ,    new   CounterStat (  )  )  ;", "for    ( int   i    =     0  ;    i    <     1  0  ;    i +  +  )     {", "hiveSplitSource . addToQueue ( new   TestHiveSplitSource . TestSplit ( i )  )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     ( i    +     1  )  )  ;", "}", "assertEquals ( TestHiveSplitSource . getSplits ( hiveSplitSource ,     1  )  . size (  )  ,     1  )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     9  )  ;", "assertEquals ( TestHiveSplitSource . getSplits ( hiveSplitSource ,     4  )  . size (  )  ,     4  )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     5  )  ;", "assertEquals ( TestHiveSplitSource . getSplits ( hiveSplitSource ,     2  0  )  . size (  )  ,     5  )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testOutstandingSplitCount"], "fileName": "com.facebook.presto.hive.TestHiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "DataSize   maxOutstandingSplitsSize    =    new   DataSize (  1  ,    MEGABYTE )  ;", "HiveSplitSource   hiveSplitSource    =    HiveSplitSource . allAtOnce ( HiveTestUtils . SESSION ,     \" database \"  ,     \" table \"  ,    TupleDomain . all (  )  ,     1  0  ,     1  0  0  0  0  ,    maxOutstandingSplitsSize ,    new    . TestingHiveSplitLoader (  )  ,    Executors . newFixedThreadPool (  5  )  ,    new   CounterStat (  )  )  ;", "InternalHiveSplit   testSplit    =    new   InternalHiveSplit (  \" partition - name \"  ,     \" path \"  ,     0  ,     1  0  0  ,     1  0  0  ,    new   Properties (  )  ,    ImmutableList . of ( new   HivePartitionKey (  \" pk _ col \"  ,     \" pk _ value \"  )  )  ,    ImmutableList . of ( new   InternalHiveSplit . InternalHiveBlock (  0  ,     1  0  0  ,    ImmutableList . of ( HostAddress . fromString (  \" localhost \"  )  )  )  )  ,    OptionalInt . empty (  )  ,    true ,    false ,    ImmutableMap . of (  )  ,    Optional . empty (  )  )  ;", "int   testSplitSizeInBytes    =    testSplit . getEstimatedSizeInBytes (  )  ;", "int   maxSplitCount    =     ( Math . toIntExact ( maxOutstandingSplitsSize . toBytes (  )  )  )     /    testSplitSizeInBytes ;", "for    ( int   i    =     0  ;    i    <    maxSplitCount ;    i +  +  )     {", "hiveSplitSource . addToQueue ( testSplit )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     ( i    +     1  )  )  ;", "}", "assertEquals (  . getSplits ( hiveSplitSource ,    maxSplitCount )  . size (  )  ,    maxSplitCount )  ;", "for    ( int   i    =     0  ;    i    <    maxSplitCount ;    i +  +  )     {", "hiveSplitSource . addToQueue ( testSplit )  ;", "assertEquals ( hiveSplitSource . getBufferedInternalSplitCount (  )  ,     ( i    +     1  )  )  ;", "}", "try    {", "hiveSplitSource . addToQueue ( testSplit )  ;", "fail (  \" expect   failure \"  )  ;", "}    catch    ( PrestoException   e )     {", "Assertions . assertContains ( e . getMessage (  )  ,     \" Split   buffering   for   database . table   exceeded   memory   limit \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testOutstandingSplitSize"], "fileName": "com.facebook.presto.hive.TestHiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "final   HiveSplitSource   hiveSplitSource    =    HiveSplitSource . allAtOnce ( HiveTestUtils . SESSION ,     \" database \"  ,     \" table \"  ,    TupleDomain . all (  )  ,     1  0  ,     1  0  ,    new   io . airlift . units . DataSize (  1  ,    MEGABYTE )  ,    new   TestHiveSplitSource . TestingHiveSplitLoader (  )  ,    Executors . newFixedThreadPool (  5  )  ,    new   CounterStat (  )  )  ;", "final   SettableFuture < ConnectorSplit >    splits    =    SettableFuture . create (  )  ;", "final   CountDownLatch   started    =    new   CountDownLatch (  1  )  ;", "Thread   getterThread    =    new   Thread ( new   Runnable (  )     {", "@ Override", "public   void   run (  )     {", "try    {", "started . countDown (  )  ;", "List < ConnectorSplit >    batch    =    TestHiveSplitSource . getSplits ( hiveSplitSource ,     1  )  ;", "assertEquals ( batch . size (  )  ,     1  )  ;", "splits . set ( batch . get (  0  )  )  ;", "}    catch    ( Throwable   e )     {", "splits . setException ( e )  ;", "}", "}", "}  )  ;", "getterThread . start (  )  ;", "try    {", "assertTrue ( started . await (  1  ,    TimeUnit . SECONDS )  )  ;", "TimeUnit . MILLISECONDS . sleep (  2  0  0  )  ;", "assertTrue (  (  !  ( splits . isDone (  )  )  )  )  ;", "hiveSplitSource . addToQueue ( new   TestHiveSplitSource . TestSplit (  3  3  )  )  ;", "ConnectorSplit   split    =    splits . get (  8  0  0  ,    TimeUnit . MILLISECONDS )  ;", "assertEquals (  (  ( HiveSplit )     ( split )  )  . getSchema (  )  . getProperty (  \" id \"  )  ,     \"  3  3  \"  )  ;", "}    finally    {", "getterThread . interrupt (  )  ;", "}", "}", "METHOD_END"], "methodName": ["testReaderWaitsForSplits"], "fileName": "com.facebook.presto.hive.TestHiveSplitSource"}, {"methodBody": ["METHOD_START", "{", "HiveTableHandle   expected    =    new   HiveTableHandle (  \" schema \"  ,     \" table \"  )  ;", "String   json    =    codec . toJson ( expected )  ;", "HiveTableHandle   actual    =    codec . fromJson ( json )  ;", "assertEquals ( actual . getSchemaTableName (  )  ,    expected . getSchemaTableName (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoundTrip"], "fileName": "com.facebook.presto.hive.TestHiveTableHandle"}, {"methodBody": ["METHOD_START", "{", "Type   type    =    HiveTestUtils . TYPE _ MANAGER . getType ( TypeSignature . parseTypeSignature ( typeName )  )  ;", "assertEquals ( HiveType . toHiveType ( t ,    type )  ,    hiveType )  ;", "}", "METHOD_END"], "methodName": ["assertTypeTranslation"], "fileName": "com.facebook.presto.hive.TestHiveTypeTranslator"}, {"methodBody": ["METHOD_START", "{", "for    ( Map . Entry < String ,    HiveType >    entry    :    typeTranslationMap . entrySet (  )  )     {", "assertion ( entry . getKey (  )  ,    entry . getValue (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testTypeTranslator"], "fileName": "com.facebook.presto.hive.TestHiveTypeTranslator"}, {"methodBody": ["METHOD_START", "{", "List < String >    actual    =    HiveUtil . toPartitionValues ( partitionName )  ;", "AbstractList < String >    expected    =    new   ArrayList <  >  (  )  ;", "for    ( String   s    :    actual )     {", "expected . add ( null )  ;", "}", "Warehouse . makeValsFromName ( partitionName ,    expected )  ;", "assertEquals ( actual ,    expected )  ;", "}", "METHOD_END"], "methodName": ["assertToPartitionValues"], "fileName": "com.facebook.presto.hive.TestHiveUtil"}, {"methodBody": ["METHOD_START", "{", "String   defaultId    =    DateTimeZone . getDefault (  )  . getID (  )  ;", "for    ( String   id    :    DateTimeZone . getAvailableIDs (  )  )     {", "if    (  !  ( id . equals ( defaultId )  )  )     {", "DateTimeZone   zone    =    DateTimeZone . forID ( id )  ;", "if    (  ( zone . getStandardOffset (  0  )  )     !  =     0  )     {", "return   zone ;", "}", "}", "}", "throw   new   IllegalStateException (  \" no   non - default   timezone \"  )  ;", "}", "METHOD_END"], "methodName": ["nonDefaultTimeZone"], "fileName": "com.facebook.presto.hive.TestHiveUtil"}, {"methodBody": ["METHOD_START", "{", "return   HiveUtil . parseHiveTimestamp ( DateTimeFormat . forPattern ( pattern )  . print ( time )  ,    TestHiveUtil . nonDefaultTimeZone (  )  )  ;", "}", "METHOD_END"], "methodName": ["parse"], "fileName": "com.facebook.presto.hive.TestHiveUtil"}, {"methodBody": ["METHOD_START", "{", "Properties   schema    =    new   Properties (  )  ;", "schema . setProperty ( serdeConstants . SERIALIZATION _ LIB ,    ThriftDeserializer . class . getName (  )  )  ;", "schema . setProperty ( serdeConstants . SERIALIZATION _ CLASS ,    IntString . class . getName (  )  )  ;", "schema . setProperty ( serdeConstants . SERIALIZATION _ FORMAT ,    TBinaryProtocol . class . getName (  )  )  ;", "Assertions . assertInstanceOf (  . getDeserializer ( schema )  ,    ThriftDeserializer . class )  ;", "}", "METHOD_END"], "methodName": ["testGetThriftDeserializer"], "fileName": "com.facebook.presto.hive.TestHiveUtil"}, {"methodBody": ["METHOD_START", "{", "DateTime   time    =    new   DateTime (  2  0  1  1  ,     5  ,     6  ,     7  ,     8  ,     9  ,     1  2  3  ,    TestHiveUtil . nonDefaultTimeZone (  )  )  ;", "assertEquals ( TestHiveUtil . parse ( time ,     \" yyyy - MM - dd   HH : mm : ss \"  )  ,    TestHiveUtil . unixTime ( time ,     0  )  )  ;", "assertEquals ( TestHiveUtil . parse ( time ,     \" yyyy - MM - dd   HH : mm : ss . S \"  )  ,    TestHiveUtil . unixTime ( time ,     1  )  )  ;", "assertEquals ( TestHiveUtil . parse ( time ,     \" yyyy - MM - dd   HH : mm : ss . SSS \"  )  ,    TestHiveUtil . unixTime ( time ,     3  )  )  ;", "assertEquals ( TestHiveUtil . parse ( time ,     \" yyyy - MM - dd   HH : mm : ss . SSSSSSS \"  )  ,    TestHiveUtil . unixTime ( time ,     6  )  )  ;", "assertEquals ( TestHiveUtil . parse ( time ,     \" yyyy - MM - dd   HH : mm : ss . SSSSSSSSS \"  )  ,    TestHiveUtil . unixTime ( time ,     7  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseHiveTimestamp"], "fileName": "com.facebook.presto.hive.TestHiveUtil"}, {"methodBody": ["METHOD_START", "{", "TestHiveUtil . assertToPartitionValues (  \" ds =  2  0  1  5  -  1  2  -  3  0  / event _ type = QueryCompletion \"  )  ;", "TestHiveUtil . assertToPartitionValues (  \" ds =  2  0  1  5  -  1  2  -  3  0  \"  )  ;", "TestHiveUtil . assertToPartitionValues (  \" a =  1  / b =  2  / c =  3  \"  )  ;", "TestHiveUtil . assertToPartitionValues (  \" a =  1  \"  )  ;", "TestHiveUtil . assertToPartitionValues (  \" pk =  !  @  %  2  3  $  %  2  5  %  5 E &  %  2 A (  )  %  2 F %  3 D \"  )  ;", "TestHiveUtil . assertToPartitionValues (  \" pk =  _  _ HIVE _ DEFAULT _ PARTITION _  _  \"  )  ;", "}", "METHOD_END"], "methodName": ["testToPartitionValues"], "fileName": "com.facebook.presto.hive.TestHiveUtil"}, {"methodBody": ["METHOD_START", "{", "int   factor    =     (  ( int )     ( Math . pow (  1  0  ,    Math . max (  0  ,     (  3     -    factionalDigits )  )  )  )  )  ;", "return    (  ( time . getMillis (  )  )     /    factor )     *    factor ;", "}", "METHOD_END"], "methodName": ["unixTime"], "fileName": "com.facebook.presto.hive.TestHiveUtil"}, {"methodBody": ["METHOD_START", "{", "HdfsEnvironment   hdfsEnvironment    =    HiveTestUtils . createTestHdfsEnvironment ( new   HiveClientConfig (  )  )  ;", "assertTrue ( HiveWriteUtils . isS 3 FileSystem (  . CONTEXT ,    hdfsEnvironment ,    new   Path (  \" s 3  :  /  / test - bucket / test - folder \"  )  )  )  ;", "assertFalse ( HiveWriteUtils . isS 3 FileSystem (  . CONTEXT ,    hdfsEnvironment ,    new   Path (  \"  / test - dir / test - folder \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testIsS3FileSystem"], "fileName": "com.facebook.presto.hive.TestHiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "HdfsEnvironment   hdfsEnvironment    =    HiveTestUtils . createTestHdfsEnvironment ( new   HiveClientConfig (  )  )  ;", "Path   viewfsPath    =    new   Path (  \" viewfs :  /  / ns - default / test - folder \"  )  ;", "Path   nonViewfsPath    =    new   Path (  \" hdfs :  /  / localhost / test - dir / test - folder \"  )  ;", "hdfsEnvironment . getConfiguration (  . CONTEXT ,    viewfsPath )  . set (  \" fs . viewfs . mounttable . ns - default . link .  / test - folder \"  ,     \" hdfs :  /  / localhost / app \"  )  ;", "assertTrue ( HiveWriteUtils . isViewFileSystem (  . CONTEXT ,    hdfsEnvironment ,    viewfsPath )  )  ;", "assertFalse ( HiveWriteUtils . isViewFileSystem (  . CONTEXT ,    hdfsEnvironment ,    nonViewfsPath )  )  ;", "}", "METHOD_END"], "methodName": ["testIsViewFileSystem"], "fileName": "com.facebook.presto.hive.TestHiveWriteUtils"}, {"methodBody": ["METHOD_START", "{", "HiveColumnHandle   columnHandle    =    new   HiveColumnHandle (  \" column \"  ,    HiveType . HIVE _ FLOAT ,    TypeSignature . parseTypeSignature ( DOUBLE )  ,     (  -  1  )  ,    HiveColumnHandle . ColumnType . PARTITION _ KEY ,    Optional . of (  \" comment \"  )  )  ;", "assertTrue ( objectMapper . canSerialize ( HiveColumnHandle . class )  )  ;", "String   json    =    objectMapper . writeValueAsString ( columnHandle )  ;", "testJsonEquals ( json ,     . COLUMN _ HANDLE _ AS _ MAP )  ;", "}", "METHOD_END"], "methodName": ["testColumnHandleSerialize"], "fileName": "com.facebook.presto.hive.TestJsonHiveHandles"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    jsonMap    =    objectMapper . readValue ( json ,    new   TypeReference < Map < String ,    Object >  >  (  )     {  }  )  ;", "Assertions . assertEqualsIgnoreOrder ( jsonMap . entrySet (  )  ,    expectedMap . entrySet (  )  )  ;", "}", "METHOD_END"], "methodName": ["testJsonEquals"], "fileName": "com.facebook.presto.hive.TestJsonHiveHandles"}, {"methodBody": ["METHOD_START", "{", "String   json    =    objectMapper . writeValueAsString ( TestJsonHiveHandles . TABLE _ HANDLE _ AS _ MAP )  ;", "HiveTableHandle   tableHandle    =    objectMapper . readValue ( json ,    HiveTableHandle . class )  ;", "assertEquals ( tableHandle . getSchemaName (  )  ,     \" hive _ schema \"  )  ;", "assertEquals ( tableHandle . getTableName (  )  ,     \" hive _ table \"  )  ;", "assertEquals ( tableHandle . getSchemaTableName (  )  ,    new   SchemaTableName (  \" hive _ schema \"  ,     \" hive _ table \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testTableHandleDeserialize"], "fileName": "com.facebook.presto.hive.TestJsonHiveHandles"}, {"methodBody": ["METHOD_START", "{", "HiveTableHandle   tableHandle    =    new   HiveTableHandle (  \" hive _ schema \"  ,     \" hive _ table \"  )  ;", "assertTrue ( objectMapper . canSerialize ( HiveTableHandle . class )  )  ;", "String   json    =    objectMapper . writeValueAsString ( tableHandle )  ;", "testJsonEquals ( json ,     . TABLE _ HANDLE _ AS _ MAP )  ;", "}", "METHOD_END"], "methodName": ["testTableHandleSerialize"], "fileName": "com.facebook.presto.hive.TestJsonHiveHandles"}, {"methodBody": ["METHOD_START", "{", "assertRecordedDefaults ( recordDefaults ( OrcFileWriterConfig . class )  . setStripeMaxSize ( new   io . airlift . units . DataSize (  6  4  ,    MEGABYTE )  )  . setStripeMinRowCount (  1  0  0  0  0  0  )  . setStripeMaxRowCount (  1  0  0  0  0  0  0  0  )  . setRowGroupMaxRowCount (  1  0  0  0  0  )  . setDictionaryMaxMemory ( new   io . airlift . units . DataSize (  1  6  ,    MEGABYTE )  )  . setStringStatisticsLimit ( new   io . airlift . units . DataSize (  6  4  ,    BYTE )  )  . setMaxCompressionBufferSize ( new   io . airlift . units . DataSize (  2  5  6  ,    KILOBYTE )  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "com.facebook.presto.hive.TestOrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . orc . writer . stripe - max - size \"  ,     \"  2  7 MB \"  )  . put (  \" hive . orc . writer . stripe - min - rows \"  ,     \"  3  3  \"  )  . put (  \" hive . orc . writer . stripe - max - rows \"  ,     \"  4  4  \"  )  . put (  \" hive . orc . writer . row - group - max - rows \"  ,     \"  1  1  \"  )  . put (  \" hive . orc . writer . dictionary - max - memory \"  ,     \"  1  3 MB \"  )  . put (  \" hive . orc . writer . string - statistics - limit \"  ,     \"  1  7 MB \"  )  . put (  \" hive . orc . writer . max - compression - buffer - size \"  ,     \"  1  9 MB \"  )  . build (  )  ;", "expected    =    new    (  )  . setStripeMaxSize ( new   io . airlift . units . DataSize (  2  7  ,    MEGABYTE )  )  . setStripeMinRowCount (  3  3  )  . setStripeMaxRowCount (  4  4  )  . setRowGroupMaxRowCount (  1  1  )  . setDictionaryMaxMemory ( new   io . airlift . units . DataSize (  1  3  ,    MEGABYTE )  )  . setStringStatisticsLimit ( new   io . airlift . units . DataSize (  1  7  ,    MEGABYTE )  )  . setMaxCompressionBufferSize ( new   io . airlift . units . DataSize (  1  9  ,    MEGABYTE )  )  ;", "assertFullMapping ( properties ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMappings"], "fileName": "com.facebook.presto.hive.TestOrcFileWriterConfig"}, {"methodBody": ["METHOD_START", "{", "try    ( ThreadContextClassLoader   ignored    =    new   ThreadContextClassLoader ( FileSystem . class . getClassLoader (  )  )  )     {", "WriterOptions   options    =    new   OrcWriterOptions ( conf )  . memory ( new   NullMemoryManager ( conf )  )  . compress ( ZLIB )  ;", "try    {", "return    . WRITER _ CONSTRUCTOR . newInstance ( target ,    options )  ;", "}    catch    ( ReflectiveOperationException   e )     {", "throw   new   RuntimeException ( e )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["createRecordWriter"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "testColumns    =    ImmutableList . copyOf ( filter ( testColumns ,    not ( TestOrcPageSourceMemoryTracking . TestColumn :  : isPartitionKey )  )  )  ;", "Properties   tableProperties    =    new   Properties (  )  ;", "tableProperties . setProperty (  \" columns \"  ,    Joiner . on (  '  ,  '  )  . join ( transform ( testColumns ,    TestOrcPageSourceMemoryTracking . TestColumn :  : getName )  )  )  ;", "tableProperties . setProperty (  \" columns . types \"  ,    Joiner . on (  '  ,  '  )  . join ( transform ( testColumns ,    TestOrcPageSourceMemoryTracking . TestColumn :  : getType )  )  )  ;", "serDe . initialize ( TestOrcPageSourceMemoryTracking . CONFIGURATION ,    tableProperties )  ;", "JobConf   jobConf    =    new   JobConf (  )  ;", "if    ( compressionCodec    !  =    null )     {", "CompressionCodec   codec    =    new   CompressionCodecFactory ( TestOrcPageSourceMemoryTracking . CONFIGURATION )  . getCodecByName ( compressionCodec )  ;", "jobConf . set ( FileOutputFormat . COMPRESS _ CODEC ,    codec . getClass (  )  . getName (  )  )  ;", "jobConf . set ( FileOutputFormat . COMPRESS _ TYPE ,    BLOCK . toString (  )  )  ;", "}", "RecordWriter   recordWriter    =    TestOrcPageSourceMemoryTracking . createRecordWriter ( new   Path ( filePath )  ,    TestOrcPageSourceMemoryTracking . CONFIGURATION )  ;", "try    {", "SettableStructObjectInspector   objectInspector    =    ObjectInspectorFactory . getStandardStructObjectInspector ( ImmutableList . copyOf ( transform ( testColumns ,    TestOrcPageSourceMemoryTracking . TestColumn :  : getName )  )  ,    ImmutableList . copyOf ( transform ( testColumns ,    TestOrcPageSourceMemoryTracking . TestColumn :  : getObjectInspector )  )  )  ;", "Object   row    =    objectInspector . create (  )  ;", "List < StructField >    fields    =    ImmutableList . copyOf ( objectInspector . getAllStructFieldRefs (  )  )  ;", "for    ( int   rowNumber    =     0  ;    rowNumber    <    numRows ;    rowNumber +  +  )     {", "for    ( int   i    =     0  ;    i    <     ( testColumns . size (  )  )  ;    i +  +  )     {", "Object   writeValue    =    testColumns . get ( i )  . getWriteValue (  )  ;", "if    ( writeValue   instanceof   Slice )     {", "writeValue    =     (  ( Slice )     ( writeValue )  )  . getBytes (  )  ;", "}", "objectInspector . setStructFieldData ( row ,    fields . get ( i )  ,    writeValue )  ;", "}", "Writable   record    =    serDe . serialize ( row ,    objectInspector )  ;", "recordWriter . write ( record )  ;", "if    (  ( rowNumber    %    stripeRows )     =  =     ( stripeRows    -     1  )  )     {", "TestOrcPageSourceMemoryTracking . flushStripe ( recordWriter )  ;", "}", "}", "}    finally    {", "recordWriter . close ( false )  ;", "}", "Path   path    =    new   Path ( filePath )  ;", "path . getFileSystem ( TestOrcPageSourceMemoryTracking . CONFIGURATION )  . setVerifyChecksum ( true )  ;", "File   file    =    new   File ( filePath )  ;", "return   new   FileSplit ( path ,     0  ,    file . length (  )  ,    new   String [  0  ]  )  ;", "}", "METHOD_END"], "methodName": ["createTestFile"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "try    {", "Field   writerField    =    OrcOutputFormat . class . getClassLoader (  )  . loadClass (  . ORC _ RECORD _ WRITER )  . getDeclaredField (  \" writer \"  )  ;", "writerField . setAccessible ( true )  ;", "Writer   writer    =     (  ( Writer )     ( writerField . get ( recordWriter )  )  )  ;", "Method   flushStripe    =    WriterImpl . class . getDeclaredMethod (  \" flushStripe \"  )  ;", "flushStripe . setAccessible ( true )  ;", "flushStripe . invoke ( writer )  ;", "}    catch    ( ReflectiveOperationException   e )     {", "throw   Throwables . propagate ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["flushStripe"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "try    {", "Constructor <  ?    extends   RecordWriter >    constructor    =    OrcOutputFormat . class . getClassLoader (  )  . loadClass (  . ORC _ RECORD _ WRITER )  . asSubclass ( RecordWriter . class )  . getDeclaredConstructor ( Path . class ,    WriterOptions . class )  ;", "constructor . setAccessible ( true )  ;", "return   constructor ;", "}    catch    ( ReflectiveOperationException   e )     {", "throw   Throwables . propagate ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["getOrcWriterConstructor"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "return   new   Object [  ]  [  ]  {    new   Object [  ]  {     5  0  0  0  0     }  ,    new   Object [  ]  {     1  0  0  0  0     }  ,    new   Object [  ]  {     5  0  0  0     }     }  ;", "}", "METHOD_END"], "methodName": ["rowCount"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "tempFile    =    File . createTempFile (  \" presto _ test _ orc _ page _ source _ memory _ tracking \"  ,     \" orc \"  )  ;", "tempFile . delete (  )  ;", "testPreparer    =    new    . TestPreparer ( tempFile . getAbsolutePath (  )  )  ;", "}", "METHOD_END"], "methodName": ["setUp"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "tempFile . delete (  )  ;", "}", "METHOD_END"], "methodName": ["tearDown"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "int   maxReadBytes    =     1  0  0  0  ;", "HiveClientConfig   config    =    new   HiveClientConfig (  )  ;", "config . setOrcMaxReadBlockSize ( new   io . airlift . units . DataSize ( maxReadBytes ,    BYTE )  )  ;", "ConnectorSession   session    =    new   com . facebook . presto . testing . TestingConnectorSession ( new   HiveSessionProperties ( config ,    new   OrcFileWriterConfig (  )  )  . getSessionProperties (  )  )  ;", "FileFormatDataSourceStats   stats    =    new   FileFormatDataSourceStats (  )  ;", "int   numColumns    =     5  ;", "int   step    =     2  5  0  ;", "ImmutableList . Builder <  . TestColumn >    columnBuilder    =    ImmutableList .  <  . TestColumn > builder (  )  . add ( new    . TestColumn (  \" p _ empty _ string \"  ,    PrimitiveObjectInspectorFactory . javaStringObjectInspector ,     (  )     -  >     \"  \"  ,    true )  )  ;", ". GrowingTestColumn [  ]    dataColumns    =    new    . GrowingTestColumn [ numColumns ]  ;", "for    ( int   i    =     0  ;    i    <    numColumns ;    i +  +  )     {", "dataColumns [ i ]     =    new    . GrowingTestColumn (  \" p _ string \"  ,    PrimitiveObjectInspectorFactory . javaStringObjectInspector ,     (  )     -  >    Long . toHexString ( random . nextLong (  )  )  ,    false ,     ( step    *     ( i    +     1  )  )  )  ;", "columnBuilder . add ( dataColumns [ i ]  )  ;", "}", "List <  . TestColumn >    testColumns    =    columnBuilder . build (  )  ;", "File   tempFile    =    File . createTempFile (  \" presto _ test _ orc _ page _ source _ max _ read _ bytes \"  ,     \" orc \"  )  ;", "tempFile . delete (  )  ;", ". TestPreparer   testPreparer    =    new    . TestPreparer ( tempFile . getAbsolutePath (  )  ,    testColumns ,    rowCount ,    rowCount )  ;", "ConnectorPageSource   pageSource    =    testPreparer . newPageSource ( stats ,    session )  ;", "try    {", "int   positionCount    =     0  ;", "while    ( true )     {", "Page   page    =    pageSource . getNextPage (  )  ;", "if    ( pageSource . isFinished (  )  )     {", "break ;", "}", "assertNotNull ( page )  ;", "page . assureLoaded (  )  ;", "positionCount    +  =    page . getPositionCount (  )  ;", "if    ( positionCount    >     ( MAX _ BATCH _ SIZE )  )     {", "assertTrue (  (  (  ( page . getSizeInBytes (  )  )     <     ( maxReadBytes    *     (  ( MAX _ BATCH _ SIZE )     /    step )  )  )     |  |     (  1     =  =     ( page . getPositionCount (  )  )  )  )  )  ;", "}", "}", "Distribution   distribution    =    stats . getMaxCombinedBytesPerRow (  )  . getAllTime (  )  ;", "assertEquals (  (  ( int )     ( distribution . getCount (  )  )  )  ,     1  )  ;", "assertEquals (  (  ( int )     ( distribution . getMax (  )  )  )  ,     (  ( Arrays . stream ( dataColumns )  . mapToInt (  . GrowingTestColumn :  : getMaxSize )  . sum (  )  )     +     (  (  ( Integer . BYTES )     +     ( Byte . BYTES )  )     *    numColumns )  )  )  ;", "pageSource . close (  )  ;", "}    finally    {", "tempFile . delete (  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMaxReadBytes"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "FileFormatDataSourceStats   stats    =    new   FileFormatDataSourceStats (  )  ;", "Connector   pageSource    =    testPreparer . new ( stats )  ;", "assertEquals ( pageSource . getSystemMemoryUsage (  )  ,     0  )  ;", "long   memoryUsage    =     -  1  ;", "for    ( int   i    =     0  ;    i    <     2  0  ;    i +  +  )     {", "assertFalse ( pageSource . isFinished (  )  )  ;", "Page   page    =    pageSource . getNextPage (  )  ;", "assertNotNull ( page )  ;", "Block   block    =    page . getBlock (  1  )  ;", "if    ( memoryUsage    =  =     (  -  1  )  )     {", "Assertions . assertBetweenInclusive ( pageSource . getSystemMemoryUsage (  )  ,     1  8  0  0  0  0 L ,     1  8  9  9  9  9 L )  ;", "VarcharType . createUnboundedVarcharType (  )  . getSlice ( block ,     (  ( block . getPositionCount (  )  )     -     1  )  )  ;", "memoryUsage    =    pageSource . getSystemMemoryUsage (  )  ;", "Assertions . assertBetweenInclusive ( memoryUsage ,     4  6  0  0  0  0 L ,     4  6  9  9  9  9 L )  ;", "} else    {", "assertEquals ( pageSource . getSystemMemoryUsage (  )  ,    memoryUsage )  ;", "VarcharType . createUnboundedVarcharType (  )  . getSlice ( block ,     (  ( block . getPositionCount (  )  )     -     1  )  )  ;", "assertEquals ( pageSource . getSystemMemoryUsage (  )  ,    memoryUsage )  ;", "}", "}", "memoryUsage    =     -  1  ;", "for    ( int   i    =     2  0  ;    i    <     4  0  ;    i +  +  )     {", "assertFalse ( pageSource . isFinished (  )  )  ;", "Page   page    =    pageSource . getNextPage (  )  ;", "assertNotNull ( page )  ;", "Block   block    =    page . getBlock (  1  )  ;", "if    ( memoryUsage    =  =     (  -  1  )  )     {", "Assertions . assertBetweenInclusive ( pageSource . getSystemMemoryUsage (  )  ,     1  8  0  0  0  0 L ,     1  8  9  9  9  9 L )  ;", "VarcharType . createUnboundedVarcharType (  )  . getSlice ( block ,     (  ( block . getPositionCount (  )  )     -     1  )  )  ;", "memoryUsage    =    pageSource . getSystemMemoryUsage (  )  ;", "Assertions . assertBetweenInclusive ( memoryUsage ,     4  6  0  0  0  0 L ,     4  6  9  9  9  9 L )  ;", "} else    {", "assertEquals ( pageSource . getSystemMemoryUsage (  )  ,    memoryUsage )  ;", "VarcharType . createUnboundedVarcharType (  )  . getSlice ( block ,     (  ( block . getPositionCount (  )  )     -     1  )  )  ;", "assertEquals ( pageSource . getSystemMemoryUsage (  )  ,    memoryUsage )  ;", "}", "}", "memoryUsage    =     -  1  ;", "for    ( int   i    =     4  0  ;    i    <     5  0  ;    i +  +  )     {", "assertFalse ( pageSource . isFinished (  )  )  ;", "Page   page    =    pageSource . getNextPage (  )  ;", "assertNotNull ( page )  ;", "Block   block    =    page . getBlock (  1  )  ;", "if    ( memoryUsage    =  =     (  -  1  )  )     {", "Assertions . assertBetweenInclusive ( pageSource . getSystemMemoryUsage (  )  ,     9  0  0  0  0 L ,     9  9  9  9  9 L )  ;", "VarcharType . createUnboundedVarcharType (  )  . getSlice ( block ,     (  ( block . getPositionCount (  )  )     -     1  )  )  ;", "memoryUsage    =    pageSource . getSystemMemoryUsage (  )  ;", "Assertions . assertBetweenInclusive ( memoryUsage ,     3  6  0  0  0  0 L ,     3  6  9  9  9  9 L )  ;", "} else    {", "assertEquals ( pageSource . getSystemMemoryUsage (  )  ,    memoryUsage )  ;", "VarcharType . createUnboundedVarcharType (  )  . getSlice ( block ,     (  ( block . getPositionCount (  )  )     -     1  )  )  ;", "assertEquals ( pageSource . getSystemMemoryUsage (  )  ,    memoryUsage )  ;", "}", "}", "assertFalse ( pageSource . isFinished (  )  )  ;", "assertNull ( pageSource . getNextPage (  )  )  ;", "assertTrue ( pageSource . isFinished (  )  )  ;", "assertEquals ( pageSource . getSystemMemoryUsage (  )  ,     0  )  ;", "pageSource . close (  )  ;", "}", "METHOD_END"], "methodName": ["testPageSource"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "DriverContext   driverContext    =    testPreparer . newDriverContext (  )  ;", "Operator   operator    =    testPreparer . newScanFilterAndProjectOperator ( driverContext )  ;", "assertEquals ( driverContext . getSystemMemoryUsage (  )  ,     0  )  ;", "for    ( int   i    =     0  ;    i    <     5  0  ;    i +  +  )     {", "assertFalse ( operator . isFinished (  )  )  ;", "assertNotNull ( operator . getOutput (  )  )  ;", "Assertions . assertBetweenInclusive ( driverContext . getSystemMemoryUsage (  )  ,     9  0  0  0  0 L ,     4  9  9  9  9  9 L )  ;", "}", "assertNull ( operator . getOutput (  )  )  ;", "assertTrue ( operator . isFinished (  )  )  ;", "Assertions . assertBetweenInclusive ( driverContext . getSystemMemoryUsage (  )  ,     0 L ,     5  0  0 L )  ;", "}", "METHOD_END"], "methodName": ["testScanFilterAndProjectOperator"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "DriverContext   driverContext    =    testPreparer . newDriverContext (  )  ;", "Operator   operator    =    testPreparer . newTableScanOperator ( driverContext )  ;", "assertEquals ( driverContext . getSystemMemoryUsage (  )  ,     0  )  ;", "long   memoryUsage    =     -  1  ;", "for    ( int   i    =     0  ;    i    <     2  0  ;    i +  +  )     {", "assertFalse ( operator . isFinished (  )  )  ;", "Page   page    =    operator . getOutput (  )  ;", "assertNotNull ( page )  ;", "page . getBlock (  1  )  ;", "if    ( memoryUsage    =  =     (  -  1  )  )     {", "memoryUsage    =    driverContext . getSystemMemoryUsage (  )  ;", "Assertions . assertBetweenInclusive ( memoryUsage ,     4  6  0  0  0  0 L ,     4  6  9  9  9  9 L )  ;", "} else    {", "assertEquals ( driverContext . getSystemMemoryUsage (  )  ,    memoryUsage )  ;", "}", "}", "memoryUsage    =     -  1  ;", "for    ( int   i    =     2  0  ;    i    <     4  0  ;    i +  +  )     {", "assertFalse ( operator . isFinished (  )  )  ;", "Page   page    =    operator . getOutput (  )  ;", "assertNotNull ( page )  ;", "page . getBlock (  1  )  ;", "if    ( memoryUsage    =  =     (  -  1  )  )     {", "memoryUsage    =    driverContext . getSystemMemoryUsage (  )  ;", "Assertions . assertBetweenInclusive ( memoryUsage ,     4  6  0  0  0  0 L ,     4  6  9  9  9  9 L )  ;", "} else    {", "assertEquals ( driverContext . getSystemMemoryUsage (  )  ,    memoryUsage )  ;", "}", "}", "memoryUsage    =     -  1  ;", "for    ( int   i    =     4  0  ;    i    <     5  0  ;    i +  +  )     {", "assertFalse ( operator . isFinished (  )  )  ;", "Page   page    =    operator . getOutput (  )  ;", "assertNotNull ( page )  ;", "page . getBlock (  1  )  ;", "if    ( memoryUsage    =  =     (  -  1  )  )     {", "memoryUsage    =    driverContext . getSystemMemoryUsage (  )  ;", "Assertions . assertBetweenInclusive ( memoryUsage ,     3  6  0  0  0  0 L ,     3  6  9  9  9  9 L )  ;", "} else    {", "assertEquals ( driverContext . getSystemMemoryUsage (  )  ,    memoryUsage )  ;", "}", "}", "assertFalse ( operator . isFinished (  )  )  ;", "assertNull ( operator . getOutput (  )  )  ;", "assertTrue ( operator . isFinished (  )  )  ;", "assertEquals ( driverContext . getSystemMemoryUsage (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testTableScanOperator"], "fileName": "com.facebook.presto.hive.TestOrcPageSourceMemoryTracking"}, {"methodBody": ["METHOD_START", "{", "PartitionOfflineException   tableOfflineException    =    new   PartitionOfflineException ( tableName ,    partitionName ,    forPresto ,    offlineMessage )  ;", "assertEquals ( tableOfflineException . getMessage (  )  ,    expectedMessage )  ;", "}", "METHOD_END"], "methodName": ["assertMessage"], "fileName": "com.facebook.presto.hive.TestPartitionOfflineException"}, {"methodBody": ["METHOD_START", "{", "TestPartitionOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,     \" pk =  1  \"  ,    false ,     \"  \"  ,     \" Table    ' schema . table '    partition    ' pk =  1  '    is   offline \"  )  ;", "TestPartitionOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,     \" pk =  1  \"  ,    false ,    null ,     \" Table    ' schema . table '    partition    ' pk =  1  '    is   offline \"  )  ;", "TestPartitionOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,     \" pk =  1  \"  ,    true ,     \"  \"  ,     \" Table    ' schema . table '    partition    ' pk =  1  '    is   offline   for   Presto \"  )  ;", "TestPartitionOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,     \" pk =  1  \"  ,    true ,    null ,     \" Table    ' schema . table '    partition    ' pk =  1  '    is   offline   for   Presto \"  )  ;", "TestPartitionOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,     \" pk =  1  \"  ,    false ,     \" offline   reason \"  ,     \" Table    ' schema . table '    partition    ' pk =  1  '    is   offline :    offline   reason \"  )  ;", "TestPartitionOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,     \" pk =  1  \"  ,    true ,     \" offline   reason \"  ,     \" Table    ' schema . table '    partition    ' pk =  1  '    is   offline   for   Presto :    offline   reason \"  )  ;", "}", "METHOD_END"], "methodName": ["testMessage"], "fileName": "com.facebook.presto.hive.TestPartitionOfflineException"}, {"methodBody": ["METHOD_START", "{", "TableOfflineException   tableOfflineException    =    new   TableOfflineException ( tableName ,    forPresto ,    offlineMessage )  ;", "assertEquals ( tableOfflineException . getMessage (  )  ,    expectedMessage )  ;", "}", "METHOD_END"], "methodName": ["assertMessage"], "fileName": "com.facebook.presto.hive.TestTableOfflineException"}, {"methodBody": ["METHOD_START", "{", "TestTableOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,    false ,     \"  \"  ,     \" Table    ' schema . table '    is   offline \"  )  ;", "TestTableOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,    false ,    null ,     \" Table    ' schema . table '    is   offline \"  )  ;", "TestTableOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,    true ,     \"  \"  ,     \" Table    ' schema . table '    is   offline   for   Presto \"  )  ;", "TestTableOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,    true ,    null ,     \" Table    ' schema . table '    is   offline   for   Presto \"  )  ;", "TestTableOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,    false ,     \" offline   reason \"  ,     \" Table    ' schema . table '    is   offline :    offline   reason \"  )  ;", "TestTableOfflineException . assertMessage ( new   SchemaTableName (  \" schema \"  ,     \" table \"  )  ,    true ,     \" offline   reason \"  ,     \" Table    ' schema . table '    is   offline   for   Presto :    offline   reason \"  )  ;", "}", "METHOD_END"], "methodName": ["testMessage"], "fileName": "com.facebook.presto.hive.TestTableOfflineException"}, {"methodBody": ["METHOD_START", "{", "return   viewName ;", "}", "METHOD_END"], "methodName": ["getViewName"], "fileName": "com.facebook.presto.hive.ViewAlreadyExistsException"}, {"methodBody": ["METHOD_START", "{", "return   bytes ;", "}", "METHOD_END"], "methodName": ["getBytes"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   environment ;", "}", "METHOD_END"], "methodName": ["getEnvironment"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   host ;", "}", "METHOD_END"], "methodName": ["getHost"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   partitionName ;", "}", "METHOD_END"], "methodName": ["getPartitionName"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   path ;", "}", "METHOD_END"], "methodName": ["getPath"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   prestoVersion ;", "}", "METHOD_END"], "methodName": ["getPrestoVersion"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   principal ;", "}", "METHOD_END"], "methodName": ["getPrincipal"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   queryId ;", "}", "METHOD_END"], "methodName": ["getQueryId"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   rows ;", "}", "METHOD_END"], "methodName": ["getRows"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   schemaName ;", "}", "METHOD_END"], "methodName": ["getSchemaName"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   sessionProperties ;", "}", "METHOD_END"], "methodName": ["getSessionProperties"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   storageFormat ;", "}", "METHOD_END"], "methodName": ["getStorageFormat"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   timestamp ;", "}", "METHOD_END"], "methodName": ["getTimestamp"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "return   writerImplementation ;", "}", "METHOD_END"], "methodName": ["getWriterImplementation"], "fileName": "com.facebook.presto.hive.WriteCompletedEvent"}, {"methodBody": ["METHOD_START", "{", "KerberosAuthentication   kerberosAuthentication    =    new   KerberosAuthentication ( principal ,    keytabLocation )  ;", "KerberosHadoopAuthentication   kerberosHadoopAuthentication    =    new   KerberosHadoopAuthentication ( kerberosAuthentication )  ;", "return   new   CachingKerberosHadoopAuthentication ( kerberosHadoopAuthentication )  ;", "}", "METHOD_END"], "methodName": ["createCachingKerberosHadoopAuthentication"], "fileName": "com.facebook.presto.hive.authentication.AuthenticationModules"}, {"methodBody": ["METHOD_START", "{", "return   new   Module (  )     {", "@ Override", "public   void   configure ( Binder   binder )     {", "binder . bind ( HdfsAuthentication . class )  . to ( DirectHdfsAuthentication . class )  . in ( SINGLETON )  ;", "configBinder ( binder )  . bindConfig ( HdfsKerberosConfig . class )  ;", "}", "@ Inject", "@ Provides", "@ Singleton", "@ ForHdfs", "HadoopAuthentication   createHadoopAuthentication ( HdfsKerberosConfig   config )     {", "String   principal    =    config . getHdfsPrestoPrincipal (  )  ;", "String   keytabLocation    =    config . getHdfsPrestoKeytab (  )  ;", "return    . createCachingKerberosHadoopAuthentication ( principal ,    keytabLocation )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["kerberosHdfsAuthenticationModule"], "fileName": "com.facebook.presto.hive.authentication.AuthenticationModules"}, {"methodBody": ["METHOD_START", "{", "return   new   Module (  )     {", "@ Override", "public   void   configure ( Binder   binder )     {", "binder . bind ( HiveMetastoreAuthentication . class )  . to ( KerberosHiveMetastoreAuthentication . class )  . in ( SINGLETON )  ;", "configBinder ( binder )  . bindConfig ( MetastoreKerberosConfig . class )  ;", "}", "@ Provides", "@ Singleton", "@ ForHiveMetastore", "HadoopAuthentication   createHadoopAuthentication ( MetastoreKerberosConfig   config )     {", "String   principal    =    config . getHiveMetastoreClientPrincipal (  )  ;", "String   keytabLocation    =    config . getHiveMetastoreClientKeytab (  )  ;", "return    . createCachingKerberosHadoopAuthentication ( principal ,    keytabLocation )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["kerberosHiveMetastoreAuthenticationModule"], "fileName": "com.facebook.presto.hive.authentication.AuthenticationModules"}, {"methodBody": ["METHOD_START", "{", "return   new   Module (  )     {", "@ Override", "public   void   configure ( Binder   binder )     {", "binder . bind ( HdfsAuthentication . class )  . to ( ImpersonatingHdfsAuthentication . class )  . in ( SINGLETON )  ;", "configBinder ( binder )  . bindConfig ( HdfsKerberosConfig . class )  ;", "}", "@ Inject", "@ Provides", "@ Singleton", "@ ForHdfs", "HadoopAuthentication   createHadoopAuthentication ( HdfsKerberosConfig   config )     {", "String   principal    =    config . getHdfsPrestoPrincipal (  )  ;", "String   keytabLocation    =    config . getHdfsPrestoKeytab (  )  ;", "return    . createCachingKerberosHadoopAuthentication ( principal ,    keytabLocation )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["kerberosImpersonatingHdfsAuthenticationModule"], "fileName": "com.facebook.presto.hive.authentication.AuthenticationModules"}, {"methodBody": ["METHOD_START", "{", "return    (    binder )     -  >    binder . bind (  . class )  . to (  . class )  . in ( SINGLETON )  ;", "}", "METHOD_END"], "methodName": ["noHdfsAuthenticationModule"], "fileName": "com.facebook.presto.hive.authentication.AuthenticationModules"}, {"methodBody": ["METHOD_START", "{", "return    (    binder )     -  >    binder . bind (  . class )  . to (  . class )  . in ( SINGLETON )  ;", "}", "METHOD_END"], "methodName": ["noHiveMetastoreAuthenticationModule"], "fileName": "com.facebook.presto.hive.authentication.AuthenticationModules"}, {"methodBody": ["METHOD_START", "{", "return    (    binder )     -  >     {", "binder . bind ( Key . get (  . class ,     . class )  )  . to (  . class )  ;", "binder . bind (  . class )  . to (  . class )  . in ( SINGLETON )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["simpleImpersonatingHdfsAuthenticationModule"], "fileName": "com.facebook.presto.hive.authentication.AuthenticationModules"}, {"methodBody": ["METHOD_START", "{", "Subject   subject    =    getSubject ( userGroupInformation )  ;", "checkArgument (  ( subject    !  =    null )  ,     \" subject   must   be   present   in   kerberos   based   UGI \"  )  ;", "Ticket   tgtTicket    =    TicketUtils . getTicketGrantingTicket ( subject )  ;", "return   TicketUtils . getRefreshTime ( tgtTicket )  ;", "}", "METHOD_END"], "methodName": ["calculateNextRefreshTime"], "fileName": "com.facebook.presto.hive.authentication.CachingKerberosHadoopAuthentication"}, {"methodBody": ["METHOD_START", "{", "return    (  ( nextRefreshTime )     <     ( System . currentTimeMillis (  )  )  )     |  |     (  ( userGroupInformation )     =  =    null )  ;", "}", "METHOD_END"], "methodName": ["refreshIsNeeded"], "fileName": "com.facebook.presto.hive.authentication.CachingKerberosHadoopAuthentication"}, {"methodBody": ["METHOD_START", "{", "userGroupInformation    =    delegate . getUserGroupInformation (  )  ;", "nextRefreshTime    =    calculateNextRefreshTime ( userGroupInformation )  ;", "}", "METHOD_END"], "methodName": ["refreshUgi"], "fileName": "com.facebook.presto.hive.authentication.CachingKerberosHadoopAuthentication"}, {"methodBody": ["METHOD_START", "{", "doAs ( user ,     (  )     -  >     {", "acrun (  )  ;", "return   null ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["doAs"], "fileName": "com.facebook.presto.hive.authentication.HdfsAuthentication"}, {"methodBody": ["METHOD_START", "{", "return   hdfsPrestoKeytab ;", "}", "METHOD_END"], "methodName": ["getHdfsPrestoKeytab"], "fileName": "com.facebook.presto.hive.authentication.HdfsKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "return   hdfsPrestoPrincipal ;", "}", "METHOD_END"], "methodName": ["getHdfsPrestoPrincipal"], "fileName": "com.facebook.presto.hive.authentication.HdfsKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "this . hdfsPrestoKeytab    =    hdfsPrestoKeytab ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHdfsPrestoKeytab"], "fileName": "com.facebook.presto.hive.authentication.HdfsKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "this . hdfsPrestoPrincipal    =    hdfsPrestoPrincipal ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHdfsPrestoPrincipal"], "fileName": "com.facebook.presto.hive.authentication.HdfsKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "install ( installModuleIf ( HiveClientConfig . class ,    predicate ,    module )  )  ;", "}", "METHOD_END"], "methodName": ["bindAuthenticationModule"], "fileName": "com.facebook.presto.hive.authentication.HiveAuthenticationModule"}, {"methodBody": ["METHOD_START", "{", "return    ( config . getHdfsAuthenticationType (  )  )     =  =     ( HiveClientConfig . HdfsAuthenticationType . KERBEROS )  ;", "}", "METHOD_END"], "methodName": ["kerberosHdfsAuth"], "fileName": "com.facebook.presto.hive.authentication.HiveAuthenticationModule"}, {"methodBody": ["METHOD_START", "{", "return    ( config . getHdfsAuthenticationType (  )  )     =  =     ( HiveClientConfig . HdfsAuthenticationType . NONE )  ;", "}", "METHOD_END"], "methodName": ["noHdfsAuth"], "fileName": "com.facebook.presto.hive.authentication.HiveAuthenticationModule"}, {"methodBody": ["METHOD_START", "{", "return   UserGroupInformation . createProxyUser ( user ,    hadoopAuthentication . getUserGroupInformation (  )  )  ;", "}", "METHOD_END"], "methodName": ["createProxyUser"], "fileName": "com.facebook.presto.hive.authentication.ImpersonatingHdfsAuthentication"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    options    =    ImmutableMap .  < String ,    String > builder (  )  . put (  \" useKeyTab \"  ,     \" true \"  )  . put (  \" storeKey \"  ,     \" true \"  )  . put (  \" doNotPrompt \"  ,     \" true \"  )  . put (  \" isInitiator \"  ,     \" true \"  )  . put (  \" principal \"  ,    principal )  . put (  \" keyTab \"  ,    keytabLocation )  . build (  )  ;", "return   new   Configuration (  )     {", "@ Override", "public   AppConfigurationEntry [  ]    getAppConfigurationEntry ( String   name )     {", "return   new   AppConfigurationEntry [  ]  {    new   AppConfigurationEntry (  . KERBEROS _ LOGIN _ MODULE ,    AppConfigurationEntry . LoginModuleControlFlag . REQUIRED ,    options )     }  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["createConfiguration"], "fileName": "com.facebook.presto.hive.authentication.KerberosAuthentication"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   new   Principal ( getServerPrincipal ( principal ,    InetAddress . getLocalHost (  )  . getCanonicalHostName (  )  )  )  ;", "}    catch    ( IOException   e )     {", "throw   new   UncheckedIOException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["createKerberosPrincipal"], "fileName": "com.facebook.presto.hive.authentication.KerberosAuthentication"}, {"methodBody": ["METHOD_START", "{", "Subject   subject    =    new   Subject ( false ,    ImmutableSet . of ( principal )  ,    Collections . emptySet (  )  ,    Collections . emptySet (  )  )  ;", "try    {", "LoginContext   loginContext    =    new   LoginContext (  \"  \"  ,    subject ,    null ,    configur )  ;", "loginContext . login (  )  ;", "return   loginContext . getSubject (  )  ;", "}    catch    ( LoginException   e )     {", "throw   Throwables . propagate ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["getSubject"], "fileName": "com.facebook.presto.hive.authentication.KerberosAuthentication"}, {"methodBody": ["METHOD_START", "{", "long   start    =    ticket . getStartTime (  )  . getTime (  )  ;", "long   end    =    ticket . getEndTime (  )  . getTime (  )  ;", "return   start    +     (  ( long )     (  ( end    -    start )     *     (  . TICKET _ RENEW _ WINDOW )  )  )  ;", "}", "METHOD_END"], "methodName": ["getRefreshTime"], "fileName": "com.facebook.presto.hive.authentication.KerberosTicketUtils"}, {"methodBody": ["METHOD_START", "{", "Set < KerberosTicket >    tickets    =    subject . getPrivateCredentials ( KerberosTicket . class )  ;", "for    ( KerberosTicket   ticket    :    tickets )     {", "if    (  . isOriginalTicketGrantingTicket ( ticket )  )     {", "return   ticket ;", "}", "}", "throw   new   IllegalArgumentException (  (  \" kerberos   ticket   not   found   in    \"     +    subject )  )  ;", "}", "METHOD_END"], "methodName": ["getTicketGrantingTicket"], "fileName": "com.facebook.presto.hive.authentication.KerberosTicketUtils"}, {"methodBody": ["METHOD_START", "{", "return   KerberosTicketUtils . isTicketGrantingServerPrincipal ( ticket . getServer (  )  )  ;", "}", "METHOD_END"], "methodName": ["isOriginalTicketGrantingTicket"], "fileName": "com.facebook.presto.hive.authentication.KerberosTicketUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( principal    =  =    null )     {", "return   false ;", "}", "if    ( principal . getName (  )  . equals (  (  (  (  \" krbtgt /  \"     +     ( principal . getRealm (  )  )  )     +     \"  @  \"  )     +     ( principal . getRealm (  )  )  )  )  )     {", "return   true ;", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isTicketGrantingServerPrincipal"], "fileName": "com.facebook.presto.hive.authentication.KerberosTicketUtils"}, {"methodBody": ["METHOD_START", "{", "return   hiveMetastoreClientKeytab ;", "}", "METHOD_END"], "methodName": ["getHiveMetastoreClientKeytab"], "fileName": "com.facebook.presto.hive.authentication.MetastoreKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "return   hiveMetastoreClientPrincipal ;", "}", "METHOD_END"], "methodName": ["getHiveMetastoreClientPrincipal"], "fileName": "com.facebook.presto.hive.authentication.MetastoreKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "return   hiveMetastoreServicePrincipal ;", "}", "METHOD_END"], "methodName": ["getHiveMetastoreServicePrincipal"], "fileName": "com.facebook.presto.hive.authentication.MetastoreKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "this . hiveMetastoreClientKeytab    =    hiveMetastoreClientKeytab ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHiveMetastoreClientKeytab"], "fileName": "com.facebook.presto.hive.authentication.MetastoreKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "this . hiveMetastoreClientPrincipal    =    hiveMetastoreClientPrincipal ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHiveMetastoreClientPrincipal"], "fileName": "com.facebook.presto.hive.authentication.MetastoreKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "this . hiveMetastoreServicePrincipal    =    hiveMetastoreServicePrincipal ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setHiveMetastoreServicePrincipal"], "fileName": "com.facebook.presto.hive.authentication.MetastoreKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . hdfs . presto . principal \"  ,     \" presto @ EXAMPLE . COM \"  )  . put (  \" hive . hdfs . presto . keytab \"  ,     \"  / tmp / presto . keytab \"  )  . build (  )  ;", "expected    =    new    (  )  . setHdfsPrestoPrincipal (  \" presto @ EXAMPLE . COM \"  )  . setHdfsPrestoKeytab (  \"  / tmp / presto . keytab \"  )  ;", "ConfigAssertions . assertFullMapping ( properties ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMappings"], "fileName": "com.facebook.presto.hive.authentication.TestHdfsKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . metastore . service . principal \"  ,     \" hive /  _ HOST @ EXAMPLE . COM \"  )  . put (  \" hive . metastore . client . principal \"  ,     \" metastore @ EXAMPLE . COM \"  )  . put (  \" hive . metastore . client . keytab \"  ,     \"  / tmp / metastore . keytab \"  )  . build (  )  ;", "expected    =    new    (  )  . setHiveMetastoreServicePrincipal (  \" hive /  _ HOST @ EXAMPLE . COM \"  )  . setHiveMetastoreClientPrincipal (  \" metastore @ EXAMPLE . COM \"  )  . setHiveMetastoreClientKeytab (  \"  / tmp / metastore . keytab \"  )  ;", "ConfigAssertions . assertFullMapping ( properties ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMappings"], "fileName": "com.facebook.presto.hive.authentication.TestMetastoreKerberosConfig"}, {"methodBody": ["METHOD_START", "{", "return   userGroupInformation . doAs (  (  ( PrivilegedAction < UserGroupInformationUtils . ResultOrException < R ,    E >  >  )     (  (  )     -  >     {", "try    {", "return   new   UserGroupInformationUtils . ResultOrException <  >  ( action . run (  )  ,    null )  ;", "}    catch    ( Throwable   e )     {", "return   new   UserGroupInformationUtils . ResultOrException <  >  ( null ,    e )  ;", "}", "}  )  )  )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["executeActionInDoAs"], "fileName": "com.facebook.presto.hive.authentication.UserGroupInformationUtils"}, {"methodBody": ["METHOD_START", "{", "List < HiveColumnHandle >    columnHandles    =    new   ArrayList <  >  ( columnNames . size (  )  )  ;", "TypeTranslator   typeTranslator    =    new   HiveTypeTranslator (  )  ;", "for    ( int   i    =     0  ;    i    <     ( columnNames . size (  )  )  ;    i +  +  )     {", "String   columnName    =    columnNames . get ( i )  ;", "Type   columnType    =    columnTypes . get ( i )  ;", "columnHandles . add ( new   HiveColumnHandle ( columnName ,    HiveType . toHiveType ( typeTranslator ,    columnType )  ,    columnType . getTypeSignature (  )  ,    i ,    HiveColumnHandle . ColumnType . REGULAR ,    Optional . empty (  )  )  )  ;", "}", "return   pageSourceFactory . createPageSource (  . conf ,    session ,    new   Path ( targetFile . getAbsolutePath (  )  )  ,     0  ,    targetFile . length (  )  ,    targetFile . length (  )  ,     . createSchema ( format ,    columnNames ,    columnTypes )  ,    columnHandles ,    TupleDomain . all (  )  ,    DateTimeZone . forID ( session . getTimeZoneKey (  )  . getId (  )  )  )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["createPageSource"], "fileName": "com.facebook.presto.hive.benchmark.FileFormat"}, {"methodBody": ["METHOD_START", "{", "List < HiveColumnHandle >    columnHandles    =    new   ArrayList <  >  ( columnNames . size (  )  )  ;", "TypeTranslator   typeTranslator    =    new   HiveTypeTranslator (  )  ;", "for    ( int   i    =     0  ;    i    <     ( columnNames . size (  )  )  ;    i +  +  )     {", "String   columnName    =    columnNames . get ( i )  ;", "Type   columnType    =    columnTypes . get ( i )  ;", "columnHandles . add ( new   HiveColumnHandle ( columnName ,    HiveType . toHiveType ( typeTranslator ,    columnType )  ,    columnType . getTypeSignature (  )  ,    i ,    HiveColumnHandle . ColumnType . REGULAR ,    Optional . empty (  )  )  )  ;", "}", "RecordCursor   recordCursor    =    cursorProvider . createRecordCursor ( FileFormat . conf ,    session ,    new   Path ( targetFile . getAbsolutePath (  )  )  ,     0  ,    targetFile . length (  )  ,    targetFile . length (  )  ,    FileFormat . createSchema ( format ,    columnNames ,    columnTypes )  ,    columnHandles ,    TupleDomain . all (  )  ,    DateTimeZone . forID ( session . getTimeZoneKey (  )  . getId (  )  )  ,    HiveTestUtils . TYPE _ MANAGER )  . get (  )  ;", "return   new   spi . RecordPageSource ( columnTypes ,    recordCursor )  ;", "}", "METHOD_END"], "methodName": ["createPageSource"], "fileName": "com.facebook.presto.hive.benchmark.FileFormat"}, {"methodBody": ["METHOD_START", "{", "return   true ;", "}", "METHOD_END"], "methodName": ["supports"], "fileName": "com.facebook.presto.hive.benchmark.FileFormat"}, {"methodBody": ["METHOD_START", "{", "return   true ;", "}", "METHOD_END"], "methodName": ["supportsDate"], "fileName": "com.facebook.presto.hive.benchmark.FileFormat"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   s . createTempDirectory ( prefix )  . to (  )  ;", "}    catch    ( IOException   e )     {", "throw   new   UncheckedIOException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["createTempDir"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "return   HiveFileFormatBenchmark . createTpchDataSet ( format ,    tpchTable ,    ImmutableList . copyOf ( columns )  )  ;", "}", "METHOD_END"], "methodName": ["createTpchDataSet"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "switch    ( input . getType (  )  . getBase (  )  )     {", "case   IDENTIFIER    :", "return   spi . type . BigintType . BIGINT ;", "case   spi . type . IntegerType . INTEGER    :", "return   spi . type . IntegerType . INTEGER ;", "case   spi . type . DateType . DATE    :", "return   spi . type . DateType . DATE ;", "case   spi . type . DoubleType . DOUBLE    :", "return   spi . type . DoubleType . DOUBLE ;", "case   VARCHAR    :", "return   VarcharType . createUnboundedVarcharType (  )  ;", "}", "throw   new   IllegalArgumentException (  (  \" Unsupported   type    \"     +     ( input . getType (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getColumnType"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "Options   opt    =    new   OptionsBuilder (  )  . include (  (  (  \"  .  *  \\  \\  .  \"     +     ( HiveFileFormatBenchmark . class . getSimpleName (  )  )  )     +     \"  .  *  \"  )  )  . jvmArgsAppend (  \"  - Xmx 4 g \"  ,     \"  - Xms 4 g \"  ,     \"  - XX :  + UseG 1 GC \"  )  . build (  )  ;", "Collection < RunResult >    results    =    new   Runner ( opt )  . run (  )  ;", "for    ( RunResult   result    :    results )     {", "Statistics   inputSizeStats    =    result . getSecondaryResults (  )  . get (  \" inputSize \"  )  . getStatistics (  )  ;", "Statistics   outputSizeStats    =    result . getSecondaryResults (  )  . get (  \" outputSize \"  )  . getStatistics (  )  ;", "double   compressionRatio    =     (  1  .  0     *     ( inputSizeStats . getSum (  )  )  )     /     ( outputSizeStats . getSum (  )  )  ;", "String   compression    =    result . getParams (  )  . getParam (  \" compression \"  )  ;", "String   fileFormat    =    result . getParams (  )  . getParam (  \" fileFormat \"  )  ;", "String   dataSet    =    result . getParams (  )  . getParam (  \" dataSet \"  )  ;", "System . out . printf (  \"        %  -  1  0 s       %  -  3  0 s       %  -  1  0 s       %  -  2  5 s       %  2  .  2 f       %  1  0 s    \\ u 0  0 b 1     %  1  1 s    (  %  5  .  2 f %  %  )     ( N    =     % d ,     \\ u 0  3 b 1     =     9  9  .  9  %  %  )  \\ n \"  ,    result . getPrimaryResult (  )  . getLabel (  )  ,    dataSet ,    compression ,    fileFormat ,    compressionRatio ,    HiveFileFormatBenchmark . toHumanReadableSpeed (  (  ( long )     ( inputSizeStats . getMean (  )  )  )  )  ,    HiveFileFormatBenchmark . toHumanReadableSpeed (  (  ( long )     ( inputSizeStats . getMeanErrorAt (  0  .  9  9  9  )  )  )  )  ,     (  (  ( inputSizeStats . getMeanErrorAt (  0  .  9  9  9  )  )     *     1  0  0  )     /     ( inputSizeStats . getMean (  )  )  )  ,    inputSizeStats . getN (  )  )  ;", "}", "System . out . println (  )  ;", "}", "METHOD_END"], "methodName": ["main"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "return   min    +     ( random . nextInt (  ( max    -    min )  )  )  ;", "}", "METHOD_END"], "methodName": ["nextRandomBetween"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( fileFormat . supports ( data )  )  )     {", "throw   new   RuntimeException (  (  (  ( fileFormat )     +     \"    does   not   support   data   set    \"  )     +     ( dataSet )  )  )  ;", "}", "List < Page >    pages    =    new   ArrayList <  >  (  1  0  0  )  ;", "try    ( ConnectorPageSource   pageSource    =    fileFormat . createFileFormatReader (  . SESSION ,     . HDFS _ ENVIRONMENT ,    dataFile ,    data . getColumnNames (  )  ,    data . getColumnTypes (  )  )  )     {", "while    (  !  ( pageSource . isFinished (  )  )  )     {", "Page   page    =    pageSource . getNextPage (  )  ;", "if    ( page    !  =    null )     {", "page . assureLoaded (  )  ;", "pages . add ( page )  ;", "}", "}", "}", "counter . inputSize    +  =    data . getSize (  )  ;", "counter . outputSize    +  =    dataFile . length (  )  ;", "return   pages ;", "}", "METHOD_END"], "methodName": ["read"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "data    =    dataSet . createTestData ( fileFormat )  ;", "targetDir . mkdirs (  )  ;", "dataFile    =    new   File ( targetDir ,    UUID . randomUUID (  )  . toString (  )  )  ;", "writeData ( dataFile )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "deleteRecursively ( targetDir . toPath (  )  ,    ALLOW _ INSECURE )  ;", "}", "METHOD_END"], "methodName": ["tearDown"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "String   humanReadableSpeed ;", "if    ( bytesPerSecond    <     (  1  0  2  4     *     1  0 L )  )     {", "humanReadableSpeed    =    String . f (  \"  % dB / s \"  ,    bytesPerSecond )  ;", "} else", "if    ( bytesPerSecond    <     (  (  1  0  2  4     *     1  0  2  4  )     *     1  0 L )  )     {", "humanReadableSpeed    =    String . f (  \"  %  .  1 fkB / s \"  ,     ( bytesPerSecond    /     1  0  2  4  .  0 F )  )  ;", "} else", "if    ( bytesPerSecond    <     (  (  (  1  0  2  4     *     1  0  2  4  )     *     1  0  2  4  )     *     1  0 L )  )     {", "humanReadableSpeed    =    String . f (  \"  %  .  1 fMB / s \"  ,     ( bytesPerSecond    /     (  1  0  2  4  .  0 F    *     1  0  2  4  .  0 F )  )  )  ;", "} else    {", "humanReadableSpeed    =    String . f (  \"  %  .  1 fGB / s \"  ,     ( bytesPerSecond    /     (  (  1  0  2  4  .  0 F    *     1  0  2  4  .  0 F )     *     1  0  2  4  .  0 F )  )  )  ;", "}", "return   humanReadableSpeed ;", "}", "METHOD_END"], "methodName": ["toHumanReadableSpeed"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "File   targetFile    =    new   File ( targetDir ,    UUID . randomUUID (  )  . toString (  )  )  ;", "writeData ( targetFile )  ;", "counter . inputSize    +  =    data . getSize (  )  ;", "counter . outputSize    +  =    targetFile . length (  )  ;", "return   targetFile ;", "}", "METHOD_END"], "methodName": ["write"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "List < Page >    inputPages    =    data . getPages (  )  ;", "try    ( FormatWriter   formatWriter    =    fileFormat . createFileFormatWriter (  . SESSION ,    targetFile ,    data . getColumnNames (  )  ,    data . getColumnTypes (  )  ,    compression )  )     {", "for    ( Page   page    :    inputPages )     {", "formatWriter . writePage ( page )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["writeData"], "fileName": "com.facebook.presto.hive.benchmark.HiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "HiveFileFormatBenchmark   benchmark    =    new   HiveFileFormatBenchmark ( dataSet ,    codec ,    format )  ;", "try    {", "benchmark . setup (  )  ;", "benchmark . read ( new   HiveFileFormatBenchmark . CompressionCounter (  )  )  ;", "benchmark . write ( new   HiveFileFormatBenchmark . CompressionCounter (  )  )  ;", "}    catch    ( Exception   e )     {", "throw   new   RuntimeException (  (  (  (  (  (  \" Failed    \"     +    dataSet )     +     \"     \"  )     +    codec )     +     \"     \"  )     +    format )  ,    e )  ;", "}    finally    {", "benchmark . tearDown (  )  ;", "}", "}", "METHOD_END"], "methodName": ["executeBenchmark"], "fileName": "com.facebook.presto.hive.benchmark.TestHiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveCompressionCodec   codec    :    HiveCompressionCodec . values (  )  )     {", ". executeBenchmark ( HiveFileFormatBenchmark . DataSet . LINEITEM ,    codec ,    FileFormat . PRESTO _ RCBINARY )  ;", "}", "}", "METHOD_END"], "methodName": ["testAllCompression"], "fileName": "com.facebook.presto.hive.benchmark.TestHiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "for    ( HiveFileFormatBenchmark . DataSet   dataSet    :    HiveFileFormatBenchmark . DataSet . values (  )  )     {", ". executeBenchmark ( dataSet ,    HiveCompressionCodec . SNAPPY ,    FileFormat . PRESTO _ RCBINARY )  ;", "}", "}", "METHOD_END"], "methodName": ["testAllDataSets"], "fileName": "com.facebook.presto.hive.benchmark.TestHiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "TestHiveFileFormatBenchmark . executeBenchmark ( HiveFileFormatBenchmark . DataSet . LINEITEM ,    HiveCompressionCodec . SNAPPY ,    FileFormat . PRESTO _ RCBINARY )  ;", "TestHiveFileFormatBenchmark . executeBenchmark ( HiveFileFormatBenchmark . DataSet . LINEITEM ,    HiveCompressionCodec . SNAPPY ,    FileFormat . PRESTO _ ORC )  ;", "TestHiveFileFormatBenchmark . executeBenchmark ( HiveFileFormatBenchmark . DataSet . LINEITEM ,    HiveCompressionCodec . SNAPPY ,    FileFormat . HIVE _ RCBINARY )  ;", "TestHiveFileFormatBenchmark . executeBenchmark ( HiveFileFormatBenchmark . DataSet . MAP _ VARCHAR _ DOUBLE ,    HiveCompressionCodec . SNAPPY ,    FileFormat . PRESTO _ RCBINARY )  ;", "TestHiveFileFormatBenchmark . executeBenchmark ( HiveFileFormatBenchmark . DataSet . MAP _ VARCHAR _ DOUBLE ,    HiveCompressionCodec . SNAPPY ,    FileFormat . PRESTO _ ORC )  ;", "TestHiveFileFormatBenchmark . executeBenchmark ( HiveFileFormatBenchmark . DataSet . MAP _ VARCHAR _ DOUBLE ,    HiveCompressionCodec . SNAPPY ,    FileFormat . HIVE _ RCBINARY )  ;", "TestHiveFileFormatBenchmark . executeBenchmark ( HiveFileFormatBenchmark . DataSet . LARGE _ MAP _ VARCHAR _ DOUBLE ,    HiveCompressionCodec . SNAPPY ,    FileFormat . PRESTO _ RCBINARY )  ;", "TestHiveFileFormatBenchmark . executeBenchmark ( HiveFileFormatBenchmark . DataSet . LARGE _ MAP _ VARCHAR _ DOUBLE ,    HiveCompressionCodec . SNAPPY ,    FileFormat . PRESTO _ ORC )  ;", "TestHiveFileFormatBenchmark . executeBenchmark ( HiveFileFormatBenchmark . DataSet . LARGE _ MAP _ VARCHAR _ DOUBLE ,    HiveCompressionCodec . SNAPPY ,    FileFormat . HIVE _ RCBINARY )  ;", "}", "METHOD_END"], "methodName": ["testSomeFormats"], "fileName": "com.facebook.presto.hive.benchmark.TestHiveFileFormatBenchmark"}, {"methodBody": ["METHOD_START", "{", "databaseNamesCache . invalidateAll (  )  ;", "tableNamesCache . invalidateAll (  )  ;", "viewNamesCache . invalidateAll (  )  ;", "partitionNamesCache . invalidateAll (  )  ;", "databaseCache . invalidateAll (  )  ;", "tableCache . invalidateAll (  )  ;", "partitionCache . invalidateAll (  )  ;", "partitionFilterCache . invalidateAll (  )  ;", "userTablePrivileges . invalidateAll (  )  ;", "}", "METHOD_END"], "methodName": ["flushCache"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   ce . get ( key )  ;", "}    catch    ( ExecutionException    |    UncheckedExecutionException    |    ExecutionError   e )     {", "throw   Throwables . propagate ( e . getCause (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["get"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   ce . getAll ( keys )  ;", "}    catch    ( ExecutionException    |    UncheckedExecutionException    |    ExecutionError   e )     {", "throw   Throwables . propagate ( e . getCause (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getAll"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "databaseCache . invalidate ( databaseName )  ;", "databaseNamesCache . invalidateAll (  )  ;", "}", "METHOD_END"], "methodName": ["invalidateDatabase"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "CachingHiveMetastore . HiveTableName   hiveTableName    =    CachingHiveMetastore . HiveTableName . table ( databaseName ,    tableName )  ;", "partitionNamesCache . invalidate ( hiveTableName )  ;", "partitionCache . asMap (  )  . keySet (  )  . stream (  )  . filter (  (    partitionName )     -  >    partitionName . getHiveTableName (  )  . equals ( hiveTableName )  )  . forEach ( partitionCache :  : invalidate )  ;", "partitionFilterCache . asMap (  )  . keySet (  )  . stream (  )  . filter (  (    partitionFilter )     -  >    partitionFilter . getHiveTableName (  )  . equals ( hiveTableName )  )  . forEach ( partitionFilterCache :  : invalidate )  ;", "}", "METHOD_END"], "methodName": ["invalidatePartitionCache"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "tableCache . invalidate ( new   CachingHiveMetastore . HiveTableName ( databaseName ,    tableName )  )  ;", "tableNamesCache . invalidate ( databaseName )  ;", "viewNamesCache . invalidate ( databaseName )  ;", "userTablePrivileges . asMap (  )  . keySet (  )  . stream (  )  . filter (  (    userTableKey )     -  >    userTableKey . matches ( databaseName ,    tableName )  )  . forEach ( userTablePrivileges :  : invalidate )  ;", "invalidatePartitionCache ( databaseName ,    tableName )  ;", "}", "METHOD_END"], "methodName": ["invalidateTable"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getAllDatabases (  )  ;", "}", "METHOD_END"], "methodName": ["loadAllDatabases"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getAllTables ( databaseName )  ;", "}", "METHOD_END"], "methodName": ["loadAllTables"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getAllViews ( databaseName )  ;", "}", "METHOD_END"], "methodName": ["loadAllViews"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( Iterables . isEmpty ( keys )  )     {", "return   ImmutableMap . of (  )  ;", "}", ". HiveTableName   hiveTableName    =    stream ( keys )  . findFirst (  )  . get (  )  . getHiveTableName (  )  ;", "checkArgument ( stream ( keys )  . allMatch (  (    key )     -  >    key . getHiveTableName (  )  . equals ( hiveTableName )  )  ,     \" all   keys   must   relate   to   same   hive   table \"  )  ;", "Set < String >    columnNames    =    stream ( keys )  . map (  . TableColumnStatisticsCacheKey :  : getColumnName )  . collect ( Collectors . toSet (  )  )  ;", "Optional < Map < String ,    HiveColumnStatistics >  >    columnStatistics    =    delegate . getTableColumnStatistics ( hiveTableName . getDatabaseName (  )  ,    hiveTableName . getTableName (  )  ,    columnNames )  ;", "Builder <  . TableColumnStatisticsCacheKey ,    Optional < HiveColumnStatistics >  >    resultMap    =    ImmutableMap . builder (  )  ;", "for    (  . TableColumnStatisticsCacheKey   key    :    keys )     {", "if    (  (  !  ( columnStatistics . isPresent (  )  )  )     |  |     (  !  ( columnStatistics . get (  )  . containsKey ( key . getColumnName (  )  )  )  )  )     {", "resultMap . put ( key ,    Optional . empty (  )  )  ;", "} else    {", "resultMap . put ( key ,    Optional . of ( columnStatistics . get (  )  . get ( key . getColumnName (  )  )  )  )  ;", "}", "}", "return   resultMap . build (  )  ;", "}", "METHOD_END"], "methodName": ["loadColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getDatabase ( databaseName )  ;", "}", "METHOD_END"], "methodName": ["loadDatabase"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getPartition ( partitionName . getHiveTableName (  )  . getDatabaseName (  )  ,    partitionName . getHiveTableName (  )  . getTableName (  )  ,    partitionName . getPartitionValues (  )  )  ;", "}", "METHOD_END"], "methodName": ["loadPartitionByName"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( Iterables . isEmpty ( keys )  )     {", "return   ImmutableMap . of (  )  ;", "}", ". PartitionColumnStatisticsCacheKey   firstKey    =    Iterables . getFirst ( keys ,    null )  ;", ". HiveTableName   hiveTableName    =    firstKey . getHivePartitionName (  )  . getHiveTableName (  )  ;", "checkArgument ( stream ( keys )  . allMatch (  (    key )     -  >    key . getHivePartitionName (  )  . getHiveTableName (  )  . equals ( hiveTableName )  )  ,     \" all   keys   must   relate   to   same   hive   table \"  )  ;", "Set < String >    partitionNames    =    stream ( keys )  . map (  (    key )     -  >    key . getHivePartitionName (  )  . getPartitionName (  )  )  . collect ( Collectors . toSet (  )  )  ;", "Set < String >    columnNames    =    stream ( keys )  . map (  . PartitionColumnStatisticsCacheKey :  : getColumnName )  . collect ( Collectors . toSet (  )  )  ;", "Optional < Map < String ,    Map < String ,    HiveColumnStatistics >  >  >    columnStatistics    =    delegate . getPartitionColumnStatistics ( hiveTableName . getDatabaseName (  )  ,    hiveTableName . getTableName (  )  ,    partitionNames ,    columnNames )  ;", "Builder <  . PartitionColumnStatisticsCacheKey ,    Optional < HiveColumnStatistics >  >    resultMap    =    ImmutableMap . builder (  )  ;", "for    (  . PartitionColumnStatisticsCacheKey   key    :    keys )     {", "if    (  (  ( columnStatistics . isPresent (  )  )     &  &     ( columnStatistics . get (  )  . containsKey ( key . getHivePartitionName (  )  . getPartitionName (  )  )  )  )     &  &     ( columnStatistics . get (  )  . get ( key . getHivePartitionName (  )  . getPartitionName (  )  )  . containsKey ( key . getColumnName (  )  )  )  )     {", "resultMap . put ( key ,    Optional . of ( columnStatistics . get (  )  . get ( key . getHivePartitionName (  )  . getPartitionName (  )  )  . get ( key . getColumnName (  )  )  )  )  ;", "} else    {", "resultMap . put ( key ,    Optional . empty (  )  )  ;", "}", "}", "return   resultMap . build (  )  ;", "}", "METHOD_END"], "methodName": ["loadPartitionColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getPartitionNames ( hiveTableName . getDatabaseName (  )  ,    hiveTableName . getTableName (  )  )  ;", "}", "METHOD_END"], "methodName": ["loadPartitionNames"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getPartitionNamesByParts ( partitionFilter . getHiveTableName (  )  . getDatabaseName (  )  ,    partitionFilter . getHiveTableName (  )  . getTableName (  )  ,    partitionFilter . getParts (  )  )  ;", "}", "METHOD_END"], "methodName": ["loadPartitionNamesByParts"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( partitionNames ,     \" partitionNames   is   null \"  )  ;", "checkArgument (  (  !  ( Iterables . isEmpty ( partitionNames )  )  )  ,     \" partitionNames   is   empty \"  )  ;", ". HivePartitionName   firstPartition    =    Iterables . get ( partitionNames ,     0  )  ;", ". HiveTableName   hiveTableName    =    firstPartition . getHiveTableName (  )  ;", "String   databaseName    =    hiveTableName . getDatabaseName (  )  ;", "String   tableName    =    hiveTableName . getTableName (  )  ;", "List < String >    partitionsToFetch    =    new   ArrayList <  >  (  )  ;", "for    (  . HivePartitionName   partitionName    :    partitionNames )     {", "checkArgument ( partitionName . getHiveTableName (  )  . equals ( hiveTableName )  ,     \" Expected   table   name    % s   but   got    % s \"  ,    hiveTableName ,    partitionName . getHiveTableName (  )  )  ;", "partitionsToFetch . add ( partitionName . getPartitionName (  )  )  ;", "}", "Builder <  . HivePartitionName ,    Optional < Partition >  >    partitions    =    ImmutableMap . builder (  )  ;", "Map < String ,    Optional < Partition >  >    partitionsByNames    =    delegate . getPartitionsByNames ( databaseName ,    tableName ,    partitionsToFetch )  ;", "for    ( Map . Entry < String ,    Optional < Partition >  >    entry    :    partitionsByNames . entrySet (  )  )     {", "partitions . put (  . HivePartitionName . partition ( hiveTableName ,    entry . getKey (  )  )  ,    entry . getValue (  )  )  ;", "}", "return   partitions . build (  )  ;", "}", "METHOD_END"], "methodName": ["loadPartitionsByNames"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getRoles ( user )  ;", "}", "METHOD_END"], "methodName": ["loadRoles"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getTable ( hiveTableName . getDatabaseName (  )  ,    hiveTableName . getTableName (  )  )  ;", "}", "METHOD_END"], "methodName": ["loadTable"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   delegate . getTablePrivileges ( user ,    databaseName ,    tableName )  ;", "}", "METHOD_END"], "methodName": ["loadTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   new   CachingHiveMetastore ( delegate ,    newDirectExecutorService (  )  ,    OptionalLong . empty (  )  ,    OptionalLong . empty (  )  ,    maximumSize )  ;", "}", "METHOD_END"], "methodName": ["memoizeMetastore"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "CacheBuilder < Object ,    Object >    cacheBuilder    =    CacheBuilder . newBuilder (  )  ;", "if    ( expiresAfterWriteMillis . isPresent (  )  )     {", "cacheBuilder    =    cacheBuilder . expireAfterWrite ( expiresAfterWriteMillis . getAsLong (  )  ,    TimeUnit . MILLISECONDS )  ;", "}", "if    (  ( refreshMillis . isPresent (  )  )     &  &     (  (  !  ( expiresAfterWriteMillis . isPresent (  )  )  )     |  |     (  ( expiresAfterWriteMillis . getAsLong (  )  )     >     ( refreshMillis . getAsLong (  )  )  )  )  )     {", "cacheBuilder    =    cacheBuilder . refreshAfterWrite ( refreshMillis . getAsLong (  )  ,    TimeUnit . MILLISECONDS )  ;", "}", "cacheBuilder    =    cacheBuilder . maximumSize ( maximumSize )  ;", "return   cacheBuilder ;", "}", "METHOD_END"], "methodName": ["newCacheBuilder"], "fileName": "com.facebook.presto.hive.metastore.CachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   comment ;", "}", "METHOD_END"], "methodName": ["getComment"], "fileName": "com.facebook.presto.hive.metastore.Column"}, {"methodBody": ["METHOD_START", "{", "return   name ;", "}", "METHOD_END"], "methodName": ["getName"], "fileName": "com.facebook.presto.hive.metastore.Column"}, {"methodBody": ["METHOD_START", "{", "return   type ;", "}", "METHOD_END"], "methodName": ["getType"], "fileName": "com.facebook.presto.hive.metastore.Column"}, {"methodBody": ["METHOD_START", "{", "return   new   Database . Builder (  )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.Database"}, {"methodBody": ["METHOD_START", "{", "return   new   Database . Builder ( database )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.Database"}, {"methodBody": ["METHOD_START", "{", "return   comment ;", "}", "METHOD_END"], "methodName": ["getComment"], "fileName": "com.facebook.presto.hive.metastore.Database"}, {"methodBody": ["METHOD_START", "{", "return   databaseName ;", "}", "METHOD_END"], "methodName": ["getDatabaseName"], "fileName": "com.facebook.presto.hive.metastore.Database"}, {"methodBody": ["METHOD_START", "{", "return   location ;", "}", "METHOD_END"], "methodName": ["getLocation"], "fileName": "com.facebook.presto.hive.metastore.Database"}, {"methodBody": ["METHOD_START", "{", "return   ownerName ;", "}", "METHOD_END"], "methodName": ["getOwnerName"], "fileName": "com.facebook.presto.hive.metastore.Database"}, {"methodBody": ["METHOD_START", "{", "return   ownerType ;", "}", "METHOD_END"], "methodName": ["getOwnerType"], "fileName": "com.facebook.presto.hive.metastore.Database"}, {"methodBody": ["METHOD_START", "{", "return   parameters ;", "}", "METHOD_END"], "methodName": ["getParameters"], "fileName": "com.facebook.presto.hive.metastore.Database"}, {"methodBody": ["METHOD_START", "{", "return   averageColumnLength ;", "}", "METHOD_END"], "methodName": ["getAverageColumnLength"], "fileName": "com.facebook.presto.hive.metastore.HiveColumnStatistics"}, {"methodBody": ["METHOD_START", "{", "return   distinctValuesCount ;", "}", "METHOD_END"], "methodName": ["getDistinctValuesCount"], "fileName": "com.facebook.presto.hive.metastore.HiveColumnStatistics"}, {"methodBody": ["METHOD_START", "{", "return   falseCount ;", "}", "METHOD_END"], "methodName": ["getFalseCount"], "fileName": "com.facebook.presto.hive.metastore.HiveColumnStatistics"}, {"methodBody": ["METHOD_START", "{", "return   highValue ;", "}", "METHOD_END"], "methodName": ["getHighValue"], "fileName": "com.facebook.presto.hive.metastore.HiveColumnStatistics"}, {"methodBody": ["METHOD_START", "{", "return   lowValue ;", "}", "METHOD_END"], "methodName": ["getLowValue"], "fileName": "com.facebook.presto.hive.metastore.HiveColumnStatistics"}, {"methodBody": ["METHOD_START", "{", "return   maxColumnLength ;", "}", "METHOD_END"], "methodName": ["getMaxColumnLength"], "fileName": "com.facebook.presto.hive.metastore.HiveColumnStatistics"}, {"methodBody": ["METHOD_START", "{", "return   nullsCount ;", "}", "METHOD_END"], "methodName": ["getNullsCount"], "fileName": "com.facebook.presto.hive.metastore.HiveColumnStatistics"}, {"methodBody": ["METHOD_START", "{", "return   trueCount ;", "}", "METHOD_END"], "methodName": ["getTrueCount"], "fileName": "com.facebook.presto.hive.metastore.HiveColumnStatistics"}, {"methodBody": ["METHOD_START", "{", "install ( installModuleIf ( MetastoreConfig . class ,     (    metastore )     -  >    name . equalsIgnoreCase ( metastore . getMetastoreType (  )  )  ,    module )  )  ;", "}", "METHOD_END"], "methodName": ["bindMetastoreModule"], "fileName": "com.facebook.presto.hive.metastore.HiveMetastoreModule"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( modifiedPartitions ,     \" modifiedPartitions   is   null \"  )  ;", "return   new    ( schemaTableName ,    table ,     . JsonSerializableEntry . toMap ( modifiedPartitions )  )  ;", "}", "METHOD_END"], "methodName": ["deserialize"], "fileName": "com.facebook.presto.hive.metastore.HivePageSinkMetadata"}, {"methodBody": ["METHOD_START", "{", "return   HivePageSinkMetadata . JsonSerializableEntry . fromMap ( modifiedPartitions )  ;", "}", "METHOD_END"], "methodName": ["getJsonSerializableModifiedPartitions"], "fileName": "com.facebook.presto.hive.metastore.HivePageSinkMetadata"}, {"methodBody": ["METHOD_START", "{", "return   modifiedPartitions ;", "}", "METHOD_END"], "methodName": ["getModifiedPartitions"], "fileName": "com.facebook.presto.hive.metastore.HivePageSinkMetadata"}, {"methodBody": ["METHOD_START", "{", "return   schemaTableName ;", "}", "METHOD_END"], "methodName": ["getSchemaTableName"], "fileName": "com.facebook.presto.hive.metastore.HivePageSinkMetadata"}, {"methodBody": ["METHOD_START", "{", "return   table ;", "}", "METHOD_END"], "methodName": ["getTable"], "fileName": "com.facebook.presto.hive.metastore.HivePageSinkMetadata"}, {"methodBody": ["METHOD_START", "{", "if    (  (  !  ( table . isPresent (  )  )  )     |  |     ( table . get (  )  . getPartitionColumns (  )  . isEmpty (  )  )  )     {", "throw   new   IllegalArgumentException ( String . format (  \" Unexpected   call   to   getPartition .    Table   name :     % s \"  ,    schemaTableName )  )  ;", "}", "Optional < Partition >    modifiedPartition    =    modifiedPartitions . get ( partitionValues )  ;", "if    ( modifiedPartition    =  =    null )     {", "return   delegate . getPartition ( schemaTableName . getSchemaName (  )  ,    schemaTableName . getTableName (  )  ,    partitionValues )  ;", "} else    {", "return   modifiedPartition ;", "}", "}", "METHOD_END"], "methodName": ["getPartition"], "fileName": "com.facebook.presto.hive.metastore.HivePageSinkMetadataProvider"}, {"methodBody": ["METHOD_START", "{", "return   table ;", "}", "METHOD_END"], "methodName": ["getTable"], "fileName": "com.facebook.presto.hive.metastore.HivePageSinkMetadataProvider"}, {"methodBody": ["METHOD_START", "{", "return   principalName ;", "}", "METHOD_END"], "methodName": ["getPrincipalName"], "fileName": "com.facebook.presto.hive.metastore.HivePrincipal"}, {"methodBody": ["METHOD_START", "{", "return   principalType ;", "}", "METHOD_END"], "methodName": ["getPrincipalType"], "fileName": "com.facebook.presto.hive.metastore.HivePrincipal"}, {"methodBody": ["METHOD_START", "{", "if    ( grantee . equalsIgnoreCase ( HivePrincipal . PUBLIC _ ROLE _ NAME )  )     {", "return   new   HivePrincipal ( HivePrincipal . PUBLIC _ ROLE _ NAME ,    PrincipalType . ROLE )  ;", "} else    {", "return   new   HivePrincipal ( grantee ,    PrincipalType . USER )  ;", "}", "}", "METHOD_END"], "methodName": ["toHivePrincipal"], "fileName": "com.facebook.presto.hive.metastore.HivePrincipal"}, {"methodBody": ["METHOD_START", "{", "return   hivePrivilege ;", "}", "METHOD_END"], "methodName": ["getHivePrivilege"], "fileName": "com.facebook.presto.hive.metastore.HivePrivilegeInfo"}, {"methodBody": ["METHOD_START", "{", "return    ( getHivePrivilege (  )  . equals ( hivePrivilegeInfo . getHivePrivilege (  )  )  )     &  &     (  (  ( isGrantOption (  )  )     =  =     ( hivePrivilegeInfo . isGrantOption (  )  )  )     |  |     (  (  !  ( isGrantOption (  )  )  )     &  &     ( hivePrivilegeInfo . isGrantOption (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["isContainedIn"], "fileName": "com.facebook.presto.hive.metastore.HivePrivilegeInfo"}, {"methodBody": ["METHOD_START", "{", "return   grantOption ;", "}", "METHOD_END"], "methodName": ["isGrantOption"], "fileName": "com.facebook.presto.hive.metastore.HivePrivilegeInfo"}, {"methodBody": ["METHOD_START", "{", "boolean   withGrantOption    =    userGrant . isGrantOption (  )  ;", "String   name    =    userGrant . getPrivilege (  )  . toUpperCase ( Locale . ENGLISH )  ;", "switch    ( name )     {", "case    \" ALL \"     :", "return   Arrays . asList (  . HivePrivilege . values (  )  )  . stream (  )  . map (  (    hivePrivilege )     -  >    new    ( hivePrivilege ,    withGrantOption )  )  . collect ( Collectors . toSet (  )  )  ;", "case    \" SELECT \"     :", "return   ImmutableSet . of ( new    (  . HivePrivilege . SELECT ,    withGrantOption )  )  ;", "case    \" INSERT \"     :", "return   ImmutableSet . of ( new    (  . HivePrivilege . INSERT ,    withGrantOption )  )  ;", "case    \" UPDATE \"     :", "return   ImmutableSet . of ( new    (  . HivePrivilege . UPDATE ,    withGrantOption )  )  ;", "case    \" DELETE \"     :", "return   ImmutableSet . of ( new    (  . HivePrivilege . DELETE ,    withGrantOption )  )  ;", "case    \" OWNERSHIP \"     :", "return   ImmutableSet . of ( new    (  . HivePrivilege . OWNERSHIP ,    withGrantOption )  )  ;", "}", "return   ImmutableSet . of (  )  ;", "}", "METHOD_END"], "methodName": ["parsePrivilege"], "fileName": "com.facebook.presto.hive.metastore.HivePrivilegeInfo"}, {"methodBody": ["METHOD_START", "{", "switch    ( privilege )     {", "case   SELECT    :", "return    . HivePrivilege . SELECT ;", "case   INSERT    :", "return    . HivePrivilege . INSERT ;", "case   DELETE    :", "return    . HivePrivilege . DELETE ;", "case   UPDATE    :", "return    . HivePrivilege . UPDATE ;", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["toHivePrivilege"], "fileName": "com.facebook.presto.hive.metastore.HivePrivilegeInfo"}, {"methodBody": ["METHOD_START", "{", "switch    ( getHivePrivilege (  )  )     {", "case   SELECT    :", "return   ImmutableSet . of ( new   PrivilegeInfo ( Privilege . SELECT ,    isGrantOption (  )  )  )  ;", "case   INSERT    :", "return   ImmutableSet . of ( new   PrivilegeInfo ( Privilege . INSERT ,    isGrantOption (  )  )  )  ;", "case   DELETE    :", "return   ImmutableSet . of ( new   PrivilegeInfo ( Privilege . DELETE ,    isGrantOption (  )  )  )  ;", "case   UPDATE    :", "return   ImmutableSet . of ( new   PrivilegeInfo ( Privilege . UPDATE ,    isGrantOption (  )  )  )  ;", "case   OWNERSHIP    :", "return   Arrays . asList ( Privilege . values (  )  )  . stream (  )  . map (  (    privilege )     -  >    new   PrivilegeInfo ( privilege ,    Boolean . TRUE )  )  . collect ( Collectors . toSet (  )  )  ;", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["toPrivilegeInfo"], "fileName": "com.facebook.presto.hive.metastore.HivePrivilegeInfo"}, {"methodBody": ["METHOD_START", "{", "return   new   HivePrivilegeInfo ( hivePrivilege ,    grantOption )  ;", "}", "METHOD_END"], "methodName": ["withGrantOption"], "fileName": "com.facebook.presto.hive.metastore.HivePrivilegeInfo"}, {"methodBody": ["METHOD_START", "{", "return   metastoreType ;", "}", "METHOD_END"], "methodName": ["getMetastoreType"], "fileName": "com.facebook.presto.hive.metastore.MetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "this . metastoreType    =    metastoreType ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMetastoreType"], "fileName": "com.facebook.presto.hive.metastore.MetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "return   MetastoreUtil . getHiveSchema ( partition . getStorage (  )  ,    partition . getColumns (  )  ,    table . getDataColumns (  )  ,    table . getParameters (  )  ,    table . getDatabaseName (  )  ,    table . getTableName (  )  ,    table . getPartitionColumns (  )  )  ;", "}", "METHOD_END"], "methodName": ["getHiveSchema"], "fileName": "com.facebook.presto.hive.metastore.MetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "return   MetastoreUtil . getHiveSchema ( table . getStorage (  )  ,    table . getDataColumns (  )  ,    table . getDataColumns (  )  ,    table . getParameters (  )  ,    table . getDatabaseName (  )  ,    table . getTableName (  )  ,    table . getPartitionColumns (  )  )  ;", "}", "METHOD_END"], "methodName": ["getHiveSchema"], "fileName": "com.facebook.presto.hive.metastore.MetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "return   MetastoreUtil . getProtectMode ( partition . getParameters (  )  )  ;", "}", "METHOD_END"], "methodName": ["getProtectMode"], "fileName": "com.facebook.presto.hive.metastore.MetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "return   MetastoreUtil . getProtectMode ( table . getParameters (  )  )  ;", "}", "METHOD_END"], "methodName": ["getProtectMode"], "fileName": "com.facebook.presto.hive.metastore.MetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( parameters . containsKey ( PARAMETER _ NAME )  )  )     {", "return   new   ProtectMode (  )  ;", "} else    {", "return   ProtectMode . getProtectModeFromString ( parameters . get ( PARAMETER _ NAME )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getProtectMode"], "fileName": "com.facebook.presto.hive.metastore.MetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( partitionColumns . size (  )  )     =  =     ( values . size (  )  )  )  )  ;", "List < String >    partitionColumnNames    =    partitionColumns . stream (  )  . map ( Column :  : getName )  . collect ( Collectors . toList (  )  )  ;", "return   Fils . makePartName ( partitionColumnNames ,    values )  ;", "}", "METHOD_END"], "methodName": ["makePartName"], "fileName": "com.facebook.presto.hive.metastore.MetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   ddl    =    new   StringBuilder (  )  ;", "ddl . append (  \" struct    \"  )  ;", "ddl . append ( structName )  ;", "ddl . append (  \"     {     \"  )  ;", "boolean   first    =    true ;", "for    ( Column   column    :    columns )     {", "if    ( first )     {", "first    =    false ;", "} else    {", "ddl . append (  \"  ,     \"  )  ;", "}", "ddl . append ( MetaSs . typeToThriftType ( column . getType (  )  . getHiveTypeName (  )  . toString (  )  )  )  ;", "ddl . append (  '     '  )  ;", "ddl . append ( column . getName (  )  )  ;", "}", "ddl . append (  \"  }  \"  )  ;", "return   ddl . toString (  )  ;", "}", "METHOD_END"], "methodName": ["toThriftDdl"], "fileName": "com.facebook.presto.hive.metastore.MetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Table   table    =    metastore . getTable ( databaseName ,    tableName )  . orElseThrow (  (  )     -  >    new   com . facebook . presto . spi . TableNotFoundException ( new   SchemaTableName ( databaseName ,    tableName )  )  )  ;", "if    ( table . getPartitionColumns (  )  . stream (  )  . anyMatch (  (    column )     -  >    column . getName (  )  . equals ( columnName )  )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Cannot   drop   partition   columns \"  )  ;", "}", "if    (  ( table . getDataColumns (  )  . size (  )  )     <  =     1  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Cannot   drop   the   only   non - partition   column   in   a   table \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["verifyCanDropColumn"], "fileName": "com.facebook.presto.hive.metastore.MetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "if    ( protectMode . offline )     {", "if    ( partitionName . isPresent (  )  )     {", "throw   new   PartitionOfflineException ( tableName ,    partitionName . get (  )  ,    false ,    null )  ;", "}", "throw   new   TableOfflineException ( tableName ,    false ,    null )  ;", "}", "String   Offline    =    parameters . get ( HiveSplitManager . PRESTO _ OFFLINE )  ;", "if    (  !  ( isNullOrEmpty ( Offline )  )  )     {", "if    ( partitionName . isPresent (  )  )     {", "throw   new   PartitionOfflineException ( tableName ,    partitionName . get (  )  ,    true ,    Offline )  ;", "}", "throw   new   TableOfflineException ( tableName ,    true ,    Offline )  ;", "}", "}", "METHOD_END"], "methodName": ["verifyOnline"], "fileName": "com.facebook.presto.hive.metastore.MetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "return   new   Partition . Builder (  )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.Partition"}, {"methodBody": ["METHOD_START", "{", "return   new   Partition . Builder ( partition )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.Partition"}, {"methodBody": ["METHOD_START", "{", "return   columns ;", "}", "METHOD_END"], "methodName": ["getColumns"], "fileName": "com.facebook.presto.hive.metastore.Partition"}, {"methodBody": ["METHOD_START", "{", "return   databaseName ;", "}", "METHOD_END"], "methodName": ["getDatabaseName"], "fileName": "com.facebook.presto.hive.metastore.Partition"}, {"methodBody": ["METHOD_START", "{", "return   parameters ;", "}", "METHOD_END"], "methodName": ["getParameters"], "fileName": "com.facebook.presto.hive.metastore.Partition"}, {"methodBody": ["METHOD_START", "{", "return   storage ;", "}", "METHOD_END"], "methodName": ["getStorage"], "fileName": "com.facebook.presto.hive.metastore.Partition"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.metastore.Partition"}, {"methodBody": ["METHOD_START", "{", "return   values ;", "}", "METHOD_END"], "methodName": ["getValues"], "fileName": "com.facebook.presto.hive.metastore.Partition"}, {"methodBody": ["METHOD_START", "{", "return   new   PrincipalPrivileges . Builder (  )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.PrincipalPrivileges"}, {"methodBody": ["METHOD_START", "{", "return   new   PrincipalPrivileges . Builder ( table )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.PrincipalPrivileges"}, {"methodBody": ["METHOD_START", "{", "return   rolePrivileges ;", "}", "METHOD_END"], "methodName": ["getRolePrivileges"], "fileName": "com.facebook.presto.hive.metastore.PrincipalPrivileges"}, {"methodBody": ["METHOD_START", "{", "return   userPrivileges ;", "}", "METHOD_END"], "methodName": ["getUserPrivileges"], "fileName": "com.facebook.presto.hive.metastore.PrincipalPrivileges"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . addColumn ( databaseName ,    tableName ,    columnName ,    columnType ,    columnComment )  )  ;", "}", "METHOD_END"], "methodName": ["addColumn"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setShared (  )  ;", "checkArgument (  . getPrestoQueryId ( partition )  . isPresent (  )  )  ;", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionsOfTable    =    partitionActions . computeIfAbsent ( new   SchemaTableName ( databaseName ,    tableName )  ,     (    k )     -  >    new   HashMap <  >  (  )  )  ;", ". Action <  . PartitionAndMore >    oldPartitionAction    =    partitionActionsOfTable . get ( partition . getValues (  )  )  ;", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    databaseName ,    tableName )  ;", "if    ( oldPartitionAction    =  =    null )     {", "partitionActionsOfTable . put ( partition . getValues (  )  ,    new    . Action (  . ActionType . ADD ,    new    . PartitionAndMore ( partition ,    currentLocation ,    Optional . empty (  )  )  ,    context )  )  ;", "return ;", "}", "switch    ( oldPartitionAction . getType (  )  )     {", "case   DROP    :", "{", "if    (  !  ( oldPartitionAction . getContext (  )  . getIdentity (  )  . getUser (  )  . equals ( session . getUser (  )  )  )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . TRANSACTION _ CONFLICT ,     \" Operation   on   the   same   partition   with   different   user   in   the   same   transaction   is   not   supported \"  )  ;", "}", "partitionActionsOfTable . put ( partition . getValues (  )  ,    new    . Action (  . ActionType . ALTER ,    new    . PartitionAndMore ( partition ,    currentLocation ,    Optional . empty (  )  )  ,    context )  )  ;", "break ;", "}", "case   ADD    :", "case   ALTER    :", "case   INSERT _ EXISTING    :", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . ALREADY _ EXISTS ,    String . format (  \" Partition   already   exists   for   table    '  % s .  % s '  :     % s \"  ,    databaseName ,    tableName ,    partition . getValues (  )  )  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["addPartition"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "FileSystem   fileSystem ;", "try    {", "fileSystem    =    hdfsEnvironment . getFileSystem ( context ,    currentPath )  ;", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,    String . format (  \" Error   moving   data   files   to   final   location .    Error   listing   directory    % s \"  ,    currentPath )  ,    e )  ;", "}", "for    ( String   fileName    :    fileNames )     {", "Path   source    =    new   Path ( currentPath ,    fileName )  ;", "Path   target    =    new   Path ( targetPath ,    fileName )  ;", "fileRenameFutures . add ( CompletableFuture . runAsync (  (  )     -  >     {", "if    ( cancelled . get (  )  )     {", "return ;", "}", "try    {", "if    (  ( fileSystem . exists ( target )  )     |  |     (  !  ( fileSystem . rename ( source ,    target )  )  )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,    String . format (  \" Error   moving   data   files   from    % s   to   final   location    % s \"  ,    source ,    target )  )  ;", "}", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,    String . format (  \" Error   moving   data   files   from    % s   to   final   location    % s \"  ,    source ,    target )  ,    e )  ;", "}", "}  ,    executor )  )  ;", "}", "}", "METHOD_END"], "methodName": ["asyncRename"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( Thread . holdsLock ( this )  )  )     {", "throw   new   IllegalStateExcep ( String . format (  \" Thread   must   hold   a   lock   on   the    % s \"  ,    getClass (  )  . getSimpleName (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkHoldsLock"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkHoldsLock (  )  ;", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionsOfTable    =    partitionActions . get ( new   SchemaTableName ( databaseName ,    tableName )  )  ;", "if    (  ( partitionActionsOfTable    !  =    null )     &  &     (  !  ( partitionActionsOfTable . isEmpty (  )  )  )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Cannot   make   schema   changes   to   a   table / view   with   modified   partitions   in   the   same   transaction \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkNoPartitionAction"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkHoldsLock (  )  ;", "switch    ( state )     {", "case   EMPTY    :", "case   SHARED _ OPERATION _ BUFFERED    :", "return ;", "case   EXCLUSIVE _ OPERATION _ BUFFERED    :", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Unsupported   combination   of   operations   in   a   single   transaction \"  )  ;", "case   FINISHED    :", "throw   new   IllegalStateException (  \" Tried   to   access   metastore   after   transaction   has   been   committed / aborted \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkReadable"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "switch    ( state )     {", "case   EMPTY    :", "break ;", "case   SHARED _ OPERATION _ BUFFERED    :", "commitShared (  )  ;", "break ;", "case   EXCLUSIVE _ OPERATION _ BUFFERED    :", "Objects . requireNonNull ( bufferedExclusiveOperation ,     \" bufferedExclusiveOperation   is   null \"  )  ;", "bufferedExclusiveOperation . execute ( delegate ,    hdfsEnvironment )  ;", "break ;", "case   FINISHED    :", "throw   new   IllegalStateException (  \" Tried   to   commit   buffered   metastore   operations   after   transaction   has   been   committed / aborted \"  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   state \"  )  ;", "}", "}    finally    {", "state    =     . State . FINISHED ;", "}", "}", "METHOD_END"], "methodName": ["commit"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkHoldsLock (  )  ;", ". Committer   committer    =    new    . Committer (  )  ;", "try    {", "for    ( Map . Entry < SchemaTableName ,     . Action <  . TableAndMore >  >    entry    :    tableActions . entrySet (  )  )     {", "SchemaTableName   schemaTableName    =    entry . getKey (  )  ;", ". Action <  . TableAndMore >    action    =    entry . getValue (  )  ;", "switch    ( action . getType (  )  )     {", "case   DROP    :", "committer . prepareDropTable ( schemaTableName )  ;", "break ;", "case   ALTER    :", "committer . prepareAlterTable (  )  ;", "break ;", "case   ADD    :", "committer . prepareAddTable ( action . getContext (  )  ,    action . getData (  )  )  ;", "break ;", "case   INSERT _ EXISTING    :", "committer . prepareInsertExistingTable ( action . getContext (  )  ,    action . getData (  )  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "for    ( Map . Entry < SchemaTableName ,    Map < List < String >  ,     . Action <  . PartitionAndMore >  >  >    tableEntry    :    partitionActions . entrySet (  )  )     {", "SchemaTableName   schemaTableName    =    tableEntry . getKey (  )  ;", "for    ( Map . Entry < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionEntry    :    tableEntry . getValue (  )  . entrySet (  )  )     {", "List < String >    partitionValues    =    partitionEntry . getKey (  )  ;", ". Action <  . PartitionAndMore >    action    =    partitionEntry . getValue (  )  ;", "switch    ( action . getType (  )  )     {", "case   DROP    :", "committer . prepareDropPartition ( schemaTableName ,    partitionValues )  ;", "break ;", "case   ALTER    :", "committer . prepareAlterPartition ( action . getContext (  )  ,    action . getData (  )  )  ;", "break ;", "case   ADD    :", "committer . prepareAddPartition ( action . getContext (  )  ,    action . getData (  )  )  ;", "break ;", "case   INSERT _ EXISTING    :", "committer . prepareInsertExistingPartition ( action . getContext (  )  ,    action . getData (  )  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "}", "committer . waitForAsyncRenames (  )  ;", "committer . executeAddTableOperations (  )  ;", "committer . executeAlterPartitionOperations (  )  ;", "committer . executeAddPartitionOperations (  )  ;", "}    catch    ( Throwable   t )     {", "committer . cancelUnstartedAsyncRenames (  )  ;", "committer . undoAddPartitionOperations (  )  ;", "committer . undoAddTableOperations (  )  ;", "committer . waitForAsyncRenamesSuppressThrowables (  )  ;", "committer . executeCleanupTasksForAbort ( committer . extractFilePrefixes ( declaredIntentionsToWrite )  )  ;", "committer . executeRenameTasksForAbort (  )  ;", "committer . undoAlterPartitionOperations (  )  ;", "rollbackShared (  )  ;", "throw   t ;", "}", "try    {", "committer . executeIrreversibleMetastoreOperations (  )  ;", "}    finally    {", "committer . executeDeletionTasksForFinish (  )  ;", "committer . deleteEmptyStagingDirectories ( declaredIntentionsToWrite )  ;", "}", "}", "METHOD_END"], "methodName": ["commitShared"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . createDatabase ( database )  )  ;", "}", "METHOD_END"], "methodName": ["createDatabase"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setShared (  )  ;", "checkNoPartitionAction ( table . getDatabaseName (  )  ,    table . getTableName (  )  )  ;", "SchemaTableName   schemaTableName    =    new   SchemaTableName ( table . getDatabaseName (  )  ,    table . getTableName (  )  )  ;", ". Action <  . TableAndMore >    oldTableAction    =    tableActions . get ( schemaTableName )  ;", ". TableAndMore   tableAndMore    =    new    . TableAndMore ( table ,    Optional . of ( principalPrivileges )  ,    currentPath ,    Optional . empty (  )  ,    ignoreExisting )  ;", "if    ( oldTableAction    =  =    null )     {", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    table . getDatabaseName (  )  ,    table . getTableName (  )  )  ;", "tableActions . put ( schemaTableName ,    new    . Action (  . ActionType . ADD ,    tableAndMore ,    context )  )  ;", "return ;", "}", "switch    ( oldTableAction . getType (  )  )     {", "case   DROP    :", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . TRANSACTION _ CONFLICT ,     \" Dropping   and   then   recreating   the   same   table   in   a   transaction   is   not   supported \"  )  ;", "case   ADD    :", "case   ALTER    :", "case   INSERT _ EXISTING    :", "throw   new   TableAlreadyExistsException ( schemaTableName )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["createTable"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setShared (  )  ;", "if    ( writeMode    =  =     (  . WriteMode . DIRECT _ TO _ TARGET _ EXISTING _ DIRECTORY )  )     {", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionsOfTable    =    partitionActions . get ( schemaTableName )  ;", "if    (  ( partitionActionsOfTable    !  =    null )     &  &     (  !  ( partitionActionsOfTable . isEmpty (  )  )  )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Can   not   insert   into   a   table   with   a   partition   that   has   been   modified   in   the   same   transaction   when   Presto   is   configured   to   skip   temporary   directories .  \"  )  ;", "}", "}", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    schemaTableName . getSchemaName (  )  ,    schemaTableName . getTableName (  )  )  ;", "declaredIntentionsToWrite . add ( new    . DeclaredIntentionToWrite ( writeMode ,    context ,    stagingPathRoot ,    filePrefix ,    schemaTableName )  )  ;", "}", "METHOD_END"], "methodName": ["declareIntentionToWrite"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "if    ( fileSystem . delete ( path ,    recursive )  )     {", "return   true ;", "}", "return    !  ( fileSystem . exists ( path )  )  ;", "}    catch    ( FileNotFoundExcep   ignored )     {", "return   true ;", "}    catch    ( IOExcep   ignored )     {", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["deleteIfExists"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "FileSystem   fileSystem ;", "try    {", "fileSystem    =    hdfsEnvironment . getFileSystem ( context ,    path )  ;", "}    catch    ( IOException   ignored )     {", "return   false ;", "}", "return    . deleteIfExists ( fileSystem ,    path ,    true )  ;", "}", "METHOD_END"], "methodName": ["deleteRecursivelyIfExists"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkHoldsLock (  )  ;", "checkReadable (  )  ;", "Optional < Table >    table    =    getTable ( databaseName ,    tableName )  ;", "if    (  !  ( table . isPresent (  )  )  )     {", "return   Optional . empty (  )  ;", "}", "List < String >    partitionNames ;", ". TableSource   tableSource    =    getTableSource ( databaseName ,    tableName )  ;", "switch    ( tableSource )     {", "case   CREATED _ IN _ THIS _ TRANSACTION    :", "partitionNames    =    ImmutableList . of (  )  ;", "break ;", "case   PRE _ EXISTING _ TABLE    :", "{", "Optional < List < String >  >    partitionNameResult ;", "if    ( parts . isPresent (  )  )     {", "partitionNameResult    =    delegate . getPartitionNamesByParts ( databaseName ,    tableName ,    parts . get (  )  )  ;", "} else    {", "partitionNameResult    =    delegate . getPartitionNames ( databaseName ,    tableName )  ;", "}", "if    (  !  ( partitionNameResult . isPresent (  )  )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . TRANSACTION _ CONFLICT ,    String . format (  \" Table    % s .  % s   was   dropped   by   another   transaction \"  ,    databaseName ,    tableName )  )  ;", "}", "partitionNames    =    partitionNameResult . get (  )  ;", "break ;", "}", "default    :", "throw   new   UnsupportedOperationException (  \" Unknown   table   source \"  )  ;", "}", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionsOfTable    =    partitionActions . computeIfAbsent ( new   SchemaTableName ( databaseName ,    tableName )  ,     (    k )     -  >    new   HashMap <  >  (  )  )  ;", "ImmutableList . Builder < String >    resultBuilder    =    ImmutableList . builder (  )  ;", "for    ( String   partitionName    :    partitionNames )     {", "List < String >    partitionValues    =    HiveUtil . toPartitionValues ( partitionName )  ;", ". Action <  . PartitionAndMore >    partitionAction    =    partitionActionsOfTable . get ( partitionValues )  ;", "if    ( partitionAction    =  =    null )     {", "resultBuilder . add ( partitionName )  ;", "continue ;", "}", "switch    ( partitionAction . getType (  )  )     {", "case   ADD    :", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . TRANSACTION _ CONFLICT ,    String . format (  \" Another   transaction   created   partition    % s   in   table    % s .  % s \"  ,    partitionValues ,    databaseName ,    tableName )  )  ;", "case   DROP    :", "break ;", "case   ALTER    :", "case   INSERT _ EXISTING    :", "resultBuilder . add ( partitionName )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "if    (  !  ( partitionActionsOfTable . isEmpty (  )  )  )     {", "List < String >    columnNames    =    table . get (  )  . getPartitionColumns (  )  . stream (  )  . map ( Column :  : getName )  . collect ( Collectors . toList (  )  )  ;", "for    (  . Action <  . PartitionAndMore >    partitionAction    :    partitionActionsOfTable . values (  )  )     {", "if    (  ( partitionAction . getType (  )  )     =  =     (  . ActionType . ADD )  )     {", "List < String >    values    =    partitionAction . getData (  )  . getPartition (  )  . getValues (  )  ;", "if    (  (  !  ( parts . isPresent (  )  )  )     |  |     (  . partitionValuesMatch ( values ,    parts . get (  )  )  )  )     {", "resultBuilder . add ( makePartName ( columnNames ,    values )  )  ;", "}", "}", "}", "}", "return   Optional . of ( resultBuilder . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["doGetPartitionNames"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( directory . getName (  )  . startsWith (  \"  . presto \"  )  )     {", "return   new    . RecursiveDeleteResult ( false ,    ImmutableList . of (  )  )  ;", "}", "FileStatus [  ]    allFiles ;", "try    {", "allFiles    =    fileSystem . listStatus ( directory )  ;", "}    catch    ( IOException   e )     {", "ImmutableList . Builder < String >    notDeletedItems    =    ImmutableList . builder (  )  ;", "notDeletedItems . add (  (  ( directory . toString (  )  )     +     \"  /  *  *  \"  )  )  ;", "return   new    . RecursiveDeleteResult ( false ,    notDeletedItems . build (  )  )  ;", "}", "boolean   allDescendentsDeleted    =    true ;", "ImmutableList . Builder < String >    notDeletedEligibleItems    =    ImmutableList . builder (  )  ;", "for    ( FileStatus   fileStatus    :    allFiles )     {", "if    ( HadoopFileStatus . isFile ( fileStatus )  )     {", "Path   filePath    =    fileStatus . getPath (  )  ;", "String   fileName    =    filePath . getName (  )  ;", "boolean   eligible    =    false ;", "if    (  !  ( fileName . startsWith (  \"  . presto \"  )  )  )     {", "eligible    =    filePrefixes . stream (  )  . anyMatch ( fileName :  : startsWith )  ;", "}", "if    ( eligible )     {", "if    (  !  (  . deleteIfExists ( fileSystem ,    filePath ,    false )  )  )     {", "allDescendentsDeleted    =    false ;", "notDeletedEligibleItems . add ( filePath . toString (  )  )  ;", "}", "} else    {", "allDescendentsDeleted    =    false ;", "}", "} else", "if    ( HadoopFileStatus . isDirectory ( fileStatus )  )     {", ". RecursiveDeleteResult   subResult    =     . doRecursiveDeleteFiles ( fileSystem ,    fileStatus . getPath (  )  ,    filePrefixes ,    deleteEmptyDirectories )  ;", "if    (  !  ( subResult . isDirectoryNoLongerExists (  )  )  )     {", "allDescendentsDeleted    =    false ;", "}", "if    (  !  ( subResult . getNotDeletedEligibleItems (  )  . isEmpty (  )  )  )     {", "notDeletedEligibleItems . addAll ( subResult . getNotDeletedEligibleItems (  )  )  ;", "}", "} else    {", "allDescendentsDeleted    =    false ;", "notDeletedEligibleItems . add ( fileStatus . getPath (  )  . toString (  )  )  ;", "}", "}", "if    ( allDescendentsDeleted    &  &    deleteEmptyDirectories )     {", "verify ( notDeletedEligibleItems . build (  )  . isEmpty (  )  )  ;", "if    (  !  (  . deleteIfExists ( fileSystem ,    directory ,    false )  )  )     {", "return   new    . RecursiveDeleteResult ( false ,    ImmutableList . of (  (  ( directory . toString (  )  )     +     \"  /  \"  )  )  )  ;", "}", "return   new    . RecursiveDeleteResult ( true ,    ImmutableList . of (  )  )  ;", "}", "return   new    . RecursiveDeleteResult ( false ,    notDeletedEligibleItems . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["doRecursiveDeleteFiles"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . dropColumn ( databaseName ,    tableName ,    columnName )  )  ;", "}", "METHOD_END"], "methodName": ["dropColumn"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . dropDatabase ( schemaName )  )  ;", "}", "METHOD_END"], "methodName": ["dropDatabase"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setShared (  )  ;", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionsOfTable    =    partitionActions . computeIfAbsent ( new   SchemaTableName ( databaseName ,    tableName )  ,     (    k )     -  >    new   HashMap <  >  (  )  )  ;", ". Action <  . PartitionAndMore >    oldPartitionAction    =    partitionActionsOfTable . get ( partitionValues )  ;", "if    ( oldPartitionAction    =  =    null )     {", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    databaseName ,    tableName )  ;", "partitionActionsOfTable . put ( partitionValues ,    new    . Action <  >  (  . ActionType . DROP ,    null ,    context )  )  ;", "return ;", "}", "switch    ( oldPartitionAction . getType (  )  )     {", "case   DROP    :", "throw   new   PartitionNotFoundException ( new   SchemaTableName ( databaseName ,    tableName )  ,    partitionValues )  ;", "case   ADD    :", "case   ALTER    :", "case   INSERT _ EXISTING    :", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,    String . format (  \" dropping   a   partition   added   in   the   same   transaction   is   not   supported :     % s    % s    % s \"  ,    databaseName ,    tableName ,    partitionValues )  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["dropPartition"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setShared (  )  ;", "checkNoPartitionAction ( databaseName ,    tableName )  ;", "SchemaTableName   schemaTableName    =    new   SchemaTableName ( databaseName ,    tableName )  ;", ". Action <  . TableAndMore >    oldTableAction    =    tableActions . get ( schemaTableName )  ;", "if    (  ( oldTableAction    =  =    null )     |  |     (  ( oldTableAction . getType (  )  )     =  =     (  . ActionType . ALTER )  )  )     {", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    databaseName ,    tableName )  ;", "tableActions . put ( schemaTableName ,    new    . Action (  . ActionType . DROP ,    null ,    context )  )  ;", "return ;", "}", "switch    ( oldTableAction . getType (  )  )     {", "case   DROP    :", "throw   new   com . facebook . presto . spi . TableNotFoundException ( schemaTableName )  ;", "case   ADD    :", "case   ALTER    :", "case   INSERT _ EXISTING    :", "throw   new   UnsupportedOperationException (  \" dropping   a   table   added / modified   in   the   same   transaction   is   not   supported \"  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["dropTable"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setShared (  )  ;", "SchemaTableName   schemaTableName    =    new   SchemaTableName ( databaseName ,    tableName )  ;", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionsOfTable    =    partitionActions . computeIfAbsent ( schemaTableName ,     (    k )     -  >    new   HashMap <  >  (  )  )  ;", ". Action <  . PartitionAndMore >    oldPartitionAction    =    partitionActionsOfTable . get ( partitionValues )  ;", "if    ( oldPartitionAction    =  =    null )     {", "Optional < Partition >    partition    =    delegate . getPartition ( databaseName ,    tableName ,    partitionValues )  ;", "if    (  !  ( partition . isPresent (  )  )  )     {", "throw   new   PartitionNotFoundException ( schemaTableName ,    partitionValues )  ;", "}", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    databaseName ,    tableName )  ;", "partitionActionsOfTable . put ( partitionValues ,    new    . Action (  . ActionType . INSERT _ EXISTING ,    new    . PartitionAndMore ( partition . get (  )  ,    currentLocation ,    Optional . of ( fileNames )  )  ,    context )  )  ;", "return ;", "}", "switch    ( oldPartitionAction . getType (  )  )     {", "case   DROP    :", "throw   new   PartitionNotFoundException ( schemaTableName ,    partitionValues )  ;", "case   ADD    :", "case   ALTER    :", "case   INSERT _ EXISTING    :", "throw   new   UnsupportedOperationException (  \" Inserting   into   a   partition   that   were   added ,    altered ,    or   inserted   into   in   the   same   transaction   is   not   supported \"  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["finishInsertIntoExistingPartition"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setShared (  )  ;", "SchemaTableName   schemaTableName    =    new   SchemaTableName ( databaseName ,    tableName )  ;", ". Action <  . TableAndMore >    oldTableAction    =    tableActions . get ( schemaTableName )  ;", "if    ( oldTableAction    =  =    null )     {", "Optional < Table >    table    =    delegate . getTable ( databaseName ,    tableName )  ;", "if    (  !  ( table . isPresent (  )  )  )     {", "throw   new   com . facebook . presto . spi . TableNotFoundException ( schemaTableName )  ;", "}", "HdfsEnvironment . HdfsContext   context    =    new   HdfsEnvironment . HdfsContext ( session ,    databaseName ,    tableName )  ;", "tableActions . put ( schemaTableName ,    new    . Action (  . ActionType . INSERT _ EXISTING ,    new    . TableAndMore ( table . get (  )  ,    Optional . empty (  )  ,    Optional . of ( currentLocation )  ,    Optional . of ( fileNames )  ,    false )  ,    context )  )  ;", "return ;", "}", "switch    ( oldTableAction . getType (  )  )     {", "case   DROP    :", "throw   new   com . facebook . presto . spi . TableNotFoundException ( schemaTableName )  ;", "case   ADD    :", "case   ALTER    :", "case   INSERT _ EXISTING    :", "throw   new   UnsupportedOperationException (  \" Inserting   into   an   unpartitioned   table   that   were   added ,    altered ,    or   inserted   into   in   the   same   transaction   is   not   supported \"  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["finishInsertIntoExistingTable"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", "Optional < Table >    table    =    getTable ( schemaTableName . getSchemaName (  )  ,    schemaTableName . getTableName (  )  )  ;", "if    (  !  ( table . isPresent (  )  )  )     {", "return   new   HivePageSinkMetadata ( schemaTableName ,    Optional . empty (  )  ,    ImmutableMap . of (  )  )  ;", "}", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionMap    =    partitionActions . get ( schemaTableName )  ;", "Map < List < String >  ,    Optional < Partition >  >    modifiedPartitionMap ;", "if    ( partitionActionMap    =  =    null )     {", "modifiedPartitionMap    =    ImmutableMap . of (  )  ;", "} else    {", "Builder < List < String >  ,    Optional < Partition >  >    modifiedPartitionMapBuilder    =    ImmutableMap . builder (  )  ;", "for    ( Map . Entry < List < String >  ,     . Action <  . PartitionAndMore >  >    entry    :    partitionActionMap . entrySet (  )  )     {", "modifiedPartitionMapBuilder . put ( entry . getKey (  )  ,     . getPartitionFromPartitionAction ( entry . getValue (  )  )  )  ;", "}", "modifiedPartitionMap    =    modifiedPartitionMapBuilder . build (  )  ;", "}", "return   new   HivePageSinkMetadata ( schemaTableName ,    table ,    modifiedPartitionMap )  ;", "}", "METHOD_END"], "methodName": ["generatePageSinkMetadata"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", "turn   delegate . getAllDatabases (  )  ;", "}", "METHOD_END"], "methodName": ["getAllDatabases"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", "if    (  !  ( tableActions . isEmpty (  )  )  )     {", "throw   new   UnsupportedOperationException (  \" Listing   all   tables   after   adding / dropping / altering   tables / views   in   a   t   is   not   supported \"  )  ;", "}", "return   delegate . getAllTables ( databaseName )  ;", "}", "METHOD_END"], "methodName": ["getAllTables"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", "if    (  !  ( tableActions . isEmpty (  )  )  )     {", "throw   new   UnsupportedOperationException (  \" Listing   all   tables   after   adding / dropping / altering   tables / views   in   a   t   is   not   supported \"  )  ;", "}", "return   delegate . getAllViews ( databaseName )  ;", "}", "METHOD_END"], "methodName": ["getAllViews"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", "turn   delegate . getDatabase ( databaseName )  ;", "}", "METHOD_END"], "methodName": ["getDatabase"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", "turn   delegate . getDatabasePrivileges ( user ,    databaseName )  ;", "}", "METHOD_END"], "methodName": ["getDatabasePrivileges"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", ". TableSource   tableSource    =    getTableSource ( databaseName ,    tableName )  ;", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionsOfTable    =    partitionActions . computeIfAbsent ( new   SchemaTableName ( databaseName ,    tableName )  ,     (    k )     -  >    new   HashMap <  >  (  )  )  ;", ". Action <  . PartitionAndMore >    partitionAction    =    partitionActionsOfTable . get ( partitionValues )  ;", "if    ( partitionAction    !  =    null )     {", "return    . getPartitionFromPartitionAction ( partitionAction )  ;", "}", "switch    ( tableSource )     {", "case   PRE _ EXISTING _ TABLE    :", "return   delegate . getPartition ( databaseName ,    tableName ,    partitionValues )  ;", "case   CREATED _ IN _ THIS _ TRANSACTION    :", "return   Optional . empty (  )  ;", "default    :", "throw   new   UnsupportedOperationException (  \" unknown   table   source \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["getPartition"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", "Optional < Table >    table    =    getTable ( databaseName ,    tableName )  ;", "if    (  !  ( table . isPresent (  )  )  )     {", "return   Optional . empty (  )  ;", "}", ". TableSource   tableSource    =    getTableSource ( databaseName ,    tableName )  ;", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionsOfTable    =    partitionActions . computeIfAbsent ( new   SchemaTableName ( databaseName ,    tableName )  ,     (    k )     -  >    new   HashMap <  >  (  )  )  ;", "ImmutableSet . Builder < String >    partitionNamesToQuery    =    ImmutableSet . builder (  )  ;", "Builder < String ,    Map < String ,    HiveColumnStatistics >  >    resultBuilder    =    ImmutableMap . builder (  )  ;", "for    ( String   partitionName    :    partitionNames )     {", "List < String >    partitionValues    =    HiveUtil . toPartitionValues ( partitionName )  ;", ". Action <  . PartitionAndMore >    partitionAction    =    partitionActionsOfTable . get ( partitionValues )  ;", "if    ( partitionAction    =  =    null )     {", "switch    ( tableSource )     {", "case   PRE _ EXISTING _ TABLE    :", "partitionNamesToQuery . add ( partitionName )  ;", "break ;", "case   CREATED _ IN _ THIS _ TRANSACTION    :", "resultBuilder . put ( partitionName ,    ImmutableMap . of (  )  )  ;", "break ;", "default    :", "throw   new   UnsupportedOperationException (  \" unknown   table   source \"  )  ;", "}", "} else    {", "resultBuilder . put ( partitionName ,    ImmutableMap . of (  )  )  ;", "}", "}", "Optional < Map < String ,    Map < String ,    HiveColumnStatistics >  >  >    delegateResult    =    delegate . getPartitionColumnStatistics ( databaseName ,    tableName ,    partitionNamesToQuery . build (  )  ,    columnNames )  ;", "if    ( delegateResult . isPresent (  )  )     {", "resultBuilder . putAll ( delegateResult . get (  )  )  ;", "} else    {", "partitionNamesToQuery . build (  )  . forEach (  (    partionName )     -  >    resultBuilder . put ( partionName ,    ImmutableMap . of (  )  )  )  ;", "}", "return   Optional . of ( resultBuilder . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "switch    ( partitionAction . getType (  )  )     {", "case   ADD    :", "case   ALTER    :", "case   INSERT _ EXISTING    :", "return   Optional . of ( partitionAction . getData (  )  . getAugmentedPartitionForInRead (  )  )  ;", "case   DROP    :", "return   Optional . empty (  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["getPartitionFromPartitionAction"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   doGetPartitionNames ( databaseName ,    tableName ,    Optional . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionNames"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   doGetPartitionNames ( databaseName ,    tableName ,    Optional . of ( parts )  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionNamesByParts"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", ". TableSource   tableSource    =    getTableSource ( databaseName ,    tableName )  ;", "Map < List < String >  ,     . Action <  . PartitionAndMore >  >    partitionActionsOfTable    =    partitionActions . computeIfAbsent ( new   SchemaTableName ( databaseName ,    tableName )  ,     (    k )     -  >    new   HashMap <  >  (  )  )  ;", "ImmutableList . Builder < String >    partitionNamesToQuery    =    ImmutableList . builder (  )  ;", "Builder < String ,    Optional < Partition >  >    resultBuilder    =    ImmutableMap . builder (  )  ;", "for    ( String   partitionName    :    partitionNames )     {", "List < String >    partitionValues    =    HiveUtil . toPartitionValues ( partitionName )  ;", ". Action <  . PartitionAndMore >    partitionAction    =    partitionActionsOfTable . get ( partitionValues )  ;", "if    ( partitionAction    =  =    null )     {", "switch    ( tableSource )     {", "case   PRE _ EXISTING _ TABLE    :", "partitionNamesToQuery . add ( partitionName )  ;", "break ;", "case   CREATED _ IN _ THIS _ TRANSACTION    :", "resultBuilder . put ( partitionName ,    Optional . empty (  )  )  ;", "break ;", "default    :", "throw   new   UnsupportedOperationException (  \" unknown   table   source \"  )  ;", "}", "} else    {", "resultBuilder . put ( partitionName ,     . getPartitionFromPartitionAction ( partitionAction )  )  ;", "}", "}", "Map < String ,    Optional < Partition >  >    delegateResult    =    delegate . getPartitionsByNames ( databaseName ,    tableName ,    partitionNamesToQuery . build (  )  )  ;", "resultBuilder . putAll ( delegateResult )  ;", "return   resultBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionsByNames"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   Optional . ofNullable ( partition . getParameters (  )  . get ( HiveMetadata . PRESTO _ QUERY _ ID _ NAME )  )  ;", "}", "METHOD_END"], "methodName": ["getPrestoQueryId"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   Optional . ofNullable ( table . getParameters (  )  . get ( HiveMetadata . PRESTO _ QUERY _ ID _ NAME )  )  ;", "}", "METHOD_END"], "methodName": ["getPrestoQueryId"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", "turn   delegate . getRoles ( user )  ;", "}", "METHOD_END"], "methodName": ["getRoles"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", ". Action <  . TableAndMore >    tableAction    =    tableActions . get ( new   SchemaTableName ( databaseName ,    tableName )  )  ;", "if    ( tableAction    =  =    null )     {", "return   delegate . getTable ( databaseName ,    tableName )  ;", "}", "switch    ( tableAction . getType (  )  )     {", "case   ADD    :", "case   ALTER    :", "case   INSERT _ EXISTING    :", "return   Optional . of ( tableAction . getData (  )  . getTable (  )  )  ;", "case   DROP    :", "return   Optional . empty (  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["getTable"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", ". Action <  . TableAndMore >    tableAction    =    tableActions . get ( new   SchemaTableName ( databaseName ,    tableName )  )  ;", "if    ( tableAction    =  =    null )     {", "return   delegate . getTableColumnStatistics ( databaseName ,    tableName ,    columnNames )  ;", "}", "switch    ( tableAction . getType (  )  )     {", "case   ADD    :", "case   ALTER    :", "case   INSERT _ EXISTING    :", "case   DROP    :", "return   Optional . empty (  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["getTableColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkReadable (  )  ;", "SchemaTableName   schemaTableName    =    new   SchemaTableName ( databaseName ,    tableName )  ;", ". Action <  . TableAndMore >    tableAction    =    tableActions . get ( schemaTableName )  ;", "if    ( tableAction    =  =    null )     {", "return   delegate . getTablePrivileges ( user ,    databaseName ,    tableName )  ;", "}", "switch    ( tableAction . getType (  )  )     {", "case   ADD    :", "case   ALTER    :", "{", "if    (  !  ( user . equals ( tableAction . getData (  )  . getTable (  )  . getOwner (  )  )  )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Cannot   access   a   table   newly   created   in   the   transaction   with   a   different   user \"  )  ;", "}", "Collection < HivePrivilegeInfo >    privileges    =    tableAction . getData (  )  . getPrincipalPrivileges (  )  . getUserPrivileges (  )  . get ( user )  ;", "return   ImmutableSet .  < HivePrivilegeInfo > builder (  )  . addAll ( privileges )  . add ( new   HivePrivilegeInfo ( HivePrivilegeInfo . HivePrivilege . OWNERSHIP ,    true )  )  . build (  )  ;", "}", "case   INSERT _ EXISTING    :", "return   delegate . getTablePrivileges ( user ,    databaseName ,    tableName )  ;", "case   DROP    :", "throw   new   com . facebook . presto . spi . TableNotFoundException ( schemaTableName )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["getTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkHoldsLock (  )  ;", "checkReadable (  )  ;", ". Action <  . TableAndMore >    tableAction    =    tableActions . get ( new   SchemaTableName ( databaseName ,    tableName )  )  ;", "if    ( tableAction    =  =    null )     {", "return    . TableSource . PRE _ EXISTING _ TABLE ;", "}", "switch    ( tableAction . getType (  )  )     {", "case   ADD    :", "return    . TableSource . CREATED _ IN _ THIS _ TRANSACTION ;", "case   ALTER    :", "throw   new   IllegalStateException (  \" Tables   are   never   altered   in   the   current   implementation \"  )  ;", "case   DROP    :", "throw   new   com . facebook . presto . spi . TableNotFoundException ( new   SchemaTableName ( databaseName ,    tableName )  )  ;", "case   INSERT _ EXISTING    :", "return    . TableSource . PRE _ EXISTING _ TABLE ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   action   type \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["getTableSource"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . grantTablePrivileges ( databaseName ,    tableName ,    grantee ,    privileges )  )  ;", "}", "METHOD_END"], "methodName": ["grantTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "int   parentDepth    =    parent . depth (  )  ;", "int   childDepth    =    child . depth (  )  ;", "if    ( parentDepth    >    childDepth )     {", "return   false ;", "}", "for    ( int   i    =    childDepth ;    i    >    parentDepth ;    i -  -  )     {", "child    =    child . getParent (  )  ;", "}", "return   parent . equals ( child )  ;", "}", "METHOD_END"], "methodName": ["isSameOrParent"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( throwOnCleanupFailure )     {", "throw   new   RuntimeException ( String . format ( format ,    args )  )  ;", "}", ". log . warn ( format ,    args )  ;", "}", "METHOD_END"], "methodName": ["logCleanupFailure"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( throwOnCleanupFailure )     {", "throw   new   RuntimeException ( String . format ( format ,    args )  ,    t )  ;", "}", ". log . warn ( t ,    format ,    args )  ;", "}", "METHOD_END"], "methodName": ["logCleanupFailure"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( values . size (  )  )     =  =     ( pattern . size (  )  )  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( values . size (  )  )  ;    i +  +  )     {", "if    ( pattern . get ( i )  . isEmpty (  )  )     {", "continue ;", "}", "if    ( values . get ( i )  . equals ( pattern . get ( i )  )  )     {", "return   false ;", "}", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["partitionValuesMatch"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "FileSystem   fileSystem ;", "try    {", "fileSystem    =    hdfsEnvironment . getFileSystem ( context ,    directory )  ;", "if    (  !  ( fileSystem . exists ( directory )  )  )     {", "return   new    . RecursiveDeleteResult ( true ,    ImmutableList . of (  )  )  ;", "}", "}    catch    ( IOException   e )     {", "ImmutableList . Builder < String >    notDeletedItems    =    ImmutableList . builder (  )  ;", "notDeletedItems . add (  (  ( directory . toString (  )  )     +     \"  /  *  *  \"  )  )  ;", "return   new    . RecursiveDeleteResult ( false ,    notDeletedItems . build (  )  )  ;", "}", "return    . doRecursiveDeleteFiles ( fileSystem ,    directory ,    filePrefixes ,    deleteEmptyDirectories )  ;", "}", "METHOD_END"], "methodName": ["recursiveDeleteFiles"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "SemiTransactionalHiveMetastore . RecursiveDeleteResult   recursiveDeleteResult    =    SemiTransactionalHiveMetastore . recursiveDeleteFiles ( hdfsEnvironment ,    context ,    directory ,    filePrefixes ,    deleteEmptyDirectories )  ;", "if    (  !  ( recursiveDeleteResult . getNotDeletedEligibleItems (  )  . isEmpty (  )  )  )     {", "logCleanupFailure (  \" Error   deleting   directory    % s   for    % s .    Some   eligible   items   can   not   be   deleted :     % s .  \"  ,    directory . toString (  )  ,    reason ,    recursiveDeleteResult . getNotDeletedEligibleItems (  )  )  ;", "} else", "if    ( deleteEmptyDirectories    &  &     (  !  ( recursiveDeleteResult . isDirectoryNoLongerExists (  )  )  )  )     {", "logCleanupFailure (  \" Error   deleting   directory    % s   for    % s .    Can   not   delete   the   directory .  \"  ,    directory . toString (  )  ,    reason )  ;", "}", "}", "METHOD_END"], "methodName": ["recursiveDeleteFilesAndLog"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . renameColumn ( databaseName ,    tableName ,    oldColumnName ,    newColumnName )  )  ;", "}", "METHOD_END"], "methodName": ["renameColumn"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . renameDatabase ( source ,    target )  )  ;", "}", "METHOD_END"], "methodName": ["renameDatabase"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( HiveWriteUtils . pathExists ( context ,    hdfsEnvironment ,    target )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ PATH _ ALREADY _ EXISTS ,    String . format (  \" Unable   to   rename   from    % s   to    % s :    target   directory   already   exists \"  ,    source ,    target )  )  ;", "}", "if    (  !  ( HiveWriteUtils . pathExists ( context ,    hdfsEnvironment ,    target . getParent (  )  )  )  )     {", "HiveWriteUtils . createDirectory ( context ,    hdfsEnvironment ,    target . getParent (  )  )  ;", "}", "runWhenPathDoesntExist . run (  )  ;", "try    {", "if    (  !  ( hdfsEnvironment . getFileSystem ( context ,    source )  . rename ( source ,    target )  )  )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,    String . format (  \" Failed   to   rename    % s   to    % s :    rename   returned   false \"  ,    source ,    target )  )  ;", "}", "}    catch    ( IOException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,    String . format (  \" Failed   to   rename    % s   to    % s \"  ,    source ,    target )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["renameDirectory"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . renameTable ( databaseName ,    tableName ,    newDatabaseName ,    newTableName )  )  ;", "}", "METHOD_END"], "methodName": ["renameTable"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . replaceTable ( databaseName ,    tableName ,    table ,    principalPrivileges )  )  ;", "}", "METHOD_END"], "methodName": ["replaceView"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "setExclusive (  (    delegate ,    hdfsEnvironment )     -  >    delegate . revokeTablePrivileges ( databaseName ,    tableName ,    grantee ,    privileges )  )  ;", "}", "METHOD_END"], "methodName": ["revokeTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "switch    ( state )     {", "case   EMPTY    :", "case   EXCLUSIVE _ OPERATION _ BUFFERED    :", "break ;", "case   SHARED _ OPERATION _ BUFFERED    :", "rollbackShared (  )  ;", "break ;", "case   FINISHED    :", "throw   new   IllegalStateException (  \" Tried   to   rollback   buffered   metastore   operations   after   transaction   has   been   committed / aborted \"  )  ;", "default    :", "throw   new   IllegalStateException (  \" Unknown   state \"  )  ;", "}", "}    finally    {", "state    =     . State . FINISHED ;", "}", "}", "METHOD_END"], "methodName": ["rollback"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkHoldsLock (  )  ;", "for    (  . DeclaredIntentionToWrite   declaredIntentionToWrite    :    declaredIntentionsToWrite )     {", "switch    ( declaredIntentionToWrite . getMode (  )  )     {", "case   STAGE _ AND _ MOVE _ TO _ TARGET _ DIRECTORY    :", "case   DIRECT _ TO _ TARGET _ NEW _ DIRECTORY    :", "{", "Path   rootPath    =    declaredIntentionToWrite . getRootPath (  )  ;", "recursiveDeleteFilesAndLog ( declaredIntentionToWrite . getContext (  )  ,    rootPath ,    ImmutableList . of ( declaredIntentionToWrite . getFilePrefix (  )  )  ,    true ,    String . format (  \" staging / target _ new   directory   rollback   for   table    % s \"  ,    declaredIntentionToWrite . getSchemaTableName (  )  )  )  ;", "break ;", "}", "case   DIRECT _ TO _ TARGET _ EXISTING _ DIRECTORY    :", "{", "Set < Path >    pathsToClean    =    new   HashSet <  >  (  )  ;", "Path   baseDirectory    =    declaredIntentionToWrite . getRootPath (  )  ;", "pathsToClean . add ( baseDirectory )  ;", "SchemaTableName   schemaTableName    =    declaredIntentionToWrite . getSchemaTableName (  )  ;", "Optional < Table >    table    =    delegate . getTable ( schemaTableName . getSchemaName (  )  ,    schemaTableName . getTableName (  )  )  ;", "if    ( table . isPresent (  )  )     {", "if    (  !  ( table . get (  )  . getPartitionColumns (  )  . isEmpty (  )  )  )     {", "List < String >    partitionNames    =    delegate . getPartitionNames ( schemaTableName . getSchemaName (  )  ,    schemaTableName . getTableName (  )  )  . orElse ( ImmutableList . of (  )  )  ;", "for    ( List < String >    partitionNameBatch    :    Iterables . partition ( partitionNames ,     1  0  )  )     {", "Collection < Optional < Partition >  >    partitions    =    delegate . getPartitionsByNames ( schemaTableName . getSchemaName (  )  ,    schemaTableName . getTableName (  )  ,    partitionNameBatch )  . values (  )  ;", "partitions . stream (  )  . filter ( Optional :  : isPresent )  . map ( Optional :  : get )  . map (  (    partition )     -  >    partition . getStorage (  )  . getLocation (  )  )  . map ( Path :  : new )  . filter (  (    path )     -  >     !  ( isSameOrParent ( baseDirectory ,    path )  )  )  . forEach ( pathsToClean :  : add )  ;", "}", "}", "} else    {", "logCleanupFailure (  \" Error   rolling   back   write   to   table    % s .  % s .    Data   directory   may   contain   temporary   data .    Table   was   dropped   in   another   transaction .  \"  ,    schemaTableName . getSchemaName (  )  ,    schemaTableName . getTableName (  )  )  ;", "}", "for    ( Path   path    :    pathsToClean )     {", "recursiveDeleteFilesAndLog ( declaredIntentionToWrite . getContext (  )  ,    path ,    ImmutableList . of ( declaredIntentionToWrite . getFilePrefix (  )  )  ,    false ,    String . format (  \" target _ existing   directory   rollback   for   table    % s \"  ,    schemaTableName )  )  ;", "}", "break ;", "}", "default    :", "throw   new   UnsupportedOperationException (  \" Unknown   write   mode \"  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["rollbackShared"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkHoldsLock (  )  ;", "if    (  ( state )     !  =     (  . State . EMPTY )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ,     \" Unsupported   combination   of   operations   in   a   single   transaction \"  )  ;", "}", "state    =     . State . EXCLUSIVE _ OPERATION _ BUFFERED ;", "bufferedExclusiveOperation    =    exclusiveOperation ;", "}", "METHOD_END"], "methodName": ["setExclusive"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkHoldsLock (  )  ;", "checkReadable (  )  ;", "state    =     . State . SHARED _ OPERATION _ BUFFERED ;", "}", "METHOD_END"], "methodName": ["setShared"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    (  ( state )     !  =     ( SemiTransactionalHiveMetastore . State . EMPTY )  )     {", "throw   new   AssertionError (  \" Test   did   not   commit   or   rollback \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testOnlyCheckIsReadOnly"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "throwOnCleanupFailure    =    true ;", "}", "METHOD_END"], "methodName": ["testOnlyThrowOnCleanupFailures"], "fileName": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   new   Storage . Builder (  )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.Storage"}, {"methodBody": ["METHOD_START", "{", "return   new   Storage . Builder ( storage )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.Storage"}, {"methodBody": ["METHOD_START", "{", "return   bucketProperty ;", "}", "METHOD_END"], "methodName": ["getBucketProperty"], "fileName": "com.facebook.presto.hive.metastore.Storage"}, {"methodBody": ["METHOD_START", "{", "return   location ;", "}", "METHOD_END"], "methodName": ["getLocation"], "fileName": "com.facebook.presto.hive.metastore.Storage"}, {"methodBody": ["METHOD_START", "{", "return   serdeParameters ;", "}", "METHOD_END"], "methodName": ["getSerdeParameters"], "fileName": "com.facebook.presto.hive.metastore.Storage"}, {"methodBody": ["METHOD_START", "{", "return   storageFormat ;", "}", "METHOD_END"], "methodName": ["getStorageFormat"], "fileName": "com.facebook.presto.hive.metastore.Storage"}, {"methodBody": ["METHOD_START", "{", "return   skewed ;", "}", "METHOD_END"], "methodName": ["isSkewed"], "fileName": "com.facebook.presto.hive.metastore.Storage"}, {"methodBody": ["METHOD_START", "{", "return   sorted ;", "}", "METHOD_END"], "methodName": ["isSorted"], "fileName": "com.facebook.presto.hive.metastore.Storage"}, {"methodBody": ["METHOD_START", "{", "return   new   StorageFormat ( Objects . requireNonNull ( serde ,     \" serDe   is   null \"  )  ,    Objects . requireNonNull ( inputFormat ,     \" inputFormat   is   null \"  )  ,    Objects . requireNonNull ( outputFormat ,     \" outputFormat   is   null \"  )  )  ;", "}", "METHOD_END"], "methodName": ["create"], "fileName": "com.facebook.presto.hive.metastore.StorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   new   StorageFormat ( serDe ,    inputFormat ,    outputFormat )  ;", "}", "METHOD_END"], "methodName": ["createNullable"], "fileName": "com.facebook.presto.hive.metastore.StorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   new   StorageFormat ( hiveStorageFormat . getSerDe (  )  ,    hiveStorageFormat . getInputFormat (  )  ,    hiveStorageFormat . getOutputFormat (  )  )  ;", "}", "METHOD_END"], "methodName": ["fromHiveStorageFormat"], "fileName": "com.facebook.presto.hive.metastore.StorageFormat"}, {"methodBody": ["METHOD_START", "{", "if    (  ( inputFormat )     =  =    null )     {", "throw   new   IllegalStateException (  \" inputFormat   should   not   be   accessed   from   a   null    \"  )  ;", "}", "return   inputFormat ;", "}", "METHOD_END"], "methodName": ["getInputFormat"], "fileName": "com.facebook.presto.hive.metastore.StorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   inputFormat ;", "}", "METHOD_END"], "methodName": ["getInputFormatNullable"], "fileName": "com.facebook.presto.hive.metastore.StorageFormat"}, {"methodBody": ["METHOD_START", "{", "if    (  ( outputFormat )     =  =    null )     {", "throw   new   IllegalStateException (  \" outputFormat   should   not   be   accessed   from   a   null    \"  )  ;", "}", "return   outputFormat ;", "}", "METHOD_END"], "methodName": ["getOutputFormat"], "fileName": "com.facebook.presto.hive.metastore.StorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   outputFormat ;", "}", "METHOD_END"], "methodName": ["getOutputFormatNullable"], "fileName": "com.facebook.presto.hive.metastore.StorageFormat"}, {"methodBody": ["METHOD_START", "{", "if    (  ( serDe )     =  =    null )     {", "throw   new   IllegalStateException (  \" serDe   should   not   be   accessed   from   a   null    \"  )  ;", "}", "return   serDe ;", "}", "METHOD_END"], "methodName": ["getSerDe"], "fileName": "com.facebook.presto.hive.metastore.StorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   serDe ;", "}", "METHOD_END"], "methodName": ["getSerDeNullable"], "fileName": "com.facebook.presto.hive.metastore.StorageFormat"}, {"methodBody": ["METHOD_START", "{", "return   new   Table . Builder (  )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   new   Table . Builder ( table )  ;", "}", "METHOD_END"], "methodName": ["builder"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   Stream . concat ( partitionColumns . stream (  )  ,    dataColumns . stream (  )  )  . filter (  (    column )     -  >    column . getName (  )  . equals ( name )  )  . findFirst (  )  ;", "}", "METHOD_END"], "methodName": ["getColumn"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   dataColumns ;", "}", "METHOD_END"], "methodName": ["getDataColumns"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   databaseName ;", "}", "METHOD_END"], "methodName": ["getDatabaseName"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   owner ;", "}", "METHOD_END"], "methodName": ["getOwner"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   parameters ;", "}", "METHOD_END"], "methodName": ["getParameters"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   partitionColumns ;", "}", "METHOD_END"], "methodName": ["getPartitionColumns"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   storage ;", "}", "METHOD_END"], "methodName": ["getStorage"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   tableName ;", "}", "METHOD_END"], "methodName": ["getTableName"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   tableType ;", "}", "METHOD_END"], "methodName": ["getTableType"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   viewExpandedText ;", "}", "METHOD_END"], "methodName": ["getViewExpandedText"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "return   viewOriginalText ;", "}", "METHOD_END"], "methodName": ["getViewOriginalText"], "fileName": "com.facebook.presto.hive.metastore.Table"}, {"methodBody": ["METHOD_START", "{", "mockClient    =    new   MockHiveMetastoreClient (  )  ;", ". MockHiveCluster   mockHiveCluster    =    new    . MockHiveCluster ( mockClient )  ;", "ListeningExecutorService   executor    =    listeningDecorator ( Executors . newCachedThreadPool ( Threads . daemonThreadsNamed (  \" test -  % s \"  )  )  )  ;", "ThriftHiveMetastore   thriftHiveMetastore    =    new   ThriftHiveMetastore ( mockHiveCluster )  ;", "metastore    =    new   CachingHiveMetastore ( new   BridgingHiveMetastore ( thriftHiveMetastore )  ,    executor ,    new   Duration (  5  ,    TimeUnit . MINUTES )  ,    new   Duration (  1  ,    TimeUnit . MINUTES )  ,     1  0  0  0  )  ;", "stats    =    thriftHiveMetastore . getStats (  )  ;", "}", "METHOD_END"], "methodName": ["setUp"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( mockClient . getAccessCount (  )  ,     0  )  ;", "assertEquals ( metastore . getAllDatabases (  )  ,    ImmutableList . of ( MockClient . TEST _ DATABASE )  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "assertEquals ( metastore . getAllDatabases (  )  ,    ImmutableList . of ( MockClient . TEST _ DATABASE )  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "metastore . flushCache (  )  ;", "assertEquals ( metastore . getAllDatabases (  )  ,    ImmutableList . of ( MockClient . TEST _ DATABASE )  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     2  )  ;", "}", "METHOD_END"], "methodName": ["testGetAllDatabases"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( mockClient . getAccessCount (  )  ,     0  )  ;", "assertEquals ( metastore . getAllTables ( MockClient . TEST _ DATABASE )  . get (  )  ,    ImmutableList . of ( MockClient . TEST _ TABLE )  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "assertEquals ( metastore . getAllTables ( MockClient . TEST _ DATABASE )  . get (  )  ,    ImmutableList . of ( MockClient . TEST _ TABLE )  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "metastore . flushCache (  )  ;", "assertEquals ( metastore . getAllTables ( MockClient . TEST _ DATABASE )  . get (  )  ,    ImmutableList . of ( MockClient . TEST _ TABLE )  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     2  )  ;", "}", "METHOD_END"], "methodName": ["testGetAllTable"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "ImmutableList < String >    expectedPartitions    =    ImmutableList . of ( MockHiveMetastoreClient . TEST _ PARTITION 1  ,    MockHiveMetastoreClient . TEST _ PARTITION 2  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     0  )  ;", "assertEquals ( metastore . getPartitionNames ( MockHiveMetastoreClient . TEST _ DATABASE ,    MockHiveMetastoreClient . TEST _ TABLE )  . get (  )  ,    expectedPartitions )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "assertEquals ( metastore . getPartitionNames ( MockHiveMetastoreClient . TEST _ DATABASE ,    MockHiveMetastoreClient . TEST _ TABLE )  . get (  )  ,    expectedPartitions )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "metastore . flushCache (  )  ;", "assertEquals ( metastore . getPartitionNames ( MockHiveMetastoreClient . TEST _ DATABASE ,    MockHiveMetastoreClient . TEST _ TABLE )  . get (  )  ,    expectedPartitions )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     2  )  ;", "}", "METHOD_END"], "methodName": ["testGetPartitionNames"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "ImmutableList < String >    parts    =    ImmutableList . of (  )  ;", "ImmutableList < String >    expectedPartitions    =    ImmutableList . of ( MockClient . TEST _ PARTITION 1  ,    MockClient . TEST _ PARTITION 2  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     0  )  ;", "assertEquals ( metastore . getPartitionNamesByParts ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE ,    parts )  . get (  )  ,    expectedPartitions )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "assertEquals ( metastore . getPartitionNamesByParts ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE ,    parts )  . get (  )  ,    expectedPartitions )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "metastore . flushCache (  )  ;", "assertEquals ( metastore . getPartitionNamesByParts ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE ,    parts )  . get (  )  ,    expectedPartitions )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     2  )  ;", "}", "METHOD_END"], "methodName": ["testGetPartitionNamesByParts"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( mockClient . getAccessCount (  )  ,     0  )  ;", "metastore . getTable ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "assertEquals ( metastore . getPartitionsByNames ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE ,    ImmutableList . of ( MockClient . TEST _ PARTITION 1  )  )  . size (  )  ,     1  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     2  )  ;", "assertEquals ( metastore . getPartitionsByNames ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE ,    ImmutableList . of ( MockClient . TEST _ PARTITION 1  ,    MockClient . TEST _ PARTITION 2  )  )  . size (  )  ,     2  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     3  )  ;", "assertEquals ( metastore . getPartitionsByNames ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE ,    ImmutableList . of ( MockClient . TEST _ PARTITION 1  )  )  . size (  )  ,     1  )  ;", "assertEquals ( metastore . getPartitionsByNames ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE ,    ImmutableList . of ( MockClient . TEST _ PARTITION 2  )  )  . size (  )  ,     1  )  ;", "assertEquals ( metastore . getPartitionsByNames ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE ,    ImmutableList . of ( MockClient . TEST _ PARTITION 1  ,    MockClient . TEST _ PARTITION 2  )  )  . size (  )  ,     2  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     3  )  ;", "metastore . flushCache (  )  ;", "assertEquals ( metastore . getPartitionsByNames ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE ,    ImmutableList . of ( MockClient . TEST _ PARTITION 1  ,    MockClient . TEST _ PARTITION 2  )  )  . size (  )  ,     2  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     4  )  ;", "}", "METHOD_END"], "methodName": ["testGetPartitionsByNames"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( mockClient . getAccessCount (  )  ,     0  )  ;", "assertNotNull ( metastore . getTable ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE )  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "assertNotNull ( metastore . getTable ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE )  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "metastore . flushCache (  )  ;", "assertNotNull ( metastore . getTable ( MockClient . TEST _ DATABASE ,    MockClient . TEST _ TABLE )  )  ;", "assertEquals ( mockClient . getAccessCount (  )  ,     2  )  ;", "}", "METHOD_END"], "methodName": ["testGetTable"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "assertFalse ( metastore . getAllTables ( MockHiveMetastoreClient . BAD _ DATABASE )  . isPresent (  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidDbGetAllTAbles"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "assertFalse ( metastore . getTable ( MockHiveMetastoreClient . BAD _ DATABASE ,    MockHiveMetastoreClient . TEST _ TABLE )  . isPresent (  )  )  ;", "assertEquals ( stats . getGetTable (  )  . getThriftExceptions (  )  . getTotalCount (  )  ,     0  )  ;", "assertEquals ( stats . getGetTable (  )  . getTotalFailures (  )  . getTotalCount (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidDbGetTable"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( metastore . getPartitionNames ( MockHiveMetastoreClient . BAD _ DATABASE ,    MockHiveMetastoreClient . TEST _ TABLE )  . get (  )  ,    ImmutableList . of (  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidGetPartitionNames"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "ImmutableList < String >    parts    =    ImmutableList . of (  )  ;", "assertFalse ( metastore . getPartitionNamesByParts ( MockClient . BAD _ DATABASE ,    MockClient . TEST _ TABLE ,    parts )  . isPresent (  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidGetPartitionNamesByParts"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Optional < Partition >  >    partitionsByNames    =    metastore . getPartitionsByNames ( MockHiveMetastoreClient . BAD _ DATABASE ,    MockHiveMetastoreClient . TEST _ TABLE ,    ImmutableList . of ( MockHiveMetastoreClient . TEST _ PARTITION 1  )  )  ;", "assertEquals ( partitionsByNames . size (  )  ,     1  )  ;", "Optional < Partition >    onlyElement    =    Iterables . getOnlyElement ( partitionsByNames . values (  )  )  ;", "assertFalse ( onlyElement . isPresent (  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidGetPartitionsByNames"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "mockClient . setThrowException ( true )  ;", "try    {", "getAllDatabases (  )  ;", "}    catch    ( RuntimeException   ignored )     {", "}", "assertEquals ( mockClient . getAccessCount (  )  ,     1  )  ;", "try    {", "getAllDatabases (  )  ;", "}    catch    ( RuntimeException   ignored )     {", "}", "assertEquals ( mockClient . getAccessCount (  )  ,     2  )  ;", "}", "METHOD_END"], "methodName": ["testNoCacheExceptions"], "fileName": "com.facebook.presto.hive.metastore.TestCachingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "assertRecordedDefaults ( recordDefaults ( MetastoreConfig . class )  . setMetastoreType (  \" thrift \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "com.facebook.presto.hive.metastore.TestMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . metastore \"  ,     \" foo \"  )  . build (  )  ;", "expected    =    new    (  )  . setMetastoreType (  \" foo \"  )  ;", "assertFullMapping ( properties ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMappings"], "fileName": "com.facebook.presto.hive.metastore.TestMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "Properties   expected    =    MetaStoreUtils . getPartitionMetadata ( TestMetastoreUtil . TEST _ PARTITION _ WITH _ UNSUPPORTED _ FIELDS ,    TestMetastoreUtil . TEST _ TABLE _ WITH _ UNSUPPORTED _ FIELDS )  ;", "Properties   actual    =    MetastoreUtil . getHiveSchema ( ThriftMetastoreUtil . fromMetastoreApiPartition ( TestMetastoreUtil . TEST _ PARTITION _ WITH _ UNSUPPORTED _ FIELDS )  ,    ThriftMetastoreUtil . fromMetastoreApiTable ( TestMetastoreUtil . TEST _ TABLE _ WITH _ UNSUPPORTED _ FIELDS )  )  ;", "assertEquals ( actual ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testHiveSchemaPartition"], "fileName": "com.facebook.presto.hive.metastore.TestMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Properties   expected    =    MetaStoreUtils . getTableMetadata ( TestMetastoreUtil . TEST _ TABLE _ WITH _ UNSUPPORTED _ FIELDS )  ;", "Properties   actual    =    MetastoreUtil . getHiveSchema ( ThriftMetastoreUtil . fromMetastoreApiTable ( TestMetastoreUtil . TEST _ TABLE _ WITH _ UNSUPPORTED _ FIELDS )  )  ;", "assertEquals ( actual ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testHiveSchemaTable"], "fileName": "com.facebook.presto.hive.metastore.TestMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Partition   partition    =    ThriftMetastoreUtil . fromMetastoreApiPartition ( TestMetastoreUtil . TEST _ PARTITION )  ;", "Partition   metastoreApiPartition    =    ThriftMetastoreUtil . toMetastoreApiPartition ( partition )  ;", "assertEquals ( metastoreApiPartition ,    TestMetastoreUtil . TEST _ PARTITION )  ;", "}", "METHOD_END"], "methodName": ["testPartitionRoundTrip"], "fileName": "com.facebook.presto.hive.metastore.TestMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Partition   partition    =    ThriftMetastoreUtil . fromMetastoreApiPartition ( TestMetastoreUtil . TEST _ PARTITION _ WITH _ UNSUPPORTED _ FIELDS )  ;", "ThriftMetastoreUtil . toMetastoreApiPartition ( partition )  ;", "}", "METHOD_END"], "methodName": ["testPartitionRoundTripUnsupported"], "fileName": "com.facebook.presto.hive.metastore.TestMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Table   table    =    ThriftMetastoreUtil . fromMetastoreApiTable ( TestMetastoreUtil . TEST _ TABLE )  ;", "PrincipalPrivileges   privileges    =    new   PrincipalPrivileges ( ImmutableMultimap . of (  )  ,    ImmutableMultimap . of (  )  )  ;", "Table   metastoreApiTable    =    ThriftMetastoreUtil . toMetastoreApiTable ( table ,    privileges )  ;", "assertEquals ( metastoreApiTable ,    TestMetastoreUtil . TEST _ TABLE )  ;", "}", "METHOD_END"], "methodName": ["testTableRoundTrip"], "fileName": "com.facebook.presto.hive.metastore.TestMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Table   table    =    ThriftMetastoreUtil . fromMetastoreApiTable ( TestMetastoreUtil . TEST _ TABLE _ WITH _ UNSUPPORTED _ FIELDS )  ;", "ThriftMetastoreUtil . toMetastoreApiTable ( table ,    null )  ;", "}", "METHOD_END"], "methodName": ["testTableRoundTripUnsupported"], "fileName": "com.facebook.presto.hive.metastore.TestMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "return   comment ;", "}", "METHOD_END"], "methodName": ["getComment"], "fileName": "com.facebook.presto.hive.metastore.file.DatabaseMetadata"}, {"methodBody": ["METHOD_START", "{", "return   ownerName ;", "}", "METHOD_END"], "methodName": ["getOwnerName"], "fileName": "com.facebook.presto.hive.metastore.file.DatabaseMetadata"}, {"methodBody": ["METHOD_START", "{", "return   ownerType ;", "}", "METHOD_END"], "methodName": ["getOwnerType"], "fileName": "com.facebook.presto.hive.metastore.file.DatabaseMetadata"}, {"methodBody": ["METHOD_START", "{", "return   parameters ;", "}", "METHOD_END"], "methodName": ["getParameters"], "fileName": "com.facebook.presto.hive.metastore.file.DatabaseMetadata"}, {"methodBody": ["METHOD_START", "{", "return   Database . builder (  )  . setDatabaseName ( databaseName )  . setLocation ( Optional . of ( location )  )  . setOwnerName ( ownerName )  . setOwnerType ( ownerType )  . setParameters ( parameters )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["toDatabase"], "fileName": "com.facebook.presto.hive.metastore.file.DatabaseMetadata"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( databaseName ,     \" databaseName   is   null \"  )  ;", "Objects . requireNonNull ( tableName ,     \" tableName   is   null \"  )  ;", "Path   tabldataDirectory    =    getTabldataDirectory ( databaseName ,    tableName )  ;", "Tabldata   oldTableSchema    =    readSchemaFile (  \" table \"  ,    tabldataDirectory ,    tableCodec )  . orElseThrow (  (  )     -  >    new   TableNotFoundException ( new   SchemaTableName ( databaseName ,    tableName )  )  )  ;", "Tabldata   newTableSchema    =    alterFunction . apply ( oldTableSchema )  ;", "if    ( oldTableSchema    =  =    newTableSchema )     {", "return ;", "}", "writeSchemaFile (  \" table \"  ,    tabldataDirectory ,    tableCodec ,    newTableSchema ,    true )  ;", "}", "METHOD_END"], "methodName": ["alterTable"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "Path   schemaPath    =    new   Path ( metadataDirectory ,     . PRESTO _ SCHEMA _ FILE _ NAME )  ;", "if    (  !  ( metadataFileSystem . isFile ( schemaPath )  )  )     {", "return ;", "}", "if    (  !  ( metadataFileSystem . delete ( metadataDirectory ,    true )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     \" Could   not   delete   metadata   directory \"  )  ;", "}", "}    catch    ( IOException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["deleteMetadataDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "if    (  !  ( metadataFileSystem . delete ( new   Path ( metadataDirectory ,     . PRESTO _ SCHEMA _ FILE _ NAME )  ,    false )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     (  (  \" Could   not   delete    \"     +    type )     +     \"    schema \"  )  )  ;", "}", "}    catch    ( IOException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     (  (  \" Could   not   delete    \"     +    type )     +     \"    schema \"  )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["deleteSchemaFile"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "Path   permissionsDirectory    =    getPermissionsDirectory ( table )  ;", "metadataFileSystem . delete ( permissionsDirectory ,    true )  ;", "}    catch    ( IOException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     \" Could   not   delete   table   permissions \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["deleteTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "if    (  !  ( metadataFileSystem . isDirectory ( metadataDirectory )  )  )     {", "return   ImmutableList . of (  )  ;", "}", "ImmutableList . Builder < Path >    childSchemaDirectories    =    ImmutableList . builder (  )  ;", "for    ( FileStatus   child    :    metadataFileSystem . listStatus ( metadataDirectory )  )     {", "if    (  !  ( child . isDirectory (  )  )  )     {", "continue ;", "}", "Path   childPath    =    child . getPath (  )  ;", "if    ( childPath . getName (  )  . startsWith (  \"  .  \"  )  )     {", "continue ;", "}", "if    ( metadataFileSystem . isFile ( new   Path ( childPath ,     . PRESTO _ SCHEMA _ FILE _ NAME )  )  )     {", "childSchemaDirectories . add ( childPath )  ;", "}", "}", "return   childSchemaDirectories . build (  )  ;", "}    catch    ( IOException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["getChildSchemaDirectories"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   new   Path ( catalogDirectory ,    databaseName )  ;", "}", "METHOD_END"], "methodName": ["getDatabaseMetadataDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Path   tableMetadataDirectory    =    getTableMetadataDirectory ( table )  ;", "return   new   Path ( tableMetadataDirectory ,    partitionName )  ;", "}", "METHOD_END"], "methodName": ["getPartitionMetadataDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "String   partitionName    =    MetastoreUtil . makePartName ( table . getPartitionColumns (  )  ,    values )  ;", "return   getPartitionMetadataDirectory ( table ,    partitionName )  ;", "}", "METHOD_END"], "methodName": ["getPartitionMetadataDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   new   Path ( getTableMetadataDirectory ( table )  ,    FileHiveMetastore . PRESTO _ PERMISSIONS _ DIRECTORY _ NAME )  ;", "}", "METHOD_END"], "methodName": ["getPermissionsDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   new   Path ( permissionsDirectory ,     (  (  ( principalType . name (  )  . toLowerCase ( Locale . US )  )     +     \"  _  \"  )     +    principalName )  )  ;", "}", "METHOD_END"], "methodName": ["getPermissionsPath"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   getDatabase ( databaseName )  . orElseThrow (  (  )     -  >    new   SchemaNotFoundException ( databaseName )  )  ;", "}", "METHOD_END"], "methodName": ["getRequiredDatabase"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   getTable ( databaseName ,    tableName )  . orElseThrow (  (  )     -  >    new   com . facebook . presto . spi . TableNotFoundException ( new   SchemaTableName ( databaseName ,    tableName )  )  )  ;", "}", "METHOD_END"], "methodName": ["getRequiredTable"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   getTableMetadataDirectory ( table . getDatabaseName (  )  ,    table . getTableName (  )  )  ;", "}", "METHOD_END"], "methodName": ["getTableMetadataDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   new   Path ( getDatabaseMetadataDirectory ( databaseName )  ,    tableName )  ;", "}", "METHOD_END"], "methodName": ["getTableMetadataDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Path   permissionFilePath    =    FileHiveMetastore . getPermissionsPath ( permissionsDirectory ,    principalName ,    principalType )  ;", "return   readFile (  \" permissions \"  ,    permissionFilePath ,    permissionsCodec )  . orElse ( ImmutableList . of (  )  )  . stream (  )  . map ( PermissionMetadata :  : toHivePrivilegeInfo )  . collect ( Collectors . toList (  )  )  ;", "}", "METHOD_END"], "methodName": ["getTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( parentDirectory . equals ( childDirectory )  )     {", "return   true ;", "}", "if    ( childDirectory . isRoot (  )  )     {", "return   false ;", "}", "return    . isChildDirectory ( parentDirectory ,    childDirectory . getParent (  )  )  ;", "}", "METHOD_END"], "methodName": ["isChildDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( Database . DEFAULT _ DATABASE _ NAME . equalsIgnoreCase ( databaseName )  )     {", "return   true ;", "}", "Optional < Database >    databasdata    =    getDatabase ( databaseName )  ;", "if    (  !  ( databasdata . isPresent (  )  )  )     {", "return   false ;", "}", "Database   database    =    databasdata . get (  )  ;", "if    (  (  ( database . getOwnerType (  )  )     =  =     ( PrincipalType . USER )  )     &  &     ( user . equals ( database . getOwnerName (  )  )  )  )     {", "return   true ;", "}", "if    (  (  ( database . getOwnerType (  )  )     =  =     ( PrincipalType . ROLE )  )     &  &     ( getRoles ( user )  . contains ( database . getOwnerName (  )  )  )  )     {", "return   true ;", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isDatabaseOwner"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( partitionColumns . isEmpty (  )  )     {", "return   ImmutableList . of (  )  ;", "}", "try    {", "String   directoryPrefix    =     ( partitionColumns . get (  0  )  . getName (  )  )     +     '  =  '  ;", "List < ArrayDeque < String >  >    partitionValues    =    new   ArrayList <  >  (  )  ;", "for    ( FileStatus   fileStatus    :    metadataFileSystem . listStatus ( director )  )     {", "if    (  !  ( fileStatus . isDirectory (  )  )  )     {", "continue ;", "}", "if    (  !  ( fileStatus . getPath (  )  . getName (  )  . startsWith ( directoryPrefix )  )  )     {", "continue ;", "}", "List < ArrayDeque < String >  >    childPartitionValues ;", "if    (  ( partitionColumns . size (  )  )     =  =     1  )     {", "childPartitionValues    =    ImmutableList . of ( new   ArrayDeque (  )  )  ;", "} else    {", "childPartitionValues    =    listPartitions ( fileStatus . getPath (  )  ,    partitionColumns . subList (  1  ,    partitionColumns . size (  )  )  )  ;", "}", "String   value    =    unescapePathName ( fileStatus . getPath (  )  . getName (  )  . substring ( directoryPrefix . length (  )  )  )  ;", "for    ( ArrayDeque < String >    childPartition    :    childPartitionValues )     {", "childPartition . addFirst ( value )  ;", "partitionValues . add ( childPartition )  ;", "}", "}", "return   partitionValues ;", "}    catch    ( IOException   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     \" Error   listing   partition   directories \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["listPartitions"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "List < String >    values    =    HiveUtil . toPartitionValues ( partitionName )  ;", "if    (  ( values . size (  )  )     !  =     ( parts . size (  )  )  )     {", "return   false ;", "}", "for    ( int   i    =     0  ;    i    <     ( values . size (  )  )  ;    i +  +  )     {", "String   part    =    parts . get ( i )  ;", "if    (  (  !  ( part . isEmpty (  )  )  )     &  &     (  !  ( values . get ( i )  . equals ( part )  )  )  )     {", "return   false ;", "}", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["partitionMatches"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "if    (  !  ( metadataFileSystem . isFile ( path )  )  )     {", "return   Optional . empty (  )  ;", "}", "try    ( FSDataInputStream   inputStream    =    metadataFileSystem . open ( path )  )     {", "byte [  ]    json    =    ByteStreams . toByteArray ( inputStream )  ;", "return   Optional . of ( codec . fromJson ( json )  )  ;", "}", "}    catch    ( Exception   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     (  \" Could   not   read    \"     +    type )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["readFile"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Path   schemaPath    =    new   Path ( metadataDirectory ,    FileHiveMetastore . PRESTO _ SCHEMA _ FILE _ NAME )  ;", "return   readFile (  ( type    +     \"    schema \"  )  ,    schemaPath ,    codec )  ;", "}", "METHOD_END"], "methodName": ["readSchemaFile"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( principalName ,     \" principalName   is   null \"  )  ;", "Objects . requireNonNull ( principalType ,     \" principalType   is   null \"  )  ;", "Objects . requireNonNull ( databaseName ,     \" databaseName   is   null \"  )  ;", "Objects . requireNonNull ( tableName ,     \" tableName   is   null \"  )  ;", "Objects . requireNonNull ( privileges ,     \" privileges   is   null \"  )  ;", "try    {", "Table   table    =    getRequiredTable ( databaseName ,    tableName )  ;", "Path   permissionsDirectory    =    getPermissionsDirectory ( table )  ;", "metadataFileSystem . mkdirs ( permissionsDirectory )  ;", "if    (  !  ( metadataFileSystem . isDirectory ( permissionsDirectory )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     \" Could   not   create   permissions   directory \"  )  ;", "}", "Path   permissionFilePath    =     . getPermissionsPath ( permissionsDirectory ,    principalName ,    principalType )  ;", "List < PermissionMetadata >    permissions    =    privileges . stream (  )  . map ( PermissionMetadata :  : new )  . collect ( Collectors . toList (  )  )  ;", "writeFile (  \" permissions \"  ,    permissionFilePath ,    permissionsCodec ,    permissions ,    true )  ;", "}    catch    ( IOException   e )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["setTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( getDatabase ( databaseName )  . isPresent (  )  )     {", "throw   new   SchemaAlreadyExistsException ( databaseName )  ;", "}", "}", "METHOD_END"], "methodName": ["verifyDatabaseNotExists"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( getTable ( newDatabaseName ,    newTableName )  . isPresent (  )  )     {", "throw   new   TableAlreadyExistsException ( new   SchemaTableName ( newDatabaseName ,    newTableName )  )  ;", "}", "}", "METHOD_END"], "methodName": ["verifyTableNotExists"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "byte [  ]    json    =    codec . toJsonBytes ( value )  ;", "if    (  ! overwrite )     {", "if    ( metadataFileSystem . exists ( path )  )     {", "throw   new   PException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     ( type    +     \"    file   already   exists \"  )  )  ;", "}", "}", "metadataFileSystem . mkdirs ( path . getParent (  )  )  ;", "try    ( OutputStream   outputStream    =    metadataFileSystem . create ( path ,    overwrite )  )     {", "outputStream . write ( json )  ;", "}", "}    catch    ( Exception   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     (  \" Could   not   write    \"     +    type )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["writeFile"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Path   schemaPath    =    new   Path ( directory ,    FileHiveMetastore . PRESTO _ SCHEMA _ FILE _ NAME )  ;", "writeFile (  ( type    +     \"    schema \"  )  ,    schemaPath ,    codec ,    value ,    overwrite )  ;", "}", "METHOD_END"], "methodName": ["writeSchemaFile"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   catalogDirectory ;", "}", "METHOD_END"], "methodName": ["getCatalogDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "return   metastoreUser ;", "}", "METHOD_END"], "methodName": ["getMetastoreUser"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "this . catalogDirectory    =    catalogDirectory ;", "}", "METHOD_END"], "methodName": ["setCatalogDirectory"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "this . metastoreUser    =    metastoreUser ;", "}", "METHOD_END"], "methodName": ["setMetastoreUser"], "fileName": "com.facebook.presto.hive.metastore.file.FileHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "return   bucketProperty ;", "}", "METHOD_END"], "methodName": ["getBucketProperty"], "fileName": "com.facebook.presto.hive.metastore.file.PartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   columns ;", "}", "METHOD_END"], "methodName": ["getColumns"], "fileName": "com.facebook.presto.hive.metastore.file.PartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   externalLocation ;", "}", "METHOD_END"], "methodName": ["getExternalLocation"], "fileName": "com.facebook.presto.hive.metastore.file.PartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   parameters ;", "}", "METHOD_END"], "methodName": ["getParameters"], "fileName": "com.facebook.presto.hive.metastore.file.PartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   serdeParameters ;", "}", "METHOD_END"], "methodName": ["getSerdeParameters"], "fileName": "com.facebook.presto.hive.metastore.file.PartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   storageFormat ;", "}", "METHOD_END"], "methodName": ["getStorageFormat"], "fileName": "com.facebook.presto.hive.metastore.file.PartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   new   Partition ( databaseName ,    tableName ,    values ,    Storage . builder (  )  . setLocation ( externalLocation . orElse ( location )  )  . setStorageFormat ( storageFormat . map ( StorageFormat :  : fromHiveStorageFormat )  . orElse ( StorageFormat . VIEW _ STORAGE _ FORMAT )  )  . setBucketProperty ( bucketProperty )  . setSerdeParameters ( serdeParameters )  . build (  )  ,    columns ,    parameters )  ;", "}", "METHOD_END"], "methodName": ["toPartition"], "fileName": "com.facebook.presto.hive.metastore.file.PartitionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   permission ;", "}", "METHOD_END"], "methodName": ["getPermission"], "fileName": "com.facebook.presto.hive.metastore.file.PermissionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   grantOption ;", "}", "METHOD_END"], "methodName": ["isGrantOption"], "fileName": "com.facebook.presto.hive.metastore.file.PermissionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   new   HivePrivilegeInfo ( permission ,    grantOption )  ;", "}", "METHOD_END"], "methodName": ["toHivePrivilegeInfo"], "fileName": "com.facebook.presto.hive.metastore.file.PermissionMetadata"}, {"methodBody": ["METHOD_START", "{", "return   bucketProperty ;", "}", "METHOD_END"], "methodName": ["getBucketProperty"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "for    ( Column   partitionColumn    :    partitionColumns )     {", "if    ( partitionColumn . getName (  )  . equals ( name )  )     {", "return   Optional . of ( partitionColumn )  ;", "}", "}", "for    ( Column   Column    :    Columns )     {", "if    ( Column . getName (  )  . equals ( name )  )     {", "return   Optional . of ( Column )  ;", "}", "}", "return   Optional . empty (  )  ;", "}", "METHOD_END"], "methodName": ["getColumn"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   dataColumns ;", "}", "METHOD_END"], "methodName": ["getDataColumns"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   externalLocation ;", "}", "METHOD_END"], "methodName": ["getExternalLocation"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   owner ;", "}", "METHOD_END"], "methodName": ["getOwner"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   parameters ;", "}", "METHOD_END"], "methodName": ["getParameters"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   partitionColumns ;", "}", "METHOD_END"], "methodName": ["getPartitionColumns"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   serdeParameters ;", "}", "METHOD_END"], "methodName": ["getSerdeParameters"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   storageFormat ;", "}", "METHOD_END"], "methodName": ["getStorageFormat"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   tableType ;", "}", "METHOD_END"], "methodName": ["getTableType"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   viewExpandedText ;", "}", "METHOD_END"], "methodName": ["getViewExpandedText"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   viewOriginalText ;", "}", "METHOD_END"], "methodName": ["getViewOriginalText"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   new   Table ( databaseName ,    tableName ,    owner ,    tableType ,    Storage . builder (  )  . setLocation ( externalLocation . orElse ( location )  )  . setStorageFormat ( storageFormat . map ( StorageFormat :  : fromHiveStorageFormat )  . orElse ( StorageFormat . VIEW _ STORAGE _ FORMAT )  )  . setBucketProperty ( bucketProperty )  . setSerdeParameters ( serdeParameters )  . build (  )  ,    dataColumns ,    partitionColumns ,    parameters ,    viewOriginalText ,    viewExpandedText )  ;", "}", "METHOD_END"], "methodName": ["toTable"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "return   new   TableMetadata ( owner ,    tableType ,    dataColumns ,    partitionColumns ,    parameters ,    storageFormat ,    bucketProperty ,    serdeParameters ,    externalLocation ,    viewOriginalText ,    viewExpandedText )  ;", "}", "METHOD_END"], "methodName": ["withDataColumns"], "fileName": "com.facebook.presto.hive.metastore.file.TableMetadata"}, {"methodBody": ["METHOD_START", "{", "if    (  ( partitionValues    =  =    null )     |  |     ( partitionValues . isEmpty (  )  )  )     {", "return   null ;", "}", "if    (  ( partitionKeys    =  =    null )     |  |     (  ( partitionValues . size (  )  )     !  =     ( partitionKeys . size (  )  )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     (  \" Incorrect   number   of   partition   values :     \"     +    partitionValues )  )  ;", "}", "List < String >    predicates    =    new   LinkedList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( partitionValues . size (  )  )  ;    i +  +  )     {", "if    (  !  ( Strings . isNullOrEmpty ( partitionValues . get ( i )  )  )  )     {", "predicates . add (  . buildPredicate ( partitionKeys . get ( i )  ,    partitionValues . get ( i )  )  )  ;", "}", "}", "return    . JOINER . join ( predicates )  ;", "}", "METHOD_END"], "methodName": ["buildGlueExpression"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueExpressionUtil"}, {"methodBody": ["METHOD_START", "{", "if    ( GlueExpressionUtil . isQuotedType ( partitionKey . getType (  )  )  )     {", "return   String . format (  \"  (  % s =  '  % s '  )  \"  ,    partitionKey . getName (  )  ,    value )  ;", "}", "return   String . format (  \"  (  % s =  % s )  \"  ,    partitionKey . getName (  )  ,    value )  ;", "}", "METHOD_END"], "methodName": ["buildPredicate"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueExpressionUtil"}, {"methodBody": ["METHOD_START", "{", "return   GlueExpressionUtil . QUOTED _ TYPES . contains ( type . getTypeSignature (  )  . getBase (  )  )  ;", "}", "METHOD_END"], "methodName": ["isQuotedType"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueExpressionUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "List < PartitionValueList >    partitionValueLists    =    partitionNames . stream (  )  . map (  (    partitionName )     -  >    new   PartitionValueList (  )  . withValues ( HiveUtil . toPartitionValues ( partitionName )  )  )  . collect ( Collectors . toList (  )  )  ;", "List < List < PartitionValueList >  >    batchedPartitionValueLists    =    Lists . partition ( partitionValueLists ,     . BATCH _ GET _ PARTITION _ MAX _ PAGE _ SIZE )  ;", "List < Future < BatchGetPartitionResult >  >    batchGetPartitionFutures    =    new   ArrayList <  >  (  )  ;", "List < Partition >    result    =    new   ArrayList <  >  (  )  ;", "for    ( List < PartitionValueList >    partitions    :    batchedPartitionValueLists )     {", "batchGetPartitionFutures . add ( glueClient . batchGetPartitionAsync ( new   BatchGetPartitionRequest (  )  . withDatabaseName ( databaseName )  . withTableName ( tableName )  . withPartitionsToGet ( partitions )  )  )  ;", "}", "for    ( Future < BatchGetPartitionResult >    future    :    batchGetPartitionFutures )     {", "future . get (  )  . getPartitions (  )  . forEach (  (    partition )     -  >    result . add ( GlueToPrestoConverter . convertPartition ( partition )  )  )  ;", "}", "return   result ;", "}    catch    ( AmazonServiceException    |    InterruptedException    |    ExecutionException   e )     {", "if    ( e   instanceof   InterruptedException )     {", "Thread . currentThread (  )  . interrupt (  )  ;", "}", "throw   new   PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["batchGetPartition"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   partitions . stream (  )  . map (  (    partition )     -  >    MetastoreUtil . makePartName ( partitionColumns ,    partition . getValues (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "}", "METHOD_END"], "methodName": ["buildPartitionNames"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "ClientConfiguration   clientConfig    =    new   ClientConfiguration (  )  . withMaxConnections ( config . getMaxGlueConnections (  )  )  ;", "AWSGlueAsyncClientBuilder   asyncGlueClientBuilder    =    AWSGlueAsyncClientBuilder . standard (  )  . withClientConfiguration ( clientConfig )  ;", "if    ( config . getGlueRegion (  )  . isPresent (  )  )     {", "asyncGlueClientBuilder . setRegion ( config . getGlueRegion (  )  . get (  )  )  ;", "} else", "if    ( config . getPinGlueClientToCurrentRegion (  )  )     {", "com . amazonaws . regions . Region   currentRegion    =    com . amazonaws . regions . Regions . getCurrentRegion (  )  ;", "if    ( currentRegion    !  =    null )     {", "asyncGlueClientBuilder . setRegion ( currentRegion . getName (  )  )  ;", "}", "}", "return   asyncGlueClientBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["createAsyncGlueClient"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "hdfsEnvironment . getFileSystem ( context ,    path )  . delete ( path ,    recursive )  ;", "}    catch    ( Exception   e )     {", ". log . warn ( e ,     (  \" Failed   to   delete   path :     \"     +     ( path . toString (  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["deleteDir"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "try    {", "List < Partition >    partitions    =    new   ArrayList <  >  (  )  ;", "String   nextToken    =    null ;", "do    {", "GetPartitionsResult   result    =    glueClient . getPartitions ( new   GetPartitionsRequest (  )  . withDatabaseName ( databaseName )  . withTableName ( tableName )  . withExpression ( expression )  . withNextToken ( nextToken )  )  ;", "result . getPartitions (  )  . forEach (  (    partition )     -  >    partitions . add ( GlueToPrestoConverter . convertPartition ( partition )  )  )  ;", "nextToken    =    result . getNextToken (  )  ;", "}    while    ( nextToken    !  =    null    )  ;", "return   partitions ;", "}    catch    ( AmazonServiceException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["getPartitions"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   getTable ( databaseName ,    tableName )  . orElseThrow (  (  )     -  >    new   com . facebook . presto . spi . TableNotFoundException ( new   SchemaTableName ( databaseName ,    tableName )  )  )  ;", "}", "METHOD_END"], "methodName": ["getTableOrElseThrow"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    (  ( partitionErrors    !  =    null )     &  &     (  !  ( partitionErrors . isEmpty (  )  )  )  )     {", "ErrorDetail   errorDetail    =    partitionErrors . get (  0  )  . getErrorDetail (  )  ;", "String   glueExceptionCode    =    errorDetail . getErrorCode (  )  ;", "switch    ( glueExceptionCode )     {", "case    \" AlreadyExistsException \"     :", "throw   new   spi . PrestoException ( spi . StandardErrorCode . ALREADY _ EXISTS ,    errorDetail . getErrorMessage (  )  )  ;", "case    \" EntityNotFoundException \"     :", "throw   new   spi . TableNotFoundException ( new   SchemaTableName ( databaseName ,    tableName )  ,    errorDetail . getErrorMessage (  )  )  ;", "default    :", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,     (  (  ( errorDetail . getErrorCode (  )  )     +     \"  :     \"  )     +     ( errorDetail . getErrorMessage (  )  )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["propagatePartitionErrorToPrestoException"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   defaultWarehouseDir ;", "}", "METHOD_END"], "methodName": ["getDefaultWarehouseDir"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "return   glueRegion ;", "}", "METHOD_END"], "methodName": ["getGlueRegion"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxGlueConnections ;", "}", "METHOD_END"], "methodName": ["getMaxGlueConnections"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "return   pinGlueClientToCurrentRegion ;", "}", "METHOD_END"], "methodName": ["getPinGlueClientToCurrentRegion"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "this . defaultWarehouseDir    =    Optional . ofNullable ( defaultWarehouseDir )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setDefaultWarehouseDir"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "this . glueRegion    =    Optional . ofNullable ( region )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setGlueRegion"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "this . maxGlueConnections    =    maxGlueConnections ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxGlueConnections"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "this . pinGlueClientToCurrentRegion    =    pinGlueClientToCurrentRegion ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setPinGlueClientToCurrentRegion"], "fileName": "com.facebook.presto.hive.metastore.glue.GlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "return   new   Column ( name ,    HiveType . valueOf ( type )  ,    Optional . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["getColumn"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueExpressionUtil"}, {"methodBody": ["METHOD_START", "{", "List < String >    partitionValues    =    ImmutableList . of (  \" foo \"  ,     \"  2  0  1  8  -  0  1  -  0  2  \"  ,     \"  9  9  \"  )  ;", "String   expression    =    GlueExpressionUtil . buildGlueExpression (  . PARTITION _ KEYS ,    partitionValues )  ;", "assertEquals ( expression ,     \"  ( name =  ' foo '  )    AND    ( birthday =  '  2  0  1  8  -  0  1  -  0  2  '  )    AND    ( age =  9  9  )  \"  )  ;", "partitionValues    =    ImmutableList . of (  \" foo \"  ,     \"  2  0  1  8  -  0  1  -  0  2  \"  ,     \"  \"  )  ;", "expression    =    GlueExpressionUtil . buildGlueExpression (  . PARTITION _ KEYS ,    partitionValues )  ;", "assertEquals ( expression ,     \"  ( name =  ' foo '  )    AND    ( birthday =  '  2  0  1  8  -  0  1  -  0  2  '  )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testBuildExpression"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueExpressionUtil"}, {"methodBody": ["METHOD_START", "{", "List < String >    partitionValues    =    ImmutableList . of (  \"  \"  ,     \"  2  0  1  8  -  0  1  -  0  2  \"  ,     \"  \"  )  ;", "String   expression    =    GlueExpressionUtil . buildGlueExpression (  . PARTITION _ KEYS ,    partitionValues )  ;", "assertEquals ( expression ,     \"  ( birthday =  '  2  0  1  8  -  0  1  -  0  2  '  )  \"  )  ;", "partitionValues    =    ImmutableList . of (  \" foo \"  ,     \"  \"  ,     \"  9  9  \"  )  ;", "expression    =    GlueExpressionUtil . buildGlueExpression (  . PARTITION _ KEYS ,    partitionValues )  ;", "assertEquals ( expression ,     \"  ( name =  ' foo '  )    AND    ( age =  9  9  )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testBuildExpressionFromPartialSpecification"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueExpressionUtil"}, {"methodBody": ["METHOD_START", "{", "List < String >    partitionValues    =    ImmutableList . of (  \" foo \"  ,     \"  2  0  1  7  -  0  1  -  0  2  \"  ,     \"  9  9  \"  ,     \" extra \"  )  ;", "GlueExpressionUtil . buildGlueExpression (  . PARTITION _ KEYS ,    partitionValues )  ;", "}", "METHOD_END"], "methodName": ["testBuildExpressionInvalidPartitionValueListSize"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueExpressionUtil"}, {"methodBody": ["METHOD_START", "{", "assertNull ( GlueExpressionUtil . buildGlueExpression ( TestGlueExpressionUtil . PARTITION _ KEYS ,    ImmutableList . of (  )  )  )  ;", "assertNull ( GlueExpressionUtil . buildGlueExpression ( TestGlueExpressionUtil . PARTITION _ KEYS ,    null )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildExpressionNullOrEmptyValues"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueExpressionUtil"}, {"methodBody": ["METHOD_START", "{", "List < String >    partitionValues    =    ImmutableList . of (  \" foo \"  ,     \"  2  0  1  8  -  0  1  -  0  2  \"  ,     \"  9  9  \"  )  ;", ". buildGlueExpression ( null ,    partitionValues )  ;", "}", "METHOD_END"], "methodName": ["testBuildExpressionNullPartitionKeys"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueExpressionUtil"}, {"methodBody": ["METHOD_START", "{", "assertRecordedDefaults ( recordDefaults ( GlueHiveMetastoreConfig . class )  . setGlueRegion ( null )  . setPinGlueClientToCurrentRegion ( false )  . setMaxGlueConnections (  5  )  . setDefaultWarehouseDir ( null )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . metastore . glue . region \"  ,     \" us - east -  1  \"  )  . put (  \" hive . metastore . glue . pin - client - to - current - region \"  ,     \" true \"  )  . put (  \" hive . metastore . glue . max - connections \"  ,     \"  1  0  \"  )  . put (  \" hive . metastore . glue . default - warehouse - dir \"  ,     \"  / location \"  )  . build (  )  ;", "expected    =    new    (  )  . setGlueRegion (  \" us - east -  1  \"  )  . setPinGlueClientToCurrentRegion ( true )  . setMaxGlueConnections (  1  0  )  . setDefaultWarehouseDir (  \"  / location \"  )  ;", "assertFullMapping ( properties ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMapping"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueHiveMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( actual . getName (  )  ,    expected . getName (  )  )  ;", "assertEquals ( actual . getType (  )  ,    expected . getType (  )  . getHiveTypeName (  )  . toString (  )  )  ;", "assertEquals ( actual . getComment (  )  ,    expected . getComment (  )  . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertColumn"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "if    ( expected    =  =    null )     {", "assertNull ( actual )  ;", "}", "assertEquals ( actual . size (  )  ,    expected . size (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( expected . size (  )  )  ;    i +  +  )     {", ". assertColumn ( actual . get ( i )  ,    expected . get ( i )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertColumnList"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( actual . getLocation (  )  ,    expected . getLocation (  )  )  ;", "assertEquals ( actual . getSerdeInfo (  )  . getSerializationLibrary (  )  ,    expected . getStorageFormat (  )  . getSerDe (  )  )  ;", "assertEquals ( actual . getFormat (  )  ,    expected . getStorageFormat (  )  . getFormat (  )  )  ;", "assertEquals ( actual . getOutputFormat (  )  ,    expected . getStorageFormat (  )  . getOutputFormat (  )  )  ;", "if    ( expected . getBucketProperty (  )  . isPresent (  )  )     {", "HiveBucketProperty   bucketProperty    =    expected . getBucketProperty (  )  . get (  )  ;", "assertEquals ( actual . getBucketColumns (  )  ,    bucketProperty . getBucketedBy (  )  )  ;", "assertEquals ( actual . getNumberOfBuckets (  )  . intValue (  )  ,    bucketProperty . getBucketCount (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertStorage"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "DatabaseInput   dbInput    =    GlueInputConverter . convertDatabase ( testDb )  ;", "assertEquals ( dbInput . getName (  )  ,    testDb . getDatabaseName (  )  )  ;", "assertEquals ( dbInput . getDescription (  )  ,    testDb . getComment (  )  . get (  )  )  ;", "assertEquals ( dbInput . getLocationUri (  )  ,    testDb . getLocation (  )  . get (  )  )  ;", "assertEquals ( dbInput . getParameters (  )  ,    testDb . getParameters (  )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertDatabase"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "PartitionInput   partitionInput    =    GlueInputConverter . convertPartition ( testPartition )  ;", "assertEquals ( partitionInput . getParameters (  )  ,    testPartition . getParameters (  )  )  ;", ". assertStorage ( partitionInput . getStorageDescriptor (  )  ,    testPartition . getStorage (  )  )  ;", "assertEquals ( partitionInput . getValues (  )  ,    testPartition . getValues (  )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertPartition"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "TableInput   tblInput    =    GlueInputConverter . convertTable ( testTbl )  ;", "assertEquals ( tblInput . getName (  )  ,    testTbl . getTableName (  )  )  ;", "assertEquals ( tblInput . getOwner (  )  ,    testTbl . getOwner (  )  )  ;", "assertEquals ( tblInput . getTableType (  )  ,    testTbl . getTableType (  )  )  ;", "assertEquals ( tblInput . getParameters (  )  ,    testTbl . getParameters (  )  )  ;", ". assertColumnList ( tblInput . getStorageDescriptor (  )  . getColumns (  )  ,    testTbl . getDataColumns (  )  )  ;", ". assertColumnList ( tblInput . getPartitionKeys (  )  ,    testTbl . getPartitionColumns (  )  )  ;", ". assertStorage ( tblInput . getStorageDescriptor (  )  ,    testTbl . getStorage (  )  )  ;", "assertEquals ( tblInput . getViewExpandedText (  )  ,    testTbl . getViewExpandedText (  )  . get (  )  )  ;", "assertEquals ( tblInput . getViewOriginalText (  )  ,    testTbl . getViewOriginalText (  )  . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertTable"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( actual . getName (  )  ,    expected . getName (  )  )  ;", "assertEquals ( actual . getType (  )  . getHiveTypeName (  )  . toString (  )  ,    expected . getType (  )  )  ;", "assertEquals ( actual . getComment (  )  . get (  )  ,    expected . getComment (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertColumn"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "if    ( expected    =  =    null )     {", "assertNull ( actual )  ;", "}", "assertEquals ( actual . size (  )  ,    expected . size (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( expected . size (  )  )  ;    i +  +  )     {", ". assertColumn ( actual . get ( i )  ,    expected . get ( i )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertColumnList"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( actual . getLocation (  )  ,    expected . getLocation (  )  )  ;", "assertEquals ( actual . getStorageFormat (  )  . getSerDe (  )  ,    expected . getSerdeInfo (  )  . getSerializationLibrary (  )  )  ;", "assertEquals ( actual . getStorageFormat (  )  . getInputFormat (  )  ,    expected . getInputFormat (  )  )  ;", "assertEquals ( actual . getStorageFormat (  )  . getOutputFormat (  )  ,    expected . getOutputFormat (  )  )  ;", "if    (  !  ( CollectionUtils . isNullOrEmpty ( expected . getBucketColumns (  )  )  )  )     {", "HiveBucketProperty   bucketProperty    =    actual . getBucketProperty (  )  . get (  )  ;", "assertEquals ( bucketProperty . getBucketedBy (  )  ,    expected . getBucketColumns (  )  )  ;", "assertEquals ( bucketProperty . getBucketCount (  )  ,    expected . getNumberOfBuckets (  )  . intValue (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertStorage"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "testDb    =    TestingMetastoreObjects . getGlueTestDatabase (  )  ;", "testTbl    =    TestingMetastoreObjects . getGlueTestTable ( testDb . getName (  )  )  ;", "testPartition    =    TestingMetastoreObjects . getGlueTestPartition ( testDb . getName (  )  ,    testTbl . getName (  )  ,    ImmutableList . of (  \" val 1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "Database   prestoDb    =    GlueToPrestoConverter . convertDatabase ( testDb )  ;", "assertEquals ( prestoDb . getDatabaseName (  )  ,    testDb . getName (  )  )  ;", "assertEquals ( prestoDb . getLocation (  )  . get (  )  ,    testDb . getLocationUri (  )  )  ;", "assertEquals ( prestoDb . getComment (  )  . get (  )  ,    testDb . getDescription (  )  )  ;", "assertEquals ( prestoDb . getParameters (  )  ,    testDb . getParameters (  )  )  ;", "assertEquals ( prestoDb . getOwnerName (  )  ,     . PUBLIC _ OWNER )  ;", "assertEquals ( prestoDb . getOwnerType (  )  ,    PrincipalType . ROLE )  ;", "}", "METHOD_END"], "methodName": ["testConvertDatabase"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "Partition   prestoPartition    =    GlueToPrestoConverter . convertPartition ( testPartition )  ;", "assertEquals ( prestoPartition . getDatabaseName (  )  ,    testPartition . getDatabaseName (  )  )  ;", "assertEquals ( prestoPartition . getTableName (  )  ,    testPartition . getTableName (  )  )  ;", ". assertColumnList ( prestoPartition . getColumns (  )  ,    testPartition . getStorageDescriptor (  )  . getColumns (  )  )  ;", "assertEquals ( prestoPartition . getValues (  )  ,    testPartition . getValues (  )  )  ;", ". assertStorage ( prestoPartition . getStorage (  )  ,    testPartition . getStorageDescriptor (  )  )  ;", "assertEquals ( prestoPartition . getParameters (  )  ,    testPartition . getParameters (  )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertPartition"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "Table   prestoTbl    =    GlueToPrestoConverter . convertTable ( testTbl ,    testDb . getName (  )  )  ;", "assertEquals ( prestoTbl . getTableName (  )  ,    testTbl . getName (  )  )  ;", "assertEquals ( prestoTbl . getDatabaseName (  )  ,    testDb . getName (  )  )  ;", "assertEquals ( prestoTbl . getTableType (  )  ,    testTbl . getTableType (  )  )  ;", "assertEquals ( prestoTbl . getOwner (  )  ,    testTbl . getOwner (  )  )  ;", "assertEquals ( prestoTbl . getParameters (  )  ,    testTbl . getParameters (  )  )  ;", ". assertColumnList ( prestoTbl . getDataColumns (  )  ,    testTbl . getStorageDescriptor (  )  . getColumns (  )  )  ;", ". assertColumnList ( prestoTbl . getPartitionColumns (  )  ,    testTbl . getPartitionKeys (  )  )  ;", ". assertStorage ( prestoTbl . getStorage (  )  ,    testTbl . getStorageDescriptor (  )  )  ;", "assertEquals ( prestoTbl . getViewOriginalText (  )  . get (  )  ,    testTbl . getViewOriginalText (  )  )  ;", "assertEquals ( prestoTbl . getViewExpandedText (  )  . get (  )  ,    testTbl . getViewExpandedText (  )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertTable"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "testTbl . setPartitionKeys ( null )  ;", "Table   prestoTbl    =     . convertTable ( testTbl ,    testDb . getName (  )  )  ;", "assertTrue ( prestoTbl . getPartitionColumns (  )  . isEmpty (  )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertTableNullPartitions"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "Column   uppercaseCol    =    TestingMetastoreObjects . getGlueTestColumn (  )  . withType (  \" String \"  )  ;", "testTbl . getStorageDescriptor (  )  . setColumns ( ImmutableList . of ( uppercaseCol )  )  ;", ". convertTable ( testTbl ,    testDb . getName (  )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertTableUppercaseColumnType"], "fileName": "com.facebook.presto.hive.metastore.glue.TestGlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "return   String . format (  \"  %  0  4 x \"  ,    ThreadLocalRandom . current (  )  . nextInt (  )  )  ;", "}", "METHOD_END"], "methodName": ["generateRandom"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   new   Column (  )  . withName (  (  \" test - col \"     +     ( TestingMetastoreObjects . generateRandom (  )  )  )  )  . withType (  \" string \"  )  . withComment (  \" column   comment \"  )  ;", "}", "METHOD_END"], "methodName": ["getGlueTestColumn"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   new   Database (  )  . withName (  (  \" test - db \"     +     ( TestingMetastoreObjects . generateRandom (  )  )  )  )  . withDescription (  \" database   desc \"  )  . withLocationUri (  \"  / db \"  )  . withParameters ( ImmutableMap . of (  )  )  ;", "}", "METHOD_END"], "methodName": ["getGlueTestDatabase"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   new   Partition (  )  . withDatabaseName ( dbName )  . withTableName ( tblName )  . withValues ( values )  . withParameters ( ImmutableMap . of (  )  )  . withStorageDescriptor ( TestingMetastoreObjects . getGlueTestStorageDescriptor (  )  )  ;", "}", "METHOD_END"], "methodName": ["getGlueTestPartition"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   new   StorageDescriptor (  )  . withBucketColumns ( ImmutableList . of (  \" test - bucket - col \"  )  )  . withColumns ( ImmutableList . of ( TestingMetastoreObjects . getGlueTestColumn (  )  )  )  . withParameters ( ImmutableMap . of (  )  )  . withSerdeInfo ( new   SerDeInfo (  )  . withSerializationLibrary (  \" SerdeLib \"  )  . withParameters ( ImmutableMap . of (  )  )  )  . withInputFormat (  \" InputFormat \"  )  . withOutputFormat (  \" OutputFormat \"  )  . withLocation (  \"  / test - tbl \"  )  . withNumberOfBuckets (  1  )  ;", "}", "METHOD_END"], "methodName": ["getGlueTestStorageDescriptor"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   new   Table (  )  . withDatabaseName ( dbName )  . withName (  (  \" test - tbl \"     +     ( TestingMetastoreObjects . generateRandom (  )  )  )  )  . withOwner (  \" owner \"  )  . withParameters ( ImmutableMap . of (  )  )  . withPartitionKeys ( ImmutableList . of ( TestingMetastoreObjects . getGlueTestColumn (  )  )  )  . withStorageDescriptor ( TestingMetastoreObjects . getGlueTestStorageDescriptor (  )  )  . withTableType ( EXTERNAL _ TABLE . name (  )  )  . withViewOriginalText (  \" originalText \"  )  . withViewExpandedText (  \" expandedText \"  )  ;", "}", "METHOD_END"], "methodName": ["getGlueTestTable"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   new   Column (  (  \" test - col \"     +     ( TestingMetastoreObjects . generateRandom (  )  )  )  ,    HiveType . HIVE _ STRING ,    Optional . of (  \" column   comment \"  )  )  ;", "}", "METHOD_END"], "methodName": ["getPrestoTestColumn"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   Database . builder (  )  . setDatabaseName (  (  \" test - db \"     +     ( TestingMetastoreObjects . generateRandom (  )  )  )  )  . setComment ( Optional . of (  \" database   desc \"  )  )  . setLocation ( Optional . of (  \"  / db \"  )  )  . setParameters ( ImmutableMap . of (  )  )  . setOwnerName (  \" PUBLIC \"  )  . setOwnerType ( PrincipalType . ROLE )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPrestoTestDatabase"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   Partition . builder (  )  . setDatabaseName ( dbName )  . setTableName ( tblName )  . setValues ( values )  . setColumns ( ImmutableList . of ( TestingMetastoreObjects . getPrestoTestColumn (  )  )  )  . setParameters ( ImmutableMap . of (  )  )  . withStorage ( TestingMetastoreObjects . STORAGE _ CONSUMER )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPrestoTestPartition"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   Table . builder (  )  . setDatabaseName ( dbName )  . setTableName (  (  \" test - tbl \"     +     ( TestingMetastoreObjects . generateRandom (  )  )  )  )  . setOwner (  \" owner \"  )  . setParameters ( ImmutableMap . of (  )  )  . setTableType ( EXTERNAL _ TABLE . name (  )  )  . setDataColumns ( ImmutableList . of ( TestingMetastoreObjects . getPrestoTestColumn (  )  )  )  . setPartitionColumns ( ImmutableList . of ( TestingMetastoreObjects . getPrestoTestColumn (  )  )  )  . setViewOriginalText ( Optional . of (  \" originalText \"  )  )  . setViewExpandedText ( Optional . of (  \" expandedText \"  )  )  . withStorage ( TestingMetastoreObjects . STORAGE _ CONSUMER )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPrestoTestTable"], "fileName": "com.facebook.presto.hive.metastore.glue.TestingMetastoreObjects"}, {"methodBody": ["METHOD_START", "{", "return   new   Column (  )  . withName ( prestoColumn . getName (  )  )  . withType ( prestoColumn . getType (  )  . toString (  )  )  . withComment ( prestoColumn . getComment (  )  . orElse ( null )  )  ;", "}", "METHOD_END"], "methodName": ["convertColumn"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "DatabaseInput   input    =    new   DatabaseInput (  )  ;", "input . setName ( database . getDatabaseName (  )  )  ;", "input . setParameters ( database . getParameters (  )  )  ;", "database . getComment (  )  . ifPresent ( input :  : setDescription )  ;", "database . getLocation (  )  . ifPresent ( input :  : setLocationUri )  ;", "return   input ;", "}", "METHOD_END"], "methodName": ["convertDatabase"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "PartitionInput   input    =    new   PartitionInput (  )  ;", "input . setValues ( partition . getValues (  )  )  ;", "input . setStorageDescriptor (  . convertStorage ( partition . getStorage (  )  ,    partition . getColumns (  )  )  )  ;", "input . setParameters ( partition . getParameters (  )  )  ;", "return   input ;", "}", "METHOD_END"], "methodName": ["convertPartition"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "if    (  ( storage . isSorted (  )  )     |  |     ( storage . isSkewed (  )  )  )     {", "throw   new   IllegalArgumentException (  \" Writing   to   sorted   and / or   skewed   table / partition   is   not   supported \"  )  ;", "}", "SerDeInfo   serdeInfo    =    new   SerDeInfo (  )  . withSerializationLibrary ( storage . getStorageFormat (  )  . getSerDeNullable (  )  )  . withParameters ( storage . getSerdeParameters (  )  )  ;", "StorageDescriptor   sd    =    new   StorageDescriptor (  )  ;", "sd . setLocation ( storage . getLocation (  )  )  ;", "sd . setColumns ( columns . stream (  )  . map (  :  : convertColumn )  . collect ( Collectors . toList (  )  )  )  ;", "sd . setSerdeInfo ( serdeInfo )  ;", "sd . setInputFormat ( storage . getStorageFormat (  )  . getInputFormatNullable (  )  )  ;", "sd . setOutputFormat ( storage . getStorageFormat (  )  . getOutputFormatNullable (  )  )  ;", "sd . setParameters ( ImmutableMap . of (  )  )  ;", "if    ( storage . getBucketProperty (  )  . isPresent (  )  )     {", "sd . setNumberOfBuckets ( storage . getBucketProperty (  )  . get (  )  . getBucketCount (  )  )  ;", "sd . setBucketColumns ( storage . getBucketProperty (  )  . get (  )  . getBucketedBy (  )  )  ;", "}", "return   sd ;", "}", "METHOD_END"], "methodName": ["convertStorage"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "TableInput   input    =    new   TableInput (  )  ;", "input . setName ( table . getTableName (  )  )  ;", "input . setOwner ( table . getOwner (  )  )  ;", "input . setTableType ( table . getTableType (  )  )  ;", "input . setStorageDescriptor (  . convertStorage ( table . getStorage (  )  ,    table . getDataColumns (  )  )  )  ;", "input . setPartitionKeys ( table . getPartitionColumns (  )  . stream (  )  . map (  :  : convertColumn )  . collect ( Collectors . toList (  )  )  )  ;", "input . setParameters ( table . getParameters (  )  )  ;", "table . getViewOriginalText (  )  . ifPresent ( input :  : setViewOriginalText )  ;", "table . getViewExpandedText (  )  . ifPresent ( input :  : setViewExpandedText )  ;", "return   input ;", "}", "METHOD_END"], "methodName": ["convertTable"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueInputConverter"}, {"methodBody": ["METHOD_START", "{", "return   new   Column ( glueColumn . getName (  )  ,    HiveType . valueOf ( glueColumn . getType (  )  . toLowerCase (  )  )  ,    Optional . ofNullable ( glueColumn . getComment (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["convertColumn"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "return   Database . builder (  )  . setDatabaseName ( glueDb . getName (  )  )  . setLocation ( Optional . ofNullable ( glueDb . getLocationUri (  )  )  )  . setComment ( Optional . ofNullable ( glueDb . getDescription (  )  )  )  . setParameters ( glueDb . getParameters (  )  )  . setOwnerName ( GlueToPrestoConverter . PUBLIC _ OWNER )  . setOwnerType ( PrincipalType . ROLE )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["convertDatabase"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( gluePartition . getStorageDescriptor (  )  ,     \" Partition   StorageDescriptor   is   null \"  )  ;", "StorageDescriptor   sd    =    gluePartition . getStorageDescriptor (  )  ;", "Partition . Builder   partitionBuilder    =    Partition . builder (  )  . setDatabaseName ( gluePartition . getDatabaseName (  )  )  . setTableName ( gluePartition . getTableName (  )  )  . setValues ( gluePartition . getValues (  )  )  . setColumns ( sd . getColumns (  )  . stream (  )  . map (  :  : convertColumn )  . collect ( Collectors . toList (  )  )  )  . setParameters ( gluePartition . getParameters (  )  )  ;", ". setStorageBuilder ( sd ,    partitionBuilder . getStorageBuilder (  )  )  ;", "return   partitionBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["convertPartition"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( glueTable . getStorageDescriptor (  )  ,     \" Table   StorageDescriptor   is   null \"  )  ;", "StorageDescriptor   sd    =    glueTable . getStorageDescriptor (  )  ;", "Table . Builder   tableBuilder    =    Table . builder (  )  . setDatabaseName ( dbName )  . setTableName ( glueTable . getName (  )  )  . setOwner ( nullToEmpty ( glueTable . getOwner (  )  )  )  . setTableType ( glueTable . getTableType (  )  )  . setDataColumns ( sd . getColumns (  )  . stream (  )  . map (  :  : convertColumn )  . collect ( Collectors . toList (  )  )  )  . setParameters ( glueTable . getParameters (  )  )  . setViewOriginalText ( Optional . ofNullable ( glueTable . getViewOriginalText (  )  )  )  . setViewExpandedText ( Optional . ofNullable ( glueTable . getViewExpandedText (  )  )  )  ;", "if    (  ( glueTable . getPartitionKeys (  )  )     !  =    null )     {", "tableBuilder . setPartitionColumns ( glueTable . getPartitionKeys (  )  . stream (  )  . map (  :  : convertColumn )  . collect ( Collectors . toList (  )  )  )  ;", "} else    {", "tableBuilder . setPartitionColumns ( new   ArrayList <  >  (  )  )  ;", "}", ". setStorageBuilder ( sd ,    tableBuilder . getStorageBuilder (  )  )  ;", "return   tableBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["convertTable"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "return    ( list    =  =    null )     |  |     ( list . isEmpty (  )  )  ;", "}", "METHOD_END"], "methodName": ["isNullOrEmpty"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( sd . getSerdeInfo (  )  ,     \" StorageDescriptor   SerDeInfo   is   null \"  )  ;", "SerDeInfo   serdeInfo    =    sd . getSerdeInfo (  )  ;", "Optional < HiveBucketProperty >    bucketProperty    =    Optional . empty (  )  ;", "if    (  ( sd . getNumberOfBuckets (  )  )     >     0  )     {", "if    (  . isNullOrEmpty ( sd . getBucketColumns (  )  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ INVALID _ METADATA ,     \" Table / partition   metadata   has    ' numBuckets '    set ,    but    ' bucketCols '    is   not   set \"  )  ;", "}", "bucketProperty    =    Optional . of ( new   HiveBucketProperty ( sd . getBucketColumns (  )  ,    sd . getNumberOfBuckets (  )  )  )  ;", "}", "storageBuilder . setStorageFormat ( StorageFormat . createNullable ( serdeInfo . getSerializationLibrary (  )  ,    sd . getInputFormat (  )  ,    sd . getOutputFormat (  )  )  )  . setLocation ( nullToEmpty ( sd . getLocation (  )  )  )  . setBucketProperty ( bucketProperty )  . setSorted (  (  !  (  . isNullOrEmpty ( sd . getSortColumns (  )  )  )  )  )  . setSkewed (  (  (  ( sd . getSkewedInfo (  )  )     !  =    null )     &  &     (  !  (  . isNullOrEmpty ( sd . getSkewedInfo (  )  . getSkewedColumnNames (  )  )  )  )  )  )  . setSerdeParameters ( firstNonNull ( serdeInfo . getParameters (  )  ,    ImmutableMap . of (  )  )  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["setStorageBuilder"], "fileName": "com.facebook.presto.hive.metastore.glue.converter.GlueToPrestoConverter"}, {"methodBody": ["METHOD_START", "{", "delegate . alterTable ( databaseName ,    tableName ,    table )  ;", "}", "METHOD_END"], "methodName": ["alterTable"], "fileName": "com.facebook.presto.hive.metastore.thrift.BridgingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   ImmutableMap . copyOf ( statistics . stream (  )  . collect ( Collectors . toMap ( ColumnStatisticsObj :  : getColName ,    ThriftMetastoreUtil :  : fromMetastoreApiColumnStatistics )  )  )  ;", "}", "METHOD_END"], "methodName": ["groupStatisticsByColumn"], "fileName": "com.facebook.presto.hive.metastore.thrift.BridgingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( Database . DEFAULT _ DATABASE _ NAME . equalsIgnoreCase ( databaseName )  )     {", "return   true ;", "}", "Optional < Database >    databaseMetadata    =    getDatabase ( databaseName )  ;", "if    (  !  ( databaseMetadata . isPresent (  )  )  )     {", "return   false ;", "}", "Database   database    =    databaseMetadata . get (  )  ;", "if    (  (  ( database . getOwnerType (  )  )     =  =     ( PrincipalType . USER )  )     &  &     ( user . equals ( database . getOwnerName (  )  )  )  )     {", "return   true ;", "}", "if    (  (  ( database . getOwnerType (  )  )     =  =     ( PrincipalType . ROLE )  )     &  &     ( getRoles ( user )  . contains ( database . getOwnerName (  )  )  )  )     {", "return   true ;", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isDatabaseOwner"], "fileName": "com.facebook.presto.hive.metastore.thrift.HiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Optional < Table >    table    =    getTable ( databaseName ,    tableName )  ;", "return    ( table . isPent (  )  )     &  &     ( user . equals ( table . get (  )  . getOwner (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["isTableOwner"], "fileName": "com.facebook.presto.hive.metastore.thrift.HiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   metastoreExceptions ;", "}", "METHOD_END"], "methodName": ["getMetastoreExceptions"], "fileName": "com.facebook.presto.hive.metastore.thrift.HiveMetastoreApiStats"}, {"methodBody": ["METHOD_START", "{", "return   thriftExceptions ;", "}", "METHOD_END"], "methodName": ["getThriftExceptions"], "fileName": "com.facebook.presto.hive.metastore.thrift.HiveMetastoreApiStats"}, {"methodBody": ["METHOD_START", "{", "return   time ;", "}", "METHOD_END"], "methodName": ["getTime"], "fileName": "com.facebook.presto.hive.metastore.thrift.HiveMetastoreApiStats"}, {"methodBody": ["METHOD_START", "{", "return   totalFailures ;", "}", "METHOD_END"], "methodName": ["getTotalFailures"], "fileName": "com.facebook.presto.hive.metastore.thrift.HiveMetastoreApiStats"}, {"methodBody": ["METHOD_START", "{", "return    (  )     -  >     {", "try    ( TimeStat . BlockTimer   ignored    =    time . time (  )  )     {", "return   callable . call (  )  ;", "}    catch    ( Exception   e )     {", "if    ( e   instanceof   MetaException )     {", "Exceptions . update (  1  )  ;", "totalFailures . update (  1  )  ;", "throw   e ;", "}", "if    ( e   instanceof   TException )     {", "if    ( e   instanceof   TBase )     {", "throw   e ;", "}", "thriftExceptions . update (  1  )  ;", "totalFailures . update (  1  )  ;", "throw   e ;", "}", "totalFailures . update (  1  )  ;", "throw   e ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["wrap"], "fileName": "com.facebook.presto.hive.metastore.thrift.HiveMetastoreApiStats"}, {"methodBody": ["METHOD_START", "{", "return   new   ThriftHiveMetastoreClient ( Transport . create ( address ,    sslContext ,    socksProxy ,    timeoutMillis ,    metastoreAuthentication )  )  ;", "}", "METHOD_END"], "methodName": ["create"], "fileName": "com.facebook.presto.hive.metastore.thrift.HiveMetastoreClientFactory"}, {"methodBody": ["METHOD_START", "{", "return   InMemoryHiveMetastore . makePartName ( table . getPartitionKeys (  )  ,    partition . getValues (  )  )  ;", "}", "METHOD_END"], "methodName": ["createPartitionName"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "for    ( File   parent    =    directory . getParentFile (  )  ;    parent    !  =    null ;    parent    =    parent . getParentFile (  )  )     {", "if    ( parent . equals ( baseDirectory )  )     {", "return   true ;", "}", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isParentDir"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < String >    locations    =    ImmutableList . builder (  )  ;", "Table   table    =    getTable ( schemaName ,    tableName )  . get (  )  ;", "if    (  ( table . getSd (  )  . getLocation (  )  )     !  =    null )     {", "locations . add ( table . getSd (  )  . getLocation (  )  )  ;", "}", "Optional < List < String >  >    partitionNames    =    getPartitionNames ( schemaName ,    tableName )  ;", "if    ( partitionNames . isPresent (  )  )     {", "getPartitionsByNames ( schemaName ,    tableName ,    partitionNames . get (  )  )  . stream (  )  . map (  (    partition )     -  >    partition . getSd (  )  . getLocation (  )  )  . filter (  (    location )     -  >     !  ( location . startsWith ( table . getSd (  )  . getLocation (  )  )  )  )  . forEach ( locations :  : add )  ;", "}", "return   locations . build (  )  ;", "}", "METHOD_END"], "methodName": ["listAllDataPaths"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( partitionColumns . size (  )  )     =  =     ( values . size (  )  )  )  )  ;", "List < String >    partitionColumnNames    =    partitionColumns . stream (  )  . map ( FieldSchema :  : getName )  . collect ( Collecs . toList (  )  )  ;", "return   FileUtils . makePartName ( partitionColumnNames ,    values )  ;", "}", "METHOD_END"], "methodName": ["makePartName"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    (  (  !  ( partition . getDbName (  )  . equals ( databaseName )  )  )     |  |     (  !  ( partition . getTableName (  )  . equals ( tableName )  )  )  )     {", "return   false ;", "}", "List < String >    values    =    partition . getValues (  )  ;", "if    (  ( values . size (  )  )     !  =     ( parts . size (  )  )  )     {", "return   false ;", "}", "for    ( int   i    =     0  ;    i    <     ( values . size (  )  )  ;    i +  +  )     {", "String   part    =    parts . get ( i )  ;", "if    (  (  !  ( part . isEmpty (  )  )  )     &  &     (  !  ( values . get ( i )  . equals ( part )  )  )  )     {", "return   false ;", "}", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["partitionMatches"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "for    ( K   key    :    ImmutableSet . copyOf ( map . keySet (  )  )  )     {", "K   newKey    =    keyRewriter . apply ( key )  ;", "if    (  !  ( newKey . equals ( key )  )  )     {", "map . put ( newKey ,    map . rve ( key )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["rewriteKeys"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkArgument ( columnStatisticsObj . getColName (  )  . equals ( columnName )  ,     \" columnName   argument   and   columnStatisticsObj . getColName (  )    must   be   the   same \"  )  ;", "SchemaTableName   schemaTableName    =    new   SchemaTableName ( databaseName ,    tableName )  ;", "columnStatistics . puteIfAbsent ( schemaTableName ,     (    key )     -  >    new   HashMap <  >  (  )  )  . put ( columnName ,    columnStatisticsObj )  ;", "}", "METHOD_END"], "methodName": ["setColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkArgument ( columnStatisticsObj . getColName (  )  . equals ( columnName )  ,     \" columnName   argument   and   columnStatisticsObj . getColName (  )    must   be   the   same \"  )  ;", ". PartitionName   partitionKey    =     . PartitionName . partition ( databaseName ,    tableName ,    partitionName )  ;", "partitionColumnStatistics . computeIfAbsent ( partitionKey ,     (    key )     -  >    new   HashMap <  >  (  )  )  . put ( columnName ,    columnStatisticsObj )  ;", "}", "METHOD_END"], "methodName": ["setPartitionColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "tablePrivileges . put ( new   InMemoryHiveMetastore . PrincipalTableKey ( principalName ,    principalType ,    tableName ,    databaseName )  ,    ImmutableSet . copyOf ( privileges )  )  ;", "}", "METHOD_END"], "methodName": ["setTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( roles . contains ( InMemoryHiveMetastore . PUBLIC _ ROLE _ NAME )  )  )     {", "roles    =    ImmutableSet .  < String > builder (  )  . addAll ( roles )  . add ( InMemoryHiveMetastore . PUBLIC _ ROLE _ NAME )  . build (  )  ;", "}", "roleGrants . put ( user ,    ImmutableSet . copyOf ( roles )  )  ;", "}", "METHOD_END"], "methodName": ["setUserRoles"], "fileName": "com.facebook.presto.hive.metastore.thrift.InMemoryHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   accessCount . get (  )  ;", "}", "METHOD_END"], "methodName": ["getAccessCount"], "fileName": "com.facebook.presto.hive.metastore.thrift.MockHiveMetastoreClient"}, {"methodBody": ["METHOD_START", "{", "this . throwException    =    throwException ;", "}", "METHOD_END"], "methodName": ["setThrowException"], "fileName": "com.facebook.presto.hive.metastore.thrift.MockHiveMetastoreClient"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( uri ,     \" metastoreUri   is   null \"  )  ;", "String   scheme    =    uri . getScheme (  )  ;", "checkArgument (  (  !  ( isNullOrEmpty ( scheme )  )  )  ,     \" metastoreUri   scheme   is   missing :     % s \"  ,    uri )  ;", "checkArgument ( scheme . equals (  \" thrift \"  )  ,     \" metastoreUri   scheme   must   be   thrift :     % s \"  ,    uri )  ;", "checkArgument (  (  ( uri . getHost (  )  )     !  =    null )  ,     \" metastoreUri   host   is   missing :     % s \"  ,    uri )  ;", "checkArgument (  (  ( uri . getPort (  )  )     !  =     (  -  1  )  )  ,     \" metastoreUri   port   is   missing :     % s \"  ,    uri )  ;", "return   uri ;", "}", "METHOD_END"], "methodName": ["checkMetastoreUri"], "fileName": "com.facebook.presto.hive.metastore.thrift.StaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "return   metastoreUris ;", "}", "METHOD_END"], "methodName": ["getMetastoreUris"], "fileName": "com.facebook.presto.hive.metastore.thrift.StaticMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "return   metastoreUsername ;", "}", "METHOD_END"], "methodName": ["getMetastoreUsername"], "fileName": "com.facebook.presto.hive.metastore.thrift.StaticMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "if    ( uris    =  =    null )     {", "this . metastoreUris    =    null ;", "return   this ;", "}", "this . metastoreUris    =    ImmutableList . copyOf ( transform (  . SPLITTER . split ( uris )  ,    URI :  : create )  )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMetastoreUris"], "fileName": "com.facebook.presto.hive.metastore.thrift.StaticMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "this . metastoreUsername    =    metastoreUsername ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMetastoreUsername"], "fileName": "com.facebook.presto.hive.metastore.thrift.StaticMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "try    {", "cluster . createMClient (  )  ;", "fail (  \" expected   exception \"  )  ;", "}    catch    ( PrestoException   e )     {", "Assertions . assertContains ( e . getMessage (  )  ,    message )  ;", "}", "}", "METHOD_END"], "methodName": ["assertCreateClientFails"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "return   new   MockHiveMetastoreClient (  )  ;", "}", "METHOD_END"], "methodName": ["createFakeMetastoreClient"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "return   new   StaticHiveCluster ( config ,    new   MockHiveMetastoreClientFactory ( Optional . empty (  )  ,    new   Duration (  1  ,    TimeUnit . SECONDS )  ,    clients )  )  ;", "}", "METHOD_END"], "methodName": ["createHiveCluster"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "HiveCluster   cluster    =    TestStaticHiveCluster . createHiveCluster ( TestStaticHiveCluster . CONFIG _ WITH _ FALLBACK ,    Collections . singletonList ( TestStaticHiveCluster . DEFAULT _ CLIENT )  )  ;", "assertEquals ( cluster . createMetastoreClient (  )  ,    TestStaticHiveCluster . DEFAULT _ CLIENT )  ;", "}", "METHOD_END"], "methodName": ["testDefaultHiveMetastore"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "HiveCluster   cluster    =    TestStaticHiveCluster . createHiveCluster ( TestStaticHiveCluster . CONFIG _ WITH _ FALLBACK ,    Arrays . asList ( null ,    null ,    TestStaticHiveCluster . FALLBACK _ CLIENT )  )  ;", "assertEquals ( cluster . createMetastoreClient (  )  ,    TestStaticHiveCluster . FALLBACK _ CLIENT )  ;", "}", "METHOD_END"], "methodName": ["testFallbackHiveMetastore"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "HiveCluster   cluster    =    TestStaticHiveCluster . createHiveCluster ( TestStaticHiveCluster . CONFIG _ WITH _ FALLBACK ,    Arrays . asList ( null ,    null ,    null )  )  ;", "TestStaticHiveCluster . assertCreateClientFails ( cluster ,     \" Failed   connecting   to   Hive   metastore :     [ default :  8  0  8  0  ,    fallback :  8  0  9  0  ,    fallback 2  :  8  0  9  0  ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["testFallbackHiveMetastoreFails"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "HiveCluster   cluster    =    TestStaticHiveCluster . createHiveCluster ( TestStaticHiveCluster . CONFIG _ WITH _ FALLBACK _ WITH _ USER ,    Arrays . asList ( null ,    null ,    TestStaticHiveCluster . FALLBACK _ CLIENT )  )  ;", "assertEquals ( cluster . createMetastoreClient (  )  ,    TestStaticHiveCluster . FALLBACK _ CLIENT )  ;", "}", "METHOD_END"], "methodName": ["testFallbackHiveMetastoreWithHiveUser"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "HiveCluster   cluster    =    TestStaticHiveCluster . createHiveCluster ( TestStaticHiveCluster . CONFIG _ WITHOUT _ FALLBACK ,    Collections . singletonList ( null )  )  ;", "TestStaticHiveCluster . assertCreateClientFails ( cluster ,     \" Failed   connecting   to   Hive   metastore :     [ default :  8  0  8  0  ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["testMetastoreFailedWithoutFallback"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "HiveCluster   cluster    =    TestStaticHiveCluster . createHiveCluster ( TestStaticHiveCluster . CONFIG _ WITHOUT _ FALLBACK _ WITH _ USER ,    Collections . singletonList ( null )  )  ;", "TestStaticHiveCluster . assertCreateClientFails ( cluster ,     \" Failed   connecting   to   Hive   metastore :     [ default :  8  0  8  0  ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["testMetastoreFailedWithoutFallbackWithHiveUser"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticHiveCluster"}, {"methodBody": ["METHOD_START", "{", "assertRecordedDefaults ( recordDefaults ( StaticMetastoreConfig . class )  . setMetastoreUris ( null )  . setMetastoreUsername ( null )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . metastore . uri \"  ,     \" thrift :  /  / localhost :  9  0  8  3  , thrift :  /  /  1  9  2  .  0  .  2  .  3  :  8  9  3  2  \"  )  . put (  \" hive . metastore . username \"  ,     \" presto \"  )  . build (  )  ;", "expected    =    new    (  )  . setMetastoreUris (  \" thrift :  /  / localhost :  9  0  8  3  , thrift :  /  /  1  9  2  .  0  .  2  .  3  :  8  9  3  2  \"  )  . setMetastoreUsername (  \" presto \"  )  ;", "assertFullMapping ( properties ,    expected )  ;", "assertEquals ( expected . getMetastoreUris (  )  ,    ImmutableList . of ( URI . create (  \" thrift :  /  / localhost :  9  0  8  3  \"  )  ,    URI . create (  \" thrift :  /  /  1  9  2  .  0  .  2  .  3  :  8  9  3  2  \"  )  )  )  ;", "assertEquals ( expected . getMetastoreUsername (  )  ,     \" presto \"  )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMappingsMultipleMetastores"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . metastore . uri \"  ,     \" thrift :  /  / localhost :  9  0  8  3  \"  )  . put (  \" hive . metastore . username \"  ,     \" presto \"  )  . build (  )  ;", "expected    =    new    (  )  . setMetastoreUris (  \" thrift :  /  / localhost :  9  0  8  3  \"  )  . setMetastoreUsername (  \" presto \"  )  ;", "assertFullMapping ( properties ,    expected )  ;", "assertEquals ( expected . getMetastoreUris (  )  ,    ImmutableList . of ( URI . create (  \" thrift :  /  / localhost :  9  0  8  3  \"  )  )  )  ;", "assertEquals ( expected . getMetastoreUsername (  )  ,     \" presto \"  )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMappingsSingleMetastore"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestStaticMetastoreConfig"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( actual . getLowValue (  )  ,    Optional . empty (  )  )  ;", "assertEquals ( actual . getHighValue (  )  ,    Optional . empty (  )  )  ;", "assertEquals ( actual . getMaxColumnLength (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getAverageColumnLength (  )  ,    OptionalDouble . empty (  )  )  ;", "assertEquals ( actual . getTrueCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getFalseCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getNullsCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getDistinctValuesCount (  )  ,    OptionalLong . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertEmptyColumnStats"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "BinaryColumnStatsData   binaryColumnStatsData    =    new   BinaryColumnStatsData (  )  ;", "binaryColumnStatsData . setMaxColLen (  1  0  0  )  ;", "binaryColumnStatsData . setAvgColLen (  4  0  )  ;", "binaryColumnStatsData . setNumNulls (  0  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . BINARY _ TYPE _ NAME ,    ColumnStatisticsData . binaryStats ( binaryColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =     . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", "assertEquals ( actual . getLowValue (  )  ,    Optional . empty (  )  )  ;", "assertEquals ( actual . getHighValue (  )  ,    Optional . empty (  )  )  ;", "assertEquals ( actual . getMaxColumnLength (  )  ,    OptionalLong . of (  1  0  0  )  )  ;", "assertEquals ( actual . getAverageColumnLength (  )  ,    OptionalDouble . of (  4  0  )  )  ;", "assertEquals ( actual . getTrueCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getFalseCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getNullsCount (  )  ,    OptionalLong . of (  0  )  )  ;", "assertEquals ( actual . getDistinctValuesCount (  )  ,    OptionalLong . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "BooleanColumnStatsData   booleanColumnStatsData    =    new   BooleanColumnStatsData (  )  ;", "booleanColumnStatsData . setNumTrues (  1  0  0  )  ;", "booleanColumnStatsData . setNumFalses (  1  0  )  ;", "booleanColumnStatsData . setNumNulls (  0  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . BOOLEAN _ TYPE _ NAME ,    ColumnStatisticsData . booleanStats ( booleanColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =     . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", "assertEquals ( actual . getLowValue (  )  ,    Optional . empty (  )  )  ;", "assertEquals ( actual . getHighValue (  )  ,    Optional . empty (  )  )  ;", "assertEquals ( actual . getMaxColumnLength (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getAverageColumnLength (  )  ,    OptionalDouble . empty (  )  )  ;", "assertEquals ( actual . getTrueCount (  )  ,    OptionalLong . of (  1  0  0  )  )  ;", "assertEquals ( actual . getFalseCount (  )  ,    OptionalLong . of (  1  0  )  )  ;", "assertEquals ( actual . getNullsCount (  )  ,    OptionalLong . of (  0  )  )  ;", "assertEquals ( actual . getDistinctValuesCount (  )  ,    OptionalLong . of (  2  )  )  ;", "}", "METHOD_END"], "methodName": ["testBooleanStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "DateColumnStatsData   dateColumnStatsData    =    new   DateColumnStatsData (  )  ;", "dateColumnStatsData . setLowValue ( new   Date (  1  0  0  0  )  )  ;", "dateColumnStatsData . setHighValue ( new   Date (  2  0  0  0  )  )  ;", "dateColumnStatsData . setNumNulls (  0  )  ;", "dateColumnStatsData . setNumDVs (  2  0  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . DATE _ TYPE _ NAME ,    ColumnStatisticsData . dateStats ( dateColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =     . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", "assertEquals ( actual . getLowValue (  )  ,    Optional . of ( LocalDate . ofEpochDay (  1  0  0  0  )  )  )  ;", "assertEquals ( actual . getHighValue (  )  ,    Optional . of ( LocalDate . ofEpochDay (  2  0  0  0  )  )  )  ;", "assertEquals ( actual . getMaxColumnLength (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getAverageColumnLength (  )  ,    OptionalDouble . empty (  )  )  ;", "assertEquals ( actual . getTrueCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getFalseCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getNullsCount (  )  ,    OptionalLong . of (  0  )  )  ;", "assertEquals ( actual . getDistinctValuesCount (  )  ,    OptionalLong . of (  2  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testDateStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "DecimalColumnStatsData   decimalColumnStatsData    =    new   DecimalColumnStatsData (  )  ;", "BigDecimal   low    =    new   BigDecimal (  \"  0  \"  )  ;", "decimalColumnStatsData . setLowValue ( new   Decimal ( ByteBuffer . wrap ( low . unscaledValue (  )  . toByteArray (  )  )  ,     (  ( short )     ( low . scale (  )  )  )  )  )  ;", "BigDecimal   high    =    new   BigDecimal (  \"  1  0  0  \"  )  ;", "decimalColumnStatsData . setHighValue ( new   Decimal ( ByteBuffer . wrap ( high . unscaledValue (  )  . toByteArray (  )  )  ,     (  ( short )     ( high . scale (  )  )  )  )  )  ;", "decimalColumnStatsData . setNumNulls (  0  )  ;", "decimalColumnStatsData . setNumDVs (  2  0  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . DECIMAL _ TYPE _ NAME ,    ColumnStatisticsData . decimalStats ( decimalColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =     . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", "assertEquals ( actual . getLowValue (  )  ,    Optional . of ( low )  )  ;", "assertEquals ( actual . getHighValue (  )  ,    Optional . of ( high )  )  ;", "assertEquals ( actual . getMaxColumnLength (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getAverageColumnLength (  )  ,    OptionalDouble . empty (  )  )  ;", "assertEquals ( actual . getTrueCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getFalseCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getNullsCount (  )  ,    OptionalLong . of (  0  )  )  ;", "assertEquals ( actual . getDistinctValuesCount (  )  ,    OptionalLong . of (  2  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testDecimalStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "DoubleColumnStatsData   doubleColumnStatsData    =    new   DoubleColumnStatsData (  )  ;", "doubleColumnStatsData . setLowValue (  0  )  ;", "doubleColumnStatsData . setHighValue (  1  0  0  )  ;", "doubleColumnStatsData . setNumNulls (  0  )  ;", "doubleColumnStatsData . setNumDVs (  2  0  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . DOUBLE _ TYPE _ NAME ,    ColumnStatisticsData . doubleStats ( doubleColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =     . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", "assertEquals ( actual . getLowValue (  )  ,    Optional . of (  0  .  0  )  )  ;", "assertEquals ( actual . getHighValue (  )  ,    Optional . of (  1  0  0  .  0  )  )  ;", "assertEquals ( actual . getMaxColumnLength (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getAverageColumnLength (  )  ,    OptionalDouble . empty (  )  )  ;", "assertEquals ( actual . getTrueCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getFalseCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getNullsCount (  )  ,    OptionalLong . of (  0  )  )  ;", "assertEquals ( actual . getDistinctValuesCount (  )  ,    OptionalLong . of (  2  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "BinaryColumnStatsData   emptyBinaryColumnStatsData    =    new   BinaryColumnStatsData (  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . BINARY _ TYPE _ NAME ,    ColumnStatisticsData . binaryStats ( emptyBinaryColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =    ThriftMetastoreUtil . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", ". assertEmptyColumnStats ( actual )  ;", "}", "METHOD_END"], "methodName": ["testEmptyBinaryStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "BooleanColumnStatsData   emptyBooleanColumnStatsData    =    new   BooleanColumnStatsData (  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . BOOLEAN _ TYPE _ NAME ,    ColumnStatisticsData . booleanStats ( emptyBooleanColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =    ThriftMetastoreUtil . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", ". assertEmptyColumnStats ( actual )  ;", "}", "METHOD_END"], "methodName": ["testEmptyBooleanStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "DateColumnStatsData   emptyDateColumnStatsData    =    new   DateColumnStatsData (  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . DATE _ TYPE _ NAME ,    ColumnStatisticsData . dateStats ( emptyDateColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =    ThriftMetastoreUtil . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", ". assertEmptyColumnStats ( actual )  ;", "}", "METHOD_END"], "methodName": ["testEmptyDateStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "DecimalColumnStatsData   emptyDecimalColumnStatsData    =    new   DecimalColumnStatsData (  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . DECIMAL _ TYPE _ NAME ,    ColumnStatisticsData . decimalStats ( emptyDecimalColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =    ThriftMetastoreUtil . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", ". assertEmptyColumnStats ( actual )  ;", "}", "METHOD_END"], "methodName": ["testEmptyDecimalStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "DoubleColumnStatsData   emptyDoubleColumnStatsData    =    new   DoubleColumnStatsData (  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . DOUBLE _ TYPE _ NAME ,    ColumnStatisticsData . doubleStats ( emptyDoubleColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =    ThriftMetastoreUtil . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", ". assertEmptyColumnStats ( actual )  ;", "}", "METHOD_END"], "methodName": ["testEmptyDoubleStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "LongColumnStatsData   emptyLongColumnStatsData    =    new   LongColumnStatsData (  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . BIGINT _ TYPE _ NAME ,    ColumnStatisticsData . longStats ( emptyLongColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =    ThriftMetastoreUtil . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", ". assertEmptyColumnStats ( actual )  ;", "}", "METHOD_END"], "methodName": ["testEmptyLongStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "StringColumnStatsData   emptyStringColumnStatsData    =    new   StringColumnStatsData (  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . STRING _ TYPE _ NAME ,    ColumnStatisticsData . stringStats ( emptyStringColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =    ThriftMetastoreUtil . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", ". assertEmptyColumnStats ( actual )  ;", "}", "METHOD_END"], "methodName": ["testEmptyStringColumnStatsData"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "LongColumnStatsData   longColumnStatsData    =    new   LongColumnStatsData (  )  ;", "longColumnStatsData . setLowValue (  0  )  ;", "longColumnStatsData . setHighValue (  1  0  0  )  ;", "longColumnStatsData . setNumNulls (  0  )  ;", "longColumnStatsData . setNumDVs (  2  0  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . BIGINT _ TYPE _ NAME ,    ColumnStatisticsData . longStats ( longColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =     . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", "assertEquals ( actual . getLowValue (  )  ,    Optional . of (  0 L )  )  ;", "assertEquals ( actual . getHighValue (  )  ,    Optional . of (  1  0  0 L )  )  ;", "assertEquals ( actual . getMaxColumnLength (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getAverageColumnLength (  )  ,    OptionalDouble . empty (  )  )  ;", "assertEquals ( actual . getTrueCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getFalseCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getNullsCount (  )  ,    OptionalLong . of (  0  )  )  ;", "assertEquals ( actual . getDistinctValuesCount (  )  ,    OptionalLong . of (  2  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "StringColumnStatsData   stringColumnStatsData    =    new   StringColumnStatsData (  )  ;", "stringColumnStatsData . setMaxColLen (  1  0  0  )  ;", "stringColumnStatsData . setAvgColLen (  4  0  )  ;", "stringColumnStatsData . setNumNulls (  0  )  ;", "stringColumnStatsData . setNumDVs (  2  0  )  ;", "ColumnStatisticsObj   columnStatisticsObj    =    new   ColumnStatisticsObj (  \" my _ col \"  ,    serdeConstants . STRING _ TYPE _ NAME ,    ColumnStatisticsData . stringStats ( stringColumnStatsData )  )  ;", "HiveColumnStatistics   actual    =     . fromMetastoreApiColumnStatistics ( columnStatisticsObj )  ;", "assertEquals ( actual . getLowValue (  )  ,    Optional . empty (  )  )  ;", "assertEquals ( actual . getHighValue (  )  ,    Optional . empty (  )  )  ;", "assertEquals ( actual . getMaxColumnLength (  )  ,    OptionalLong . of (  1  0  0  )  )  ;", "assertEquals ( actual . getAverageColumnLength (  )  ,    OptionalDouble . of (  4  0  )  )  ;", "assertEquals ( actual . getTrueCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getFalseCount (  )  ,    OptionalLong . empty (  )  )  ;", "assertEquals ( actual . getNullsCount (  )  ,    OptionalLong . of (  0  )  )  ;", "assertEquals ( actual . getDistinctValuesCount (  )  ,    OptionalLong . of (  2  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testStringStatsToColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "deleteRecursly ( dir . toPath (  )  ,    ALLOW _ INSECURE )  ;", "}    catch    ( IOException   e )     {", "throw   new   UncheckedIOException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["deleteDirectory"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Table   oldTable    =    relations . get ( tableName )  ;", "if    ( oldTable    =  =    null )     {", "throw   new   spi . TableNotFoundException ( tableName )  ;", "}", "return   oldTable ;", "}", "METHOD_END"], "methodName": ["getRequiredTable"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( Database . DEFAULT _ DATABASE _ NAME . equalsIgnoreCase ( databaseName )  )     {", "return   true ;", "}", "Optional < Database >    databasdata    =    getDatabase ( databaseName )  ;", "if    (  !  ( databasdata . isPresent (  )  )  )     {", "return   false ;", "}", "Database   database    =    databasdata . get (  )  ;", "if    (  (  ( database . getOwnerType (  )  )     =  =     ( PrincipalType . USER )  )     &  &     ( user . equals ( database . getOwnerName (  )  )  )  )     {", "return   true ;", "}", "if    (  (  ( database . getOwnerType (  )  )     =  =     ( PrincipalType . ROLE )  )     &  &     ( getRoles ( user )  . contains ( database . getOwnerName (  )  )  )  )     {", "return   true ;", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isDatabaseOwner"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   directory . toPath (  )  . startsWith ( baseDirectory . toPath (  )  )  ;", "}", "METHOD_END"], "methodName": ["isParentDir"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "Optional < Table >    table    =    getTable ( databaseName ,    tableName )  ;", "return    ( table . isPent (  )  )     &  &     ( user . equals ( table . get (  )  . getOwner (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["isTableOwner"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    (  (  !  ( partition . getDatabaseName (  )  . equals ( databaseName )  )  )     |  |     (  !  ( partition . getTableName (  )  . equals ( tableName )  )  )  )     {", "return   false ;", "}", "List < Str >    values    =    partition . getValues (  )  ;", "if    (  ( values . size (  )  )     !  =     ( parts . size (  )  )  )     {", "return   false ;", "}", "for    ( int   i    =     0  ;    i    <     ( values . size (  )  )  ;    i +  +  )     {", "Str   part    =    parts . get ( i )  ;", "if    (  (  !  ( part . isEmpty (  )  )  )     &  &     (  !  ( values . get ( i )  . equals ( part )  )  )  )     {", "return   false ;", "}", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["partitionMatches"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "tablePrivileges . put ( new   TestingHiveMetastore . PrincipalTableKey ( principalName ,    principalType ,    tableName ,    databaseName )  ,    ImmutableSet . copyOf ( privileges )  )  ;", "}", "METHOD_END"], "methodName": ["setTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "roleGrants . put ( user ,    roles )  ;", "}", "METHOD_END"], "methodName": ["setUserRoles"], "fileName": "com.facebook.presto.hive.metastore.thrift.TestingHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < HiveObjectPrivilege >    privilegeBagBuilder    =    ImmutableList . builder (  )  ;", "for    ( PrivilegeGrantInfo   privilegeGrantInfo    :    privilegeGrantInfos )     {", "privilegeBagBuilder . add ( new   HiveObjectPrivilege ( new   HiveObjectRef ( HiveObjectType . TABLE ,    databaseName ,    tableName ,    null ,    null )  ,    hivePrincipal . getPrincipalName (  )  ,    hivePrincipal . getPrincipalType (  )  ,    privilegeGrantInfo )  )  ;", "}", "return   new   PrivilegeBag ( privilegeBagBuilder . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["buildPrivilegeBag"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   requestedPrivileges . stream (  )  . anyMatch (  (    privilege )     -  >    privilege . getPrivilege (  )  . equalsIgnoreCase (  \" all \"  )  )  ;", "}", "METHOD_END"], "methodName": ["containsAllPrivilege"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( hivePrincipal . getPrincipalType (  )  )     =  =     ( PrincipalType . ROLE )  )  ,     \" Expected   ROLE   PrincipalType   but   found   USER \"  )  ;", "try    {", "return   retry (  )  . stopOnIllegalExceptions (  )  . run (  \" getListPrivileges \"  ,    stats . getListPrivileges (  )  . wrap (  (  )     -  >     {", "try    ( HiveMetastoreClient   client    =    clientProvider . createMetastoreClient (  )  )     {", "ImmutableSet . Builder < HivePrivilegeInfo >    privileges    =    ImmutableSet . builder (  )  ;", "List < HiveObjectPrivilege >    hiveObjectPrivilegeList    =    client . listPrivileges ( hivePrincipal . getPrincipalName (  )  ,    hivePrincipal . getPrincipalType (  )  ,    hiveObjectRef )  ;", "for    ( HiveObjectPrivilege   hiveObjectPrivilege    :    hiveObjectPrivilegeList )     {", "privileges . addAll ( HivePrivilegeInfo . parsePrivilege ( hiveObjectPrivilege . getGrantInfo (  )  )  )  ;", "}", "return   privileges . build (  )  ;", "}", "}  )  )  ;", "}    catch    ( TException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,    e )  ;", "}    catch    ( Exception   e )     {", "throw   propagate ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["getRolePrivileges"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   stats ;", "}", "METHOD_END"], "methodName": ["getStats"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    (  ( hivePrincipal . getPrincipalType (  )  )     =  =     ( PrincipalType . ROLE )  )     {", "return   getRolePrivileges ( hivePrincipal ,    new   HiveObjectRef ( HiveObjectType . TABLE ,    databaseName ,    tableName ,    null ,    null )  )  ;", "} else    {", "return   getUserPrivileges ( hivePrincipal ,    new   HiveObjectRef ( HiveObjectType . TABLE ,    databaseName ,    tableName ,    null ,    null )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( hivePrincipal . getPrincipalType (  )  )     =  =     ( PrincipalType . USER )  )  ,     \" Expected   USER   PrincipalType   but   found   ROLE \"  )  ;", "try    {", "return   retry (  )  . stopOnIllegalExceptions (  )  . run (  \" getPrivilegeSet \"  ,    stats . getGetPrivilegeSet (  )  . wrap (  (  )     -  >     {", "try    ( HiveMetastoreClient   client    =    clientProvider . createMetastoreClient (  )  )     {", "ImmutableSet . Builder < HivePrivilegeInfo >    privileges    =    ImmutableSet . builder (  )  ;", "String   principalName    =    hivePrincipal . getPrincipalName (  )  ;", "PrincipalPrivilegeSet   privilegeSet    =    client . getPrivilegeSet ( objectReference ,    principalName ,    null )  ;", "if    ( privilegeSet    !  =    null )     {", "Map < String ,    List < PrivilegeGrantInfo >  >    userPrivileges    =    privilegeSet . getUserPrivileges (  )  ;", "if    ( userPrivileges    !  =    null )     {", "privileges . addAll ( ThriftMetastoreUtil . toGrants ( userPrivileges . get ( principalName )  )  )  ;", "}", "Map < String ,    List < PrivilegeGrantInfo >  >    rolePrivilegesMap    =    privilegeSet . getRolePrivileges (  )  ;", "if    ( rolePrivilegesMap    !  =    null )     {", "for    ( List < PrivilegeGrantInfo >    rolePrivileges    :    rolePrivilegesMap . values (  )  )     {", "privileges . addAll ( ThriftMetastoreUtil . toGrants ( rolePrivileges )  )  ;", "}", "}", "}", "return   privileges . build (  )  ;", "}", "}  )  )  ;", "}    catch    ( TException   e )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ METASTORE _ ERROR ,    e )  ;", "}    catch    ( Exception   e )     {", "throw   propagate ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["getUserPrivileges"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return    \" true \"  . equals ( table . getParameters (  )  . get ( HiveUtil . PRESTO _ VIEW _ FLAG )  )  ;", "}", "METHOD_END"], "methodName": ["isPrestoView"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "if    ( throwable   instanceof   InterruptedException )     {", "Thread . currentThread (  )  . interrupt (  )  ;", "}", "throw   Throwables . propagate ( throwable )  ;", "}", "METHOD_END"], "methodName": ["propagate"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   RetryDriver . retry (  )  . exceptionMapper ( exceptionMapper )  . stopOn ( PrestoException . class )  ;", "}", "METHOD_END"], "methodName": ["retry"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore"}, {"methodBody": ["METHOD_START", "{", "return   addPartitions ;", "}", "METHOD_END"], "methodName": ["getAddPartitions"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   alterDatabase ;", "}", "METHOD_END"], "methodName": ["getAlterDatabase"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   alterPartition ;", "}", "METHOD_END"], "methodName": ["getAlterPartition"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   alterTable ;", "}", "METHOD_END"], "methodName": ["getAlterTable"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   createDatabase ;", "}", "METHOD_END"], "methodName": ["getCreateDatabase"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   createTable ;", "}", "METHOD_END"], "methodName": ["getCreateTable"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   dropDatabase ;", "}", "METHOD_END"], "methodName": ["getDropDatabase"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   dropPartition ;", "}", "METHOD_END"], "methodName": ["getDropPartition"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   dropTable ;", "}", "METHOD_END"], "methodName": ["getDropTable"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getAllDatabases ;", "}", "METHOD_END"], "methodName": ["getGetAllDatabases"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getAllTables ;", "}", "METHOD_END"], "methodName": ["getGetAllTables"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getAllViews ;", "}", "METHOD_END"], "methodName": ["getGetAllViews"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getDatabase ;", "}", "METHOD_END"], "methodName": ["getGetDatabase"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getPartition ;", "}", "METHOD_END"], "methodName": ["getGetPartition"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getPartitionColumnStatistics ;", "}", "METHOD_END"], "methodName": ["getGetPartitionColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getPartitionNames ;", "}", "METHOD_END"], "methodName": ["getGetPartitionNames"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getPartitionNamesPs ;", "}", "METHOD_END"], "methodName": ["getGetPartitionNamesPs"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getPartitionsByNames ;", "}", "METHOD_END"], "methodName": ["getGetPartitionsByNames"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getPrivilegeSet ;", "}", "METHOD_END"], "methodName": ["getGetPrivilegeSet"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getTable ;", "}", "METHOD_END"], "methodName": ["getGetTable"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   getTableColumnStatistics ;", "}", "METHOD_END"], "methodName": ["getGetTableColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   grantTablePrivileges ;", "}", "METHOD_END"], "methodName": ["getGrantTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   listPrivileges ;", "}", "METHOD_END"], "methodName": ["getListPrivileges"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   loadRoles ;", "}", "METHOD_END"], "methodName": ["getLoadRoles"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "return   revokeTablePrivileges ;", "}", "METHOD_END"], "methodName": ["getRevokeTablePrivileges"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreStats"}, {"methodBody": ["METHOD_START", "{", "if    ( columnStatistics . getStatsData (  )  . isSetLongStats (  )  )     {", "LongColumnStatsData   longStatsData    =    columnStatistics . getStatsData (  )  . getLongStats (  )  ;", "return   new   HiveColumnStatistics (  ( longStatsData . isSetLowValue (  )     ?    Optional . of ( longStatsData . getLowValue (  )  )     :    Optional . empty (  )  )  ,     ( longStatsData . isSetHighValue (  )     ?    Optional . of ( longStatsData . getHighValue (  )  )     :    Optional . empty (  )  )  ,    OptionalLong . empty (  )  ,    OptionalDouble . empty (  )  ,    OptionalLong . empty (  )  ,    OptionalLong . empty (  )  ,     ( longStatsData . isSetNumNulls (  )     ?    OptionalLong . of ( longStatsData . getNumNulls (  )  )     :    OptionalLong . empty (  )  )  ,     ( longStatsData . isSetNumDVs (  )     ?    OptionalLong . of ( longStatsData . getNumDVs (  )  )     :    OptionalLong . empty (  )  )  )  ;", "} else", "if    ( columnStatistics . getStatsData (  )  . isSetDoubleStats (  )  )     {", "DoubleColumnStatsData   doubleStatsData    =    columnStatistics . getStatsData (  )  . getDoubleStats (  )  ;", "return   new   HiveColumnStatistics (  ( doubleStatsData . isSetLowValue (  )     ?    Optional . of ( doubleStatsData . getLowValue (  )  )     :    Optional . empty (  )  )  ,     ( doubleStatsData . isSetHighValue (  )     ?    Optional . of ( doubleStatsData . getHighValue (  )  )     :    Optional . empty (  )  )  ,    OptionalLong . empty (  )  ,    OptionalDouble . empty (  )  ,    OptionalLong . empty (  )  ,    OptionalLong . empty (  )  ,     ( doubleStatsData . isSetNumNulls (  )     ?    OptionalLong . of ( doubleStatsData . getNumNulls (  )  )     :    OptionalLong . empty (  )  )  ,     ( doubleStatsData . isSetNumDVs (  )     ?    OptionalLong . of ( doubleStatsData . getNumDVs (  )  )     :    OptionalLong . empty (  )  )  )  ;", "} else", "if    ( columnStatistics . getStatsData (  )  . isSetDecimalStats (  )  )     {", "DecimalColumnStatsData   decimalStatsData    =    columnStatistics . getStatsData (  )  . getDecimalStats (  )  ;", "return   new   HiveColumnStatistics (  ( decimalStatsData . isSetLowValue (  )     ?    ThriftMetastoreUtil . fromMetastoreDecimal ( decimalStatsData . getLowValue (  )  )     :    Optional . empty (  )  )  ,     ( decimalStatsData . isSetHighValue (  )     ?    ThriftMetastoreUtil . fromMetastoreDecimal ( decimalStatsData . getHighValue (  )  )     :    Optional . empty (  )  )  ,    OptionalLong . empty (  )  ,    OptionalDouble . empty (  )  ,    OptionalLong . empty (  )  ,    OptionalLong . empty (  )  ,     ( decimalStatsData . isSetNumNulls (  )     ?    OptionalLong . of ( decimalStatsData . getNumNulls (  )  )     :    OptionalLong . empty (  )  )  ,     ( decimalStatsData . isSetNumDVs (  )     ?    OptionalLong . of ( decimalStatsData . getNumDVs (  )  )     :    OptionalLong . empty (  )  )  )  ;", "} else", "if    ( columnStatistics . getStatsData (  )  . isSetBooleanStats (  )  )     {", "BooleanColumnStatsData   booleanStatsData    =    columnStatistics . getStatsData (  )  . getBooleanStats (  )  ;", "return   new   HiveColumnStatistics ( Optional . empty (  )  ,    Optional . empty (  )  ,    OptionalLong . empty (  )  ,    OptionalDouble . empty (  )  ,     ( booleanStatsData . isSetNumTrues (  )     ?    OptionalLong . of ( booleanStatsData . getNumTrues (  )  )     :    OptionalLong . empty (  )  )  ,     ( booleanStatsData . isSetNumFalses (  )     ?    OptionalLong . of ( booleanStatsData . getNumFalses (  )  )     :    OptionalLong . empty (  )  )  ,     ( booleanStatsData . isSetNumNulls (  )     ?    OptionalLong . of ( booleanStatsData . getNumNulls (  )  )     :    OptionalLong . empty (  )  )  ,     (  ( booleanStatsData . isSetNumFalses (  )  )     &  &     ( booleanStatsData . isSetNumTrues (  )  )     ?    OptionalLong . of (  (  (  ( booleanStatsData . getNumFalses (  )  )     >     0     ?     1     :     0  )     +     (  ( booleanStatsData . getNumTrues (  )  )     >     0     ?     1     :     0  )  )  )     :    OptionalLong . empty (  )  )  )  ;", "} else", "if    ( columnStatistics . getStatsData (  )  . isSetDateStats (  )  )     {", "DateColumnStatsData   dateStatsData    =    columnStatistics . getStatsData (  )  . getDateStats (  )  ;", "return   new   HiveColumnStatistics (  ( dateStatsData . isSetLowValue (  )     ?    ThriftMetastoreUtil . fromMetastoreDate ( dateStatsData . getLowValue (  )  )     :    Optional . empty (  )  )  ,     ( dateStatsData . isSetHighValue (  )     ?    ThriftMetastoreUtil . fromMetastoreDate ( dateStatsData . getHighValue (  )  )     :    Optional . empty (  )  )  ,    OptionalLong . empty (  )  ,    OptionalDouble . empty (  )  ,    OptionalLong . empty (  )  ,    OptionalLong . empty (  )  ,     ( dateStatsData . isSetNumNulls (  )     ?    OptionalLong . of ( dateStatsData . getNumNulls (  )  )     :    OptionalLong . empty (  )  )  ,     ( dateStatsData . isSetNumDVs (  )     ?    OptionalLong . of ( dateStatsData . getNumDVs (  )  )     :    OptionalLong . empty (  )  )  )  ;", "} else", "if    ( columnStatistics . getStatsData (  )  . isSetStringStats (  )  )     {", "StringColumnStatsData   stringStatsData    =    columnStatistics . getStatsData (  )  . getStringStats (  )  ;", "return   new   HiveColumnStatistics ( Optional . empty (  )  ,    Optional . empty (  )  ,     ( stringStatsData . isSetMaxColLen (  )     ?    OptionalLong . of ( stringStatsData . getMaxColLen (  )  )     :    OptionalLong . empty (  )  )  ,     ( stringStatsData . isSetAvgColLen (  )     ?    OptionalDouble . of ( stringStatsData . getAvgColLen (  )  )     :    OptionalDouble . empty (  )  )  ,    OptionalLong . empty (  )  ,    OptionalLong . empty (  )  ,     ( stringStatsData . isSetNumNulls (  )     ?    OptionalLong . of ( stringStatsData . getNumNulls (  )  )     :    OptionalLong . empty (  )  )  ,     ( stringStatsData . isSetNumDVs (  )     ?    OptionalLong . of ( stringStatsData . getNumDVs (  )  )     :    OptionalLong . empty (  )  )  )  ;", "} else", "if    ( columnStatistics . getStatsData (  )  . isSetBinaryStats (  )  )     {", "BinaryColumnStatsData   binaryStatsData    =    columnStatistics . getStatsData (  )  . getBinaryStats (  )  ;", "return   new   HiveColumnStatistics ( Optional . empty (  )  ,    Optional . empty (  )  ,     ( binaryStatsData . isSetMaxColLen (  )     ?    OptionalLong . of ( binaryStatsData . getMaxColLen (  )  )     :    OptionalLong . empty (  )  )  ,     ( binaryStatsData . isSetAvgColLen (  )     ?    OptionalDouble . of ( binaryStatsData . getAvgColLen (  )  )     :    OptionalDouble . empty (  )  )  ,    OptionalLong . empty (  )  ,    OptionalLong . empty (  )  ,     ( binaryStatsData . isSetNumNulls (  )     ?    OptionalLong . of ( binaryStatsData . getNumNulls (  )  )     :    OptionalLong . empty (  )  )  ,    OptionalLong . empty (  )  )  ;", "} else    {", "throw   new   com . facebook . presto . spi . PrestoException ( com . facebook . presto . hive . HiveErrorCode . HIVE _ INVALID _ METADATA ,     (  \" Invalid   column   statistics   data :     \"     +    columnStatistics )  )  ;", "}", "}", "METHOD_END"], "methodName": ["fromMetastoreApiColumnStatistics"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "String   ownerName    =     \" PUBLIC \"  ;", "PrincipalType   ownerType    =    PrincipalType . ROLE ;", "if    (  ( database . getOwnerName (  )  )     !  =    null )     {", "ownerName    =    database . getOwnerName (  )  ;", "ownerType    =     . fromMetastoreApiPrincipalType ( database . getOwnerType (  )  )  ;", "}", "Map < String ,    String >    parameters    =    database . getParameters (  )  ;", "if    ( parameters    =  =    null )     {", "parameters    =    ImmutableMap . of (  )  ;", "}", "return   Database . builder (  )  . setDatabaseName ( database . getName (  )  )  . setLocation ( Optional . ofNullable ( database . getLocationUri (  )  )  )  . setOwnerName ( ownerName )  . setOwnerType ( ownerType )  . setComment ( Optional . ofNullable ( database . getDescription (  )  )  )  . setParameters ( parameters )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["fromMetastoreApiDatabase"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "return   new   Column ( fieldSchema . getName (  )  ,    HiveType . valueOf ( fieldSchema . getType (  )  )  ,    Optional . ofNullable ( emptyToNull ( fieldSchema . getComment (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["fromMetastoreApiFieldSchema"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "StorageDescriptor   storageDescriptor    =    partition . getSd (  )  ;", "if    ( storageDescriptor    =  =    null )     {", "throw   new   spi . PrestoException ( HiveErrorCode . HIVE _ INVALID _ METADATA ,     (  \" Partition   does   not   contain   a   storage   descriptor :     \"     +    partition )  )  ;", "}", "Partition . Builder   partitionBuilder    =    Partition . builder (  )  . setDatabaseName ( partition . getDbName (  )  )  . setTableName ( partition . getTableName (  )  )  . setValues ( partition . getValues (  )  )  . setColumns ( storageDescriptor . getCols (  )  . stream (  )  . map ( ThriftMetastoreUtil :  : fromMetastoreApiFieldSchema )  . collect ( Collectors . toList (  )  )  )  . setParameters ( partition . getParameters (  )  )  ;", "ThriftMetastoreUtil . fromMetastoreApiStorageDescriptor ( storageDescriptor ,    partitionBuilder . getStorageBuilder (  )  ,    String . format (  \"  % s .  % s \"  ,    partition . getTableName (  )  ,    partition . getValues (  )  )  )  ;", "return   partitionBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["fromMetastoreApiPartition"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "switch    ( principalType )     {", "case   USER    :", "return   PrincipalType . USER ;", "case   ROLE    :", "return   PrincipalType . ROLE ;", "default    :", "ow   new   IllegalArgumentException (  (  \" Unsupported   principal   type :     \"     +    principalType )  )  ;", "}", "}", "METHOD_END"], "methodName": ["fromMetastoreApiPrincipalType"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "SerDeInfo   serdeInfo    =    storageDescriptor . getSerdeInfo (  )  ;", "if    ( serdeInfo    =  =    null )     {", "throw   new   PException ( HiveErrorCode . HIVE _ INVALID _ METADATA ,     \" Table   storage   descriptor   is   missing   SerDe   info \"  )  ;", "}", "builder . setStorageFormat ( StorageFormat . createNullable ( serdeInfo . getSerializationLib (  )  ,    storageDescriptor . getInputFormat (  )  ,    storageDescriptor . getOutputFormat (  )  )  )  . setLocation ( nullToEmpty ( storageDescriptor . getLocation (  )  )  )  . setBucketProperty ( HiveBucketProperty . fromStorageDescriptor ( storageDescriptor ,    tablePartitionName )  )  . setSorted (  (  ( storageDescriptor . isSetSortCols (  )  )     &  &     (  !  ( storageDescriptor . getSortCols (  )  . isEmpty (  )  )  )  )  )  . setSkewed (  (  (  ( storageDescriptor . isSetSkewedInfo (  )  )     &  &     ( storageDescriptor . getSkewedInfo (  )  . isSetSkewedColNames (  )  )  )     &  &     (  !  ( storageDescriptor . getSkewedInfo (  )  . getSkewedColNames (  )  . isEmpty (  )  )  )  )  )  . setSerdeParameters (  (  ( serdeInfo . getParameters (  )  )     =  =    null    ?    ImmutableMap . of (  )     :    serdeInfo . getParameters (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["fromMetastoreApiStorageDescriptor"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "StorageDescriptor   storageDescriptor    =    table . getSd (  )  ;", "if    ( storageDescriptor    =  =    null )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ INVALID _ METADATA ,     \" Table   is   missing   storage   descriptor \"  )  ;", "}", "Table . Builder   tableBuilder    =    Table . builder (  )  . setDatabaseName ( table . getDbName (  )  )  . setTableName ( table . getTableName (  )  )  . setOwner ( nullToEmpty ( table . getOwner (  )  )  )  . setTableType ( table . getTableType (  )  )  . setDataColumns ( storageDescriptor . getCols (  )  . stream (  )  . map (  :  : fromMetastoreApiFieldSchema )  . collect ( Collectors . toList (  )  )  )  . setPartitionColumns ( table . getPartitionKeys (  )  . stream (  )  . map (  :  : fromMetastoreApiFieldSchema )  . collect ( Collectors . toList (  )  )  )  . setParameters (  (  ( table . getParameters (  )  )     =  =    null    ?    ImmutableMap . of (  )     :    table . getParameters (  )  )  )  . setViewOriginalText ( Optional . ofNullable ( emptyToNull ( table . getViewOriginalText (  )  )  )  )  . setViewExpandedText ( Optional . ofNullable ( emptyToNull ( table . getViewExpandedText (  )  )  )  )  ;", ". fromMetastoreApiStorageDescriptor ( storageDescriptor ,    tableBuilder . getStorageBuilder (  )  ,    table . getTableName (  )  )  ;", "return   tableBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["fromMetastoreApiTable"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "if    ( date    =  =    null )     {", "return   Optional . empty (  )  ;", "}", "return   Optional . of ( LocalDate . ofEpochDay ( date . getDaysSinceEpoch (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["fromMetastoreDate"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "if    ( decimal    =  =    null )     {", "return   Optional . empty (  )  ;", "}", "return   Optional . of ( new   BigDecimal ( new   BigInteger ( decimal . getUnscaled (  )  )  ,    decimal . getScale (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["fromMetastoreDecimal"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "if    (  ( storage . isSorted (  )  )     |  |     ( storage . isSkewed (  )  )  )     {", "throw   new   IllegalArgumentException (  \" Writing   to   sorted   and / or   skewed   table / partition   is   not   supported \"  )  ;", "}", "SerDeInfo   serdeInfo    =    new   SerDeInfo (  )  ;", "serdeInfo . setName ( tableName )  ;", "serdeInfo . setSerializationLib ( storage . getStorageFormat (  )  . getSerDeNullable (  )  )  ;", "serdeInfo . setParameters ( storage . getSerdeParameters (  )  )  ;", "StorageDescriptor   sd    =    new   StorageDescriptor (  )  ;", "sd . setLocation ( emptyToNull ( storage . getLocation (  )  )  )  ;", "sd . setCols ( columns . stream (  )  . map (  :  : toMetastoreApiFieldSchema )  . collect ( Collectors . toList (  )  )  )  ;", "sd . setSerdeInfo ( serdeInfo )  ;", "sd . setInputFormat ( storage . getStorageFormat (  )  . getInputFormatNullable (  )  )  ;", "sd . setOutputFormat ( storage . getStorageFormat (  )  . getOutputFormatNullable (  )  )  ;", "sd . setParameters ( ImmutableMap . of (  )  )  ;", "Optional < HiveBucketProperty >    bucketProperty    =    storage . getBucketProperty (  )  ;", "if    ( bucketProperty . isPresent (  )  )     {", "sd . setNumBuckets ( bucketProperty . get (  )  . getBucketCount (  )  )  ;", "sd . setBucketCols ( bucketProperty . get (  )  . getBucketedBy (  )  )  ;", "}", "return   sd ;", "}", "METHOD_END"], "methodName": ["makeStorageDescriptor"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "if    ( userGrants    =  =    null )     {", "return   ImmutableSet . of (  )  ;", "}", "ImmutableSet . Builder < HPrivilegeInfo >    privileges    =    ImmutableSet . builder (  )  ;", "for    ( PrivilegeGrantInfo   userGrant    :    userGrants )     {", "privileges . addAll ( HPrivilegeInfo . parsePrivilege ( userGrant )  )  ;", "}", "return   privileges . build (  )  ;", "}", "METHOD_END"], "methodName": ["toGrants"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Database   result    =    new   Database (  )  ;", "result . setName ( database . getDatabaseName (  )  )  ;", "database . getLocation (  )  . ifPresent ( result :  : setLocationUri )  ;", "result . setOwnerName ( database . getOwnerName (  )  )  ;", "result . setOwnerType (  . toMetastoreApiPrincipalType ( database . getOwnerType (  )  )  )  ;", "database . getComment (  )  . ifPresent ( result :  : setDescription )  ;", "result . setParameters ( database . getParameters (  )  )  ;", "return   result ;", "}", "METHOD_END"], "methodName": ["toMetastoreApiDatabase"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "return   new   FieldSchema ( column . getName (  )  ,    column . getType (  )  . getHiveTypeName (  )  . toString (  )  ,    column . getComment (  )  . orElse ( null )  )  ;", "}", "METHOD_END"], "methodName": ["toMetastoreApiFieldSchema"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Partition   result    =    new   Partition (  )  ;", "result . setDbName ( partition . getDatabaseName (  )  )  ;", "result . setTableName ( partition . getTableName (  )  )  ;", "result . setValues ( partition . getValues (  )  )  ;", "result . setSd (  . makeStorageDescriptor ( partition . getTableName (  )  ,    partition . getColumns (  )  ,    partition . getStorage (  )  )  )  ;", "result . setParameters ( partition . getParameters (  )  )  ;", "return   result ;", "}", "METHOD_END"], "methodName": ["toMetastoreApiPartition"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Builder < String ,    List < PrivilegeGrantInfo >  >    userPrivileges    =    ImmutableMap . builder (  )  ;", "for    ( Map . Entry < String ,    Collection < HivePrivilegeInfo >  >    entry    :    privileges . getUserPrivileges (  )  . asMap (  )  . entrySet (  )  )     {", "userPrivileges . put ( entry . getKey (  )  ,    entry . getValue (  )  . stream (  )  . map (  (    privilegeInfo )     -  >     . toMetastoreApiPrivilegeGrantInfo ( grantee ,    privilegeInfo )  )  . collect ( Collectors . toList (  )  )  )  ;", "}", "Builder < String ,    List < PrivilegeGrantInfo >  >    rolePrivileges    =    ImmutableMap . builder (  )  ;", "for    ( Map . Entry < String ,    Collection < HivePrivilegeInfo >  >    entry    :    privileges . getRolePrivileges (  )  . asMap (  )  . entrySet (  )  )     {", "rolePrivileges . put ( entry . getKey (  )  ,    entry . getValue (  )  . stream (  )  . map (  (    privilegeInfo )     -  >     . toMetastoreApiPrivilegeGrantInfo ( grantee ,    privilegeInfo )  )  . collect ( Collectors . toList (  )  )  )  ;", "}", "return   new   PrincipalPrivilegeSet ( userPrivileges . build (  )  ,    ImmutableMap . of (  )  ,    rolePrivileges . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["toMetastoreApiPrincipalPrivilegeSet"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "switch    ( principalType )     {", "case   USER    :", "return   PrincipalType ;", "case   ROLE    :", "return   PrincipalType ;", "default    :", "throw   new   IllegalArgumentException (  (  \" Unsupported   principal   type :     \"     +    principalType )  )  ;", "}", "}", "METHOD_END"], "methodName": ["toMetastoreApiPrincipalType"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "return   new    < PrincipalType > PrivilegeGrantInfo ( privilegeInfo . getHivePrivilege (  )  . name (  )  . toLowerCase (  )  ,     0  ,    grantee ,    privilegeInfo . isGrantOption (  )  )  ;", "}", "METHOD_END"], "methodName": ["toMetastoreApiPrivilegeGrantInfo"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "Table   result    =    new   Table (  )  ;", "result . setDbName ( table . getDatabaseName (  )  )  ;", "result . setTableName ( table . getTableName (  )  )  ;", "result . setOwner ( table . getOwner (  )  )  ;", "result . setTableType ( table . getTableType (  )  )  ;", "result . setParameters ( table . getParameters (  )  )  ;", "result . setPartitionKeys ( table . getPartitionColumns (  )  . stream (  )  . map (  :  : toMetastoreApiFieldSchema )  . collect ( Collectors . toList (  )  )  )  ;", "result . setSd (  . makeStorageDescriptor ( table . getTableName (  )  ,    table . getDataColumns (  )  ,    table . getStorage (  )  )  )  ;", "result . setPrivileges (  . toMetastoreApiPrincipalPrivilegeSet ( table . getOwner (  )  ,    privileges )  )  ;", "result . setViewOriginalText ( table . getViewOriginalText (  )  . orElse ( null )  )  ;", "result . setViewExpandedText ( table . getViewExpandedText (  )  . orElse ( null )  )  ;", "return   result ;", "}", "METHOD_END"], "methodName": ["toMetastoreApiTable"], "fileName": "com.facebook.presto.hive.metastore.thrift.ThriftMetastoreUtil"}, {"methodBody": ["METHOD_START", "{", "try    {", "T   raw    =     . createRaw ( address ,    sslContext ,    socksProxy ,    timeoutMillis )  ;", "T   authenticated    =    authentication . authenticate ( raw ,    address . getHost (  )  )  ;", "if    (  !  ( authenticated . isOpen (  )  )  )     {", "authenticated . open (  )  ;", "}", "return   new    . TWrapper ( authenticated ,    address )  ;", "}    catch    ( TException   e )     {", "throw    . rewriteException ( e ,    address )  ;", "}", "}", "METHOD_END"], "methodName": ["create"], "fileName": "com.facebook.presto.hive.metastore.thrift.Transport"}, {"methodBody": ["METHOD_START", "{", "Proxy   proxy    =    socksProxy . map (  (    socksAddress )     -  >    new   Proxy ( SOCKS ,    InetSocketAddress . createUnresolved ( socksAddress . getHost (  )  ,    socksAddress . getPort (  )  )  )  )  . orElse ( Proxy . NO _ PROXY )  ;", "Socket   socket    =    new   Socket ( proxy )  ;", "try    {", "socket . connect ( new   InetSocketAddress ( address . getHost (  )  ,    address . getPort (  )  )  ,    timeoutMillis )  ;", "socket . setSoTimeout ( timeoutMillis )  ;", "if    ( sslContext . isPresent (  )  )     {", "HostAndPort   sslConnectAddress    =    socksProxy . orElse ( address )  ;", "socket    =    sslContext . get (  )  . getSocketFactory (  )  . createSocket ( socket ,    sslConnectAddress . getHost (  )  ,    sslConnectAddress . getPort (  )  ,    true )  ;", "}", "return   new   TSocket ( socket )  ;", "}    catch    ( Throwable   t )     {", "try    {", "socket . close (  )  ;", "}    catch    ( IOException   e )     {", "t . addSuppressed ( e )  ;", "}", "throw   new   TException ( t )  ;", "}", "}", "METHOD_END"], "methodName": ["createRaw"], "fileName": "com.facebook.presto.hive.metastore.thrift.Transport"}, {"methodBody": ["METHOD_START", "{", "return   new   TTransportException ( e . getType (  )  ,    String . format (  \"  % s :     % s \"  ,    address ,    e . getMessage (  )  )  ,    e . getCause (  )  )  ;", "}", "METHOD_END"], "methodName": ["rewriteException"], "fileName": "com.facebook.presto.hive.metastore.thrift.Transport"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( throwable ,     \" throwable   is   null \"  )  ;", "try    {", "close (  )  ;", "}    catch    ( RuntimeException   e )     {", "if    ( throwable    !  =    e )     {", "throwable . addSupsed ( e )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["closeWithSuppression"], "fileName": "com.facebook.presto.hive.orc.OrcPageSource"}, {"methodBody": ["METHOD_START", "{", "Builder < String ,    Integer >    physicalNameOrdinalMap    =    ImmutableMap . builder (  )  ;", "int   ordinal    =     0  ;", "for    ( String   physicalColumnName    :    reader . getColumnNames (  )  )     {", "physicalNameOrdinalMap . put ( physicalColumnName ,    ordinal )  ;", "ordinal +  +  ;", "}", "return   physicalNameOrdinalMap . build (  )  ;", "}", "METHOD_END"], "methodName": ["buildPhysicalNameOrdinalMap"], "fileName": "com.facebook.presto.hive.orc.OrcPageSourceFactory"}, {"methodBody": ["METHOD_START", "{", "OrcDataSource   orcDataSource ;", "try    {", "FileSystem   fileSystem    =    hdfsEnvironment . getFileSystem ( sessionUser ,    path ,    configuration )  ;", "FSDataInputStream   inputStream    =    fileSystem . open ( path )  ;", "orcDataSource    =    new   HdfsOrcDataSource ( new   orc . OrcDataSourceId ( path . toString (  )  )  ,    fileSize ,    maxMergeDistance ,    maxBufferSize ,    streamBufferSize ,    lazyReadSmallRanges ,    inputStream ,    stats )  ;", "}    catch    ( Exception   e )     {", "if    (  ( nullToEmpty ( e . getMessage (  )  )  . trim (  )  . equals (  \" Filesystem   closed \"  )  )     |  |     ( e   instanceof   FileNotFoundException )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ CANNOT _ OPEN _ SPLIT ,    e )  ;", "}", "throw   new   PrestoException ( HiveErrorCode . HIVE _ CANNOT _ OPEN _ SPLIT ,    OrcPageSourceFactory . splitError ( e ,    path ,    start ,    length )  ,    e )  ;", "}", "AggregatedMemoryContext   systemMemoryUsage    =    newSimpleAggregatedMemoryContext (  )  ;", "try    {", "OrcReader   reader    =    new   OrcReader ( orcDataSource ,    orcEncoding ,    maxMergeDistance ,    maxBufferSize ,    maxReadBlockSize )  ;", "List < HiveColumnHandle >    physicalColumns    =    OrcPageSourceFactory . getPhysicalHiveColumnHandles ( columns ,    useOrcColumnNames ,    reader ,    path )  ;", "Builder < Integer ,    Type >    includedColumns    =    ImmutableMap . builder (  )  ;", "ImmutableList . Builder < ColumnReference < HiveColumnHandle >  >    columnReferences    =    ImmutableList . builder (  )  ;", "for    ( HiveColumnHandle   column    :    physicalColumns )     {", "if    (  ( column . getColumnType (  )  )     =  =     ( HiveColumnHandle . ColumnType . REGULAR )  )     {", "Type   type    =    typeManager . getType ( column . getTypeSignature (  )  )  ;", "includedColumns . put ( column . getHiveColumnIndex (  )  ,    type )  ;", "columnReferences . add ( new   ColumnReference ( column ,    column . getHiveColumnIndex (  )  ,    type )  )  ;", "}", "}", "OrcPredicate   predicate    =    new   orc . TupleDomainOrcPredicate ( effectivePredicate ,    columnReferences . build (  )  ,    orcBloomFiltersEnabled )  ;", "OrcRecordReader   recordReader    =    reader . createRecordReader ( includedColumns . build (  )  ,    predicate ,    start ,    length ,    hiveStorageTimeZone ,    systemMemoryUsage )  ;", "return   new   OrcPageSource ( recordReader ,    orcDataSource ,    physicalColumns ,    typeManager ,    systemMemoryUsage ,    stats )  ;", "}    catch    ( Exception   e )     {", "try    {", "orcDataSource . close (  )  ;", "}    catch    ( IOException   ignored )     {", "}", "if    ( e   instanceof   PrestoException )     {", "throw    (  ( PrestoException )     ( e )  )  ;", "}", "String   message    =    OrcPageSourceFactory . splitError ( e ,    path ,    start ,    length )  ;", "if    ( e . getClass (  )  . getSimpleName (  )  . equals (  \" BlockMissingException \"  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ MISSING _ DATA ,    message ,    e )  ;", "}", "throw   new   PrestoException ( HiveErrorCode . HIVE _ CANNOT _ OPEN _ SPLIT ,    message ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["createOrcPageSource"], "fileName": "com.facebook.presto.hive.orc.OrcPageSourceFactory"}, {"methodBody": ["METHOD_START", "{", "if    (  ! useOrcColumnNames )     {", "return   columns ;", "}", ". verifyFileHasColumnNames ( reader . getColumnNames (  )  ,    path )  ;", "Map < String ,    Integer >    physicalNameOrdinalMap    =     . buildPhysicalNameOrdinalMap ( reader )  ;", "int   nextMissingColumnIndex    =    physicalNameOrdinalMap . size (  )  ;", "ImmutableList . Builder < HiveColumnHandle >    physicalColumns    =    ImmutableList . builder (  )  ;", "for    ( HiveColumnHandle   column    :    columns )     {", "Integer   physicalOrdinal    =    physicalNameOrdinalMap . get ( column . getName (  )  )  ;", "if    ( physicalOrdinal    =  =    null )     {", "physicalOrdinal    =    nextMissingColumnIndex ;", "nextMissingColumnIndex +  +  ;", "}", "physicalColumns . add ( new   HiveColumnHandle ( column . getName (  )  ,    column . getHiveType (  )  ,    column . getTypeSignature (  )  ,    physicalOrdinal ,    column . getColumnType (  )  ,    column . getComment (  )  )  )  ;", "}", "return   physicalColumns . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPhysicalHiveColumnHandles"], "fileName": "com.facebook.presto.hive.orc.OrcPageSourceFactory"}, {"methodBody": ["METHOD_START", "{", "return   String . format (  \" Error   opening   Hive   split    % s    ( offset =  % s ,    length =  % s )  :     % s \"  ,    path ,    start ,    length ,    t . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["splitError"], "fileName": "com.facebook.presto.hive.orc.OrcPageSourceFactory"}, {"methodBody": ["METHOD_START", "{", "if    (  (  !  ( physicalColumnNames . isEmpty (  )  )  )     &  &     ( physicalColumnNames . stream (  )  . allMatch (  (    physicalColumnName )     -  >    OrcPageSourceFactory . DEFAULT _ HIVE _ COLUMN _ NAME _ PATTERN . matcher ( physicalColumnName )  . matches (  )  )  )  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( HiveErrorCode . HIVE _ FILE _ MISSING _ COLUMN _ NAMES ,     (  \" ORC   file   does   not   contain   column   names   in   the   footer :     \"     +    path )  )  ;", "}", "}", "METHOD_END"], "methodName": ["verifyFileHasColumnNames"], "fileName": "com.facebook.presto.hive.orc.OrcPageSourceFactory"}, {"methodBody": ["METHOD_START", "{", "return   ContiguousSet . create ( Range . openClosed ( lowerInclusive ,    upperExclusive )  ,    DiscreteDomain . bigIntegers (  )  )  ;", "}", "METHOD_END"], "methodName": ["bigIntegersBetween"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    ( input    =  =    null )     {", "turn   null ;", "}", "turn   new   SqlVarbinary ( input )  ;", "}", "METHOD_END"], "methodName": ["byteArrayToVarbinary"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   AbstractTestParquetReader . toInteger ( input )  ;", "}", "METHOD_END"], "methodName": ["byteToInt"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return    (  )     -  >    new   com . google . common . collect . AbstractSequentialIterator < Double >  ( start )     {", "private   int   item ;", "@ Override", "protected   Double   computeNext ( Double   previous )     {", "if    (  ( item )     >  =    items )     {", "return   null ;", "}", "( item )  +  +  ;", "return   previous    +    step ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["doubleSequence"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   transform ( AbstractTestParquetReader . doubleSequence ( start ,    step ,    items )  ,     (    input )     -  >     {", "if    ( input    =  =    null )     {", "return   null ;", "}", "return   input . floatValue (  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["floatSequence"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    ( input    =  =    null )     {", "turn   null ;", "}", "turn   input . byteValue (  )  ;", "}", "METHOD_END"], "methodName": ["intToByte"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    ( input    =  =    null )     {", "turn   null ;", "}", "turn   Date . valueOf ( LocalDate . ofEpochDay ( input )  )  ;", "}", "METHOD_END"], "methodName": ["intToDate"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   AbstractTestParquetReader . toLong ( input )  ;", "}", "METHOD_END"], "methodName": ["intToLong"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    ( input    =  =    null )     {", "turn   null ;", "}", "turn   Shorts . checkedCast ( input )  ;", "}", "METHOD_END"], "methodName": ["intToShort"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    ( input    =  =    null )     {", "turn   null ;", "}", "turn   new   SqlDate ( input )  ;", "}", "METHOD_END"], "methodName": ["intToSqlDate"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    ( input    =  =    null )     {", "return   null ;", "}", "return   new   spi . type . SqlTimestamp ( input ,    TimeZoneKey . UTC _ KEY )  ;", "}", "METHOD_END"], "methodName": ["intToSqlTimestamp"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    ( input    =  =    null )     {", "return   null ;", "}", "Timamp   timamp    =    new   Timamp (  0  )  ;", "long   seconds    =    input    /     1  0  0  0  ;", "int   nanos    =     ( input    %     1  0  0  0  )     *     1  0  0  0  0  0  0  ;", "nanos    +  =     8  8  8  8  8  8  ;", "if    ( nanos    <     0  )     {", "nanos    +  =     1  0  0  0  0  0  0  0  0  0  ;", "seconds    -  =     1  ;", "}", "if    ( nanos    >     1  0  0  0  0  0  0  0  0  0  )     {", "nanos    -  =     1  0  0  0  0  0  0  0  0  0  ;", "seconds    +  =     1  ;", "}", "timamp . setTime (  ( seconds    *     1  0  0  0  )  )  ;", "timamp . setNanos ( nanos )  ;", "return   timamp ;", "}", "METHOD_END"], "methodName": ["intToTimestamp"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   ContiguousSet . create ( Range . openClosed ( lowerInclusive ,    upperExclusive )  ,    DiscreteDomain . integers (  )  )  ;", "}", "METHOD_END"], "methodName": ["intsBetween"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   ContiguousSet . create ( Range . openClosed ( lowerInclusive ,    upperExclusive )  ,    DiscreteDomain . longs (  )  )  ;", "}", "METHOD_END"], "methodName": ["longsBetween"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   Math . round ( Math . floor ( Math . log 1  0  (  (  ( Math . pow (  2  ,     (  (  8     *    numBytes )     -     1  )  )  )     -     1  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["maxPrecision"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return    (  )     -  >    new   com . google . common . collect . AbstractIterator < T >  (  )     {", "private   final   Iterator < T >    delegate    =    iterable . iterator (  )  ;", "private   int   position ;", "private   T   value ;", "@ Override", "protected   T   computeNext (  )     {", "if    (  ( position )     =  =     0  )     {", "if    (  !  ( delegate . hasNext (  )  )  )     {", "return   endOfData (  )  ;", "}", "value    =    delegate . next (  )  ;", "}", "( position )  +  +  ;", "if    (  ( position )     >  =    n )     {", "position    =     0  ;", "}", "return   value ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["repeatEach"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "Logger . getLogger ( ParquetOutputFormat . class . getName (  )  )  . setLevel ( Level . WARNING )  ;", "Logger . getLogger ( CodecConfig . class . getName (  )  )  . setLevel ( Level . WARNING )  ;", "Logger . getLogger (  \" parquet . hadoop . InternalcordWriter \"  )  . setLevel ( Level . WARNING )  ;", "Logger . getLogger (  \" parquet . hadoop . ColumnChunkPageWriteStore \"  )  . setLevel ( Level . WARNING )  ;", "}", "METHOD_END"], "methodName": ["setParquetLogging"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( DateTimeZone . getDefault (  )  ,    ParquetTester . HIVE _ STORAGE _ TIME _ ZONE )  ;", "seLogging (  )  ;", "}", "METHOD_END"], "methodName": ["setUp"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   AbstractTestParquetReader . toInteger ( input )  ;", "}", "METHOD_END"], "methodName": ["shortToInt"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return    (  )     -  >    new   com . google . common . collect . AbstractIterator < T >  (  )     {", "private   final   Iterator < T >    delegate    =    iterable . iterator (  )  ;", "private   int   position ;", "@ Override", "protected   T   computeNext (  )     {", "while    ( true )     {", "if    (  !  ( delegate . hasNext (  )  )  )     {", "return   endOfData (  )  ;", "}", "T   next    =    delegate . next (  )  ;", "( position )  +  +  ;", "if    (  ( position )     <  =    n )     {", "return   next ;", "}", "position    =     0  ;", "}", "}", "}  ;", "}", "METHOD_END"], "methodName": ["skipEvery"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   input . getBytes ( StandardCharsets . UTF _  8  )  ;", "}", "METHOD_END"], "methodName": ["stringToByteArray"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "Iterable < byte [  ]  >    writeValues    =    limit ( cycle ( transform ( ImmutableList . of (  1  ,     3  ,     5  ,     7  ,     1  1  ,     1  3  ,     1  7  )  ,    compose ( AbstractTestParquetReader :  : stringToByteArray ,    Object :  : toString )  )  )  ,     3  0  0  0  0  )  ;", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaByteArrayObjectInspector ,    writeValues ,    transform ( writeValues ,    AbstractTestParquetReader :  : byteArrayToVarbinary )  ,    VarbinaryType . VARBINARY )  ;", "}", "METHOD_END"], "methodName": ["testBinaryDictionarySequence"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "Iterable < byte [  ]  >    writeValues    =    transform ( AbstractTestParquetReader . intsBetween (  0  ,     3  0  0  0  0  )  ,    compose ( AbstractTestParquetReader :  : stringToByteArray ,    Object :  : toString )  )  ;", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaByteArrayObjectInspector ,    writeValues ,    transform ( writeValues ,    AbstractTestParquetReader :  : byteArrayToVarbinary )  ,    VarbinaryType . VARBINARY )  ;", "}", "METHOD_END"], "methodName": ["testBinaryDirectSequence"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "for    ( int   precision    =     ( AbstractTestParquetReader . MAX _ PRECISION _ INT 6  4  )     +     1  ;    precision    <     ( Decimals . MAX _ PRECISION )  ;    precision +  +  )     {", "int   scale    =    ThreadLocalRandom . current (  )  . nextInt ( precision )  ;", "MessageType   parquetSchema    =    MessageTypeParser . parseMessageType ( String . format (  \" message   hive _ decimal    {    optional   FIXED _ LEN _ BYTE _ ARRAY (  1  6  )    test    ( DECIMAL (  % d ,     % d )  )  ;     }  \"  ,    precision ,    scale )  )  ;", "ContiguousSet < BigInteger >    values    =    AbstractTestParquetReader . bigIntegersBetween ( BigDecimal . valueOf ( Math . pow (  1  0  ,     ( precision    -     1  )  )  )  . toBigInteger (  )  ,    BigDecimal . valueOf ( Math . pow (  1  0  ,    precision )  )  . toBigInteger (  )  )  ;", "ImmutableList . Builder < SqlDecimal >    expectedValues    =    new   ImmutableList . Builder <  >  (  )  ;", "ImmutableList . Builder < HiveDecimal >    writeValues    =    new   ImmutableList . Builder <  >  (  )  ;", "for    ( BigInteger   value    :    limit ( values ,     1  0  0  0  )  )     {", "writeValues . add ( HiveDecimal . create ( value ,    scale )  )  ;", "expectedValues . add ( new   SqlDecimal ( value ,    precision ,    scale )  )  ;", "}", "tester . testRoundTrip ( new   JavaHiveDecimalObjectInspector ( new   DecimalTypeInfo ( precision ,    scale )  )  ,    writeValues . build (  )  ,    expectedValues . build (  )  ,    DecimalType . createDecimalType ( precision ,    scale )  ,    Optional . of ( parquetSchema )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDecimalBackedByFixedLenByteArray"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "for    ( int   precision    =     1  ;    precision    <  =     ( AbstractTestParquetReader . MAX _ PRECISION _ INT 3  2  )  ;    precision +  +  )     {", "int   scale    =    ThreadLocalRandom . current (  )  . nextInt ( precision )  ;", "MessageType   parquetSchema    =    MessageTypeParser . parseMessageType ( String . format (  \" message   hive _ decimal    {    optional   INT 3  2    test    ( DECIMAL (  % d ,     % d )  )  ;     }  \"  ,    precision ,    scale )  )  ;", "ContiguousSet < Integer >    intValues    =    AbstractTestParquetReader . intsBetween (  1  ,     1  0  0  0  )  ;", "ImmutableList . Builder < SqlDecimal >    expectedValues    =    new   ImmutableList . Builder <  >  (  )  ;", "for    ( Integer   value    :    intValues )     {", "expectedValues . add ( SqlDecimal . of ( value ,    precision ,    scale )  )  ;", "}", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaIntObjectInspector ,    intValues ,    expectedValues . build (  )  ,    DecimalType . createDecimalType ( precision ,    scale )  ,    Optional . of ( parquetSchema )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDecimalBackedByINT32"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "for    ( int   precision    =     ( AbstractTestParquetReader . MAX _ PRECISION _ INT 3  2  )     +     1  ;    precision    <  =     ( AbstractTestParquetReader . MAX _ PRECISION _ INT 6  4  )  ;    precision +  +  )     {", "int   scale    =    ThreadLocalRandom . current (  )  . nextInt ( precision )  ;", "MessageType   parquetSchema    =    MessageTypeParser . parseMessageType ( String . format (  \" message   hive _ decimal    {    optional   INT 6  4    test    ( DECIMAL (  % d ,     % d )  )  ;     }  \"  ,    precision ,    scale )  )  ;", "ContiguousSet < Long >    longValues    =    AbstractTestParquetReader . longsBetween (  1  ,     1  0  0  0  )  ;", "ImmutableList . Builder < SqlDecimal >    expectedValues    =    new   ImmutableList . Builder <  >  (  )  ;", "for    ( Long   value    :    longValues )     {", "expectedValues . add ( SqlDecimal . of ( value ,    precision ,    scale )  )  ;", "}", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaLongObjectInspector ,    longValues ,    expectedValues . build (  )  ,    DecimalType . createDecimalType ( precision ,    scale )  ,    Optional . of ( parquetSchema )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDecimalBackedByINT64"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaByteArrayObjectInspector ,    limit ( cycle ( new   byte [  0  ]  )  ,     3  0  0  0  0  )  ,    AbstractTestParquetReader :  : byteArrayToVarbinary ,    VarbinaryType . VARBINARY )  ;", "}", "METHOD_END"], "methodName": ["testEmptyBinarySequence"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaStringObjectInspector ,    limit ( cycle (  \"  \"  )  ,     3  0  0  0  0  )  ,    VarcharType . createUnboundedVarcharType (  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmptyStringSequence"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "testRoundTripNumeric ( limit ( cycle ( ImmutableList . of (  1  ,     3  ,     5  ,     7  ,     1  1  ,     1  3  ,     1  7  )  )  ,     3  0  0  0  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongDirect"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "List < Integer >    values    =    new   ArrayList <  >  (  3  1  2  3  4  )  ;", "for    ( int   i    =     0  ;    i    <     3  1  2  3  4  ;    i +  +  )     {", "values . add ( i )  ;", "}", "Collections . shuffle ( values ,    new   Random (  0  )  )  ;", "tRoundTripNumeric ( values )  ;", "}", "METHOD_END"], "methodName": ["testLongDirect2"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "testRoundTripNumeric ( limit ( cycle ( concat ( AbstractTestParquetReader . intsBetween (  0  ,     1  8  )  ,    ImmutableList . of (  3  0  0  0  0  ,     2  0  0  0  0  )  )  )  ,     3  0  0  0  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongPatchedBase"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "testRoundTripNumeric ( AbstractTestParquetReader . intsBetween (  0  ,     3  1  2  3  4  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongSequence"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "testRoundTripNumeric ( AbstractTestParquetReader . skipEvery (  5  ,    AbstractTestParquetReader . intsBetween (  0  ,     3  1  2  3  4  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongSequenceWithHoles"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "testRoundTripNumeric ( limit ( AbstractTestParquetReader . repeatEach (  4  ,    cycle ( ImmutableList . of (  1  ,     3  ,     5  ,     7  ,     1  1  ,     1  3  ,     1  7  )  )  )  ,     3  0  0  0  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongShortRepeat"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "testRoundTripNumeric ( concat ( ImmutableList . of (  1  )  ,    Collections . nCopies (  9  9  9  9  ,     1  2  3  )  ,    ImmutableList . of (  2  )  ,    Collections . nCopies (  9  9  9  9  ,     1  2  3  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongStrideDictionary"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaStringObjectInspector ,    limit ( cycle ( transform ( ImmutableList . of (  1  ,     3  ,     5  ,     7  ,     1  1  ,     1  3  ,     1  7  )  ,    Object :  : toString )  )  ,     3  0  0  0  0  )  ,    VarcharType . createUnboundedVarcharType (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStringDictionarySequence"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaStringObjectInspector ,    transform ( AbstractTestParquetReader . intsBetween (  0  ,     3  0  0  0  0  )  ,    Object :  : toString )  ,    VarcharType . createUnboundedVarcharType (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStringDirectSequence"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaStringObjectInspector ,    concat ( ImmutableList . of (  \" a \"  )  ,    Collections . nCopies (  9  9  9  9  ,     \"  1  2  3  \"  )  ,    ImmutableList . of (  \" b \"  )  ,    Collections . nCopies (  9  9  9  9  ,     \"  1  2  3  \"  )  )  ,    VarcharType . createUnboundedVarcharType (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStringStrideDictionary"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "tester . testRoundTrip ( PrimitiveObjectInspectorFactory . javaStringObjectInspector ,    limit ( cycle ( ImmutableList . of (  \" apple \"  ,     \" apple   pie \"  ,     \" apple \\ ud 8  3  5  \\ udc 0  3  \"  ,     \" apple \\ ufffd \"  )  )  ,     3  0  0  0  0  )  ,    VarcharType . createUnboundedVarcharType (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStringUnicode"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    ( input    =  =    null )     {", "turn   null ;", "}", "turn   input . intValue (  )  ;", "}", "METHOD_END"], "methodName": ["toInteger"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    ( input    =  =    null )     {", "turn   null ;", "}", "turn   input . longValue (  )  ;", "}", "METHOD_END"], "methodName": ["toLong"], "fileName": "com.facebook.presto.hive.parquet.AbstractTestParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   new   HdfsParquetDataSource ( path ,    fileSize ,    inputStream )  ;", "}", "METHOD_END"], "methodName": ["buildHdfsParquetDataSource"], "fileName": "com.facebook.presto.hive.parquet.HdfsParquetDataSource"}, {"methodBody": ["METHOD_START", "{", "try    {", "FSDataInputStream   inputStream    =    fileSystem . open ( path )  ;", "return   new    ( path ,    fileSize ,    inputStream )  ;", "}    catch    ( Exception   e )     {", "if    (  ( nullToEmpty ( e . getMessage (  )  )  . trim (  )  . equals (  \" Filesystem   closed \"  )  )     |  |     ( e   instanceof   FileNotFoundException )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ CANNOT _ OPEN _ SPLIT ,    e )  ;", "}", "throw   new   PrestoException ( HiveErrorCode . HIVE _ CANNOT _ OPEN _ SPLIT ,    String . format (  \" Error   opening   Hive   split    % s    ( offset =  % s ,    length =  % s )  :     % s \"  ,    path ,    start ,    length ,    e . getMessage (  )  )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["buildHdfsParquetDataSource"], "fileName": "com.facebook.presto.hive.parquet.HdfsParquetDataSource"}, {"methodBody": ["METHOD_START", "{", "try    {", "inputStream . readFully ( position ,    buffer ,    bufferOffset ,    bufferLength )  ;", "}    catch    ( PException   e )     {", "throw   e ;", "}    catch    ( Exception   e )     {", "throw   new   PException ( HiveErrorCode . HIVE _ FILESYSTEM _ ERROR ,    String . format (  \" Error   reading   from    % s   at   position    % s \"  ,    name ,    position )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["readInternal"], "fileName": "com.facebook.presto.hive.parquet.HdfsParquetDataSource"}, {"methodBody": ["METHOD_START", "{", "byte [  ]    byteArray    =     (  ( byte [  ]  )     ( input . getBase (  )  )  )  ;", "int   byteArrayOffset    =    inputOffset    +     (  ( int )     (  ( input . getAddress (  )  )     -     ( Unsafe . ARRAY _ BYTE _ BASE _ OFFSET )  )  )  ;", "int   size    =    decor . dec ( byteArray ,    byteArrayOffset ,    inputLength ,    output ,    outputOffset ,     (  ( output . length )     -    outputOffset )  )  ;", "return   size ;", "}", "METHOD_END"], "methodName": ["decompress"], "fileName": "com.facebook.presto.hive.parquet.ParquetCompressionUtils"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( input ,     \" input   is   null \"  )  ;", "if    (  ( input . length (  )  )     =  =     0  )     {", "return   Slices . EMPTY _ SLICE ;", "}", "switch    ( codec )     {", "case   GZIP    :", "return    . decompressGzip ( input ,    uncompressedSize )  ;", "case   SNAPPY    :", "return    . decompressSnappy ( input ,    uncompressedSize )  ;", "case   UNCOMPRESSED    :", "return   input ;", "case   LZO    :", "return    . decompressLZO ( input ,    uncompressedSize )  ;", "default    :", "throw   new   ParquetCorruptionException (  (  \" Codec   not   supported   in   Parquet :     \"     +    codec )  )  ;", "}", "}", "METHOD_END"], "methodName": ["decompress"], "fileName": "com.facebook.presto.hive.parquet.ParquetCompressionUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( uncompressedSize    =  =     0  )     {", "return   Slices . EMPTY _ SLICE ;", "}", "DynamicSliceOutput   sliceOutput    =    new   DynamicSliceOutput ( uncompressedSize )  ;", "byte [  ]    buffer    =    new   byte [ uncompressedSize ]  ;", "try    ( InputStream   gzipInputStream    =    new   GZIPInputStream ( input . getInput (  )  ,     . GZIP _ BUFFER _ SIZE )  )     {", "int   bytesRead ;", "while    (  ( bytesRead    =    gzipInputStream . read ( buffer )  )     !  =     (  -  1  )  )     {", "sliceOutput . write ( buffer ,     0  ,    bytesRead )  ;", "}", "return   sliceOutput . getUnderlyingSlice (  )  ;", "}", "}", "METHOD_END"], "methodName": ["decompressGzip"], "fileName": "com.facebook.presto.hive.parquet.ParquetCompressionUtils"}, {"methodBody": ["METHOD_START", "{", "LzoDecompressor   lzoDecompressor    =    new   LzoDecompressor (  )  ;", "long   totalDecompressedCount    =     0  ;", "byte [  ]    output    =    new   byte [ uncompressedSize    +     ( SizeOf . SIZE _ OF _ LONG )  ]  ;", "int   outputOffset    =     0  ;", "int   inputOffset    =     0  ;", "int   cumulativeUncompressedBlockLength    =     0  ;", "while    ( totalDecompressedCount    <    uncompressedSize )     {", "if    ( totalDecompressedCount    =  =    cumulativeUncompressedBlockLength )     {", "cumulativeUncompressedBlockLength    +  =    Integer . reverseBytes ( input . getInt ( inputOffset )  )  ;", "inputOffset    +  =    SizeOf . SIZE _ OF _ INT ;", "}", "int   compressedChunkLength    =    Integer . reverseBytes ( input . getInt ( inputOffset )  )  ;", "inputOffset    +  =    SizeOf . SIZE _ OF _ INT ;", "int   decompressionSize    =     . decompress ( lzoDecompressor ,    input ,    inputOffset ,    compressedChunkLength ,    output ,    outputOffset )  ;", "totalDecompressedCount    +  =    decompressionSize ;", "outputOffset    +  =    decompressionSize ;", "inputOffset    +  =    compressedChunkLength ;", "}", "checkArgument (  ( outputOffset    =  =    uncompressedSize )  )  ;", "return   Slices . wrappedBuffer ( output ,     0  ,    uncompressedSize )  ;", "}", "METHOD_END"], "methodName": ["decompressLZO"], "fileName": "com.facebook.presto.hive.parquet.ParquetCompressionUtils"}, {"methodBody": ["METHOD_START", "{", "byte [  ]    buffer    =    new   byte [ uncompressedSize ]  ;", ". decompress ( new   SnappyDecompressor (  )  ,    input ,     0  ,    input . length (  )  ,    buffer ,     0  )  ;", "return   Slices . wrappedBuffer ( buffer )  ;", "}", "METHOD_END"], "methodName": ["decompressSnappy"], "fileName": "com.facebook.presto.hive.parquet.ParquetCompressionUtils"}, {"methodBody": ["METHOD_START", "{", "return   valueCount ;", "}", "METHOD_END"], "methodName": ["getValueCount"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPage"}, {"methodBody": ["METHOD_START", "{", "return   definitionLevelEncoding ;", "}", "METHOD_END"], "methodName": ["getDefinitionLevelEncoding"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV1"}, {"methodBody": ["METHOD_START", "{", "return   repetitionLevelEncoding ;", "}", "METHOD_END"], "methodName": ["getRepetitionLevelEncoding"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV1"}, {"methodBody": ["METHOD_START", "{", "return   slice ;", "}", "METHOD_END"], "methodName": ["getSlice"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV1"}, {"methodBody": ["METHOD_START", "{", "return   statistics ;", "}", "METHOD_END"], "methodName": ["getStatistics"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV1"}, {"methodBody": ["METHOD_START", "{", "return   valuesEncoding ;", "}", "METHOD_END"], "methodName": ["getValueEncoding"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV1"}, {"methodBody": ["METHOD_START", "{", "return   dataEncoding ;", "}", "METHOD_END"], "methodName": ["getDataEncoding"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV2"}, {"methodBody": ["METHOD_START", "{", "return   definitionLevels ;", "}", "METHOD_END"], "methodName": ["getDefinitionLevels"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV2"}, {"methodBody": ["METHOD_START", "{", "return   nullCount ;", "}", "METHOD_END"], "methodName": ["getNullCount"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV2"}, {"methodBody": ["METHOD_START", "{", "return   repetitionLevels ;", "}", "METHOD_END"], "methodName": ["getRepetitionLevels"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV2"}, {"methodBody": ["METHOD_START", "{", "return   rowCount ;", "}", "METHOD_END"], "methodName": ["getRowCount"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV2"}, {"methodBody": ["METHOD_START", "{", "return   slice ;", "}", "METHOD_END"], "methodName": ["getSlice"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV2"}, {"methodBody": ["METHOD_START", "{", "return   statistics ;", "}", "METHOD_END"], "methodName": ["getStatistics"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV2"}, {"methodBody": ["METHOD_START", "{", "return   isCompressed ;", "}", "METHOD_END"], "methodName": ["isCompressed"], "fileName": "com.facebook.presto.hive.parquet.ParquetDataPageV2"}, {"methodBody": ["METHOD_START", "{", "return   new   ParquetDictionaryPage ( Slices . wrappedBuffer ( Arrays . copyOf ( slice . getBytes (  )  ,    slice . length (  )  )  )  ,    getUncompressedSize (  )  ,    dictionarySize ,    encoding )  ;", "}", "METHOD_END"], "methodName": ["copy"], "fileName": "com.facebook.presto.hive.parquet.ParquetDictionaryPage"}, {"methodBody": ["METHOD_START", "{", "return   dictionarySize ;", "}", "METHOD_END"], "methodName": ["getDictionarySize"], "fileName": "com.facebook.presto.hive.parquet.ParquetDictionaryPage"}, {"methodBody": ["METHOD_START", "{", "return   encoding ;", "}", "METHOD_END"], "methodName": ["getEncoding"], "fileName": "com.facebook.presto.hive.parquet.ParquetDictionaryPage"}, {"methodBody": ["METHOD_START", "{", "return   slice ;", "}", "METHOD_END"], "methodName": ["getSlice"], "fileName": "com.facebook.presto.hive.parquet.ParquetDictionaryPage"}, {"methodBody": ["METHOD_START", "{", "throw   new   UnsupportedOperationException (  (  \" Parquet   Dictionary   encoding   is   not   supported   for :     \"     +     ( name (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getDictionaryBasedValuesReader"], "fileName": "com.facebook.presto.hive.parquet.ParquetEncoding"}, {"methodBody": ["METHOD_START", "{", "switch    ( valuesType )     {", "case   REPETITION _ LEVEL    :", "return   descriptor . getMaxRepetitionLevel (  )  ;", "case   DEFINITION _ LEVEL    :", "return   descriptor . getMaxDefinitionLevel (  )  ;", "case   VALUES    :", "if    (  ( descriptor . getType (  )  )     =  =     ( PrimitiveTypeName . BOOLEAN )  )     {", "return    1  ;", "}", "default    :", "throw   new   DecodingException (  (  \" Unsupported      values   type :     \"     +    valuesType )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getMaxLevel"], "fileName": "com.facebook.presto.hive.parquet.ParquetEncoding"}, {"methodBody": ["METHOD_START", "{", "throw   new   UnsupportedOperationException (  (  \" Error   decoding   Parquet   values   in   encoding :     \"     +     ( this . name (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getValuesReader"], "fileName": "com.facebook.presto.hive.parquet.ParquetEncoding"}, {"methodBody": ["METHOD_START", "{", "throw   new   UnsupportedOperationException (  (  \" Parquet   Dictionary   encoding   is   not   supported   for :     \"     +     ( name (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["initDictionary"], "fileName": "com.facebook.presto.hive.parquet.ParquetEncoding"}, {"methodBody": ["METHOD_START", "{", "return   false ;", "}", "METHOD_END"], "methodName": ["usesDictionary"], "fileName": "com.facebook.presto.hive.parquet.ParquetEncoding"}, {"methodBody": ["METHOD_START", "{", "if    ( parquetType . isPrimitive (  )  )     {", "if    (  ( parquetType . getOriginalType (  )  )     =  =     ( OriginalType . DECIMAL )  )     {", "DecimalMetadata   decimalMetadata    =     (  ( PrimitiveType )     ( parquetType )  )  . getDecimalMetadata (  )  ;", "return   new    . ParquetDecimalConverter ( DecimalType . createDecimalType ( decimalMetadata . getPrecision (  )  ,    decimalMetadata . getScale (  )  )  )  ;", "} else    {", "return   new    . ParquetPrimitiveConverter ( prestoType ,    fieldIndex )  ;", "}", "}", "return    . createGroupConverter ( prestoType ,    columnName ,    parquetType ,    fieldIndex )  ;", "}", "METHOD_END"], "methodName": ["createConverter"], "fileName": "com.facebook.presto.hive.parquet.ParquetHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "GroupType   groupType    =    parquetType . asGroupType (  )  ;", "switch    ( prestoType . getTypeSignature (  )  . getBase (  )  )     {", "case   StandardTypes . ARRAY    :", "return   new    . ParquetListConverter ( prestoType ,    columnName ,    groupType ,    fieldIndex )  ;", "case   StandardTypes . MAP    :", "return   new    . ParquetMapConverter ( prestoType ,    columnName ,    groupType ,    fieldIndex )  ;", "case   StandardTypes . ROW    :", "return   new    . ParquetStructConverter ( prestoType ,    columnName ,    groupType ,    fieldIndex )  ;", "default    :", "throw   new   IllegalArgumentException (  (  (  (  (  \" Column    \"     +    columnName )     +     \"    type    \"  )     +     ( parquetType . getOriginalType (  )  )  )     +     \"    not   supported \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["createGroupConverter"], "fileName": "com.facebook.presto.hive.parquet.ParquetHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "ParquetDataSource   dataSource    =    null ;", "try    {", "FileSystem   fileSystem    =    hdfsEnvironment . getFileSystem ( sessionUser ,    path ,    configuration )  ;", "dataSource    =    HdfsParquetDataSource . buildHdfsParquetDataSource ( fileSystem ,    path ,    start ,    length ,    fileSize )  ;", "ParquetMetadata   parquetMetadata    =    hdfsEnvironment . doAs ( sessionUser ,     (  )     -  >    ParquetFileReader . readFooter ( configuration ,    path ,    NO _ FILTER )  )  ;", "List < BlockMetaData >    blocks    =    parquetMetadata . getBlocks (  )  ;", "FileMetaData   fileMetaData    =    parquetMetadata . getFileMetaData (  )  ;", "MessageType   fileSchema    =    fileMetaData . getSchema (  )  ;", ". PrestoReadSupport   readSupport    =    new    . PrestoReadSupport ( useParquetColumnNames ,    columns ,    fileSchema )  ;", "List < Type >    fields    =    columns . stream (  )  . filter (  (    column )     -  >     ( column . getColumnType (  )  )     =  =     ( HiveColumnHandle . ColumnType . REGULAR )  )  . map (  (    column )     -  >    ParquetTypeUtils . getParquetType ( column ,    fileSchema ,    useParquetColumnNames )  )  . filter ( Objects :  : nonNull )  . collect ( Collectors . toList (  )  )  ;", "MessageType   requestedSchema    =    new   MessageType ( fileSchema . getName (  )  ,    fields )  ;", "LongArrayList   offsets    =    new   LongArrayList ( blocks . size (  )  )  ;", "for    ( BlockMetaData   block    :    blocks )     {", "long   firstDataPage    =    block . getColumns (  )  . get (  0  )  . getFirstDataPageOffset (  )  ;", "if    (  ( firstDataPage    >  =    start )     &  &     ( firstDataPage    <     ( start    +    length )  )  )     {", "if    ( predicatePushdownEnabled )     {", "TupleDomain < ColumnDescriptor >    parquetTupleDomain    =    ParquetPredicateUtils . getParquetTupleDomain ( fileSchema ,    requestedSchema ,    effectivePredicate )  ;", "ParquetPredicate   parquetPredicate    =    ParquetPredicateUtils . buildParquetPredicate ( requestedSchema ,    parquetTupleDomain ,    fileSchema )  ;", "if    ( ParquetPredicateUtils . predicateMatches ( parquetPredicate ,    block ,    dataSource ,    fileSchema ,    requestedSchema ,    parquetTupleDomain )  )     {", "offsets . add ( block . getStartingPos (  )  )  ;", "}", "} else    {", "offsets . add ( block . getStartingPos (  )  )  ;", "}", "}", "}", "ParquetInputSplit   split    =    new   ParquetInputSplit ( path ,    start ,     ( start    +    length )  ,    length ,    null ,    offsets . toLongArray (  )  )  ;", "TaskAttemptContext   taskContext    =    ContextUtil . newTaskAttemptContext ( configuration ,    new   TaskAttemptID (  )  )  ;", "return   hdfsEnvironment . doAs ( sessionUser ,     (  )     -  >     {", "ParquetRecordReader <  . FakeParquetRecord >    realReader    =    new    . PrestoParquetRecordReader ( readSupport )  ;", "realReader . initialize ( split ,    taskContext )  ;", "return   realReader ;", "}  )  ;", "}    catch    ( Exception   e )     {", "throwIfInstanceOf ( e ,    PrestoException . class )  ;", "if    ( e   instanceof   InterruptedException )     {", "Thread . currentThread (  )  . interrupt (  )  ;", "throw   new   RuntimeException ( e )  ;", "}", "String   message    =    String . format (  \" Error   opening   Hive   split    % s    ( offset =  % s ,    length =  % s )  :     % s \"  ,    path ,    start ,    length ,    e . getMessage (  )  )  ;", "if    ( e . getClass (  )  . getSimpleName (  )  . equals (  \" BlockMissingException \"  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ MISSING _ DATA ,    message ,    e )  ;", "}", "throw   new   PrestoException ( HiveErrorCode . HIVE _ CANNOT _ OPEN _ SPLIT ,    message ,    e )  ;", "}    finally    {", "if    ( dataSource    !  =    null )     {", "try    {", "dataSource . close (  )  ;", "}    catch    ( IOException   ignored )     {", "}", "}", "}", "}", "METHOD_END"], "methodName": ["createParquetRecordReader"], "fileName": "com.facebook.presto.hive.parquet.ParquetHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "try    {", "long   newCompletedBytes    =     (  ( long )     (  ( totalBytes )     *     ( rReader . getProgress (  )  )  )  )  ;", "completedBytes    =    Math . min ( totalBytes ,    Math . max ( completedBytes ,    newCompletedBytes )  )  ;", "}    catch    ( IOException   ignored )     {", "}    catch    ( InterruptedException   e )     {", "Thread . currentThread (  )  . interrupt (  )  ;", "}", "}", "METHOD_END"], "methodName": ["updateCompletedBytes"], "fileName": "com.facebook.presto.hive.parquet.ParquetHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "if    (  ( types [ fieldId ]  . getJavaType (  )  )     !  =    javaType )     {", "throw   new   IllegalArgumentException ( String . format (  \" Expected   field   to   be    % s ,    actual    % s    ( field    % s )  \"  ,    getName (  )  ,    types [ fieldId ]  . getJavaType (  )  . getName (  )  ,    fieldId )  )  ;", "}", "}", "METHOD_END"], "methodName": ["validateType"], "fileName": "com.facebook.presto.hive.parquet.ParquetHiveRecordCursor"}, {"methodBody": ["METHOD_START", "{", "return   compressedSize ;", "}", "METHOD_END"], "methodName": ["getCompressedSize"], "fileName": "com.facebook.presto.hive.parquet.ParquetPage"}, {"methodBody": ["METHOD_START", "{", "return   uncompressedSize ;", "}", "METHOD_END"], "methodName": ["getUncompressedSize"], "fileName": "com.facebook.presto.hive.parquet.ParquetPage"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( throwable ,     \" throwable   is   null \"  )  ;", "try    {", "close (  )  ;", "}    catch    ( RuntimeException   e )     {", "if    ( e    !  =    throwable )     {", "throwable . addSupsed ( e )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["closeWithSuppression"], "fileName": "com.facebook.presto.hive.parquet.ParquetPageSource"}, {"methodBody": ["METHOD_START", "{", "AggregatedMemoryContext   systemMemoryContext    =    newSimpleAggregatedMemoryContext (  )  ;", "ParquetDataSource   dataSource    =    null ;", "try    {", "FileSystem   fileSystem    =    hdfsEnvironment . getFileSystem ( user ,    path ,    configuration )  ;", "FSDataInputStream   inputStream    =    fileSystem . open ( path )  ;", "ParquetMetadata   parquetMetadata    =    ParquetMetadataReader . readFooter ( inputStream ,    path ,    fileSize )  ;", "FileMetaData   fileMetaData    =    parquetMetadata . getFileMetaData (  )  ;", "MessageType   fileSchema    =    fileMetaData . getSchema (  )  ;", "dataSource    =    HdfsParquetDataSource . buildHdfsParquetDataSource ( inputStream ,    path ,    fileSize )  ;", "List < Type >    fields    =    columns . stream (  )  . filter (  (    column )     -  >     ( column . getColumnType (  )  )     =  =     ( HiveColumnHandle . ColumnType . REGULAR )  )  . map (  (    column )     -  >    ParquetTypeUtils . getParquetType ( column ,    fileSchema ,    useParquetColumnNames )  )  . filter ( Objects :  : nonNull )  . collect ( Collectors . toList (  )  )  ;", "MessageType   requestedSchema    =    new   MessageType ( fileSchema . getName (  )  ,    fields )  ;", "List < BlockMetaData >    blocks    =    new   ArrayList <  >  (  )  ;", "for    ( BlockMetaData   block    :    parquetMetadata . getBlocks (  )  )     {", "long   firstDataPage    =    block . getColumns (  )  . get (  0  )  . getFirstDataPageOffset (  )  ;", "if    (  ( firstDataPage    >  =    start )     &  &     ( firstDataPage    <     ( start    +    length )  )  )     {", "blocks . add ( block )  ;", "}", "}", "if    ( predicatePushdownEnabled )     {", "TupleDomain < ColumnDescriptor >    parquetTupleDomain    =    ParquetPredicateUtils . getParquetTupleDomain ( fileSchema ,    requestedSchema ,    effectivePredicate )  ;", "ParquetPredicate   parquetPredicate    =    ParquetPredicateUtils . buildParquetPredicate ( requestedSchema ,    parquetTupleDomain ,    fileMetaData . getSchema (  )  )  ;", "final   ParquetDataSource   finalDataSource    =    dataSource ;", "blocks    =    blocks . stream (  )  . filter (  (    block )     -  >    predicateMatches ( parquetPredicate ,    block ,    finalDataSource ,    fileSchema ,    requestedSchema ,    parquetTupleDomain )  )  . collect ( Collectors . toList (  )  )  ;", "}", "ParquetReader   parquetReader    =    new   ParquetReader ( fileSchema ,    requestedSchema ,    blocks ,    dataSource ,    typeManager ,    systemMemoryContext )  ;", "return   new    ( parquetReader ,    dataSource ,    fileSchema ,    requestedSchema ,    schema ,    columns ,    effectivePredicate ,    typeManager ,    useParquetColumnNames ,    systemMemoryContext )  ;", "}    catch    ( Exception   e )     {", "try    {", "if    ( dataSource    !  =    null )     {", "dataSource . close (  )  ;", "}", "}    catch    ( IOException   ignored )     {", "}", "if    ( e   instanceof   PrestoException )     {", "throw    (  ( PrestoException )     ( e )  )  ;", "}", "if    (  ( nullToEmpty ( e . getMessage (  )  )  . trim (  )  . equals (  \" Filesystem   closed \"  )  )     |  |     ( e   instanceof   FileNotFoundException )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ CANNOT _ OPEN _ SPLIT ,    e )  ;", "}", "String   message    =    String . format (  \" Error   opening   Hive   split    % s    ( offset =  % s ,    length =  % s )  :     % s \"  ,    path ,    start ,    length ,    e . getMessage (  )  )  ;", "if    ( e . getClass (  )  . getSimpleName (  )  . equals (  \" BlockMissingException \"  )  )     {", "throw   new   PrestoException ( HiveErrorCode . HIVE _ MISSING _ DATA ,    message ,    e )  ;", "}", "throw   new   PrestoException ( HiveErrorCode . HIVE _ CANNOT _ OPEN _ SPLIT ,    message ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["createParquetPageSource"], "fileName": "com.facebook.presto.hive.parquet.ParquetPageSourceFactory"}, {"methodBody": ["METHOD_START", "{", "Path   path    =    new   Path ( tempFile . getFile (  )  . toURI (  )  )  ;", "FileSystem   fileSystem    =    path . getFileSystem ( jobConf )  ;", "ParquetMetadata   parquetMetadata    =    ParquetMetadataReader . readFooter ( fileSystem ,    path ,    fileSystem . getFileStatus ( path )  . getLen (  )  )  ;", "FileMetaData   fileMetaData    =    parquetMetadata . getFileMetaData (  )  ;", "MessageType   fileSchema    =    fileMetaData . getSchema (  )  ;", "long   size    =    fileSystem . getFileStatus ( path )  . getLen (  )  ;", "FSDataInputStream   inputStream    =    fileSystem . open ( path )  ;", "ParquetDataSource   dataSource    =    new   HdfsParquetDataSource ( path ,    size ,    inputStream )  ;", "ParquetReader   parquetReader    =    new   ParquetReader ( fileSchema ,    fileSchema ,    parquetMetadata . getBlocks (  )  ,    dataSource ,    HiveTestUtils . TYPE _ MANAGER ,    newSimpleAggregatedMemoryContext (  )  )  ;", "assertEquals ( parquetReader . getPosition (  )  ,     0  )  ;", "int   rowsProcessed    =     0  ;", "Iterator <  ?  >    iterator    =    expectedValues . iterator (  )  ;", "for    ( int   batchSize    =    parquetReader . nextBatch (  )  ;    batchSize    >  =     0  ;    batchSize    =    parquetReader . nextBatch (  )  )     {", "ColumnDescriptor   columnDescriptor    =    fileSchema . getColumns (  )  . get (  0  )  ;", "Block   block    =    parquetReader . readPrimitive ( columnDescriptor ,    type )  ;", "for    ( int   i    =     0  ;    i    <    batchSize ;    i +  +  )     {", "assertTrue ( iterator . hasNext (  )  )  ;", "Object   expected    =    iterator . next (  )  ;", "Object   actual    =     . decodeObject ( type ,    block ,    i )  ;", "assertEquals ( actual ,    expected )  ;", "}", "rowsProcessed    +  =    batchSize ;", "assertEquals ( parquetReader . getPosition (  )  ,    rowsProcessed )  ;", "}", "assertFalse ( iterator . hasNext (  )  )  ;", "assertEquals ( parquetReader . getPosition (  )  ,    rowsProcessed )  ;", "parquetReader . close (  )  ;", "}", "METHOD_END"], "methodName": ["assertFileContents"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "assertRoundTrip ( objectInspector ,    writeValues ,    readValues ,    type ,    Optional . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertRoundTrip"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "for    ( WriterVersion   version    :    versions )     {", "for    ( CompressionCodecName   compressionCodecName    :    compressions )     {", "try    (  . TempFile   tempFile    =    new    . TempFile (  \" test \"  ,     \" parquet \"  )  )     {", "JobConf   jobConf    =    new   JobConf (  )  ;", "jobConf . setEnum ( ParquetOutputFormat . COMPRESSION ,    compressionCodecName )  ;", "jobConf . setBoolean ( ParquetOutputFormat . ENABLE _ DICTIONARY ,    true )  ;", "jobConf . setEnum ( ParquetOutputFormat . WRITER _ VERSION ,    version )  ;", ". writeParquetColumn ( jobConf ,    tempFile . getFile (  )  ,    compressionCodecName ,    objectInspector ,    writeValues . iterator (  )  ,    parquetSchema )  ;", ". assertFileContents ( jobConf ,    tempFile ,    readValues ,    type )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["assertRoundTrip"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "return   ObjectInspectorFactory . getStandardStructObjectInspector ( ImmutableList . of ( name )  ,    ImmutableList . of ( objectInspector )  )  ;", "}", "METHOD_END"], "methodName": ["createSettableStructObjectInspector"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "Properties   orderTableProperties    =    new   Properties (  )  ;", "orderTableProperties . setProperty (  \" columns \"  ,    name )  ;", "orderTableProperties . setProperty (  \" columns . types \"  ,    type )  ;", "return   orderTableProperties ;", "}", "METHOD_END"], "methodName": ["createTableProperties"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "if    ( block . isNull ( position )  )     {", "return   null ;", "}", "return   type . getObjectValue ( SESSION ,    block ,    position )  ;", "}", "METHOD_END"], "methodName": ["decodeObject"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "ParquetTester   parquetTester    =    new   ParquetTester (  )  ;", "parquetTester . compressions    =    ImmutableSet . of ( CompressionCodecName . GZIP ,    CompressionCodecName . UNCOMPRESSED ,    CompressionCodecName . SNAPPY ,    CompressionCodecName . LZO )  ;", "parquetTester . versions    =    ImmutableSet . copyOf ( WriterVersion . values (  )  )  ;", "return   parquetTester ;", "}", "METHOD_END"], "methodName": ["fullParquetTester"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "return    (  )     -  >    new   com . google . common . collect . AbstractIterator < T >  (  )     {", "private   final   Iterator < T >    delegate    =    iterable . iterator (  )  ;", "private   int   position ;", "@ Override", "protected   T   computeNext (  )     {", "( position )  +  +  ;", "if    (  ( position )     >    n )     {", "position    =     0  ;", "return   null ;", "}", "if    (  !  ( delegate . hasNext (  )  )  )     {", "return   endOfData (  )  ;", "}", "return   delegate . next (  )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["insertNullEvery"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "ParquetTester   parquetTester    =    new   ParquetTester (  )  ;", "parquetTester . compressions    =    ImmutableSet . of ( CompressionCodecName . GZIP )  ;", "parquetTester . versions    =    ImmutableSet . of ( PARQUET _  1  _  0  )  ;", "return   parquetTester ;", "}", "METHOD_END"], "methodName": ["quickParquetTester"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "return   Lists . reverse ( ImmutableList . copyOf ( iterable )  )  ;", "}", "METHOD_END"], "methodName": ["reverse"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "testRoundTripType ( objectInspector ,    writeValues ,    readValues ,    type )  ;", "assertRoundTrip ( objectInspector ,    transform ( writeValues ,    constant ( null )  )  ,    transform ( readValues ,    constant ( null )  )  ,    type )  ;", "}", "METHOD_END"], "methodName": ["testRoundTrip"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "testRoundTripType ( objectInspector ,    writeValues ,    readValues ,    type )  ;", "assertRoundTrip ( objectInspector ,    transform ( writeValues ,    constant ( null )  )  ,    transform ( readValues ,    constant ( null )  )  ,    type ,    Schema )  ;", "}", "METHOD_END"], "methodName": ["testRoundTrip"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "testRoundTrip ( columnObjectInspector ,    writeValues ,    writeValues ,    parameterType )  ;", "}", "METHOD_END"], "methodName": ["testRoundTrip"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "testRoundTrip ( columnObjectInspector ,    writeValues ,    transform ( writeValues ,    readTransform )  ,    parameterType )  ;", "}", "METHOD_END"], "methodName": ["testRoundTrip"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "assertRoundTrip ( objectInspector ,    writeValues ,    readValues ,    type )  ;", "assertRoundTrip ( objectInspector ,     . reverse ( writeValues )  ,     . reverse ( readValues )  ,    type )  ;", "assertRoundTrip ( objectInspector ,     . insertNullEvery (  5  ,    writeValues )  ,     . insertNullEvery (  5  ,    readValues )  ,    type )  ;", "assertRoundTrip ( objectInspector ,     . insertNullEvery (  5  ,     . reverse ( writeValues )  )  ,     . insertNullEvery (  5  ,     . reverse ( readValues )  )  ,    type )  ;", "}", "METHOD_END"], "methodName": ["testRoundTripType"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "RecordWriter   recordWriter    =    new   TestMapredParquetOutputFormat ( parquetSchema )  . getHiveRecordWriter ( jobConf ,    new   Path ( outputFile . toURI (  )  )  ,    Text . class ,     ( compressionCodecName    !  =     ( CompressionCodecName . UNCOMPRESSED )  )  ,    ParquetTester . createTableProperties (  \" test \"  ,    columnObjectInspector . getTypeName (  )  )  ,     (  )     -  >     {", "}  )  ;", "SettableStructObjectInspector   objectInspector    =    ParquetTester . createSettableStructObjectInspector (  \" test \"  ,    columnObjectInspector )  ;", "Object   row    =    objectInspector . create (  )  ;", "List < StructField >    fields    =    ImmutableList . copyOf ( objectInspector . getAllStructFieldRefs (  )  )  ;", "while    ( values . hasNext (  )  )     {", "Object   value    =    values . next (  )  ;", "objectInspector . setStructFieldData ( row ,    fields . get (  0  )  ,    value )  ;", "ParquetHiveSerDe   serde    =    new   ParquetHiveSerDe (  )  ;", "serde . initialize ( jobConf ,    ParquetTester . createTableProperties (  \" test \"  ,    columnObjectInspector . getTypeName (  )  )  ,    null )  ;", "Writable   record    =    serde . serialize ( row ,    objectInspector )  ;", "recordWriter . write ( record )  ;", "}", "recordWriter . close ( false )  ;", "return   succinctBytes ( outputFile . length (  )  )  ;", "}", "METHOD_END"], "methodName": ["writeParquetColumn"], "fileName": "com.facebook.presto.hive.parquet.ParquetTester"}, {"methodBody": ["METHOD_START", "{", "if    (  ( timestampBinary . length (  )  )     !  =     1  2  )     {", "throw   new   com . facebook . presto . spi . PrestoException ( HiveErrorCode . HIVE _ BAD _ DATA ,     (  \" Parquet   timestamp   must   be    1  2    bytes ,    actual    \"     +     ( timestampBinary . length (  )  )  )  )  ;", "}", "byte [  ]    bytes    =    timestampBinary . getBytes (  )  ;", "long   timeOfDayNanos    =    Longs . fromBytes ( bytes [  7  ]  ,    bytes [  6  ]  ,    bytes [  5  ]  ,    bytes [  4  ]  ,    bytes [  3  ]  ,    bytes [  2  ]  ,    bytes [  1  ]  ,    bytes [  0  ]  )  ;", "int   julianDay    =    Ints . fromBytes ( bytes [  1  1  ]  ,    bytes [  1  0  ]  ,    bytes [  9  ]  ,    bytes [  8  ]  )  ;", "return    (  . julianDayToMillis ( julianDay )  )     +     ( timeOfDayNanos    /     (  . NANOS _ PER _ MILLISECOND )  )  ;", "}", "METHOD_END"], "methodName": ["getTimestampMillis"], "fileName": "com.facebook.presto.hive.parquet.ParquetTimestampUtils"}, {"methodBody": ["METHOD_START", "{", "return    ( julianDay    -     ( ParquetTimestampUtils . JULIAN _ EPOCH _ OFFSET _ DAYS )  )     *     ( ParquetTimestampUtils . MILLIS _ IN _ DAY )  ;", "}", "METHOD_END"], "methodName": ["julianDayToMillis"], "fileName": "com.facebook.presto.hive.parquet.ParquetTimestampUtils"}, {"methodBody": ["METHOD_START", "{", "if    (  ( descriptor . getPrimitiveType (  )  . getOriginalType (  )  )     !  =     ( OriginalType . DECIMAL )  )     {", "return   Optional . empty (  )  ;", "}", "DecimalMetadata   decimalMetadata    =    descriptor . getPrimitiveType (  )  . getDecimalMetadata (  )  ;", "return   Optional . of ( DecimalType . createDecimalType ( decimalMetadata . getPrecision (  )  ,    decimalMetadata . getScale (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["createDecimalType"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "return   new   ColumnIOFactory (  )  . getColumnIO ( requestedSchema ,    fileSchema ,    true )  . getLeaves (  )  ;", "}", "METHOD_END"], "methodName": ["getColumns"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( index    =  =     (  -  1  )  )     {", "return   Optional . empty (  )  ;", "}", "PrimitiveColumnIO   columnIO    =     . getColumns ( fileSchema ,    requestedSchema )  . get ( index )  ;", "ColumnDescriptor   descriptor    =    columnIO . getColumnDescriptor (  )  ;", "return   Optional . of ( new   RichColumnDescriptor ( descriptor . getPath (  )  ,    columnIO . getType (  )  . asPrimitiveType (  )  ,    descriptor . getMaxRepetitionLevel (  )  ,    descriptor . getMaxDefinitionLevel (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getDescriptor"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( path . size (  )  )     >  =     1  )  ,     \" Parquet   nested   path   should   have   at   least   one   component \"  )  ;", "int   index    =     . getPathIndex ( fileSchema ,    requestedSchema ,    path )  ;", "return    . getDescriptor ( fileSchema ,    requestedSchema ,    index )  ;", "}", "METHOD_END"], "methodName": ["getDescriptor"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   fileSchema . getFieldIndex ( name )  ;", "}    catch    ( InvalidRecordException   e )     {", "for    (    type    :    fileSchema . getFields (  )  )     {", "if    ( type . getName (  )  . equalsIgnoreCase ( name )  )     {", "return   fileSchema . getFieldIndex ( type . getName (  )  )  ;", "}", "}", "return    -  1  ;", "}", "}", "METHOD_END"], "methodName": ["getFieldIndex"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "switch    ( encoding )     {", "case   PLAIN    :", "return   ParquetEncoding . PLAIN ;", "case   RLE    :", "return   ParquetEncoding . RLE ;", "case   BIT _ PACKED    :", "return   ParquetEncoding . BIT _ PACKED ;", "case   PLAIN _ DICTIONARY    :", "return   ParquetEncoding . PLAIN _ DICTIONARY ;", "case   DELTA _ BINARY _ PACKED    :", "return   ParquetEncoding . DELTA _ BINARY _ PACKED ;", "case   DELTA _ LENGTH _ BYTE _ ARRAY    :", "return   ParquetEncoding . DELTA _ LENGTH _ BYTE _ ARRAY ;", "case   DELTA _ BYTE _ ARRAY    :", "return   ParquetEncoding . DELTA _ BYTE _ ARRAY ;", "case   RLE _ DICTIONARY    :", "return   ParquetEncoding . RLE _ DICTIONARY ;", "default    :", "throw   new   io . ParquetDecodingException (  (  \" Unsupported   Parquet   encoding :     \"     +    encoding )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getParquetEncoding"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( useParquetColumnNames )     {", "return    . getParquetTypeByName ( column . getName (  )  ,    messageType )  ;", "}", "if    (  ( column . getHiveColumnIndex (  )  )     <     ( messageType . getFieldCount (  )  )  )     {", "return   messageType . getType ( column . getHiveColumnIndex (  )  )  ;", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["getParquetType"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( messageType . containsField ( columnName )  )     {", "return   messageType . g ( columnName )  ;", "}", "for    ( Type   type    :    messageType . getFields (  )  )     {", "if    ( type . getName (  )  . equalsIgnoreCase ( columnName )  )     {", "return   type ;", "}", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["getParquetTypeByName"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "int   maxLevel    =    path . size (  )  ;", "List < PrimitiveColumnIO >    columns    =     . getColumns ( fileSchema ,    requestedSchema )  ;", "int   index    =     -  1  ;", "for    ( int   columnIndex    =     0  ;    columnIndex    <     ( columns . size (  )  )  ;    columnIndex +  +  )     {", "ColumnIO [  ]    fields    =    columns . get ( columnIndex )  . getPath (  )  ;", "if    (  ( fields . length )     <  =    maxLevel )     {", "continue ;", "}", "if    ( fields [ maxLevel ]  . getName (  )  . equalsIgnoreCase ( path . get (  ( maxLevel    -     1  )  )  )  )     {", "boolean   match    =    true ;", "for    ( int   level    =     0  ;    level    <     ( maxLevel    -     1  )  ;    level +  +  )     {", "if    (  !  ( fields [  ( level    +     1  )  ]  . getName (  )  . equalsIgnoreCase ( path . get ( level )  )  )  )     {", "match    =    false ;", "}", "}", "if    ( match )     {", "index    =    columnIndex ;", "}", "}", "}", "return   index ;", "}", "METHOD_END"], "methodName": ["getPathIndex"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "switch    ( descriptor . getType (  )  )     {", "case   BOOLEAN    :", "return   spi . type . BooleanType . BOOLEAN ;", "case   BINARY    :", "return   ParquetTypeUtils . createDecimalType ( descriptor )  . orElse ( VARCHAR )  ;", "case   FLOAT    :", "return   spi . type . RealType . REAL ;", "case   DOUBLE    :", "return   spi . type . DoubleType . DOUBLE ;", "case   INT 3  2     :", "return   ParquetTypeUtils . createDecimalType ( descriptor )  . orElse ( INTEGER )  ;", "case   INT 6  4     :", "return   ParquetTypeUtils . createDecimalType ( descriptor )  . orElse ( BIGINT )  ;", "case   INT 9  6     :", "return   spi . type . TimestampType . TIMESTAMP ;", "case   FIXED _ LEN _ BYTE _ ARRAY    :", "return   ParquetTypeUtils . createDecimalType ( descriptor )  . orElseThrow (  (  )     -  >    new   PrestoException ( NOT _ SUPPORTED ,     (  \" Parquet   type   FIXED _ LEN _ BYTE _ ARRAY   supported   as   DECIMAL ;    got    \"     +     ( descriptor . getPrimitiveType (  )  . getOriginalType (  )  )  )  )  )  ;", "default    :", "throw   new   PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,     (  \" Unsupported   parquet   type :     \"     +     ( descriptor . getType (  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getPrestoType"], "fileName": "com.facebook.presto.hive.parquet.ParquetTypeUtils"}, {"methodBody": ["METHOD_START", "{", "if    (  ! condition )     {", "throw   new   CorruptionException ( String . format ( formatString ,    args )  )  ;", "}", "}", "METHOD_END"], "methodName": ["validateParquet"], "fileName": "com.facebook.presto.hive.parquet.ParquetValidationUtils"}, {"methodBody": ["METHOD_START", "{", "return   primitiveType ;", "}", "METHOD_END"], "methodName": ["getPrimitiveType"], "fileName": "com.facebook.presto.hive.parquet.RichColumnDescriptor"}, {"methodBody": ["METHOD_START", "{", "Timestamp   timestamp    =    Timestamp . valueOf ( timestampString )  ;", "Binary   timestampBytes    =    NanoTimeUtils . getNanoTime ( timestamp ,    false )  . toBinary (  )  ;", "long   decodedTimestampMillis    =     . getTimestampMillis ( timestampBytes )  ;", "assertEquals ( decodedTimestampMillis ,    timestamp . getTime (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertTimestampCorrect"], "fileName": "com.facebook.presto.hive.parquet.TestParquetTimestampUtils"}, {"methodBody": ["METHOD_START", "{", "TestParquetTimestampUtils . assertTimestampCorrect (  \"  2  0  1  1  -  0  1  -  0  1     0  0  :  0  0  :  0  0  .  0  0  0  0  0  0  0  0  0  \"  )  ;", "TestParquetTimestampUtils . assertTimestampCorrect (  \"  2  0  0  1  -  0  1  -  0  1     0  1  :  0  1  :  0  1  .  0  0  0  0  0  0  0  0  1  \"  )  ;", "TestParquetTimestampUtils . assertTimestampCorrect (  \"  2  0  1  5  -  1  2  -  3  1     2  3  :  5  9  :  5  9  .  9  9  9  9  9  9  9  9  9  \"  )  ;", "}", "METHOD_END"], "methodName": ["testGetTimestampMillis"], "fileName": "com.facebook.presto.hive.parquet.TestParquetTimestampUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "byte [  ]    invalidLengthBinaryTimestamp    =    new   byte [  8  ]  ;", ". getTimestampMillis ( Binary . fromByteArray ( invalidLengthBinaryTimestamp )  )  ;", "}    catch    ( PrestoException   e )     {", "assertEquals ( e . getErrorCode (  )  ,    HiveErrorCode . HIVE _ BAD _ DATA . toErrorCode (  )  )  ;", "assertEquals ( e . getMessage (  )  ,     \" Parquet   timestamp   must   be    1  2    bytes ,    actual    8  \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testInvalidBinaryLength"], "fileName": "com.facebook.presto.hive.parquet.TestParquetTimestampUtils"}, {"methodBody": ["METHOD_START", "{", "BooleanStatistics   statistics    =    new   BooleanStatistics (  )  ;", "statistics . setMinMax ( minimum ,    maximum )  ;", "return   statistics ;", "}", "METHOD_END"], "methodName": ["booleanColumnStats"], "fileName": "com.facebook.presto.hive.parquet.TestTupleDomainParquetPredicate"}, {"methodBody": ["METHOD_START", "{", "DoubleStatistics   statistics    =    new   DoubleStatistics (  )  ;", "statistics . setMinMax ( minimum ,    maximum )  ;", "return   statistics ;", "}", "METHOD_END"], "methodName": ["doubleColumnStats"], "fileName": "com.facebook.presto.hive.parquet.TestTupleDomainParquetPredicate"}, {"methodBody": ["METHOD_START", "{", "FloatStatistics   statistics    =    new   FloatStatistics (  )  ;", "statistics . setMinMax ( minimum ,    maximum )  ;", "return   statistics ;", "}", "METHOD_END"], "methodName": ["floatColumnStats"], "fileName": "com.facebook.presto.hive.parquet.TestTupleDomainParquetPredicate"}, {"methodBody": ["METHOD_START", "{", "LongStatistics   statistics    =    new   LongStatistics (  )  ;", "statistics . setMinMax ( minimum ,    maximum )  ;", "return   statistics ;", "}", "METHOD_END"], "methodName": ["longColumnStats"], "fileName": "com.facebook.presto.hive.parquet.TestTupleDomainParquetPredicate"}, {"methodBody": ["METHOD_START", "{", "BinaryStatistics   statistics    =    new   BinaryStatistics (  )  ;", "statistics . setMinMax ( Binary . fromString ( minimum )  ,    Binary . fromString ( maximum )  )  ;", "return   statistics ;", "}", "METHOD_END"], "methodName": ["stringColumnStats"], "fileName": "com.facebook.presto.hive.parquet.TestTupleDomainParquetPredicate"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( TupleDomainParquetPredicate . getDomain ( VarcharType . createUnboundedVarcharType (  )  ,     0  ,    null )  ,    all ( VarcharType . createUnboundedVarcharType (  )  )  )  ;", "assertEquals ( TupleDomainParquetPredicate . getDomain ( VarcharType . createUnboundedVarcharType (  )  ,     1  0  ,     . stringColumnStats (  \" taco \"  ,     \" taco \"  )  )  ,    singleValue ( VarcharType . createUnboundedVarcharType (  )  ,    Slices . utf 8 Slice (  \" taco \"  )  )  )  ;", "assertEquals ( TupleDomainParquetPredicate . getDomain ( VarcharType . createUnboundedVarcharType (  )  ,     1  0  ,     . stringColumnStats (  \" apple \"  ,     \" taco \"  )  )  ,    create ( ValueSet . ofRanges ( range ( VarcharType . createUnboundedVarcharType (  )  ,    Slices . utf 8 Slice (  \" apple \"  )  ,    true ,    Slices . utf 8 Slice (  \" taco \"  )  ,    true )  )  ,    false )  )  ;", "assertEquals ( TupleDomainParquetPredicate . getDomain ( VarcharType . createUnboundedVarcharType (  )  ,     1  0  ,     . stringColumnStats (  \"  \u00d6\u00d0  \u00b9\u00fa  \"  ,     \"  \u00c3\u00c0  \u00c0\u00fb  \u00bc\u00e1  \"  )  )  ,    create ( ValueSet . ofRanges ( range ( VarcharType . createUnboundedVarcharType (  )  ,    Slices . utf 8 Slice (  \"  \u00d6\u00d0  \u00b9\u00fa  \"  )  ,    true ,    Slices . utf 8 Slice (  \"  \u00c3\u00c0  \u00c0\u00fb  \u00bc\u00e1  \"  )  ,    true )  )  ,    false )  )  ;", "}", "METHOD_END"], "methodName": ["testString"], "fileName": "com.facebook.presto.hive.parquet.TestTupleDomainParquetPredicate"}, {"methodBody": ["METHOD_START", "{", "throw   new   UnsupportedOperationException (  )  ;", "}", "METHOD_END"], "methodName": ["decodeToBinary"], "fileName": "com.facebook.presto.hive.parquet.dictionary.ParquetDictionary"}, {"methodBody": ["METHOD_START", "{", "throw   new   UnsupportedOperationException (  )  ;", "}", "METHOD_END"], "methodName": ["decodeToDouble"], "fileName": "com.facebook.presto.hive.parquet.dictionary.ParquetDictionary"}, {"methodBody": ["METHOD_START", "{", "throw   new   UnsupportedOperationException (  )  ;", "}", "METHOD_END"], "methodName": ["decodeToFloat"], "fileName": "com.facebook.presto.hive.parquet.dictionary.ParquetDictionary"}, {"methodBody": ["METHOD_START", "{", "throw   new   UnsupportedOperationException (  )  ;", "}", "METHOD_END"], "methodName": ["decodeToInt"], "fileName": "com.facebook.presto.hive.parquet.dictionary.ParquetDictionary"}, {"methodBody": ["METHOD_START", "{", "throw   new   UnsupportedOperationException (  )  ;", "}", "METHOD_END"], "methodName": ["decodeToLong"], "fileName": "com.facebook.presto.hive.parquet.dictionary.ParquetDictionary"}, {"methodBody": ["METHOD_START", "{", "return   encoding ;", "}", "METHOD_END"], "methodName": ["getEncoding"], "fileName": "com.facebook.presto.hive.parquet.dictionary.ParquetDictionary"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   decoder . readInt (  )  ;", "}    catch    ( IOException   e )     {", "throw   new   ecodingException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["readInt"], "fileName": "com.facebook.presto.hive.parquet.dictionary.ParquetDictionaryReader"}, {"methodBody": ["METHOD_START", "{", "return   columnDescriptor ;", "}", "METHOD_END"], "methodName": ["getColumnDescriptor"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetDictionaryDescriptor"}, {"methodBody": ["METHOD_START", "{", "return   dictionaryPage ;", "}", "METHOD_END"], "methodName": ["getDictionaryPage"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetDictionaryDescriptor"}, {"methodBody": ["METHOD_START", "{", "ImmutableList . Builder < RichColumnDescriptor >    columnReferences    =    ImmutableList . builder (  )  ;", "for    ( String [  ]    paths    :    requestedSchema . getPaths (  )  )     {", "Optional < RichColumnDescriptor >    descriptor    =    ParquetTypeUtils . getDescriptor ( fileSchema ,    requestedSchema ,    Arrays . asList ( paths )  )  ;", "if    ( descriptor . isPresent (  )  )     {", "columnReferences . add ( descriptor . get (  )  )  ;", "}", "}", "return   new   TupleDomain ( parquetTupleDomain ,    columnReferences . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["buildParquetPredicate"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetPredicateUtils"}, {"methodBody": ["METHOD_START", "{", "Builder < ColumnDescriptor ,    ParquetDictionaryDescriptor >    dictionaries    =    ImmutableMap . builder (  )  ;", "for    ( ColumnChunkMetaData   columnMetaData    :    blockMetadata . getColumns (  )  )     {", "Optional < RichColumnDescriptor >    descriptor    =    ParquetTypeUtils . getDescriptor ( fileSchema ,    requestedSchema ,    Arrays . asList ( columnMetaData . getPath (  )  . toArray (  )  )  )  ;", "if    ( descriptor . isPresent (  )  )     {", "ColumnDescriptor   columnDescriptor    =    descriptor . get (  )  ;", "if    (  (  . isOnlyDictionaryEncodingPages ( columnMetaData . getEncodings (  )  )  )     &  &     (  . isColumnPredicate ( columnDescriptor ,    parquetTupleDomain )  )  )     {", "int   totalSize    =    Math . toIntExact ( columnMetaData . getTotalSize (  )  )  ;", "byte [  ]    buffer    =    new   byte [ totalSize ]  ;", "dataSource . readFully ( columnMetaData . getStartingPos (  )  ,    buffer )  ;", "Optional < ParquetDictionaryPage >    dictionaryPage    =     . readDictionaryPage ( buffer ,    columnMetaData . getCodec (  )  )  ;", "dictionaries . put ( columnDescriptor ,    new   ParquetDictionaryDescriptor ( columnDescriptor ,    dictionaryPage )  )  ;", "break ;", "}", "}", "}", "return   dictionaries . build (  )  ;", "}", "METHOD_END"], "methodName": ["getDictionaries"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetPredicateUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( effectivePredicate . isNone (  )  )     {", "return   TupleDomain . none (  )  ;", "}", "Builder < ColumnDescriptor ,    Domain >     =    ImmutableMap . builder (  )  ;", "for    ( Map . Entry < HiveColumnHandle ,    Domain >    entry    :    effectivePredicate . getDomains (  )  . get (  )  . entrySet (  )  )     {", "Optional < RichColumnDescriptor >    descriptor    =    ParquetTypeUtils . getDescriptor ( fileSchema ,    requestedSchema ,    ImmutableList . of ( entry . getKey (  )  . getName (  )  )  )  ;", "if    ( descriptor . isPresent (  )  )     {", "put ( descriptor . get (  )  ,    entry . getValue (  )  )  ;", "}", "}", "return   TupleDomain . withColumnDomains ( build (  )  )  ;", "}", "METHOD_END"], "methodName": ["getParquetTupleDomain"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetPredicateUtils"}, {"methodBody": ["METHOD_START", "{", "Builder < ColumnDescriptor ,    Statistics <  ?  >  >    statistics    =    ImmutableMap . builder (  )  ;", "for    ( ColumnChunkMetaData   columnMetaData    :    blockMetadata . getColumns (  )  )     {", "Statistics <  ?  >    columnStatistics    =    columnMetaData . getStatistics (  )  ;", "if    ( columnStatistics    !  =    null )     {", "Optional < RichColumnDescriptor >    descriptor    =    TypeUtils . getDescriptor ( fileSchema ,    requestedSchema ,    Arrays . asList ( columnMetaData . getPath (  )  . toArray (  )  )  )  ;", "if    ( descriptor . isPresent (  )  )     {", "statistics . put ( descriptor . get (  )  ,    columnStatistics )  ;", "}", "}", "}", "return   statistics . build (  )  ;", "}", "METHOD_END"], "methodName": ["getStatistics"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetPredicateUtils"}, {"methodBody": ["METHOD_START", "{", "verify ( parquetTupleDomain . getDomains (  )  . isPresent (  )  ,     \" parquetTupleDomain   is   empty \"  )  ;", "return   parquetTupleDomain . getDomains (  )  . get (  )  . keySet (  )  . contains ( columnDescriptor )  ;", "}", "METHOD_END"], "methodName": ["isColumnPredicate"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetPredicateUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( encodings . contains ( Encoding . PLAIN _ DICTIONARY )  )     {", "rrn   S . difference ( encodings ,    ImmutableSof ( Encoding . PLAIN _ DICTIONARY ,    Encoding . RLE ,    Encoding . BIT _ PACKED )  )  . isEmpty (  )  ;", "}", "rrn   false ;", "}", "METHOD_END"], "methodName": ["isOnlyDictionaryEncodingPages"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetPredicateUtils"}, {"methodBody": ["METHOD_START", "{", "Map < ColumnDescriptor ,    Statistics <  ?  >  >    columnStatistics    =    ParquetPredicateUtils . getStatistics ( block ,    fileSchema ,    requestedSchema )  ;", "if    (  !  ( parquetPredicate . matches ( block . getRowCount (  )  ,    columnStatistics )  )  )     {", "return   false ;", "}", "Map < ColumnDescriptor ,    ParquetDictionaryDescriptor >    dictionaries    =    ParquetPredicateUtils . getDictionaries ( block ,    dataSource ,    fileSchema ,    requestedSchema ,    parquetTupleDomain )  ;", "return   parquetPredicate . matches ( dictionaries )  ;", "}", "METHOD_END"], "methodName": ["predicateMatches"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetPredicateUtils"}, {"methodBody": ["METHOD_START", "{", "try    {", "ByteArrayInputStream   inputStream    =    new   ByteArrayInputStream ( data )  ;", "PageHeader   pageHeader    =    Util . readPageHeader ( inputStream )  ;", "if    (  ( pageHeader . type )     !  =     ( PageType . DICTIONARY _ PAGE )  )     {", "return   Optional . empty (  )  ;", "}", "Slice   compressedData    =    Slices . wrappedBuffer ( data ,     (  ( data . length )     -     ( inputStream . available (  )  )  )  ,    pageHeader . getCompressed _ page _ size (  )  )  ;", "DictionaryPageHeader   dicHeader    =    pageHeader . getDictionary _ page _ header (  )  ;", "Encoding   encoding    =    TypeUtils . getEncoding ( Encoding . valueOf ( dicHeader . getEncoding (  )  . name (  )  )  )  ;", "int   dictionarySize    =    dicHeader . getNum _ values (  )  ;", "return   Optional . of ( new   DictionaryPage ( CompressionUtils . decompress ( codecName ,    compressedData ,    pageHeader . getUncompressed _ page _ size (  )  )  ,    dictionarySize ,    encoding )  )  ;", "}    catch    ( IOException   ignored )     {", "return   Optional . empty (  )  ;", "}", "}", "METHOD_END"], "methodName": ["readDictionaryPage"], "fileName": "com.facebook.presto.hive.parquet.predicate.ParquetPredicateUtils"}, {"methodBody": ["METHOD_START", "{", "Set < Encoding >    required    =    ImmutableSet . of ( Encoding . BIT _ PACKED )  ;", "Set < Encoding >    optional    =    ImmutableSet . of ( Encoding . BIT _ PACKED ,    Encoding . RLE )  ;", "Set < Encoding >    repeated    =    ImmutableSet . of ( Encoding . RLE )  ;", "Set < Encoding >    notDictionary    =    ImmutableSet . of ( Encoding . PLAIN )  ;", "Set < Encoding >    mixedDictionary    =    ImmutableSet . of ( Encoding . PLAIN _ DICTIONARY ,    Encoding . PLAIN )  ;", "Set < Encoding >    dictionary    =    ImmutableSet . of ( Encoding . PLAIN _ DICTIONARY )  ;", "assertFalse (  . isOnlyDictionaryEncodingPages ( union ( required ,    notDictionary )  )  ,     \" required   notDictionary \"  )  ;", "assertFalse (  . isOnlyDictionaryEncodingPages ( union ( optional ,    notDictionary )  )  ,     \" optional   notDictionary \"  )  ;", "assertFalse (  . isOnlyDictionaryEncodingPages ( union ( repeated ,    notDictionary )  )  ,     \" repeated   notDictionary \"  )  ;", "assertFalse (  . isOnlyDictionaryEncodingPages ( union ( required ,    mixedDictionary )  )  ,     \" required   mixedDictionary \"  )  ;", "assertFalse (  . isOnlyDictionaryEncodingPages ( union ( optional ,    mixedDictionary )  )  ,     \" optional   mixedDictionary \"  )  ;", "assertFalse (  . isOnlyDictionaryEncodingPages ( union ( repeated ,    mixedDictionary )  )  ,     \" repeated   mixedDictionary \"  )  ;", "assertTrue (  . isOnlyDictionaryEncodingPages ( union ( required ,    dictionary )  )  ,     \" required   dictionary \"  )  ;", "assertTrue (  . isOnlyDictionaryEncodingPages ( union ( optional ,    dictionary )  )  ,     \" optional   dictionary \"  )  ;", "assertTrue (  . isOnlyDictionaryEncodingPages ( union ( repeated ,    dictionary )  )  ,     \" repeated   dictionary \"  )  ;", "}", "METHOD_END"], "methodName": ["testDictionaryEncodingCasesV1"], "fileName": "com.facebook.presto.hive.parquet.predicate.TestParquetPredicateUtils"}, {"methodBody": ["METHOD_START", "{", "return   TupleDomainParquetPredicate . createDomain ( type ,    hasNullValue ,    rangeStatistics ,     (    value )     -  >    value )  ;", "}", "METHOD_END"], "methodName": ["createDomain"], "fileName": "com.facebook.presto.hive.parquet.predicate.TupleDomainParquetPredicate"}, {"methodBody": ["METHOD_START", "{", "F   min    =    rangeStatistics . getMin (  )  ;", "F   max    =    rangeStatistics . getMax (  )  ;", "if    (  ( min    !  =    null )     &  &     ( max    !  =    null )  )     {", "return    . create ( ValueSet . ofRanges ( Range . range ( type ,    function . apply ( min )  ,    true ,    function . apply ( max )  ,    true )  )  ,    hasNullValue )  ;", "}", "if    ( max    !  =    null )     {", "return    . create ( ValueSet . ofRanges ( Range . lessThanOrEqual ( type ,    function . apply ( max )  )  )  ,    hasNullValue )  ;", "}", "if    ( min    !  =    null )     {", "return    . create ( ValueSet . ofRanges ( Range . greaterThanOrEqual ( type ,    function . apply ( min )  )  )  ,    hasNullValue )  ;", "}", "return    . create ( ValueSet . all ( type )  ,    hasNullValue )  ;", "}", "METHOD_END"], "methodName": ["createDomain"], "fileName": "com.facebook.presto.hive.parquet.predicate.TupleDomainParquetPredicate"}, {"methodBody": ["METHOD_START", "{", "return   descriptor ;", "}", "METHOD_END"], "methodName": ["getDescriptor"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunk"}, {"methodBody": ["METHOD_START", "{", "return   pos ;", "}", "METHOD_END"], "methodName": ["getPosition"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunk"}, {"methodBody": ["METHOD_START", "{", "Slice   slice    =    Slices . wrappedBuffer ( buf ,    pos ,    size )  ;", "pos    +  =    size ;", "return   slice ;", "}", "METHOD_END"], "methodName": ["getSlice"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunk"}, {"methodBody": ["METHOD_START", "{", "List < ParquetDataPage >    pages    =    new   ArrayList <  >  (  )  ;", "ParquetDictionaryPage   dictionaryPage    =    null ;", "long   valueCount    =     0  ;", "while    ( valueCount    <     ( descriptor . gMetaData (  )  . getValueCount (  )  )  )     {", "PageHeader   pageHeader    =    readPageHeader (  )  ;", "int   uncompressedPageSize    =    pageHeader . getUncompressed _ page _ size (  )  ;", "int   compressedPageSize    =    pageHeader . getCompressed _ page _ size (  )  ;", "switch    ( pageHeader . type )     {", "case   DICTIONARY _ PAGE    :", "if    ( dictionaryPage    !  =    null )     {", "throw   new   ParquetCorruptionException (  \"  % s   has   more   than   one   dictionary   page   in   column   chunk \"  ,    descriptor . getColumnDescriptor (  )  )  ;", "}", "dictionaryPage    =    readDictionaryPage ( pageHeader ,    uncompressedPageSize ,    compressedPageSize )  ;", "break ;", "case   DATA _ PAGE    :", "valueCount    +  =    readDataPageV 1  ( pageHeader ,    uncompressedPageSize ,    compressedPageSize ,    pages )  ;", "break ;", "case   DATA _ PAGE _ V 2     :", "valueCount    +  =    readDataPageV 2  ( pageHeader ,    uncompressedPageSize ,    compressedPageSize ,    pages )  ;", "break ;", "default    :", "skip ( compressedPageSize )  ;", "break ;", "}", "}", "return   new   ParquetPageReader ( descriptor . gMetaData (  )  . getCodec (  )  ,    pages ,    dictionaryPage )  ;", "}", "METHOD_END"], "methodName": ["readAllPages"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunk"}, {"methodBody": ["METHOD_START", "{", "DataPageHeader   dataHeaderV 1     =    pageHeader . getData _ page _ header (  )  ;", "pages . add ( new   ParquetDataPageV 1  ( getSlice ( compressedPageSize )  ,    dataHeaderV 1  . getNum _ values (  )  ,    uncompressedPageSize ,    ParquetMetadataReader . readStats ( dataHeaderV 1  . getStatistics (  )  ,    descriptor . gDescriptor (  )  . getType (  )  )  ,    ParquetTypeUtils . getParquetEncoding ( Encoding . valueOf ( dataHeaderV 1  . getRepetition _ level _ encoding (  )  . name (  )  )  )  ,    ParquetTypeUtils . getParquetEncoding ( Encoding . valueOf ( dataHeaderV 1  . getDefinition _ level _ encoding (  )  . name (  )  )  )  ,    ParquetTypeUtils . getParquetEncoding ( Encoding . valueOf ( dataHeaderV 1  . getEncoding (  )  . name (  )  )  )  )  )  ;", "return   dataHeaderV 1  . getNum _ values (  )  ;", "}", "METHOD_END"], "methodName": ["readDataPageV1"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunk"}, {"methodBody": ["METHOD_START", "{", "DataPageHeaderV 2    dataHeaderV 2     =    pageHeader . getData _ page _ header _ v 2  (  )  ;", "int   dataSize    =     ( compressedPageSize    -     ( dataHeaderV 2  . getRepetition _ levels _ byte _ length (  )  )  )     -     ( dataHeaderV 2  . getDefinition _ levels _ byte _ length (  )  )  ;", "pages . add ( new   ParquetDataPageV 2  ( dataHeaderV 2  . getNum _ rows (  )  ,    dataHeaderV 2  . getNum _ nulls (  )  ,    dataHeaderV 2  . getNum _ values (  )  ,    getSlice ( dataHeaderV 2  . getRepetition _ levels _ byte _ length (  )  )  ,    getSlice ( dataHeaderV 2  . getDefinition _ levels _ byte _ length (  )  )  ,    ParquetTypeUtils . getParquetEncoding ( Encoding . valueOf ( dataHeaderV 2  . getEncoding (  )  . name (  )  )  )  ,    getSlice ( dataSize )  ,    uncompressedPageSize ,    ParquetMetadataReader . readStats ( dataHeaderV 2  . getStatistics (  )  ,    descriptor . gDescriptor (  )  . getType (  )  )  ,    dataHeaderV 2  . isIs _ compressed (  )  )  )  ;", "return   dataHeaderV 2  . getNum _ values (  )  ;", "}", "METHOD_END"], "methodName": ["readDataPageV2"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunk"}, {"methodBody": ["METHOD_START", "{", "DictionaryPageHeader   dicHeader    =    pageHeader . getDictionary _ page _ header (  )  ;", "return   new   DictionaryPage ( getSlice ( compressedPageSize )  ,    uncompressedPageSize ,    dicHeader . getNum _ values (  )  ,    TypeUtils . getEncoding ( Encoding . valueOf ( dicHeader . getEncoding (  )  . name (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["readDictionaryPage"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunk"}, {"methodBody": ["METHOD_START", "{", "return   Util . readPageHeader ( this )  ;", "}", "METHOD_END"], "methodName": ["readPageHeader"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunk"}, {"methodBody": ["METHOD_START", "{", "return   columnChunkMetaData ;", "}", "METHOD_END"], "methodName": ["getColumnChunkMetaData"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunkDescriptor"}, {"methodBody": ["METHOD_START", "{", "return   columnDescriptor ;", "}", "METHOD_END"], "methodName": ["getColumnDescriptor"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunkDescriptor"}, {"methodBody": ["METHOD_START", "{", "return   size ;", "}", "METHOD_END"], "methodName": ["getSize"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnChunkDescriptor"}, {"methodBody": ["METHOD_START", "{", "if    ( maxLevel    =  =     0  )     {", "return   new   ParquetLevelNullReader (  )  ;", "}", "return   new   ParquetLevelRLEReader ( new   column . values . rle . RunLengthBitPackingHybridDecoder ( BytesUtils . getWidthFromMaxInt ( maxLevel )  ,    new   ByteArrayInputStream ( slice . getBytes (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["buildLevelRLEReader"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "Optional < Type >    type    =    ParquetTypeUtils . createDecimalType ( descriptor )  ;", "if    ( type . isPresent (  )  )     {", "DecimalType   decimalType    =     (  ( DecimalType )     ( type . get (  )  )  )  ;", "return   Optional . of ( ParquetDecimalFactory . createReader ( descriptor ,    decimalType . getPrecision (  )  ,    decimalType . getScale (  )  )  )  ;", "}", "return   Optional . empty (  )  ;", "}", "METHOD_END"], "methodName": ["createDecimalColumnReader"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "switch    ( descriptor . getType (  )  )     {", "case   BOOLEAN    :", "return   new   ParquetBooleanColumnReader ( descriptor )  ;", "case   INT 3  2     :", "return   ParquetColumnReader . createDecimalColumnReader ( descriptor )  . orElse ( new   ParquetIntColumnReader ( descriptor )  )  ;", "case   INT 6  4     :", "return   ParquetColumnReader . createDecimalColumnReader ( descriptor )  . orElse ( new   ParquetLongColumnReader ( descriptor )  )  ;", "case   INT 9  6     :", "return   new   ParquetTimestampColumnReader ( descriptor )  ;", "case   FLOAT    :", "return   new   ParquetFloatColumnReader ( descriptor )  ;", "case   DOUBLE    :", "return   new   ParquetDoubleColumnReader ( descriptor )  ;", "case   BINARY    :", "return   ParquetColumnReader . createDecimalColumnReader ( descriptor )  . orElse ( new   ParquetBinaryColumnReader ( descriptor )  )  ;", "case   FIXED _ LEN _ BYTE _ ARRAY    :", "return   ParquetColumnReader . createDecimalColumnReader ( descriptor )  . orElseThrow (  (  )     -  >    new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,     (  \" Parquet   type   FIXED _ LEN _ BYTE _ ARRAY   supported   as   DECIMAL ;    got    \"     +     ( descriptor . getPrimitiveType (  )  . getOriginalType (  )  )  )  )  )  ;", "default    :", "throw   new   spi . PrestoException ( spi . StandardErrorCode . NOT _ SUPPORTED ,     (  \" Unsupported   parquet   type :     \"     +     ( descriptor . getType (  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["createReader"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "return   columnDescriptor ;", "}", "METHOD_END"], "methodName": ["getDescriptor"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "return   pageReader ;", "}", "METHOD_END"], "methodName": ["getPageReader"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "ValuesReader   valuesReader ;", "if    ( dataEncoding . usesDictionary (  )  )     {", "if    (  ( dictionary )     =  =    null )     {", "throw   new   DecodingException (  \" Dictionary   is   missing   for   Page \"  )  ;", "}", "valuesReader    =    dataEncoding . getDictionaryBasedValuesReader ( columnDescriptor ,    ValuesType . VALUES ,    dictionary )  ;", "} else    {", "valuesReader    =    dataEncoding . getValuesReader ( columnDescriptor ,    ValuesType . VALUES )  ;", "}", "try    {", "valuesReader . initFromPage ( valueCount ,    bytes ,    offset )  ;", "return   valuesReader ;", "}    catch    ( IOException   e )     {", "throw   new   DecodingException (  (  \" Error   reading   parquet   page   in   column    \"     +     ( columnDescriptor )  )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["initDataReader"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "readOffset    =     ( readOffset )     +     ( nextBatchSize )  ;", "nextBatchSize    =    batchSize ;", "}", "METHOD_END"], "methodName": ["prepareNextRead"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "page    =    pageReader . readPage (  )  ;", "ValidationUtils . validate (  (  ( page )     !  =    null )  ,     \" Not   enough   values   to   read   in   column   chunk \"  )  ;", "remainingValueCountInPage    =    page . getValueCount (  )  ;", "if    (  ( page )    instanceof   DataPageV 1  )     {", "valuesReader    =    readPageV 1  (  (  ( DataPageV 1  )     ( page )  )  )  ;", "} else    {", "valuesReader    =    readPageV 2  (  (  ( DataPageV 2  )     ( page )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["readNextPage"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "ValuesReader   rlReader    =    page . getRepetitionLevelEncoding (  )  . getValuesReader ( columnDescriptor ,    ParquetValuesType . REPETITION _ LEVEL )  ;", "ValuesReader   dlReader    =    page . getDefinitionLevelEncoding (  )  . getValuesReader ( columnDescriptor ,    ParquetValuesType . DEFINITION _ LEVEL )  ;", "repetitionReader    =    new   ParquetLevelValuesReader ( rlReader )  ;", "definitionReader    =    new   ParquetLevelValuesReader ( dlReader )  ;", "try    {", "byte [  ]    bytes    =    page . getSlice (  )  . getBytes (  )  ;", "rlReader . initFromPage ( page . getValueCount (  )  ,    bytes ,     0  )  ;", "int   offset    =    rlReader . getNextOffset (  )  ;", "dlReader . initFromPage ( page . getValueCount (  )  ,    bytes ,    offset )  ;", "offset    =    dlReader . getNextOffset (  )  ;", "return   initDataReader ( page . getValueEncoding (  )  ,    bytes ,    offset ,    page . getValueCount (  )  )  ;", "}    catch    ( IOException   e )     {", "throw   new   io . ParquetDecodingException (  (  (  (  \" Error   reading   page    \"     +    page )     +     \"    in   column    \"  )     +     ( columnDescriptor )  )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["readPageV1"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "repetitionReader    =    buildLevelRLEReader ( columnDescriptor . getMaxRepetitionLevel (  )  ,    page . getRepetitionLevels (  )  )  ;", "definitionReader    =    buildLevelRLEReader ( columnDescriptor . getMaxDefinitionLevel (  )  ,    page . getDefinitionLevels (  )  )  ;", "return   initDataReader ( page . getDataEncoding (  )  ,    page . getSlice (  )  . getBytes (  )  ,     0  ,    page . getValueCount (  )  )  ;", "}", "METHOD_END"], "methodName": ["readPageV2"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "seek (  )  ;", "BlockBuilder   blockBuilder    =    type . createBlockBuilder ( null ,    nextBatchSize )  ;", "int   valueCount    =     0  ;", "while    ( valueCount    <     ( nextBatchSize )  )     {", "if    (  ( page )     =  =    null )     {", "NextPage (  )  ;", "}", "int   numValues    =    Math . min ( remainingValueCountInPage ,     (  ( nextBatchSize )     -    valueCount )  )  ;", "Values ( blockBuilder ,    numValues ,    type ,    positions )  ;", "valueCount    +  =    numValues ;", "updatePosition ( numValues )  ;", "}", "checkArgument (  ( valueCount    =  =     ( nextBatchSize )  )  ,     \" valueCount    % s   not   equals   to   batchSize    % s \"  ,    valueCount ,    nextBatchSize )  ;", "Offset    =     0  ;", "nextBatchSize    =     0  ;", "return   blockBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["readPrimitive"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "definitionLevel    =    definitionReader . readLevel (  )  ;", "repetitionLevel    =    repetitionReader . readLevel (  )  ;", "int   valueCount    =     0  ;", "for    ( int   i    =     0  ;    i    <    numValues ;    i +  +  )     {", "do    {", "readValue ( blockBuilder ,    type )  ;", "try    {", "valueCount +  +  ;", "repetitionLevel    =    repetitionReader . readLevel (  )  ;", "if    (  ( repetitionLevel )     =  =     0  )     {", "positions . add ( valueCount )  ;", "valueCount    =     0  ;", "if    ( i    =  =     ( numValues    -     1  )  )     {", "return ;", "}", "}", "definitionLevel    =    definitionReader . readLevel (  )  ;", "}    catch    ( IllegalArgumentException   expected )     {", "positions . add ( valueCount )  ;", "return ;", "}", "}    while    (  ( repetitionLevel )     !  =     0     )  ;", "}", "}", "METHOD_END"], "methodName": ["readValues"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  (  ( currentValueCount )     <  =     ( totalValueCount )  )  ,     \" Already   read   all   values   in   column   chunk \"  )  ;", "if    (  ( readOffset )     =  =     0  )     {", "return ;", "}", "int   valuePosition    =     0  ;", "while    ( valuePosition    <     ( readOffset )  )     {", "if    (  ( page )     =  =    null )     {", "readNextPage (  )  ;", "}", "int   offset    =    Math . min ( remainingValueCountInPage ,     (  ( readOffset )     -    valuePosition )  )  ;", "skipValues ( offset )  ;", "valuePosition    =    valuePosition    +    offset ;", "updatePosition ( offset )  ;", "}", "checkArgument (  ( valuePosition    =  =     ( readOffset )  )  ,     \" valuePosition    % s   must   be   equal   to   readOffset    % s \"  ,    valuePosition ,    readOffset )  ;", "}", "METHOD_END"], "methodName": ["seek"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "this . pageReader    =    Objects . requireNonNull ( pageReader ,     \" pageReader \"  )  ;", "ParquetDictionaryPage   dictionaryPage    =    pageReader . readDictionaryPage (  )  ;", "if    ( dictionaryPage    !  =    null )     {", "try    {", "dictionary    =    dictionaryPage . getEncoding (  )  . initDictionary ( columnDescriptor ,    dictionaryPage )  ;", "}    catch    ( IOException   e )     {", "throw   new   io . ParquetDecodingException (  (  \" could   not   decode   the   dictionary   for    \"     +     ( columnDescriptor )  )  ,    e )  ;", "}", "} else    {", "dictionary    =    null ;", "}", "checkArgument (  (  ( pageReader . getTotalValueCount (  )  )     >     0  )  ,     \" page   is   empty \"  )  ;", "totalValueCount    =    pageReader . getTotalValueCount (  )  ;", "}", "METHOD_END"], "methodName": ["setPageReader"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "definitionLevel    =    definitionReader . readLevel (  )  ;", "repetitionLevel    =    repetitionReader . readLevel (  )  ;", "for    ( int   i    =     0  ;    i    <    offset ;    i +  +  )     {", "do    {", "skipValue (  )  ;", "try    {", "repetitionLevel    =    repetitionReader . readLevel (  )  ;", "if    (  ( i    =  =     ( offset    -     1  )  )     &  &     (  ( repetitionLevel )     =  =     0  )  )     {", "return ;", "}", "definitionLevel    =    definitionReader . readLevel (  )  ;", "}    catch    ( IllegalArgumentException   expected )     {", "return ;", "}", "}    while    (  ( repetitionLevel )     !  =     0     )  ;", "}", "}", "METHOD_END"], "methodName": ["skipValues"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "if    ( numValues    =  =     ( remainingValueCountInPage )  )     {", "page    =    null ;", "values    =    null ;", "}", "remainingValueCountInPage    =     ( remainingValueCountInPage )     -    numValues ;", "currentValueCount    +  =    numValues ;", "}", "METHOD_END"], "methodName": ["updatePosition"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetColumnReader"}, {"methodBody": ["METHOD_START", "{", "DecimalType   decimalType    =    DecimalType . createDecimalType ( precision ,    scale )  ;", "if    ( decimalType . isShort (  )  )     {", "return   new   ParquetShor ( descriptor )  ;", "} else    {", "return   new   ParquetLongDecimalColumnReader ( descriptor )  ;", "}", "}", "METHOD_END"], "methodName": ["createReader"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetDecimalColumnReaderFactory"}, {"methodBody": ["METHOD_START", "{", "switch    ( type )     {", "case   UTF 8     :", "turn   OriginalType . UTF 8  ;", "case   MAP    :", "turn   OriginalType . MAP ;", "case   MAP _ KEY _ VALUE    :", "turn   OriginalType . MAP _ KEY _ VALUE ;", "case   LIST    :", "turn   OriginalType . LIST ;", "case   ENUM    :", "turn   OriginalType . ENUM ;", "case   DECIMAL    :", "turn   OriginalType . DECIMAL ;", "case   DATE    :", "turn   OriginalType . DATE ;", "case   TIME _ MILLIS    :", "turn   OriginalType . TIME _ MILLIS ;", "case   TIMESTAMP _ MILLIS    :", "turn   OriginalType . TIMESTAMP _ MILLIS ;", "case   INTERVAL    :", "turn   OriginalType . INTERVAL ;", "case   INT _  8     :", "turn   OriginalType . INT _  8  ;", "case   INT _  1  6     :", "turn   OriginalType . INT _  1  6  ;", "case   INT _  3  2     :", "turn   OriginalType . INT _  3  2  ;", "case   INT _  6  4     :", "turn   OriginalType . INT _  6  4  ;", "case   UINT _  8     :", "turn   OriginalType . UINT _  8  ;", "case   UINT _  1  6     :", "turn   OriginalType . UINT _  1  6  ;", "case   UINT _  3  2     :", "turn   OriginalType . UINT _  3  2  ;", "case   UINT _  6  4     :", "turn   OriginalType . UINT _  6  4  ;", "case   JSON    :", "turn   OriginalType . JSON ;", "case   BSON    :", "turn   OriginalType . BSON ;", "default    :", "throw   new   IllegalArgumentException (  (  \" Unknown   converted   type    \"     +    type )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getOriginalType"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetMetadataReader"}, {"methodBody": ["METHOD_START", "{", "switch    ( type )     {", "case   BYTE _ ARRAY    :", "return   PrimitTypeName . BINARY ;", "case   INT 6  4     :", "return   PrimitTypeName . INT 6  4  ;", "case   INT 3  2     :", "return   PrimitTypeName . INT 3  2  ;", "case   BOOLEAN    :", "return   PrimitTypeName . BOOLEAN ;", "case   FLOAT    :", "return   PrimitTypeName . FLOAT ;", "case   DOUBLE    :", "return   PrimitTypeName . DOUBLE ;", "case   INT 9  6     :", "return   PrimitTypeName . INT 9  6  ;", "case   FIXED _ LEN _ BYTE _ ARRAY    :", "return   PrimitTypeName . FIXED _ LEN _ BYTE _ ARRAY ;", "default    :", "throw   new   IllegalArgumentException (  (  \" Unknown   type    \"     +    type )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getTypeName"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetMetadataReader"}, {"methodBody": ["METHOD_START", "{", "Set < Encoding >    columnEncodings    =    new   HashSet <  >  (  )  ;", "for    ( format . Encoding   encoding    :    encodings )     {", "columnEncodings . add ( Encoding . valueOf ( encoding . name (  )  )  )  ;", "}", "return   Collections . unmodifiableSet ( columnEncodings )  ;", "}", "METHOD_END"], "methodName": ["readEncodings"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetMetadataReader"}, {"methodBody": ["METHOD_START", "{", "ParquetValidationUtils . validateParquet (  ( fileSize    >  =     (  (  ( ParquetMetadataReader . MAGIC . length )     +     ( ParquetMetadataReader . PARQUET _ METADATA _ LENGTH )  )     +     ( ParquetMetadataReader . MAGIC . length )  )  )  ,     \"  % s   is   not   a   valid   Parquet   File \"  ,    file )  ;", "long   metadataLengthIndex    =     ( fileSize    -     ( ParquetMetadataReader . PARQUET _ METADATA _ LENGTH )  )     -     ( ParquetMetadataReader . MAGIC . length )  ;", "inputStream . seek ( metadataLengthIndex )  ;", "int   metadataLength    =    ParquetMetadataReader . readIntLittleEndian ( inputStream )  ;", "byte [  ]    magic    =    new   byte [ ParquetMetadataReader . MAGIC . length ]  ;", "inputStream . readFully ( magic )  ;", "ParquetValidationUtils . validateParquet ( Arrays . equals ( ParquetMetadataReader . MAGIC ,    magic )  ,     \" Not   valid   Parquet   file :     % s   expected   magic   number :     % s   got :     % s \"  ,    file ,    Arrays . toString ( ParquetMetadataReader . MAGIC )  ,    Arrays . toString ( magic )  )  ;", "long   metadataIndex    =    metadataLengthIndex    -    metadataLength ;", "ParquetValidationUtils . validateParquet (  (  ( metadataIndex    >  =     ( ParquetMetadataReader . MAGIC . length )  )     &  &     ( metadataIndex    <    metadataLengthIndex )  )  ,     \" Corrupted   Parquet   file :     % s   metadata   index :     % s   out   of   range \"  ,    file ,    metadataIndex )  ;", "inputStream . seek ( metadataIndex )  ;", "FileMetaData   fileMetaData    =    readFileMetaData ( inputStream )  ;", "List < SchemaElement >    schema    =    fileMetaData . getSchema (  )  ;", "ParquetValidationUtils . validateParquet (  (  !  ( schema . isEmpty (  )  )  )  ,     \" Empty   Parquet   schema   in   file :     % s \"  ,    file )  ;", "MessageType   messageType    =    ParquetMetadataReader . readParquetSchema ( schema )  ;", "List < BlockMetaData >    blocks    =    new   ArrayList <  >  (  )  ;", "List < RowGroup >    rowGroups    =    fileMetaData . getRow _ groups (  )  ;", "if    ( rowGroups    !  =    null )     {", "for    ( RowGroup   rowGroup    :    rowGroups )     {", "BlockMetaData   blockMetaData    =    new   BlockMetaData (  )  ;", "blockMetaData . setRowCount ( rowGroup . getNum _ rows (  )  )  ;", "blockMetaData . setTotalByteSize ( rowGroup . getTotal _ byte _ size (  )  )  ;", "List < ColumnChunk >    columns    =    rowGroup . getColumns (  )  ;", "ParquetValidationUtils . validateParquet (  (  !  ( columns . isEmpty (  )  )  )  ,     \" No   columns   in   row   group :     % s \"  ,    rowGroup )  ;", "String   filePath    =    columns . get (  0  )  . getFile _ path (  )  ;", "for    ( ColumnChunk   columnChunk    :    columns )     {", "ParquetValidationUtils . validateParquet (  (  (  ( filePath    =  =    null )     &  &     (  ( columnChunk . getFile _ path (  )  )     =  =    null )  )     |  |     (  ( filePath    !  =    null )     &  &     ( filePath . equals ( columnChunk . getFile _ path (  )  )  )  )  )  ,     \" all   column   chunks   of   the   same   row   group   must   be   in   the   same   file \"  )  ;", "ColumnMetaData   metaData    =    columnChunk . meta _ data ;", "String [  ]    path    =    metaData . path _ in _ schema . toArray ( new   String [ metaData . path _ in _ schema . size (  )  ]  )  ;", "ColumnPath   columnPath    =    ColumnPath . get ( path )  ;", "PrimitiveTypeName   primitiveTypeName    =    messageType . getType ( columnPath . toArray (  )  )  . asPrimitiveType (  )  . getPrimitiveTypeName (  )  ;", "ColumnChunkMetaData   column    =    ColumnChunkMetaData . get ( columnPath ,    primitiveTypeName ,    CompressionCodecName . fromParquet ( metaData . codec )  ,    ParquetMetadataReader . readEncodings ( metaData . encodings )  ,    ParquetMetadataReader . readStats ( metaData . statistics ,    primitiveTypeName )  ,    metaData . data _ page _ offset ,    metaData . dictionary _ page _ offset ,    metaData . num _ values ,    metaData . total _ compressed _ size ,    metaData . total _ uncompressed _ size )  ;", "blockMetaData . addColumn ( column )  ;", "}", "blockMetaData . setPath ( filePath )  ;", "blocks . add ( blockMetaData )  ;", "}", "}", "Map < String ,    String >    keyValueMetaData    =    new   HashMap <  >  (  )  ;", "List < KeyValue >    keyValueList    =    fileMetaData . getKey _ value _ metadata (  )  ;", "if    ( keyValueList    !  =    null )     {", "for    ( KeyValue   keyValue    :    keyValueList )     {", "keyValueMetaData . put ( keyValue . key ,    keyValue . value )  ;", "}", "}", "return   new   parquet . hadoop . metadata . ParquetMetadata ( new   parquet . hadoop . metadata . FileMetaData ( messageType ,    keyValueMetaData ,    fileMetaData . getCreated _ by (  )  )  ,    blocks )  ;", "}", "METHOD_END"], "methodName": ["readFooter"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetMetadataReader"}, {"methodBody": ["METHOD_START", "{", "try    ( FSDataInputStream   inputStream    =    fileSystem . open ( file )  )     {", "return    . readFooter ( inputStream ,    file ,    fileSize )  ;", "}", "}", "METHOD_END"], "methodName": ["readFooter"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetMetadataReader"}, {"methodBody": ["METHOD_START", "{", "int   ch 1     =    in . read (  )  ;", "int   ch 2     =    in . read (  )  ;", "int   ch 3     =    in . read (  )  ;", "int   ch 4     =    in . read (  )  ;", "if    (  (  (  ( ch 1     |    ch 2  )     |    ch 3  )     |    ch 4  )     <     0  )     {", "throw   new   EOFException (  )  ;", "}", "return    (  (  ( ch 4     <  <     2  4  )     +     ( ch 3     <  <     1  6  )  )     +     ( ch 2     <  <     8  )  )     +    ch 1  ;", "}", "METHOD_END"], "methodName": ["readIntLittleEndian"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetMetadataReader"}, {"methodBody": ["METHOD_START", "{", "Iterator < SchemaElement >    schemaIterator    =    schema . iterator (  )  ;", "SchemaElement   rootSchema    =    schemaIterator . next (  )  ;", "Types . MessageTypeBuilder   builder    =    Types . buildMessage (  )  ;", "TypeSchema ( builder ,    schemaIterator ,    rootSchema . getNum _ children (  )  )  ;", "return   builder . named ( rootSchema . name )  ;", "}", "METHOD_END"], "methodName": ["readParquetSchema"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetMetadataReader"}, {"methodBody": ["METHOD_START", "{", "Statistics <  ?  >    stats    =    Statistics . getStatsBasedOnType ( type )  ;", "if    ( statistics    !  =    null )     {", "if    (  ( statistics . isSax (  )  )     &  &     ( statistics . isSin (  )  )  )     {", "stats . sinMaxFromBytes ( statistics . min . array (  )  ,    statistics . max . array (  )  )  ;", "}", "stats . setNumNulls ( statistics . null _ count )  ;", "}", "return   stats ;", "}", "METHOD_END"], "methodName": ["readStats"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetMetadataReader"}, {"methodBody": ["METHOD_START", "{", "for    ( int   i    =     0  ;    i    <    typeCount ;    i +  +  )     {", "SchemaElement   element    =    schemaIterator . next (  )  ;", "Types . Builder <  ?  ,     ?  >    typeBuilder ;", "if    (  ( element . type )     =  =    null )     {", "typeBuilder    =    builder . group ( Repetition . valueOf ( element . repetition _ type . name (  )  )  )  ;", "readTypeSchema (  (  ( Types . GroupBuilder <  ?  >  )     ( typeBuilder )  )  ,    schemaIterator ,    element . num _ children )  ;", "} else    {", "Types . PrimitiveBuilder <  ?  >    primitiveBuilder    =    builder . primitive (  . getTypeName ( element . type )  ,    Repetition . valueOf ( element . repetition _ type . name (  )  )  )  ;", "if    ( element . isSetType _ length (  )  )     {", "primitiveBuilder . length ( element . type _ length )  ;", "}", "if    ( element . isSetPrecision (  )  )     {", "primitiveBuilder . precision ( element . precision )  ;", "}", "if    ( element . isSetScale (  )  )     {", "primitiveBuilder . scale ( element . scale )  ;", "}", "typeBuilder    =    primitiveBuilder ;", "}", "if    ( element . isSetConverted _ type (  )  )     {", "typeBuilder . as (  . getOriginalType ( element . converted _ type )  )  ;", "}", "if    ( element . isSetField _ id (  )  )     {", "typeBuilder . id ( element . field _ id )  ;", "}", "typeBuilder . named ( element . name )  ;", "}", "}", "METHOD_END"], "methodName": ["readTypeSchema"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetMetadataReader"}, {"methodBody": ["METHOD_START", "{", "return   valueCount ;", "}", "METHOD_END"], "methodName": ["getTotalValueCount"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetPageReader"}, {"methodBody": ["METHOD_START", "{", "if    (  ( compressedDictionaryPage )     =  =    null )     {", "return   null ;", "}", "try    {", "return   new   DictionaryPage ( CompressionUtils . decompress ( codec ,    compressedDictionaryPage . getSlice (  )  ,    compressedDictionaryPage . getUncompressedSize (  )  )  ,    compressedDictionaryPage . getDictionarySize (  )  ,    compressedDictionaryPage . getEncoding (  )  )  ;", "}    catch    ( IOException   e )     {", "throw   new   RuntimeException (  \" Error   reading   dictionary   page \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["readDictionaryPage"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetPageReader"}, {"methodBody": ["METHOD_START", "{", "if    ( compressedPages . isEmpty (  )  )     {", "return   null ;", "}", "DataPage   compressedPage    =    compressedPages . remove (  0  )  ;", "try    {", "if    ( compressedPage   instanceof   DataPageV 1  )     {", "DataPageV 1    dataPageV 1     =     (  ( DataPageV 1  )     ( compressedPage )  )  ;", "return   new   DataPageV 1  ( CompressionUtils . decompress ( codec ,    dataPageV 1  . getSlice (  )  ,    dataPageV 1  . getUncompressedSize (  )  )  ,    dataPageV 1  . getValueCount (  )  ,    dataPageV 1  . getUncompressedSize (  )  ,    dataPageV 1  . getStatistics (  )  ,    dataPageV 1  . getRepetitionLevelEncoding (  )  ,    dataPageV 1  . getDefinitionLevelEncoding (  )  ,    dataPageV 1  . getValueEncoding (  )  )  ;", "} else    {", "DataPageV 2    dataPageV 2     =     (  ( DataPageV 2  )     ( compressedPage )  )  ;", "if    (  !  ( dataPageV 2  . isCompressed (  )  )  )     {", "return   dataPageV 2  ;", "}", "int   uncompressedSize    =    Math . toIntExact (  (  (  ( dataPageV 2  . getUncompressedSize (  )  )     -     ( dataPageV 2  . getDefinitionLevels (  )  . length (  )  )  )     -     ( dataPageV 2  . getRepetitionLevels (  )  . length (  )  )  )  )  ;", "return   new   DataPageV 2  ( dataPageV 2  . getRowCount (  )  ,    dataPageV 2  . getNullCount (  )  ,    dataPageV 2  . getValueCount (  )  ,    dataPageV 2  . getRepetitionLevels (  )  ,    dataPageV 2  . getDefinitionLevels (  )  ,    dataPageV 2  . getDataEncoding (  )  ,    CompressionUtils . decompress ( codec ,    dataPageV 2  . getSlice (  )  ,    uncompressedSize )  ,    dataPageV 2  . getUncompressedSize (  )  ,    dataPageV 2  . getStatistics (  )  ,    false )  ;", "}", "}    catch    ( IOException   e )     {", "throw   new   RuntimeException (  \" Could   not   decompress   page \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["readPage"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetPageReader"}, {"methodBody": ["METHOD_START", "{", "currentRowGroupMemoryContext . close (  )  ;", "currentRowGroupMemoryContext    =    systemMemoryContext . newAggregatedMemoryContext (  )  ;", "if    (  ( currentBlock )     =  =     ( blocks . size (  )  )  )     {", "return   false ;", "}", "currentBlockMetadata    =    blocks . get ( currentBlock )  ;", "currentBlock    =     ( currentBlock )     +     1  ;", "nextRowInGroup    =     0 L ;", "currentGroupRowCount    =    currentBlockMetadata . getRowCount (  )  ;", "columnsMap . clear (  )  ;", "initializeColumns (  )  ;", "return   true ;", "}", "METHOD_END"], "methodName": ["advanceToNextRowGroup"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "byte [  ]    buff =    new   byte [ length ]  ;", "LocalMemoryContext   blockMemoryContext    =    currentRowGroupMemoryContext . newLocalMemoryContext (  )  ;", "blockMemoryContext . setBytes ( bufflength )  ;", "return   buff", "}", "METHOD_END"], "methodName": ["allocateBlock"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "for    ( ColumnChunkMetaData   metadata    :    currentBlockMetadata . getColumns (  )  )     {", "if    ( metadata . getPath (  )  . equals ( ColumnPath . get ( columnDescriptor . getPath (  )  )  )  )     {", "return   metadata ;", "}", "}", "throw   new   CorruptionException (  \" Metadata   is   missing   for   column :     % s \"  ,    columnDescriptor )  ;", "}", "METHOD_END"], "methodName": ["getColumnChunkMetaData"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   currentPosition ;", "}", "METHOD_END"], "methodName": ["getPosition"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "for    ( PrimitiveColumnIO   columnIO    :    ParquetTypeUtils . getColumns ( fileSchema ,    requestedSchema )  )     {", "ColumnDescriptor   descriptor    =    columnIO . getColumnDescriptor (  )  ;", "RichColumnDescriptor   column    =    new   RichColumnDescriptor ( descriptor . getPath (  )  ,    columnIO . getType (  )  . asPrimitiveType (  )  ,    descriptor . getMaxRepetitionLevel (  )  ,    descriptor . getMaxDefinitionLevel (  )  )  ;", "columnReadersMap . put ( column ,    ParquetColumnReader . createReader ( column )  )  ;", "}", "}", "METHOD_END"], "methodName": ["initializeColumnReaders"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( nextRowInGroup )     >  =     ( currentGroupRowCount )  )     &  &     (  !  ( advanceToNextRowGroup (  )  )  )  )     {", "return    -  1  ;", "}", "batchSize    =    Math . toIntExact ( Math . min (  . MAX _ VECTOR _ LENGTH ,     (  ( currentGroupRowCount )     -     ( nextRowInGroup )  )  )  )  ;", "nextRowInGroup    +  =    batchSize ;", "currentPosition    +  =    batchSize ;", "for    ( PrimitiveColumnIO   columnIO    :    ParquetTypeUtils . getColumns ( fileSchema ,    requestedSchema )  )     {", "ColumnDescriptor   descriptor    =    columnIO . getColumnDescriptor (  )  ;", "RichColumnDescriptor   column    =    new   RichColumnDescriptor ( descriptor . getPath (  )  ,    columnIO . getType (  )  . asPrimitiveType (  )  ,    descriptor . getMaxRepetitionLevel (  )  ,    descriptor . getMaxDefinitionLevel (  )  )  ;", "ParquetColumnReader   columnReader    =    columnReadersMap . get ( column )  ;", "columnReader . prepareNextRead ( batchSize )  ;", "}", "return   batchSize ;", "}", "METHOD_END"], "methodName": ["nextBatch"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   readArray ( type ,    path ,    new   IntArrayList (  )  )  ;", "}", "METHOD_END"], "methodName": ["readArray"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "List < Type >    parameters    =    type . getTypeParameters (  )  ;", "checkArgument (  (  ( parameters . size (  )  )     =  =     1  )  ,     \" Arrays   must   have   a   single   type   parameter ,    found    % d \"  ,    parameters . size (  )  )  ;", "path . add (  . ARRAY _ TYPE _ NAME )  ;", "Type   elementType    =    parameters . get (  0  )  ;", "Block   block    =    readBlock (  . ARRAY _ ELEMENT _ NAME ,    elementType ,    path ,    elementOffsets )  ;", "path . remove (  . ARRAY _ TYPE _ NAME )  ;", "if    ( elementOffsets . isEmpty (  )  )     {", "for    ( int   i    =     0  ;    i    <     ( batchSize )  ;    i +  +  )     {", "elementOffsets . add (  0  )  ;", "}", "return   RunLengthEncodedBlock . create ( elementType ,    null ,    batchSize )  ;", "}", "int [  ]    offsets    =    new   int [  ( batchSize )     +     1  ]  ;", "for    ( int   i    =     1  ;    i    <     ( offsets . length )  ;    i +  +  )     {", "offsets [ i ]     =     ( offsets [  ( i    -     1  )  ]  )     +     ( elementOffsets . getInt (  ( i    -     1  )  )  )  ;", "}", "return   ArrayBlock . fromElementBlock ( batchSize ,    new   boolean [ batchSize ]  ,    offsets ,    block )  ;", "}", "METHOD_END"], "methodName": ["readArray"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "path . add ( name )  ;", "Optional < RichColumnDescriptor >    descriptor    =    TypeUtils . getDescriptor ( fileSchema ,    requestedSchema ,    path )  ;", "if    (  !  ( descriptor . isPresent (  )  )  )     {", "path . remove ( name )  ;", "return   RunLengthEncodedBlock . create ( type ,    null ,    batchSize )  ;", "}", "Block   block ;", "if    ( StandardTypes . ROW . equals ( type . getTypeSignature (  )  . getBase (  )  )  )     {", "block    =    readStruct ( type ,    path ,    offsets )  ;", "} else", "if    ( StandardTypes . MAP . equals ( type . getTypeSignature (  )  . getBase (  )  )  )     {", "block    =    readMap ( type ,    path ,    offsets )  ;", "} else", "if    ( StandardTypes . ARRAY . equals ( type . getTypeSignature (  )  . getBase (  )  )  )     {", "block    =    readArray ( type ,    path ,    offsets )  ;", "} else    {", "block    =    readPrimitive ( descriptor . get (  )  ,    type ,    offsets )  ;", "}", "path . remove ( name )  ;", "return   block ;", "}", "METHOD_END"], "methodName": ["readBlock"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   readMap ( type ,    path ,    new   IntArrayList (  )  )  ;", "}", "METHOD_END"], "methodName": ["readMap"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "List < Type >    parameters    =    type . getTypeParameters (  )  ;", "checkArgument (  (  ( parameters . size (  )  )     =  =     2  )  ,     \" Maps   must   have   two   type   parameters ,    found    % d \"  ,    parameters . size (  )  )  ;", "Block [  ]    blocks    =    new   Block [ parameters . size (  )  ]  ;", "IntList   keyOffsets    =    new   IntArrayList (  )  ;", "IntList   valueOffsets    =    new   IntArrayList (  )  ;", "path . add (  . MAP _ TYPE _ NAME )  ;", "blocks [  0  ]     =    readBlock (  . MAP _ KEY _ NAME ,    parameters . get (  0  )  ,    path ,    keyOffsets )  ;", "blocks [  1  ]     =    readBlock (  . MAP _ VALUE _ NAME ,    parameters . get (  1  )  ,    path ,    valueOffsets )  ;", "path . remove (  . MAP _ TYPE _ NAME )  ;", "if    (  ( blocks [  0  ]  . getPositionCount (  )  )     =  =     0  )     {", "for    ( int   i    =     0  ;    i    <     ( batchSize )  ;    i +  +  )     {", "elementOffsets . add (  0  )  ;", "}", "return   RunLengthEncodedBlock . create ( parameters . get (  0  )  ,    null ,    batchSize )  ;", "}", "int [  ]    offsets    =    new   int [  ( batchSize )     +     1  ]  ;", "for    ( int   i    =     1  ;    i    <     ( offsets . length )  ;    i +  +  )     {", "int   elementPositionCount    =    keyOffsets . getInt (  ( i    -     1  )  )  ;", "elementOffsets . add (  ( elementPositionCount    *     2  )  )  ;", "offsets [ i ]     =     ( offsets [  ( i    -     1  )  ]  )     +    elementPositionCount ;", "}", "return    (  ( MapType )     ( type )  )  . createBlockFromKeyValue ( new   boolean [ batchSize ]  ,    offsets ,    blocks [  0  ]  ,    blocks [  1  ]  )  ;", "}", "METHOD_END"], "methodName": ["readMap"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   readPrimitive ( columnDescriptor ,    type ,    new   IntArrayList (  )  )  ;", "}", "METHOD_END"], "methodName": ["readPrimitive"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "ParquetColumnReader   columnReader    =    columnReadersMap . get ( columnDescriptor )  ;", "if    (  ( columnReader . getPageReader (  )  )     =  =    null )     {", "ParquetValidationUtils . validateParquet (  (  ( currentBlockMetadata . getRowCount (  )  )     >     0  )  ,     \" Row   group   has    0    rows \"  )  ;", "ColumnChunkMetaData   metadata    =    getColumnChunkMetaData ( columnDescriptor )  ;", "long   startingPosition    =    metadata . getStartingPos (  )  ;", "int   totalSize    =    Math . toIntExact ( metadata . getTotalSize (  )  )  ;", "byte [  ]    buffer    =    allocateBlock ( totalSize )  ;", "dataSource . readFully ( startingPosition ,    buffer )  ;", "ParquetColumnChunkDescriptor   descriptor    =    new   ParquetColumnChunkDescriptor ( columnDescriptor ,    metadata ,    totalSize )  ;", "ParquetColumnChunk   columnChunk    =    new   ParquetColumnChunk ( descriptor ,    buffer ,     0  )  ;", "columnReader . setPageReader ( columnChunk . readAllPages (  )  )  ;", "}", "return   columnReader . readPrimitive ( type ,    offsets )  ;", "}", "METHOD_END"], "methodName": ["readPrimitive"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "return   readStruct ( type ,    path ,    new   IntArrayList (  )  )  ;", "}", "METHOD_END"], "methodName": ["readStruct"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "List < TypeSignatureParameter >    parameters    =    type . getTypeSignature (  )  . getParameters (  )  ;", "Block [  ]    blocks    =    new   Block [ parameters . size (  )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( parameters . size (  )  )  ;    i +  +  )     {", "NamedTypeSignature   namedTypeSignature    =    parameters . get ( i )  . getNamedTypeSignature (  )  ;", "Type   fieldType    =    typeManager . getType ( namedTypeSignature . getTypeSignature (  )  )  ;", "String   name    =    namedTypeSignature . getName (  )  . get (  )  ;", "blocks [ i ]     =    Block ( name ,    fieldType ,    path ,    new   IntArrayList (  )  )  ;", "}", "int   positionCount    =    blocks [  0  ]  . getPositionCount (  )  ;", "for    ( int   i    =     0  ;    i    <    positionCount ;    i +  +  )     {", "elementOffsets . add ( parameters . size (  )  )  ;", "}", "return   RowBlock . fromFieldBlocks ( new   boolean [ positionCount ]  ,    blocks )  ;", "}", "METHOD_END"], "methodName": ["readStruct"], "fileName": "com.facebook.presto.hive.parquet.reader.ParquetReader"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( throwable ,     \" throwable   is   null \"  )  ;", "try    {", "close (  )  ;", "}    catch    ( Exception   e )     {", "if    ( e    !  =    throwable )     {", "throwable . addSupsed ( e )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["closeWithSuppression"], "fileName": "com.facebook.presto.hive.rcfile.RcFilePageSource"}, {"methodBody": ["METHOD_START", "{", "int   hiveColumnIndex    =    hiveColumnIndexes [ fieldId ]  ;", "return   new   LazyBlock ( currentPageSize ,    new    . RcFileBlockLoader ( hiveColumnIndex )  )  ;", "}", "METHOD_END"], "methodName": ["createBlock"], "fileName": "com.facebook.presto.hive.rcfile.RcFilePageSource"}, {"methodBody": ["METHOD_START", "{", "int   nestingLevels ;", "if    (  !  (  \" true \"  . equalsIgnoreCase ( schema . getProperty ( SERIALIZATION _ EXTEND _ NESTING _ LEVELS )  )  )  )     {", "nestingLevels    =     . TEXT _ LEGACY _ NESTING _ LEVELS ;", "} else    {", "nestingLevels    =     . TEXT _ EXTENDED _ NESTING _ LEVELS ;", "}", "byte [  ]    separators    =    Arrays . copyOf ( DEFAULT _ SEPARATORS ,    nestingLevels )  ;", "separators [  0  ]     =    getByte ( schema . getProperty ( serdeConstants . FIELD _ DELIM ,    schema . getProperty ( serdeConstants . SERIALIZATION _ FORMAT )  )  ,    DEFAULT _ SEPARATORS [  0  ]  )  ;", "separators [  1  ]     =    getByte ( schema . getProperty ( serdeConstants . COLLECTION _ DELIM )  ,    DEFAULT _ SEPARATORS [  1  ]  )  ;", "separators [  2  ]     =    getByte ( schema . getProperty ( serdeConstants . MAPKEY _ DELIM )  ,    DEFAULT _ SEPARATORS [  2  ]  )  ;", "Slice   nullSequence ;", "String   nullSequenceString    =    schema . getProperty ( serdeConstants . SERIALIZATION _ NULL _ FORMAT )  ;", "if    ( nullSequenceString    =  =    null )     {", "nullSequence    =    DEFAULT _ NULL _ SEQUENCE ;", "} else    {", "nullSequence    =    Slices . utf 8 Slice ( nullSequenceString )  ;", "}", "String   lastColumnTakesRestString    =    schema . getProperty ( serdeConstants . SERIALIZATION _ LAST _ COLUMN _ TAKES _ REST )  ;", "boolean   lastColumnTakesRest    =     \" true \"  . equalsIgnoreCase ( lastColumnTakesRestString )  ;", "String   escapeProperty    =    schema . getProperty ( serdeConstants . ESCAPE _ CHAR )  ;", "Byte   escapeByte    =    null ;", "if    ( escapeProperty    !  =    null )     {", "escapeByte    =    getByte ( escapeProperty ,     (  ( byte )     (  '  \\  \\  '  )  )  )  ;", "}", "return   new   com . facebook . presto . rcfile . text . TextRcFileEncoding ( hiveStorageTimeZone ,    nullSequence ,    separators ,    escapeByte ,    lastColumnTakesRest )  ;", "}", "METHOD_END"], "methodName": ["createTextVectorEncoding"], "fileName": "com.facebook.presto.hive.rcfile.RcFilePageSourceFactory"}, {"methodBody": ["METHOD_START", "{", "return   String . format (  \" Error   opening   Hive   split    % s    ( offset =  % s ,    length =  % s )  :     % s \"  ,    path ,    start ,    length ,    t . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["splitError"], "fileName": "com.facebook.presto.hive.rcfile.RcFilePageSourceFactory"}, {"methodBody": ["METHOD_START", "{", "return   s 3 AwsAccessKey ;", "}", "METHOD_END"], "methodName": ["getS3AwsAccessKey"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 AwsSecretKey ;", "}", "METHOD_END"], "methodName": ["getS3AwsSecretKey"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 ConnectTimeout ;", "}", "METHOD_END"], "methodName": ["getS3ConnectTimeout"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 EncryptionMaterialsProvider ;", "}", "METHOD_END"], "methodName": ["getS3EncryptionMaterialsProvider"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 Endpoint ;", "}", "METHOD_END"], "methodName": ["getS3Endpoint"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 KmsKeyId ;", "}", "METHOD_END"], "methodName": ["getS3KmsKeyId"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 MaxBackoffTime ;", "}", "METHOD_END"], "methodName": ["getS3MaxBackoffTime"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 MaxClientRetries ;", "}", "METHOD_END"], "methodName": ["getS3MaxClientRetries"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 MaxConnections ;", "}", "METHOD_END"], "methodName": ["getS3MaxConnections"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 MaxErrorRetries ;", "}", "METHOD_END"], "methodName": ["getS3MaxErrorRetries"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 MaxRetryTime ;", "}", "METHOD_END"], "methodName": ["getS3MaxRetryTime"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 MultipartMinFileSize ;", "}", "METHOD_END"], "methodName": ["getS3MultipartMinFileSize"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 MultipartMinPartSize ;", "}", "METHOD_END"], "methodName": ["getS3MultipartMinPartSize"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 SignerType ;", "}", "METHOD_END"], "methodName": ["getS3SignerType"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 SocketTimeout ;", "}", "METHOD_END"], "methodName": ["getS3SocketTimeout"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 SseKmsKeyId ;", "}", "METHOD_END"], "methodName": ["getS3SseKmsKeyId"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 SseType ;", "}", "METHOD_END"], "methodName": ["getS3SseType"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 StagingDirectory ;", "}", "METHOD_END"], "methodName": ["getS3StagingDirectory"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 UserAgentPrefix ;", "}", "METHOD_END"], "methodName": ["getS3UserAgentPrefix"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   pinS 3 ClientToCurrentRegion ;", "}", "METHOD_END"], "methodName": ["isPinS3ClientToCurrentRegion"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 PathStyleAccess ;", "}", "METHOD_END"], "methodName": ["isS3PathStyleAccess"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 SseEnabled ;", "}", "METHOD_END"], "methodName": ["isS3SseEnabled"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 SslEnabled ;", "}", "METHOD_END"], "methodName": ["isS3SslEnabled"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   s 3 UseInstanceCredentials ;", "}", "METHOD_END"], "methodName": ["isS3UseInstanceCredentials"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . pinS 3 ClientToCurrentRegion    =    pinS 3 ClientToCurrentRegion ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setPinS3ClientToCurrentRegion"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 AwsAccessKey    =    s 3 AwsAccessKey ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3AwsAccessKey"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 AwsSecretKey    =    s 3 AwsSecretKey ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3AwsSecretKey"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 ConnectTimeout    =    s 3 ConnectTimeout ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3ConnectTimeout"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 EncryptionMaterialsProvider    =    s 3 EncryptionMaterialsProvider ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3EncryptionMaterialsProvider"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 Endpoint    =    s 3 Endpoint ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3Endpoint"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 KmsKeyId    =    s 3 KmsKeyId ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3KmsKeyId"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 MaxBackoffTime    =    s 3 MaxBackoffTime ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3MaxBackoffTime"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 MaxClientRetries    =    s 3 MaxClientRetries ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3MaxClientRetries"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 MaxConnections    =    s 3 MaxConnections ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3MaxConnections"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 MaxErrorRetries    =    s 3 MaxErrorRetries ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3MaxErrorRetries"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 MaxRetryTime    =    s 3 MaxRetryTime ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3MaxRetryTime"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 MultipartMinFileSize    =    size ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3MultipartMinFileSize"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 MultipartMinPartSize    =    size ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3MultipartMinPartSize"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 PathStyleAccess    =    s 3 PathStyleAccess ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3PathStyleAccess"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 SignerType    =    s 3 SignerType ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3SignerType"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 SocketTimeout    =    s 3 SocketTimeout ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3SocketTimeout"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 SseEnabled    =    s 3 SseEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3SseEnabled"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 SseKmsKeyId    =    s 3 SseKmsKeyId ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3SseKmsKeyId"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 SseType    =    s 3 SseType ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3SseType"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 SslEnabled    =    s 3 SslEnabled ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3SslEnabled"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 StagingDirectory    =    s 3 StagingDirectory ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3StagingDirectory"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 UseInstanceCredentials    =    s 3 UseInstanceCredentials ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3UseInstanceCredentials"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "this . s 3 UserAgentPrefix    =    s 3 UserAgentPrefix ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setS3UserAgentPrefix"], "fileName": "com.facebook.presto.hive.s3.HiveS3Config"}, {"methodBody": ["METHOD_START", "{", "try    {", "Class . forName (  . EMR _ FS _ CLASS _ NAME ,    true ,    JavaUtils . getClassLoader (  )  )  ;", "}    catch    ( ClassNotFoundException   e )     {", "throw   new   RuntimeException (  (  \" EMR   File   System   class   not   found :     \"     +     (  . EMR _ FS _ CLASS _ NAME )  )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["validateEmrFsClass"], "fileName": "com.facebook.presto.hive.s3.HiveS3Module"}, {"methodBody": ["METHOD_START", "{", "return   getObjectMetadataRequest ;", "}", "METHOD_END"], "methodName": ["getGetObjectMetadataRequest"], "fileName": "com.facebook.presto.hive.s3.MockAmazonS3"}, {"methodBody": ["METHOD_START", "{", "this . getObjectHttpCode    =    getObjectHttpErrorCode ;", "}", "METHOD_END"], "methodName": ["setGetObjectHttpErrorCode"], "fileName": "com.facebook.presto.hive.s3.MockAmazonS3"}, {"methodBody": ["METHOD_START", "{", "this . getObjectMetadataHttpCode    =    getObjectMetadataHttpCode ;", "}", "METHOD_END"], "methodName": ["setGetObjectMetadataHttpCode"], "fileName": "com.facebook.presto.hive.s3.MockAmazonS3"}, {"methodBody": ["METHOD_START", "{", "AWSCredentialsProvider   credentials    =    getAwsCredentialsProvider ( uri ,    hadoopConfig )  ;", "Optional < EncryptionMaterialsProvider >    encryptionMaterialsProvider    =     . createEncryptionMaterialsProvider ( hadoopConfig )  ;", "AmazonS 3 Builder <  ?    extends   AmazonS 3 Builder ,     ?    extends   AmazonS 3  >    clientBuilder ;", "String   signerType    =    hadoopConfig . get ( S 3 ConfigurationUpdater . S 3  _ SIGNER _ TYPE )  ;", "if    ( signerType    !  =    null )     {", "clientConfig . withSignerOverride ( signerType )  ;", "}", "if    ( encryptionMaterialsProvider . isPresent (  )  )     {", "clientBuilder    =    AmazonS 3 EncryptionClient . encryptionBuilder (  )  . withCredentials ( credentials )  . withEncryptionMaterials ( encryptionMaterialsProvider . get (  )  )  . withClientConfiguration ( clientConfig )  . withMetricsCollector (  . METRIC _ COLLECTOR )  ;", "} else    {", "clientBuilder    =    AmazonS 3 Client . builder (  )  . withCredentials ( credentials )  . withClientConfiguration ( clientConfig )  . withMetricsCollector (  . METRIC _ COLLECTOR )  ;", "}", "boolean   regionOrEndpointSet    =    false ;", "if    ( pinS 3 ClientToCurrentRegion )     {", "Region   region    =    Regions . getCurrentRegion (  )  ;", "if    ( region    !  =    null )     {", "clientBuilder    =    clientBuilder . withRegion ( region . getName (  )  )  ;", "regionOrEndpointSet    =    true ;", "}", "}", "String   endpoint    =    hadoopConfig . get ( S 3 ConfigurationUpdater . S 3  _ ENDPOINT )  ;", "if    ( endpoint    !  =    null )     {", "clientBuilder    =    clientBuilder . withEndpointConfiguration ( new   EndpointConfiguration ( endpoint ,    null )  )  ;", "regionOrEndpointSet    =    true ;", "}", "if    ( isPathStyleAccess )     {", "clientBuilder    =    clientBuilder . enablePathStyleAccess (  )  ;", "}", "if    (  ! regionOrEndpointSet )     {", "clientBuilder    =    clientBuilder . withRegion ( US _ EAST _  1  )  ;", "clientBuilder . setForceGlobalBucketAccessEnabled ( true )  ;", "}", "return   clientBuilder . build (  )  ;", "}", "METHOD_END"], "methodName": ["createAmazonS3Client"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "String   kmsKeyId    =    hadoopConfig . get ( S 3 ConfigurationUpdater . S 3  _ KMS _ KEY _ ID )  ;", "if    ( kmsKeyId    !  =    null )     {", "return   Optional . of ( new   KMSEncryptionMaterialsProvider ( kmsKeyId )  )  ;", "}", "String   empClassName    =    hadoopConfig . get ( S 3 ConfigurationUpdater . S 3  _ ENCRYPTION _ MATERIALS _ PROVIDER )  ;", "if    ( empClassName    =  =    null )     {", "return   Optional . empty (  )  ;", "}", "try    {", "Object   instance    =    Class . forName ( empClassName )  . getConstructor (  )  . newInstance (  )  ;", "if    (  !  ( instance   instanceof   EncryptionMaterialsProvider )  )     {", "throw   new   RuntimeException (  (  \" Invalid   encryption   materials   provider   class :     \"     +     ( instance . getClass (  )  . getName (  )  )  )  )  ;", "}", "EncryptionMaterialsProvider   emp    =     (  ( EncryptionMaterialsProvider )     ( instance )  )  ;", "if    ( emp   instanceof   Configurable )     {", "(  ( Configurable )     ( emp )  )  . setConf ( hadoopConfig )  ;", "}", "return   Optional . of ( emp )  ;", "}    catch    ( ReflectOperationException   e )     {", "throw   new   RuntimeException (  (  \" Unable   to   load   or   create   S 3    encryption   materials   provider :     \"     +    empClassName )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["createEncryptionMaterialsProvider"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    {", "BlockLocation [  ]    fakeLocation    =    getFileBlockLocations ( status ,     0  ,    status . getLen (  )  )  ;", "return   new   Locatedtatus ( status ,    fakeLocation )  ;", "}    catch    ( IOException   e )     {", "throw   new   UncheckedIOException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["createLocatedFileStatus"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    {", "s 3  . deleteObject (  . getBucketName ( uri )  ,    key )  ;", "return   true ;", "}    catch    ( AmazonClientException   e )     {", "return   false ;", "}", "}", "METHOD_END"], "methodName": ["deleteObject"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "return   HadoopFileStatus . isDirectory ( getFileStatus ( path )  )  ;", "}", "METHOD_END"], "methodName": ["directory"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "String   accessKey    =    conf . get ( S 3 ConfigurationUpdater . S 3  _ ACCESS _ KEY )  ;", "String   secretKey    =    conf . get ( S 3 ConfigurationUpdater . S 3  _ SECRET _ KEY )  ;", "String   userInfo    =    uri . getUserInfo (  )  ;", "if    ( userInfo    !  =    null )     {", "int   index    =    userInfo . indexOf (  '  :  '  )  ;", "if    ( index    <     0  )     {", "accessKey    =    userInfo ;", "} else    {", "accessKey    =    userInfo . substring (  0  ,    index )  ;", "secretKey    =    userInfo . substring (  ( index    +     1  )  )  ;", "}", "}", "if    (  ( isNullOrEmpty ( accessKey )  )     |  |     ( isNullOrEmpty ( secretKey )  )  )     {", "return   Optional . empty (  )  ;", "}", "return   Optional . of ( new   BasicAWSCredentials ( accessKey ,    secretKey )  )  ;", "}", "METHOD_END"], "methodName": ["getAwsCredentials"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Optional < AWSCredentials >    credentials    =    PrestoS 3 FileSystem . getAwsCredentials ( uri ,    conf )  ;", "if    ( credentials . isPresent (  )  )     {", "return   new   com . amazonaws . auth . AWSStaticCredentialsProvider ( credentials . get (  )  )  ;", "}", "if    ( useInstanceCredentials )     {", "return   InstanceProfileCredentialsProvider . getInstance (  )  ;", "}", "String   providerClass    =    conf . get ( S 3 ConfigurationUpdater . S 3  _ CREDENTIALS _ PROVIDER )  ;", "if    (  !  ( isNullOrEmpty ( providerClass )  )  )     {", "return   PrestoS 3 FileSystem . getCustomAWSCredentialsProvider ( uri ,    conf ,    providerClass )  ;", "}", "throw   new   RuntimeException (  \" S 3    credentials   not   configured \"  )  ;", "}", "METHOD_END"], "methodName": ["getAwsCredentialsProvider"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "if    (  ( uri . getHost (  )  )     !  =    null )     {", "return   uri . getHost (  )  ;", "}", "if    (  ( uri . getUserInfo (  )  )     =  =    null )     {", "return   uri . getAuthority (  )  ;", "}", "throw   new   IllegalArgumentException (  \" Unable   to   determine   S 3    bucket   from   URI .  \"  )  ;", "}", "METHOD_END"], "methodName": ["getBucketName"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    {", ". log . debug (  \" Using   AWS   credential   provider    % s   for   URI    % s \"  ,    providerClass ,    uri )  ;", "return   conf . getClassByName ( providerClass )  . asSubclass ( AWSCredentialsProvider . class )  . getConstructor ( URI . class ,    Configuration . class )  . newInstance ( uri ,    conf )  ;", "}    catch    ( ReflectiveOperationException   e )     {", "throw   new   RuntimeException ( String . format (  \" Error   creating   an   instance   of    % s   for   URI    % s \"  ,    providerClass ,    uri )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["getCustomAWSCredentialsProvider"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "return   PrestoS 3 FileSystem . STATS ;", "}", "METHOD_END"], "methodName": ["getFileSystemStats"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    userMetadata    =    metadata . getUserMetadata (  )  ;", "String   ngth    =    userMetadata . get ( Headers . UNENCRYPTED _ CONTENT _ LENGTH )  ;", "if    (  ( userMetadata . containsKey ( Headers . SERVER _ SIDE _ ENCRYPTION )  )     &  &     ( ngth    =  =    null )  )     {", "throw   new   IOException ( String . format (  \"  % s   header   is   not   set   on   an   encrypted   object :     % s \"  ,    Headers . UNENCRYPTED _ CONTENT _ LENGTH ,    path )  )  ;", "}", "return   ngth    !  =    null    ?    Long . parseLong ( ngth )     :    metadata . getContentLength (  )  ;", "}", "METHOD_END"], "methodName": ["getObjectSize"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "return   s 3  ;", "}", "METHOD_END"], "methodName": ["getS3Client"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   RetryDriver . retry (  )  . maxAttempts ( maxAttempts )  . exponentialBackoff (  . BACKOFF _ MIN _ SLEEP ,    maxBackoffTime ,    maxRetryTime ,     2  .  0  )  . stopOn ( InterruptedException . class ,     . UnrecoverableS 3 OperationException . class )  . onRetry (  . STATS :  : newGetMetadataRetry )  . run (  \" getS 3 ObjectMetadata \"  ,     (  )     -  >     {", "try    {", ". STATS . newMetadataCall (  )  ;", "return   s 3  . getObjectMetadata ( getBucketName ( uri )  ,    keyFromPath ( path )  )  ;", "}    catch    (    e )     {", ". STATS . newGetMetadataError (  )  ;", "if    ( e   instanceof   AmazonS 3 Exception )     {", "switch    (  (  ( AmazonS 3 Exception )     ( e )  )  . getStatusCode (  )  )     {", "case   SC _ NOT _ FOUND    :", "return   null ;", "case   SC _ FORBIDDEN    :", "case   SC _ BAD _ REQUEST    :", "throw   new    < e > UnrecoverableS 3 OperationException ( path )  ;", "}", "}", "throw   e ;", "}", "}  )  ;", "}    catch    ( InterruptedException   e )     {", "Thread . currentThread (  )  . interrupt (  )  ;", "throw   new   RuntimeException ( e )  ;", "}    catch    ( Exception   e )     {", "throwIfInstanceOf ( e ,    IOException . class )  ;", "throwIfUnchecked ( e )  ;", "throw   new   RuntimeException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["getS3ObjectMetadata"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "checkArgument ( path . isAbsolute (  )  ,     \" Path   is   not   absolute :     % s \"  ,    path )  ;", "String   key    =    nullToEmpty ( path . toUri (  )  . getPath (  )  )  ;", "if    ( key . startsWith (  . PATH _ SEPARATOR )  )     {", "key    =    key . substring (  . PATH _ SEPARATOR . length (  )  )  ;", "}", "if    ( key . endsWith (  . PATH _ SEPARATOR )  )     {", "key    =    key . substring (  0  ,     (  ( key . length (  )  )     -     (  . PATH _ SEPARATOR . length (  )  )  )  )  ;", "}", "return   key ;", "}", "METHOD_END"], "methodName": ["keyFromPath"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "return   PrestoS 3 FileSystem . keyFromPath ( p 1  )  . equals ( PrestoS 3 FileSystem . keyFromPath ( p 2  )  )  ;", "}", "METHOD_END"], "methodName": ["keysEqual"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Date   date    =    metadata . getLastModified (  )  ;", "return   date    !  =    null    ?    date . getTime (  )     :     0  ;", "}", "METHOD_END"], "methodName": ["lastModifiedTime"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "String   key    =    PrestoS 3 FileSystem . keyFromPath ( path )  ;", "if    (  !  ( key . isEmpty (  )  )  )     {", "key    +  =    PrestoS 3 FileSystem . PATH _ SEPARATOR ;", "}", "ListObjectsRequest   request    =    new   ListObjectsRequest (  )  . withBucketName ( PrestoS 3 FileSystem . getBucketName ( uri )  )  . withPrefix ( key )  . withDelimiter ( PrestoS 3 FileSystem . PATH _ SEPARATOR )  ;", "PrestoS 3 FileSystem . STATS . newListObjectsCall (  )  ;", "Iterator < ObjectListing >    listings    =    new   com . google . common . collect . AbstractSequentialIterator < ObjectListing >  ( s 3  . listObjects ( request )  )     {", "@ Override", "protected   ObjectListing   computeNext ( ObjectListing   previous )     {", "if    (  !  ( previous . isTruncated (  )  )  )     {", "return   null ;", "}", "return   s 3  . listNextBatchOfObjects ( previous )  ;", "}", "}  ;", "return   Iterators . concat ( Iterators . transform ( listings ,    this :  : statusFromListing )  )  ;", "}", "METHOD_END"], "methodName": ["listPrefix"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "return   path . makeQualified ( this . uri ,    getWorkingDirectory (  )  )  ;", "}", "METHOD_END"], "methodName": ["qualifiedPath"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "s 3     =    client ;", "}", "METHOD_END"], "methodName": ["setS3Client"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "return   Iterators . concat ( statusFromPrefixes ( listing . getCommonPrefixes (  )  )  ,    statusFromObjects ( listing . getObjectSummaries (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["statusFromListing"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "return   objects . stream (  )  . filter (  (    object )     -  >     !  ( object . getKey (  )  . endsWith ( PrestoS 3 FileSystem . PATH _ SEPARATOR )  )  )  . map (  (    object )     -  >    new   FileStatus ( object . getSize (  )  ,    false ,     1  ,    PrestoS 3 FileSystem . BLOCK _ SIZE . toBytes (  )  ,    object . getLastModified (  )  . getTime (  )  ,    qualifiedPath ( new   Path (  (  ( PrestoS 3 FileSystem . PATH _ SEPARATOR )     +     ( object . getKey (  )  )  )  )  )  )  )  . map ( this :  : createLocatedFileStatus )  . iterator (  )  ;", "}", "METHOD_END"], "methodName": ["statusFromObjects"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "List < LocatedFileStatus >    list    =    new   ArrayList <  >  (  )  ;", "for    ( String   prefix    :    prefixes )     {", "Path   path    =    qualifiedPath ( new   Path (  (  (  . PATH _ SEPARATOR )     +    prefix )  )  )  ;", "FileStatus   status    =    new   FileStatus (  0  ,    true ,     1  ,     0  ,     0  ,    path )  ;", "list . add ( createLocatedFileStatus ( status )  )  ;", "}", "return   list . iterator (  )  ;", "}", "METHOD_END"], "methodName": ["statusFromPrefixes"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "awsClientExecuteTime . add ( duration )  ;", "}", "METHOD_END"], "methodName": ["addAwsClientExecuteTime"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "awsRequestTime . add ( duration )  ;", "}", "METHOD_END"], "methodName": ["addAwsRequestTime"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "activeConnections . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["connectionOpened"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "activeConnections . update (  (  -  1  )  )  ;", "}", "METHOD_END"], "methodName": ["connectionReleased"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   activeConnections ;", "}", "METHOD_END"], "methodName": ["getActiveConnections"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   awsAbortedExceptions ;", "}", "METHOD_END"], "methodName": ["getAwsAbortedExceptions"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   awsClientExecuteTime ;", "}", "METHOD_END"], "methodName": ["getAwsClientExecuteTime"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   awsRequestCount ;", "}", "METHOD_END"], "methodName": ["getAwsRequestCount"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   awsRequestTime ;", "}", "METHOD_END"], "methodName": ["getAwsRequestTime"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   awsRetryCount ;", "}", "METHOD_END"], "methodName": ["getAwsRetryCount"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   awsThrottleExceptions ;", "}", "METHOD_END"], "methodName": ["getAwsThrottleExceptions"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   failedUploads ;", "}", "METHOD_END"], "methodName": ["getFailedUploads"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   getMetadataErrors ;", "}", "METHOD_END"], "methodName": ["getGetMetadataErrors"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   getMetadataRetries ;", "}", "METHOD_END"], "methodName": ["getGetMetadataRetries"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   getObjectErrors ;", "}", "METHOD_END"], "methodName": ["getGetObjectErrors"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   getObjectRetries ;", "}", "METHOD_END"], "methodName": ["getGetObjectRetries"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   listLocatedStatusCalls ;", "}", "METHOD_END"], "methodName": ["getListLocatedStatusCalls"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   listObjectsCalls ;", "}", "METHOD_END"], "methodName": ["getListObjectsCalls"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   listStatusCalls ;", "}", "METHOD_END"], "methodName": ["getListStatusCalls"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   metadataCalls ;", "}", "METHOD_END"], "methodName": ["getMetadataCalls"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   otherReadErrors ;", "}", "METHOD_END"], "methodName": ["getOtherReadErrors"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   readRetries ;", "}", "METHOD_END"], "methodName": ["getReadRetries"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   socketExceptions ;", "}", "METHOD_END"], "methodName": ["getSocketExceptions"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   socketTimeoutExceptions ;", "}", "METHOD_END"], "methodName": ["getSocketTimeoutExceptions"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   startedUploads ;", "}", "METHOD_END"], "methodName": ["getStartedUploads"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "return   successfulUploads ;", "}", "METHOD_END"], "methodName": ["getSuccessfulUploads"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "getMetadataErrors . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["newGetMetadataError"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "getMetadataRetries . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["newGetMetadataRetry"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "getObjectErrors . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["newGetObjectError"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "getObjectRetries . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["newGetObjectRetry"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "listLocatedStatusCalls . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["newListLocatedStatusCall"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "listObjectsCalls . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["newListObjectsCall"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "listStatusCalls . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["newListStatusCall"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "metadataCalls . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["newMetadataCall"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "if    ( e   instanceof   SocketException )     {", "socketExceptions . update (  1  )  ;", "} else", "if    ( e   instanceof   SocketTimeoutException )     {", "socketTimeoutExceptions . update (  1  )  ;", "} else", "if    ( e   instanceof   amazonaws . AbortedException )     {", "awsAbortedExceptions . update (  1  )  ;", "} else    {", "otherReadErrors . update (  1  )  ;", "}", "}", "METHOD_END"], "methodName": ["newReadError"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "readRetries . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["newReadRetry"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "awsRequestCount . update ( requestCount )  ;", "}", "METHOD_END"], "methodName": ["updateAwsRequestCount"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "awsRetryCount . update ( retryCount )  ;", "}", "METHOD_END"], "methodName": ["updateAwsRetryCount"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "awsThrottleExceptions . update ( throttleExceptionsCount )  ;", "}", "METHOD_END"], "methodName": ["updateAwsThrottleExceptionsCount"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "failedUploads . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["uploadFailed"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "startedUploads . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["uploadStarted"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "successfulUploads . update (  1  )  ;", "}", "METHOD_END"], "methodName": ["uploadSuccessful"], "fileName": "com.facebook.presto.hive.s3.PrestoS3FileSystemStats"}, {"methodBody": ["METHOD_START", "{", "assertRecordedDefaults ( recordDefaults ( HiveS 3 Config . class )  . setS 3 AwsAccessKey ( null )  . setS 3 AwsSecretKey ( null )  . setS 3 Endpoint ( null )  . setS 3 SignerType ( null )  . setS 3 PathStyleAccess ( false )  . setS 3 UseInstanceCredentials ( true )  . setS 3 SslEnabled ( true )  . setS 3 SseEnabled ( false )  . setS 3 SseType ( PrestoS 3 SseType . S 3  )  . setS 3 SseKmsKeyId ( null )  . setS 3 KmsKeyId ( null )  . setS 3 EncryptionMaterialsProvider ( null )  . setS 3 MaxClientRetries (  5  )  . setS 3 MaxErrorRetries (  1  0  )  . setS 3 MaxBackoffTime ( new   Duration (  1  0  ,    TimeUnit . MINUTES )  )  . setS 3 MaxRetryTime ( new   Duration (  1  0  ,    TimeUnit . MINUTES )  )  . setS 3 ConnectTimeout ( new   Duration (  5  ,    TimeUnit . SECONDS )  )  . setS 3 SocketTimeout ( new   Duration (  5  ,    TimeUnit . SECONDS )  )  . setS 3 MultipartMinFileSize ( new   io . airlift . units . DataSize (  1  6  ,    Unit . MEGABYTE )  )  . setS 3 MultipartMinPartSize ( new   io . airlift . units . DataSize (  5  ,    Unit . MEGABYTE )  )  . setS 3 MaxConnections (  5  0  0  )  . setS 3 StagingDirectory ( new   File ( JAVA _ IO _ TMPDIR . value (  )  )  )  . setPinS 3 ClientToCurrentRegion ( false )  . setS 3 UserAgentPrefix (  \"  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "com.facebook.presto.hive.s3.TestHiveS3Config"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . s 3  . aws - access - key \"  ,     \" abc 1  2  3  \"  )  . put (  \" hive . s 3  . aws - secret - key \"  ,     \" secret \"  )  . put (  \" hive . s 3  . endpoint \"  ,     \" endpoint . example . com \"  )  . put (  \" hive . s 3  . signer - type \"  ,     \" S 3 SignerType \"  )  . put (  \" hive . s 3  . path - style - access \"  ,     \" true \"  )  . put (  \" hive . s 3  . use - instance - credentials \"  ,     \" false \"  )  . put (  \" hive . s 3  . ssl . enabled \"  ,     \" false \"  )  . put (  \" hive . s 3  . sse . enabled \"  ,     \" true \"  )  . put (  \" hive . s 3  . sse . type \"  ,     \" KMS \"  )  . put (  \" hive . s 3  . sse . kms - key - id \"  ,     \" KMS _ KEY _ ID \"  )  . put (  \" hive . s 3  . encryption - materials - provider \"  ,     \" EMP _ CLASS \"  )  . put (  \" hive . s 3  . kms - key - id \"  ,     \" KEY _ ID \"  )  . put (  \" hive . s 3  . max - client - retries \"  ,     \"  9  \"  )  . put (  \" hive . s 3  . max - error - retries \"  ,     \"  8  \"  )  . put (  \" hive . s 3  . max - backoff - time \"  ,     \"  4 m \"  )  . put (  \" hive . s 3  . max - retry - time \"  ,     \"  2  0 m \"  )  . put (  \" hive . s 3  . connect - timeout \"  ,     \"  8 s \"  )  . put (  \" hive . s 3  . socket - timeout \"  ,     \"  4 m \"  )  . put (  \" hive . s 3  . multipart . min - file - size \"  ,     \"  3  2 MB \"  )  . put (  \" hive . s 3  . multipart . min - part - size \"  ,     \"  1  5 MB \"  )  . put (  \" hive . s 3  . max - connections \"  ,     \"  7  7  \"  )  . put (  \" hive . s 3  . staging - directory \"  ,     \"  / s 3  - staging \"  )  . put (  \" hive . s 3  . pin - client - to - current - region \"  ,     \" true \"  )  . put (  \" hive . s 3  . user - agent - prefix \"  ,     \" user - agent - prefix \"  )  . build (  )  ;", "expected    =    new    (  )  . setS 3 AwsAccessKey (  \" abc 1  2  3  \"  )  . setS 3 AwsSecretKey (  \" secret \"  )  . setS 3 Endpoint (  \" endpoint . example . com \"  )  . setS 3 SignerType ( PrestoS 3 SignerType . S 3 SignerType )  . setS 3 PathStyleAccess ( true )  . setS 3 UseInstanceCredentials ( false )  . setS 3 SslEnabled ( false )  . setS 3 SseEnabled ( true )  . setS 3 SseType ( PrestoS 3 SseType . KMS )  . setS 3 SseKmsKeyId (  \" KMS _ KEY _ ID \"  )  . setS 3 EncryptionMaterialsProvider (  \" EMP _ CLASS \"  )  . setS 3 KmsKeyId (  \" KEY _ ID \"  )  . setS 3 MaxClientRetries (  9  )  . setS 3 MaxErrorRetries (  8  )  . setS 3 MaxBackoffTime ( new   Duration (  4  ,    TimeUnit . MINUTES )  )  . setS 3 MaxRetryTime ( new   Duration (  2  0  ,    TimeUnit . MINUTES )  )  . setS 3 ConnectTimeout ( new   Duration (  8  ,    TimeUnit . SECONDS )  )  . setS 3 SocketTimeout ( new   Duration (  4  ,    TimeUnit . MINUTES )  )  . setS 3 MultipartMinFileSize ( new   io . airlift . units . DataSize (  3  2  ,    Unit . MEGABYTE )  )  . setS 3 MultipartMinPartSize ( new   io . airlift . units . DataSize (  1  5  ,    Unit . MEGABYTE )  )  . setS 3 MaxConnections (  7  7  )  . setS 3 StagingDirectory ( new   File (  \"  / s 3  - staging \"  )  )  . setPinS 3 ClientToCurrentRegion ( true )  . setS 3 UserAgentPrefix (  \" user - agent - prefix \"  )  ;", "assertFullMapping ( properties ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMappings"], "fileName": "com.facebook.presto.hive.s3.TestHiveS3Config"}, {"methodBody": ["METHOD_START", "{", "return   TestPrestoS 3 FileSystem . getFieldValue ( fs . getS 3 Client (  )  ,     \" awsCredentialsProvider \"  ,    AWSCredentialsProvider . class )  ;", "}", "METHOD_END"], "methodName": ["getAwsCredentialsProvider"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    {", "Field   field    =    clazz . getDeclaredField ( name )  ;", "checkArgument (  (  ( field . getType (  )  )     =  =    type )  ,     \" expected    % s   but   found    % s \"  ,    type ,    field . getType (  )  )  ;", "field . setAccessible ( true )  ;", "return    (  ( T )     ( field . get ( instance )  )  )  ;", "}    catch    ( ReflectOperationException   e )     {", "throw   Throwables . propagate ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["getFieldValue"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "return   TestPrestoS 3 FileSystem . getFieldValue ( instance ,    instance . getClass (  )  ,    name ,    type )  ;", "}", "METHOD_END"], "methodName": ["getFieldValue"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ ACCESS _ KEY ,     \" test _ secret _ access _ key \"  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ SECRET _ KEY ,     \" test _ access _ key _ id \"  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ ENDPOINT ,     \" test . example . endpoint . com \"  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ SIGNER _ TYPE ,     \" S 3 SignerType \"  )  ;", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "fs . initialize ( new   URI (  \" s 3 a :  /  / test - bucket /  \"  )  ,    config )  ;", "Assertions . assertInstanceOf (  . getAwsCredentialsProvider ( fs )  ,    AWSStaticCredentialsProvider . class )  ;", "}", "}", "METHOD_END"], "methodName": ["testCompatibleStaticCredentials"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Path   stagingParent    =    Files . createTempDirectory (  \" test \"  )  ;", "Path   staging    =    Paths . get ( stagingParent . toString (  )  ,     \" staging \"  )  ;", "try    (    fs    =    new    (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "Configuration   conf    =    new   Configuration (  )  ;", "conf . set ( S 3 ConfigurationUpdater . S 3  _ STAGING _ DIRECTORY ,    staging . toString (  )  )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    conf )  ;", "fs . setS 3 Client ( s 3  )  ;", "FSDataOutputStream   stream    =    fs . create ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  ;", "stream . close (  )  ;", "assertTrue ( Files . exists ( staging )  )  ;", "}    finally    {", "deleteRecursively ( stagingParent ,    ALLOW _ INSECURE )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateWithNonexistentStagingDirectory"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Path   staging    =    Files . createTempFile (  \" staging \"  ,    null )  ;", "try    (    fs    =    new    (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "Configuration   conf    =    new   Configuration (  )  ;", "conf . set ( S 3 ConfigurationUpdater . S 3  _ STAGING _ DIRECTORY ,    staging . toString (  )  )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    conf )  ;", "fs . setS 3 Client ( s 3  )  ;", "fs . create ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  ;", "}    finally    {", "Files . deleteIfExists ( staging )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateWithStagingDirectoryFile"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Path   staging    =    Files . createTempDirectory (  \" staging \"  )  ;", "Path   link    =    Paths . get (  ( staging    +     \"  . symlink \"  )  )  ;", "try    {", "try    {", "Files . createSymbolicLink ( link ,    staging )  ;", "}    catch    ( UnsupportedOperationException   e )     {", "throw   new   SkipException (  \" Filesystem   does   not   support   symlinks \"  ,    e )  ;", "}", "try    (    fs    =    new    (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "Configuration   conf    =    new   Configuration (  )  ;", "conf . set ( S 3 ConfigurationUpdater . S 3  _ STAGING _ DIRECTORY ,    link . toString (  )  )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    conf )  ;", "fs . setS 3 Client ( s 3  )  ;", "FSDataOutputStream   stream    =    fs . create ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  ;", "stream . close (  )  ;", "assertTrue ( Files . exists ( link )  )  ;", "}", "}    finally    {", "deleteRecursively ( link ,    ALLOW _ INSECURE )  ;", "deleteRecursively ( staging ,    ALLOW _ INSECURE )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateWithStagingDirectorySymlink"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ USE _ INSTANCE _ CREDENTIALS ,     \" false \"  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ CREDENTIALS _ PROVIDER ,     \" com . example . DoesNotExist \"  )  ;", "try    (    fs    =    new    (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    config )  ;", "}", "}", "METHOD_END"], "methodName": ["testCustomCredentialsClassCannotBeFound"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ USE _ INSTANCE _ CREDENTIALS ,     \" false \"  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ CREDENTIALS _ PROVIDER ,     . TestCredentialsProvider . class . getName (  )  )  ;", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    config )  ;", "Assertions . assertInstanceOf (  . getAwsCredentialsProvider ( fs )  ,     . TestCredentialsProvider . class )  ;", "}", "}", "METHOD_END"], "methodName": ["testCustomCredentialsProvider"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "HiveS 3 Config   defaults    =    new   HiveS 3 Config (  )  ;", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    new   Configuration (  )  )  ;", "ClientConfiguration   config    =     . getFieldValue ( fs . getS 3 Client (  )  ,    AmazonWebServiceClient . class ,     \" clientConfiguration \"  ,    ClientConfiguration . class )  ;", "assertEquals ( config . getMaxErrorRetry (  )  ,    defaults . getS 3 MaxErrorRetries (  )  )  ;", "assertEquals ( config . getConnectionTimeout (  )  ,    defaults . getS 3 ConnectTimeout (  )  . toMillis (  )  )  ;", "assertEquals ( config . getSocketTimeout (  )  ,    defaults . getS 3 SocketTimeout (  )  . toMillis (  )  )  ;", "assertEquals ( config . getMaxConnections (  )  ,    defaults . getS 3 MaxConnections (  )  )  ;", "assertEquals ( config . getUserAgentSuffix (  )  ,    S 3 ConfigurationUpdater . S 3  _ USER _ AGENT _ SUFFIX )  ;", "assertEquals ( config . getUserAgentPrefix (  )  ,     \"  \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDefaultS3ClientConfiguration"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ ENCRYPTION _ MATERIALS _ PROVIDER ,     . TestEncryptionMaterialsProvider . class . getName (  )  )  ;", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    config )  ;", "Assertions . assertInstanceOf ( fs . getS 3 Client (  )  ,    AmazonS 3 EncryptionClient . class )  ;", "}", "}", "METHOD_END"], "methodName": ["testEncryptionMaterialsProvider"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ ENDPOINT ,     \" test . example . endpoint . com \"  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ PIN _ CLIENT _ TO _ CURRENT _ REGION ,     \" true \"  )  ;", "try    (    fs    =    new    (  )  )     {", "fs . initialize ( new   URI (  \" s 3 a :  /  / test - bucket /  \"  )  ,    config )  ;", "}", "}", "METHOD_END"], "methodName": ["testEndpointWithPinToCurrentRegionConfiguration"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "s 3  . setGetObjectMetadataHttpCode ( SC _ FORBIDDEN )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    new   Configuration (  )  )  ;", "fs . setS 3 Client ( s 3  )  ;", "fs . getS 3 ObjectMetadata ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetMetadataForbidden"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "s 3  . setGetObjectMetadataHttpCode ( SC _ NOT _ FOUND )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    new   Configuration (  )  )  ;", "fs . setS 3 Client ( s 3  )  ;", "assertEquals ( fs . getS 3 ObjectMetadata ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  ,    null )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetMetadataNotFound"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "int   maxRetries    =     2  ;", "try    (    fs    =    new    (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "s 3  . setGetObjectMetadataHttpCode ( SC _ INTERNAL _ SERVER _ ERROR )  ;", "Configuration   configuration    =    new   Configuration (  )  ;", "configuration . set ( S 3 ConfigurationUpdater . S 3  _ MAX _ BACKOFF _ TIME ,     \"  1 ms \"  )  ;", "configuration . set ( S 3 ConfigurationUpdater . S 3  _ MAX _ RETRY _ TIME ,     \"  5 s \"  )  ;", "configuration . setInt ( S 3 ConfigurationUpdater . S 3  _ MAX _ CLIENT _ RETRIES ,    maxRetries )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    configuration )  ;", "fs . setS 3 Client ( s 3  )  ;", "fs . getS 3 ObjectMetadata ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  ;", "}    catch    ( Throwable   expected )     {", "Assertions . assertInstanceOf ( expected ,    AmazonS 3 Exception . class )  ;", "assertEquals (  (  ( AmazonS 3 Exception )     ( expected )  )  . getStatusCode (  )  ,    SC _ INTERNAL _ SERVER _ ERROR )  ;", "assertEquals (  . getFileSystemStats (  )  . getGetMetadataRetries (  )  . getTotalCount (  )  ,    maxRetries )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetMetadataRetryCounter"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . setBoolean ( S 3 ConfigurationUpdater . S 3  _ USE _ INSTANCE _ CREDENTIALS ,    false )  ;", "try    (    fs    =    new    (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    config )  ;", "}", "}", "METHOD_END"], "methodName": ["testInstanceCredentialsDisabled"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    config )  ;", "Assertions . assertInstanceOf (  . getAwsCredentialsProvider ( fs )  ,    InstanceProfileCredentialsProvider . class )  ;", "}", "}", "METHOD_END"], "methodName": ["testInstanceCredentialsEnabled"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ KMS _ KEY _ ID ,     \" test - key - id \"  )  ;", "try    (    fs    =    new    (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    config )  ;", "Assertions . assertInstanceOf ( fs . getS 3 Client (  )  ,    AmazonS 3 EncryptionClient . class )  ;", "}", "}", "METHOD_END"], "methodName": ["testKMSEncryptionMaterialsProvider"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . setBoolean ( S 3 ConfigurationUpdater . S 3  _ PATH _ STYLE _ ACCESS ,    true )  ;", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    config )  ;", "S 3 ClientOptions   clientOptions    =     . getFieldValue ( fs . getS 3 Client (  )  ,    AmazonS 3 Client . class ,     \" clientOptions \"  ,    S 3 ClientOptions . class )  ;", "assertTrue ( clientOptions . isPathStyleAccess (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testPathStyleAccess"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "s 3  . setGetObjectHttpErrorCode ( SC _ FORBIDDEN )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    new   Configuration (  )  )  ;", "fs . setS 3 Client ( s 3  )  ;", "try    ( FSDataInputStream   inputStream    =    fs . open ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  )     {", "inputStream . read (  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testReadForbidden"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "s 3  . setGetObjectHttpErrorCode ( SC _ NOT _ FOUND )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    new   Configuration (  )  )  ;", "fs . setS 3 Client ( s 3  )  ;", "try    ( FSDataInputStream   inputStream    =    fs . open ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  )     {", "inputStream . read (  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testReadNotFound"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "s 3  . setGetObjectHttpErrorCode ( SC _ REQUESTED _ RANGE _ NOT _ SATISFIABLE )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    new   Configuration (  )  )  ;", "fs . setS 3 Client ( s 3  )  ;", "try    ( FSDataInputStream   inputStream    =    fs . open ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  )     {", "assertEquals ( inputStream . read (  )  ,     (  -  1  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testReadRequestRangeNotSatisfiable"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "int   maxRetries    =     2  ;", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "s 3  . setGetObjectHttpErrorCode ( SC _ INTERNAL _ SERVER _ ERROR )  ;", "Configuration   configuration    =    new   Configuration (  )  ;", "configuration . set ( S 3 ConfigurationUpdater . S 3  _ MAX _ BACKOFF _ TIME ,     \"  1 ms \"  )  ;", "configuration . set ( S 3 ConfigurationUpdater . S 3  _ MAX _ RETRY _ TIME ,     \"  5 s \"  )  ;", "configuration . setInt ( S 3 ConfigurationUpdater . S 3  _ MAX _ CLIENT _ RETRIES ,    maxRetries )  ;", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    configuration )  ;", "fs . setS 3 Client ( s 3  )  ;", "try    ( FSDataInputStream   inputStream    =    fs . open ( new   Path (  \" s 3 n :  /  / test - bucket / test \"  )  )  )     {", "inputStream . read (  )  ;", "}    catch    ( Throwable   expected )     {", "Assertions . assertInstanceOf ( expected ,    AmazonS 3 Exception . class )  ;", "assertEquals (  (  ( AmazonS 3 Exception )     ( expected )  )  . getStatusCode (  )  ,    SC _ INTERNAL _ SERVER _ ERROR )  ;", "assertEquals ( PrestoS 3 FileSystem . getFileSystemStats (  )  . getReadRetries (  )  . getTotalCount (  )  ,    maxRetries )  ;", "assertEquals ( PrestoS 3 FileSystem . getFileSystemStats (  )  . getGetObjectRetries (  )  . getTotalCount (  )  ,     (  ( maxRetries    +     1 L )     *    maxRetries )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testReadRetryCounters"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ ACCESS _ KEY ,     \" test _ secret _ access _ key \"  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ SECRET _ KEY ,     \" test _ access _ key _ id \"  )  ;", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    config )  ;", "Assertions . assertInstanceOf (  . getAwsCredentialsProvider ( fs )  ,    AWSStaticCredentialsProvider . class )  ;", "}", "}", "METHOD_END"], "methodName": ["testStaticCredentials"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "Configuration   config    =    new   Configuration (  )  ;", "config . setBoolean ( S 3 ConfigurationUpdater . S 3  _ PATH _ STYLE _ ACCESS ,    true )  ;", "try    (    fs    =    new    (  )  )     {", "MockAmazonS 3    s 3     =    new   MockAmazonS 3  (  )  ;", "String   expectedBucketName    =     \" test - bucket _ underscore \"  ;", "fs . initialize ( new   URI (  (  (  \" s 3 n :  /  /  \"     +    expectedBucketName )     +     \"  /  \"  )  )  ,    config )  ;", "fs . setS 3 Client ( s 3  )  ;", "fs . getS 3 ObjectMetadata ( new   Path (  \"  / test / path \"  )  )  ;", "assertEquals ( expectedBucketName ,    s 3  . getGetObjectMetadataRequest (  )  . getBucketName (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testUnderscoreBucket"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "throw   new   PrestoS 3 FileSystem . UnrecoverableS 3 OperationException ( new   Path (  \"  / tmp / test / path \"  )  ,    new   IOException (  \" test   io   exception \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnrecoverableS3ExceptionMessage"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "String   userAgentPrefix    =     \" agent _ prefix \"  ;", "Configuration   config    =    new   Configuration (  )  ;", "config . set ( S 3 ConfigurationUpdater . S 3  _ USER _ AGENT _ PREFIX ,    userAgentPrefix )  ;", "try    ( PrestoS 3 FileSystem   fs    =    new   PrestoS 3 FileSystem (  )  )     {", "fs . initialize ( new   URI (  \" s 3 n :  /  / test - bucket /  \"  )  ,    config )  ;", "ClientConfiguration   clientConfig    =     . getFieldValue ( fs . getS 3 Client (  )  ,    AmazonWebServiceClient . class ,     \" clientConfiguration \"  ,    ClientConfiguration . class )  ;", "assertEquals ( clientConfig . getUserAgentSuffix (  )  ,    S 3 ConfigurationUpdater . S 3  _ USER _ AGENT _ SUFFIX )  ;", "assertEquals ( clientConfig . getUserAgentPrefix (  )  ,    userAgentPrefix )  ;", "}", "}", "METHOD_END"], "methodName": ["testUserAgentPrefix"], "fileName": "com.facebook.presto.hive.s3.TestPrestoS3FileSystem"}, {"methodBody": ["METHOD_START", "{", "install ( installModuleIf ( SecurityConfig . class ,     (    security )     -  >    name . equalsIgnoreCase ( security . getSecuritySystem (  )  )  ,    module )  )  ;", "}", "METHOD_END"], "methodName": ["bindSecurityModule"], "fileName": "com.facebook.presto.hive.security.HiveSecurityModule"}, {"methodBody": ["METHOD_START", "{", "return   this . allowAddColumn ;", "}", "METHOD_END"], "methodName": ["getAllowAddColumn"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "return   this . allowDropColumn ;", "}", "METHOD_END"], "methodName": ["getAllowDropColumn"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "return   this . allowDropTable ;", "}", "METHOD_END"], "methodName": ["getAllowDropTable"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "return   this . allowRenameColumn ;", "}", "METHOD_END"], "methodName": ["getAllowRenameColumn"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "return   this . allowRenameTable ;", "}", "METHOD_END"], "methodName": ["getAllowRenameTable"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "this . allowAddColumn    =    allowAddColumn ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setAllowAddColumn"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "this . allowDropColumn    =    allowDropColumn ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setAllowDropColumn"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "this . allowDropTable    =    allowDropTable ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setAllowDropTable"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "this . allowRenameColumn    =    allowRenameColumn ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setAllowRenameColumn"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "this . allowRenameTable    =    allowRenameTable ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setAllowRenameTable"], "fileName": "com.facebook.presto.hive.security.LegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "return   securitySystem ;", "}", "METHOD_END"], "methodName": ["getSecuritySystem"], "fileName": "com.facebook.presto.hive.security.SecurityConfig"}, {"methodBody": ["METHOD_START", "{", "this . securitySystem    =    securitySystem ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setSecuritySystem"], "fileName": "com.facebook.presto.hive.security.SecurityConfig"}, {"methodBody": ["METHOD_START", "{", "SemiTransactionalHiveMetastore   metastore    =    metastoreProvider . apply (  (  ( HiveTransactionHandle )     ( transaction )  )  )  ;", "Set < HivePrivilegeInfo . HivePrivilege >    privilegeSet    =    metastore . getDatabasePrivileges ( identgetUser (  )  ,    schemaName )  . stream (  )  . map ( HivePrivilegeInfo :  : getHivePrivilege )  . collect ( Collectors . toSet (  )  )  ;", "return   privilegeSet . containsAll ( ImmutableSet . copyOf ( requiredPrivileges )  )  ;", "}", "METHOD_END"], "methodName": ["checkDatabasePermission"], "fileName": "com.facebook.presto.hive.security.SqlStandardAccessControl"}, {"methodBody": ["METHOD_START", "{", "if    ( SqlStandardAccessControl . INFORMATION _ SCHEMA _ NAME . equals ( tableName . getSchemaName (  )  )  )     {", "return   true ;", "}", "SemiTransactionalHiveMetastore   metastore    =    metastoreProvider . apply (  (  ( HiveTransactionHandle )     ( transaction )  )  )  ;", "Set < HivePrivilegeInfo . HivePrivilege >    privilegeSet    =    metastore . getTablePrivileges ( identity . getUser (  )  ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . stream (  )  . map ( HivePrivilegeInfo :  : getHivePrivilege )  . collect ( Collectors . toSet (  )  )  ;", "return   privilegeSet . containsAll ( ImmutableSet . copyOf ( requiredPrivileges )  )  ;", "}", "METHOD_END"], "methodName": ["checkTablePermission"], "fileName": "com.facebook.presto.hive.security.SqlStandardAccessControl"}, {"methodBody": ["METHOD_START", "{", "SemiTransactionalHiveMetastore   metastore    =    metastoreProvider . apply (  (  ( HiveTransactionHandle )     ( transaction )  )  )  ;", "return   metastore . getTablePrivileges ( identgetUser (  )  ,    tableName . getSchemaName (  )  ,    tableName . getTableName (  )  )  . contains ( new   HivePrivilegeInfo ( HivePrivilegeInfo . toHivePrivilege ( privilege )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["getGrantOptionForPrivilege"], "fileName": "com.facebook.presto.hive.security.SqlStandardAccessControl"}, {"methodBody": ["METHOD_START", "{", "SemiTransactionalHiveMetastore   metastore    =    metastoreProvider . apply (  (  ( HiveTransactionHandle )     ( transaction )  )  )  ;", "return   metastore . getRoles ( identity . getUser (  )  )  . contains (  . ADMIN _ ROLE _ NAME )  ;", "}", "METHOD_END"], "methodName": ["isAdmin"], "fileName": "com.facebook.presto.hive.security.SqlStandardAccessControl"}, {"methodBody": ["METHOD_START", "{", "return   checkDatabasePermission ( transaction ,    identity ,    schemaName ,    HivePrivilegeInfo . HivePrivilege . OWNERSHIP )  ;", "}", "METHOD_END"], "methodName": ["isDatabaseOwner"], "fileName": "com.facebook.presto.hive.security.SqlStandardAccessControl"}, {"methodBody": ["METHOD_START", "{", "assertRecordedDefaults ( recordDefaults ( LegacySecurityConfig . class )  . setAllowAddColumn ( false )  . setAllowDropColumn ( false )  . setAllowDropTable ( false )  . setAllowRenameTable ( false )  . setAllowRenameColumn ( false )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "com.facebook.presto.hive.security.TestLegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    properties    =    new   Builder < String ,    String >  (  )  . put (  \" hive . allow - add - column \"  ,     \" true \"  )  . put (  \" hive . allow - drop - column \"  ,     \" true \"  )  . put (  \" hive . allow - drop - table \"  ,     \" true \"  )  . put (  \" hive . allow - rename - table \"  ,     \" true \"  )  . put (  \" hive . allow - rename - column \"  ,     \" true \"  )  . build (  )  ;", "expected    =    new    (  )  . setAllowAddColumn ( true )  . setAllowDropColumn ( true )  . setAllowDropTable ( true )  . setAllowRenameTable ( true )  . setAllowRenameColumn ( true )  ;", "assertFullMapping ( properties ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testExplicitPropertyMappings"], "fileName": "com.facebook.presto.hive.security.TestLegacySecurityConfig"}, {"methodBody": ["METHOD_START", "{", "for    ( Method   interfaceMethod    :    interfaceClass . getMethods (  )  )     {", "Method   implementationMethod    =    implementationClass . getMethod ( interfaceMethod . getName (  )  ,    interfaceMethod . getParameterTypes (  )  )  ;", "if    ( interfaceMethod . equals ( implementationMethod )  )     {", "throw   new   AssertionError ( String . format (  \" Method   should   be   overridden   in    % s :     % s \"  ,    implementationClass ,    interfaceMethod )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["checkEverythingImplemented"], "fileName": "com.facebook.presto.hive.security.TestPartitionsAwareAccessControl"}, {"methodBody": ["METHOD_START", "{", "TestPartitionsAwareAccessControl . checkEverythingImplemented ( ConnectorAccessControl . class ,    PartitionsAwareAccessControl . class )  ;", "}", "METHOD_END"], "methodName": ["testEverythingDelegated"], "fileName": "com.facebook.presto.hive.security.TestPartitionsAwareAccessControl"}, {"methodBody": ["METHOD_START", "{", "return   summarizePartitionStatistics ( statisticsByPartitionName . values (  )  ,    column ,     (    columnStatistics )     -  >     {", "if    ( columnStatistics . getDistinctValuesCount (  )  . isPresent (  )  )     {", "return   OptionalDouble . of ( columnStatistics . getDistinctValuesCount (  )  . getAsLong (  )  )  ;", "} else    {", "return   OptionalDouble . empty (  )  ;", "}", "}  ,    DoubleStream :  : max )  ;", "}", "METHOD_END"], "methodName": ["calculateDistinctValuesCount"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "Estimate   totalNullsCount    =    summarizePartitionStatistics ( statisticsByPartitionName . values (  )  ,    column ,     (    columnStatistics )     -  >     {", "if    ( columnStatistics . getNullsCount (  )  . isPresent (  )  )     {", "return   OptionalDouble . of ( columnStatistics . getNullsCount (  )  . getAsLong (  )  )  ;", "} else    {", "return   OptionalDouble . empty (  )  ;", "}", "}  ,     (    nullsCountStream )     -  >     {", "double   nullsCount    =     0  ;", "long   partitionsWithStatisticsCount    =     0  ;", "for    ( PrimitiveIterator . OfDouble   nullsCountIterator    =    nullsCountStream . iterator (  )  ;    nullsCountIterator . hasNext (  )  ;  )     {", "nullsCount    +  =    nullsCountIterator . nextDouble (  )  ;", "partitionsWithStatisticsCount +  +  ;", "}", "if    ( partitionsWithStatisticsCount    =  =     0  )     {", "return   OptionalDouble . empty (  )  ;", "} else    {", "int   allPartitionsCount    =    statisticsByPartitionName . size (  )  ;", "return   OptionalDouble . of (  (  ( allPartitionsCount    /    partitionsWithStatisticsCount )     *    nullsCount )  )  ;", "}", "}  )  ;", "if    (  ( totalNullsCount . isValueUnknown (  )  )     |  |     ( totalRowsCount . isValueUnknown (  )  )  )     {", "return   Estimate . unknownValue (  )  ;", "}", "if    (  ( totalRowsCount . getValue (  )  )     =  =     0  .  0  )     {", "return   Estimate . zeroValue (  )  ;", "}", "return   new   Estimate (  (  ( totalNullsCount . getValue (  )  )     /     ( totalRowsCount . getValue (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["calculateNullsFraction"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "OptionalDouble   rowsPerPartition    =    partitionStatistics . values (  )  . stream (  )  . map ( PartitionStatistics :  : getRowCount )  . filter ( OptionalLong :  : isPresent )  . mapToLong ( OptionalLong :  : getAsLong )  . average (  )  ;", "if    (  !  ( rowsPerPartition . isPresent (  )  )  )     {", "return   Estimate . unknownValue (  )  ;", "}", "double   estimatedTotalRowsCount    =     ( rowsPerPartition . getAsDouble (  )  )     *     ( partitions . size (  )  )  ;", "if    ( estimatedTotalRowsCount    =  =     0  .  0  )     {", "return   Estimate . zeroValue (  )  ;", "}", "double   estimatedNullsCount    =    partitions . stream (  )  . filter (  (    partition )     -  >    partition . getKeys (  )  . get ( partitionColumn )  . isNull (  )  )  . map ( HivePartition :  : getPartitionId )  . mapToLong (  (    partitionId )     -  >    partitionStatistics . get ( partitionId )  . getRowCount (  )  . orElse (  (  ( long )     ( rowsPerPartition . getAsDouble (  )  )  )  )  )  . sum (  )  ;", "return   new   Estimate (  ( estimatedNullsCount    /    estimatedTotalRowsCount )  )  ;", "}", "METHOD_END"], "methodName": ["calculateNullsFractionForPartitioningKey"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "List < Long >    knownPartitionRowCounts    =    partitionStatistics . values (  )  . stream (  )  . map ( PartitionStatistics :  : getRowCount )  . filter ( OptionalLong :  : isPresent )  . map ( OptionalLong :  : getAsLong )  . collect ( Collectors . toList (  )  )  ;", "long   knownPartitionRowCountsSum    =    knownPartitionRowCounts . stream (  )  . mapToLong (  (    a )     -  >    a )  . sum (  )  ;", "long   partitionsWithStatsCount    =    knownPartitionRowCounts . size (  )  ;", "long   allPartitionsCount    =    partitionStatistics . size (  )  ;", "if    ( partitionsWithStatsCount    =  =     0  )     {", "return   Estimate . unknownValue (  )  ;", "}", "return   new   Estimate (  (  (  (  1  .  0     *    knownPartitionRowCountsSum )     /    partitionsWithStatsCount )     *    allPartitionsCount )  )  ;", "}", "METHOD_END"], "methodName": ["calculateRowsCount"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "if    ( parameterValue    =  =    null )     {", "return   OptionalLong . empty (  )  ;", "}", "try    {", "long   longValue    =    Long . parseLong ( parameterValue )  ;", "if    ( longValue    <     0  )     {", "return   OptionalLong . empty (  )  ;", "}", "return   OptionalLong . of ( longValue )  ;", "}    catch    ( NumberFormatException   e )     {", "return   OptionalLong . empty (  )  ;", "}", "}", "METHOD_END"], "methodName": ["convertStringParameter"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "return   new   com . facebook . presto . spi . statistics . Estimate ( partitions . stream (  )  . map ( HivePartition :  : getKeys )  . map (  (    keys )     -  >    keys . get ( partitionColumn )  )  . distinct (  )  . count (  )  )  ;", "}", "METHOD_END"], "methodName": ["countDistinctPartitionKeys"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "return    (  ( HiveColumnHandle )     ( columnHandle )  )  . getColumnMetadata ( typeManager )  ;", "}", "METHOD_END"], "methodName": ["getColumnMetadata"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "if    ( hivePartitions . isEmpty (  )  )     {", "return   ImmutableMap . of (  )  ;", "}", "boolean   unpartitioned    =    hivePartitions . stream (  )  . anyMatch (  (    partition )     -  >    partition . getPartitionId (  )  . equals ( HivePartition . UNPARTITIONED _ ID )  )  ;", "if    ( unpartitioned )     {", "checkArgument (  (  ( hivePartitions . size (  )  )     =  =     1  )  ,     \" expected   only   one   hive   partition \"  )  ;", "}", "if    ( unpartitioned )     {", "return   ImmutableMap . of ( HivePartition . UNPARTITIONED _ ID ,    getTableStatistics ( tableHandle . getSchemaTableName (  )  ,    tableColumns . keySet (  )  )  )  ;", "} else    {", "return   getPartitionsStatistics ( tableHandle . getSchemaTableName (  )  ,    hivePartitions ,     . listNonPartitioningColumns ( tableColumns )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getPartitionsStatistics"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "String   databaseName    =    schemaTableName . getSchemaName (  )  ;", "String   tableName    =    schemaTableName . getTableName (  )  ;", "Builder < String ,    Partition >    resultMap    =    ImmutableMap . builder (  )  ;", "List < String >    partitionNames    =    hivePartitions . stream (  )  . map ( HivePartition :  : getPartitionId )  . collect ( Collectors . toList (  )  )  ;", "Map < String ,    Map < String ,    HiveColumn >  >    partitionColumnMap    =    metastore . getPartitionColumn ( databaseName ,    tableName ,    new   HashSet <  >  ( partitionNames )  ,    tableColumns )  . orElse ( ImmutableMap . of (  )  )  ;", "Map < String ,    Optional < Partition >  >    partitionsByNames    =    metastore . getPartitionsByNames ( databaseName ,    tableName ,    partitionNames )  ;", "for    ( String   partitionName    :    partitionNames )     {", "Map < String ,    String >    partitionParameters    =    partitionsByNames . get ( partitionName )  . map ( Partition :  : getParameters )  . orElseThrow (  (  )     -  >    new   IllegalArgumentException ( String . format (  \" Could   not   get   metadata   for   partition    % s .  % s .  % s \"  ,    databaseName ,    tableName ,    partitionName )  )  )  ;", "Map < String ,    HiveColumn >    partitionColumn    =    partitionColumnMap . getOrDefault ( partitionName ,    ImmutableMap . of (  )  )  ;", "resultMap . put ( partitionName ,    readFromParameters ( partitionParameters ,    partitionColumn )  )  ;", "}", "return   resultMap . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPartitionsStatistics"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "String   databaseName    =    schemaTableName . getSchemaName (  )  ;", "String   tableName    =    schemaTableName . getTableName (  )  ;", "Table   table    =    metastore . getTable ( databaseName ,    tableName )  . orElseThrow (  (  )     -  >    new   IllegalArgumentException ( String . format (  \" Could   not   get   metadata   for   table    % s .  % s \"  ,    databaseName ,    tableName )  )  )  ;", "Map < String ,    HiveColumn >    tableColumn    =    metastore . getTableColumn ( databaseName ,    tableName ,    tableColumns )  . orElse ( ImmutableMap . of (  )  )  ;", "return   readFromParameters ( table . getParameters (  )  ,    tableColumn )  ;", "}", "METHOD_END"], "methodName": ["getTableStatistics"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "return   tableColumns . entrySet (  )  . stream (  )  . filter (  (    entry )     -  >     !  (  (  ( HiveColumnHandle )     ( entry . getValue (  )  )  )  . isPartitionKey (  )  )  )  . map ( Map . Entry :  : getKey )  . collect ( toImmutableSet (  )  )  ;", "}", "METHOD_END"], "methodName": ["listNonPartitioningColumns"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "boolean   columnStatsAcurate    =    Boolean . valueOf ( Optional . ofNullable ( parameters . get (  \" COLUMN _ STATS _ ACCURATE \"  )  )  . orElse (  \" false \"  )  )  ;", "OptionalLong   numFiles    =    convertStringParameter ( parameters . get (  \" numFiles \"  )  )  ;", "OptionalLong   numRows    =    convertStringParameter ( parameters . get (  \" numRows \"  )  )  ;", "OptionalLong   rawDataSize    =    convertStringParameter ( parameters . get (  \" rawDataSize \"  )  )  ;", "OptionalLong   totalSize    =    convertStringParameter ( parameters . get (  \" totalSize \"  )  )  ;", "return   new   Partition ( columnStatsAcurate ,    numFiles ,    numRows ,    rawDataSize ,    totalSize ,    column )  ;", "}", "METHOD_END"], "methodName": ["readStatisticsFromParameters"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "DoubleStream   intermediateStream    =    partitionStatistics . stream (  )  . map ( PartitionStatistics :  : getColumnStatistics )  . filter (  (    stats )     -  >    stats . containsKey ( column )  )  . map (  (    stats )     -  >    stats . get ( column )  )  . map ( valueExtractFunction )  . filter ( OptionalDouble :  : isPresent )  . mapToDouble ( OptionalDouble :  : getAsDouble )  ;", "OptionalDouble   statisticsValue    =    valueAggregateFunction . apply ( intermediateStream )  ;", "if    ( statisticsValue . isPresent (  )  )     {", "return   new   Estimate ( statisticsValue . getAsDouble (  )  )  ;", "} else    {", "return   Estimate . unknownValue (  )  ;", "}", "}", "METHOD_END"], "methodName": ["summarizePartitionStatistics"], "fileName": "com.facebook.presto.hive.statistics.MetastoreHiveStatisticsProvider"}, {"methodBody": ["METHOD_START", "{", "AsyncQueue . checkArgument (  ( maxSize    >  =     0  )  ,     \" maxSize   must   be   at   least    0  \"  )  ;", "ListenableFuture < List < T >  >    borrowedListFuture ;", "synchronized ( this )     {", "List < T >    list    =    getBatch ( maxSize )  ;", "if    (  !  ( list . isEmpty (  )  )  )     {", "borrowedListFuture    =    AsyncQueue . immediateFuture ( list )  ;", "( borrowerCount )  +  +  ;", "} else", "if    (  ( finishing )     &  &     (  ( borrowerCount )     =  =     0  )  )     {", "borrowedListFuture    =    immediateFuture ( com . google . common . collect . ImmutableList . of (  )  )  ;", "} else    {", "borrowedListFuture    =    Futures . transform ( notEmptySignal ,     (    ignored )     -  >     {", "synchronized ( this )     {", "List < T >    batch    =    getBatch ( maxSize )  ;", "if    (  !  ( batch . isEmpty (  )  )  )     {", "( borrowerCount )  +  +  ;", "}", "return   batch ;", "}", "}  ,    executor )  ;", "}", "}", "return   Futures . transform ( borrowedListFuture ,     (    elements )     -  >     {", "try    {", "BorrowResult < T ,    O >    borrowResult    =    function . apply ( elements )  ;", "if    ( elements . isEmpty (  )  )     {", "checkArgument ( borrowResult . getElementsToInsert (  )  . isEmpty (  )  ,     \" Function   must   not   insert   anything   when   no   element   is   borrowed \"  )  ;", "return   borrowResult . getResult (  )  ;", "}", "for    ( T   element    :    borrowResult . getElementsToInsert (  )  )     {", "offer ( element )  ;", "}", "return   borrowResult . getResult (  )  ;", "}    finally    {", "if    (  !  ( elements . isEmpty (  )  )  )     {", "synchronized ( this )     {", "( borrowerCount )  -  -  ;", "signalIfFinishing (  )  ;", "}", "}", "}", "}  )  ;", "}", "METHOD_END"], "methodName": ["borrowBatchAsync"], "fileName": "com.facebook.presto.hive.util.AsyncQueue"}, {"methodBody": ["METHOD_START", "{", "executor . execute (  (  )     -  >    future . set ( null )  )  ;", "}", "METHOD_END"], "methodName": ["completeAsync"], "fileName": "com.facebook.presto.hive.util.AsyncQueue"}, {"methodBody": ["METHOD_START", "{", "if    ( finishing )     {", "return ;", "}", "finishing    =    true ;", "signalIfFinishing (  )  ;", "}", "METHOD_END"], "methodName": ["finish"], "fileName": "com.facebook.presto.hive.util.AsyncQueue"}, {"methodBody": ["METHOD_START", "{", "int   oldSize    =    elements . size (  )  ;", "int   reduceBy    =    Math . min ( maxSize ,    oldSize )  ;", "if    ( reduceBy    =  =     0  )     {", "return   ImmutableList . of (  )  ;", "}", "List < T >    result    =    new   ArrayList <  >  ( reduceBy )  ;", "for    ( int   i    =     0  ;    i    <    reduceBy ;    i +  +  )     {", "result . add ( elements . remove (  )  )  ;", "}", "if    (  ( oldSize    >  =     ( targetQueueSize )  )     &  &     (  ( oldSize    -    reduceBy )     <     ( targetQueueSize )  )  )     {", ". completeAsync ( executor ,    notFullSignal )  ;", "notFullSignal    =    SettableFuture . create (  )  ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["getBatch"], "fileName": "com.facebook.presto.hive.util.AsyncQueue"}, {"methodBody": ["METHOD_START", "{", "return   borrowBatchAsync ( maxSize ,     (    elements )     -  >    new   AsyncQueue . BorrowResult ( ImmutableList . of (  )  ,    elements )  )  ;", "}", "METHOD_END"], "methodName": ["getBatchAsync"], "fileName": "com.facebook.presto.hive.util.AsyncQueue"}, {"methodBody": ["METHOD_START", "{", "return    (  ( finishing )     &  &     (  ( borrowerCount )     =  =     0  )  )     &  &     (  ( elements . size (  )  )     =  =     0  )  ;", "}", "METHOD_END"], "methodName": ["isFinished"], "fileName": "com.facebook.presto.hive.util.AsyncQueue"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( element )  ;", "if    (  ( finishing )     &  &     (  ( borrowerCount )     =  =     0  )  )     {", "return    . immediateFuture ( null )  ;", "}", "elements . add ( element )  ;", "int   newSize    =    elements . size (  )  ;", "if    ( newSize    =  =     1  )     {", ". completeAsync ( executor ,    notEmptySignal )  ;", "notEmptySignal    =    SettableFuture . create (  )  ;", "}", "if    ( newSize    >  =     ( targetQueueSize )  )     {", "return   notFullSignal ;", "}", "return    . immediateFuture ( null )  ;", "}", "METHOD_END"], "methodName": ["offer"], "fileName": "com.facebook.presto.hive.util.AsyncQueue"}, {"methodBody": ["METHOD_START", "{", "if    (  ( finishing )     &  &     (  ( borrowerCount )     =  =     0  )  )     {", "if    (  ( elements . size (  )  )     =  =     0  )     {", ". completeAsync ( executor ,    notEmptySignal )  ;", "notEmptySignal    =    SettableFuture . create (  )  ;", "} else", "if    (  ( elements . size (  )  )     >  =     ( targetQueueSize )  )     {", ". completeAsync ( executor ,    notFullSignal )  ;", "notFullSignal    =    SettableFuture . create (  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["signalIfFinishing"], "fileName": "com.facebook.presto.hive.util.AsyncQueue"}, {"methodBody": ["METHOD_START", "{", "for    ( Map . Entry < String ,    String >    entry    :    from )     {", "set ( entry . getKey (  )  ,    entry . getValue (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["copy"], "fileName": "com.facebook.presto.hive.util.ConfigurationUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( conf   instanceof   JobConf )     {", "return    (  ( JobConf )     ( conf )  )  ;", "}", "return   new   JobConf ( conf )  ;", "}", "METHOD_END"], "methodName": ["toJobConf"], "fileName": "com.facebook.presto.hive.util.ConfigurationUtils"}, {"methodBody": ["METHOD_START", "{", "BigInteger   value    =    new   BigInteger ( writable . getInternalStorage (  )  )  ;", "value    =    s . rescale ( value ,    writable . getScale (  )  ,    columnScale )  ;", "return   s . encodeUnscaledValue ( value )  ;", "}", "METHOD_END"], "methodName": ["getLongDecimalValue"], "fileName": "com.facebook.presto.hive.util.DecimalUtils"}, {"methodBody": ["METHOD_START", "{", "long   value    =     0  ;", "if    (  (  ( bytes [  0  ]  )     &     1  2  8  )     !  =     0  )     {", "for    ( int   i    =     0  ;    i    <     (  8     -     ( bytes . length )  )  ;     +  + i )     {", "value    |  =     2  5  5 L    <  <     (  8     *     (  7     -    i )  )  ;", "}", "}", "for    ( int   i    =     0  ;    i    <     ( bytes . length )  ;    i +  +  )     {", "value    |  =     (  (  ( long )     ( bytes [  (  (  ( bytes . length )     -    i )     -     1  )  ]  )  )     &     2  5  5 L )     <  <     (  8     *    i )  ;", "}", "return   value ;", "}", "METHOD_END"], "methodName": ["getShortDecimalValue"], "fileName": "com.facebook.presto.hive.util.DecimalUtils"}, {"methodBody": ["METHOD_START", "{", "byte [  ]    bytes    =    writable . getInternalStorage (  )  ;", "long   value    =     . getShortDecimalValue ( bytes )  ;", "value    =    Decimals . rescale ( value ,    writable . getScale (  )  ,    columnScale )  ;", "return   value ;", "}", "METHOD_END"], "methodName": ["getShortDecimalValue"], "fileName": "com.facebook.presto.hive.util.DecimalUtils"}, {"methodBody": ["METHOD_START", "{", "try    ( TimeStat . BlockTimer   ignored    =    namenodeStats . getRemoteIteratorNext (  )  . time (  )  )     {", "return   iterator . next (  )  ;", "}", "}", "METHOD_END"], "methodName": ["getLocatedFileStatus"], "fileName": "com.facebook.presto.hive.util.HiveFileIterator"}, {"methodBody": ["METHOD_START", "{", "try    ( TimeStat . BlockTimer   ignored    =    namenodeStats . getListLocatedStatus (  )  . time (  )  )     {", "return   new    . FileStatusIterator ( path ,    fileSystem ,    directoryLister ,    namenodeStats )  ;", "}", "}", "METHOD_END"], "methodName": ["getLocatedFileStatusRemoteIterator"], "fileName": "com.facebook.presto.hive.util.HiveFileIterator"}, {"methodBody": ["METHOD_START", "{", "return   blocks . stream (  )  . map ( InternalHiveSplit . InternalHiveBlock :  : getAddresses )  . allMatch ( InternalHiveSplitFactory :  : hasRealAddress )  ;", "}", "METHOD_END"], "methodName": ["allBlocksHaveRealAddress"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "checkArgument (  ( length    >  =     0  )  )  ;", "checkArgument (  (  !  ( blocks . isEmpty (  )  )  )  )  ;", "checkArgument (  ( start    =  =     ( blocks . get (  0  )  . getStart (  )  )  )  )  ;", "checkArgument (  (  ( start    +    length )     =  =     ( blocks . get (  (  ( blocks . size (  )  )     -     1  )  )  . getEnd (  )  )  )  )  ;", "for    ( int   i    =     1  ;    i    <     ( blocks . size (  )  )  ;    i +  +  )     {", "checkArgument (  (  ( blocks . get (  ( i    -     1  )  )  . getEnd (  )  )     =  =     ( blocks . get ( i )  . getStart (  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkBlocks"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "return   createInternalHiveSplit ( status ,    OptionalInt . empty (  )  )  ;", "}", "METHOD_END"], "methodName": ["createInternalHiveSplit"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "return   createInternalHiveSplit ( status ,    OptionalInt . of ( bucketNumber )  )  ;", "}", "METHOD_END"], "methodName": ["createInternalHiveSplit"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "return   createInternalHiveSplit ( status . getPath (  )  ,    status . getBlockLocations (  )  ,     0  ,    status . getLen (  )  ,    status . getLen (  )  ,    bucketNumber ,    HiveUtil . isSplittable ( inputFormat ,    fileSystem ,    status . getPath (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["createInternalHiveSplit"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "String   pathString    =    path . toString (  )  ;", "if    (  !  (  . pathMatchesPredicate ( pathDomain ,    pathString )  )  )     {", "return   Optional . empty (  )  ;", "}", "boolean   forceLocalScheduling    =    this . forceLocalScheduling ;", "if    (  ( fileSize    =  =     0  )     &  &     (  ( blockLocations . length )     =  =     0  )  )     {", "blockLocations    =    new   BlockLocation [  ]  {    new   BlockLocation (  )     }  ;", "forceLocalScheduling    =    false ;", "}", "ImmutableList . Builder < InternalHiveSplit . InternalHiveBlock >    blockBuilder    =    ImmutableList . builder (  )  ;", "for    ( BlockLocation   blockLocation    :    blockLocations )     {", "long   blockStart    =    Math . max ( start ,    blockLocation . getOffset (  )  )  ;", "long   blockEnd    =    Math . min (  ( start    +    length )  ,     (  ( blockLocation . getOffset (  )  )     +     ( blockLocation . getLength (  )  )  )  )  ;", "if    ( blockStart    >    blockEnd )     {", "continue ;", "}", "if    (  ( blockStart    =  =    blockEnd )     &  &     (  !  (  ( blockStart    =  =    start )     &  &     ( blockEnd    =  =     ( start    +    length )  )  )  )  )     {", "continue ;", "}", "blockBuilder . add ( new   InternalHiveSplit . InternalHiveBlock ( blockStart ,    blockEnd ,     . getHostAddresses ( blockLocation )  )  )  ;", "}", "List < InternalHiveSplit . InternalHiveBlock >    blocks    =    blockBuilder . build (  )  ;", ". checkBlocks ( blocks ,    start ,    length )  ;", "if    (  ! splittable )     {", "blocks    =    ImmutableList . of ( new   InternalHiveSplit . InternalHiveBlock ( start ,     ( start    +    length )  ,    blocks . get (  0  )  . getAddresses (  )  )  )  ;", "}", "return   Optional . of ( new   InternalHiveSplit ( partitionName ,    pathString ,    start ,     ( start    +    length )  ,    fileSize ,    schema ,    partitionKeys ,    blocks ,    bucketNumber ,    splittable ,     ( forceLocalScheduling    &  &     (  . allBlocksHaveRealAddress ( blocks )  )  )  ,    columnCoercions ,    bucketConversion )  )  ;", "}", "METHOD_END"], "methodName": ["createInternalHiveSplit"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "FileStatus   file    =    fileSystem . getFileStatus ( split . getPath (  )  )  ;", "return   create ( split . getPath (  )  ,    fileSystem . getFileBlockLocations ( file ,    split . getStart (  )  ,    split . getLength (  )  )  ,    split . getStart (  )  ,    split . getLength (  )  ,    file . getLen (  )  ,    OptionalInt . empty (  )  ,    false )  ;", "}", "METHOD_END"], "methodName": ["createInternalHiveSplit"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "String [  ]    hosts ;", "try    {", "hosts    =    blockLocation . getHosts (  )  ;", "}    catch    ( IOException   e )     {", "throw   new   UncheckedIOException ( e )  ;", "}", "return   Arrays . stream ( hosts )  . map ( HostAdds :  : fromString )  . collect ( toImmutableList (  )  )  ;", "}", "METHOD_END"], "methodName": ["getHostAddresses"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "return   partitionName ;", "}", "METHOD_END"], "methodName": ["getPartitionName"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( effectivePredicate . getDomains (  )  . isPresent (  )  )  )     {", "return   Optional . empty (  )  ;", "}", "return   effectivePredicate . getDomains (  )  . get (  )  . entrySet (  )  . stream (  )  . filter (  (    entry )     -  >    isPathColumnHandle ( entry . getKey (  )  )  )  . findFirst (  )  . map ( Map . Entry :  : getValue )  ;", "}", "METHOD_END"], "methodName": ["getPathDomain"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "return   addresses . stream (  )  . anyMatch (  (    address )     -  >     !  ( address . getHostText (  )  . equals (  \" localhost \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["hasRealAddress"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( pathDomain . isPresent (  )  )  )     {", "return   true ;", "}", "return   pathDomain . get (  )  . includesNullableValue ( Slices . utf 8 Slice ( path )  )  ;", "}", "METHOD_END"], "methodName": ["pathMatchesPredicate"], "fileName": "com.facebook.presto.hive.util.InternalHiveSplitFactory"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   task . process (  )  ;", "}    catch    ( Throwable   t )     {", ". log . warn ( t ,     \" ResumableTask   completed   exceptionally \"  )  ;", "return   ResumableTask . TaskStatus . finished (  )  ;", "}", "}", "METHOD_END"], "methodName": ["safeProcessTask"], "fileName": "com.facebook.presto.hive.util.ResumableTasks"}, {"methodBody": ["METHOD_START", "{", "executor . execute ( new   Runnable (  )     {", "@ Override", "public   void   run (  )     {", "ResumableTask . TaskStatus   status    =     . safeProcessTask ( task )  ;", "if    (  !  ( status . isFinished (  )  )  )     {", "status . getContinuationFuture (  )  . addListener ( this ,    executor )  ;", "}", "}", "}  )  ;", "}", "METHOD_END"], "methodName": ["submit"], "fileName": "com.facebook.presto.hive.util.ResumableTasks"}, {"methodBody": ["METHOD_START", "{", "if    ( object   instanceof   LazyDate )     {", "return    (  ( LazyDate )     ( object )  )  . getWritableObject (  )  . getDays (  )  ;", "}", "if    ( object   instanceof   DateWritable )     {", "return    (  ( DateWritable )     ( object )  )  . getDays (  )  ;", "}", "long   millisLocal    =    inspector . getPrimitJavaObject ( object )  . getTime (  )  ;", "long   millisUtc    =    DateTimeZone . getDefault (  )  . getMillisKeepLocal ( UTC ,    millisLocal )  ;", "return   TimeUnit . MILLISECONDS . toDays ( millisUtc )  ;", "}", "METHOD_END"], "methodName": ["formatDateAsLong"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "Timestamp   timestamp    =    SerDeUtils . getTimestamp ( object ,    inspector )  ;", "return   timestamp . getTime (  )  ;", "}", "METHOD_END"], "methodName": ["formatTimestampAsLong"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "return   Objects . requireNonNull ( SerDeUtils . serializeObject ( type ,    null ,    object ,    objectInspector )  ,     \" serialized   result   is   null \"  )  ;", "}", "METHOD_END"], "methodName": ["getBlockObject"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( object   instanceof   TimestampWritable )     {", "return    (  ( TimestampWritable )     ( object )  )  . getTimestamp (  )  ;", "}", "return   inspector . getPrimitiveJavaObject ( object )  ;", "}", "METHOD_END"], "methodName": ["getTimestamp"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "List <  ?  >    list    =    inspector . getList ( object )  ;", "if    ( list    =  =    null )     {", "Objects . requireNonNull ( builder ,     \" parent   builder   is   null \"  )  . appendNull (  )  ;", "return   null ;", "}", "List < Type >    typeParameters    =    type . getTypeParameters (  )  ;", "checkArgument (  (  ( typeParameters . size (  )  )     =  =     1  )  ,     \" list   must   have   exactly    1    type   parameter \"  )  ;", "Type   elementType    =    typeParameters . get (  0  )  ;", "ObjectInspector   elementInspector    =    inspector . getListElementObjectInspector (  )  ;", "BlockBuilder   currentBuilder ;", "if    ( builder    !  =    null )     {", "currentBuilder    =    builder . beginBlockEntry (  )  ;", "} else    {", "currentBuilder    =    elementType . createBlockBuilder ( null ,    list . size (  )  )  ;", "}", "for    ( Object   element    :    list )     {", ". serializeObject ( elementType ,    currentBuilder ,    element ,    elementInspector )  ;", "}", "if    ( builder    !  =    null )     {", "builder . closeEntry (  )  ;", "return   null ;", "} else    {", "Block   resultBlock    =    currentBuilder . build (  )  ;", "return   resultBlock ;", "}", "}", "METHOD_END"], "methodName": ["serializeList"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "Map <  ?  ,     ?  >    map    =    inspector . getMap ( object )  ;", "if    ( map    =  =    null )     {", "Objects . requireNonNull ( builder ,     \" parent   builder   is   null \"  )  . appendNull (  )  ;", "return   null ;", "}", "List < Type >    typeParameters    =    type . getTypeParameters (  )  ;", "checkArgument (  (  ( typeParameters . size (  )  )     =  =     2  )  ,     \" map   must   have   exactly    2    type   parameter \"  )  ;", "Type   keyType    =    typeParameters . get (  0  )  ;", "Type   valueType    =    typeParameters . get (  1  )  ;", "ObjectInspector   keyInspector    =    inspector . getMapKeyObjectInspector (  )  ;", "ObjectInspector   valueInspector    =    inspector . getMapValueObjectInspector (  )  ;", "BlockBuilder   currentBuilder ;", "boolean   builderSynthesized    =    false ;", "if    ( builder    =  =    null )     {", "builderSynthesized    =    true ;", "builder    =    type . createBlockBuilder ( null ,     1  )  ;", "}", "currentBuilder    =    builder . beginBlockEntry (  )  ;", "for    ( Map . Entry <  ?  ,     ?  >    entry    :    map . entrySet (  )  )     {", "if    (  (  ! filterNullMapKeys )     |  |     (  ( entry . getKey (  )  )     !  =    null )  )     {", ". serializeObject ( keyType ,    currentBuilder ,    entry . getKey (  )  ,    keyInspector )  ;", ". serializeObject ( valueType ,    currentBuilder ,    entry . getValue (  )  ,    valueInspector )  ;", "}", "}", "builder . closeEntry (  )  ;", "if    ( builderSynthesized )     {", "return    (  ( Block )     ( type . getObject ( builder ,     0  )  )  )  ;", "} else    {", "return   null ;", "}", "}", "METHOD_END"], "methodName": ["serializeMap"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "return   SerDeUtils . serializeObject ( type ,    builder ,    object ,    inspector ,    true )  ;", "}", "METHOD_END"], "methodName": ["serializeObject"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "switch    ( inspector . getCategory (  )  )     {", "case   PRIMITIVE    :", ". serializePrimitive ( type ,    builder ,    object ,     (  ( PrimitiveObjectInspector )     ( inspector )  )  )  ;", "return   null ;", "case   LIST    :", "return    . serializeList ( type ,    builder ,    object ,     (  ( ListObjectInspector )     ( inspector )  )  )  ;", "case   MAP    :", "return    . serializeMap ( type ,    builder ,    object ,     (  ( MapObjectInspector )     ( inspector )  )  ,    filterNullMapKeys )  ;", "case   STRUCT    :", "return    . serializeStruct ( type ,    builder ,    object ,     (  ( StructObjectInspector )     ( inspector )  )  )  ;", "}", "throw   new   RuntimeException (  (  \" Unknown   object   inspector   category :     \"     +     ( inspector . getCategory (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["serializeObject"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( builder ,     \" parent   builder   is   null \"  )  ;", "if    ( object    =  =    null )     {", "builder . appendNull (  )  ;", "return ;", "}", "switch    ( inspector . getPrimitiveCategory (  )  )     {", "case   BOOLEAN    :", "BOOLEAN . writeBoolean ( builder ,     (  ( BooleanObjectInspector )     ( inspector )  )  . get ( object )  )  ;", "return ;", "case   BYTE    :", "TINYINT . writeLong ( builder ,     (  ( ByteObjectInspector )     ( inspector )  )  . get ( object )  )  ;", "return ;", "case   SHORT    :", "SMALLINT . writeLong ( builder ,     (  ( ShortObjectInspector )     ( inspector )  )  . get ( object )  )  ;", "return ;", "case   INT    :", "INTEGER . writeLong ( builder ,     (  ( IntObjectInspector )     ( inspector )  )  . get ( object )  )  ;", "return ;", "case   LONG    :", "BIGINT . writeLong ( builder ,     (  ( LongObjectInspector )     ( inspector )  )  . get ( object )  )  ;", "return ;", "case   FLOAT    :", "REAL . writeLong ( builder ,    Float . floatToRawIntBits (  (  ( FloatObjectInspector )     ( inspector )  )  . get ( object )  )  )  ;", "return ;", "case   DOUBLE    :", "DOUBLE . writeDouble ( builder ,     (  ( DoubleObjectInspector )     ( inspector )  )  . get ( object )  )  ;", "return ;", "case   STRING    :", "type . writeSlice ( builder ,    Slices . utf 8 Slice (  (  ( StringObjectInspector )     ( inspector )  )  . getPrimitiveJavaObject ( object )  )  )  ;", "return ;", "case   VARCHAR    :", "type . writeSlice ( builder ,    Slices . utf 8 Slice (  (  ( HiveVarcharObjectInspector )     ( inspector )  )  . getPrimitiveJavaObject ( object )  . getValue (  )  )  )  ;", "return ;", "case   CHAR    :", "CharType   charType    =     (  ( CharType )     ( type )  )  ;", "HiveChar   hiveChar    =     (  ( HiveCharObjectInspector )     ( inspector )  )  . getPrimitiveJavaObject ( object )  ;", "type . writeSlice ( builder ,    Chars . truncateToLengthAndTrimSpaces ( Slices . utf 8 Slice ( hiveChar . getValue (  )  )  ,    charType . getLength (  )  )  )  ;", "return ;", "case   DATE    :", "DATE . writeLong ( builder ,     . formatDateAsLong ( object ,     (  ( DateObjectInspector )     ( inspector )  )  )  )  ;", "return ;", "case   TIMESTAMP    :", "TIMESTAMP . writeLong ( builder ,     . formatTimestampAsLong ( object ,     (  ( TimestampObjectInspector )     ( inspector )  )  )  )  ;", "return ;", "case   BINARY    :", "VarbinaryType . VARBINARY . writeSlice ( builder ,    Slices . wrappedBuffer (  (  ( BinaryObjectInspector )     ( inspector )  )  . getPrimitiveJavaObject ( object )  )  )  ;", "return ;", "case   DECIMAL    :", "DecimalType   decimalType    =     (  ( DecimalType )     ( type )  )  ;", "HiveDecimalWritable   hiveDecimal    =     (  ( HiveDecimalObjectInspector )     ( inspector )  )  . getPrimitiveWritableObject ( object )  ;", "if    ( decimalType . isShort (  )  )     {", "decimalType . writeLong ( builder ,    DecimalUtils . getShortDecimalValue ( hiveDecimal ,    decimalType . getScale (  )  )  )  ;", "} else    {", "decimalType . writeSlice ( builder ,    DecimalUtils . getLongDecimalValue ( hiveDecimal ,    decimalType . getScale (  )  )  )  ;", "}", "return ;", "}", "throw   new   RuntimeException (  (  \" Unknown   primitive   type :     \"     +     ( inspector . getPrimitiveCategory (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["serializePrimitive"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "if    ( object    =  =    null )     {", "Objects . requireNonNull ( builder ,     \" parent   builder   is   null \"  )  . appendNull (  )  ;", "return   null ;", "}", "List < Type >    typeParameters    =    type . getTypeParameters (  )  ;", "List <  ?    extends   StructField >    allStructFieldRefs    =    inspector . getAllStructFieldRefs (  )  ;", "checkArgument (  (  ( typeParameters . size (  )  )     =  =     ( allStructFieldRefs . size (  )  )  )  )  ;", "BlockBuilder   currentBuilder ;", "boolean   builderSynthesized    =    false ;", "if    ( builder    =  =    null )     {", "builderSynthesized    =    true ;", "builder    =    type . createBlockBuilder ( null ,     1  )  ;", "}", "currentBuilder    =    builder . beginBlockEntry (  )  ;", "for    ( int   i    =     0  ;    i    <     ( typeParameters . size (  )  )  ;    i +  +  )     {", "StructField   field    =    allStructFieldRefs . get ( i )  ;", ". serializeObject ( typeParameters . get ( i )  ,    currentBuilder ,    inspector . getStructFieldData ( object ,    field )  ,    field . getFieldObjectInspector (  )  )  ;", "}", "builder . closeEntry (  )  ;", "if    ( builderSynthesized )     {", "return    (  ( Block )     ( type . getObject ( builder ,     0  )  )  )  ;", "} else    {", "return   null ;", "}", "}", "METHOD_END"], "methodName": ["serializeStruct"], "fileName": "com.facebook.presto.hive.util.SerDeUtils"}, {"methodBody": ["METHOD_START", "{", "executor    =    Executors . newFixedThreadPool (  8  ,    Threads . daemonThreadsNamed (  \" test - async - queue -  % s \"  )  )  ;", "}", "METHOD_END"], "methodName": ["setUpClass"], "fileName": "com.facebook.presto.hive.util.TestAsyncQueue"}, {"methodBody": ["METHOD_START", "{", "executor . shutdownNow (  )  ;", "}", "METHOD_END"], "methodName": ["tearDownClass"], "fileName": "com.facebook.presto.hive.util.TestAsyncQueue"}, {"methodBody": ["METHOD_START", "{", "AsyncQueue < Integer >    queue    =    new   AsyncQueue <  >  (  4  ,    executor )  ;", "queue . offer (  1  )  ;", "queue . offer (  2  )  ;", "queue . offer (  3  )  ;", "queue . offer (  4  )  ;", "queue . offer (  5  )  ;", "Runnable   runnable    =     (  )     -  >     {", "for    ( int   i    =     0  ;    i    <     7  0  0  ;    i +  +  )     {", "MoreFutures . getFutureValue ( queue . borrowBatchAsync (  3  ,     (    elements )     -  >    new   BorrowResult <  >  ( elements ,    null )  )  )  ;", "}", "}  ;", "Future <  ?  >    future 1     =    executor . submit ( runnable )  ;", "Future <  ?  >    future 2     =    executor . submit ( runnable )  ;", "Future <  ?  >    future 3     =    executor . submit ( runnable )  ;", "future 1  . get (  )  ;", "future 2  . get (  )  ;", "future 3  . get (  )  ;", "queue . finish (  )  ;", "assertFalse ( queue . isFinished (  )  )  ;", "AtomicBoolean   done    =    new   AtomicBoolean (  )  ;", "executor . submit (  (  )     -  >     {", "while    (  !  ( done . get (  )  )  )     {", "assertFalse (  (  ( queue . isFinished (  )  )     |  |     ( done . get (  )  )  )  )  ;", "}", "}  )  ;", "future 1     =    executor . submit ( runnable )  ;", "future 2     =    executor . submit ( runnable )  ;", "future 3     =    executor . submit ( runnable )  ;", "future 1  . get (  )  ;", "future 2  . get (  )  ;", "future 3  . get (  )  ;", "done . set ( true )  ;", "assertFalse ( queue . isFinished (  )  )  ;", "ArrayList < Integer >    list    =    new   ArrayList ( queue . getBatchAsync (  1  0  0  )  . get (  )  )  ;", "list . sort ( Integer :  : compare )  ;", "assertEquals ( list ,    ImmutableList . of (  1  ,     2  ,     3  ,     4  ,     5  )  )  ;", "assertTrue ( queue . isFinished (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBorrow"], "fileName": "com.facebook.presto.hive.util.TestAsyncQueue"}, {"methodBody": ["METHOD_START", "{", "AsyncQueue < Integer >    queue    =    new   AsyncQueue <  >  (  4  ,    executor )  ;", "queue . offer (  1  )  ;", "queue . offer (  2  )  ;", "queue . offer (  3  )  ;", "queue . offer (  4  )  ;", "queue . offer (  5  )  ;", "ListenableFuture <  ?  >    future 1     =    queue . offer (  6  )  ;", "assertFalse ( future 1  . isDone (  )  )  ;", "Runnable   runnable    =     (  )     -  >     {", "MoreFutures . getFutureValue ( queue . borrowBatchAsync (  1  ,     (    elements )     -  >     {", "throw   new   RuntimeException (  \" test   fail \"  )  ;", "}  )  )  ;", "}  ;", "try    {", "executor . submit ( runnable )  . get (  )  ;", "fail (  \" expected   failure \"  )  ;", "}    catch    ( ExecutionException   e )     {", "Assertions . assertContains ( e . getMessage (  )  ,     \" test   fail \"  )  ;", "}", "ListenableFuture <  ?  >    future 2     =    queue . offer (  7  )  ;", "assertFalse ( future 1  . isDone (  )  )  ;", "assertFalse ( future 2  . isDone (  )  )  ;", "queue . finish (  )  ;", "future 1  . get (  )  ;", "future 2  . get (  )  ;", "assertTrue ( queue . offer (  8  )  . isDone (  )  )  ;", "try    {", "executor . submit ( runnable )  . get (  )  ;", "fail (  \" expected   failure \"  )  ;", "}    catch    ( ExecutionException   e )     {", "Assertions . assertContains ( e . getMessage (  )  ,     \" test   fail \"  )  ;", "}", "assertTrue ( queue . offer (  9  )  . isDone (  )  )  ;", "assertFalse ( queue . isFinished (  )  )  ;", "ArrayList < Integer >    list    =    new   ArrayList ( queue . getBatchAsync (  1  0  0  )  . get (  )  )  ;", "assertEquals ( list ,    ImmutableList . of (  3  ,     4  ,     5  ,     6  ,     7  )  )  ;", "assertTrue ( queue . isFinished (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBorrowThrows"], "fileName": "com.facebook.presto.hive.util.TestAsyncQueue"}, {"methodBody": ["METHOD_START", "{", "AsyncQueue < String >    queue    =    new   AsyncQueue <  >  (  4  ,    executor )  ;", "assertTrue ( queue . offer (  \"  1  \"  )  . isDone (  )  )  ;", "assertTrue ( queue . offer (  \"  2  \"  )  . isDone (  )  )  ;", "assertTrue ( queue . offer (  \"  3  \"  )  . isDone (  )  )  ;", "assertEquals ( queue . getBatchAsync (  2  )  . get (  )  ,    ImmutableList . of (  \"  1  \"  ,     \"  2  \"  )  )  ;", "assertEquals ( queue . getBatchAsync (  2  )  . get (  )  ,    ImmutableList . of (  \"  3  \"  )  )  ;", "ListenableFuture <  ?  >    batchFuture    =    queue . getBatchAsync (  2  )  ;", "assertFalse ( batchFuture . isDone (  )  )  ;", "assertTrue ( queue . offer (  \"  4  \"  )  . isDone (  )  )  ;", "assertEquals ( batchFuture . get (  )  ,    ImmutableList . of (  \"  4  \"  )  )  ;", "batchFuture    =    queue . getBatchAsync (  2  )  ;", "assertFalse ( batchFuture . isDone (  )  )  ;", "queue . finish (  )  ;", "batchFuture . get (  )  ;", "assertTrue ( queue . isFinished (  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmptyQueue"], "fileName": "com.facebook.presto.hive.util.TestAsyncQueue"}, {"methodBody": ["METHOD_START", "{", "AsyncQueue < String >    queue    =    new   AsyncQueue <  >  (  4  ,    executor )  ;", "assertTrue ( queue . offer (  \"  1  \"  )  . isDone (  )  )  ;", "assertTrue ( queue . offer (  \"  2  \"  )  . isDone (  )  )  ;", "assertTrue ( queue . offer (  \"  3  \"  )  . isDone (  )  )  ;", "assertFalse ( queue . offer (  \"  4  \"  )  . isDone (  )  )  ;", "assertFalse ( queue . offer (  \"  5  \"  )  . isDone (  )  )  ;", "ListenableFuture <  ?  >    offerFuture    =    queue . offer (  \"  6  \"  )  ;", "assertFalse ( offerFuture . isDone (  )  )  ;", "assertEquals ( queue . getBatchAsync (  2  )  . get (  )  ,    ImmutableList . of (  \"  1  \"  ,     \"  2  \"  )  )  ;", "assertFalse ( offerFuture . isDone (  )  )  ;", "assertEquals ( queue . getBatchAsync (  1  )  . get (  )  ,    ImmutableList . of (  \"  3  \"  )  )  ;", "offerFuture . get (  )  ;", "offerFuture    =    queue . offer (  \"  7  \"  )  ;", "assertFalse ( offerFuture . isDone (  )  )  ;", "queue . finish (  )  ;", "offerFuture . get (  )  ;", "assertFalse ( queue . isFinished (  )  )  ;", "assertEquals ( queue . getBatchAsync (  4  )  . get (  )  ,    ImmutableList . of (  \"  4  \"  ,     \"  5  \"  ,     \"  6  \"  ,     \"  7  \"  )  )  ;", "assertTrue ( queue . isFinished (  )  )  ;", "}", "METHOD_END"], "methodName": ["testFullQueue"], "fileName": "com.facebook.presto.hive.util.TestAsyncQueue"}, {"methodBody": ["METHOD_START", "{", "AsyncQueue < String >    queue    =    new   AsyncQueue <  >  (  4  ,    executor )  ;", "queue . offer (  \"  1  \"  )  ;", "queue . offer (  \"  2  \"  )  ;", "queue . offer (  \"  3  \"  )  ;", "assertEquals ( queue . getBatchAsync (  1  0  0  )  . get (  )  ,    ImmutableList . of (  \"  1  \"  ,     \"  2  \"  ,     \"  3  \"  )  )  ;", "queue . finish (  )  ;", "assertTrue ( queue . isFinished (  )  )  ;", "}", "METHOD_END"], "methodName": ["testGetPartial"], "fileName": "com.facebook.presto.hive.util.TestAsyncQueue"}, {"methodBody": ["METHOD_START", "{", "AsyncQueue < String >    queue    =    new   AsyncQueue <  >  (  4  ,    executor )  ;", "assertTrue ( queue . offer (  \"  1  \"  )  . isDone (  )  )  ;", "assertTrue ( queue . offer (  \"  2  \"  )  . isDone (  )  )  ;", "assertTrue ( queue . offer (  \"  3  \"  )  . isDone (  )  )  ;", "assertFalse ( queue . offer (  \"  4  \"  )  . isDone (  )  )  ;", "queue . finish (  )  ;", "assertTrue ( queue . offer (  \"  5  \"  )  . isDone (  )  )  ;", "assertTrue ( queue . offer (  \"  6  \"  )  . isDone (  )  )  ;", "assertTrue ( queue . offer (  \"  7  \"  )  . isDone (  )  )  ;", "assertFalse ( queue . isFinished (  )  )  ;", "assertEquals ( queue . getBatchAsync (  1  0  0  )  . get (  )  ,    ImmutableList . of (  \"  1  \"  ,     \"  2  \"  ,     \"  3  \"  ,     \"  4  \"  )  )  ;", "assertTrue ( queue . isFinished (  )  )  ;", "}", "METHOD_END"], "methodName": ["testOfferAfterFinish"], "fileName": "com.facebook.presto.hive.util.TestAsyncQueue"}, {"methodBody": ["METHOD_START", "{", "LazyMap   lazyMap    =     (  ( LazyMap )     ( createLazyObject ( getLazySimpleMapObjectInspector ( TestLazyMap . LAZY _ STRING _ OBJECT _ INSPECTOR ,    getLazyStringObjectInspector ( false ,     (  ( byte )     (  0  )  )  )  ,     (  ( byte )     (  2  )  )  ,     (  ( byte )     (  3  )  )  ,    new   Text (  \"  \\  \\ N \"  )  ,    false ,     (  ( byte )     (  0  )  )  )  )  )  )  ;", "lazyMap . init ( TestLazyMap . newByteArrayRef ( encodedMap )  ,     0  ,    encodedMap . length (  )  )  ;", "Map < Object ,    Object >    map    =    lazyMap . getMap (  )  ;", "assertEquals ( map ,    expectedMap )  ;", "}", "METHOD_END"], "methodName": ["assertMapDecode"], "fileName": "com.facebook.presto.hive.util.TestLazyMap"}, {"methodBody": ["METHOD_START", "{", "LazyString   lazyString    =    new   LazyString ( TestLazyMap . LAZY _ STRING _ OBJECT _ INSPECTOR )  ;", "lazyString . init ( TestLazyMap . newByteArrayRef ( string )  ,     0  ,    string . length (  )  )  ;", "return   lazyString ;", "}", "METHOD_END"], "methodName": ["lazyString"], "fileName": "com.facebook.presto.hive.util.TestLazyMap"}, {"methodBody": ["METHOD_START", "{", "ByteArrayRef   bytes    =    new   ByteArrayRef (  )  ;", "bytes . setData ( encoded . getBytes ( StandardCharsets . US _ ASCII )  )  ;", "return   bytes ;", "}", "METHOD_END"], "methodName": ["newByteArrayRef"], "fileName": "com.facebook.presto.hive.util.TestLazyMap"}, {"methodBody": ["METHOD_START", "{", "TestLazyMap . assertMapDecode (  \"  \\  \\ N \\ u 0  0  0  3 ignored \"  ,    ImmutableMap . of (  )  )  ;", "TestLazyMap . assertMapDecode (  \"  \\  \\ N \\ u 0  0  0  3 ignored \\ u 0  0  0  2 alice \\ u 0  0  0  3 apple \"  ,    ImmutableMap . of ( TestLazyMap . lazyString (  \" alice \"  )  ,    TestLazyMap . lazyString (  \" apple \"  )  )  )  ;", "TestLazyMap . assertMapDecode (  \" alice \\ u 0  0  0  3 apple \\ u 0  0  0  2  \\  \\ N \\ u 0  0  0  3 ignored \"  ,    ImmutableMap . of ( TestLazyMap . lazyString (  \" alice \"  )  ,    TestLazyMap . lazyString (  \" apple \"  )  )  )  ;", "TestLazyMap . assertMapDecode (  \" alice \\ u 0  0  0  3 apple \\ u 0  0  0  2  \\  \\ N \\ u 0  0  0  3 ignored \\ u 0  0  0  2 bob \\ u 0  0  0  3 banana \"  ,    ImmutableMap . of ( TestLazyMap . lazyString (  \" alice \"  )  ,    TestLazyMap . lazyString (  \" apple \"  )  ,    TestLazyMap . lazyString (  \" bob \"  )  ,    TestLazyMap . lazyString (  \" banana \"  )  )  )  ;", "TestLazyMap . assertMapDecode (  \"  \\  \\ N \\ u 0  0  0  3 ignored \\ u 0  0  0  2  \\ u 0  0  0  3  \"  ,    ImmutableMap . of ( TestLazyMap . lazyString (  \"  \"  )  ,    TestLazyMap . lazyString (  \"  \"  )  )  )  ;", "HashMap < Object ,    Object >    expectedMap    =    new   HashMap <  >  (  )  ;", "expectedMap . put (  \" null \"  ,    null )  ;", "TestLazyMap . assertMapDecode (  \"  \\  \\ N \\ u 0  0  0  3 ignored \\ u 0  0  0  2 null \\ u 0  0  0  3  \\  \\ N \"  ,    expectedMap )  ;", "}", "METHOD_END"], "methodName": ["test"], "fileName": "com.facebook.presto.hive.util.TestLazyMap"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( TestSerDeUtils . blockToSlice ( actual )  ,    TestSerDeUtils . blockToSlice ( expected )  )  ;", "}", "METHOD_END"], "methodName": ["assertBlockEquals"], "fileName": "com.facebook.presto.hive.util.TestSerDeUtils"}, {"methodBody": ["METHOD_START", "{", "SliceOutput   sliceOutput    =    new   DynamicSliceOutput (  1  0  0  0  )  ;", "BlockSerd . writeBlock ( sliceOutput ,    block )  ;", "return   sliceOutput . slice (  )  ;", "}", "METHOD_END"], "methodName": ["blockToSlice"], "fileName": "com.facebook.presto.hive.util.TestSerDeUtils"}, {"methodBody": ["METHOD_START", "{", "return   ObjectInspectorFactory . getReflectionObjectInspector ( type ,    JAVA )  ;", "}", "METHOD_END"], "methodName": ["getInspector"], "fileName": "com.facebook.presto.hive.util.TestSerDeUtils"}, {"methodBody": ["METHOD_START", "{", "BlockBuilder   builder    =    VarbinaryType . VARBINARY . createBlockBuilder ( null ,     1  )  ;", ". serializeObject ( type ,    builder ,    object ,    inspector )  ;", "return   builder . build (  )  ;", "}", "METHOD_END"], "methodName": ["getPrimitiveBlock"], "fileName": "com.facebook.presto.hive.util.TestSerDeUtils"}, {"methodBody": ["METHOD_START", "{", "if    (  ( inspector . getCategory (  )  )     =  =     ( Category . PRIMITIVE )  )     {", "return    . getPrimitiveBlock ( type ,    object ,    inspector )  ;", "}", "return   SerDeUtils . getBlockObject ( type ,    object ,    inspector )  ;", "}", "METHOD_END"], "methodName": ["toBinaryBlock"], "fileName": "com.facebook.presto.hive.util.TestSerDeUtils"}]