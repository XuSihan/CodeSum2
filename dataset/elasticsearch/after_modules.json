[{"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ ascii _ folding . type \"  ,     \" asciifolding \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ ascii _ folding \"  )  ;", "String   source    =     \" Anspr \u00a8\u00b9 che \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" Anspruche \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testDefault"], "fileName": "org.elasticsearch.analysis.common.ASCIIFoldingTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ ascii _ folding . type \"  ,     \" asciifolding \"  )  . put (  \" index . analysis . filter . my _ ascii _ folding . preserve _ original \"  ,    true )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ ascii _ folding \"  )  ;", "String   source    =     \" Anspr \u00a8\u00b9 che \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" Anspruche \"  ,     \" Anspr \u00a8\u00b9 che \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "tokenFilter    =     (  (  )     (  (  ( MultiTermAwareComponent )     ( tokenFilter )  )  . getMultiTermComponent (  )  )  )  ;", "tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "expected    =    new   String [  ]  {     \" Anspruche \"     }  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testPreserveOriginal"], "fileName": "org.elasticsearch.analysis.common.ASCIIFoldingTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . put (  \" index . analysis . filter . my _ word _ delimiter . generate _ word _ parts \"  ,     \" false \"  )  . put (  \" index . analysis . filter . my _ word _ delimiter . generate _ number _ parts \"  ,     \" false \"  )  . put (  \" index . analysis . filter . my _ word _ delimiter . catenate _ all \"  ,     \" true \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot    5  0  0  -  4  2    wi - fi   wi - fi -  4  0  0  0    j 2 se   O ' Neil ' s \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" PowerShot \"  ,     \"  5  0  0  4  2  \"  ,     \" wifi \"  ,     \" wifi 4  0  0  0  \"  ,     \" j 2 se \"  ,     \" ONeil \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testCatenateAll"], "fileName": "org.elasticsearch.analysis.common.BaseWordDelimiterTokenFilterFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . put (  \" index . analysis . filter . my _ word _ delimiter . generate _ number _ parts \"  ,     \" false \"  )  . put (  \" index . analysis . filter . my _ word _ delimiter . catenate _ numbers \"  ,     \" true \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot    5  0  0  -  4  2    wi - fi   wi - fi -  4  0  0  0    j 2 se   O ' Neil ' s \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" Power \"  ,     \" Shot \"  ,     \"  5  0  0  4  2  \"  ,     \" wi \"  ,     \" fi \"  ,     \" wi \"  ,     \" fi \"  ,     \"  4  0  0  0  \"  ,     \" j \"  ,     \"  2  \"  ,     \" se \"  ,     \" O \"  ,     \" Neil \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testCatenateNumbers"], "fileName": "org.elasticsearch.analysis.common.BaseWordDelimiterTokenFilterFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . put (  \" index . analysis . filter . my _ word _ delimiter . catenate _ words \"  ,     \" true \"  )  . put (  \" index . analysis . filter . my _ word _ delimiter . generate _ word _ parts \"  ,     \" false \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot    5  0  0  -  4  2    wi - fi   wi - fi -  4  0  0  0    j 2 se   O ' Neil ' s \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" PowerShot \"  ,     \"  5  0  0  \"  ,     \"  4  2  \"  ,     \" wifi \"  ,     \" wifi \"  ,     \"  4  0  0  0  \"  ,     \" j \"  ,     \"  2  \"  ,     \" se \"  ,     \" ONeil \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testCatenateWords"], "fileName": "org.elasticsearch.analysis.common.BaseWordDelimiterTokenFilterFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot    5  0  0  -  4  2    wi - fi   wi - fi -  4  0  0  0    j 2 se   O ' Neil ' s \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" Power \"  ,     \" Shot \"  ,     \"  5  0  0  \"  ,     \"  4  2  \"  ,     \" wi \"  ,     \" fi \"  ,     \" wi \"  ,     \" fi \"  ,     \"  4  0  0  0  \"  ,     \" j \"  ,     \"  2  \"  ,     \" se \"  ,     \" O \"  ,     \" Neil \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testDefault"], "fileName": "org.elasticsearch.analysis.common.BaseWordDelimiterTokenFilterFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . put (  \" index . analysis . filter . my _ word _ delimiter . preserve _ original \"  ,     \" true \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot    5  0  0  -  4  2    wi - fi   wi - fi -  4  0  0  0    j 2 se   O ' Neil ' s \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" PowerShot \"  ,     \" Power \"  ,     \" Shot \"  ,     \"  5  0  0  -  4  2  \"  ,     \"  5  0  0  \"  ,     \"  4  2  \"  ,     \" wi - fi \"  ,     \" wi \"  ,     \" fi \"  ,     \" wi - fi -  4  0  0  0  \"  ,     \" wi \"  ,     \" fi \"  ,     \"  4  0  0  0  \"  ,     \" j 2 se \"  ,     \" j \"  ,     \"  2  \"  ,     \" se \"  ,     \" O ' Neil ' s \"  ,     \" O \"  ,     \" Neil \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testPreserveOriginal"], "fileName": "org.elasticsearch.analysis.common.BaseWordDelimiterTokenFilterFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . put (  \" index . analysis . filter . my _ word _ delimiter . split _ on _ case _ change \"  ,     \" false \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" PowerShot \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testSplitOnCaseChange"], "fileName": "org.elasticsearch.analysis.common.BaseWordDelimiterTokenFilterFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . put (  \" index . analysis . filter . my _ word _ delimiter . stem _ english _ possessive \"  ,     \" false \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot    5  0  0  -  4  2    wi - fi   wi - fi -  4  0  0  0    j 2 se   O ' Neil ' s \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" Power \"  ,     \" Shot \"  ,     \"  5  0  0  \"  ,     \"  4  2  \"  ,     \" wi \"  ,     \" fi \"  ,     \" wi \"  ,     \" fi \"  ,     \"  4  0  0  0  \"  ,     \" j \"  ,     \"  2  \"  ,     \" se \"  ,     \" O \"  ,     \" Neil \"  ,     \" s \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testStemEnglishPossessive"], "fileName": "org.elasticsearch.analysis.common.BaseWordDelimiterTokenFilterFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "analysis    =    AnalysisTestsHelper . createTestAnalysisFromClassPath ( createTempDir (  )  ,    CJKFilterFactoryTests . RESOURCE ,    new   CommonAnalysisPlugin (  )  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.analysis.common.CJKFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" cjk _ bigram \"  )  ;", "String   source    =     \"  \u00b6\u00e0  \u00a4\u00af  \u00a4\u00ce  \u00d1\u00a7  \u00c9\u00fa  \u00a4\u00ac  \u00d4\u2021  \u00f2Y  \u00a4\u00cb  \u00c2\u00e4  \u00a4\u00c1  \u00a4\u00bf  \u00a1\u00a3  \"  ;", "String [  ]    expected    =    new   String [  ]  {     \"  \u00b6\u00e0  \u00a4\u00af  \"  ,     \"  \u00a4\u00af  \u00a4\u00ce  \"  ,     \"  \u00a4\u00ce  \u00d1\u00a7  \"  ,     \"  \u00d1\u00a7  \u00c9\u00fa  \"  ,     \"  \u00c9\u00fa  \u00a4\u00ac  \"  ,     \"  \u00a4\u00ac  \u00d4\u2021  \"  ,     \"  \u00d4\u2021  \u00f2Y  \"  ,     \"  \u00f2Y  \u00a4\u00cb  \"  ,     \"  \u00a4\u00cb  \u00c2\u00e4  \"  ,     \"  \u00c2\u00e4  \u00a4\u00c1  \"  ,     \"  \u00a4\u00c1  \u00a4\u00bf  \"     }  ;", "Tokenizer   tokenizer    =    new   StandardTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testDefault"], "fileName": "org.elasticsearch.analysis.common.CJKFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "TokenFilterFactory   allFlagsFactory    =    analysis . tokenFilter . get (  \" cjk _ all _ flags \"  )  ;", "TokenFilterFactory   hanOnlyFactory    =    analysis . tokenFilter . get (  \" cjk _ han _ only \"  )  ;", "String   source    =     \"  \u00b6\u00e0  \u00a4\u00af  \u00a4\u00ce  \u00d1\u00a7  \u00c9\u00fa  \u00a4\u00ac  \u00d4\u2021  \u00f2Y  \u00a4\u00cb  \u00c2\u00e4  \u00a4\u00c1  \u00a4\u00bf  \u00a1\u00a3  \"  ;", "Tokenizer   tokenizer    =    new   StandardTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "try    ( TokenStream   tokenStream    =    allFlagsFactory . create ( tokenizer )  )     {", "assertTrue ( tokenStream . hasAttribute ( DisableGraphAttribute . class )  )  ;", "}", "tokenizer    =    new   StandardTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "try    ( TokenStream   tokenStream    =    hanOnlyFactory . create ( tokenizer )  )     {", "assertFalse ( tokenStream . hasAttribute ( DisableGraphAttribute . class )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDisableGraph"], "fileName": "org.elasticsearch.analysis.common.CJKFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" cjk _ han _ only \"  )  ;", "String   source    =     \"  \u00b6\u00e0  \u00a4\u00af  \u00a4\u00ce  \u00d1\u00a7  \u00c9\u00fa  \u00a4\u00ac  \u00d4\u2021  \u00f2Y  \u00a4\u00cb  \u00c2\u00e4  \u00a4\u00c1  \u00a4\u00bf  \u00a1\u00a3  \"  ;", "String [  ]    expected    =    new   String [  ]  {     \"  \u00b6\u00e0  \"  ,     \"  \u00a4\u00af  \"  ,     \"  \u00a4\u00ce  \"  ,     \"  \u00d1\u00a7  \u00c9\u00fa  \"  ,     \"  \u00a4\u00ac  \"  ,     \"  \u00d4\u2021  \u00f2Y  \"  ,     \"  \u00a4\u00cb  \"  ,     \"  \u00c2\u00e4  \"  ,     \"  \u00a4\u00c1  \"  ,     \"  \u00a4\u00bf  \"     }  ;", "Tokenizer   tokenizer    =    new   StandardTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testHanOnly"], "fileName": "org.elasticsearch.analysis.common.CJKFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" cjk _ han _ unigram _ only \"  )  ;", "String   source    =     \"  \u00b6\u00e0  \u00a4\u00af  \u00a4\u00ce  \u00d1\u00a7  \u00c9\u00fa  \u00a4\u00ac  \u00d4\u2021  \u00f2Y  \u00a4\u00cb  \u00c2\u00e4  \u00a4\u00c1  \u00a4\u00bf  \u00a1\u00a3  \"  ;", "String [  ]    expected    =    new   String [  ]  {     \"  \u00b6\u00e0  \"  ,     \"  \u00a4\u00af  \"  ,     \"  \u00a4\u00ce  \"  ,     \"  \u00d1\u00a7  \"  ,     \"  \u00d1\u00a7  \u00c9\u00fa  \"  ,     \"  \u00c9\u00fa  \"  ,     \"  \u00a4\u00ac  \"  ,     \"  \u00d4\u2021  \"  ,     \"  \u00d4\u2021  \u00f2Y  \"  ,     \"  \u00f2Y  \"  ,     \"  \u00a4\u00cb  \"  ,     \"  \u00c2\u00e4  \"  ,     \"  \u00a4\u00c1  \"  ,     \"  \u00a4\u00bf  \"     }  ;", "Tokenizer   tokenizer    =    new   StandardTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testHanUnigramOnly"], "fileName": "org.elasticsearch.analysis.common.CJKFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" cjk _ no _ flags \"  )  ;", "String   source    =     \"  \u00b6\u00e0  \u00a4\u00af  \u00a4\u00ce  \u00d1\u00a7  \u00c9\u00fa  \u00a4\u00ac  \u00d4\u2021  \u00f2Y  \u00a4\u00cb  \u00c2\u00e4  \u00a4\u00c1  \u00a4\u00bf  \u00a1\u00a3  \"  ;", "String [  ]    expected    =    new   String [  ]  {     \"  \u00b6\u00e0  \u00a4\u00af  \"  ,     \"  \u00a4\u00af  \u00a4\u00ce  \"  ,     \"  \u00a4\u00ce  \u00d1\u00a7  \"  ,     \"  \u00d1\u00a7  \u00c9\u00fa  \"  ,     \"  \u00c9\u00fa  \u00a4\u00ac  \"  ,     \"  \u00a4\u00ac  \u00d4\u2021  \"  ,     \"  \u00d4\u2021  \u00f2Y  \"  ,     \"  \u00f2Y  \u00a4\u00cb  \"  ,     \"  \u00a4\u00cb  \u00c2\u00e4  \"  ,     \"  \u00c2\u00e4  \u00a4\u00c1  \"  ,     \"  \u00a4\u00c1  \u00a4\u00bf  \"     }  ;", "Tokenizer   tokenizer    =    new   StandardTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testNoFlags"], "fileName": "org.elasticsearch.analysis.common.CJKFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.analysis.common.CommonAnalysisClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "List < String >    unmarked    =    map . entrySet (  )  . stream (  )  . filter (  (    e )     -  >     ( e . getValue (  )  )     =  =     ( MovedToAnalysisCommon . class )  )  . map ( Map . Entry :  : getKey )  . sorted (  )  . collect ( Collectors . toList (  )  )  ;", "assertEquals (  (  ( name    +     \"    marked   in   Case   as   moved   to   analysis - common    \"  )     +     \" but   not   mapped   here \"  )  ,    Collections . emptyList (  )  ,    unmarked )  ;", "}", "METHOD_END"], "methodName": ["markedTestCase"], "fileName": "org.elasticsearch.analysis.common.CommonAnalysisFactoryTests"}, {"methodBody": ["METHOD_START", "{", "markedTestCase (  \" char   filter \"  ,    getCharFilters (  )  )  ;", "}", "METHOD_END"], "methodName": ["testAllCharFiltersMarked"], "fileName": "org.elasticsearch.analysis.common.CommonAnalysisFactoryTests"}, {"methodBody": ["METHOD_START", "{", "markedTestCase (  \" token   filter \"  ,    getTokenFilters (  )  )  ;", "}", "METHOD_END"], "methodName": ["testAllTokenFiltersMarked"], "fileName": "org.elasticsearch.analysis.common.CommonAnalysisFactoryTests"}, {"methodBody": ["METHOD_START", "{", "markedTestCase (  \" char   filter \"  ,    getTokenizers (  )  )  ;", "}", "METHOD_END"], "methodName": ["testAllTokenizersMarked"], "fileName": "org.elasticsearch.analysis.common.CommonAnalysisFactoryTests"}, {"methodBody": ["METHOD_START", "{", "InputStream   words    =    getClass (  )  . getResourceAsStream (  \" common _ words . txt \"  )  ;", "Path   home    =    createTempDir (  )  ;", "Path   config    =    home . resolve (  \" config \"  )  ;", "Files . createDirectory ( config )  ;", "Files . copy ( words ,    config . resolve (  \" common _ words . txt \"  )  )  ;", "return   home ;", "}", "METHOD_END"], "methodName": ["createHome"], "fileName": "org.elasticsearch.analysis.common.CommonGramsTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "}", "METHOD_END"], "methodName": ["createTestAnalysisFromSettings"], "fileName": "org.elasticsearch.analysis.common.CommonGramsTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "String   json    =     \"  / org / elasticsearch / analysis / common / commongrams . json \"  ;", "Settings   settings    =    Settings . builder (  )  . loadFromStream ( json ,    getClass (  )  . getResourceAsStream ( json )  ,    false )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createHome (  )  )  . build (  )  ;", "{", "IndexAnalyzers   indexAnalyzers    =     . createTestAnalysisFromSettings ( settings )  . indexAnalyzers ;", "Analyzer   analyzer    =    indexAnalyzers . get (  \" commongramsAnalyzer \"  )  . analyzer (  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   or   not \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" quick \"  ,     \" quick _ brown \"  ,     \" brown \"  ,     \" brown _ is \"  ,     \" is \"  ,     \" a \"  ,     \" a _ fox \"  ,     \" fox \"  ,     \" fox _ or \"  ,     \" or \"  ,     \" not \"     }  ;", "assertTokenStreamContents ( analyzer . tokenStream (  \" test \"  ,    source )  ,    expected )  ;", "}", "{", "IndexAnalyzers   indexAnalyzers    =     . createTestAnalysisFromSettings ( settings )  . indexAnalyzers ;", "Analyzer   analyzer    =    indexAnalyzers . get (  \" commongramsAnalyzer _ file \"  )  . analyzer (  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   or   not \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" quick \"  ,     \" quick _ brown \"  ,     \" brown \"  ,     \" brown _ is \"  ,     \" is \"  ,     \" a \"  ,     \" a _ fox \"  ,     \" fox \"  ,     \" fox _ or \"  ,     \" or \"  ,     \" not \"     }  ;", "assertTokenStreamContents ( analyzer . tokenStream (  \" test \"  ,    source )  ,    expected )  ;", "}", "}", "METHOD_END"], "methodName": ["testCommonGramsAnalysis"], "fileName": "org.elasticsearch.analysis.common.CommonGramsTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _ default . type \"  ,     \" common _ grams \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "try    {", "AnalysisTestsHelper . createTestAnalysisFromSettings ( settings )  ;", "Assert . fail (  \"  [ common _ words ]    or    [ common _ words _ path ]    is   set \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "}    catch    ( IOException   e )     {", "fail (  \" expected   IAE \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDefault"], "fileName": "org.elasticsearch.analysis.common.CommonGramsTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "String   json    =     \"  / org / elasticsearch / analysis / common / commongrams _ query _ mode . json \"  ;", "Settings   settings    =    Settings . builder (  )  . loadFromStream ( json ,    getClass (  )  . getResourceAsStream ( json )  ,    false )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createHome (  )  )  . build (  )  ;", "{", "IndexAnalyzers   indexAnalyzers    =     . createTestAnalysisFromSettings ( settings )  . indexAnalyzers ;", "Analyzer   analyzer    =    indexAnalyzers . get (  \" commongramsAnalyzer \"  )  . analyzer (  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   or   not \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" quick _ brown \"  ,     \" brown _ is \"  ,     \" is \"  ,     \" a _ fox \"  ,     \" fox _ or \"  ,     \" or \"  ,     \" not \"     }  ;", "assertTokenStreamContents ( analyzer . tokenStream (  \" test \"  ,    source )  ,    expected )  ;", "}", "{", "IndexAnalyzers   indexAnalyzers    =     . createTestAnalysisFromSettings ( settings )  . indexAnalyzers ;", "Analyzer   analyzer    =    indexAnalyzers . get (  \" commongramsAnalyzer _ file \"  )  . analyzer (  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   or   not \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" quick _ brown \"  ,     \" brown _ is \"  ,     \" is \"  ,     \" a _ fox \"  ,     \" fox _ or \"  ,     \" or \"  ,     \" not \"     }  ;", "assertTokenStreamContents ( analyzer . tokenStream (  \" test \"  ,    source )  ,    expected )  ;", "}", "}", "METHOD_END"], "methodName": ["testQueryModeCommonGramsAnalysis"], "fileName": "org.elasticsearch.analysis.common.CommonGramsTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _  1  . type \"  ,     \" common _ grams \"  )  . put (  \" index . analysis . filter . common _ grams _  1  . query _ mode \"  ,    true )  . putList (  \" index . analysis . filter . common _ grams _  1  . common _ words \"  ,     \" the \"  ,     \" Or \"  ,     \" Not \"  ,     \" a \"  ,     \" is \"  ,     \" an \"  ,     \" they \"  ,     \" are \"  )  . put (  \" index . analysis . filter . common _ grams _  1  . ignore _ case \"  ,    true )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" common _ grams _  1  \"  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   or   noT \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the _ quick \"  ,     \" quick \"  ,     \" brown _ is \"  ,     \" is _ a \"  ,     \" a _ fox \"  ,     \" fox _ or \"  ,     \" or _ noT \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _  2  . type \"  ,     \" common _ grams \"  )  . put (  \" index . analysis . filter . common _ grams _  2  . query _ mode \"  ,    true )  . putList (  \" index . analysis . filter . common _ grams _  2  . common _ words \"  ,     \" the \"  ,     \" Or \"  ,     \" noT \"  ,     \" a \"  ,     \" is \"  ,     \" an \"  ,     \" they \"  ,     \" are \"  )  . put (  \" index . analysis . filter . common _ grams _  2  . ignore _ case \"  ,    false )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" common _ grams _  2  \"  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   or   why   noT \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the _ quick \"  ,     \" quick \"  ,     \" brown _ is \"  ,     \" is _ a \"  ,     \" a _ fox \"  ,     \" fox \"  ,     \" or \"  ,     \" why _ noT \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _  3  . type \"  ,     \" common _ grams \"  )  . put (  \" index . analysis . filter . common _ grams _  3  . query _ mode \"  ,    true )  . putList (  \" index . analysis . filter . common _ grams _  3  . common _ words \"  ,     \" the \"  ,     \" Or \"  ,     \" noT \"  ,     \" a \"  ,     \" is \"  ,     \" an \"  ,     \" they \"  ,     \" are \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" common _ grams _  3  \"  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   or   why   noT \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the _ quick \"  ,     \" quick \"  ,     \" brown _ is \"  ,     \" is _ a \"  ,     \" a _ fox \"  ,     \" fox \"  ,     \" or \"  ,     \" why _ noT \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _  4  . type \"  ,     \" common _ grams \"  )  . put (  \" index . analysis . filter . common _ grams _  4  . query _ mode \"  ,    true )  . putList (  \" index . analysis . filter . common _ grams _  4  . common _ words \"  ,     \" the \"  ,     \" or \"  ,     \" not \"  ,     \" a \"  ,     \" is \"  ,     \" an \"  ,     \" they \"  ,     \" are \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" common _ grams _  4  \"  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   Or   noT \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the _ quick \"  ,     \" quick \"  ,     \" brown _ is \"  ,     \" is _ a \"  ,     \" a _ fox \"  ,     \" fox \"  ,     \" Or \"  ,     \" noT \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "}", "METHOD_END"], "methodName": ["testQueryModeSettings"], "fileName": "org.elasticsearch.analysis.common.CommonGramsTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _  1  . type \"  ,     \" common _ grams \"  )  . put (  \" index . analysis . filter . common _ grams _  1  . ignore _ case \"  ,    true )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . putList (  \" index . analysis . filter . common _ grams _  1  . common _ words \"  ,     \" the \"  ,     \" Or \"  ,     \" Not \"  ,     \" a \"  ,     \" is \"  ,     \" an \"  ,     \" they \"  ,     \" are \"  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" common _ grams _  1  \"  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   or   noT \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" the _ quick \"  ,     \" quick \"  ,     \" brown \"  ,     \" brown _ is \"  ,     \" is \"  ,     \" is _ a \"  ,     \" a \"  ,     \" a _ fox \"  ,     \" fox \"  ,     \" fox _ or \"  ,     \" or \"  ,     \" or _ noT \"  ,     \" noT \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _  2  . type \"  ,     \" common _ grams \"  )  . put (  \" index . analysis . filter . common _ grams _  2  . ignore _ case \"  ,    false )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . putList (  \" index . analysis . filter . common _ grams _  2  . common _ words \"  ,     \" the \"  ,     \" Or \"  ,     \" noT \"  ,     \" a \"  ,     \" is \"  ,     \" an \"  ,     \" they \"  ,     \" are \"  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" common _ grams _  2  \"  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   or   why   noT \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" the _ quick \"  ,     \" quick \"  ,     \" brown \"  ,     \" brown _ is \"  ,     \" is \"  ,     \" is _ a \"  ,     \" a \"  ,     \"  \"     +     \" a _ fox \"  ,     \" fox \"  ,     \" or \"  ,     \" why \"  ,     \" why _ noT \"  ,     \" noT \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _  3  . type \"  ,     \" common _ grams \"  )  . putList (  \" index . analysis . filter . common _ grams _  3  . common _ words \"  ,     \" the \"  ,     \" or \"  ,     \" not \"  ,     \" a \"  ,     \" is \"  ,     \" an \"  ,     \" they \"  ,     \" are \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" common _ grams _  3  \"  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   Or   noT \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" the _ quick \"  ,     \" quick \"  ,     \" brown \"  ,     \" brown _ is \"  ,     \" is \"  ,     \" is _ a \"  ,     \" a \"  ,     \" a _ fox \"  ,     \" fox \"  ,     \" Or \"  ,     \" noT \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "}", "METHOD_END"], "methodName": ["testSettings"], "fileName": "org.elasticsearch.analysis.common.CommonGramsTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _ default . type \"  ,     \" common _ grams \"  )  . putList (  \" index . analysis . filter . common _ grams _ default . common _ words \"  ,     \" chromosome \"  ,     \" protein \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "{", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" common _ grams _ default \"  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   Or   noT \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" quick \"  ,     \" brown \"  ,     \" is \"  ,     \" a \"  ,     \" fox \"  ,     \" Or \"  ,     \" noT \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "}", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . common _ grams _ default . type \"  ,     \" common _ grams \"  )  . put (  \" index . analysis . filter . common _ grams _ default . query _ mode \"  ,    false )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . putList (  \" index . analysis . filter . common _ grams _ default . common _ words \"  ,     \" chromosome \"  ,     \" protein \"  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "{", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" common _ grams _ default \"  )  ;", "String   source    =     \" the   quick   brown   is   a   fox   Or   noT \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" quick \"  ,     \" brown \"  ,     \" is \"  ,     \" a \"  ,     \" fox \"  ,     \" Or \"  ,     \" noT \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testWithoutCommonWordsMatch"], "fileName": "org.elasticsearch.analysis.common.CommonGramsTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "IndexSettings   idxSettings    =    IndexSettingsModule . newIndexSettings (  \" test \"  ,    settings )  ;", "AnalysisModule   Module    =    createAnalysisModule ( settings )  ;", "IndexAnalyzers   indexAnalyzers    =    Module . getAnalysisRegistry (  )  . build ( idxSettings )  ;", "Analyzer   analyzer    =    indexAnalyzers . get ( analyzerName )  . analyzer (  )  ;", "TokenStream   stream    =    analyzer . tokenStream (  \"  \"  ,    text )  ;", "stream . reset (  )  ;", "CharTermAttribute   termAtt    =    stream . addAttribute ( CharTermAttribute . class )  ;", "List < String >    terms    =    new   ArrayList <  >  (  )  ;", "while    ( stream . incrementToken (  )  )     {", "String   tokText    =    termAtt . toString (  )  ;", "terms . add ( tokText )  ;", "}", "return   terms ;", "}", "METHOD_END"], "methodName": ["analyze"], "fileName": "org.elasticsearch.analysis.common.CompoundAnalysisTests"}, {"methodBody": ["METHOD_START", "{", "CommonAnalysisPlugin   commonAnalysisPlugin    =    new   CommonAnalysisPlugin (  )  ;", "return   new   indices . analysis . AnalysisModule ( TestEnvironment . newEnvironment ( settings )  ,    Arrays . asList ( commonAnalysisPlugin ,    new   AnalysisPlugin (  )     {", "@ Override", "public   Map < String ,    AnalysisProvider < TokenFilterFactory >  >    getTokenFilters (  )     {", "return   Collections . singletonMap (  \" myfilter \"  ,    MyFilterTokenFilterFactory :  : new )  ;", "}", "}  )  )  ;", "}", "METHOD_END"], "methodName": ["createAnalysisModule"], "fileName": "org.elasticsearch.analysis.common.CompoundAnalysisTests"}, {"methodBody": ["METHOD_START", "{", "String   json    =     \"  / org / elasticsearch / analysis / common / test 1  . json \"  ;", "return   Settings . builder (  )  . loadFromStream ( json ,    getClass (  )  . getResourceAsStream ( json )  ,    false )  . put ( SETTING _ VERSION _ CREATED ,    CURRENT )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getJsonSettings"], "fileName": "org.elasticsearch.analysis.common.CompoundAnalysisTests"}, {"methodBody": ["METHOD_START", "{", "String   yaml    =     \"  / org / elasticsearch / analysis / common / test 1  . yml \"  ;", "return   Settings . builder (  )  . loadFromStream ( yaml ,    getClass (  )  . getResourceAsStream ( yaml )  ,    false )  . put ( SETTING _ VERSION _ CREATED ,    CURRENT )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["getYamlSettings"], "fileName": "org.elasticsearch.analysis.common.CompoundAnalysisTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    getJsonSettings (  )  ;", "IndexSettings   idxSettings    =    IndexSettingsModule . newIndexSettings (  \" test \"  ,    settings )  ;", "AnalysisModule   Module    =    createAnalysisModule ( settings )  ;", "TokenFilterFactory   filterFactory    =    Module . getAnalysisRegistry (  )  . buildTokenFilterFactories ( idxSettings )  . get (  \" dict _ dec \"  )  ;", "MatcherAssert . assertThat ( filterFactory ,    instanceOf ( DictionaryCompoundWordTokenFilterFactory . class )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaultsCompoundAnalysis"], "fileName": "org.elasticsearch.analysis.common.CompoundAnalysisTests"}, {"methodBody": ["METHOD_START", "{", "Settings [  ]    settingsArr    =    new   Settings [  ]  {    getJsonSettings (  )  ,    getYamlSettings (  )     }  ;", "for    ( Settings   settings    :    settingsArr )     {", "List < String >    terms    =    analyze ( settings ,     \" decingAnalyzer \"  ,     \" donaudampfschiff   spargelcremesuppe \"  )  ;", "MatcherAssert . assertThat ( terms . size (  )  ,    equalTo (  8  )  )  ;", "MatcherAssert . assertThat ( terms ,    hasItems (  \" donau \"  ,     \" dampf \"  ,     \" schiff \"  ,     \" donaudampfschiff \"  ,     \" spargel \"  ,     \" creme \"  ,     \" suppe \"  ,     \" spargelcremesuppe \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDictionaryDecompounder"], "fileName": "org.elasticsearch.analysis.common.CompoundAnalysisTests"}, {"methodBody": ["METHOD_START", "{", "switch    ( side )     {", "case    \" front \"     :", "return    . SIDE _ FRONT ;", "case    \" back \"     :", "return    . SIDE _ BACK ;", "default    :", "throw   new   IllegalArgumentException (  (  \" invalid   side :     \"     +    side )  )  ;", "}", "}", "METHOD_END"], "methodName": ["parseSide"], "fileName": "org.elasticsearch.analysis.common.EdgeNGramTokenFilterFactory"}, {"methodBody": ["METHOD_START", "{", "Index   index    =    new   Index (  \" test \"  ,     \"  _ na _  \"  )  ;", "String   name    =     \" ngr \"  ;", "Settings   indexSettings    =    newAnalysisSettingsBuilder (  )  . build (  )  ;", "IndexSettings   indexProperties    =    IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ;", "Settings   settings    =    newAnalysisSettingsBuilder (  )  . build (  )  ;", "TokenStream   in    =    new   CannedTokenStream (  0  ,     1  2  ,    new   Token [  ]  {     . token (  \" wtf \"  ,     1  ,     5  ,     0  ,     3  )  ,     . token (  \" what \"  ,     0  ,     1  ,     0  ,     3  )  ,     . token (  \" wow \"  ,     0  ,     3  ,     0  ,     3  )  ,     . token (  \" the \"  ,     1  ,     1  ,     0  ,     3  )  ,     . token (  \" fudge \"  ,     1  ,     3  ,     0  ,     3  )  ,     . token (  \" that ' s \"  ,     1  ,     1  ,     0  ,     3  )  ,     . token (  \" funny \"  ,     1  ,     1  ,     0  ,     3  )  ,     . token (  \" happened \"  ,     1  ,     1  ,     4  ,     1  2  )     }  )  ;", "TokenStream   tokens    =    new   FlattenGraphTokenFilterFactory ( indexProperties ,    null ,    name ,    settings )  . create ( in )  ;", "assertTokenStreamContents ( tokens ,    new   String [  ]  {     \" wtf \"  ,     \" what \"  ,     \" wow \"  ,     \" the \"  ,     \" that ' s \"  ,     \" fudge \"  ,     \" funny \"  ,     \" happened \"     }  ,    new   int [  ]  {     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     4     }  ,    new   int [  ]  {     3  ,     3  ,     3  ,     3  ,     3  ,     3  ,     3  ,     1  2     }  ,    new   int [  ]  {     1  ,     0  ,     0  ,     1  ,     0  ,     1  ,     0  ,     1     }  ,    new   int [  ]  {     3  ,     1  ,     1  ,     1  ,     1  ,     1  ,     1  ,     1     }  ,     1  2  )  ;", "}", "METHOD_END"], "methodName": ["testBasic"], "fileName": "org.elasticsearch.analysis.common.FlattenGraphTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "final   Token   t    =    new   Token ( term ,    startOffset ,    endOffset )  ;", "t . setPositionIncrement ( posInc )  ;", "t . setPositionLength ( posLength )  ;", "return   t ;", "}", "METHOD_END"], "methodName": ["token"], "fileName": "org.elasticsearch.analysis.common.FlattenGraphTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" test \"  ,     \" body \"  ,     (  \" type = text , analyzer = custom _ analyzer ,  \"     +     \" search _ analyzer = custom _ analyzer , term _ vector = with _ positions _ offsets \"  )  )  . setSettings ( Settings . builder (  )  . put ( indexSettings (  )  )  . put (  \" analysis . filter . wordDelimiter . type \"  ,     \" word _ delimiter \"  )  . put (  \" analysis . filter . wordDelimiter . type . split _ on _ numerics \"  ,    false )  . put (  \" analysis . filter . wordDelimiter . generate _ word _ parts \"  ,    true )  . put (  \" analysis . filter . wordDelimiter . generate _ number _ parts \"  ,    true )  . put (  \" analysis . filter . wordDelimiter . catenate _ words \"  ,    true )  . put (  \" analysis . filter . wordDelimiter . catenate _ numbers \"  ,    true )  . put (  \" analysis . filter . wordDelimiter . catenate _ all \"  ,    false )  . put (  \" analysis . analyzer . custom _ analyzer . tokenizer \"  ,     \" whitespace \"  )  . putList (  \" analysis . analyzer . custom _ analyzer . filter \"  ,     \" lowercase \"  ,     \" wordDelimiter \"  )  )  )  ;", "ensureGreen (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . setSource (  \" body \"  ,     (  \" Test :    http :  /  / www . facebook . com   http :  /  / org    \"     +     (  (  (  \" http :  /  / xing . com   http :  /  / cnn . com   http :  /  / quora . com   http :  /  / twitter . com   this   is    \"     +     \" a   test   for   highlighting   feature   Test :    http :  /  / www . facebook . com    \"  )     +     \" http :  /  / org   http :  /  / xing . com   http :  /  / cnn . com   http :  /  / quora . com    \"  )     +     \" http :  /  / twitter . com   this   is   a   test   for   highlighting   feature \"  )  )  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   search    =    client (  )  . prepareSearch (  )  . setQuery ( matchPhraseQuery (  \" body \"  ,     \" Test :    http :  /  / www . facebook . com    \"  )  )  . highlighter ( new   HighlightBuilder (  )  . field (  \" body \"  )  . highlighterType (  \" fvh \"  )  )  . get (  )  ;", "assertHighlight ( search ,     0  ,     \" body \"  ,     0  ,    startsWith (  \"  < em > Test :    http :  /  / www . facebook . com <  / em >  \"  )  )  ;", "search    =    client (  )  . prepareSearch (  )  . setQuery ( matchPhraseQuery (  \" body \"  ,     (  \" Test :    http :  /  / www . facebook . com    \"     +     (  (  (  (  \" http :  /  / org   http :  /  / xing . com   http :  /  / cnn . com    \"     +     \" http :  /  / quora . com   http :  /  / twitter . com   this   is   a   test   for   highlighting    \"  )     +     \" feature   Test :    http :  /  / www . facebook . com   http :  /  / org    \"  )     +     \" http :  /  / xing . com   http :  /  / cnn . com   http :  /  / quora . com   http :  /  / twitter . com   this    \"  )     +     \" is   a   test   for   highlighting   feature \"  )  )  )  )  . highlighter ( new   HighlightBuilder (  )  . field (  \" body \"  )  . highlighterType (  \" fvh \"  )  )  . execute (  )  . actionGet (  )  ;", "assertHighlight ( search ,     0  ,     \" body \"  ,     0  ,    equalTo (  (  \"  < em > Test <  / em >  :     \"     +     (  \"  < em > http :  /  / www . facebook . com <  / em >     < em > http :  /  / org <  / em >     \"     +     \"  < em > http :  /  / xing . com <  / em >     < em > http :  /  / cnn . com <  / em >    http :  /  / quora . com \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiPhraseCutoff"], "fileName": "org.elasticsearch.analysis.common.HighlighterWithAnalyzersTests"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" test \"  ,    jsonBuilder (  )  . startObject (  )  . startObject (  \" test \"  )  . startObject (  \" properties \"  )  . startObject (  \" name \"  )  . field (  \" type \"  ,     \" text \"  )  . startObject (  \" fields \"  )  . startObject (  \" autocomplete \"  )  . field (  \" type \"  ,     \" text \"  )  . field (  \" analyzer \"  ,     \" autocomplete \"  )  . field (  \" search _ analyzer \"  ,     \" search _ autocomplete \"  )  . field (  \" term _ vector \"  ,     \" with _ positions _ offsets \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  . setSettings ( Settings . builder (  )  . put ( indexSettings (  )  )  . put ( MAX _ NGRAM _ DIFF _ SETTING . getKey (  )  ,     1  9  )  . put (  \" analysis . tokenizer . autocomplete . max _ gram \"  ,     2  0  )  . put (  \" analysis . tokenizer . autocomplete . min _ gram \"  ,     1  )  . put (  \" analysis . tokenizer . autocomplete . token _ chars \"  ,     \" letter , digit \"  )  . put (  \" analysis . tokenizer . autocomplete . type \"  ,     \" nGram \"  )  . put (  \" analysis . filter . wordDelimiter . type \"  ,     \" word _ delimiter \"  )  . putList (  \" analysis . filter . wordDelimiter . type _ table \"  ,     \"  &     =  >    ALPHANUM \"  ,     \"  |     =  >    ALPHANUM \"  ,     \"  !     =  >    ALPHANUM \"  ,     \"  ?     =  >    ALPHANUM \"  ,     \"  .     =  >    ALPHANUM \"  ,     \"  -     =  >    ALPHANUM \"  ,     \"  #     =  >    ALPHANUM \"  ,     \"  %     =  >    ALPHANUM \"  ,     \"  +     =  >    ALPHANUM \"  ,     \"  ,     =  >    ALPHANUM \"  ,     \"  ~     =  >    ALPHANUM \"  ,     \"  :     =  >    ALPHANUM \"  ,     \"  /     =  >    ALPHANUM \"  ,     \"  ^     =  >    ALPHANUM \"  ,     \"  $     =  >    ALPHANUM \"  ,     \"  @     =  >    ALPHANUM \"  ,     \"  )     =  >    ALPHANUM \"  ,     \"  (     =  >    ALPHANUM \"  ,     \"  ]     =  >    ALPHANUM \"  ,     \"  [     =  >    ALPHANUM \"  ,     \"  }     =  >    ALPHANUM \"  ,     \"  {     =  >    ALPHANUM \"  )  . put (  \" analysis . filter . wordDelimiter . type . split _ on _ numerics \"  ,    false )  . put (  \" analysis . filter . wordDelimiter . generate _ word _ parts \"  ,    true )  . put (  \" analysis . filter . wordDelimiter . generate _ number _ parts \"  ,    false )  . put (  \" analysis . filter . wordDelimiter . catenate _ words \"  ,    true )  . put (  \" analysis . filter . wordDelimiter . catenate _ numbers \"  ,    true )  . put (  \" analysis . filter . wordDelimiter . catenate _ all \"  ,    false )  . put (  \" analysis . analyzer . autocomplete . tokenizer \"  ,     \" autocomplete \"  )  . putList (  \" analysis . analyzer . autocomplete . filter \"  ,     \" lowercase \"  ,     \" wordDelimiter \"  )  . put (  \" analysis . analyzer . search _ autocomplete . tokenizer \"  ,     \" whitespace \"  )  . putList (  \" analysis . analyzer . search _ autocomplete . filter \"  ,     \" lowercase \"  ,     \" wordDelimiter \"  )  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . setSource (  \" name \"  ,     \" ARCOTEL   Hotels   Deutschland \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   search    =    client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setQuery ( matchQuery (  \" name . autocomplete \"  ,     \" deut   tel \"  )  . operator ( OR )  )  . h ( new   HighlightBuilder (  )  . field (  \" name . autocomplete \"  )  )  . get (  )  ;", "assertHighlight ( search ,     0  ,     \" name . autocomplete \"  ,     0  ,    equalTo (  \" ARCO < em > TEL <  / em >    Ho < em > tel <  / em > s    < em > Deut <  / em > schland \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNgramHighlightingWithBrokenPositions"], "fileName": "org.elasticsearch.analysis.common.HighlighterWithAnalyzersTests"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromClassPath ( createTempDir (  )  ,    KeepFilterFactoryTests . RESOURCE ,    new   CommonAnalysisPlugin (  )  )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" my _ keep _ filter \"  )  ;", "assertThat ( tokenFilter ,    instanceOf ( KeepWordFilterFactory . class )  )  ;", "String   source    =     \" hello   small   world \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" hello \"  ,     \" world \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected ,    new   int [  ]  {     1  ,     2     }  )  ;", "}", "METHOD_END"], "methodName": ["testCaseInsensitiveMapping"], "fileName": "org.elasticsearch.analysis.common.KeepFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromClassPath ( createTempDir (  )  ,    KeepFilterFactoryTests . RESOURCE ,    new   CommonAnalysisPlugin (  )  )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" my _ case _ sensitive _ keep _ filter \"  )  ;", "assertThat ( tokenFilter ,    instanceOf ( KeepWordFilterFactory . class )  )  ;", "String   source    =     \" Hello   small   world \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" Hello \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected ,    new   int [  ]  {     1     }  )  ;", "}", "METHOD_END"], "methodName": ["testCaseSensitiveMapping"], "fileName": "org.elasticsearch.analysis.common.KeepFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . non _ broken _ keep _ filter . type \"  ,     \" keep \"  )  . put (  \" index . analysis . filter . non _ broken _ keep _ filter . keep _ words _ path \"  ,     \" does / not / exists . txt \"  )  . build (  )  ;", "try    {", "AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "fail (  \" expected   an   exception   due   to   non   existent   keep _ words _ path \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "}    catch    ( IOException   e )     {", "fail (  \" expected   IAE \"  )  ;", "}", "settings    =    Settings . builder (  )  . put ( settings )  . putList (  \" index . analysis . filter . non _ broken _ keep _ filter . keep _ words \"  ,     \" test \"  )  . build (  )  ;", "try    {", "AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "fail (  \" expected   an   exception   indicating   that   you   can ' t   use    [ keep _ words _ path ]    with    [ keep _ words ]     \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "}    catch    ( IOException   e )     {", "fail (  \" expected   IAE \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testKeepWordsPathSettings"], "fileName": "org.elasticsearch.analysis.common.KeepFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . broken _ keep _ filter . type \"  ,     \" keep \"  )  . put (  \" index . analysis . filter . broken _ keep _ filter . keep _ words _ path \"  ,     \" does / not / exists . txt \"  )  . put (  \" index . analysis . filter . broken _ keep _ filter . keep _ words \"  ,     \"  [  \\  \" Hello \\  \"  ,     \\  \" worlD \\  \"  ]  \"  )  . build (  )  ;", "try    {", "AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "Assert . fail (  \" path   and   array   are   configured \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "}    catch    ( IOException   e )     {", "fail (  \" expected   IAE \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testLoadOverConfiguredSettings"], "fileName": "org.elasticsearch.analysis.common.KeepFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromClassPath ( createTempDir (  )  ,    KeepFilterFactoryTests . RESOURCE ,    new   CommonAnalysisPlugin (  )  )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" keep \"  )  ;", "Assert . assertNull ( tokenFilter )  ;", "}", "METHOD_END"], "methodName": ["testLoadWithoutSettings"], "fileName": "org.elasticsearch.analysis.common.KeepFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . keep _ numbers . type \"  ,     \" keep _ types \"  )  . putList (  \" index . analysis . filter . keep _ numbers . types \"  ,    new   String [  ]  {     \"  < NUM >  \"  ,     \"  < SOMETHINGELSE >  \"     }  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" keep _ numbers \"  )  ;", "assertThat ( tokenFilter ,    instanceOf (  . class )  )  ;", "String   source    =     \" Hello    1  2  3    world \"  ;", "String [  ]    expected    =    new   String [  ]  {     \"  1  2  3  \"     }  ;", "Tokenizer   tokenizer    =    new   StandardTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected ,    new   int [  ]  {     2     }  )  ;", "}", "METHOD_END"], "methodName": ["testKeepTypes"], "fileName": "org.elasticsearch.analysis.common.KeepTypesFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . my _ keyword . type \"  ,     \" keyword _ marker \"  )  . put (  \" index . analysis . filter . my _ keyword . keywords \"  ,     \" running \"  )  . put (  \" index . analysis . filter . my _ keyword . keywords _ pattern \"  ,     \" run [ a - z ] ing \"  )  . put (  \" index . analysis . analyzer . my _ keyword . type \"  ,     \" custom \"  )  . put (  \" index . analysis . analyzer . my _ keyword . tokenizer \"  ,     \" standard \"  )  . put (  \" index . analysis . analyzer . my _ keyword . filter \"  ,     \" my _ keyword ,    porter _ stem \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  )  ;", "assertEquals (  \" cannot   specify   both    ` keywords _ pattern `    and    ` keywords `    or    ` keywords _ path `  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCannotSpecifyBothKeywordsAndPattern"], "fileName": "org.elasticsearch.analysis.common.KeywordMarkerFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . my _ keyword . type \"  ,     \" keyword _ marker \"  )  . put (  \" index . analysis . filter . my _ keyword . keywords _ pattern \"  ,     \" run [ a - z ] ing \"  )  . put (  \" index . analysis . analyzer . my _ keyword . type \"  ,     \" custom \"  )  . put (  \" index . analysis . analyzer . my _ keyword . tokenizer \"  ,     \" standard \"  )  . put (  \" index . analysis . analyzer . my _ keyword . filter \"  ,     \" my _ keyword ,    porter _ stem \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" my _ keyword \"  )  ;", "assertThat ( tokenFilter ,    instanceOf ( KeywordMarkerTokenFilterFactory . class )  )  ;", "TokenStream   filter    =    tokenFilter . create ( new   WhitespaceTokenizer (  )  )  ;", "assertThat ( filter ,    instanceOf ( Pattern . class )  )  ;", "NamedAnalyzer   analyzer    =    analysis . indexAnalyzers . get (  \" my _ keyword \"  )  ;", "assertAnalyzesTo ( analyzer ,     \" running   sleeping \"  ,    new   String [  ]  {     \" running \"  ,     \" sleep \"     }  )  ;", "}", "METHOD_END"], "methodName": ["testKeywordPattern"], "fileName": "org.elasticsearch.analysis.common.KeywordMarkerFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . my _ keyword . type \"  ,     \" keyword _ marker \"  )  . put (  \" index . analysis . filter . my _ keyword . keywords \"  ,     \" running ,    sleeping \"  )  . put (  \" index . analysis . analyzer . my _ keyword . type \"  ,     \" custom \"  )  . put (  \" index . analysis . analyzer . my _ keyword . tokenizer \"  ,     \" standard \"  )  . put (  \" index . analysis . analyzer . my _ keyword . filter \"  ,     \" my _ keyword ,    porter _ stem \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" my _ keyword \"  )  ;", "assertThat ( tokenFilter ,    instanceOf ( KeywordMarkerTokenFilterFactory . class )  )  ;", "TokenStream   filter    =    tokenFilter . create ( new   WhitespaceTokenizer (  )  )  ;", "assertThat ( filter ,    instanceOf ( Set . class )  )  ;", "NamedAnalyzer   analyzer    =    analysis . indexAnalyzers . get (  \" my _ keyword \"  )  ;", "assertAnalyzesTo ( analyzer ,     \" running   jogging   sleeping \"  ,    new   String [  ]  {     \" running \"  ,     \" jog \"  ,     \" sleeping \"     }  )  ;", "}", "METHOD_END"], "methodName": ["testKeywordSet"], "fileName": "org.elasticsearch.analysis.common.KeywordMarkerFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "}", "METHOD_END"], "methodName": ["createTestAnalysisFromSettings"], "fileName": "org.elasticsearch.analysis.common.LimitTokenCountFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . limit _ default . type \"  ,     \" limit \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "{", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" limit _ default \"  )  ;", "String   source    =     \" the   quick   brown   fox \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "{", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" limit \"  )  ;", "String   source    =     \" the   quick   brown   fox \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "}", "METHOD_END"], "methodName": ["testDefault"], "fileName": "org.elasticsearch.analysis.common.LimitTokenCountFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . limit _  1  . type \"  ,     \" limit \"  )  . put (  \" index . analysis . filter . limit _  1  . max _ token _ count \"  ,     3  )  . put (  \" index . analysis . filter . limit _  1  . consume _ all _ tokens \"  ,    true )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" limit _  1  \"  )  ;", "String   source    =     \" the   quick   brown   fox \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" quick \"  ,     \" brown \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . limit _  1  . type \"  ,     \" limit \"  )  . put (  \" index . analysis . filter . limit _  1  . max _ token _ count \"  ,     3  )  . put (  \" index . analysis . filter . limit _  1  . consume _ all _ tokens \"  ,    false )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" limit _  1  \"  )  ;", "String   source    =     \" the   quick   brown   fox \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" quick \"  ,     \" brown \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . limit _  1  . type \"  ,     \" limit \"  )  . put (  \" index . analysis . filter . limit _  1  . max _ token _ count \"  ,     1  7  )  . put (  \" index . analysis . filter . limit _  1  . consume _ all _ tokens \"  ,    true )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =     . createTestAnalysisFromSettings ( settings )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" limit _  1  \"  )  ;", "String   source    =     \" the   quick   brown   fox \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" the \"  ,     \" quick \"  ,     \" brown \"  ,     \" fox \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "}", "METHOD_END"], "methodName": ["testSettings"], "fileName": "org.elasticsearch.analysis.common.LimitTokenCountFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "for    ( String   rule    :    rules )     {", "Matcher   m    =     . rulePattern . matcher ( rule )  ;", "if    (  !  ( m . find (  )  )  )", "throw   new   RuntimeException (  (  (  \" Invalid   Mapping   Rule    :     [  \"     +    rule )     +     \"  ]  \"  )  )  ;", "String   lhs    =    parseString ( m . group (  1  )  . trim (  )  )  ;", "String   rhs    =    parseString ( m . group (  2  )  . trim (  )  )  ;", "if    (  ( lhs    =  =    null )     |  |     ( rhs    =  =    null )  )", "throw   new   RuntimeException (  (  (  \" Invalid   Mapping   Rule    :     [  \"     +    rule )     +     \"  ]  .    Illegal   mapping .  \"  )  )  ;", "map . add ( lhs ,    rhs )  ;", "}", "}", "METHOD_END"], "methodName": ["parseRules"], "fileName": "org.elasticsearch.analysis.common.MappingCharFilterFactory"}, {"methodBody": ["METHOD_START", "{", "int   readPos    =     0  ;", "int   len    =    s . length (  )  ;", "int   writePos    =     0  ;", "while    ( readPos    <    len )     {", "c   c    =    s . cAt (  ( readPos +  +  )  )  ;", "if    ( c    =  =     '  \\  \\  '  )     {", "if    ( readPos    >  =    len )", "throw   new   RuntimeException (  (  (  \" Invalid   escaped   c   in    [  \"     +    s )     +     \"  ]  \"  )  )  ;", "c    =    s . cAt (  ( readPos +  +  )  )  ;", "switch    ( c )     {", "case    '  \\  \\  '     :", "c    =     '  \\  \\  '  ;", "break ;", "case    ' n '     :", "c    =     '  \\ n '  ;", "break ;", "case    ' t '     :", "c    =     '  \\ t '  ;", "break ;", "case    ' r '     :", "c    =     '  \\ r '  ;", "break ;", "case    ' b '     :", "c    =     '  \\ b '  ;", "break ;", "case    ' f '     :", "c    =     '  \\ f '  ;", "break ;", "case    ' u '     :", "if    (  ( readPos    +     3  )     >  =    len )", "throw   new   RuntimeException (  (  (  \" Invalid   escaped   c   in    [  \"     +    s )     +     \"  ]  \"  )  )  ;", "c    =     (  ( c )     ( Integer . parseInt ( s . substring ( readPos ,     ( readPos    +     4  )  )  ,     1  6  )  )  )  ;", "readPos    +  =     4  ;", "break ;", "}", "}", "out [  ( writePos +  +  )  ]     =    c ;", "}", "return   new   String ( out ,     0  ,    writePos )  ;", "}", "METHOD_END"], "methodName": ["parseString"], "fileName": "org.elasticsearch.analysis.common.MappingCharFilterFactory"}, {"methodBody": ["METHOD_START", "{", "String [  ]    wordList    =    new   String [  1  0  0  0  0  0  ]  ;", "for    ( int   i    =     0  ;    i    <     ( wordList . length )  ;    i +  +  )     {", "wordList [ i ]     =     \" hello   world \"  ;", "}", "client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . setSettings ( Settings . builder (  )  . put (  \" index . number _ of _ shards \"  ,     1  )  . put (  \" analyzer . test _ analyzer . type \"  ,     \" custom \"  )  . put (  \" analyzer . test _ analyzer . tokenizer \"  ,     \" standard \"  )  . putList (  \" analyzer . test _ analyzer . filter \"  ,     \" dictionary _ decompounder \"  ,     \" lowercase \"  )  . put (  \" filter . dictionary _ decompounder . type \"  ,     \" dictionary _ decompounder \"  )  . putList (  \" filter . dictionary _ decompounder . word _ list \"  ,    wordList )  )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["testCreateIndexWithMassiveWordList"], "fileName": "org.elasticsearch.analysis.common.MassiveWordListTests"}, {"methodBody": ["METHOD_START", "{", "int   default _ hash _ count    =     1  ;", "int   default _ bucket _ size    =     5  1  2  ;", "int   default _ hash _ set _ size    =     1  ;", "Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "Token   tokenFilter    =    analysis . tokenFilter . get (  \" min _ hash \"  )  ;", "String   source    =     \" the   quick   brown   fox \"  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertStreamHasNumberOfTokens ( tokenFilter . create ( tokenizer )  ,     (  ( default _ hash _ count    *    default _ bucket _ size )     *    default _ hash _ set _ size )  )  ;", "}", "METHOD_END"], "methodName": ["testDefault"], "fileName": "org.elasticsearch.analysis.common.MinHashFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . test _ min _ hash . type \"  ,     \" min _ hash \"  )  . put (  \" index . analysis . filter . test _ min _ hash . hash _ count \"  ,     \"  1  \"  )  . put (  \" index . analysis . filter . test _ min _ hash . bucket _ count \"  ,     \"  2  \"  )  . put (  \" index . analysis . filter . test _ min _ hash . hash _ set _ size \"  ,     \"  1  \"  )  . put (  \" index . analysis . filter . test _ min _ hash . with _ rotation \"  ,    false )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "Token   tokenFilter    =    analysis . tokenFilter . get (  \" test _ min _ hash \"  )  ;", "String   source    =     \" sushi \"  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertStreamHasNumberOfTokens ( tokenFilter . create ( tokenizer )  ,     1  )  ;", "}", "METHOD_END"], "methodName": ["testSettings"], "fileName": "org.elasticsearch.analysis.common.MinHashFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    settingMap    =    new   HashMap <  >  (  )  ;", "settingMap . put (  \" hashCount \"  ,    settings . get (  \" hash _ count \"  )  )  ;", "settingMap . put (  \" bucketCount \"  ,    settings . get (  \" bucket _ count \"  )  )  ;", "settingMap . put (  \" hashSetSize \"  ,    settings . get (  \" hash _ set _ size \"  )  )  ;", "settingMap . put (  \" withRotation \"  ,    settings . get (  \" with _ rotation \"  )  )  ;", "return   settingMap ;", "}", "METHOD_END"], "methodName": ["convertSettings"], "fileName": "org.elasticsearch.analysis.common.MinHashTokenFilterFactory"}, {"methodBody": ["METHOD_START", "{", "Field [  ]    declaredFields    =    Version . class . getFields (  )  ;", "List < Field >    versionFields    =    new   ArrayList <  >  (  )  ;", "for    ( Field   field    :    declaredFields )     {", "if    (  (  (  (  ( field . getModifiers (  )  )     &     ( Modifier . STATIC )  )     !  =     0  )     &  &     ( field . getName (  )  . startsWith (  \" V _  \"  )  )  )     &  &     (  ( field . getType (  )  )     =  =     ( Version . class )  )  )     {", "versionFields . add ( field )  ;", "}", "}", "return    (  ( Version )     ( versionFields . get ( random . nextInt ( versionFields . size (  )  )  )  . get ( Version . class )  )  )  ;", "}", "METHOD_END"], "methodName": ["randomVersion"], "fileName": "org.elasticsearch.analysis.common.NGramTokenizerFactoryTests"}, {"methodBody": ["METHOD_START", "{", "int   iters    =    scaledRandomIntBetween (  2  0  ,     1  0  0  )  ;", "for    ( int   i    =     0  ;    i    <    iters ;    i +  +  )     {", "final   Index   index    =    new   Index (  \" test \"  ,     \"  _ na _  \"  )  ;", "final   String   name    =     \" ngr \"  ;", "Version   v    =    randomVersion ( random (  )  )  ;", "Builder   builder    =    newAnalysisSettingsBuilder (  )  . put (  \" min _ gram \"  ,     2  )  . put (  \" max _ gram \"  ,     3  )  ;", "boolean   reverse    =    random (  )  . nextBoolean (  )  ;", "if    ( reverse )     {", "builder . put (  \" side \"  ,     \" back \"  )  ;", "}", "Settings   settings    =    builder . build (  )  ;", "Settings   indexSettings    =    newAnalysisSettingsBuilder (  )  . put ( SETTING _ VERSION _ CREATED ,    v . id )  . build (  )  ;", "Tokenizer   tokenizer    =    new   MockTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader (  \" foo   bar \"  )  )  ;", "TokenStream   edgeFilter    =    new   EdgeFilterFactory ( IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ,    null ,    name ,    settings )  . create ( tokenizer )  ;", "if    ( reverse )     {", "assertThat ( edgeFilter ,    instanceOf ( ReverseStringFilter . class )  )  ;", "} else    {", "assertThat ( edgeFilter ,    instanceOf ( EdgeFilter . class )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testBackwardsCompatibilityEdgeNgramTokenFilter"], "fileName": "org.elasticsearch.analysis.common.NGramTokenizerFactoryTests"}, {"methodBody": ["METHOD_START", "{", "final   Index   index    =    new   Index (  \" test \"  ,     \"  _ na _  \"  )  ;", "final   String   name    =     \" ngr \"  ;", "final   Settings   indexSettings    =    newAnalysisSettingsBuilder (  )  . build (  )  ;", "IndexSettings   indexProperties    =    IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ;", "int   maxAllowedNgramDiff    =    indexProperties . getMaxNgramDiff (  )  ;", "int   ngramDiff    =    maxAllowedNgramDiff    +     1  ;", "int   min _ gram    =     2  ;", "int   max _ gram    =    min _ gram    +    ngramDiff ;", "final   Settings   settings    =    newAnalysisSettingsBuilder (  )  . put (  \" min _ gram \"  ,    min _ gram )  . put (  \" max _ gram \"  ,    max _ gram )  . build (  )  ;", "IllegalArgumentException   ex    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    ( indexProperties ,    null ,    name ,    settings )  . create (  )  )  ;", "assertEquals (  (  (  (  (  (  (  \" The   difference   between   max _ gram   and   min _ gram   in   NGram   Tokenizer   must   be   less   than   or   equal   to :     [  \"     +    maxAllowedNgramDiff )     +     \"  ]    but   was    [  \"  )     +    ngramDiff )     +     \"  ]  .    This   limit   can   be   set   by   changing   the    [  \"  )     +     ( MAX _ NGRAM _ DIFF _ SETTING . getKey (  )  )  )     +     \"  ]    index   level   setting .  \"  )  ,    ex . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testMaxNGramDiffException"], "fileName": "org.elasticsearch.analysis.common.NGramTokenizerFactoryTests"}, {"methodBody": ["METHOD_START", "{", "final   Index   index    =    new   Index (  \" test \"  ,     \"  _ na _  \"  )  ;", "final   String   name    =     \" ngr \"  ;", "final   Settings   indexSettings    =    newAnalysisSettingsBuilder (  )  . put ( MAX _ NGRAM _ DIFF _ SETTING . getKey (  )  ,     2  )  . build (  )  ;", "final   Settings   settings    =    newAnalysisSettingsBuilder (  )  . put (  \" min _ gram \"  ,     2  )  . put (  \" max _ gram \"  ,     4  )  . putList (  \" token _ chars \"  ,    new   String [  0  ]  )  . build (  )  ;", "Tokenizer   tokenizer    =    new   analysis ( IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ,    null ,    name ,    settings )  . create (  )  ;", "tokenizer . setReader ( new   StringReader (  \"  1  .  3  4  \"  )  )  ;", "assertTokenStreamContents ( tokenizer ,    new   String [  ]  {     \"  1  .  \"  ,     \"  1  .  3  \"  ,     \"  1  .  3  4  \"  ,     \"  .  3  \"  ,     \"  .  3  4  \"  ,     \"  3  4  \"     }  )  ;", "}", "METHOD_END"], "methodName": ["testNoTokenChars"], "fileName": "org.elasticsearch.analysis.common.NGramTokenizerFactoryTests"}, {"methodBody": ["METHOD_START", "{", "final   Index   index    =    new   Index (  \" test \"  ,     \"  _ na _  \"  )  ;", "final   String   name    =     \" ngr \"  ;", "final   Settings   indexSettings    =    newAnalysisSettingsBuilder (  )  . build (  )  ;", "IndexSettings   indexProperties    =    IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ;", "for    ( String   tokenChars    :    Arrays . asList (  \" letters \"  ,     \" number \"  ,     \" DIRECTIONALITY _ UNDEFINED \"  )  )     {", "final   Settings   settings    =    newAnalysisSettingsBuilder (  )  . put (  \" min _ gram \"  ,     2  )  . put (  \" max _ gram \"  ,     3  )  . put (  \" token _ chars \"  ,    tokenChars )  . build (  )  ;", "try    {", "new   analysis ( indexProperties ,    null ,    name ,    settings )  . create (  )  ;", "fail (  )  ;", "}    catch    ( IllegalArgumentException   expected )     {", "}", "}", "for    ( String   tokenChars    :    Arrays . asList (  \" letter \"  ,     \"    digit    \"  ,     \" punctuation \"  ,     \" DIGIT \"  ,     \" CoNtRoL \"  ,     \" dash _ punctuation \"  )  )     {", "final   Settings   settings    =    newAnalysisSettingsBuilder (  )  . put (  \" min _ gram \"  ,     2  )  . put (  \" max _ gram \"  ,     3  )  . put (  \" token _ chars \"  ,    tokenChars )  . build (  )  ;", "indexProperties    =    IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ;", "new   analysis ( indexProperties ,    null ,    name ,    settings )  . create (  )  ;", "}", "}", "METHOD_END"], "methodName": ["testParseTokenChars"], "fileName": "org.elasticsearch.analysis.common.NGramTokenizerFactoryTests"}, {"methodBody": ["METHOD_START", "{", "final   Index   index    =    new   Index (  \" test \"  ,     \"  _ na _  \"  )  ;", "final   String   name    =     \" ngr \"  ;", "final   Settings   indexSettings    =    newAnalysisSettingsBuilder (  )  . build (  )  ;", "Settings   settings    =    newAnalysisSettingsBuilder (  )  . put (  \" min _ gram \"  ,     2  )  . put (  \" max _ gram \"  ,     3  )  . put (  \" token _ chars \"  ,     \" letter , digit \"  )  . build (  )  ;", "Tokenizer   tokenizer    =    new   analysis ( IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ,    null ,    name ,    settings )  . create (  )  ;", "tokenizer . setReader ( new   StringReader (  \"  \\ u 0  0 c 5 bc   d \\ u 0  0 e 9 f   g \\ ud 8  0  1  \\ udc 0  0 f    \"  )  )  ;", "assertTokenStreamContents ( tokenizer ,    new   String [  ]  {     \"  ? b \"  ,     \"  ? bc \"  ,     \" bc \"  ,     \" d \u00a8\u00a6  \"  ,     \" d \u00a8\u00a6 f \"  ,     \"  \u00a8\u00a6 f \"  ,     \" g \\ ud 8  0  1  \\ udc 0  0  \"  ,     \" g \\ ud 8  0  1  \\ udc 0  0 f \"  ,     \"  \\ ud 8  0  1  \\ udc 0  0 f \"     }  )  ;", "settings    =    newAnalysisSettingsBuilder (  )  . put (  \" min _ gram \"  ,     2  )  . put (  \" max _ gram \"  ,     3  )  . put (  \" token _ chars \"  ,     \" letter , digit , punctuation , whitespace , symbol \"  )  . build (  )  ;", "tokenizer    =    new   analysis ( IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ,    null ,    name ,    settings )  . create (  )  ;", "tokenizer . setReader ( new   StringReader (  \"    a !  $     9  \"  )  )  ;", "assertTokenStreamContents ( tokenizer ,    new   String [  ]  {     \"    a \"  ,     \"    a !  \"  ,     \" a !  \"  ,     \" a !  $  \"  ,     \"  !  $  \"  ,     \"  !  $     \"  ,     \"  $     \"  ,     \"  $     9  \"  ,     \"     9  \"     }  )  ;", "}", "METHOD_END"], "methodName": ["testPreTokenization"], "fileName": "org.elasticsearch.analysis.common.NGramTokenizerFactoryTests"}, {"methodBody": ["METHOD_START", "{", "final   Index   index    =    new   Index (  \" test \"  ,     \"  _ na _  \"  )  ;", "final   String   name    =     \" ngr \"  ;", "final   Settings   indexSettings    =    newAnalysisSettingsBuilder (  )  . build (  )  ;", "Settings   settings    =    newAnalysisSettingsBuilder (  )  . put (  \" min _ gram \"  ,     2  )  . put (  \" max _ gram \"  ,     3  )  . put (  \" token _ chars \"  ,     \" letter , digit \"  )  . build (  )  ;", "Tokenizer   tokenizer    =    new   Edge ( IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ,    null ,    name ,    settings )  . create (  )  ;", "tokenizer . setReader ( new   StringReader (  \"  \\ u 0  0 c 5 bc   d \\ u 0  0 e 9 f   g \\ ud 8  0  1  \\ udc 0  0 f    \"  )  )  ;", "assertTokenStreamContents ( tokenizer ,    new   String [  ]  {     \"  ? b \"  ,     \"  ? bc \"  ,     \" d \u00a8\u00a6  \"  ,     \" d \u00a8\u00a6 f \"  ,     \" g \\ ud 8  0  1  \\ udc 0  0  \"  ,     \" g \\ ud 8  0  1  \\ udc 0  0 f \"     }  )  ;", "settings    =    newAnalysisSettingsBuilder (  )  . put (  \" min _ gram \"  ,     2  )  . put (  \" max _ gram \"  ,     3  )  . put (  \" token _ chars \"  ,     \" letter , digit , punctuation , whitespace , symbol \"  )  . build (  )  ;", "tokenizer    =    new   Edge ( IndexSettingsModule . newIndexSettings ( index ,    indexSettings )  ,    null ,    name ,    settings )  . create (  )  ;", "tokenizer . setReader ( new   StringReader (  \"    a !  $     9  \"  )  )  ;", "assertTokenStreamContents ( tokenizer ,    new   String [  ]  {     \"    a \"  ,     \"    a !  \"     }  )  ;", "}", "METHOD_END"], "methodName": ["testPreTokenizationEdge"], "fileName": "org.elasticsearch.analysis.common.NGramTokenizerFactoryTests"}, {"methodBody": ["METHOD_START", "{", "try    {", "new   GroupTokenFilterFactory ( IndexSettingsModule . newIndexSettings (  \" test \"  ,    EMPTY )  ,    null ,     \" pattern _ capture \"  ,    Settings . builder (  )  . put (  \" pattern \"  ,     \" foobar \"  )  . build (  )  )  ;", "fail (  \" Expected   IllegalArgumentException \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \" required   setting    ' patterns '    is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testNoPatterns"], "fileName": "org.elasticsearch.analysis.common.PatternCaptureTokenFilterTests"}, {"methodBody": ["METHOD_START", "{", "String   json    =     \"  / org / elasticsearch / analysis / common / pattern _ capture . json \"  ;", "Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  )  . loadFromStream ( json ,    getClass (  )  . getResourceAsStream ( json )  ,    false )  . put ( SETTING _ VERSION _ CREATED ,    CURRENT )  . build (  )  ;", "IndexSettings   idxSettings    =    IndexSettingsModule . newIndexSettings (  \" index \"  ,    settings )  ;", "IndexAnalyzers   indexAnalyzers    =    createTestAnalysis ( idxSettings ,    settings ,    new   CommonAnalysisPlugin (  )  )  . indexAnalyzers ;", "NamedAnalyzer   analyzer 1     =    indexAnalyzers . get (  \" single \"  )  ;", "assertTokenStreamContents ( analyzer 1  . tokenStream (  \" test \"  ,     \" foobarbaz \"  )  ,    new   String [  ]  {     \" foobarbaz \"  ,     \" foobar \"  ,     \" foo \"     }  )  ;", "NamedAnalyzer   analyzer 2     =    indexAnalyzers . get (  \" multi \"  )  ;", "assertTokenStreamContents ( analyzer 2  . tokenStream (  \" test \"  ,     \" abc 1  2  3 def \"  )  ,    new   String [  ]  {     \" abc 1  2  3 def \"  ,     \" abc \"  ,     \"  1  2  3  \"  ,     \" def \"     }  )  ;", "NamedAnalyzer   analyzer 3     =    indexAnalyzers . get (  \" preserve \"  )  ;", "assertTokenStreamContents ( analyzer 3  . tokenStream (  \" test \"  ,     \" foobarbaz \"  )  ,    new   String [  ]  {     \" foobar \"  ,     \" foo \"     }  )  ;", "}", "METHOD_END"], "methodName": ["testPatternCaptureTokenFilter"], "fileName": "org.elasticsearch.analysis.common.PatternCaptureTokenFilterTests"}, {"methodBody": ["METHOD_START", "{", "return   pattern ;", "}", "METHOD_END"], "methodName": ["getPattern"], "fileName": "org.elasticsearch.analysis.common.PatternReplaceCharFilterFactory"}, {"methodBody": ["METHOD_START", "{", "return   replacement ;", "}", "METHOD_END"], "methodName": ["getReplacement"], "fileName": "org.elasticsearch.analysis.common.PatternReplaceCharFilterFactory"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . setSettings ( Settings . builder (  )  . put (  \" analysis . analyzer . my _ analyzer . type \"  ,     \" custom \"  )  . put (  \" analysis . analyzer . my _ analyzer . tokenizer \"  ,     \" whitespace \"  )  . put (  \" analysis . analyzer . my _ analyzer . filter \"  ,     \" custom _ word _ delimiter \"  )  . put (  \" analysis . filter . custom _ word _ delimiter . type \"  ,     \" word _ delimiter \"  )  . put (  \" analysis . filter . custom _ word _ delimiter . generate _ word _ parts \"  ,     \" true \"  )  . put (  \" analysis . filter . custom _ word _ delimiter . generate _ number _ parts \"  ,     \" false \"  )  . put (  \" analysis . filter . custom _ word _ delimiter . catenate _ numbers \"  ,     \" true \"  )  . put (  \" analysis . filter . custom _ word _ delimiter . catenate _ words \"  ,     \" false \"  )  . put (  \" analysis . filter . custom _ word _ delimiter . split _ on _ case _ change \"  ,     \" false \"  )  . put (  \" analysis . filter . custom _ word _ delimiter . split _ on _ numerics \"  ,     \" false \"  )  . put (  \" analysis . filter . custom _ word _ delimiter . stem _ english _ possessive \"  ,     \" false \"  )  )  . addMapping (  \" type 1  \"  ,     \" field 1  \"  ,     \" type = text , analyzer = my _ analyzer \"  ,     \" field 2  \"  ,     \" type = text , analyzer = my _ analyzer \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type 1  \"  ,     \"  1  \"  )  . setSource (  \" field 1  \"  ,     \" foo   bar   baz \"  ,     \" field 2  \"  ,     \" not   needed \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( qQuery (  \" foo . baz \"  )  . defaultOperator ( AND )  . field (  \" field 1  \"  )  . field (  \" field 2  \"  )  )  . get (  )  ;", "assertHitCount ( response ,     1 L )  ;", "}", "METHOD_END"], "methodName": ["testCustomWordDelimiterQueryString"], "fileName": "org.elasticsearch.analysis.common.QueryStringWithAnalyzersTests"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ ascii _ folding . type \"  ,     \" asciifolding \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "Factory   tokenFilter    =    analysis . tokenFilter . get (  \" shingle \"  )  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader (  \" this   is   a   test \"  )  )  ;", "TokenStream   tokenStream    =    tokenFilter . create ( tokenizer )  ;", "assertTrue ( tokenStream . hasAttribute ( DisableGraphAttribute . class )  )  ;", "}", "METHOD_END"], "methodName": ["testPreConfiguredShingleFilterDisableGraphAttribute"], "fileName": "org.elasticsearch.analysis.common.ShingleTokenFilterTests"}, {"methodBody": ["METHOD_START", "{", "for    ( String   rule    :    rules )     {", "String   key ;", "String   o ;", "List < String >    mapping    =    Strings . splitSmart ( rule ,    mappingSep ,    false )  ;", "if    (  ( mapping . size (  )  )     =  =     2  )     {", "key    =    mapping . get (  0  )  . trim (  )  ;", "o    =    mapping . get (  1  )  . trim (  )  ;", "} else    {", "throw   new   RuntimeException (  (  \" Invalid   Keyword   o   Rule :  \"     +    rule )  )  ;", "}", "if    (  ( key . isEmpty (  )  )     |  |     ( o . isEmpty (  )  )  )     {", "throw   new   RuntimeException (  (  \" Invalid   Keyword   o   Rule :  \"     +    rule )  )  ;", "} else    {", "builder . add ( key ,    o )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["parseRules"], "fileName": "org.elasticsearch.analysis.common.StemmerOverrideTokenFilterFactory"}, {"methodBody": ["METHOD_START", "{", "int   iters    =    scaledRandomIntBetween (  2  0  ,     1  0  0  )  ;", "for    ( int   i    =     0  ;    i    <    iters ;    i +  +  )     {", "Version   v    =    VersionUtils . randomVersion ( random (  )  )  ;", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . my _ english . type \"  ,     \" stemmer \"  )  . put (  \" index . analysis . filter . my _ english . language \"  ,     \" english \"  )  . put (  \" index . analysis . analyzer . my _ english . tokenizer \"  ,     \" whitespace \"  )  . put (  \" index . analysis . analyzer . my _ english . filter \"  ,     \" my _ english \"  )  . put ( SETTING _ VERSION _ CREATED ,    v )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,     . PLUGIN )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" my _ english \"  )  ;", "assertThat ( tokenFilter ,    instanceOf ( StemmerTokenFilterFactory . class )  )  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader (  \" foo   bar \"  )  )  ;", "TokenStream   create    =    tokenFilter . create ( tokenizer )  ;", "IndexAnalyzers   indexAnalyzers    =    analysis . indexAnalyzers ;", "NamedAnalyzer   analyzer    =    indexAnalyzers . get (  \" my _ english \"  )  ;", "assertThat ( create ,    instanceOf ( PorterStemFilter . class )  )  ;", "assertAnalyzesTo ( analyzer ,     \" consolingly \"  ,    new   String [  ]  {     \" consolingli \"     }  )  ;", "}", "}", "METHOD_END"], "methodName": ["testEnglishFilterFactory"], "fileName": "org.elasticsearch.analysis.common.StemmerTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "int   iters    =    scaledRandomIntBetween (  2  0  ,     1  0  0  )  ;", "for    ( int   i    =     0  ;    i    <    iters ;    i +  +  )     {", "Version   v    =    VersionUtils . randomVersion ( random (  )  )  ;", "Settings   settings    =    Settings . builder (  )  . put (  \" index . analysis . filter . my _ porter 2  . type \"  ,     \" stemmer \"  )  . put (  \" index . analysis . filter . my _ porter 2  . language \"  ,     \" porter 2  \"  )  . put (  \" index . analysis . analyzer . my _ porter 2  . tokenizer \"  ,     \" whitespace \"  )  . put (  \" index . analysis . analyzer . my _ porter 2  . filter \"  ,     \" my _ porter 2  \"  )  . put ( SETTING _ VERSION _ CREATED ,    v )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,     . PLUGIN )  ;", "TokenFilterFactory   tokenFilter    =    analysis . tokenFilter . get (  \" my _ porter 2  \"  )  ;", "assertThat ( tokenFilter ,    instanceOf ( StemmerTokenFilterFactory . class )  )  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader (  \" foo   bar \"  )  )  ;", "TokenStream   create    =    tokenFilter . create ( tokenizer )  ;", "IndexAnalyzers   indexAnalyzers    =    analysis . indexAnalyzers ;", "NamedAnalyzer   analyzer    =    indexAnalyzers . get (  \" my _ porter 2  \"  )  ;", "assertThat ( create ,    instanceOf ( SnowballFilter . class )  )  ;", "assertAnalyzesTo ( analyzer ,     \" possibly \"  ,    new   String [  ]  {     \" possibl \"     }  )  ;", "}", "}", "METHOD_END"], "methodName": ["testPorter2FilterFactory"], "fileName": "org.elasticsearch.analysis.common.StemmerTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . putList (  \" index . analysis . normalizer . my _ normalizer . filter \"  ,     \" trim \"  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( settings ,    new   CommonAnalysisPlugin (  )  )  ;", "assertNull ( analysis . indexAnalyzers . get (  \" my _ normalizer \"  )  )  ;", "NamedAnalyzer   normalizer    =    analysis . indexAnalyzers . getNormalizer (  \" my _ normalizer \"  )  ;", "assertNotNull ( normalizer )  ;", "assertEquals (  \" my _ normalizer \"  ,    normalizer . name (  )  )  ;", "assertTokenStreamContents ( normalizer . tokenStream (  \" foo \"  ,     \"       bar       \"  )  ,    new   String [  ]  {     \" bar \"     }  )  ;", "assertEquals ( new   BytesRef (  \" bar \"  )  ,    normalizer . normalize (  \" foo \"  ,     \"       bar       \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNormalizer"], "fileName": "org.elasticsearch.analysis.common.TrimTokenFilterTests"}, {"methodBody": ["METHOD_START", "{", "Analyzer   analyzer    =    new   Analyzer (  )     {", "@ Override", "protected   TokenStreamComponents   createComponents ( String   fieldName )     {", "Tokenizer   t    =    new   MockTokenizer ( MockTokenizer . WHITESPACE ,    false )  ;", "return   new   TokenStreamComponents ( t ,    new    ( t )  )  ;", "}", "}  ;", "TokenStream   test    =    analyzer . tokenStream (  \" test \"  ,     \" this   test   with   test \"  )  ;", "test . reset (  )  ;", "CharTermAttribute   termAttribute    =    test . addAttribute ( CharTermAttribute . class )  ;", "assertThat ( test . incrementToken (  )  ,    equalTo ( true )  )  ;", "assertThat ( termAttribute . toString (  )  ,    equalTo (  \" this \"  )  )  ;", "assertThat ( test . incrementToken (  )  ,    equalTo ( true )  )  ;", "assertThat ( termAttribute . toString (  )  ,    equalTo (  \" test \"  )  )  ;", "assertThat ( test . incrementToken (  )  ,    equalTo ( true )  )  ;", "assertThat ( termAttribute . toString (  )  ,    equalTo (  \" with \"  )  )  ;", "assertThat ( test . incrementToken (  )  ,    equalTo ( false )  )  ;", "}", "METHOD_END"], "methodName": ["testSimple"], "fileName": "org.elasticsearch.analysis.common.UniqueTokenFilterTests"}, {"methodBody": ["METHOD_START", "{", "if    ( settings . getAsBoolean ( key ,    defaultValue )  )     {", "return   flag ;", "}", "return    0  ;", "}", "METHOD_END"], "methodName": ["getFlag"], "fileName": "org.elasticsearch.analysis.common.WordDelimiterGraphTokenFilterFactory"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . put (  \" index . analysis . filter . my _ word _ delimiter . catenate _ all \"  ,     \" true \"  )  . put (  \" index . analysis . filter . my _ word _ delimiter . preserve _ original \"  ,     \" true \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot    5  0  0  -  4  2    wi - fi   wi - fi -  4  0  0  0    j 2 se   O ' Neil ' s \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" PowerShot \"  ,     \" PowerShot \"  ,     \" Power \"  ,     \" Shot \"  ,     \"  5  0  0  4  2  \"  ,     \"  5  0  0  -  4  2  \"  ,     \"  5  0  0  \"  ,     \"  4  2  \"  ,     \" wifi \"  ,     \" wi - fi \"  ,     \" wi \"  ,     \" fi \"  ,     \" wifi 4  0  0  0  \"  ,     \" wi - fi -  4  0  0  0  \"  ,     \" wi \"  ,     \" fi \"  ,     \"  4  0  0  0  \"  ,     \" j 2 se \"  ,     \" j 2 se \"  ,     \" j \"  ,     \"  2  \"  ,     \" se \"  ,     \" ONeil \"  ,     \" O ' Neil ' s \"  ,     \" O \"  ,     \" Neil \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "int [  ]    expectedIncr    =    new   int [  ]  {     1  ,     0  ,     0  ,     1  ,     1  ,     0  ,     0  ,     1  ,     1  ,     0  ,     0  ,     1  ,     1  ,     0  ,     0  ,     1  ,     1  ,     1  ,     0  ,     0  ,     1  ,     1  ,     1  ,     0  ,     0  ,     1     }  ;", "int [  ]    expectedPosLen    =    new   int [  ]  {     2  ,     2  ,     1  ,     1  ,     2  ,     2  ,     1  ,     1  ,     2  ,     2  ,     1  ,     1  ,     3  ,     3  ,     1  ,     1  ,     1  ,     3  ,     3  ,     1  ,     1  ,     1  ,     2  ,     2  ,     1  ,     1     }  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected ,    null ,    null ,    null ,    expectedIncr ,    expectedPosLen ,    null )  ;", "}", "METHOD_END"], "methodName": ["testMultiTerms"], "fileName": "org.elasticsearch.analysis.common.WordDelimiterGraphTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . put (  \" index . analysis . filter . my _ word _ delimiter . catenate _ words \"  ,     \" true \"  )  . put (  \" index . analysis . filter . my _ word _ delimiter . generate _ word _ parts \"  ,     \" true \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot \"  ;", "int [  ]    expectedIncr    =    new   int [  ]  {     1  ,     0  ,     1     }  ;", "int [  ]    expectedPosLen    =    new   int [  ]  {     2  ,     1  ,     1     }  ;", "String [  ]    expected    =    new   String [  ]  {     \" PowerShot \"  ,     \" Power \"  ,     \" Shot \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected ,    null ,    null ,    null ,    expectedIncr ,    expectedPosLen ,    null )  ;", "}", "METHOD_END"], "methodName": ["testPartsAndCatenate"], "fileName": "org.elasticsearch.analysis.common.WordDelimiterGraphTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "if    ( settings . getAsBoolean ( key ,    defaultValue )  )     {", "return   flag ;", "}", "return    0  ;", "}", "METHOD_END"], "methodName": ["getFlag"], "fileName": "org.elasticsearch.analysis.common.WordDelimiterTokenFilterFactory"}, {"methodBody": ["METHOD_START", "{", "char [  ]    out    =    new   char [  2  5  6  ]  ;", "int   readPos    =     0  ;", "int   len    =    s . length (  )  ;", "int   wrPos    =     0  ;", "while    ( readPos    <    len )     {", "char   c    =    s . charAt (  ( readPos +  +  )  )  ;", "if    ( c    =  =     '  \\  \\  '  )     {", "if    ( readPos    >  =    len )", "throw   new   RuntimeException (  (  (  \" Invalid   escaped   char   in    [  \"     +    s )     +     \"  ]  \"  )  )  ;", "c    =    s . charAt (  ( readPos +  +  )  )  ;", "switch    ( c )     {", "case    '  \\  \\  '     :", "c    =     '  \\  \\  '  ;", "break ;", "case    ' n '     :", "c    =     '  \\ n '  ;", "break ;", "case    ' t '     :", "c    =     '  \\ t '  ;", "break ;", "case    ' r '     :", "c    =     '  \\ r '  ;", "break ;", "case    ' b '     :", "c    =     '  \\ b '  ;", "break ;", "case    ' f '     :", "c    =     '  \\ f '  ;", "break ;", "case    ' u '     :", "if    (  ( readPos    +     3  )     >  =    len )", "throw   new   RuntimeException (  (  (  \" Invalid   escaped   char   in    [  \"     +    s )     +     \"  ]  \"  )  )  ;", "c    =     (  ( char )     ( Integer . parseInt ( s . substring ( readPos ,     ( readPos    +     4  )  )  ,     1  6  )  )  )  ;", "readPos    +  =     4  ;", "break ;", "}", "}", "out [  ( wrPos +  +  )  ]     =    c ;", "}", "return   new   String ( out ,     0  ,    wrPos )  ;", "}", "METHOD_END"], "methodName": ["parseString"], "fileName": "org.elasticsearch.analysis.common.WordDelimiterTokenFilterFactory"}, {"methodBody": ["METHOD_START", "{", "if    ( s . equals (  \" LOWER \"  )  )", "return   LOWER ;", "else", "if    ( s . equals (  \" UPPER \"  )  )", "return   UPPER ;", "else", "if    ( s . equals (  \" ALPHA \"  )  )", "return   ALPHA ;", "else", "if    ( s . equals (  \" DIGIT \"  )  )", "return   DIGIT ;", "else", "if    ( s . equals (  \" ALPHANUM \"  )  )", "return   ALPHANUM ;", "else", "if    ( s . equals (  \" SUBWORD _ DELIM \"  )  )", "return   SUBWORD _ DELIM ;", "else", "return   null ;", "}", "METHOD_END"], "methodName": ["parseType"], "fileName": "org.elasticsearch.analysis.common.WordDelimiterTokenFilterFactory"}, {"methodBody": ["METHOD_START", "{", "SortedMap < Character ,    Byte >    typeMap    =    new   TreeMap <  >  (  )  ;", "for    ( String   rule    :    rules )     {", "Matcher   m    =     . typePattern . matcher ( rule )  ;", "if    (  !  ( m . find (  )  )  )", "throw   new   RuntimeException (  (  (  \" Invalid   Mapping   Rule    :     [  \"     +    rule )     +     \"  ]  \"  )  )  ;", "String   lhs    =     . parseString ( m . group (  1  )  . trim (  )  )  ;", "Byte   rhs    =     . parseType ( m . group (  2  )  . trim (  )  )  ;", "if    (  ( lhs . length (  )  )     !  =     1  )", "throw   new   RuntimeException (  (  (  \" Invalid   Mapping   Rule    :     [  \"     +    rule )     +     \"  ]  .    Only   a   single   character   is   allowed .  \"  )  )  ;", "if    ( rhs    =  =    null )", "throw   new   RuntimeException (  (  (  \" Invalid   Mapping   Rule    :     [  \"     +    rule )     +     \"  ]  .    Illegal   type .  \"  )  )  ;", "typeMap . put ( lhs . charAt (  0  )  ,    rhs )  ;", "}", "byte [  ]    types    =    new   byte [ Math . max (  (  ( typeMap . lastKey (  )  )     +     1  )  ,    length )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( types . length )  ;    i +  +  )", "types [ i ]     =    getType ( i )  ;", "for    ( Map . Entry < Character ,    Byte >    mapping    :    typeMap . entrySet (  )  )", "types [ mapping . getKey (  )  ]     =    mapping . getValue (  )  ;", "return   types ;", "}", "METHOD_END"], "methodName": ["parseTypes"], "fileName": "org.elasticsearch.analysis.common.WordDelimiterTokenFilterFactory"}, {"methodBody": ["METHOD_START", "{", "ESTestCase . TestAnalysis   analysis    =    AnalysisTestsHelper . createTestAnalysisFromSettings ( Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" index . analysis . filter . my _ word _ delimiter . type \"  ,    type )  . put (  \" index . analysis . filter . my _ word _ delimiter . catenate _ words \"  ,     \" true \"  )  . put (  \" index . analysis . filter . my _ word _ delimiter . generate _ word _ parts \"  ,     \" true \"  )  . build (  )  ,    new   CommonAnalysisPlugin (  )  )  ;", "tokenFilter    =    analysis . tokenFilter . get (  \" my _ word _ delimiter \"  )  ;", "String   source    =     \" PowerShot \"  ;", "String [  ]    expected    =    new   String [  ]  {     \" Power \"  ,     \" PowerShot \"  ,     \" Shot \"     }  ;", "Tokenizer   tokenizer    =    new   WhitespaceTokenizer (  )  ;", "tokenizer . setReader ( new   StringReader ( source )  )  ;", "assertTokenStreamContents ( tokenFilter . create ( tokenizer )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testPartsAndCatenate"], "fileName": "org.elasticsearch.analysis.common.WordDelimiterTokenFilterFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Client   client    =    client (  )  ;", "BulkByScrollResponse   response    =    INSTANCE . newRequestBuilder ( client )  . filter ( QueryBuilders . matchQuery (  \" gender \"  ,     \" male \"  )  )  . source (  \" persons \"  )  . get (  )  ;", "long   deleted    =    response . getDeleted (  )  ;", "INSTANCE . newRequestBuilder ( client )  . filter ( QueryBuilders . matchQuery (  \" gender \"  ,     \" male \"  )  )  . source (  \" persons \"  )  . execute ( new   action . ActionListener < BulkByScrollResponse >  (  )     {", "@ Override", "public   void   onResponse ( BulkByScrollResponse   response )     {", "long   deleted    =    response . getDeleted (  )  ;", "}", "@ Override", "public   void   onFailure ( Exception   e )     {", "}", "}  )  ;", "}", "METHOD_END"], "methodName": ["deleteByQuery"], "fileName": "org.elasticsearch.client.documentation.ReindexDocumentationIT"}, {"methodBody": ["METHOD_START", "{", "Client   client    =    client (  )  ;", "BulkByScrollResponse   response    =    INSTANCE . newRequestBuilder ( client )  . destination (  \" target _ index \"  )  . filter ( QueryBuilders . matchQuery (  \" category \"  ,     \" xzy \"  )  )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["reindex"], "fileName": "org.elasticsearch.client.documentation.ReindexDocumentationIT"}, {"methodBody": ["METHOD_START", "{", "Client   client    =    client (  )  ;", "{", "UpdateByQueryRequestBuilder   updateByQuery    =    INSTANCE . newRequestBuilder ( client )  ;", "updateByQuery . source (  \" source _ index \"  )  . abortOnVersionConflict ( false )  ;", "BulkByScrollResponse   response    =    updateByQuery . get (  )  ;", "}", "{", "UpdateByQueryRequestBuilder   updateByQuery    =    INSTANCE . newRequestBuilder ( client )  ;", "updateByQuery . source (  \" source _ index \"  )  . filter ( QueryBuilders . termQuery (  \" level \"  ,     \" awesome \"  )  )  . size (  1  0  0  0  )  . script ( new   script . Script ( ScriptType . INLINE ,     \" ctx .  _ source . awesome    =     ' absolutely '  \"  ,     \" painless \"  ,    Collections . emptyMap (  )  )  )  ;", "BulkByScrollResponse   response    =    updateByQuery . get (  )  ;", "}", "{", "UpdateByQueryRequestBuilder   updateByQuery    =    INSTANCE . newRequestBuilder ( client )  ;", "updateByQuery . source (  \" source _ index \"  )  . source (  )  . setSize (  5  0  0  )  ;", "BulkByScrollResponse   response    =    updateByQuery . get (  )  ;", "}", "{", "UpdateByQueryRequestBuilder   updateByQuery    =    INSTANCE . newRequestBuilder ( client )  ;", "updateByQuery . source (  \" source _ index \"  )  . size (  1  0  0  )  . source (  )  . addSort (  \" cat \"  ,    DESC )  ;", "BulkByScrollResponse   response    =    updateByQuery . get (  )  ;", "}", "{", "UpdateByQueryRequestBuilder   updateByQuery    =    INSTANCE . newRequestBuilder ( client )  ;", "updateByQuery . source (  \" source _ index \"  )  . script ( new   script . Script ( ScriptType . INLINE ,     (  \" if    ( ctx .  _ source . awesome    =  =     ' absolutely )     {  \"     +     (  (  (  (  \"       ctx . op =  ' noop '  \"     +     \"  }    else   if    ( ctx .  _ source . awesome    =  =     ' lame '  )     {  \"  )     +     \"       ctx . op =  ' delete '  \"  )     +     \"  }    else    {  \"  )     +     \" ctx .  _ source . awesome    =     ' absolutely '  }  \"  )  )  ,     \" painless \"  ,    Collections . emptyMap (  )  )  )  ;", "BulkByScrollResponse   response    =    updateByQuery . get (  )  ;", "}", "{", "UpdateByQueryRequestBuilder   updateByQuery    =    INSTANCE . newRequestBuilder ( client )  ;", "updateByQuery . source (  \" foo \"  ,     \" bar \"  )  . source (  )  . setTypes (  \" a \"  ,     \" b \"  )  ;", "BulkByScrollResponse   response    =    updateByQuery . get (  )  ;", "}", "{", "UpdateByQueryRequestBuilder   updateByQuery    =    INSTANCE . newRequestBuilder ( client )  ;", "updateByQuery . source (  )  . setRouting (  \" cat \"  )  ;", "BulkByScrollResponse   response    =    updateByQuery . get (  )  ;", "}", "{", "UpdateByQueryRequestBuilder   updateByQuery    =    INSTANCE . newRequestBuilder ( client )  ;", "updateByQuery . setPipeline (  \" hurray \"  )  ;", "BulkByScrollResponse   response    =    updateByQuery . get (  )  ;", "}", "{", "ListTasksResponse   tasksList    =    client . admin (  )  . cluster (  )  . prepareListTasks (  )  . setActions ( NAME )  . setDetailed ( true )  . get (  )  ;", "for    ( TaskInfo   info    :    tasksList . getTasks (  )  )     {", "TaskId   taskId    =    info . getTaskId (  )  ;", "BulkByScrollTask . Status   status    =     (  ( BulkByScrollTask . Status )     ( info . getStatus (  )  )  )  ;", "}", "}", "{", "TaskId   taskId    =    null ;", "GetTaskResponse   get    =    client . admin (  )  . cluster (  )  . prepareGetTask ( taskId )  . get (  )  ;", "}", "{", "TaskId   taskId    =    null ;", "client . admin (  )  . cluster (  )  . prepareCancelTasks (  )  . setActions ( NAME )  . get (  )  . getTasks (  )  ;", "client . admin (  )  . cluster (  )  . prepareCancelTasks (  )  . setTaskId ( taskId )  . get (  )  . getTasks (  )  ;", "}", "{", "TaskId   taskId    =    null ;", "RethrottleAction . INSTANCE . newRequestBuilder ( client )  . setTaskId ( taskId )  . setRequestsPerSecond (  2  .  0 F )  . get (  )  ;", "}", "}", "METHOD_END"], "methodName": ["updateByQuery"], "fileName": "org.elasticsearch.client.documentation.ReindexDocumentationIT"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   Accessroller . doPrivileged (  (  ( PrivilegedExceptionAction < InputStream >  )     ( url :  : openStream )  )  )  ;", "}    catch    ( PrivilegedActionException   e )     {", "throw    (  ( IOException )     ( e . getCause (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getInputStream"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobContainer"}, {"methodBody": ["METHOD_START", "{", "return   this . path ;", "}", "METHOD_END"], "methodName": ["url"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobContainer"}, {"methodBody": ["METHOD_START", "{", "return   this . bufferSizeInBytes ;", "}", "METHOD_END"], "methodName": ["bufferSizeInBytes"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobStore"}, {"methodBody": ["METHOD_START", "{", "String [  ]    paths    =    path . toArray (  )  ;", "if    (  ( paths . length )     =  =     0  )     {", "return   path (  )  ;", "}", "URL   Path    =    new   URL ( this . path ,     (  ( paths [  0  ]  )     +     \"  /  \"  )  )  ;", "if    (  ( paths . length )     >     1  )     {", "for    ( int   i    =     1  ;    i    <     ( paths . length )  ;    i +  +  )     {", "Path    =    new   URL ( Path ,     (  ( paths [ i ]  )     +     \"  /  \"  )  )  ;", "}", "}", "return   Path ;", "}", "METHOD_END"], "methodName": ["buildPath"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobStore"}, {"methodBody": ["METHOD_START", "{", "return   path ;", "}", "METHOD_END"], "methodName": ["path"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobStore"}, {"methodBody": ["METHOD_START", "{", "for    ( int   i    =     0  ;    i    <     ( URLBlobStoreTests . message . length )  ;     +  + i )     {", "URLBlobStoreTests . message [ i ]     =    randomByte (  )  ;", "}", "URLBlobStoreTests . blobName    =    randomAlphaOfLength (  8  )  ;", "URLBlobStoreTests . httpServer    =    MockHttpServer . createHttp ( new   InetSocketAddress ( InetAddress . getLoopbackAddress (  )  . getHostAddress (  )  ,     6  0  0  1  )  ,     0  )  ;", "URLBlobStoreTests . httpServer . createContext (  (  \"  / indices /  \"     +     ( URLBlobStoreTests . blobName )  )  ,     (    s )     -  >     {", "s . sendResponseHeaders (  2  0  0  ,    URLBlobStoreTests . message . length )  ;", "OutputStream   responseBody    =    s . getResponseBody (  )  ;", "responseBody . write ( URLBlobStoreTests . message )  ;", "responseBody . close (  )  ;", "}  )  ;", "URLBlobStoreTests . httpServer . start (  )  ;", "}", "METHOD_END"], "methodName": ["startHttp"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobStoreTests"}, {"methodBody": ["METHOD_START", "{", "URLBlobStoreTests . httpServer . stop (  0  )  ;", "URLBlobStoreTests . httpServer    =    null ;", "}", "METHOD_END"], "methodName": ["stopHttp"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobStoreTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . EMPTY ;", "String   spec    =     \" http :  /  / localhost :  6  0  0  1  /  \"  ;", "urlBlobStore    =    new    ( settings ,    new   URL ( spec )  )  ;", "}", "METHOD_END"], "methodName": ["storeSetup"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobStoreTests"}, {"methodBody": ["METHOD_START", "{", "BlobContainer   container    =    urlBlobStore . blobContainer ( BlobPath . cleanPath (  )  . add (  \" indices \"  )  )  ;", "String   incorrectBlobName    =     \" incorrect _  \"     +     (  . blobName )  ;", "try    ( InputStream   ignored    =    container . readBlob ( incorrectBlobName )  )     {", "fail (  \" Should   have   thrown   NoSuchFileException   exception \"  )  ;", "ignored . read (  )  ;", "}    catch    ( NoSuchFileException   e )     {", "assertEquals ( String . format (  \"  [  % s ]    blob   not   found \"  ,    incorrectBlobName )  ,    e . getMessage (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testNoBlobFound"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobStoreTests"}, {"methodBody": ["METHOD_START", "{", "BlobContainer   container    =    urlBlobStore . blobContainer ( BlobPath . cleanPath (  )  . add (  \" indices \"  )  )  ;", "try    ( InputStream   stream    =    container . readBlob (  . blobName )  )     {", "byte [  ]    bytes    =    new   byte [  . message . length ]  ;", "int   read    =    stream . read ( bytes )  ;", "assertEquals (  . message . length ,    read )  ;", "assertArrayEquals (  . message ,    bytes )  ;", "}", "}", "METHOD_END"], "methodName": ["testURLBlobStoreCanReadBlob"], "fileName": "org.elasticsearch.common.blobstore.url.URLBlobStoreTests"}, {"methodBody": ["METHOD_START", "{", "networkService    =    new   NetworkService ( Collections . emptyList (  )  )  ;", "bigArrays    =    new   common . util . MockBigArrays ( new   common . util . MockPageCacheRecycler ( Settings . EMPTY )  ,    new   NoneCircuitBreakerService (  )  )  ;", "threadPool    =    new   TestThreadPool (  \" test \"  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.http.netty4.Netty4BadRequestTests"}, {"methodBody": ["METHOD_START", "{", "terminate ( threadPool )  ;", "}", "METHOD_END"], "methodName": ["shutdown"], "fileName": "org.elasticsearch.http.netty4.Netty4BadRequestTests"}, {"methodBody": ["METHOD_START", "{", "final   HttpServerTransport . Dispatcher   dispatcher    =    new   HttpServerTransport . Dispatcher (  )     {", "@ Override", "public   void   dispatchRequest ( RestRequest   request ,    RestChannel   channel ,    ThreadContext   threadContext )     {", "fail (  )  ;", "}", "@ Override", "public   void   dispatchBadRequest ( RestRequest   request ,    RestChannel   channel ,    ThreadContext   threadContext ,    Throwable   cause )     {", "try    {", "final   Exception   e    =     ( cause   instanceof   Exception )     ?     (  ( Exception )     ( cause )  )     :    new   ElasticsearchException ( cause )  ;", "channel . sendResponse ( new   rest . BytesRestResponse ( channel ,    rest . RestStatus . BAD _ REQUEST ,    e )  )  ;", "}    catch    ( final   IOException   e )     {", "throw   new   UncheckedIOException ( e )  ;", "}", "}", "}  ;", "try    ( HttpServerTransport   httpServerTransport    =    new   Netty 4 HttpServerTransport ( Settings . EMPTY ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    dispatcher )  )     {", "httpServerTransport . start (  )  ;", "final   TransportAddress   transportAddress    =    randomFrom ( httpServerTransport . boundAddress (  )  . boundAddresses (  )  )  ;", "try    ( Netty 4 HttpClient   nettyHttpClient    =    new   Netty 4 HttpClient (  )  )     {", "final   Collection < FullHttpResponse >    responses    =    nettyHttpClient . get ( transportAddress . address (  )  ,     \"  /  _ cluster / settings ? pretty =  %  \"  )  ;", "assertThat ( responses ,    hasSize (  1  )  )  ;", "assertThat ( responses . iterator (  )  . next (  )  . status (  )  . code (  )  ,    equalTo (  4  0  0  )  )  ;", "final   Collection < String >    responseBodies    =    Netty 4 HttpClient . returnHttpResponseBodies ( responses )  ;", "assertThat ( responseBodies ,    hasSize (  1  )  )  ;", "assertThat ( responseBodies . iterator (  )  . next (  )  ,    containsString (  \"  \\  \" type \\  \"  :  \\  \" bad _ parameter _ exception \\  \"  \"  )  )  ;", "assertThat ( responseBodies . iterator (  )  . next (  )  ,    containsString (  \"  \\  \" reason \\  \"  :  \\  \" IllegalArgumentException :    unterminated   escape   sequence   at   end   of   string :     %  \\  \"  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testBadParameterEncoding"], "fileName": "org.elasticsearch.http.netty4.Netty4BadRequestTests"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.http.netty4.Netty4ClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "if    ( transport . resetCookies )     {", "String   cookieString    =    Request . headers (  )  . get ( COOKIE )  ;", "if    ( cookieString    !  =    null )     {", "Set < Cookie >    cookies    =    STRICT . decode ( cookieString )  ;", "if    (  !  ( cookies . isEmpty (  )  )  )     {", "resp . headers (  )  . set ( SET _ COOKIE ,    ServerCookieEncoder . STRICT . encode ( cookies )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["addCookies"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannel"}, {"methodBody": ["METHOD_START", "{", "if    ( customHeaders    !  =    null )     {", "for    ( Map . Entry < String ,    List < String >  >    headerEntry    :    customHeaders . entrySet (  )  )     {", "for    ( String   headerValue    :    headerEntry . getValue (  )  )     {", "setHeaderField ( response ,    headerEntry . getKey (  )  ,    headerValue )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["addCustomHeaders"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannel"}, {"methodBody": ["METHOD_START", "{", "return   Netty 4 HttpChannel . MAP . getOrDefault ( status ,    INTERNAL _ SERVER _ ERROR )  ;", "}", "METHOD_END"], "methodName": ["getStatus"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannel"}, {"methodBody": ["METHOD_START", "{", "final   boolean   http 1  0     =    isHttp 1  0  (  )  ;", "return    ( CLOSE . contentEqualsIgnoreCase ( Request . headers (  )  . get ( CONNECTION )  )  )     |  |     ( http 1  0     &  &     (  !  ( KEEP _ ALIVE . contentEqualsIgnoreCase ( Request . headers (  )  . get ( CONNECTION )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["isCloseConnection"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannel"}, {"methodBody": ["METHOD_START", "{", "return   nettyRequest . protocolVersion (  )  . equals ( HTTP _  1  _  0  )  ;", "}", "METHOD_END"], "methodName": ["isHttp10"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannel"}, {"methodBody": ["METHOD_START", "{", "final   boolean 0     =    isHttp 1  0  (  )  ;", "final   boolean   close    =    isCloseConnection (  )  ;", "final   HttpResponseStatus   status    =    HttpResponseStatus . OK ;", "final   FullHttpResponse   response ;", "if    0  )     {", "response    =    new   io . netty . handler . codecDefaultFullHttpResponse ( HttpVersion . HTTP _  1  _  0  ,    status ,    buffer )  ;", "if    (  ! close )     {", "response . headers (  )  . add ( CONNECTION ,     \" Keep - Alive \"  )  ;", "}", "} else    {", "response    =    new   io . netty . handler . codecDefaultFullHttpResponse ( HttpVersion . HTTP _  1  _  1  ,    status ,    buffer )  ;", "}", "return   response ;", "}", "METHOD_END"], "methodName": ["newResponse"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannel"}, {"methodBody": ["METHOD_START", "{", "setHeaderField ( resp ,    headerField ,    value ,    true )  ;", "}", "METHOD_END"], "methodName": ["setHeaderField"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannel"}, {"methodBody": ["METHOD_START", "{", "if    ( override    |  |     (  !  ( resp . headers (  )  . contains ( headerField )  )  )  )     {", "resp . headers (  )  . add ( headerField ,    value )  ;", "}", "}", "METHOD_END"], "methodName": ["setHeaderField"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannel"}, {"methodBody": ["METHOD_START", "{", "return   executeRequest ( settings ,    null ,    host )  ;", "}", "METHOD_END"], "methodName": ["executeRequest"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "try    ( Netty 4 HttpServerTransport   httpServerTransport    =    new   Netty 4 HttpServerTransport ( settings ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    new   NullDispatcher (  )  )  )     {", "httpServerTransport . start (  )  ;", "final   FullHttpRequest   httpRequest    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . GET ,     \"  /  \"  )  ;", "if    ( originValue    !  =    null )     {", "httpRequest . headers (  )  . add ( ORIGIN ,    originValue )  ;", "}", "httpRequest . headers (  )  . add ( HOST ,    host )  ;", "final    . WriteCapturingChannel   writeCapturingChannel    =    new    . WriteCapturingChannel (  )  ;", "final   Netty 4 HttpRequest   request    =    new   Netty 4 HttpRequest ( xContentRegistry (  )  ,    httpRequest ,    writeCapturingChannel )  ;", "Netty 4 HttpChannel   channel    =    new   Netty 4 HttpChannel ( httpServerTransport ,    request ,    null ,    randomBoolean (  )  ,    threadPool . getThreadContext (  )  )  ;", "channel . sendResponse ( new    . TestResponse (  )  )  ;", "List < Object >    writtenObjects    =    writeCapturingChannel . getWrittenObjects (  )  ;", "assertThat ( writtenObjects . size (  )  ,    is (  1  )  )  ;", "return    (  ( FullHttpResponse )     ( writtenObjects . get (  0  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["executeRequest"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "networkService    =    new   NetworkService ( Collections . emptyList (  )  )  ;", "threadPool    =    new   TestThreadPool (  \" test \"  )  ;", "bigArrays    =    new   common . util . MockBigArrays ( new   common . util . MockPageCacheRecycler ( Settings . EMPTY )  ,    new   NoneCircuitBreakerService (  )  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( threadPool )     !  =    null )     {", "threadPool . shutdownNow (  )  ;", "}", "}", "METHOD_END"], "methodName": ["shutdown"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "final   Settings   settings    =    Settings . builder (  )  . build (  )  ;", "try    ( Netty 4 HttpServerTransport   httpServerTransport    =    new   Netty 4 HttpServerTransport ( settings ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    new   NullDispatcher (  )  )  )     {", "httpServerTransport . start (  )  ;", "final   FullHttpRequest   httpRequest ;", "final   boolean   close    =    randomBoolean (  )  ;", "if    ( randomBoolean (  )  )     {", "httpRequest    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . GET ,     \"  /  \"  )  ;", "if    ( close )     {", "httpRequest . headers (  )  . add ( CONNECTION ,    CLOSE )  ;", "}", "} else    {", "httpRequest    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  0  ,    HttpMethod . GET ,     \"  /  \"  )  ;", "if    (  ! close )     {", "httpRequest . headers (  )  . add ( CONNECTION ,    KEEP _ ALIVE )  ;", "}", "}", "final   EmbeddedChannel   embeddedChannel    =    new   EmbeddedChannel (  )  ;", "final   Netty 4 HttpRequest   request    =    new   Netty 4 HttpRequest ( xContentRegistry (  )  ,    httpRequest ,    embeddedChannel )  ;", "assertTrue ( embeddedChannel . isOpen (  )  )  ;", "final   Netty 4 HttpChannel   channel    =    new   Netty 4 HttpChannel ( httpServerTransport ,    request ,    null ,    randomBoolean (  )  ,    threadPool . getThreadContext (  )  )  ;", "final    . TestResponse   resp    =    new    . TestResponse (  )  ;", "channel . sendResponse ( resp )  ;", "assertThat ( embeddedChannel . isOpen (  )  ,    equalTo (  (  ! close )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConnectionClose"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "String   originValue    =     \" remote - host \"  ;", "String   host    =     \" remote - host \"  ;", "Settings   settings    =    Settings . builder (  )  . put ( TransportSettings . SETTING _ CORS _ ENABLED . getKey (  )  ,    true )  . build (  )  ;", "Response   response    =    executeRequest ( settings ,    originValue ,    host )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ,    notNullValue (  )  )  ;", "String   allowedOrigins    =    response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ;", "assertThat ( allowedOrigins ,    is ( originValue )  )  ;", "originValue    =     \" http :  /  /  \"     +    originValue ;", "response    =    executeRequest ( settings ,    originValue ,    host )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ,    notNullValue (  )  )  ;", "allowedOrigins    =    response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ;", "assertThat ( allowedOrigins ,    is ( originValue )  )  ;", "originValue    =    originValue    +     \"  :  5  5  5  5  \"  ;", "host    =    host    +     \"  :  5  5  5  5  \"  ;", "response    =    executeRequest ( settings ,    originValue ,    host )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ,    notNullValue (  )  )  ;", "allowedOrigins    =    response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ;", "assertThat ( allowedOrigins ,    is ( originValue )  )  ;", "originValue    =    originValue . replace (  \" http \"  ,     \" https \"  )  ;", "response    =    executeRequest ( settings ,    originValue ,    host )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ,    notNullValue (  )  )  ;", "allowedOrigins    =    response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ;", "assertThat ( allowedOrigins ,    is ( originValue )  )  ;", "}", "METHOD_END"], "methodName": ["testCorsAllowOriginWithSameHost"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "final   String   originValue    =     \" remote - host \"  ;", "Settings   settings    =    Settings . builder (  )  . put ( TransportSettings . SETTING _ CORS _ ENABLED . getKey (  )  ,    true )  . put ( TransportSettings . SETTING _ CORS _ ALLOW _ ORIGIN . getKey (  )  ,    originValue )  . build (  )  ;", "Response   response    =    executeRequest ( settings ,    originValue ,     \" request - host \"  )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ,    notNullValue (  )  )  ;", "String   allowedOrigins    =    response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ;", "assertThat ( allowedOrigins ,    is ( originValue )  )  ;", "}", "METHOD_END"], "methodName": ["testCorsEnabledWithAllowOrigins"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put ( SETTING _ CORS _ ENABLED . getKey (  )  ,    true )  . build (  )  ;", "Response   response    =    executeRequest ( settings ,     \" remote - host \"  ,     \" request - host \"  )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCorsEnabledWithoutAllowOrigins"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . build (  )  ;", "try    ( Netty 4 HttpServerTransport   httpServerTransport    =    new   Netty 4 HttpServerTransport ( settings ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    new   NullDispatcher (  )  )  )     {", "httpServerTransport . start (  )  ;", "final   FullHttpRequest   httpRequest    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . GET ,     \"  /  \"  )  ;", "httpRequest . headers (  )  . add ( ORIGIN ,     \" remote \"  )  ;", "final    . WriteCapturingChannel   writeCapturingChannel    =    new    . WriteCapturingChannel (  )  ;", "Netty 4 HttpRequest   request    =    new   Netty 4 HttpRequest ( xContentRegistry (  )  ,    httpRequest ,    writeCapturingChannel )  ;", "Netty 4 HttpChannel   channel    =    new   Netty 4 HttpChannel ( httpServerTransport ,    request ,    null ,    randomBoolean (  )  ,    threadPool . getThreadContext (  )  )  ;", ". TestResponse   resp    =    new    . TestResponse (  )  ;", "final   String   customHeader    =     \" custom - header \"  ;", "final   String   customHeaderValue    =     \" xyz \"  ;", "resp . addHeader ( customHeader ,    customHeaderValue )  ;", "channel . sendResponse ( resp )  ;", "List < Object >    writtenObjects    =    writeCapturingChannel . getWrittenObjects (  )  ;", "assertThat ( writtenObjects . size (  )  ,    is (  1  )  )  ;", "HttpResponse   response    =     (  ( HttpResponse )     ( writtenObjects . get (  0  )  )  )  ;", "assertThat ( response . headers (  )  . get (  \" non - existent - header \"  )  ,    nullValue (  )  )  ;", "assertThat ( response . headers (  )  . get ( customHeader )  ,    equalTo ( customHeaderValue )  )  ;", "assertThat ( response . headers (  )  . get ( CONTENT _ LENGTH )  ,    equalTo ( Integer . toString ( resp . content (  )  . length (  )  )  )  )  ;", "assertThat ( response . headers (  )  . get ( CONTENT _ TYPE )  ,    equalTo ( resp . contentType (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testHeadersSet"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "final   Settings   settings    =    Settings . builder (  )  . build (  )  ;", "final   NamedXContentRegistry   registry    =    xContentRegistry (  )  ;", "try    ( Netty 4 HttpServerTransport   httpServerTransport    =    new   Netty 4 HttpServerTransport ( settings ,    networkService ,    bigArrays ,    threadPool ,    registry ,    new   NullDispatcher (  )  )  )     {", "final   FullHttpRequest   httpRequest    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . GET ,     \"  /  \"  )  ;", "final   EmbeddedChannel   embeddedChannel    =    new   EmbeddedChannel (  )  ;", "final   Netty 4 HttpRequest   request    =    new   Netty 4 HttpRequest ( registry ,    httpRequest ,    embeddedChannel )  ;", "final   HttpPipelinedRequest   pipelinedRequest    =     ( randomBoolean (  )  )     ?    new   HttpPipelinedRequest ( request . request (  )  ,     1  )     :    null ;", "final   Netty 4 HttpChannel   channel    =    new   Netty 4 HttpChannel ( httpServerTransport ,    request ,    pipelinedRequest ,    randomBoolean (  )  ,    threadPool . getThreadContext (  )  )  ;", "final   BytesRestResponse   response    =    new   BytesRestResponse ( rest . RestStatus . INTERNAL _ SERVER _ ERROR ,    JsonXContent . contentBuilder (  )  . startObject (  )  . endObject (  )  )  ;", "assertThat ( response . content (  )  ,    not ( instanceOf ( Releasable . class )  )  )  ;", "if    ( randomBoolean (  )  )     {", "BytesStreamOutput   out    =    channel . bytesOutput (  )  ;", "assertThat ( out ,    instanceOf ( ReleasableBytesStreamOutput . class )  )  ;", "} else    {", "try    ( XContentBuilder   builder    =    channel . newBuilder (  )  )     {", "builder . startObject (  )  . endObject (  )  ;", "}", "}", "channel . sendResponse ( response )  ;", "}", "}", "METHOD_END"], "methodName": ["testReleaseOnSendToChannelAfterException"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "final   Settings   settings    =    Settings . builder (  )  . build (  )  ;", "final   NamedXContentRegistry   registry    =    xContentRegistry (  )  ;", "try    ( Netty 4 HttpServerTransport   httpServerTransport    =    new   Netty 4 HttpServerTransport ( settings ,    networkService ,    bigArrays ,    threadPool ,    registry ,    new   NullDispatcher (  )  )  )     {", "final   FullHttpRequest   httpRequest    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . GET ,     \"  /  \"  )  ;", "final   EmbeddedChannel   embeddedChannel    =    new   EmbeddedChannel (  )  ;", "final   Netty 4 HttpRequest   request    =    new   Netty 4 HttpRequest ( registry ,    httpRequest ,    embeddedChannel )  ;", "final   HttpPipelinedRequest   pipelinedRequest    =     ( randomBoolean (  )  )     ?    new   HttpPipelinedRequest ( request . request (  )  ,     1  )     :    null ;", "final   Netty 4 HttpChannel   channel    =    new   Netty 4 HttpChannel ( httpServerTransport ,    request ,    pipelinedRequest ,    randomBoolean (  )  ,    threadPool . getThreadContext (  )  )  ;", "final    . TestResponse   response    =    new    . TestResponse ( bigArrays )  ;", "assertThat ( response . content (  )  ,    instanceOf ( Releasable . class )  )  ;", "embeddedChannel . close (  )  ;", "channel . sendResponse ( response )  ;", "}", "}", "METHOD_END"], "methodName": ["testReleaseOnSendToClosedChannel"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "final   FullHttpResponse   response    =    executeRequest ( EMPTY ,     \" request - host \"  )  ;", "assertThat ( response . content (  )  ,    equalTo ( Netty 4 Utils . toByteBuf ( new    . TestResponse (  )  . content (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testResponse"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "final   String   originValue    =    Netty 4 CorsHandler . ANY _ ORIGIN ;", "Settings   settings    =    Settings . builder (  )  . put ( HttpTransportSettings . SETTING _ CORS _ ENABLED . getKey (  )  ,    true )  . put ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ ORIGIN . getKey (  )  ,    originValue )  . build (  )  ;", "HttpResponse   response    =    executeRequest ( settings ,    originValue ,     \" request - host \"  )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ,    notNullValue (  )  )  ;", "String   allowedOrigins    =    response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ;", "assertThat ( allowedOrigins ,    is ( originValue )  )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ CREDENTIALS )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatAnyOriginWorks"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "final   String   originValue    =     \" remote - host \"  ;", "Settings   settings    =    Settings . builder (  )  . put ( TransportSettings . SETTING _ CORS _ ENABLED . getKey (  )  ,    true )  . put ( TransportSettings . SETTING _ CORS _ ALLOW _ ORIGIN . getKey (  )  ,    originValue )  . put ( TransportSettings . SETTING _ CORS _ ALLOW _ METHODS . getKey (  )  ,     \" get ,    options ,    post \"  )  . put ( TransportSettings . SETTING _ CORS _ ALLOW _ CREDENTIALS . getKey (  )  ,    true )  . build (  )  ;", "Response   response    =    executeRequest ( settings ,    originValue ,     \" request - host \"  )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ,    notNullValue (  )  )  ;", "String   allowedOrigins    =    response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  ;", "assertThat ( allowedOrigins ,    is ( originValue )  )  ;", "assertThat ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ CREDENTIALS )  ,    equalTo (  \" true \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatStringLiteralWorksOnMatch"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpChannelTests"}, {"methodBody": ["METHOD_START", "{", "Collection < HttpRequest >    requests    =    new   ArrayList <  >  ( uris . length )  ;", "for    ( int   i    =     0  ;    i    <     ( uris . length )  ;    i +  +  )     {", "final   HttpRequestequest    =    new   io . netty . handler . codecDefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . GET ,    uris [ i ]  )  ;", "equest . headers (  )  . add ( HttpHeaderNames . HOST ,     \" localhost \"  )  ;", "equest . headers (  )  . add (  \" X - Opaque - ID \"  ,    String . valueOf ( i )  )  ;", "requests . addequest )  ;", "}", "return   sendRequests ( remoteAddress ,    requests )  ;", "}", "METHOD_END"], "methodName": ["get"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpClient"}, {"methodBody": ["METHOD_START", "{", "Collection < FullHttpResponse >    responses    =    sendRequests ( remoteAddress ,    Collections . singleton ( httpRequest )  )  ;", "assert    ( responses . size (  )  )     =  =     1     :     \" expected    1    and   only    1    http   response \"  ;", "return   responses . iterator (  )  . next (  )  ;", "}", "METHOD_END"], "methodName": ["post"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpClient"}, {"methodBody": ["METHOD_START", "{", "return   processRequestsWithBody ( POST ,    remoteAddress ,    urisAndBodies )  ;", "}", "METHOD_END"], "methodName": ["post"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpClient"}, {"methodBody": ["METHOD_START", "{", "Collection < HttpRequest >    requests    =    new   ArrayList ( urisAndBodies . length )  ;", "for    ( Tuple < String ,    CharSequence >    uriAndBody    :    urisAndBodies )     {", "ByteBuf   content    =    Unpooled . copiedBuffer ( uriAndBody . v 2  (  )  ,    StandardCharsets . UTF _  8  )  ;", "HttpRequest   request    =    new   io . netty . handler . codecDefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    method ,    uriAndBody . v 1  (  )  ,    content )  ;", "request . headers (  )  . add ( HOST ,     \" localhost \"  )  ;", "request . headers (  )  . add ( CONTENT _ LENGTH ,    content . readableBytes (  )  )  ;", "request . headers (  )  . add ( CONTENT _ TYPE ,     \" application / json \"  )  ;", "requests . add ( request )  ;", "}", "return   sendRequests ( remoteAddress ,    requests )  ;", "}", "METHOD_END"], "methodName": ["processRequestsWithBody"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpClient"}, {"methodBody": ["METHOD_START", "{", "return   processRequestsWithBody ( PUT ,    remoteAddress ,    urisAndBodies )  ;", "}", "METHOD_END"], "methodName": ["put"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpClient"}, {"methodBody": ["METHOD_START", "{", "List < String >    list    =    new   ArrayList ( responses . size (  )  )  ;", "for    ( FullResponse   response    :    responses )     {", "list . add ( response . content (  )  . toString ( StandardCharsets . UTF _  8  )  )  ;", "}", "return   list ;", "}", "METHOD_END"], "methodName": ["returnHttpResponseBodies"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpClient"}, {"methodBody": ["METHOD_START", "{", "List < String >    list    =    new   ArrayList ( responses . size (  )  )  ;", "for    ( Response   response    :    responses )     {", "list . add ( response . headers (  )  . get (  \" X - Opaque - Id \"  )  )  ;", "}", "return   list ;", "}", "METHOD_END"], "methodName": ["returnOpaqueIds"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpClient"}, {"methodBody": ["METHOD_START", "{", "final   CountDownLatch   latch    =    new   CountDownLatch ( requests . size (  )  )  ;", "final   Collection < FullHttpResponse >    content    =    Collections . synchronizedList ( new   ArrayList ( requests . size (  )  )  )  ;", "clientBootstrap . handler ( new    . CountDownLatchHandler ( latch ,    content )  )  ;", "ChannelFuture   channelFuture    =    null ;", "try    {", "channelFuture    =    clientBootstrap . connect ( remoteAddress )  ;", "channelFuture . sync (  )  ;", "for    ( HttpRequest   request    :    requests )     {", "channelFuture . channel (  )  . writeAndFlush ( request )  ;", "}", "latch . await (  3  0  ,    TimeUnit . SECONDS )  ;", "}    finally    {", "if    ( channelFuture    !  =    null )     {", "channelFuture . channel (  )  . close (  )  . sync (  )  ;", "}", "}", "return   content ;", "}", "METHOD_END"], "methodName": ["sendRequests"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpClient"}, {"methodBody": ["METHOD_START", "{", "return   new   TransportAddress ( InetAddress . getByName ( host )  ,    port )  ;", "}", "METHOD_END"], "methodName": ["address"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpPublishPortTests"}, {"methodBody": ["METHOD_START", "{", "return   address (  (  \"  1  2  7  .  0  .  0  .  \"     +     ( randomIntBetween (  1  ,     1  0  0  )  )  )  ,    randomIntBetween (  9  2  0  0  ,     9  3  0  0  )  )  ;", "}", "METHOD_END"], "methodName": ["randomAddress"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpPublishPortTests"}, {"methodBody": ["METHOD_START", "{", "List < TransportAddress >    addresses    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( randomIntBetween (  1  ,     5  )  )  ;    i +  +  )     {", "addresses . add ( randomAddress (  )  )  ;", "}", "return   addresses ;", "}", "METHOD_END"], "methodName": ["randomAddresses"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpPublishPortTests"}, {"methodBody": ["METHOD_START", "{", "int   boundPort    =    randomIntBetween (  9  0  0  0  ,     9  1  0  0  )  ;", "int   otherBoundPort    =    randomIntBetween (  9  2  0  0  ,     9  3  0  0  )  ;", "int   publishPort    =    Netty 4 HttpServerTransport . resolve ( Settings . builder (  )  . put ( SETTING _ HTTP _ PUBLISH _ PORT . getKey (  )  ,     9  0  8  0  )  . build (  )  ,    randomAddresses (  )  ,    InetAddress . getByName (  \"  1  2  7  .  0  .  0  .  2  \"  )  )  ;", "assertThat (  \" Publish   port   should   be   explicitly   set   to    9  0  8  0  \"  ,    publishPort ,    equalTo (  9  0  8  0  )  )  ;", "publishPort    =    Netty 4 HttpServerTransport . resolve ( EMPTY ,    Arrays . asList ( address (  \"  1  2  7  .  0  .  0  .  1  \"  ,    boundPort )  ,    address (  \"  1  2  7  .  0  .  0  .  2  \"  ,    otherBoundPort )  )  ,    InetAddress . getByName (  \"  1  2  7  .  0  .  0  .  1  \"  )  )  ;", "assertThat (  \" Publish   port   should   be   derived   from   matched   address \"  ,    publishPort ,    equalTo ( boundPort )  )  ;", "publishPort    =    Netty 4 HttpServerTransport . resolve ( EMPTY ,    Arrays . asList ( address (  \"  1  2  7  .  0  .  0  .  1  \"  ,    boundPort )  ,    address (  \"  1  2  7  .  0  .  0  .  2  \"  ,    boundPort )  )  ,    InetAddress . getByName (  \"  1  2  7  .  0  .  0  .  3  \"  )  )  ;", "assertThat (  \" Publish   port   should   be   derived   from   unique   port   of   bound   addresses \"  ,    publishPort ,    equalTo ( boundPort )  )  ;", "final   BindHttpException   e    =    expectThrows ( BindHttpException . class ,     (  )     -  >    resolve ( Settings . EMPTY ,    asList ( address (  \"  1  2  7  .  0  .  0  .  1  \"  ,    boundPort )  ,    address (  \"  1  2  7  .  0  .  0  .  2  \"  ,    otherBoundPort )  )  ,    getByName (  \"  1  2  7  .  0  .  0  .  3  \"  )  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" Failed   to   auto - resolve   http   publish   port \"  )  )  ;", "publishPort    =    Netty 4 HttpServerTransport . resolve ( EMPTY ,    Arrays . asList ( address (  \"  0  .  0  .  0  .  0  \"  ,    boundPort )  ,    address (  \"  1  2  7  .  0  .  0  .  2  \"  ,    otherBoundPort )  )  ,    InetAddress . getByName (  \"  1  2  7  .  0  .  0  .  1  \"  )  )  ;", "assertThat (  \" Publish   port   should   be   derived   from   matching   wildcard   address \"  ,    publishPort ,    equalTo ( boundPort )  )  ;", "if    ( NetworkUtils . SUPPORTS _ V 6  )     {", "publishPort    =    Netty 4 HttpServerTransport . resolve ( EMPTY ,    Arrays . asList ( address (  \"  0  .  0  .  0  .  0  \"  ,    boundPort )  ,    address (  \"  1  2  7  .  0  .  0  .  2  \"  ,    otherBoundPort )  )  ,    InetAddress . getByName (  \"  :  :  1  \"  )  )  ;", "assertThat (  \" Publish   port   should   be   derived   from   matching   wildcard   address \"  ,    publishPort ,    equalTo ( boundPort )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testHttpPublishPort"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpPublishPortTests"}, {"methodBody": ["METHOD_START", "{", "return   channel ;", "}", "METHOD_END"], "methodName": ["getChannel"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpRequest"}, {"methodBody": ["METHOD_START", "{", "return   this . request ;", "}", "METHOD_END"], "methodName": ["request"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpRequest"}, {"methodBody": ["METHOD_START", "{", "final   HttpHeaders   headersWithoutContentTypeHeader    =    new   DefaultHttpHeaders (  )  ;", "headersWithoutContentTypeHeader . add ( request . headers (  )  )  ;", "headersWithoutContentTypeHeader . remove (  \" Content - Type \"  )  ;", "final   FullHttpRequest   requestWithoutContentTypeHeader    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( request . protocolVersion (  )  ,    request . method (  )  ,    request . uri (  )  ,    request . content (  )  ,    headersWithoutContentTypeHeader ,    request . trailingHeaders (  )  )  ;", "try    {", "return   new    ( serverTransport . xContentRegistry ,    requestWithoutContentTypeHeader ,    channel )  ;", "}    catch    ( final   RestRequest   e )     {", "badRequestCause . addSuppressed ( e )  ;", "return   requestWithoutParameters ( requestWithoutContentTypeHeader ,    channel )  ;", "}", "}", "METHOD_END"], "methodName": ["requestWithoutContentTypeHeader"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpRequestHandler"}, {"methodBody": ["METHOD_START", "{", "return   new   Netty 4 HttpRequest ( serverTransport . xContentRegistry ,    Collections . emptyMap (  )  ,    request . uri (  )  ,    request ,    channel )  ;", "}", "METHOD_END"], "methodName": ["requestWithoutParameters"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpRequestHandler"}, {"methodBody": ["METHOD_START", "{", "long   countUnexpectedStatus    =    responses . stream (  )  . filter (  (    r )     -  >     ( r . status (  )  . equals ( expectedStatus )  )     =  =    false )  . count (  )  ;", "assertThat (  (  (  (  (  \" Expected   all   rs   with   status    [  \"     +    expectedStatus )     +     \"  ]    but    [  \"  )     +    countUnexpectedStatus )     +     \"  ]    rs   had   a   different   one \"  )  ,    countUnexpectedStatus ,    equalTo (  0 L )  )  ;", "}", "METHOD_END"], "methodName": ["assertAllInExpectedStatus"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpRequestSizeLimitIT"}, {"methodBody": ["METHOD_START", "{", "long   countExpectedStatus    =    responses . stream (  )  . filter (  (    r )     -  >    r . status (  )  . equals ( expectedStatus )  )  . count (  )  ;", "assertThat (  (  (  \" Expected   at   least   one   r   with   status    [  \"     +    expectedStatus )     +     \"  ]  \"  )  ,    countExpectedStatus ,    greaterThan (  0 L )  )  ;", "}", "METHOD_END"], "methodName": ["assertAtLeastOnceExpectedStatus"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpRequestSizeLimitIT"}, {"methodBody": ["METHOD_START", "{", "ensureGreen (  )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "Tuple < String ,    CharSequence >  [  ]    requestUris    =    new   Tuple [  1  5  0  0  ]  ;", "for    ( int   i    =     0  ;    i    <     ( requestUris . length )  ;    i +  +  )     {", "requestUris [ i ]     =    Tuple . tuple (  \"  /  _ cluster / settings \"  ,     \"  {     \\  \" transient \\  \"  :     {  \\  \" search . default _ search _ timeout \\  \"  :     \\  \"  4  0 s \\  \"     }     }  \"  )  ;", "}", "HttpServerTransport   httpServerTransport    =    internalCluster (  )  . getInstance ( HttpServerTransport . class )  ;", "TransportAddress   transportAddress    =     (  ( TransportAddress )     ( randomFrom ( httpServerTransport . boundAddress (  )  . boundAddresses (  )  )  )  )  ;", "try    ( Client   nettyHttpClient    =    new   Client (  )  )     {", "Collection < FullHttpResponse >    responses    =    nettyHttpClient . put ( transportAddress . address (  )  ,    requestUris )  ;", "assertThat ( responses ,    hasSize ( requestUris . length )  )  ;", "assertAllInExpectedStatus ( responses ,    OK )  ;", "}", "}", "METHOD_END"], "methodName": ["testDoesNotLimitExcludedRequests"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpRequestSizeLimitIT"}, {"methodBody": ["METHOD_START", "{", "ensureGreen (  )  ;", "int   numRequests    =     (  . LIMIT . bytesAsInt (  )  )     /     1  0  0  ;", "StringBuilder   bulkRequest    =    new   StringBuilder (  )  ;", "for    ( int   i    =     0  ;    i    <    numRequests ;    i +  +  )     {", "bulkRequest . append (  \"  {  \\  \" index \\  \"  :     {  }  }  \"  )  ;", "bulkRequest . append ( System . lineSeparator (  )  )  ;", "bulkRequest . append (  \"  {     \\  \" field \\  \"     :     \\  \" value \\  \"     }  \"  )  ;", "bulkRequest . append ( System . lineSeparator (  )  )  ;", "}", "@ SuppressWarnings (  \" unchecked \"  )", "Tuple < String ,    CharSequence >  [  ]    requests    =    new   Tuple [  1  5  0  ]  ;", "for    ( int   i    =     0  ;    i    <     ( requests . length )  ;    i +  +  )     {", "requests [ i ]     =    Tuple . tuple (  \"  / index / type /  _ bulk \"  ,    bulkRequest )  ;", "}", "HttpServerTransport   httpServerTransport    =    internalCluster (  )  . getInstance ( HttpServerTransport . class )  ;", "TransportAddress   transportAddress    =     (  ( TransportAddress )     ( randomFrom ( httpServerTransport . boundAddress (  )  . boundAddresses (  )  )  )  )  ;", "try    ( Netty 4 HttpClient   nettyHttpClient    =    new   Netty 4 HttpClient (  )  )     {", "Collection < FullHttpResponse >    singleResponse    =    nettyHttpClient . post ( transportAddress . address (  )  ,    requests [  0  ]  )  ;", "assertThat ( singleResponse ,    hasSize (  1  )  )  ;", "assertAtLeastOnceExpectedStatus ( singleResponse ,    OK )  ;", "Collection < FullHttpResponse >    multipleResponses    =    nettyHttpClient . post ( transportAddress . address (  )  ,    requests )  ;", "assertThat ( multipleResponses ,    hasSize ( requests . length )  )  ;", "assertAtLeastOnceExpectedStatus ( multipleResponses ,    SERVICE _ UNAVAILABLE )  ;", "}", "}", "METHOD_END"], "methodName": ["testLimitsInFlightRequests"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpRequestSizeLimitIT"}, {"methodBody": ["METHOD_START", "{", "networkService    =    new   NetworkService ( Collections . emptyList (  )  )  ;", "threadPool    =    new   TestThreadPool (  \" test \"  )  ;", "bigArrays    =    new   common . util . MockBigArrays ( new   common . util . MockPageCacheRecycler ( Settings . EMPTY )  ,    new   NoneCircuitBreakerService (  )  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerPipeliningTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( threadPool )     !  =    null )     {", "threadPool . shutdownNow (  )  ;", "}", "}", "METHOD_END"], "methodName": ["shutdown"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerPipeliningTests"}, {"methodBody": ["METHOD_START", "{", "final   Settings   settings    =    Settings . builder (  )  . put (  \" http . pipelining \"  ,    false )  . put (  \" http . port \"  ,     \"  0  \"  )  . build (  )  ;", "try    ( HttpServerTransport   httpServerTransport    =    new    . CustomNettyHttpServerTransport ( settings )  )     {", "httpServerTransport . start (  )  ;", "final   TransportAddress   transportAddress    =    randomFrom ( httpServerTransport . boundAddress (  )  . boundAddresses (  )  )  ;", "final   int   numberOfRequests    =    randomIntBetween (  4  ,     1  6  )  ;", "final   Set < Integer >    slowIds    =    new   HashSet <  >  (  )  ;", "final   List < String >    requests    =    new   ArrayList <  >  ( numberOfRequests )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "if    ( rarely (  )  )     {", "requests . add (  (  \"  / slow /  \"     +    i )  )  ;", "slowIds . add ( i )  ;", "} else    {", "requests . add (  (  \"  /  \"     +    i )  )  ;", "}", "}", "try    ( Netty 4 HttpClient   nettyHttpClient    =    new   Netty 4 HttpClient (  )  )     {", "Collection < FullHttpResponse >    responses    =    nettyHttpClient . get ( transportAddress . address (  )  ,    requests . toArray ( new   String [  ]  {        }  )  )  ;", "List < String >    responseBodies    =    new   ArrayList ( Netty 4 HttpClient . returnHttpResponseBodies ( responses )  )  ;", "assertThat ( responseBodies ,    hasSize ( numberOfRequests )  )  ;", "for    ( int   i    =     0  ;    i    <     ( numberOfRequests    -     ( slowIds . size (  )  )  )  ;    i +  +  )     {", "assertThat ( responseBodies . get ( i )  ,    matches (  \"  /  \\  \\ d +  \"  )  )  ;", "}", "final   Set < Integer >    ids    =    new   HashSet <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( slowIds . size (  )  )  ;    i +  +  )     {", "final   String   response    =    responseBodies . get (  (  ( numberOfRequests    -     ( slowIds . size (  )  )  )     +    i )  )  ;", "assertThat ( response ,    matches (  \"  / slow /  \\  \\ d +  \"  )  )  ;", "assertTrue ( ids . add ( Integer . parseInt ( response . split (  \"  /  \"  )  [  2  ]  )  )  )  ;", "}", "assertThat ( slowIds ,    equalTo ( ids )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testThatHttpPipeliningCanBeDisabled"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerPipeliningTests"}, {"methodBody": ["METHOD_START", "{", "final   Settings   settings    =    Settings . builder (  )  . put (  \" http . pipelining \"  ,    true )  . put (  \" http . port \"  ,     \"  0  \"  )  . build (  )  ;", "try    ( HttpServerTransport   httpServerTransport    =    new    . CustomNettyHttpServerTransport ( settings )  )     {", "httpServerTransport . start (  )  ;", "final   TransportAddress   transportAddress    =    randomFrom ( httpServerTransport . boundAddress (  )  . boundAddresses (  )  )  ;", "final   int   numberOfRequests    =    randomIntBetween (  4  ,     1  6  )  ;", "final   List < String >    requests    =    new   ArrayList <  >  ( numberOfRequests )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "if    ( rarely (  )  )     {", "requests . add (  (  \"  / slow /  \"     +    i )  )  ;", "} else    {", "requests . add (  (  \"  /  \"     +    i )  )  ;", "}", "}", "try    ( Netty 4 HttpClient   nettyHttpClient    =    new   Netty 4 HttpClient (  )  )     {", "Collection < FullHttpResponse >    responses    =    nettyHttpClient . get ( transportAddress . address (  )  ,    requests . toArray ( new   String [  ]  {        }  )  )  ;", "Collection < String >    responseBodies    =    Netty 4 HttpClient . returnHttpResponseBodies ( responses )  ;", "assertThat ( responseBodies ,    contains ( requests . toArray (  )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testThatHttpPipeliningWorksWhenEnabled"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerPipeliningTests"}, {"methodBody": ["METHOD_START", "{", "final   AtomicReference < Exception >    lastException    =    new   AtomicReference <  >  (  )  ;", "final   AtomicReference < InetSocketAddress >    boundSocket    =    new   AtomicReference <  >  (  )  ;", "boolean   success    =    port . iterate (  (    portNumber )     -  >     {", "try    {", "synchronized ( serverChannels )     {", "ChannelFuture   future    =    serverBootstrap . bind ( new   InetSocketAddress ( hostAddress ,    portNumber )  )  . sync (  )  ;", "serverChannels . add ( future . channel (  )  )  ;", "boundSocket . set (  (  ( InetSocketAddress )     ( future . channel (  )  . localAddress (  )  )  )  )  ;", "}", "}    catch    (    e )     {", "lastException . set ( e )  ;", "return   false ;", "}", "return   true ;", "}  )  ;", "if    (  ! success )     {", "throw   new   BindHttpException (  (  (  \" Failed   to   bind   to    [  \"     +     ( port . getPortRangeString (  )  )  )     +     \"  ]  \"  )  ,    lastException . get (  )  )  ;", "}", "if    ( logger . isDebugEnabled (  )  )     {", "logger . debug (  \" Bound   http   to   address    {  {  }  }  \"  ,    NetworkAddress . format ( boundSocket . get (  )  )  )  ;", "}", "return   new   TransportAddress ( boundSocket . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["bindAddress"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "if    (  ( HttpTransportSettings . SETTING _ CORS _ ENABLED . get ( settings )  )     =  =    false )     {", "return   Netty 4 CorsConfigBuilder . forOrigins (  )  . disable (  )  . build (  )  ;", "}", "String   origin    =    HttpTransportSettings . SETTING _ CORS _ ALLOW _ ORIGIN . get ( settings )  ;", "final   Netty 4 CorsConfigBuilder   builder ;", "if    ( Strings . isNullOrEmpty ( origin )  )     {", "builder    =    Netty 4 CorsConfigBuilder . forOrigins (  )  ;", "} else", "if    ( origin . equals ( cors . Netty 4 CorsHandler . ANY _ ORIGIN )  )     {", "builder    =    Netty 4 CorsConfigBuilder . forAnyOrigin (  )  ;", "} else    {", "Pattern   p    =    checkCorsSettingForRegex ( origin )  ;", "if    ( p    =  =    null )     {", "builder    =    Netty 4 CorsConfigBuilder . forOrigins ( corsSettingAsArray ( origin )  )  ;", "} else    {", "builder    =    Netty 4 CorsConfigBuilder . forPattern ( p )  ;", "}", "}", "if    ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ CREDENTIALS . get ( settings )  )     {", "builder . allowCredentials (  )  ;", "}", "String [  ]    strMethods    =    Strings . tokenizeToStringArray ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ METHODS . get ( settings )  ,     \"  ,  \"  )  ;", "HttpMethod [  ]    methods    =    Arrays . asList ( strMethods )  . stream (  )  . map ( HttpMethod :  : valueOf )  . toArray (  (    size )     -  >    new   HttpMethod [ size ]  )  ;", "return   builder . allowedRequestMethods ( methods )  . maxAge ( HttpTransportSettings . SETTING _ CORS _ MAX _ AGE . get ( settings )  )  . allowedRequestHeaders ( Strings . tokenizeToStringArray ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ HEADERS . get ( settings )  ,     \"  ,  \"  )  )  . shortCircuit (  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["buildCorsConfig"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "return   new   Netty 4 HttpServerTransport . HttpChannelHandler ( this ,    detailedErrorsEnabled ,    threadPool . getThreadContext (  )  )  ;", "}", "METHOD_END"], "methodName": ["configureServerChannelHandler"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "InetAddress [  ]    hostAddresses ;", "try    {", "hostAddresses    =    networkService . resolveBindHostAddresses ( bindHosts )  ;", "}    catch    ( IOException   e )     {", "throw   new   BindHttpException (  (  (  \" Failed   to   resolve   host    [  \"     +     ( Arrays . toString ( bindHosts )  )  )     +     \"  ]  \"  )  ,    e )  ;", "}", "List < TransportAddress >    boundAddresses    =    new   ArrayList <  >  ( hostAddresses . length )  ;", "for    ( InetAddress   address    :    hostAddresses )     {", "boundAddresses . add ( bindAddress ( address )  )  ;", "}", "final   InetAddress   publishInetAddress ;", "try    {", "publishInetAddress    =    networkService . resolvePublishHostAddresses ( publishHosts )  ;", "}    catch    ( Exception   e )     {", "throw   new   BindTransportException (  \" Failed   to   resolve   publish   address \"  ,    e )  ;", "}", "final   int   publishPort    =     . resolvePublishPort ( settings ,    boundAddresses ,    publishInetAddress )  ;", "final   InetSocketAddress   publishAddress    =    new   InetSocketAddress ( publishInetAddress ,    publishPort )  ;", "return   new   BoundTransportAddress ( boundAddresses . toArray ( new   TransportAddress [  0  ]  )  ,    new   TransportAddress ( publishAddress )  )  ;", "}", "METHOD_END"], "methodName": ["createBoundHttpAddress"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "final   ThreadContext   threadContext    =    threadPool . getThreadContext (  )  ;", "try    ( ThreadContext . StoredContext   ignore    =    threadContext . stashContext (  )  )     {", "dispatcher . dispatchBadRequest ( request ,    channel ,    threadContext ,    cause )  ;", "}", "}", "METHOD_END"], "methodName": ["dispatchBadRequest"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "final   ThreadContext   threadContext    =    threadPool . getThreadContext (  )  ;", "try    ( ThreadContext . StoredContext   ignore    =    threadContext . stashContext (  )  )     {", "dispatcher . dispatchRequest ( request ,    channel ,    threadContext )  ;", "}", "}", "METHOD_END"], "methodName": ["dispatchRequest"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "if    ( cause   instanceof   ReadTimeoutException )     {", "if    ( logger . isTraceEnabled (  )  )     {", "logger . trace (  \" Read   timeout    [  {  }  ]  \"  ,    ctx . channel (  )  . remoteAddress (  )  )  ;", "}", "ctx . channel (  )  . close (  )  ;", "} else    {", "if    (  !  ( lifecycle . started (  )  )  )     {", "return ;", "}", "if    (  !  ( NetworkExceptionHelper . isCloseConnectionException ( cause )  )  )     {", "logger . warn (  (  ( Supplier <  ?  >  )     (  (  )     -  >    new   ParameterizedMessage (  \" caught   exception   while   handling   client      traffic ,    closing   connection    {  }  \"  ,    ctx . channel (  )  )  )  )  ,    cause )  ;", "ctx . channel (  )  . close (  )  ;", "} else    {", "logger . debug (  (  ( Supplier <  ?  >  )     (  (  )     -  >    new   ParameterizedMessage (  \" caught   exception   while   handling   client      traffic ,    closing   connection    {  }  \"  ,    ctx . channel (  )  )  )  )  ,    cause )  ;", "ctx . channel (  )  . close (  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["exceptionCaught"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "return   corsConfig ;", "}", "METHOD_END"], "methodName": ["getCorsConfig"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "int   publishPort    =    HttpTransportSettings . SETTING _ HTTP _ PUBLISH _ PORT . get ( settings )  ;", "if    ( publishPort    <     0  )     {", "for    ( TransportAddress   boundAddress    :    boundAddresses )     {", "InetAddress   boundInetAddress    =    boundAddress . address (  )  . getAddress (  )  ;", "if    (  ( boundInetAddress . isAnyLocalAddress (  )  )     |  |     ( boundInetAddress . equals ( publishInetAddress )  )  )     {", "publishPort    =    boundAddress . getPort (  )  ;", "break ;", "}", "}", "}", "if    ( publishPort    <     0  )     {", "final   IntSet   ports    =    new   IntHashSet (  )  ;", "for    ( TransportAddress   boundAddress    :    boundAddresses )     {", "ports . add ( boundAddress . getPort (  )  )  ;", "}", "if    (  ( ports . size (  )  )     =  =     1  )     {", "publishPort    =    ports . iterator (  )  . next (  )  . value ;", "}", "}", "if    ( publishPort    <     0  )     {", "throw   new   BindHttpException (  (  (  (  (  (  (  (  (  \" Failed   to   auto - resolve   http   publish   port ,    multiple   bound   addresses    \"     +    boundAddresses )     +     \"    with   distinct   ports   and   none   of   them   matched   the   publish   address    (  \"  )     +    publishInetAddress )     +     \"  )  .     \"  )     +     \" Please   specify   a   unique   port   by   setting    \"  )     +     ( HttpTransportSettings . SETTING _ HTTP _ PORT . getKey (  )  )  )     +     \"    or    \"  )     +     ( HttpTransportSettings . SETTING _ HTTP _ PUBLISH _ PORT . getKey (  )  )  )  )  ;", "}", "return   publishPort ;", "}", "METHOD_END"], "methodName": ["resolvePublishPort"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "return   this . settings ;", "}", "METHOD_END"], "methodName": ["settings"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransport"}, {"methodBody": ["METHOD_START", "{", "final   HttpServerTransport . Dispatcher   dispatcher    =    new   HttpServerTransport . Dispatcher (  )     {", "@ Override", "public   void   dispatchRequest ( RestRequest   request ,    RestChannel   channel ,    ThreadContext   threadContext )     {", "channel . sendResponse ( new   BytesRestResponse ( OK ,    BytesRestResponse . TEXT _ CONTENT _ TYPE ,    new   BytesArray (  \" done \"  )  )  )  ;", "}", "@ Override", "public   void   dispatchBadRequest ( RestRequest   request ,    RestChannel   channel ,    ThreadContext   threadContext ,    Throwable   cause )     {", "throw   new   AssertionError (  )  ;", "}", "}  ;", "try    (    transport    =    new    ( settings ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    dispatcher )  )     {", "transport . start (  )  ;", "final   TransportAddress   remoteAddress    =    randomFrom ( transport . boundAddress (  )  . boundAddresses (  )  )  ;", "try    ( Netty 4 HttpClient   client    =    new   Netty 4 HttpClient (  )  )     {", "final   FullHttpRequest   request    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . POST ,     \"  /  \"  )  ;", "request . headers (  )  . set ( EXPECT ,    expectation )  ;", "HttpUtil . setContentLength ( request ,    contentLength )  ;", "final   FullHttpResponse   response    =    client . post ( remoteAddress . address (  )  ,    request )  ;", "assertThat ( response . status (  )  ,    equalTo ( expectedStatus )  )  ;", "if    ( expectedStatus . equals ( CONTINUE )  )     {", "final   FullHttpRequest   continuationRequest    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . POST ,     \"  /  \"  ,    Unpooled . EMPTY _ BUFFER )  ;", "final   FullHttpResponse   continuationResponse    =    client . post ( remoteAddress . address (  )  ,    continuationRequest )  ;", "assertThat ( continuationResponse . status (  )  ,    is ( OK )  )  ;", "assertThat ( new   String ( ByteBufUtil . getBytes ( continuationResponse . content (  )  )  ,    StandardCharsets . UTF _  8  )  ,    is (  \" done \"  )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["runExpectHeaderTest"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "networkService    =    new   NetworkService ( Collections . emptyList (  )  )  ;", "threadPool    =    new   TestThreadPool (  \" test \"  )  ;", "bigArrays    =    new   common . util . MockBigArrays ( new   common . util . MockPageCacheRecycler ( Settings . EMPTY )  ,    new   NoneCircuitBreakerService (  )  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( threadPool )     !  =    null )     {", "threadPool . shutdownNow (  )  ;", "}", "threadPool    =    null ;", "networkice    =    null ;", "bigArrays    =    null ;", "}", "METHOD_END"], "methodName": ["shutdown"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "final   AtomicReference < Throwable >    causeReference    =    new   AtomicReference <  >  (  )  ;", "final   HttpServerTransport . Dispatcher   dispatcher    =    new   HttpServerTransport . Dispatcher (  )     {", "@ Override", "public   void   dispatchRequest ( final   RestRequest   request ,    final   RestChannel   channel ,    final   ThreadContext   threadContext )     {", "throw   new   AssertionError (  )  ;", "}", "@ Override", "public   void   dispatchBadRequest ( final   RestRequest   request ,    final   RestChannel   channel ,    final   ThreadContext   threadContext ,    final   Throwable   cause )     {", "causeReference . set ( cause )  ;", "try    {", "final   ElasticsearchException   e    =    new   ElasticsearchException (  \" you   sent   a   bad   request   and   you   should   feel   bad \"  )  ;", "channel . sendResponse ( new   BytesRestResponse ( channel ,    BAD _ REQUEST ,    e )  )  ;", "}    catch    ( final   IOException   e )     {", "throw   new   AssertionError ( e )  ;", "}", "}", "}  ;", "final   Settings   settings ;", "final   int   maxInitialLineLength ;", "final   Setting < ByteSizeValue >    httpMaxInitialLineLengthSetting    =    HttpTransportSettings . SETTING _ HTTP _ MAX _ INITIAL _ LINE _ LENGTH ;", "if    ( randomBoolean (  )  )     {", "maxInitialLineLength    =    httpMaxInitialLineLengthSetting . getDefault ( EMPTY )  . bytesAsInt (  )  ;", "settings    =    Settings . EMPTY ;", "} else    {", "maxInitialLineLength    =    randomIntBetween (  1  ,     8  1  9  2  )  ;", "settings    =    Settings . builder (  )  . put ( httpMaxInitialLineLengthSetting . getKey (  )  ,     ( maxInitialLineLength    +     \" b \"  )  )  . build (  )  ;", "}", "try    (    transport    =    new    ( settings ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    dispatcher )  )     {", "transport . start (  )  ;", "final   TransportAddress   remoteAddress    =    randomFrom ( transport . boundAddress . boundAddresses (  )  )  ;", "try    ( Netty 4 HttpClient   client    =    new   Netty 4 HttpClient (  )  )     {", "final   String   url    =     \"  /  \"     +     ( new   String ( new   byte [ maxInitialLineLength ]  ,    Charset . forName (  \" UTF -  8  \"  )  )  )  ;", "final   FullHttpRequest   request    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . GET ,    url )  ;", "final   FullHttpResponse   response    =    client . post ( remoteAddress . address (  )  ,    request )  ;", "assertThat ( response . status (  )  ,    equalTo ( BAD _ REQUEST )  )  ;", "assertThat ( new   String ( response . content (  )  . array (  )  ,    Charset . forName (  \" UTF -  8  \"  )  )  ,    containsString (  \" you   sent   a   bad   request   and   you   should   feel   bad \"  )  )  ;", "}", "}", "assertNotNull ( causeReference . get (  )  )  ;", "assertThat ( causeReference . get (  )  ,    instanceOf ( TooLongFrameException . class )  )  ;", "}", "METHOD_END"], "methodName": ["testBadRequest"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "try    ( Netty 4 HttpServerTransport   transport    =    new   Netty 4 HttpServerTransport ( Settings . EMPTY ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    new   NullDispatcher (  )  )  )     {", "transport . start (  )  ;", "TransportAddress   remoteAddress    =    randomFrom ( transport . boundAddress (  )  . boundAddresses (  )  )  ;", "Settings   settings    =    Settings . builder (  )  . put (  \" http . port \"  ,    remoteAddress . getPort (  )  )  . build (  )  ;", "try    ( Netty 4 HttpServerTransport   otherTransport    =    new   Netty 4 HttpServerTransport ( settings ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    new   NullDispatcher (  )  )  )     {", "BindHttpException   bindHttpException    =    expectThrows ( BindHttpException . class ,     (  )     -  >    otherTransport . start (  )  )  ;", "assertEquals (  (  (  \" Failed   to   bind   to    [  \"     +     ( remoteAddress . getPort (  )  )  )     +     \"  ]  \"  )  ,    bindHttpException . getMessage (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testBindUnavailableAddress"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "final   Set < String >    methods    =    new   HashSet <  >  ( Arrays . asList (  \" get \"  ,     \" options \"  ,     \" post \"  )  )  ;", "final   Set < String >    headers    =    new   HashSet <  >  ( Arrays . asList (  \" Content - Type \"  ,     \" Content - Length \"  )  )  ;", "final   String   prefix    =     ( randomBoolean (  )  )     ?     \"     \"     :     \"  \"  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( HttpTransportSettings . SETTING _ CORS _ ENABLED . getKey (  )  ,    true )  . put ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ ORIGIN . getKey (  )  ,     \"  *  \"  )  . put ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ METHODS . getKey (  )  ,    Strings . collectionToDelimitedString ( methods ,     \"  ,  \"  ,    prefix ,     \"  \"  )  )  . put ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ HEADERS . getKey (  )  ,    Strings . collectionToDelimitedString ( headers ,     \"  ,  \"  ,    prefix ,     \"  \"  )  )  . put ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ CREDENTIALS . getKey (  )  ,    true )  . build (  )  ;", "final   Netty 4 CorsConfig   corsConfig    =     . buildCorsConfig ( settings )  ;", "assertTrue ( corsConfig . isAnyOriginSupported (  )  )  ;", "assertEquals ( headers ,    corsConfig . allowedRequestHeaders (  )  )  ;", "assertEquals ( methods ,    corsConfig . allowedRequestMethods (  )  . stream (  )  . map ( HttpMethod :  : name )  . collect ( Collectors . toSet (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCorsConfig"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "final   Set < String >    methods    =    Strings . commaDelimitedListToSet ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ METHODS . getDefault ( EMPTY )  )  ;", "final   Set < String >    headers    =    Strings . commaDelimitedListToSet ( HttpTransportSettings . SETTING _ CORS _ ALLOW _ HEADERS . getDefault ( EMPTY )  )  ;", "final   long   maxAge    =    HttpTransportSettings . SETTING _ CORS _ MAX _ AGE . getDefault ( EMPTY )  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( HttpTransportSettings . SETTING _ CORS _ ENABLED . getKey (  )  ,    true )  . build (  )  ;", "final   Netty 4 CorsConfig   corsConfig    =     . buildCorsConfig ( settings )  ;", "assertFalse ( corsConfig . isAnyOriginSupported (  )  )  ;", "assertEquals ( Collections . emptySet (  )  ,    corsConfig . origins (  )  . get (  )  )  ;", "assertEquals ( headers ,    corsConfig . allowedRequestHeaders (  )  )  ;", "assertEquals ( methods ,    corsConfig . allowedRequestMethods (  )  . stream (  )  . map ( HttpMethod :  : name )  . collect ( Collectors . toSet (  )  )  )  ;", "assertEquals ( maxAge ,    corsConfig . maxAge (  )  )  ;", "assertFalse ( corsConfig . isCredentialsAllowed (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCorsConfigWithDefaults"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "final   HttpServerTransport . Dispatcher   dispatcher    =    new   HttpServerTransport . Dispatcher (  )     {", "@ Override", "public   void   dispatchRequest ( final   RestRequest   request ,    final   RestChannel   channel ,    final   ThreadContext   threadContext )     {", "threadContext . putHeader (  \" foo \"  ,     \" bar \"  )  ;", "threadContext . putTransient (  \" bar \"  ,     \" baz \"  )  ;", "}", "@ Override", "public   void   dispatchBadRequest ( final   RestRequest   request ,    final   RestChannel   channel ,    final   ThreadContext   threadContext ,    final   Throwable   cause )     {", "threadContext . putHeader (  \" foo _ bad \"  ,     \" bar \"  )  ;", "threadContext . putTransient (  \" bar _ bad \"  ,     \" baz \"  )  ;", "}", "}  ;", "try    (    transport    =    new    ( Settings . EMPTY ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    dispatcher )  )     {", "transport . start (  )  ;", "transport . dispatchRequest ( null ,    null )  ;", "assertNull ( threadPool . getThreadContext (  )  . getHeader (  \" foo \"  )  )  ;", "assertNull ( threadPool . getThreadContext (  )  . getTransient (  \" bar \"  )  )  ;", "transport . dispatchBadRequest ( null ,    null ,    null )  ;", "assertNull ( threadPool . getThreadContext (  )  . getHeader (  \" foo _ bad \"  )  )  ;", "assertNull ( threadPool . getThreadContext (  )  . getTransient (  \" bar _ bad \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDispatchDoesNotModifyThreadContext"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "final   Settings   settings    =    Settings . EMPTY ;", "final   int   contentLength    =    randomIntBetween (  1  ,    SETTING _ HTTP _ MAX _ CONTENT _ LENGTH . get ( settings )  . bytesAsInt (  )  )  ;", "runExpectHeaderTest ( settings ,    CONTINUE . toString (  )  ,    contentLength ,    ResponseStatus . CONTINUE )  ;", "}", "METHOD_END"], "methodName": ["testExpectContinueHeader"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "final   String   key    =    SETTING _ HTTP _ MAX _ CONTENT _ LENGTH . getKey (  )  ;", "final   int   maxContentLength    =    randomIntBetween (  1  ,     1  0  4  8  5  7  6  0  0  )  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( key ,     ( maxContentLength    +     \" b \"  )  )  . build (  )  ;", "final   int   contentLength    =    randomIntBetween (  ( maxContentLength    +     1  )  ,    Integer . MAX _ VALUE )  ;", "runExpectHeader ( settings ,    CONTINUE . toString (  )  ,    contentLength ,    REQUEST _ ENTITY _ TOO _ LARGE )  ;", "}", "METHOD_END"], "methodName": ["testExpectContinueHeaderContentLengthTooLong"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "runExpectHeaderTest ( EMPTY ,     \" chocolate = yummy \"  ,     0  ,    EXPECTATION _ FAILED )  ;", "}", "METHOD_END"], "methodName": ["testExpectUnsupportedExpectation"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "final   HttpServerTransport . Dispatcher   dispatcher    =    new   HttpServerTransport . Dispatcher (  )     {", "@ Override", "public   void   dispatchRequest ( final   RestRequest   request ,    final   RestChannel   channel ,    final   ThreadContext   threadContext )     {", "throw   new   AssertionError (  \" Should   not   have   received   a   dispatched   request \"  )  ;", "}", "@ Override", "public   void   dispatchBadRequest ( final   RestRequest   request ,    final   RestChannel   channel ,    final   ThreadContext   threadContext ,    final   Throwable   cause )     {", "throw   new   AssertionError (  \" Should   not   have   received   a   dispatched   request \"  )  ;", "}", "}  ;", "Settings   settings    =    Settings . builder (  )  . put ( SETTING _ HTTP _ READ _ TIMEOUT . getKey (  )  ,    new   TimeValue ( randomIntBetween (  1  0  0  ,     3  0  0  )  )  )  . build (  )  ;", "NioEventLoopGroup   group    =    new   NioEventLoopGroup (  )  ;", "try    (    transport    =    new    ( settings ,    networkService ,    bigArrays ,    threadPool ,    xContentRegistry (  )  ,    dispatcher )  )     {", "transport . start (  )  ;", "final   TransportAddress   remoteAddress    =    randomFrom ( transport . boundAddress . boundAddresses (  )  )  ;", "AtomicBoolean   channelClosed    =    new   AtomicBoolean ( false )  ;", "Bootstrap   clientBootstrap    =    new   Bootstrap (  )  . channel ( NioSocketChannel . class )  . handler ( new   io . netty . channel . ChannelInitializer < SocketChannel >  (  )     {", "@ Override", "protected   void   initChannel ( SocketChannel   ch )     {", "ch . pipeline (  )  . addLast ( new   ChannelHandlerAdapter (  )     {  }  )  ;", "}", "}  )  . group ( group )  ;", "ChannelFuture   connect    =    clientBootstrap . connect ( remoteAddress . address (  )  )  ;", "connect . channel (  )  . closeFuture (  )  . addListener (  (    future )     -  >    channelClosed . set ( true )  )  ;", "assertBusy (  (  )     -  >    assertTrue (  \" Channel   should   be   closed   due   to   read   timeout \"  ,    channelClosed . get (  )  )  ,     5  ,    TimeUnit . SECONDS )  ;", "}    finally    {", "group . shutdownGracefully (  )  . await (  )  ;", "}", "}", "METHOD_END"], "methodName": ["testReadTimeout"], "fileName": "org.elasticsearch.http.netty4.Netty4HttpServerTransportTests"}, {"methodBody": ["METHOD_START", "{", "String   message    =    String . format ( Locale . ROOT ,     \" Expected   returned   http   message   ids   to   be   in   any   order   of :     % s \"  ,    opaqueIds )  ;", "assertThat ( message ,    opaqueIds ,    containsInAnyOrder (  \"  0  \"  ,     \"  1  \"  ,     \"  2  \"  ,     \"  3  \"  ,     \"  4  \"  ,     \"  5  \"  ,     \"  6  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["assertResponsesOutOfOrder"], "fileName": "org.elasticsearch.http.netty4.Netty4PipeliningDisabledIT"}, {"methodBody": ["METHOD_START", "{", "ensureGreen (  )  ;", "String [  ]    requests    =    new   String [  ]  {     \"  /  \"  ,     \"  /  _ nodes / stats \"  ,     \"  /  \"  ,     \"  /  _ cluster / state \"  ,     \"  /  \"  ,     \"  /  _ nodes \"  ,     \"  /  \"     }  ;", "HttpServerTransport   httpServerTransport    =    internalCluster (  )  . getInstance ( HttpServerTransport . class )  ;", "TransportAddress [  ]    boundAddresses    =    httpServerTransport . boundAddress (  )  . boundAddresses (  )  ;", "TransportAddress   transportAddress    =     (  ( TransportAddress )     ( randomFrom ( boundAddresses )  )  )  ;", "try    ( HttpClient   nettyHttpClient    =    new   HttpClient (  )  )     {", "Collection < FullHttpResponse >    responses    =    nettyHttpClient . get ( transportAddress . address (  )  ,    requests )  ;", "assertThat ( responses ,    hasSize ( requests . length )  )  ;", "List < String >    opaqueIds    =    new   ArrayList ( HttpClient . returnOpaqueIds ( responses )  )  ;", "assertResponsesOutOfOrder ( opaqueIds )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatNettyHttpServerDoesNotSupportPipelining"], "fileName": "org.elasticsearch.http.netty4.Netty4PipeliningDisabledIT"}, {"methodBody": ["METHOD_START", "{", "int   i    =     0  ;", "Str   msg    =    Str . format ( Locale . ROOT ,     \" Expected   list   of   opaque   ids   to   be   monotonically   increas ,    got    [  % s ]  \"  ,    opaqueIds )  ;", "for    ( Str   opaqueId    :    opaqueIds )     {", "assertThat ( msg ,    opaqueId ,    is ( Str . valueOf (  ( i +  +  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertOpaqueIdsInOrder"], "fileName": "org.elasticsearch.http.netty4.Netty4PipeliningEnabledIT"}, {"methodBody": ["METHOD_START", "{", "String [  ]    requests    =    new   String [  ]  {     \"  /  \"  ,     \"  /  _ nodes / stats \"  ,     \"  /  \"  ,     \"  /  _ cluster / state \"  ,     \"  /  \"     }  ;", "HttpServerTransport   httpServerTransport    =    internalCluster (  )  . getInstance ( HttpServerTransport . class )  ;", "TransportAddress [  ]    boundAddresses    =    httpServerTransport . boundAddress (  )  . boundAddresses (  )  ;", "TransportAddress   transportAddress    =     (  ( TransportAddress )     ( randomFrom ( boundAddresses )  )  )  ;", "try    ( HttpClient   nettyHttpClient    =    new   HttpClient (  )  )     {", "Collection < FullHttpResponse >    responses    =    nettyHttpClient . get ( transportAddress . address (  )  ,    requests )  ;", "assertThat ( responses ,    hasSize (  5  )  )  ;", "Collection < String >    opaqueIds    =    HttpClient . returnOpaqueIds ( responses )  ;", "assertOpaqueIdsInOrder ( opaqueIds )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatNettyHttpServerSupportsPipelining"], "fileName": "org.elasticsearch.http.netty4.Netty4PipeliningEnabledIT"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableSet ( allowedRequestHeaders )  ;", "}", "METHOD_END"], "methodName": ["allowedRequestHeaders"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableSet ( allowedRequestMethods )  ;", "}", "METHOD_END"], "methodName": ["allowedRequestMethods"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "try    {", "rurn   callable . call (  )  ;", "}    catch    ( final   Exception   e )     {", "throw   new   IllegalStateException (  (  (  \" Could   not   generate   value   for   callable    [  \"     +    callable )     +     '  ]  '  )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["getValue"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "return   anyOrigin ;", "}", "METHOD_END"], "methodName": ["isAnyOriginSupported"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "return   enabled ;", "}", "METHOD_END"], "methodName": ["isCorsSupportEnabled"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "return   allowCredentials ;", "}", "METHOD_END"], "methodName": ["isCredentialsAllowed"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "return   allowNullOrigin ;", "}", "METHOD_END"], "methodName": ["isNullOriginAllowed"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "if    ( origins . isPresent (  )  )     {", "return   origins . get (  ) ntains ( origin )  ;", "} else", "if    ( pattern . isPresent (  )  )     {", "return   pattern . get (  )  . matcher ( origin )  . matches (  )  ;", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isOriginAllowed"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "return   shortCircuit ;", "}", "METHOD_END"], "methodName": ["isShortCircuit"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "return   maxAge ;", "}", "METHOD_END"], "methodName": ["maxAge"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "return   origins ;", "}", "METHOD_END"], "methodName": ["origins"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "if    ( preflightHeaders . isEmpty (  )  )     {", "return   EmptyHttpHeaders . INSTANCE ;", "}", "final   HttpHeaders   preflightHeaders    =    new   DefaultHttpHeaders (  )  ;", "for    ( Map . Entry < CharSequence ,    Callable <  ?  >  >    entry    :    this . preflightHeaders . entrySet (  )  )     {", "final   Object   value    =     . getValue ( entry . getValue (  )  )  ;", "if    ( value   instanceof   Iterable )     {", "preflightHeaders . add ( entry . getKey (  )  . toString (  )  ,     (  ( Iterable <  ?  >  )     ( value )  )  )  ;", "} else    {", "preflightHeaders . add ( entry . getKey (  )  . toString (  )  ,    value )  ;", "}", "}", "return   preflightHeaders ;", "}", "METHOD_END"], "methodName": ["preflightResponseHeaders"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfig"}, {"methodBody": ["METHOD_START", "{", "allowCredentials    =    true ;", "return   this ;", "}", "METHOD_END"], "methodName": ["allowCredentials"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "allowNullOrigin    =    true ;", "return   this ;", "}", "METHOD_END"], "methodName": ["allowNullOrigin"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "requestHeaders . addAll ( Arrays . asList ( headers )  )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["allowedRequestHeaders"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "requestMethods . addAll ( Arrays . asList ( methods )  )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["allowedRequestMethods"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "if    (  ( preflightHeaders . isEmpty (  )  )     &  &     (  !  ( noPreflightHeaders )  )  )     {", "preflightHeaders . put (  \" date \"  ,     . DateValueGenerator . INSTANCE )  ;", "preflightHeaders . put (  \" content - length \"  ,    new    . ConstantValueGenerator (  \"  0  \"  )  )  ;", "}", "return   new   Netty 4 CorsConfig ( this )  ;", "}", "METHOD_END"], "methodName": ["build"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "enabled    =    false ;", "return   this ;", "}", "METHOD_END"], "methodName": ["disable"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "return   new   Netty 4 CorsConfigBuilder (  )  ;", "}", "METHOD_END"], "methodName": ["forAnyOrigin"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "if    (  \"  *  \"  . equals ( origin )  )     {", "return   new    (  )  ;", "}", "return   new    ( origin )  ;", "}", "METHOD_END"], "methodName": ["forOrigin"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "return   new   Netty 4 CorsConfigBuilder ( origins )  ;", "}", "METHOD_END"], "methodName": ["forOrigins"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "if    ( pattern    =  =    null )     {", "throw   new   IllegalArgumentException (  \" CORS   pattern   cannot   be   null \"  )  ;", "}", "return   new    ( pattern )  ;", "}", "METHOD_END"], "methodName": ["forPattern"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "maxAge    =    max ;", "rurn   this ;", "}", "METHOD_END"], "methodName": ["maxAge"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "noPreflightHeaders    =    true ;", "return   this ;", "}", "METHOD_END"], "methodName": ["noPreflightResponseHeaders"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "preflightHeaders . put ( name ,    new   Netty 4 CorsConfigBuilder . ConstantValueGenerator ( value )  )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["preflightResponseHeader"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "if    (  ( values . length )     =  =     1  )     {", "preflightHeaders . put ( name ,    new    . ConstantValueGenerator ( values [  0  ]  )  )  ;", "} else    {", "preflightResponseHeader ( name ,    Arrays . asList ( values )  )  ;", "}", "return   this ;", "}", "METHOD_END"], "methodName": ["preflightResponseHeader"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "preflightHeaders . put ( name ,    valueGenerator )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["preflightResponseHeader"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "shortCircuit    =    true ;", "return   this ;", "}", "METHOD_END"], "methodName": ["shortCircuit"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsConfigBuilder"}, {"methodBody": ["METHOD_START", "{", "Netty 4 CorsHandler . setOrigin ( response ,    request . headers (  )  . get ( ORIGIN )  )  ;", "}", "METHOD_END"], "methodName": ["echoRequestOrigin"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "ctx . writeAndFlush ( new   io . netty . handler . codec . http . DefaultFullHttpResponse ( request . protocolVersion (  )  ,    HttpResponseStatus . FORBIDDEN )  )  . addListener ( CLOSE )  ;", "}", "METHOD_END"], "methodName": ["forbidden"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "final   HttpResponse   response    =    new   io . netty . handler . codec . http . DefaultFullHttpResponse ( request . protocolVersion (  )  ,    HttpResponseStatus . OK ,    true ,    true )  ;", "if    ( setOrigin ( response )  )     {", "setAllowMethods ( response )  ;", "setAllowHeaders ( response )  ;", "setAllowCredentials ( response )  ;", "setMaxAge ( response )  ;", "setPreflightHeaders ( response )  ;", "ctx . writeAndFlush ( response )  . addListener ( CLOSE )  ;", "} else    {", ". forbidden ( ctx ,    request )  ;", "}", "}", "METHOD_END"], "methodName": ["handlePreflight"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "final   HttpHeaders   headers    =    request . headers (  )  ;", "return    (  ( request . method (  )  . equals ( OPTIONS )  )     &  &     ( headers . contains ( ORIGIN )  )  )     &  &     ( headers . contains ( ACCESS _ CONTROL _ REQUEST _ METHOD )  )  ;", "}", "METHOD_END"], "methodName": ["isPreflightRequest"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "if    (  ( Strings . isNullOrEmpty ( host )  )     =  =    false )     {", "final   String   originDomain    =     . SCHEME _ PATTERN . matcher ( origin )  . replaceFirst (  \"  \"  )  ;", "if    ( host . equals ( originDomain )  )     {", "return   true ;", "}", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["isSameOrigin"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "if    (  ( config . isCredentialsAllowed (  )  )     &  &     (  !  ( response . headers (  )  . get ( ACCESS _ CONTROL _ ALLOW _ ORIGIN )  . equals ( Netty 4 CorsHandler . ANY _ ORIGIN )  )  )  )     {", "response . headers (  )  . set ( ACCESS _ CONTROL _ ALLOW _ CREDENTIALS ,     \" true \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["setAllowCredentials"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "response . headers (  )  . set ( ACCESS _ CONTROL _ ALLOW _ HEADERS ,    config . allowedRequestHeaders (  )  )  ;", "}", "METHOD_END"], "methodName": ["setAllowHeaders"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "response . headers (  )  . set ( ACCESS _ CONTROL _ ALLOW _ METHODS ,    config . allowedRequestMethods (  )  . stream (  )  . map (  (    m )     -  >    m . name (  )  . trim (  )  )  . collect ( Collectors . toList (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["setAllowMethods"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "Netty 4 CorsHandler . setOrigin ( response ,    Netty 4 CorsHandler . ANY _ ORIGIN )  ;", "}", "METHOD_END"], "methodName": ["setAnyOrigin"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( config . isCorsSupportEnabled (  )  )  )     {", "return ;", "}", "String   originHeader    =    request . headers (  )  . get ( ORIGIN )  ;", "if    (  !  ( Strings . isNullOrEmpty ( originHeader )  )  )     {", "final   String   originHeaderVal ;", "if    ( config . isAnyOriginSupported (  )  )     {", "originHeaderVal    =     . ANY _ ORIGIN ;", "} else", "if    (  ( config . isOriginAllowed ( originHeader )  )     |  |     (  . isSameOrigin ( originHeader ,    request . headers (  )  . get ( HttpHeaderNames . HOST )  )  )  )     {", "originHeaderVal    =    originHeader ;", "} else    {", "originHeaderVal    =    null ;", "}", "if    ( originHeaderVal    !  =    null )     {", "resp . headers (  )  . add ( ACCESS _ CONTROL _ ALLOW _ ORIGIN ,    originHeaderVal )  ;", "}", "}", "if    ( config . isCredentialsAllowed (  )  )     {", "resp . headers (  )  . add ( ACCESS _ CONTROL _ ALLOW _ CREDENTIALS ,     \" true \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["setCorsResponseHeaders"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "response . headers (  )  . set ( ACCESS _ CONTROL _ MAX _ AGE ,    config . maxAge (  )  )  ;", "}", "METHOD_END"], "methodName": ["setMaxAge"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "final   String   origin    =    request . headers (  )  . get ( ORIGIN )  ;", "if    (  !  ( Strings . isNullOrEmpty ( origin )  )  )     {", "if    (  (  \" null \"  . equals ( origin )  )     &  &     ( config . isNullOriginAllowed (  )  )  )     {", ". setAnyOrigin ( response )  ;", "return   true ;", "}", "if    ( config . isAnyOriginSupported (  )  )     {", "if    ( config . isCredentialsAllowed (  )  )     {", "echoRequestOrigin ( response )  ;", ". setVaryHeader ( response )  ;", "} else    {", ". setAnyOrigin ( response )  ;", "}", "return   true ;", "}", "if    ( config . isOriginAllowed ( origin )  )     {", ". setOrigin ( response ,    origin )  ;", ". setVaryHeader ( response )  ;", "return   true ;", "}", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["setOrigin"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "response . headers (  )  . set ( ACCESS _ CONTROL _ ALLOW _ ORIGIN ,    origin )  ;", "}", "METHOD_END"], "methodName": ["setOrigin"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "response . headers (  )  . add ( config . preflightResponseHeaders (  )  )  ;", "}", "METHOD_END"], "methodName": ["setPreflightHeaders"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "response . headers (  )  . set ( VARY ,    ORIGIN )  ;", "}", "METHOD_END"], "methodName": ["setVaryHeader"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "if    ( config . isAnyOriginSupported (  )  )     {", "return   true ;", "}", "final   String   origin    =    request . headers (  )  . get ( ORIGIN )  ;", "if    ( Strings . isNullOrEmpty ( origin )  )     {", "return   true ;", "}", "if    (  (  \" null \"  . equals ( origin )  )     &  &     ( config . isNullOriginAllowed (  )  )  )     {", "return   true ;", "}", "if    (  . isSameOrigin ( origin ,    request . headers (  )  . get ( HOST )  )  )     {", "return   true ;", "}", "return   config . isOriginAllowed ( origin )  ;", "}", "METHOD_END"], "methodName": ["validateOrigin"], "fileName": "org.elasticsearch.http.netty4.cors.Netty4CorsHandler"}, {"methodBody": ["METHOD_START", "{", "return   new   HttpPipelinedResponse ( response ,    promise ,    sequence )  ;", "}", "METHOD_END"], "methodName": ["createHttpResponse"], "fileName": "org.elasticsearch.http.netty4.pipelining.HttpPipelinedRequest"}, {"methodBody": ["METHOD_START", "{", "return   last ;", "}", "METHOD_END"], "methodName": ["last"], "fileName": "org.elasticsearch.http.netty4.pipelining.HttpPipelinedRequest"}, {"methodBody": ["METHOD_START", "{", "return   promise ;", "}", "METHOD_END"], "methodName": ["promise"], "fileName": "org.elasticsearch.http.netty4.pipelining.HttpPipelinedResponse"}, {"methodBody": ["METHOD_START", "{", "return   response ;", "}", "METHOD_END"], "methodName": ["response"], "fileName": "org.elasticsearch.http.netty4.pipelining.HttpPipelinedResponse"}, {"methodBody": ["METHOD_START", "{", "return   sequence ;", "}", "METHOD_END"], "methodName": ["sequence"], "fileName": "org.elasticsearch.http.netty4.pipelining.HttpPipelinedResponse"}, {"methodBody": ["METHOD_START", "{", "FullHttpResponse   response    =     (  ( FullHttpResponse )     ( embeddedChannel . outboundMessages (  )  . poll (  )  )  )  ;", "assertNotNull (  \" Expected   response   to   exist ,    maybe   you   did   not   wait   long   enough ?  \"  ,    response )  ;", "assertNotNull (  (  \" Expected   response   to   have   content    \"     +    expectedContent )  ,    response . content (  )  )  ;", "String   data    =    new   String ( ByteBufUtil . getBytes ( response . content (  )  )  ,    StandardCharsets . UTF _  8  )  ;", "assertThat ( data ,    is ( expectedContent )  )  ;", "}", "METHOD_END"], "methodName": ["assertReadHttpMessageHasContent"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "return   new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . GET ,    uri )  ;", "}", "METHOD_END"], "methodName": ["createHttpRequest"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "waitingRequests . get ( url )  . countDown (  )  ;", "return   finishingRequests . get ( url )  ;", "}", "METHOD_END"], "methodName": ["finishRequest"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( executorService . isShutdown (  )  )  )     {", "executorService . shutdown (  )  ;", "executorService . awaitTermination (  1  0  ,    TimeUnit . SECONDS )  ;", "}", "}", "METHOD_END"], "methodName": ["shutdownExecutorService"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "waitingRequests . keySet (  )  . forEach ( this :  : finishRequest )  ;", "shutdownExecutorService (  )  ;", "super . tearDown (  )  ;", "}", "METHOD_END"], "methodName": ["tearDown"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "final   int   numberOfRequests    =     1  0  ;", "final   EmbeddedChannel   embeddedChannel    =    new   EmbeddedChannel ( new    ( logger ,     ( numberOfRequests    +     1  )  )  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "embeddedChannel . writeInbound ( createHttpRequest (  (  \"  /  \"     +    i )  )  )  ;", "}", "HttpPipelinedRequest   inbound ;", "ArrayList < HttpPipelinedRequest >    requests    =    new   ArrayList <  >  (  )  ;", "while    (  ( inbound    =    embeddedChannel . readInbound (  )  )     !  =    null )     {", "requests . add ( inbound )  ;", "}", "ArrayList < ChannelPromise >    promises    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     1  ;    i    <     ( requests . size (  )  )  ;     +  + i )     {", "final   DefaultFullHttpResponse   httpResponse    =    new   DefaultFullHttpResponse ( HttpVersion . HTTP _  1  _  1  ,    HttpResponseStatus . OK )  ;", "ChannelPromise   promise    =    embeddedChannel . newPromise (  )  ;", "promises . add ( promise )  ;", "HttpPipelinedResponse   response    =    requests . get ( i )  . createHttpResponse ( httpResponse ,    promise )  ;", "embeddedChannel . writeAndFlush ( response ,    promise )  ;", "}", "for    ( ChannelPromise   promise    :    promises )     {", "assertFalse ( promise . isDone (  )  )  ;", "}", "embeddedChannel . close (  )  . syncUninterruptibly (  )  ;", "for    ( ChannelPromise   promise    :    promises )     {", "assertTrue ( promise . isDone (  )  )  ;", "assertTrue (  (  ( promise . cause (  )  )    instanceof   ClosedChannelException )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testPipeliningRequestsAreReleased"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "final   int   numberOfRequests    =    randomIntBetween (  2  ,     1  2  8  )  ;", "final   EmbeddedChannel   embeddedChannel    =    new   EmbeddedChannel ( new   HttpPipeliningHandler ( logger ,    numberOfRequests )  ,    new    . WorkEmulatorHandler (  )  )  ;", "for    ( int   i    =     0  ;    i    <     (  (  1     +    numberOfRequests )     +     1  )  ;    i +  +  )     {", "embeddedChannel . writeInbound ( createHttpRequest (  (  \"  /  \"     +     ( Integer . toString ( i )  )  )  )  )  ;", "}", "final   List < CountDownLatch >    latches    =    new   ArrayList <  >  (  )  ;", "final   List < Integer >    requests    =    IntStream . range (  1  ,     ( numberOfRequests    +     1  )  )  . mapToObj (  (    r )     -  >    r )  . collect ( Collectors . toList (  )  )  ;", "Randomness . shuffle ( requests )  ;", "for    ( final   Integer   request    :    requests )     {", "latches . add ( finishRequest ( request . toString (  )  )  )  ;", "}", "for    ( final   CountDownLatch   latch    :    latches )     {", "latch . await (  )  ;", "}", "finishRequest ( Integer . toString (  ( numberOfRequests    +     1  )  )  )  . await (  )  ;", "embeddedChannel . flush (  )  ;", "assertFalse ( embeddedChannel . isOpen (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatPipeliningClosesConnectionWithTooManyEvents"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "final   int   numberOfRequests    =    randomIntBetween (  2  ,     1  2  8  )  ;", "final   EmbeddedChannel   embeddedChannel    =    new   EmbeddedChannel ( new   HttpPipeliningHandler ( logger ,    numberOfRequests )  ,    new    . WorkEmulatorHandler (  )  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "embeddedChannel . writeInbound ( createHttpRequest (  (  \"  /  \"     +     ( String . valueOf ( i )  )  )  )  )  ;", "}", "final   List < String >    urls    =    new   ArrayList <  >  ( waitingRequests . keySet (  )  )  ;", "Randomness . shuffle ( urls )  ;", "final   List < CountDownLatch >    latches    =    new   ArrayList <  >  (  )  ;", "for    ( final   String   url    :    urls )     {", "latches . add ( finishRequest ( url )  )  ;", "}", "for    ( final   CountDownLatch   latch    :    latches )     {", "latch . await (  )  ;", "}", "embeddedChannel . flush (  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "assertReadHttpMessageHasContent ( embeddedChannel ,    String . valueOf ( i )  )  ;", "}", "assertTrue ( embeddedChannel . isOpen (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatPipeliningWorksWhenSlowRequestsInDifferentOrder"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "final   int   numberOfRequests    =    randomIntBetween (  2  ,     1  2  8  )  ;", "final   EmbeddedChannel   embeddedChannel    =    new   EmbeddedChannel ( new    . AggregateUrisAndHeadersHandler (  )  ,    new   HttpPipeliningHandler ( logger ,    numberOfRequests )  ,    new    . WorkEmulatorHandler (  )  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "final   DefaultHttpRequest   request    =    new   io . netty . handler . codec . http . DefaultFullHttpRequest ( HttpVersion . HTTP _  1  _  1  ,    HttpMethod . GET ,     (  \"  /  \"     +    i )  )  ;", "embeddedChannel . writeInbound ( request )  ;", "embeddedChannel . writeInbound ( EMPTY _ LAST _ CONTENT )  ;", "}", "final   List < CountDownLatch >    latches    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =    numberOfRequests    -     1  ;    i    >  =     0  ;    i -  -  )     {", "latches . add ( finishRequest ( Integer . toString ( i )  )  )  ;", "}", "for    ( final   CountDownLatch   latch    :    latches )     {", "latch . await (  )  ;", "}", "embeddedChannel . flush (  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "assertReadHttpMessageHasContent ( embeddedChannel ,    Integer . toString ( i )  )  ;", "}", "assertTrue ( embeddedChannel . isOpen (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatPipeliningWorksWithChunkedRequests"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "final   int   numberOfRequests    =    randomIntBetween (  2  ,     1  2  8  )  ;", "final   EmbeddedChannel   embeddedChannel    =    new   EmbeddedChannel ( new   HttpPipeliningHandler ( logger ,    numberOfRequests )  ,    new    . WorkEmulatorHandler (  )  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "embeddedChannel . writeInbound ( createHttpRequest (  (  \"  /  \"     +     ( String . valueOf ( i )  )  )  )  )  ;", "}", "final   List < CountDownLatch >    latches    =    new   ArrayList <  >  (  )  ;", "for    ( final   String   url    :    waitingRequests . keySet (  )  )     {", "latches . add ( finishRequest ( url )  )  ;", "}", "for    ( final   CountDownLatch   latch    :    latches )     {", "latch . await (  )  ;", "}", "embeddedChannel . flush (  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "assertReadHttpMessageHasContent ( embeddedChannel ,    String . valueOf ( i )  )  ;", "}", "assertTrue ( embeddedChannel . isOpen (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatPipeliningWorksWithFastSerializedRequests"], "fileName": "org.elasticsearch.http.netty4.pipelining.Netty4HttpPipeliningHandlerTests"}, {"methodBody": ["METHOD_START", "{", "byte [  ]    metricBeat    =    copyToBytesFromClasspath (  \"  / org / elasticsearch / index / mapper / metricbeat -  6  .  0  . template . json \"  )  ;", "byte [  ]    packetBeat    =    copyToBytesFromClasspath (  \"  / org / elasticsearch / index / mapper / packetbeat -  6  .  0  . template . json \"  )  ;", "byte [  ]    fileBeat    =    copyToBytesFromClasspath (  \"  / org / elasticsearch / index / mapper / filebeat -  6  .  0  . template . json \"  )  ;", "client (  )  . admin (  )  . indices (  )  . preparePutTemplate (  \" metricbeat \"  )  . setSource ( metricBeat ,    JSON )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . preparePutTemplate (  \" packetbeat \"  )  . setSource ( packetBeat ,    JSON )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . preparePutTemplate (  \" filebeat \"  )  . setSource ( fileBeat ,    JSON )  . get (  )  ;", "client (  )  . prepareIndex (  \" metricbeat - foo \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" message \"  ,     \" foo \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" packetbeat - foo \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" message \"  ,     \" foo \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" filebeat - foo \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" message \"  ,     \" foo \"  )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["testBeatsTemplatesBWC"], "fileName": "org.elasticsearch.index.mapper.BWCTemplateTests"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.index.mapper.MapperExtrasClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "double   doubleValue ;", "if    ( value   instanceof   Number )     {", "doubleValue    =     (  ( Number )     ( value )  )  . doubleValue (  )  ;", "} else", "if    ( value   instanceof   apache . lucene . util . BytesRef )     {", "doubleValue    =    Double . parseDouble (  (  ( apache . lucene . util . BytesRef )     ( value )  )  . utf 8 ToString (  )  )  ;", "} else    {", "doubleValue    =    Double . parseDouble ( value . toString (  )  )  ;", "}", "return   doubleValue ;", "}", "METHOD_END"], "methodName": ["objectToDouble"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   ScaledFloatFieldMapper . objectToDouble ( value )  ;", "}", "METHOD_END"], "methodName": ["parse"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   parser . doubleValue ( coerce )  ;", "}", "METHOD_END"], "methodName": ["parse"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapper"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper    =    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "assertEquals ( mapping ,    mappingSource (  )  . toString (  )  )  ;", "ThrowingRunnable   runnable    =     (  )     -  >    parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,    value )  . endObject (  )  )  ,    XContentType . JSON )  )  ;", "MapperParsingException   e    =    expectThrows ( MapperParsingException . class ,    runnable )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    containsString ( exceptionMessageContains )  )  ;", "mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . field (  \" ignore _ malformed \"  ,    true )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper       =    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "ParsedDocument   doc    =     . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,    value )  . endObject (  )  )  ,    JSON )  )  ;", "IndexableField [  ]    fields    =    doc . rootDoc (  )  . getFields (  \" field \"  )  ;", "assertEquals (  0  ,    fields . length )  ;", "}", "METHOD_END"], "methodName": ["doTestIgnoreMalformed"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "indexService    =    createIndex (  \" test \"  )  ;", "parser    =    indexServiceService (  )  . documentMapperParser (  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper    =    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "assertEquals ( mapping ,    mappingSource (  )  . toString (  )  )  ;", "ParsedDocument   doc    =    parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     \"  1  2  3  \"  )  . endObject (  )  )  ,    JSON )  )  ;", "IndexableField [  ]    fields    =    doc . rootDoc (  )  . getFields (  \" field \"  )  ;", "assertEquals (  2  ,    fields . length )  ;", "IndexableField   pointField    =    fields [  0  ]  ;", "assertEquals (  1  ,    pointField . fieldType (  )  . pointDimensionCount (  )  )  ;", "assertEquals (  1  2  3  0  ,    pointField . numericValue (  )  . longValue (  )  )  ;", "IndexableField   dvField    =    fields [  1  ]  ;", "assertEquals ( SORTED _ NUMERIC ,    dvField . fieldType (  )  . docValuesType (  )  )  ;", "mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . field (  \" coerce \"  ,    false )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper       =    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "assertEquals ( mapping ,     . mappingSource (  )  . toString (  )  )  ;", "ThrowingRunnable   runnable    =     (  )     -  >     . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     \"  1  2  3  \"  )  . endObject (  )  )  ,    XContentType . JSON )  )  ;", "MapperParsingException   e    =    expectThrows ( MapperParsingException . class ,    runnable )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    containsString (  \" passed   as   String \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCoerce"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper    =    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "assertEquals ( mapping ,    mappingSource (  )  . toString (  )  )  ;", "ParsedDocument   doc    =    parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     1  2  3  )  . endObject (  )  )  ,    JSON )  )  ;", "IndexableField [  ]    fields    =    doc . rootDoc (  )  . getFields (  \" field \"  )  ;", "assertEquals (  2  ,    fields . length )  ;", "IndexableField   pointField    =    fields [  0  ]  ;", "assertEquals (  1  ,    pointField . fieldType (  )  . pointDimensionCount (  )  )  ;", "assertFalse ( pointField . fieldType (  )  . stored (  )  )  ;", "assertEquals (  1  2  3  0  ,    pointField . numericValue (  )  . longValue (  )  )  ;", "IndexableField   dvField    =    fields [  1  ]  ;", "assertEquals ( SORTED _ NUMERIC ,    dvField . fieldType (  )  . docValuesType (  )  )  ;", "assertEquals (  1  2  3  0  ,    dvField . numericValue (  )  . longValue (  )  )  ;", "assertFalse ( dvField . fieldType (  )  . stored (  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \"  \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" name   cannot   be   empty   string \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmptyName"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "doTestIgnoreMalformed (  \" a \"  ,     \" For   input   string :     \\  \" a \\  \"  \"  )  ;", "List < String >    values    =    Arrays . asList (  \" NaN \"  ,     \" Infinity \"  ,     \"  - Infinity \"  )  ;", "for    ( String   value    :    values )     {", "doTestIgnoreMalformed ( value ,     (  (  \"  [ s _ float ]    only   supports   finite   values ,    but   got    [  \"     +    value )     +     \"  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testIgnoreMalformed"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" scaling _ factor \"  ,     (  -  1  )  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  )  ;", "assertEquals (  \"  [ scaling _ factor ]    must   be   a   positive   number ,    got    [  -  1  .  0  ]  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalScalingFactor"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  )  ;", "assertEquals (  \" Field    [ field ]    misses   required   parameter    [ scaling _ factor ]  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testMissingScalingFactor"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" doc _ values \"  ,    false )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper    =    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "assertEquals ( mapping ,    mappingSource (  )  . toString (  )  )  ;", "ParsedDocument   doc    =    parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     1  2  3  )  . endObject (  )  )  ,    JSON )  )  ;", "IndexableField [  ]    fields    =    doc . rootDoc (  )  . getFields (  \" field \"  )  ;", "assertEquals (  1  ,    fields . length )  ;", "IndexableField   pointField    =    fields [  0  ]  ;", "assertEquals (  1  ,    pointField . fieldType (  )  . pointDimensionCount (  )  )  ;", "assertEquals (  1  2  3  0  ,    pointField . numericValue (  )  . longValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoDocValues"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" index \"  ,    false )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper    =    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "assertEquals ( mapping ,    mappingSource (  )  . toString (  )  )  ;", "ParsedDocument   doc    =    parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     1  2  3  )  . endObject (  )  )  ,    JSON )  )  ;", "IndexableField [  ]    fields    =    doc . rootDoc (  )  . getFields (  \" field \"  )  ;", "assertEquals (  1  ,    fields . length )  ;", "IndexableField   dvField    =    fields [  0  ]  ;", "assertEquals ( SORTED _ NUMERIC ,    dvField . fieldType (  )  . docValuesType (  )  )  ;", "assertEquals (  1  2  3  0  ,    dvField . numericValue (  )  . longValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNotIndexed"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper    =    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "assertEquals ( mapping ,    mappingSource (  )  . toString (  )  )  ;", "ParsedDocument   doc    =    parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . nullField (  \" field \"  )  . endObject (  )  )  ,    JSON )  )  ;", "assertArrayEquals ( new   IndexableField [  0  ]  ,    doc . rootDoc (  )  . getFields (  \" field \"  )  )  ;", "mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . field (  \" null _ value \"  ,     2  .  5  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "=    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "assertEquals ( mapping ,    mappingSource (  )  . toString (  )  )  ;", "doc    =    parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . nullField (  \" field \"  )  . endObject (  )  )  ,    JSON )  )  ;", "IndexableField [  ]    fields    =    doc . rootDoc (  )  . getFields (  \" field \"  )  ;", "assertEquals (  2  ,    fields . length )  ;", "IndexableField   pointField    =    fields [  0  ]  ;", "assertEquals (  1  ,    pointField . fieldType (  )  . pointDimensionCount (  )  )  ;", "assertFalse ( pointField . fieldType (  )  . stored (  )  )  ;", "assertEquals (  2  5  ,    pointField . numericValue (  )  . longValue (  )  )  ;", "IndexableField   dvField    =    fields [  1  ]  ;", "assertEquals ( SORTED _ NUMERIC ,    dvField . fieldType (  )  . docValuesType (  )  )  ;", "assertFalse ( dvField . fieldType (  )  . stored (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullValue"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" foo \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" index _ options \"  ,    randomFrom ( new   String [  ]  {     \" docs \"  ,     \" freqs \"  ,     \" positions \"  ,     \" offsets \"     }  )  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "ParsingException   e    =    expectThrows ( ParsingException . class ,     (  )     -  >    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" index _ options   not   allowed   in   field    [ foo ]    of   type    [ scaled _ float ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRejectIndexOptions"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" scaled _ float \"  )  . field (  \" store \"  ,    true )  . field (  \" scaling _ factor \"  ,     1  0  .  0  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper    =    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  ;", "assertEquals ( mapping ,    mappingSource (  )  . toString (  )  )  ;", "ParsedDocument   doc    =    parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     1  2  3  )  . endObject (  )  )  ,    JSON )  )  ;", "IndexableField [  ]    fields    =    doc . rootDoc (  )  . getFields (  \" field \"  )  ;", "assertEquals (  3  ,    fields . length )  ;", "IndexableField   pointField    =    fields [  0  ]  ;", "assertEquals (  1  ,    pointField . fieldType (  )  . pointDimensionCount (  )  )  ;", "assertEquals (  1  2  3  0  ,    pointField . numericValue (  )  . doubleValue (  )  ,     0  .  0  )  ;", "IndexableField   dvField    =    fields [  1  ]  ;", "assertEquals ( SORTED _ NUMERIC ,    dvField . fieldType (  )  . docValuesType (  )  )  ;", "IndexableField   storedField    =    fields [  2  ]  ;", "assertTrue ( storedField . fieldType (  )  . stored (  )  )  ;", "assertEquals (  1  2  3  0  ,    storedField . numericValue (  )  . longValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStore"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addModifier ( new   Modifier (  \" scaling _ factor \"  ,    false )     {", "@ Override", "public   void   modify ( MappedFieldType   ft )     {", "ScaledFloatFieldM   tft    =     (  ( ScaledFloatFieldM )     ( ft )  )  ;", "tft . setScalingFactor (  1  0  )  ;", "}", "@ Override", "public   void   normalizeOther ( MappedFieldType   other )     {", "super . normalizeOther ( other )  ;", "(  ( ScaledFloatFieldM )     ( other )  )  . setScalingFactor (  1  0  0  )  ;", "}", "}  )  ;", "}", "METHOD_END"], "methodName": ["setupProperties"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldTypeTests"}, {"methodBody": ["METHOD_START", "{", "ScaledFloatFieldMapper . ScaledFloatFieldType   ft    =    new   ScaledFloatFieldMapper . ScaledFloatFieldType (  )  ;", "ft . setScalingFactor (  (  0  .  1     +     (  ( randomDouble (  )  )     *     1  0  0  )  )  )  ;", "Directory   dir    =    newDirectory (  )  ;", "IndexWriter   w    =    new   IndexWriter ( dir ,    new   IndexWriterConfig ( null )  )  ;", "Document   doc    =    new   Document (  )  ;", "doc . add ( new   SortedNumericDocValuesField (  \" scaled _ float 1  \"  ,     1  0  )  )  ;", "doc . add ( new   SortedNumericDocValuesField (  \" scaled _ float 2  \"  ,     5  )  )  ;", "doc . add ( new   SortedNumericDocValuesField (  \" scaled _ float 2  \"  ,     1  2  )  )  ;", "w . addDocument ( doc )  ;", "try    ( DirectoryReader   reader    =    DirectoryReader . open ( w )  )     {", "IndexMetaData   indexMetadata    =    new   IndexMetaData . Builder (  \" index \"  )  . settings ( Settings . builder (  )  . put (  \" index . version . created \"  ,    CURRENT )  . put (  \" index . number _ of _ shards \"  ,     1  )  . put (  \" index . number _ of _ replicas \"  ,     0  )  . build (  )  )  . build (  )  ;", "IndexSettings   indexSettings    =    new   IndexSettings ( indexMetadata ,    Settings . EMPTY )  ;", "ft . setName (  \" scaled _ float 1  \"  )  ;", "IndexNumericFieldData   fielddata    =     (  ( IndexNumericFieldData )     ( ft . fielddataBuilder (  \" index \"  )  . build ( indexSettings ,    ft ,    null ,    null ,    null )  )  )  ;", "assertEquals ( fielddata . getNumericType (  )  ,    DOUBLE )  ;", "AtomicNumericFieldData   leafFieldData    =    fielddata . load ( reader . leaves (  )  . get (  0  )  )  ;", "SortedNumericDoubleValues   values    =    leafFieldData . getDoubleValues (  )  ;", "assertTrue ( values . advanceExact (  0  )  )  ;", "assertEquals (  1  ,    values . docValueCount (  )  )  ;", "assertEquals (  (  1  0     /     ( ft . getScalingFactor (  )  )  )  ,    values . nextValue (  )  ,     1  .  0 E -  4  )  ;", "ft . setName (  \" scaled _ float 2  \"  )  ;", "fielddata    =     (  ( IndexNumericFieldData )     ( ft . fielddataBuilder (  \" index \"  )  . build ( indexSettings ,    ft ,    null ,    null ,    null )  )  )  ;", "leafFieldData    =    fielddata . load ( reader . leaves (  )  . get (  0  )  )  ;", "values    =    leafFieldData . getDoubleValues (  )  ;", "assertTrue ( values . advanceExact (  0  )  )  ;", "assertEquals (  2  ,    values . docValueCount (  )  )  ;", "assertEquals (  (  5     /     ( ft . getScalingFactor (  )  )  )  ,    values . nextValue (  )  ,     1  .  0 E -  4  )  ;", "assertEquals (  (  1  2     /     ( ft . getScalingFactor (  )  )  )  ,    values . nextValue (  )  ,     1  .  0 E -  4  )  ;", "}", "IOUtils . close ( w ,    dir )  ;", "}", "METHOD_END"], "methodName": ["testFieldData"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldTypeTests"}, {"methodBody": ["METHOD_START", "{", "ScaledFloatFieldMapper . ScaledFloatFieldType   ft    =    new   ScaledFloatFieldMapper . ScaledFloatFieldType (  )  ;", "ft . setName (  \" scaled _ float \"  )  ;", "ft . setScalingFactor (  (  0  .  1     +     (  ( randomDouble (  )  )     *     1  0  0  )  )  )  ;", "Directory   dir    =    newDirectory (  )  ;", "IndexWriter   w    =    new   IndexWriter ( dir ,    new   IndexWriterConfig ( null )  )  ;", "final   int   numDocs    =     1  0  0  0  ;", "for    ( int   i    =     0  ;    i    <    numDocs ;     +  + i )     {", "Document   doc    =    new   Document (  )  ;", "double   value    =     (  (  ( randomDouble (  )  )     *     2  )     -     1  )     *     1  0  0  0  0  ;", "long   scaledValue    =    Math . round (  ( value    *     ( ft . getScalingFactor (  )  )  )  )  ;", "double   rounded    =    scaledValue    /     ( ft . getScalingFactor (  )  )  ;", "doc . add ( new   LongPoint (  \" scaled _ float \"  ,    scaledValue )  )  ;", "doc . add ( new   DoublePoint (  \" double \"  ,    rounded )  )  ;", "w . addDocument ( doc )  ;", "}", "final   DirectoryReader   reader    =    DirectoryReader . open ( w )  ;", "w . close (  )  ;", "IndexSearcher   searcher    =    newSearcher ( reader )  ;", "final   int   numQueries    =     1  0  0  0  ;", "for    ( int   i    =     0  ;    i    <    numQueries ;     +  + i )     {", "Double   l    =     ( randomBoolean (  )  )     ?    null    :     (  (  ( randomDouble (  )  )     *     2  )     -     1  )     *     1  0  0  0  0  ;", "Double   u    =     ( randomBoolean (  )  )     ?    null    :     (  (  ( randomDouble (  )  )     *     2  )     -     1  )     *     1  0  0  0  0  ;", "boolean   includeLower    =    randomBoolean (  )  ;", "boolean   includeUpper    =    randomBoolean (  )  ;", "Query   doubleQ    =    DOUBLE . rangeQuery (  \" double \"  ,    l ,    u ,    includeLower ,    includeUpper ,    false )  ;", "Query   scaledFloatQ    =    ft . rangeQuery ( l ,    u ,    includeLower ,    includeUpper ,    null )  ;", "assertEquals ( searcher . count ( doubleQ )  ,    searcher . count ( scaledFloatQ )  )  ;", "}", "IOUtils . close ( reader ,    dir )  ;", "}", "METHOD_END"], "methodName": ["testRangeQuery"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldTypeTests"}, {"methodBody": ["METHOD_START", "{", "ScaledFloatFieldMapper . ScaledFloatFieldType   ft    =    new   ScaledFloatFieldMapper . ScaledFloatFieldType (  )  ;", "ft . setName (  \" scaled _ float \"  )  ;", "ft . setScalingFactor (  1  0  0  .  0  )  ;", "Query   scaledFloatQ    =    ft . rangeQuery (  (  -  0  .  1  )  ,    null ,    false ,    true ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  9    TO    9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery (  (  -  0  .  1  )  ,    null ,    true ,    true ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  1  0    TO    9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery (  (  -  0  .  0  9  5  )  ,    null ,    false ,    true ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  9    TO    9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery (  (  -  0  .  0  9  5  )  ,    null ,    true ,    true ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  9    TO    9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery (  (  -  0  .  1  0  5  )  ,    null ,    false ,    true ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  1  0    TO    9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery (  (  -  0  .  1  0  5  )  ,    null ,    true ,    true ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  1  0    TO    9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoundsLowerBoundCorrectly"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldTypeTests"}, {"methodBody": ["METHOD_START", "{", "ScaledFloatFieldMapper . ScaledFloatFieldType   ft    =    new   ScaledFloatFieldMapper . ScaledFloatFieldType (  )  ;", "ft . setName (  \" scaled _ float \"  )  ;", "ft . setScalingFactor (  1  0  0  .  0  )  ;", "Query   scaledFloatQ    =    ft . rangeQuery ( null ,     0  .  1  ,    true ,    false ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8    TO    9  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery ( null ,     0  .  1  ,    true ,    true ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8    TO    1  0  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery ( null ,     0  .  0  9  5  ,    true ,    false ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8    TO    9  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery ( null ,     0  .  0  9  5  ,    true ,    true ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8    TO    9  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery ( null ,     0  .  1  0  5  ,    true ,    false ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8    TO    1  0  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "scaledFloatQ    =    ft . rangeQuery ( null ,     0  .  1  0  5  ,    true ,    true ,    null )  ;", "assertEquals (  \" scaled _ float :  [  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8    TO    1  0  ]  \"  ,    scaledFloatQ . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoundsUpperBoundCorrectly"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldTypeTests"}, {"methodBody": ["METHOD_START", "{", "ScaledFloatFieldMapper . ScaledFloatFieldType   ft    =    new   ScaledFloatFieldMapper . ScaledFloatFieldType (  )  ;", "ft . setName (  \" scaled _ float \"  )  ;", "ft . setScalingFactor (  (  0  .  1     +     (  ( randomDouble (  )  )     *     1  0  0  )  )  )  ;", "double   value    =     (  (  ( randomDouble (  )  )     *     2  )     -     1  )     *     1  0  0  0  0  ;", "long   scaledValue    =    Math . round (  ( value    *     ( ft . getScalingFactor (  )  )  )  )  ;", "assertEquals ( LongPoint . newExactQuery (  \" scaled _ float \"  ,    scaledValue )  ,    ft . termQuery ( value ,    null )  )  ;", "}", "METHOD_END"], "methodName": ["testTermQuery"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldTypeTests"}, {"methodBody": ["METHOD_START", "{", "ScaledFloatFieldMapper . ScaledFloatFieldType   ft    =    new   ScaledFloatFieldMapper . ScaledFloatFieldType (  )  ;", "ft . setName (  \" scaled _ float \"  )  ;", "ft . setScalingFactor (  (  0  .  1     +     (  ( randomDouble (  )  )     *     1  0  0  )  )  )  ;", "double   value 1     =     (  (  ( randomDouble (  )  )     *     2  )     -     1  )     *     1  0  0  0  0  ;", "long   scaledValue 1     =    Math . round (  ( value 1     *     ( ft . getScalingFactor (  )  )  )  )  ;", "double   value 2     =     (  (  ( randomDouble (  )  )     *     2  )     -     1  )     *     1  0  0  0  0  ;", "long   scaledValue 2     =    Math . round (  ( value 2     *     ( ft . getScalingFactor (  )  )  )  )  ;", "assertEquals ( LongPoint . newSetQuery (  \" scaled _ float \"  ,    scaledValue 1  ,    scaledValue 2  )  ,    ft . termsQuery ( Arrays . asList ( value 1  ,    value 2  )  ,    null )  )  ;", "}", "METHOD_END"], "methodName": ["testTermsQuery"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldTypeTests"}, {"methodBody": ["METHOD_START", "{", "ScaledFloatFieldMapper . ScaledFloatFieldType   ft    =    new   ScaledFloatFieldMapper . ScaledFloatFieldType (  )  ;", "ft . setName (  \" scaled _ float \"  )  ;", "ft . setScalingFactor (  (  0  .  1     +     (  ( randomDouble (  )  )     *     1  0  0  )  )  )  ;", "assertNull ( ft . valueForDisplay ( null )  )  ;", "assertEquals (  (  1  0     /     ( ft . getScalingFactor (  )  )  )  ,    ft . valueForDisplay (  1  0 L )  )  ;", "}", "METHOD_END"], "methodName": ["testValueForSearch"], "fileName": "org.elasticsearch.index.mapper.ScaledFloatFieldTypeTests"}, {"methodBody": ["METHOD_START", "{", "return   analyzer . name (  )  ;", "}", "METHOD_END"], "methodName": ["analyzer"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapper"}, {"methodBody": ["METHOD_START", "{", "try    ( TokenStream   tokenStream    =    analyzer . tokenStream ( fieldName ,    fieldValue )  )     {", "int   count    =     0  ;", "PositionIncrementAttribute   position    =    tokenStream . addAttribute ( PositionIncrementAttribute . class )  ;", "tokenStream . reset (  )  ;", "while    ( tokenStream . incrementToken (  )  )     {", "if    ( enablePositionIncrements )     {", "count    +  =    position . getPositionIncrement (  )  ;", "} else    {", "count    +  =    Math . min (  1  ,    position . getPositionIncrement (  )  )  ;", "}", "}", "tokenStream . end (  )  ;", "if    ( enablePositionIncrements )     {", "count    +  =    position . getPositionIncrement (  )  ;", "}", "return   count ;", "}", "}", "METHOD_END"], "methodName": ["countPositions"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   enablePositionIncrements ;", "}", "METHOD_END"], "methodName": ["enablePositionIncrements"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapper"}, {"methodBody": ["METHOD_START", "{", "assertThat ( hit . field (  \" foo . token _ count \"  )  ,    not ( nullValue (  )  )  )  ;", "assertThat ( hit . field (  \" foo . token _ count \"  )  . getValues (  )  . size (  )  ,    equalTo ( standardTerms . length )  )  ;", "for    ( int   i    =     0  ;    i    <     ( standardTerms . length )  ;    i +  +  )     {", "assertThat (  (  ( Integer )     ( hit . field (  \" foo . token _ count \"  )  . getValues (  )  . get ( i )  )  )  ,    equalTo ( standardTerms [ i ]  )  )  ;", "}", "assertThat ( hit . field (  \" foo . token _ count _ without _ position _ increments \"  )  ,    not ( nullValue (  )  )  )  ;", "assertThat ( hit . field (  \" foo . token _ count _ without _ position _ increments \"  )  . getValues (  )  . size (  )  ,    equalTo ( englishTerms . length )  )  ;", "for    ( int   i    =     0  ;    i    <     ( englishTerms . length )  ;    i +  +  )     {", "assertThat (  (  ( Integer )     ( hit . field (  \" foo . token _ count _ without _ position _ increments \"  )  . getValues (  )  . get ( i )  )  )  ,    equalTo ( englishTerms [ i ]  )  )  ;", "}", "if    (  ( loadedFields )     &  &     ( storeedFields )  )     {", "assertThat ( hit . field (  \" foo \"  )  . getValues (  )  . size (  )  ,    equalTo ( standardTerms . length )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertSearchHit"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "assertThat ( result . getHits (  )  . getTotalHits (  )  ,    equalTo (  (  ( long )     ( ids . length )  )  )  )  ;", "assertThat ( result . getHits (  )  . getHits (  )  . length ,    equalTo ( ids . length )  )  ;", "List < String >    foundIds    =    new   ArrayList <  >  (  )  ;", "for    ( SearchHit   hit    :    result . getHits (  )  )     {", "foundIds . add ( hit . getId (  )  )  ;", "}", "assertThat ( foundIds ,    containsInAnyOrder ( ids )  )  ;", "for    ( SearchHit   hit    :    result . getHits (  )  )     {", "String   id    =    hit . getId (  )  ;", "if    ( id . equals (  \" single \"  )  )     {", "assertSearchHit ( hit ,    new   int [  ]  {     4     }  ,    new   int [  ]  {     4     }  )  ;", "} else", "if    ( id . equals (  \" bulk 1  \"  )  )     {", "assertSearchHit ( hit ,    new   int [  ]  {     3     }  ,    new   int [  ]  {     3     }  )  ;", "} else", "if    ( id . equals (  \" bulk 2  \"  )  )     {", "assertSearchHit ( hit ,    new   int [  ]  {     5     }  ,    new   int [  ]  {     4     }  )  ;", "} else", "if    ( id . equals (  \" multi \"  )  )     {", "assertSearchHit ( hit ,    new   int [  ]  {     2  ,     7     }  ,    new   int [  ]  {     2  ,     7     }  )  ;", "} else", "if    ( id . equals (  \" multibulk 1  \"  )  )     {", "assertSearchHit ( hit ,    new   int [  ]  {     1  ,     8     }  ,    new   int [  ]  {     1  ,     8     }  )  ;", "} else", "if    ( id . equals (  \" multibulk 2  \"  )  )     {", "assertSearchHit ( hit ,    new   int [  ]  {     6  ,     1  0     }  ,    new   int [  ]  {     3  ,     9     }  )  ;", "} else    {", "throw   new   ElasticsearchException (  \" Unexpected   response !  \"  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["assertSearchReturns"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "List < Object [  ]  >    parameters    =    new   ArrayList <  >  (  )  ;", "for    ( boolean   storeedFields    :    new   boolean [  ]  {    true ,    false    }  )     {", "for    ( boolean   loadedFields    :    new   boolean [  ]  {    true ,    false    }  )     {", "parameters . add ( new   Object [  ]  {    storeedFields ,    loadedFields    }  )  ;", "}", "}", "return   parameters ;", "}", "METHOD_END"], "methodName": ["buildParameters"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "prepareCreate (  \" test \"  )  . addMapping (  \" test \"  ,    jsonBuilder (  )  . startObject (  )  . startObject (  \" test \"  )  . startObject (  \" properties \"  )  . startObject (  \" foo \"  )  . field (  \" type \"  ,     \" text \"  )  . field (  \" store \"  ,    storeCountedFields )  . field (  \" analyzer \"  ,     \" simple \"  )  . startObject (  \" fields \"  )  . startObject (  \" token _ count \"  )  . field (  \" type \"  ,     \" token _ count \"  )  . field (  \" analyzer \"  ,     \" standard \"  )  . field (  \" store \"  ,    true )  . endObject (  )  . startObject (  \" token _ count _ unstored \"  )  . field (  \" type \"  ,     \" token _ count \"  )  . field (  \" analyzer \"  ,     \" standard \"  )  . endObject (  )  . startObject (  \" token _ count _ with _ doc _ values \"  )  . field (  \" type \"  ,     \" token _ count \"  )  . field (  \" analyzer \"  ,     \" standard \"  )  . field (  \" doc _ values \"  ,    true )  . endObject (  )  . startObject (  \" token _ count _ without _ position _ increments \"  )  . field (  \" type \"  ,     \" token _ count \"  )  . field (  \" analyzer \"  ,     \" english \"  )  . field (  \" enable _ position _ increments \"  ,    false )  . field (  \" store \"  ,    true )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  . get (  )  ;", "ensureGreen (  )  ;", "assertEquals ( CREATED ,    prepareIndex (  \" single \"  ,     \" I   have   four   terms \"  )  . get (  )  . getResult (  )  )  ;", "BulkResponse   bulk    =    client (  )  . prepareBulk (  )  . add ( prepareIndex (  \" bulk 1  \"  ,     \" bulk   three   terms \"  )  )  . add ( prepareIndex (  \" bulk 2  \"  ,     \" this   has   five   bulk   terms \"  )  )  . get (  )  ;", "assertFalse ( bulk . buildFailureMessage (  )  ,    bulk . hasFailures (  )  )  ;", "assertEquals ( CREATED ,    prepareIndex (  \" multi \"  ,     \" two   terms \"  ,     \" wow   now   I   have   seven   lucky   terms \"  )  . get (  )  . getResult (  )  )  ;", "bulk    =    client (  )  . prepareBulk (  )  . add ( prepareIndex (  \" multibulk 1  \"  ,     \" one \"  ,     \" oh   wow   now   I   have   eight   unlucky   terms \"  )  )  . add ( prepareIndex (  \" multibulk 2  \"  ,     \" six   is   a   bunch   of   terms \"  ,     \" ten !       ten   terms   is   just   crazy !       too   many   too   count !  \"  )  )  . get (  )  ;", "assertFalse ( bulk . buildFailureMessage (  )  ,    bulk . hasFailures (  )  )  ;", "assertThat ( refresh (  )  . getFailedShards (  )  ,    equalTo (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "return   client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,    id )  . setSource (  \" foo \"  ,    texts )  ;", "}", "METHOD_END"], "methodName": ["prepareIndex"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "SearchRequestBuilder   request    =    client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  ;", "request . addStoredField (  \" foo . token _ count \"  )  ;", "request . addStoredField (  \" foo . token _ count _ without _ position _ increments \"  )  ;", "if    ( loadCountedFields )     {", "request . addStoredField (  \" foo \"  )  ;", "}", "return   request ;", "}", "METHOD_END"], "methodName": ["prepareSearch"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "return   prepareSearch (  )  . setQuery ( QueryBuilders . termQuery (  \"  _ id \"  ,    id )  )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["searchById"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "return   prepareSearch (  )  . setQuery ( QueryBuilders . rangeQuery ( randomFrom ( Arrays . asList (  \" foo . token _ count \"  ,     \" foo . token _ count _ unstored \"  ,     \" foo . token _ count _ with _ doc _ values \"  )  )  )  . gte ( low )  . lte ( high )  )  ;", "}", "METHOD_END"], "methodName": ["searchByNumericRange"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "init (  )  ;", "String   face    =    randomFrom ( Arrays . asList (  \" foo . token _ count \"  ,     \" foo . token _ count _ unstored \"  ,     \" foo . token _ count _ with _ doc _ values \"  )  )  ;", "SearchResponse   result    =    searchByNumericRange (  1  ,     1  0  )  . addAggregation ( AggregationBuilders . terms (  \" facet \"  )  . field ( face )  )  . get (  )  ;", "assertSearchReturns ( result ,     \" single \"  ,     \" bulk 1  \"  ,     \" bulk 2  \"  ,     \" multi \"  ,     \" multibulk 1  \"  ,     \" multibulk 2  \"  )  ;", "assertThat ( result . getAggregations (  )  . asList (  )  . size (  )  ,    equalTo (  1  )  )  ;", "Terms   terms    =     (  ( Terms )     ( result . getAggregations (  )  . asList (  )  . get (  0  )  )  )  ;", "assertThat ( terms . getBuckets (  )  . size (  )  ,    equalTo (  9  )  )  ;", "}", "METHOD_END"], "methodName": ["testFacetByTokenCount"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "init (  )  ;", "assertSearchReturns ( ByNumericRange (  4  ,     4  )  . get (  )  ,     \" single \"  )  ;", "assertSearchReturns ( ByNumericRange (  1  0  ,     1  0  )  . get (  )  ,     \" multibulk 2  \"  )  ;", "assertSearchReturns ( ByNumericRange (  7  ,     1  0  )  . get (  )  ,     \" multi \"  ,     \" multibulk 1  \"  ,     \" multibulk 2  \"  )  ;", "assertSearchReturns ( ByNumericRange (  1  ,     1  0  )  . get (  )  ,     \" single \"  ,     \" bulk 1  \"  ,     \" bulk 2  \"  ,     \" multi \"  ,     \" multibulk 1  \"  ,     \" multibulk 2  \"  )  ;", "assertSearchReturns ( ByNumericRange (  1  2  ,     1  2  )  . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testSearchByTokenCount"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "init (  )  ;", "assertSearchReturns ( ById (  \" single \"  )  ,     \" single \"  )  ;", "assertSearchReturns ( ById (  \" bulk 1  \"  )  ,     \" bulk 1  \"  )  ;", "assertSearchReturns ( ById (  \" bulk 2  \"  )  ,     \" bulk 2  \"  )  ;", "assertSearchReturns ( ById (  \" multi \"  )  ,     \" multi \"  )  ;", "assertSearchReturns ( ById (  \" multibulk 1  \"  )  ,     \" multibulk 1  \"  )  ;", "assertSearchReturns ( ById (  \" multibulk 2  \"  )  ,     \" multibulk 2  \"  )  ;", "}", "METHOD_END"], "methodName": ["testSearchReturnsTokenCount"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "BytesReference   request    =    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" test \"  ,    fieldValue )  . endObject (  )  )  ;", "return   SourceToParse . source (  \" test \"  ,     \" person \"  ,     \"  1  \"  ,    request ,    JSON )  ;", "}", "METHOD_END"], "methodName": ["createDocument"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "final   String   content    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" person \"  )  . startObject (  \" properties \"  )  . startObject (  \" test \"  )  . field (  \" type \"  ,     \" text \"  )  . startObject (  \" fields \"  )  . startObject (  \" tc \"  )  . field (  \" type \"  ,     \" token _ count \"  )  . field (  \" analyzer \"  ,     \" standard \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "return   createIndex (  \" test \"  ) Service (  )  . documentMapperParser (  )  . parse (  \" person \"  ,    new   CompressedXContent ( content )  )  ;", "}", "METHOD_END"], "methodName": ["createIndexWithTokenCountField"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "Token   t 1     =    new   Token (  )  ;", "t 1  . setPositionIncrement (  0  )  ;", "Token   t 2     =    new   Token (  )  ;", "t 2  . setPositionIncrement (  1  )  ;", "Token   t 3     =    new   Token (  )  ;", "t 2  . setPositionIncrement (  2  )  ;", "int   finalTokenIncrement    =     4  ;", "Token [  ]    tokens    =    new   Token [  ]  {    t 1  ,    t 2  ,    t 3     }  ;", "Collections . shuffle ( Arrays . asList ( tokens )  ,    random (  )  )  ;", "final   TokenStream   tokenStream    =    new   CannedTokenStream ( finalTokenIncrement ,     0  ,    tokens )  ;", "Analyzer   analyzer    =    new   Analyzer (  )     {", "@ Override", "public   TokenStreamComponents   createComponents ( String   fieldName )     {", "return   new   TokenStreamComponents ( new   MockTokenizer (  )  ,    tokenStream )  ;", "}", "}  ;", "return   analyzer ;", "}", "METHOD_END"], "methodName": ["createMockAnalyzer"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "return   mapper . parse ( request )  . docs (  )  . stream (  )  . findFirst (  )  . orElseThrow (  (  )     -  >    new   IllegalStateException (  \" Test   object   not   parsed \"  )  )  ;", "}", "METHOD_END"], "methodName": ["parseDocument"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "Analyzer   analyzer    =    createMockAnalyzer (  )  ;", "assertThat (  . countPositions ( analyzer ,     \"  \"  ,     \"  \"  ,    true )  ,    equalTo (  7  )  )  ;", "}", "METHOD_END"], "methodName": ["testCountPositionsWithIncrements"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "Analyzer   analyzer    =    createMockAnalyzer (  )  ;", "assertThat (  . countPositions ( analyzer ,     \"  \"  ,     \"  \"  ,    false )  ,    equalTo (  2  )  )  ;", "}", "METHOD_END"], "methodName": ["testCountPositionsWithoutIncrements"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "IndexService   indexService    =    createIndex (  \" test \"  )  ;", "DocumentMapperParser   parser    =    indexServiceService (  )  . documentMapperParser (  )  ;", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \"  \"  )  . field (  \" type \"  ,     \" token _ count \"  )  . field (  \" analyzer \"  ,     \" standard \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    parser . parse (  \" type \"  ,    new   CompressedXContent ( mapping )  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" name   cannot   be   empty   string \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmptyName"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   stage 1 Mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" person \"  )  . startObject (  \" properties \"  )  . startObject (  \" tc \"  )  . field (  \" type \"  ,     \" token _ count \"  )  . field (  \" analyzer \"  ,     \" keyword \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "MapperService   mapperService    =    createIndex (  \" test \"  )  . mapperService (  )  ;", "DocumentMapper   stage 1     =    mapperService . merge (  \" person \"  ,    new   CompressedXContent ( stage 1 Mapping )  ,    MAPPING _ UPDATE )  ;", "String   stage 2 Mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" person \"  )  . startObject (  \" properties \"  )  . startObject (  \" tc \"  )  . field (  \" type \"  ,     \" token _ count \"  )  . field (  \" analyzer \"  ,     \" standard \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapper   stage 2     =    mapperService . merge (  \" person \"  ,    new   CompressedXContent ( stage 2 Mapping )  ,    MAPPING _ UPDATE )  ;", "assertThat (  (  (  )     ( stage 1  . mappers (  )  . smartNameFieldMapper (  \" tc \"  )  )  )  . analyzer (  )  ,    equalTo (  \" keyword \"  )  )  ;", "assertThat (  (  (  )     ( stage 2  . mappers (  )  . smartNameFieldMapper (  \" tc \"  )  )  )  . analyzer (  )  ,    equalTo (  \" standard \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMerge"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "DocumentMapper   mapper    =    createIndexWithTokenCountField (  )  ;", "ParseContext . Document   doc    =    parseDocument ( mapper ,    createDocument (  \"  \"  )  )  ;", "assertEquals (  0  ,    doc . getField (  \" test . tc \"  )  . numericValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseEmptyValue"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "DocumentMapper   mapper    =    createIndexWithTokenCountField (  )  ;", "ParseContext . Document   doc    =    parseDocument ( mapper ,    createDocument (  \" three   tokens   string \"  )  )  ;", "assertEquals (  3  ,    doc . getField (  \" test . tc \"  )  . numericValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseNotNullValue"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "DocumentMapper   mapper    =    createIndexWithTokenCountField (  )  ;", "ParseContext . Document   doc    =    parseDocument ( mapper ,    createDocument ( null )  )  ;", "assertNull ( doc . getField (  \" test . tc \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseNullValue"], "fileName": "org.elasticsearch.index.mapper.TokenCountFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "int   rank    =     1  ;", "double   dcg    =     0  ;", "for    ( Integer   rating    :    ratings )     {", "if    ( rating    !  =    null )     {", "dcg    +  =     (  ( Math . pow (  2  ,    rating )  )     -     1  )     /     (  ( Math . log (  ( rank    +     1  )  )  )     /     (  . LOG 2  )  )  ;", "}", "rank +  +  ;", "}", "return   dcg ;", "}", "METHOD_END"], "methodName": ["computeDCG"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGain"}, {"methodBody": ["METHOD_START", "{", "return   DiscountedCumulativeGain . PARSER . apply ( parser ,    null )  ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGain"}, {"methodBody": ["METHOD_START", "{", "return   this . k ;", "}", "METHOD_END"], "methodName": ["getK"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGain"}, {"methodBody": ["METHOD_START", "{", "return   this . normalize ;", "}", "METHOD_END"], "methodName": ["getNormalize"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGain"}, {"methodBody": ["METHOD_START", "{", "return   this . unknownDocRating ;", "}", "METHOD_END"], "methodName": ["getUnknownDocRating"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGain"}, {"methodBody": ["METHOD_START", "{", "try    ( XContentParser   parser    =    createParser ( jsonXContent ,    xContent )  )     {", "dcgAt    =     . fromXContent ( parser )  ;", "assertEquals ( expectedUnknownDocRating ,    dcgAt . getUnknownDocRating (  )  )  ;", "assertEquals ( expectedNormalize ,    dcgAt . getNormalize (  )  )  ;", "assertEquals ( expectedK ,    dcgAt . getK (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertParsedCorrect"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "boolean   normalize    =    randomBoolean (  )  ;", "Integer   unknownDocRating    =    new   Integer ( randomIntBetween (  0  ,     1  0  0  0  )  )  ;", "return   new    ( normalize ,    unknownDocRating ,     1  0  )  ;", "}", "METHOD_END"], "methodName": ["createTestItem"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "switch    ( randomIntBetween (  0  ,     2  )  )     {", "case    0     :", "return   new    (  (  !  ( original . getNormalize (  )  )  )  ,    original . getUnknownDocRating (  )  ,    original . getK (  )  )  ;", "case    1     :", "return   new    ( original . getNormalize (  )  ,    randomValueOtherThan ( original . getUnknownDocRating (  )  ,     (  )     -  >    randomIntBetween (  0  ,     1  0  )  )  ,    original . getK (  )  )  ;", "case    2     :", "return   new    ( original . getNormalize (  )  ,    original . getUnknownDocRating (  )  ,    randomValueOtherThan ( original . getK (  )  ,     (  )     -  >    randomIntBetween (  1  ,     1  0  )  )  )  ;", "default    :", "throw   new   IllegalArgumentException (  \" mutation   variant   not   allowed \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["mutateTestItem"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    rated    =    new   ArrayList <  >  (  )  ;", "int [  ]    relevanceRatings    =    new   int [  ]  {     3  ,     2  ,     3  ,     0  ,     1  ,     2     }  ;", "SearchHit [  ]    hits    =    new   SearchHit [  6  ]  ;", "for    ( int   i    =     0  ;    i    <     6  ;    i +  +  )     {", "rated . add ( new   RatedDocument (  \" index \"  ,    Integer . toString ( i )  ,    relevanceRatings [ i ]  )  )  ;", "hits [ i ]     =    new   SearchHit ( i ,    Integer . toString ( i )  ,    new   Text (  \" type \"  )  ,    Collections . emptyMap (  )  )  ;", "hits [ i ]  . shard ( new   SearchShardTarget (  \" testnode \"  ,    new   Index (  \" index \"  ,     \" uuid \"  )  ,     0  ,    null )  )  ;", "}", "DiscountedCumulativeGain   dcg    =    new   DiscountedCumulativeGain (  )  ;", "assertEquals (  . EXPECTED _ DCG ,    dcg . evaluate (  \" id \"  ,    hits ,    rated )  . getQualityLevel (  )  ,     . DELTA )  ;", "dcg    =    new   DiscountedCumulativeGain ( true ,    null ,     1  0  )  ;", "assertEquals (  . EXPECTED _ NDCG ,    dcg . evaluate (  \" id \"  ,    hits ,    rated )  . getQualityLevel (  )  ,     . DELTA )  ;", "}", "METHOD_END"], "methodName": ["testDCGAt"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "Integer [  ]    relevanceRatings    =    new   Integer [  ]  {     3  ,     2  ,     3  ,    null ,     1  ,    null    }  ;", "List < RatedDocument >    ratedDocs    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     6  ;    i +  +  )     {", "if    ( i    <     ( relevanceRatings . length )  )     {", "if    (  ( relevanceRatings [ i ]  )     !  =    null )     {", "ratedDocs . add ( new   RatedDocument (  \" index \"  ,    Integer . toString ( i )  ,    relevanceRatings [ i ]  )  )  ;", "}", "}", "}", "SearchHit [  ]    hits    =    new   SearchHit [  4  ]  ;", "for    ( int   i    =     0  ;    i    <     4  ;    i +  +  )     {", "hits [ i ]     =    new   SearchHit ( i ,    Integer . toString ( i )  ,    new   Text (  \" type \"  )  ,    Collections . emptyMap (  )  )  ;", "hits [ i ]  . shard ( new   SearchShardTarget (  \" testnode \"  ,    new   Index (  \" index \"  ,     \" uuid \"  )  ,     0  ,    null )  )  ;", "}", "DiscountedCumulativeGain   dcg    =    new   DiscountedCumulativeGain (  )  ;", "EvalQueryQuality   result    =    dcg . evaluate (  \" id \"  ,    hits ,    ratedDocs )  ;", "assertEquals (  1  2  .  3  9  2  7  8  9  2  6  0  7  1  4  3  7  1  ,    result . getQualityLevel (  )  ,     . DELTA )  ;", "assertEquals (  1  ,    EvaluationMetric . filterUnknownDocuments ( result . getHitsAndRatings (  )  )  . size (  )  )  ;", "dcg    =    new   DiscountedCumulativeGain ( true ,    null ,     1  0  )  ;", "assertEquals (  (  1  2  .  3  9  2  7  8  9  2  6  0  7  1  4  3  7  1     /     1  3  .  3  4  7  1  8  4  8  3  3  0  7  3  5  9  1  )  ,    dcg . evaluate (  \" id \"  ,    hits ,    ratedDocs )  . getQualityLevel (  )  ,     . DELTA )  ;", "}", "METHOD_END"], "methodName": ["testDCGAtFourMoreRatings"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    rated    =    new   ArrayList <  >  (  )  ;", "Integer [  ]    relevanceRatings    =    new   Integer [  ]  {     3  ,     2  ,     3  ,    null ,     1     }  ;", "SearchHit [  ]    hits    =    new   SearchHit [  6  ]  ;", "for    ( int   i    =     0  ;    i    <     6  ;    i +  +  )     {", "if    ( i    <     ( relevanceRatings . length )  )     {", "if    (  ( relevanceRatings [ i ]  )     !  =    null )     {", "rated . add ( new   RatedDocument (  \" index \"  ,    Integer . toString ( i )  ,    relevanceRatings [ i ]  )  )  ;", "}", "}", "hits [ i ]     =    new   SearchHit ( i ,    Integer . toString ( i )  ,    new   Text (  \" type \"  )  ,    Collections . emptyMap (  )  )  ;", "hits [ i ]  . shard ( new   SearchShardTarget (  \" testnode \"  ,    new   Index (  \" index \"  ,     \" uuid \"  )  ,     0  ,    null )  )  ;", "}", "DiscountedCumulativeGain   dcg    =    new   DiscountedCumulativeGain (  )  ;", "EvalQueryQuality   result    =    dcg . evaluate (  \" id \"  ,    hits ,    rated )  ;", "assertEquals (  1  2  .  7  7  9  6  4  2  0  6  7  9  4  8  9  1  3  ,    result . getQualityLevel (  )  ,     . DELTA )  ;", "assertEquals (  2  ,    EvaluationMetric . filterUnknownDocuments ( result . getHitsAndRatings (  )  )  . size (  )  )  ;", "dcg    =    new   DiscountedCumulativeGain ( true ,    null ,     1  0  )  ;", "assertEquals (  (  1  2  .  7  7  9  6  4  2  0  6  7  9  4  8  9  1  3     /     1  3  .  3  4  7  1  8  4  8  3  3  0  7  3  5  9  1  )  ,    dcg . evaluate (  \" id \"  ,    hits ,    rated )  . getQualityLevel (  )  ,     . DELTA )  ;", "}", "METHOD_END"], "methodName": ["testDCGAtSixMissingRatings"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "checkEqualsAndHashCode ( DiscountedCumulativeGainTests . createTestItem (  )  ,     (    original )     -  >     {", "return   new   DiscountedCumulativeGain ( original . getNormalize (  )  ,    original . getUnknownDocRating (  )  ,    original . getK (  )  )  ;", "}  ,    DiscountedCumulativeGainTests :  : mutateTestItem )  ;", "}", "METHOD_END"], "methodName": ["testEqualsAndHash"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "Integer [  ]    relevanceRatings    =    new   Integer [  ]  {     3  ,     2  ,     3  ,    null ,     1  ,    null    }  ;", "List < RatedDocument >    ratedDocs    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     6  ;    i +  +  )     {", "if    ( i    <     ( relevanceRatings . length )  )     {", "if    (  ( relevanceRatings [ i ]  )     !  =    null )     {", "ratedDocs . add ( new   RatedDocument (  \" index \"  ,    Integer . toString ( i )  ,    relevanceRatings [ i ]  )  )  ;", "}", "}", "}", "SearchHit [  ]    hits    =    new   SearchHit [  0  ]  ;", "DiscountedCumulativeGain   dcg    =    new   DiscountedCumulativeGain (  )  ;", "EvalQueryQuality   result    =    dcg . evaluate (  \" id \"  ,    hits ,    ratedDocs )  ;", "assertEquals (  0  .  0  ,    result . getQualityLevel (  )  ,     . DELTA )  ;", "assertEquals (  0  ,    EvaluationMetric . filterUnknownDocuments ( result . getHitsAndRatings (  )  )  . size (  )  )  ;", "dcg    =    new   DiscountedCumulativeGain ( true ,    null ,     1  0  )  ;", "result    =    dcg . evaluate (  \" id \"  ,    hits ,    ratedDocs )  ;", "assertEquals (  0  .  0  ,    result . getQualityLevel (  )  ,     . DELTA )  ;", "assertEquals (  0  ,    EvaluationMetric . filterUnknownDocuments ( result . getHitsAndRatings (  )  )  . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoResults"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "assertParsedCorrect (  \"  {     \\  \" unknown _ doc _ rating \\  \"  :     2  ,     \\  \" normalize \\  \"  :    true ,     \\  \" k \\  \"     :     1  5     }  \"  ,     2  ,    true ,     1  5  )  ;", "assertParsedCorrect (  \"  {     \\  \" normalize \\  \"  :    false ,     \\  \" k \\  \"     :     1  5     }  \"  ,    null ,    false ,     1  5  )  ;", "assertParsedCorrect (  \"  {     \\  \" unknown _ doc _ rating \\  \"  :     2  ,     \\  \" k \\  \"     :     1  5     }  \"  ,     2  ,    false ,     1  5  )  ;", "assertParsedCorrect (  \"  {     \\  \" unknown _ doc _ rating \\  \"  :     2  ,     \\  \" normalize \\  \"  :    true    }  \"  ,     2  ,    true ,     1  0  )  ;", "assertParsedCorrect (  \"  {     \\  \" normalize \\  \"  :    true    }  \"  ,    null ,    true ,     1  0  )  ;", "assertParsedCorrect (  \"  {     \\  \" k \\  \"  :     2  3     }  \"  ,    null ,    false ,     2  3  )  ;", "assertParsedCorrect (  \"  {     \\  \" unknown _ doc _ rating \\  \"  :     2     }  \"  ,     2  ,    false ,     1  0  )  ;", "}", "METHOD_END"], "methodName": ["testParseFromXContent"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "DiscountedCumulativeGain   original    =    DiscountedCumulativeGainTests . createTestItem (  )  ;", "DiscountedCumulativeGain   deserialized    =    ESTestCase . copyWriteable ( original ,    new   NamedWriteableRegistry ( Collections . emptyList (  )  )  ,    DiscountedCumulativeGain :  : new )  ;", "assertEquals ( deserialized ,    original )  ;", "assertEquals ( deserialized . hashCode (  )  ,    original . hashCode (  )  )  ;", "assertNotSame ( deserialized ,    original )  ;", "}", "METHOD_END"], "methodName": ["testSerialization"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "DiscountedCumulativeGain   testItem    =    DiscountedCumulativeGainTests . createTestItem (  )  ;", "XContentType   xContentType    =    randomFrom ( XContentType . values (  )  )  ;", "BytesReference   originalBytes    =    toShuffledXContent ( testItem ,    xContentType ,    EMPTY _ PARAMS ,    randomBoolean (  )  )  ;", "BytesReference   withRandomFields    =    insertRandomFields ( xContentType ,    originalBytes ,    null ,    random (  )  )  ;", "try    ( XContentParser   parser    =    createParser ( xContentType . xContent (  )  ,    withRandomFields )  )     {", "parser . nextToken (  )  ;", "parser . nextToken (  )  ;", "IllegalArgumentException   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    DiscountedCumulativeGain . fromXContent ( parser )  )  ;", "assertThat ( exception . getMessage (  )  ,    startsWith (  \"  [ dcg _ at ]    unknown   field \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentParsingIsNotLenient"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "DiscountedCumulativeGain   testItem    =    DiscountedCumulativeGainTests . createTestItem (  )  ;", "XContentBuilder   builder    =    XContentFactory . contentBuilder ( randomFrom ( XContentType . values (  )  )  )  ;", "XContentBuilder   shuffled    =    shuffleXContent ( testItem . toXContent ( builder ,    EMPTY _ PARAMS )  )  ;", "try    ( XContentParser   itemParser    =    createParser ( shuffled )  )     {", "itemParser . nextToken (  )  ;", "itemParser . nextToken (  )  ;", "DiscountedCumulativeGain   parsedItem    =    DiscountedCumulativeGain . fromXContent ( itemParser )  ;", "assertNotSame ( testItem ,    parsedItem )  ;", "assertEquals ( testItem ,    parsedItem )  ;", "assertEquals ( testItem . hashCode (  )  ,    parsedItem . hashCode (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentRoundtrip"], "fileName": "org.elasticsearch.index.rankeval.DiscountedCumulativeGainTests"}, {"methodBody": ["METHOD_START", "{", "this . ratedHits . addAll ( hits )  ;", "}", "METHOD_END"], "methodName": ["addHitsAndRatings"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQuality"}, {"methodBody": ["METHOD_START", "{", "return   new   EvalQueryQuality ( queryId ,    EvalQueryQuality . PARSER . apply ( parser ,    null )  )  ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQuality"}, {"methodBody": ["METHOD_START", "{", "return   this . ratedHits ;", "}", "METHOD_END"], "methodName": ["getHitsAndRatings"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQuality"}, {"methodBody": ["METHOD_START", "{", "return   queryId ;", "}", "METHOD_END"], "methodName": ["getId"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQuality"}, {"methodBody": ["METHOD_START", "{", "return   this . optionalMetricDetails ;", "}", "METHOD_END"], "methodName": ["getMetricDetails"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQuality"}, {"methodBody": ["METHOD_START", "{", "return   evaluationResult ;", "}", "METHOD_END"], "methodName": ["getQualityLevel"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQuality"}, {"methodBody": ["METHOD_START", "{", "XContentParserUtils . ensureExpectedToken ( START _ OBJECT ,    parser . currentToken (  )  ,    parser :  : getTokenLocation )  ;", "XContentParserUtils . ensureExpectedToken ( FIELD _ NAME ,    parser . nextToken (  )  ,    parser :  : getTokenLocation )  ;", "MetricDetail   metricDetail    =    parser . namedObject ( MetricDetail . cs ,    parser . currentName (  )  ,    null )  ;", "XContentParserUtils . ensureExpectedToken ( END _ OBJECT ,    parser . nextToken (  )  ,    parser :  : getTokenLocation )  ;", "return   metricDetail ;", "}", "METHOD_END"], "methodName": ["parseMetricDetail"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQuality"}, {"methodBody": ["METHOD_START", "{", "this . optionalMetricDetails    =    breakdown ;", "}", "METHOD_END"], "methodName": ["setMetricDetails"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQuality"}, {"methodBody": ["METHOD_START", "{", "return   ESTestCase . copyWriteable ( original ,    EvalQueryQualityTests . namedWritableRegistry ,    EvalQueryQuality :  : new )  ;", "}", "METHOD_END"], "methodName": ["copy"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQualityTests"}, {"methodBody": ["METHOD_START", "{", "String   id    =    original . getId (  )  ;", "double   qualityLevel    =    original . getQualityLevel (  )  ;", "List < RatedSearchHit >    ratedHits    =    new   ArrayList <  >  ( original . getHitsAndRatings (  )  )  ;", "MetricDetail   metricDetails    =    original . getMetricDetails (  )  ;", "switch    ( randomIntBetween (  0  ,     3  )  )     {", "case    0     :", "id    =    id    +     \"  _  \"  ;", "break ;", "case    1     :", "qualityLevel    =    qualityLevel    +     0  .  1  ;", "break ;", "case    2     :", "if    ( metricDetails    =  =    null )     {", "metricDetails    =    new   PrecisionAtK . Breakdown (  1  ,     5  )  ;", "} else    {", "metricDetails    =    null ;", "}", "break ;", "case    3     :", "ratedHits . add ( RatedSearchHitTests . randomRatedSearchHit (  )  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  \" The   test   should   only   allow   four   parameters   mutated \"  )  ;", "}", "evalQueryQuality    =    new    ( id ,    qualityLevel )  ;", "evalQueryQuality . setMetricDetails ( metricDetails )  ;", "evalQueryQuality . addHitsAndRatings ( ratedHits )  ;", "return   evalQueryQuality ;", "}", "METHOD_END"], "methodName": ["mutateTestItem"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQualityTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument . DocumentKey >    unknownDocs    =    new   ArrayList <  >  (  )  ;", "int   numberOfUnknownDocs    =    randomInt (  5  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfUnknownDocs ;    i +  +  )     {", "unknownDocs . add ( new   RatedDocument . DocumentKey ( randomAlphaOfLength (  1  0  )  ,    randomAlphaOfLength (  1  0  )  )  )  ;", "}", "int   numberOfSearchHits    =    randomInt (  5  )  ;", "List < RatedSearchHit >    ratedHits    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfSearchHits ;    i +  +  )     {", "RatedSearchHit   ratedSearchHit    =    RatedSearchHitTests . randomRatedSearchHit (  )  ;", "ratedSearchHit . getSearchHit (  )  . shard ( new   search . SearchShardTarget (  \"  _ na _  \"  ,    new   Index (  \" index \"  ,     \"  _ na _  \"  )  ,     0  ,    null )  )  ;", "ratedHits . add ( ratedSearchHit )  ;", "}", "EvalQueryQuality   evalQueryQuality    =    new   EvalQueryQuality ( randomAlphaOfLength (  1  0  )  ,    randomDoubleBetween (  0  .  0  ,     1  .  0  ,    true )  )  ;", "if    ( randomBoolean (  )  )     {", "if    ( randomBoolean (  )  )     {", "evalQueryQuality . setMetricDetails ( new   PrecisionAtK . Breakdown ( randomIntBetween (  0  ,     1  0  0  0  )  ,    randomIntBetween (  0  ,     1  0  0  0  )  )  )  ;", "} else    {", "evalQueryQuality . setMetricDetails ( new   MeanReciprocalRank . Breakdown ( randomIntBetween (  0  ,     1  0  0  0  )  )  )  ;", "}", "}", "evalQueryQuality . addHitsAndRatings ( ratedHits )  ;", "return   evalQueryQuality ;", "}", "METHOD_END"], "methodName": ["randomEvalQueryQuality"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQualityTests"}, {"methodBody": ["METHOD_START", "{", "checkEqualsAndHashCode ( EvalQueryQualityTests . randomEvalQueryQuality (  )  ,    EvalQueryQualityTests :  : copy ,    EvalQueryQualityTests :  : mutateTestItem )  ;", "}", "METHOD_END"], "methodName": ["testEqualsAndHash"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQualityTests"}, {"methodBody": ["METHOD_START", "{", "EvalQueryQuality   original    =    EvalQueryQualityTests . randomEvalQueryQuality (  )  ;", "EvalQueryQuality   deserialized    =    EvalQueryQualityTests . copy ( original )  ;", "assertEquals ( deserialized ,    original )  ;", "assertEquals ( deserialized . hashCode (  )  ,    original . hashCode (  )  )  ;", "assertNotSame ( deserialized ,    original )  ;", "}", "METHOD_END"], "methodName": ["testSerialization"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQualityTests"}, {"methodBody": ["METHOD_START", "{", "EvalQueryQuality   testItem    =    EvalQueryQualityTests . randomEvalQueryQuality (  )  ;", "boolean   humanReadable    =    randomBoolean (  )  ;", "XContentType   xContentType    =    randomFrom ( XContentType . values (  )  )  ;", "BytesReference   originalBytes    =    toShuffledXContent ( testItem ,    xContentType ,    EMPTY _ PARAMS ,    humanReadable )  ;", "Predicate < String >    pathsToExclude    =     (    path )     -  >     (  ( path . isEmpty (  )  )     |  |     ( path . endsWith (  \" metric _ details \"  )  )  )     |  |     ( path . contains (  \" hits \"  )  )  ;", "BytesReference   withRandomFields    =    insertRandomFields ( xContentType ,    originalBytes ,    pathsToExclude ,    random (  )  )  ;", "EvalQueryQuality   parsedItem ;", "try    ( XContentParser   parser    =    createParser ( xContentType . xContent (  )  ,    withRandomFields )  )     {", "ensureExpectedToken ( START _ OBJECT ,    parser . nextToken (  )  ,    parser :  : getTokenLocation )  ;", "ensureExpectedToken ( FIELD _ NAME ,    parser . nextToken (  )  ,    parser :  : getTokenLocation )  ;", "String   queryId    =    parser . currentName (  )  ;", "ensureExpectedToken ( START _ OBJECT ,    parser . nextToken (  )  ,    parser :  : getTokenLocation )  ;", "parsedItem    =    EvalQueryQuality . fromXContent ( parser ,    queryId )  ;", "ensureExpectedToken ( END _ OBJECT ,    parser . currentToken (  )  ,    parser :  : getTokenLocation )  ;", "ensureExpectedToken ( END _ OBJECT ,    parser . nextToken (  )  ,    parser :  : getTokenLocation )  ;", "assertNull ( parser . nextToken (  )  )  ;", "}", "assertNotSame ( testItem ,    parsedItem )  ;", "assertToXContentEquivalent ( originalBytes ,    toXContent ( parsedItem ,    xContentType ,    humanReadable )  ,    xContentType )  ;", "}", "METHOD_END"], "methodName": ["testXContentParsing"], "fileName": "org.elasticsearch.index.rankeval.EvalQueryQualityTests"}, {"methodBody": ["METHOD_START", "{", "return    ( partialResults . stream (  )  . mapToDouble ( EvalQueryQuality :  : getQualityLevel )  . sum (  )  )     /     ( partialResults . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["combine"], "fileName": "org.elasticsearch.index.rankeval.EvaluationMetric"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument . DocumentKey >    unknownDocs    =    ratedHits . stream (  )  . filter (  (    hit )     -  >     ( hit . getRating (  )  . isPresent (  )  )     =  =    false )  . map (  (    hit )     -  >    new   RatedDocument . DocumentKey ( hit . getSearchHit (  )  . getIndex (  )  ,    hit . getSearchHit (  )  . getId (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "return   unknownDocs ;", "}", "METHOD_END"], "methodName": ["filterUnknownDocuments"], "fileName": "org.elasticsearch.index.rankeval.EvaluationMetric"}, {"methodBody": ["METHOD_START", "{", "return   Optional . empty (  )  ;", "}", "METHOD_END"], "methodName": ["forcedSearchSize"], "fileName": "org.elasticsearch.index.rankeval.EvaluationMetric"}, {"methodBody": ["METHOD_START", "{", "Map < RatedDocument . DocumentKey ,    RatedDocument >    ratedDocumentMap    =    ratedDocs . stream (  )  . collect ( Collectors . toMap ( RatedDocument :  : getKey ,     (    item )     -  >    item )  )  ;", "List < RatedSHit >    ratedSHits    =    new   ArrayList ( hits . length )  ;", "for    ( SHit   hit    :    hits )     {", "RatedDocument . DocumentKey   key    =    new   RatedDocument . DocumentKey ( hit . getIndex (  )  ,    hit . getId (  )  )  ;", "RatedDocument   ratedDoc    =    ratedDocumentMap . get ( key )  ;", "if    ( ratedDoc    !  =    null )     {", "ratedSHits . add ( new   RatedSHit ( hit ,    Optional . of ( ratedDoc . getRating (  )  )  )  )  ;", "} else    {", "ratedSHits . add ( new   RatedSHit ( hit ,    Optional . empty (  )  )  )  ;", "}", "}", "return   ratedSHits ;", "}", "METHOD_END"], "methodName": ["joinHitsWithRatings"], "fileName": "org.elasticsearch.index.rankeval.EvaluationMetric"}, {"methodBody": ["METHOD_START", "{", "return   MeanReciprocalRank . PARSER . apply ( parser ,    null )  ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRank"}, {"methodBody": ["METHOD_START", "{", "return   this . k ;", "}", "METHOD_END"], "methodName": ["getK"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRank"}, {"methodBody": ["METHOD_START", "{", "return   relevantRatingThreshhold ;", "}", "METHOD_END"], "methodName": ["getRelevantRatingThreshold"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRank"}, {"methodBody": ["METHOD_START", "{", "return   new   MeanReciprocalRank ( testItem . getRelevantRatingThreshold (  )  ,    testItem . getK (  )  )  ;", "}", "METHOD_END"], "methodName": ["copy"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "SearchHit [  ]    hits    =    new   SearchHit [  ( to    +     1  )     -    from ]  ;", "for    ( int   i    =    from ;    i    <  =    to ;    i +  +  )     {", "hits [ i ]     =    new   SearchHit ( i ,     ( i    +     \"  \"  )  ,    new   Text (  \"  \"  )  ,    Collections . emptyMap (  )  )  ;", "hits [ i ]  . shard ( new   search . SearchShardTarget (  \" testnode \"  ,    new   Index ( index ,     \" uuid \"  )  ,     0  ,    null )  )  ;", "}", "return   hits ;", "}", "METHOD_END"], "methodName": ["createSearchHits"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "return   new   MeanReciprocalRank ( randomIntBetween (  0  ,     2  0  )  ,    randomIntBetween (  1  ,     2  0  )  )  ;", "}", "METHOD_END"], "methodName": ["createTestItem"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "if    ( randomBoolean (  )  )     {", "return   new    (  (  ( testItem . getRelevantRatingThreshold (  )  )     +     1  )  ,    testItem . getK (  )  )  ;", "} else    {", "return   new    ( testItem . getRelevantRatingThreshold (  )  ,     (  ( testItem . getK (  )  )     +     1  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["mutate"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "MeanReciprocalRank   reciprocalRank    =    new   MeanReciprocalRank (  )  ;", "Vector < EvalQueryQuality >    partialResults    =    new   Vector <  >  (  3  )  ;", "partialResults . add ( new   EvalQueryQuality (  \" id 1  \"  ,     0  .  5  )  )  ;", "partialResults . add ( new   EvalQueryQuality (  \" id 2  \"  ,     1  .  0  )  )  ;", "partialResults . add ( new   EvalQueryQuality (  \" id 3  \"  ,     0  .  7  5  )  )  ;", "assertEquals (  0  .  7  5  ,    reciprocalRank . combine ( partialResults )  ,    Double . MIN _ VALUE )  ;", "}", "METHOD_END"], "methodName": ["testCombine"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "checkEqualsAndHashCode ( MeanReciprocalRankTests . createTestItem (  )  ,    MeanReciprocalRankTests :  : copy ,    MeanReciprocalRankTests :  : mutate )  ;", "}", "METHOD_END"], "methodName": ["testEqualsAndHash"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "MeanReciprocalRank   reciprocalRank    =    new   MeanReciprocalRank (  )  ;", "SearchHit [  ]    hits    =     . createSearchHits (  0  ,     9  ,     \" test \"  )  ;", "List < RatedDocument >    ratedDocs    =    new   ArrayList <  >  (  )  ;", "EvalQueryQuality   evaluation    =    reciprocalRank . evaluate (  \" id \"  ,    hits ,    ratedDocs )  ;", "assertEquals (  0  .  0  ,    evaluation . getQualityLevel (  )  ,    Double . MIN _ VALUE )  ;", "}", "METHOD_END"], "methodName": ["testEvaluationNoRelevantInResults"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "MeanReciprocalRank   reciprocalRank    =    new   MeanReciprocalRank (  )  ;", "SearchHit [  ]    hits    =     . createSearchHits (  0  ,     9  ,     \" test \"  )  ;", "List < RatedDocument >    ratedDocs    =    new   ArrayList <  >  (  )  ;", "int   relevantAt    =    randomIntBetween (  0  ,     9  )  ;", "for    ( int   i    =     0  ;    i    <  =     2  0  ;    i +  +  )     {", "if    ( i    =  =    relevantAt )     {", "ratedDocs . add ( new   RatedDocument (  \" test \"  ,    Integer . toString ( i )  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "} else    {", "ratedDocs . add ( new   RatedDocument (  \" test \"  ,    Integer . toString ( i )  ,    TestRatingEnum . IRRELEVANT . ordinal (  )  )  )  ;", "}", "}", "EvalQueryQuality   evaluation    =    reciprocalRank . evaluate (  \" id \"  ,    hits ,    ratedDocs )  ;", "assertEquals (  (  1  .  0     /     ( relevantAt    +     1  )  )  ,    evaluation . getQualityLevel (  )  ,    Double . MIN _ VALUE )  ;", "assertEquals (  ( relevantAt    +     1  )  ,     (  ( MeanReciprocalRank . Breakdown )     ( evaluation . getMetricDetails (  )  )  )  . getFirstRelevantRank (  )  )  ;", "}", "METHOD_END"], "methodName": ["testEvaluationOneRelevantInResults"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new   MeanReciprocalRank (  1  ,     (  -  1  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidK"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new   MeanReciprocalRank (  (  -  1  )  ,     1  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidRelevantThreshold"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "MeanReciprocalRank   reciprocalRank    =    new   MeanReciprocalRank (  )  ;", "int   searchHits    =    randomIntBetween (  1  ,     5  0  )  ;", "SearchHit [  ]    hits    =     . createSearchHits (  0  ,    searchHits ,     \" test \"  )  ;", "List < RatedDocument >    ratedDocs    =    new   ArrayList <  >  (  )  ;", "int   relevantAt    =    randomIntBetween (  0  ,    searchHits )  ;", "for    ( int   i    =     0  ;    i    <  =    searchHits ;    i +  +  )     {", "if    ( i    =  =    relevantAt )     {", "ratedDocs . add ( new   RatedDocument (  \" test \"  ,    Integer . toString ( i )  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "} else    {", "ratedDocs . add ( new   RatedDocument (  \" test \"  ,    Integer . toString ( i )  ,    TestRatingEnum . IRRELEVANT . ordinal (  )  )  )  ;", "}", "}", "int   rankAtFirstRelevant    =    relevantAt    +     1  ;", "EvalQueryQuality   evaluation    =    reciprocalRank . evaluate (  \" id \"  ,    hits ,    ratedDocs )  ;", "assertEquals (  (  1  .  0     /    rankAtFirstRelevant )  ,    evaluation . getQualityLevel (  )  ,    Double . MIN _ VALUE )  ;", "assertEquals ( rankAtFirstRelevant ,     (  ( MeanReciprocalRank . Breakdown )     ( evaluation . getMetricDetails (  )  )  )  . getFirstRelevantRank (  )  )  ;", "reciprocalRank    =    new   MeanReciprocalRank (  )  ;", "evaluation    =    reciprocalRank . evaluate (  \" id \"  ,    Arrays . copyOfRange ( hits ,     0  ,    relevantAt )  ,    ratedDocs )  ;", "assertEquals (  0  .  0  ,    evaluation . getQualityLevel (  )  ,    Double . MIN _ VALUE )  ;", "}", "METHOD_END"], "methodName": ["testMaxAcceptableRank"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "SearchHit [  ]    hits    =    new   SearchHit [  0  ]  ;", "EvalQueryQuality   evaluated    =    new    (  )  . evaluate (  \" id \"  ,    hits ,    Collections . emptyList (  )  )  ;", "assertEquals (  0  .  0  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  (  -  1  )  ,     (  (  . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getFirstRelevantRank (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoResults"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "String   xContent    =     \"  {     }  \"  ;", "try    ( XContentParser   parser    =    createParser ( jsonXContent ,    xContent )  )     {", "mrr    =     . fromXContent ( parser )  ;", "assertEquals (  1  ,    mrr . getRelevantRatingThreshold (  )  )  ;", "assertEquals (  1  0  ,    mrr . getK (  )  )  ;", "}", "xContent    =     \"  {     \\  \" relevant _ rating _ threshold \\  \"  :     2     }  \"  ;", "try    ( XContentParser   parser    =    createParser ( jsonXContent ,    xContent )  )     {", "mrr    =     . fromXContent ( parser )  ;", "assertEquals (  2  ,    mrr . getRelevantRatingThreshold (  )  )  ;", "assertEquals (  1  0  ,    mrr . getK (  )  )  ;", "}", "xContent    =     \"  {     \\  \" relevant _ rating _ threshold \\  \"  :     2  ,     \\  \" k \\  \"     :     1  5     }  \"  ;", "try    ( XContentParser   parser    =    createParser ( jsonXContent ,    xContent )  )     {", "mrr    =     . fromXContent ( parser )  ;", "assertEquals (  2  ,    mrr . getRelevantRatingThreshold (  )  )  ;", "assertEquals (  1  5  ,    mrr . getK (  )  )  ;", "}", "xContent    =     \"  {     \\  \" k \\  \"     :     1  5     }  \"  ;", "try    ( XContentParser   parser    =    createParser ( jsonXContent ,    xContent )  )     {", "mrr    =     . fromXContent ( parser )  ;", "assertEquals (  1  ,    mrr . getRelevantRatingThreshold (  )  )  ;", "assertEquals (  1  5  ,    mrr . getK (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testParseFromXContent"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    rated    =    new   ArrayList <  >  (  )  ;", "rated . add ( new   RatedDocument (  \" test \"  ,     \"  0  \"  ,     0  )  )  ;", "rated . add ( new   RatedDocument (  \" test \"  ,     \"  1  \"  ,     1  )  )  ;", "rated . add ( new   RatedDocument (  \" test \"  ,     \"  2  \"  ,     2  )  )  ;", "rated . add ( new   RatedDocument (  \" test \"  ,     \"  3  \"  ,     3  )  )  ;", "rated . add ( new   RatedDocument (  \" test \"  ,     \"  4  \"  ,     4  )  )  ;", "SearchHit [  ]    hits    =     . createSearchHits (  0  ,     5  ,     \" test \"  )  ;", "MeanReciprocalRank   reciprocalRank    =    new   MeanReciprocalRank (  2  ,     1  0  )  ;", "EvalQueryQuality   evaluation    =    reciprocalRank . evaluate (  \" id \"  ,    hits ,    rated )  ;", "assertEquals (  (  (  ( double )     (  1  )  )     /     3  )  ,    evaluation . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  3  ,     (  ( MeanReciprocalRank . Breakdown )     ( evaluation . getMetricDetails (  )  )  )  . getFirstRelevantRank (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrecisionAtFiveRelevanceThreshold"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "MeanReciprocalRank   original    =    MeanReciprocalRankTests . createTestItem (  )  ;", "MeanReciprocalRank   deserialized    =    ESTestCase . copyWriteable ( original ,    new   NamedWriteableRegistry ( Collections . emptyList (  )  )  ,    MeanReciprocalRank :  : new )  ;", "assertEquals ( deserialized ,    original )  ;", "assertEquals ( deserialized . hashCode (  )  ,    original . hashCode (  )  )  ;", "assertNotSame ( deserialized ,    original )  ;", "}", "METHOD_END"], "methodName": ["testSerialization"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "MeanReciprocalRank   testItem    =    MeanReciprocalRankTests . createTestItem (  )  ;", "XContentType   xContentType    =    randomFrom ( XContentType . values (  )  )  ;", "BytesReference   originalBytes    =    toShuffledXContent ( testItem ,    xContentType ,    EMPTY _ PARAMS ,    randomBoolean (  )  )  ;", "BytesReference   withRandomFields    =    insertRandomFields ( xContentType ,    originalBytes ,    null ,    random (  )  )  ;", "try    ( XContentParser   parser    =    createParser ( xContentType . xContent (  )  ,    withRandomFields )  )     {", "parser . nextToken (  )  ;", "parser . nextToken (  )  ;", "IllegalArgumentException   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    MeanReciprocalRank . fromXContent ( parser )  )  ;", "assertThat ( exception . getMessage (  )  ,    startsWith (  \"  [ reciprocal _ rank ]    unknown   field \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentParsingIsNotLenient"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "MeanReciprocalRank   testItem    =    MeanReciprocalRankTests . createTestItem (  )  ;", "XContentBuilder   builder    =    XContentFactory . contentBuilder ( randomFrom ( XContentType . values (  )  )  )  ;", "XContentBuilder   shuffled    =    shuffleXContent ( testItem . toXContent ( builder ,    EMPTY _ PARAMS )  )  ;", "try    ( XContentParser   itemParser    =    createParser ( shuffled )  )     {", "itemParser . nextToken (  )  ;", "itemParser . nextToken (  )  ;", "MeanReciprocalRank   parsedItem    =    MeanReciprocalRank . fromXContent ( itemParser )  ;", "assertNotSame ( testItem ,    parsedItem )  ;", "assertEquals ( testItem ,    parsedItem )  ;", "assertEquals ( testItem . hashCode (  )  ,    parsedItem . hashCode (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentRoundtrip"], "fileName": "org.elasticsearch.index.rankeval.MeanReciprocalRankTests"}, {"methodBody": ["METHOD_START", "{", "return   getWriteableName (  )  ;", "}", "METHOD_END"], "methodName": ["getMetricName"], "fileName": "org.elasticsearch.index.rankeval.MetricDetail"}, {"methodBody": ["METHOD_START", "{", "return   PrecisionAtK . PARSER . apply ( parser ,    null )  ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtK"}, {"methodBody": ["METHOD_START", "{", "return   ignoreUnlabeled ;", "}", "METHOD_END"], "methodName": ["getIgnoreUnlabeled"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtK"}, {"methodBody": ["METHOD_START", "{", "return   this . k ;", "}", "METHOD_END"], "methodName": ["getK"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtK"}, {"methodBody": ["METHOD_START", "{", "return   relevantRatingThreshhold ;", "}", "METHOD_END"], "methodName": ["getRelevantRatingThreshold"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtK"}, {"methodBody": ["METHOD_START", "{", "return   new   PrecisionAtK ( original . getRelevantRatingThreshold (  )  ,    original . getIgnoreUnlabeled (  )  ,    original . forcedSearchSize (  )  . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["copy"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "return   new   RatedDocument ( index ,    id ,    rating )  ;", "}", "METHOD_END"], "methodName": ["createRatedDoc"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "return   new   PrecisionAtK ( randomIntBetween (  0  ,     1  0  )  ,    randomBoolean (  )  ,    randomIntBetween (  1  ,     5  0  )  )  ;", "}", "METHOD_END"], "methodName": ["createTestItem"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "PrecisionAtK   pAtK ;", "switch    ( randomIntBetween (  0  ,     2  )  )     {", "case    0     :", "pAtK    =    new   PrecisionAtK ( original . getRelevantRatingThreshold (  )  ,     (  !  ( original . getIgnoreUnlabeled (  )  )  )  ,    original . forcedSearchSize (  )  . get (  )  )  ;", "break ;", "case    1     :", "pAtK    =    new   PrecisionAtK ( randomValueOtherThan ( original . getRelevantRatingThreshold (  )  ,     (  )     -  >    randomIntBetween (  0  ,     1  0  )  )  ,    original . getIgnoreUnlabeled (  )  ,    original . forcedSearchSize (  )  . get (  )  )  ;", "break ;", "case    2     :", "pAtK    =    new   PrecisionAtK ( original . getRelevantRatingThreshold (  )  ,    original . getIgnoreUnlabeled (  )  ,     (  ( original . forcedSearchSize (  )  . get (  )  )     +     1  )  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  \" The   test   should   only   allow   three   parameters   mutated \"  )  ;", "}", "return   pAtK ;", "}", "METHOD_END"], "methodName": ["mutate"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "PrecisionAtK   metric    =    new   PrecisionAtK (  )  ;", "Vector < EvalQueryQuality >    partialResults    =    new   Vector <  >  (  3  )  ;", "partialResults . add ( new   EvalQueryQuality (  \" a \"  ,     0  .  1  )  )  ;", "partialResults . add ( new   EvalQueryQuality (  \" b \"  ,     0  .  2  )  )  ;", "partialResults . add ( new   EvalQueryQuality (  \" c \"  ,     0  .  6  )  )  ;", "assertEquals (  0  .  3  ,    metric . combine ( partialResults )  ,    Double . MIN _ VALUE )  ;", "}", "METHOD_END"], "methodName": ["testCombine"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "checkEqualsAndHashCode ( PrecisionAtKTests . createTestItem (  )  ,    PrecisionAtKTests :  : copy ,    PrecisionAtKTests :  : mutate )  ;", "}", "METHOD_END"], "methodName": ["testEqualsAndHash"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    rated    =    new   ArrayList <  >  (  )  ;", "rated . add ( PrecisionAtKTests . createRatedDoc (  \" test \"  ,     \"  0  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "rated . add ( PrecisionAtKTests . createRatedDoc (  \" test \"  ,     \"  1  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "SearchHit [  ]    searchHits    =    Arrays . copyOf ( PrecisionAtKTests . toSearchHits ( rated ,     \" test \"  )  ,     3  )  ;", "searchHits [  2  ]     =    new   SearchHit (  2  ,     \"  2  \"  ,    new   Text (  \" testtype \"  )  ,    Collections . emptyMap (  )  )  ;", "searchHits [  2  ]  . shard ( new   search . SearchShardTarget (  \" testnode \"  ,    new   Index (  \" index \"  ,     \" uuid \"  )  ,     0  ,    null )  )  ;", "EvalQueryQuality   evaluated    =    new   PrecisionAtK (  )  . evaluate (  \" id \"  ,    searchHits ,    rated )  ;", "assertEquals (  (  (  ( double )     (  2  )  )     /     3  )  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  2  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRelevantRetrieved (  )  )  ;", "assertEquals (  3  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRetrieved (  )  )  ;", "PrecisionAtK   prec    =    new   PrecisionAtK (  1  ,    true ,     1  0  )  ;", "evaluated    =    prec . evaluate (  \" id \"  ,    searchHits ,    rated )  ;", "assertEquals (  (  (  ( double )     (  2  )  )     /     2  )  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  2  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRelevantRetrieved (  )  )  ;", "assertEquals (  2  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRetrieved (  )  )  ;", "}", "METHOD_END"], "methodName": ["testIgnoreUnlabeled"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new   PrecisionAtK (  1  ,    false ,     (  -  1  0  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidK"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new   PrecisionAtK (  (  -  1  )  ,    false ,     1  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidRelevantThreshold"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "SearchHit [  ]    hits    =    new   SearchHit [  5  ]  ;", "for    ( int   i    =     0  ;    i    <     5  ;    i +  +  )     {", "hits [ i ]     =    new   SearchHit ( i ,     ( i    +     \"  \"  )  ,    new   Text (  \" type \"  )  ,    Collections . emptyMap (  )  )  ;", "hits [ i ]  . shard ( new   search . SearchShardTarget (  \" testnode \"  ,    new   Index (  \" index \"  ,     \" uuid \"  )  ,     0  ,    null )  )  ;", "}", "EvalQueryQuality   evaluated    =    new   PrecisionAtK (  )  . evaluate (  \" id \"  ,    hits ,    Collections . emptyList (  )  )  ;", "assertEquals (  0  .  0  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  0  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRelevantRetrieved (  )  )  ;", "assertEquals (  5  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRetrieved (  )  )  ;", "PrecisionAtK   prec    =    new   PrecisionAtK (  1  ,    true ,     1  0  )  ;", "evaluated    =    prec . evaluate (  \" id \"  ,    hits ,    Collections . emptyList (  )  )  ;", "assertEquals (  0  .  0  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  0  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRelevantRetrieved (  )  )  ;", "assertEquals (  0  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRetrieved (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoRatedDocs"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "SearchHit [  ]    hits    =    new   SearchHit [  0  ]  ;", "EvalQueryQuality   evaluated    =    new    (  )  . evaluate (  \" id \"  ,    hits ,    Collections . emptyList (  )  )  ;", "assertEquals (  0  .  0  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  0  ,     (  (  . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRelevantRetrieved (  )  )  ;", "assertEquals (  0  ,     (  (  . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRetrieved (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoResults"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "String   xContent    =     \"     {  \\ n \"     +     (  \"           \\  \" relevant _ rating _ threshold \\  \"     :     2  \"     +     \"  }  \"  )  ;", "try    ( XContentParser   parser    =    createParser ( jsonXContent ,    xContent )  )     {", "precicionAt    =     . fromXContent ( parser )  ;", "assertEquals (  2  ,    precicionAt . getRelevantRatingThreshold (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testParseFromXContent"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    rated    =    new   ArrayList <  >  (  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  0  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "EvalQueryQuality   evaluated    =    new   PrecisionAtK (  )  . evaluate (  \" id \"  ,     . toSearchHits ( rated ,     \" test \"  )  ,    rated )  ;", "assertEquals (  1  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  1  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRelevantRetrieved (  )  )  ;", "assertEquals (  1  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRetrieved (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrecisionAtFiveCalculation"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    rated    =    new   ArrayList <  >  (  )  ;", "rated . add (  . createRatedDoc (  \" test _ other \"  ,     \"  0  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "rated . add (  . createRatedDoc (  \" test _ other \"  ,     \"  1  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  0  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  1  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  2  \"  ,    TestRatingEnum . IRRELEVANT . ordinal (  )  )  )  ;", "EvalQueryQuality   evaluated    =    new   PrecisionAtK (  )  . evaluate (  \" id \"  ,     . toSearchHits ( rated . subList (  2  ,     5  )  ,     \" test \"  )  ,    rated )  ;", "assertEquals (  (  (  ( double )     (  2  )  )     /     3  )  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  2  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRelevantRetrieved (  )  )  ;", "assertEquals (  3  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRetrieved (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrecisionAtFiveCorrectIndex"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    rated    =    new   ArrayList <  >  (  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  0  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  1  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  2  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  3  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  4  \"  ,    TestRatingEnum . IRRELEVANT . ordinal (  )  )  )  ;", "EvalQueryQuality   evaluated    =    new   PrecisionAtK (  )  . evaluate (  \" id \"  ,     . toSearchHits ( rated ,     \" test \"  )  ,    rated )  ;", "assertEquals (  (  (  ( double )     (  4  )  )     /     5  )  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  4  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRelevantRetrieved (  )  )  ;", "assertEquals (  5  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRetrieved (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrecisionAtFiveIgnoreOneResult"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    rated    =    new   ArrayList <  >  (  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  0  \"  ,     0  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  1  \"  ,     1  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  2  \"  ,     2  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  3  \"  ,     3  )  )  ;", "rated . add (  . createRatedDoc (  \" test \"  ,     \"  4  \"  ,     4  )  )  ;", "PrecisionAtK   precisionAtN    =    new   PrecisionAtK (  2  ,    false ,     5  )  ;", "EvalQueryQuality   evaluated    =    precisionAtN . evaluate (  \" id \"  ,     . toSearchHits ( rated ,     \" test \"  )  ,    rated )  ;", "assertEquals (  (  (  ( double )     (  3  )  )     /     5  )  ,    evaluated . getQualityLevel (  )  ,     1  .  0 E -  5  )  ;", "assertEquals (  3  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRelevantRetrieved (  )  )  ;", "assertEquals (  5  ,     (  ( PrecisionAtK . Breakdown )     ( evaluated . getMetricDetails (  )  )  )  . getRetrieved (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrecisionAtFiveRelevanceThreshold"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "PrecisionAtK   original    =    PrecisionAtKTests . createTestItem (  )  ;", "PrecisionAtK   deserialized    =    ESTestCase . copyWriteable ( original ,    new   NamedWriteableRegistry ( Collections . emptyList (  )  )  ,    PrecisionAtK :  : new )  ;", "assertEquals ( deserialized ,    original )  ;", "assertEquals ( deserialized . hashCode (  )  ,    original . hashCode (  )  )  ;", "assertNotSame ( deserialized ,    original )  ;", "}", "METHOD_END"], "methodName": ["testSerialization"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "PrecisionAtK   testItem    =    PrecisionAtKTests . createTestItem (  )  ;", "XContentType   xContentType    =    randomFrom ( XContentType . values (  )  )  ;", "BytesReference   originalBytes    =    toShuffledXContent ( testItem ,    xContentType ,    EMPTY _ PARAMS ,    randomBoolean (  )  )  ;", "BytesReference   withRandomFields    =    insertRandomFields ( xContentType ,    originalBytes ,    null ,    random (  )  )  ;", "try    ( XContentParser   parser    =    createParser ( xContentType . xContent (  )  ,    withRandomFields )  )     {", "parser . nextToken (  )  ;", "parser . nextToken (  )  ;", "IllegalArgumentException   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    PrecisionAtK . fromXContent ( parser )  )  ;", "assertThat ( exception . getMessage (  )  ,    startsWith (  \"  [ precision ]    unknown   field \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentParsingIsNotLenient"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "PrecisionAtK   testItem    =    PrecisionAtKTests . createTestItem (  )  ;", "XContentBuilder   builder    =    XContentFactory . contentBuilder ( randomFrom ( XContentType . values (  )  )  )  ;", "XContentBuilder   shuffled    =    shuffleXContent ( testItem . toXContent ( builder ,    EMPTY _ PARAMS )  )  ;", "try    ( XContentParser   itemParser    =    createParser ( shuffled )  )     {", "itemParser . nextToken (  )  ;", "itemParser . nextToken (  )  ;", "PrecisionAtK   parsedItem    =    PrecisionAtK . fromXContent ( itemParser )  ;", "assertNotSame ( testItem ,    parsedItem )  ;", "assertEquals ( testItem ,    parsedItem )  ;", "assertEquals ( testItem . hashCode (  )  ,    parsedItem . hashCode (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentRoundtrip"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "SearchHit [  ]    hits    =    new   SearchHit [ rated . size (  )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( rated . size (  )  )  ;    i +  +  )     {", "hits [ i ]     =    new   SearchHit ( i ,     ( i    +     \"  \"  )  ,    new   Text (  \"  \"  )  ,    Collections . emptyMap (  )  )  ;", "hits [ i ]  . shard ( new   search . SearchShardTarget (  \" testnode \"  ,    new   Index ( index ,     \" uuid \"  )  ,     0  ,    null )  )  ;", "}", "return   hits ;", "}", "METHOD_END"], "methodName": ["toSearchHits"], "fileName": "org.elasticsearch.index.rankeval.PrecisionAtKTests"}, {"methodBody": ["METHOD_START", "{", "return   rankingEvaluationSpec ;", "}", "METHOD_END"], "methodName": ["getRankEvalSpec"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequest"}, {"methodBody": ["METHOD_START", "{", "this . indicesOptions    =    Objects . requireNonNull ( indicesOptions ,     \" indicesOptions   must   not   be   null \"  )  ;", "}", "METHOD_END"], "methodName": ["indicesOptions"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequest"}, {"methodBody": ["METHOD_START", "{", "this . rankingEvaluationSpec    =    task ;", "}", "METHOD_END"], "methodName": ["setRankEvalSpec"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequest"}, {"methodBody": ["METHOD_START", "{", "return   this . request . getRankEvalSpec (  )  ;", "}", "METHOD_END"], "methodName": ["getRankEvalSpec"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "this . request . setRankEvalSpec ( spec )  ;", "}", "METHOD_END"], "methodName": ["setRankEvalSpec"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    relevant    =    new   ArrayList <  >  (  )  ;", "for    ( String   doc    :    docs )     {", "relevant . add ( new   RatedDocument (  \" test \"  ,    doc ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "}", "return   relevant ;", "}", "METHOD_END"], "methodName": ["createRelevant"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestIT"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  1  \"  )  . setSource (  \" text \"  ,     \" berlin \"  ,     \" title \"  ,     \" Berlin ,    Germany \"  ,     \" population \"  ,     3  6  7  0  6  2  2  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  2  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  ,     \" population \"  ,     8  5  1  5  7  3  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  3  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  ,     \" population \"  ,     8  5  1  5  7  3  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  4  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  ,     \" population \"  ,     8  5  1  5  7  3  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  5  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  ,     \" population \"  ,     8  5  1  5  7  3  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  6  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  ,     \" population \"  ,     8  5  1  5  7  3  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test 2  \"  ,     \" testtype \"  )  . setId (  \"  7  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  ,     \" population \"  ,     8  5  1  5  7  3  )  . get (  )  ;", "refresh (  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestIT"}, {"methodBody": ["METHOD_START", "{", "List < RatedRequest >    specifications    =    new   ArrayList <  >  (  )  ;", "SearchSourceBuilder   amsterdamQuery    =    new   SearchSourceBuilder (  )  ;", "amsterdamQuery . query ( new   MatchAllQueryBuilder (  )  )  ;", "RatedRequest   amsterdamRequest    =    new   RatedRequest (  \" amsterdam _ query \"  ,     . createRelevant (  \"  2  \"  ,     \"  3  \"  ,     \"  4  \"  ,     \"  5  \"  )  ,    amsterdamQuery )  ;", "specifications . add ( amsterdamRequest )  ;", "SearchSourceBuilder   brokenQuery    =    new   SearchSourceBuilder (  )  ;", "brokenQuery . query ( QueryBuilders . termQuery (  \" population \"  ,     \" noStringOnNumericFields \"  )  )  ;", "RatedRequest   brokenRequest    =    new   RatedRequest (  \" broken _ query \"  ,     . createRelevant (  \"  1  \"  )  ,    brokenQuery )  ;", "specifications . add ( brokenRequest )  ;", "RankEvalSpec   task    =    new   RankEvalSpec ( specifications ,    new   PrecisionAtK (  )  )  ;", "RankEvalRequestBuilder   builder    =    new   RankEvalRequestBuilder ( client (  )  ,    RankEvalAction . INSTANCE ,    new   RankEvalRequest ( task ,    new   String [  ]  {     \" test \"     }  )  )  ;", "builder . setRankEvalSpec ( task )  ;", "RankEvalResponse   response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    builder . request (  )  )  . actionGet (  )  ;", "assertEquals (  1  ,    response . getFailures (  )  . size (  )  )  ;", "ElasticsearchException [  ]    rootCauses    =    ElasticsearchException . guessRootCauses ( response . getFailures (  )  . get (  \" broken _ query \"  )  )  ;", "assertEquals (  \" NumberFormatException :    For   input   string :     \\  \" noStringOnNumericFields \\  \"  \"  ,    rootCauses [  0  ]  . getCause (  )  . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBadQuery"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestIT"}, {"methodBody": ["METHOD_START", "{", "SearchSourceBuilder   testQuery    =    new   SearchSourceBuilder (  )  ;", "testQuery . query ( new   MatchAllQueryBuilder (  )  )  ;", "testQuery . sort (  \"  _ id \"  )  ;", "List < RatedRequest >    specifications    =    new   ArrayList <  >  (  )  ;", "List < RatedDocument >    ratedDocs    =    Arrays . asList ( new   RatedDocument (  \" test \"  ,     \"  1  \"  ,     3  )  ,    new   RatedDocument (  \" test \"  ,     \"  2  \"  ,     2  )  ,    new   RatedDocument (  \" test \"  ,     \"  3  \"  ,     3  )  ,    new   RatedDocument (  \" test \"  ,     \"  4  \"  ,     0  )  ,    new   RatedDocument (  \" test \"  ,     \"  5  \"  ,     1  )  ,    new   RatedDocument (  \" test \"  ,     \"  6  \"  ,     2  )  )  ;", "specifications . add ( new   RatedRequest (  \" amsterdam _ query \"  ,    ratedDocs ,    testQuery )  )  ;", "DiscountedCumulativeGain   metric    =    new   DiscountedCumulativeGain ( false ,    null ,     1  0  )  ;", "RankEvalSpec   task    =    new   RankEvalSpec ( specifications ,    metric )  ;", "Builder   builder    =    new   Builder ( client (  )  ,    RankEvalAction . INSTANCE ,    new    ( task ,    new   String [  ]  {     \" test \"     }  )  )  ;", "RankEvalResponse   response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    builder . request (  )  )  . actionGet (  )  ;", "assertEquals ( DiscountedCumulativeGainTests . EXPECTED _ DCG ,    response . getEvaluationResult (  )  ,     1  .  0 E -  1  3  )  ;", "metric    =    new   DiscountedCumulativeGain ( false ,    null ,     3  )  ;", "task    =    new   RankEvalSpec ( specifications ,    metric )  ;", "builder    =    new   Builder ( client (  )  ,    RankEvalAction . INSTANCE ,    new    ( task ,    new   String [  ]  {     \" test \"     }  )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    builder . request (  )  )  . actionGet (  )  ;", "assertEquals (  1  2  .  3  9  2  7  8  9  2  6  0  7  1  4  3  7  ,    response . getEvaluationResult (  )  ,     1  .  0 E -  1  3  )  ;", "}", "METHOD_END"], "methodName": ["testDCGRequest"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestIT"}, {"methodBody": ["METHOD_START", "{", "SearchSourceBuilder   amsterdamQuery    =    new   SearchSourceBuilder (  )  . query ( new   MatchAllQueryBuilder (  )  )  ;", "List < RatedDocument >    relevantDocs    =     . createRelevant (  \"  2  \"  ,     \"  3  \"  ,     \"  4  \"  ,     \"  5  \"  ,     \"  6  \"  )  ;", "relevantDocs . add ( new   RatedDocument (  \" test 2  \"  ,     \"  7  \"  ,    TestRatingEnum . RELEVANT . ordinal (  )  )  )  ;", "List < RatedRequest >    specifications    =    new   ArrayList <  >  (  )  ;", "specifications . add ( new   RatedRequest (  \" amsterdam _ query \"  ,    relevantDocs ,    amsterdamQuery )  )  ;", "RankEvalSpec   task    =    new   RankEvalSpec ( specifications ,    new   PrecisionAtK (  )  )  ;", "RankEvalRequest   request    =    new   RankEvalRequest ( task ,    new   String [  ]  {     \" test \"  ,     \" test 2  \"     }  )  ;", "request . setRankEvalSpec ( task )  ;", "RankEvalResponse   response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    request )  . actionGet (  )  ;", "PrecisionAtK . Breakdown   details    =     (  ( PrecisionAtK . Breakdown )     ( response . getPartialResults (  )  . get (  \" amsterdam _ query \"  )  . getMetricDetails (  )  )  )  ;", "assertEquals (  7  ,    details . getRetrieved (  )  )  ;", "assertEquals (  6  ,    details . getRelevantRetrieved (  )  )  ;", "assertTrue ( client (  )  . admin (  )  . indices (  )  . prepareClose (  \" test 2  \"  )  . get (  )  . isAcknowledged (  )  )  ;", "request . indicesOptions ( IndicesOptions . fromParameters ( null ,     \" true \"  ,    null ,    DEFAULT _ INDICES _ OPTIONS )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    request )  . actionGet (  )  ;", "details    =     (  ( PrecisionAtK . Breakdown )     ( response . getPartialResults (  )  . get (  \" amsterdam _ query \"  )  . getMetricDetails (  )  )  )  ;", "assertEquals (  6  ,    details . getRetrieved (  )  )  ;", "assertEquals (  5  ,    details . getRelevantRetrieved (  )  )  ;", "assertTrue ( client (  )  . admin (  )  . indices (  )  . prepareClose (  \" test 2  \"  )  . get (  )  . isAcknowledged (  )  )  ;", "request . indicesOptions ( IndicesOptions . fromParameters ( null ,     \" false \"  ,    null ,    DEFAULT _ INDICES _ OPTIONS )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    request )  . actionGet (  )  ;", "assertEquals (  1  ,    response . getFailures (  )  . size (  )  )  ;", "assertThat ( response . getFailures (  )  . get (  \" amsterdam _ query \"  )  ,    instanceOf ( IndexClosedException . class )  )  ;", "request    =    new   RankEvalRequest ( task ,    new   String [  ]  {     \" tes *  \"     }  )  ;", "request . indicesOptions ( IndicesOptions . fromParameters (  \" none \"  ,    null ,    null ,    DEFAULT _ INDICES _ OPTIONS )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    request )  . actionGet (  )  ;", "details    =     (  ( PrecisionAtK . Breakdown )     ( response . getPartialResults (  )  . get (  \" amsterdam _ query \"  )  . getMetricDetails (  )  )  )  ;", "assertEquals (  0  ,    details . getRetrieved (  )  )  ;", "request . indicesOptions ( IndicesOptions . fromParameters (  \" open \"  ,    null ,    null ,    DEFAULT _ INDICES _ OPTIONS )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    request )  . actionGet (  )  ;", "details    =     (  ( PrecisionAtK . Breakdown )     ( response . getPartialResults (  )  . get (  \" amsterdam _ query \"  )  . getMetricDetails (  )  )  )  ;", "assertEquals (  6  ,    details . getRetrieved (  )  )  ;", "assertEquals (  5  ,    details . getRelevantRetrieved (  )  )  ;", "request . indicesOptions ( IndicesOptions . fromParameters (  \" closed \"  ,    null ,    null ,    DEFAULT _ INDICES _ OPTIONS )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    request )  . actionGet (  )  ;", "assertEquals (  1  ,    response . getFailures (  )  . size (  )  )  ;", "assertThat ( response . getFailures (  )  . get (  \" amsterdam _ query \"  )  ,    instanceOf ( IndexClosedException . class )  )  ;", "request    =    new   RankEvalRequest ( task ,    new   String [  ]  {     \" bad *  \"     }  )  ;", "request . indicesOptions ( IndicesOptions . fromParameters ( null ,    null ,     \" true \"  ,    DEFAULT _ INDICES _ OPTIONS )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    request )  . actionGet (  )  ;", "details    =     (  ( PrecisionAtK . Breakdown )     ( response . getPartialResults (  )  . get (  \" amsterdam _ query \"  )  . getMetricDetails (  )  )  )  ;", "assertEquals (  0  ,    details . getRetrieved (  )  )  ;", "request . indicesOptions ( IndicesOptions . fromParameters ( null ,    null ,     \" false \"  ,    DEFAULT _ INDICES _ OPTIONS )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    request )  . actionGet (  )  ;", "assertEquals (  1  ,    response . getFailures (  )  . size (  )  )  ;", "assertThat ( response . getFailures (  )  . get (  \" amsterdam _ query \"  )  ,    instanceOf ( IndexNotFoundException . class )  )  ;", "}", "METHOD_END"], "methodName": ["testIndicesOptions"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestIT"}, {"methodBody": ["METHOD_START", "{", "SearchSourceBuilder   testQuery    =    new   SearchSourceBuilder (  )  ;", "testQuery . query ( new   MatchAllQueryBuilder (  )  )  ;", "testQuery . sort (  \"  _ id \"  )  ;", "List < RatedRequest >    specifications    =    new   ArrayList <  >  (  )  ;", "specifications . add ( new   RatedRequest (  \" amsterdam _ query \"  ,     . createRelevant (  \"  5  \"  )  ,    testQuery )  )  ;", "specifications . add ( new   RatedRequest (  \" berlin _ query \"  ,     . createRelevant (  \"  1  \"  )  ,    testQuery )  )  ;", "MeanReciprocalRank   metric    =    new   MeanReciprocalRank (  1  ,     1  0  )  ;", "RankEvalSpec   task    =    new   RankEvalSpec ( specifications ,    metric )  ;", "RankEvalRequestBuilder   builder    =    new   RankEvalRequestBuilder ( client (  )  ,    RankEvalAction . INSTANCE ,    new   RankEvalRequest ( task ,    new   String [  ]  {     \" test \"     }  )  )  ;", "RankEvalResponse   response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    builder . request (  )  )  . actionGet (  )  ;", "double   expectedMRR    =     (  1  .  0     +     (  1  .  0     /     5  .  0  )  )     /     2  .  0  ;", "assertEquals ( expectedMRR ,    response . getEvaluationResult (  )  ,     0  .  0  )  ;", "metric    =    new   MeanReciprocalRank (  1  ,     3  )  ;", "task    =    new   RankEvalSpec ( specifications ,    metric )  ;", "builder    =    new   RankEvalRequestBuilder ( client (  )  ,    RankEvalAction . INSTANCE ,    new   RankEvalRequest ( task ,    new   String [  ]  {     \" test \"     }  )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    builder . request (  )  )  . actionGet (  )  ;", "expectedMRR    =     1  .  0     /     2  .  0  ;", "assertEquals ( expectedMRR ,    response . getEvaluationResult (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testMRRRequest"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestIT"}, {"methodBody": ["METHOD_START", "{", "List < RatedRequest >    specifications    =    new   ArrayList <  >  (  )  ;", "SearchSourceBuilder   testQuery    =    new   SearchSourceBuilder (  )  ;", "testQuery . query ( new   MatchAllQueryBuilder (  )  )  ;", "testQuery . sort (  \"  _ id \"  )  ;", "RatedRequest   amsterdamRequest    =    new   RatedRequest (  \" amsterdam _ query \"  ,     . createRelevant (  \"  2  \"  ,     \"  3  \"  ,     \"  4  \"  ,     \"  5  \"  )  ,    testQuery )  ;", "amsterdamRequest . addSummaryFields ( Arrays . asList ( new   String [  ]  {     \" text \"  ,     \" title \"     }  )  )  ;", "specifications . add ( amsterdamRequest )  ;", "RatedRequest   berlinRequest    =    new   RatedRequest (  \" berlin _ query \"  ,     . createRelevant (  \"  1  \"  )  ,    testQuery )  ;", "berlinRequest . addSummaryFields ( Arrays . asList ( new   String [  ]  {     \" text \"  ,     \" title \"     }  )  )  ;", "specifications . add ( berlinRequest )  ;", "PrecisionAtK   metric    =    new   PrecisionAtK (  1  ,    false ,     1  0  )  ;", "RankEvalSpec   task    =    new   RankEvalSpec ( specifications ,    metric )  ;", "RankEvalRequestBuilder   builder    =    new   RankEvalRequestBuilder ( client (  )  ,    RankEvalAction . INSTANCE ,    new   RankEvalRequest (  )  )  ;", "builder . setRankEvalSpec ( task )  ;", "RankEvalResponse   response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    builder . request (  )  . indices (  \" test \"  )  )  . actionGet (  )  ;", "double   expectedPrecision    =     (  (  1  .  0     /     6  .  0  )     +     (  4  .  0     /     6  .  0  )  )     /     2  .  0  ;", "assertEquals ( expectedPrecision ,    response . getEvaluationResult (  )  ,    Double . MIN _ VALUE )  ;", "Set < Map . Entry < String ,    EvalQueryQuality >  >    entrySet    =    response . getPartialResults (  )  . entrySet (  )  ;", "assertEquals (  2  ,    entrySet . size (  )  )  ;", "for    ( Map . Entry < String ,    EvalQueryQuality >    entry    :    entrySet )     {", "EvalQueryQuality   quality    =    entry . getValue (  )  ;", "if    (  ( entry . getKey (  )  )     =  =     \" amsterdam _ query \"  )     {", "assertEquals (  2  ,    EvaluationMetric . filterUnknownDocuments ( quality . getHitsAndRatings (  )  )  . size (  )  )  ;", "List < RatedSearchHit >    hitsAndRatings    =    quality . getHitsAndRatings (  )  ;", "assertEquals (  6  ,    hitsAndRatings . size (  )  )  ;", "for    ( RatedSearchHit   hit    :    hitsAndRatings )     {", "String   id    =    hit . getSearchHit (  )  . getId (  )  ;", "if    (  ( id . equals (  \"  1  \"  )  )     |  |     ( id . equals (  \"  6  \"  )  )  )     {", "assertFalse ( hit . getRating (  )  . isPresent (  )  )  ;", "} else    {", "assertEquals ( TestRatingEnum . RELEVANT . ordinal (  )  ,    hit . getRating (  )  . get (  )  . intValue (  )  )  ;", "}", "}", "}", "if    (  ( entry . getKey (  )  )     =  =     \" berlin _ query \"  )     {", "assertEquals (  5  ,    EvaluationMetric . filterUnknownDocuments ( quality . getHitsAndRatings (  )  )  . size (  )  )  ;", "List < RatedSearchHit >    hitsAndRatings    =    quality . getHitsAndRatings (  )  ;", "assertEquals (  6  ,    hitsAndRatings . size (  )  )  ;", "for    ( RatedSearchHit   hit    :    hitsAndRatings )     {", "String   id    =    hit . getSearchHit (  )  . getId (  )  ;", "if    ( id . equals (  \"  1  \"  )  )     {", "assertEquals ( TestRatingEnum . RELEVANT . ordinal (  )  ,    hit . getRating (  )  . get (  )  . intValue (  )  )  ;", "} else    {", "assertFalse ( hit . getRating (  )  . isPresent (  )  )  ;", "}", "}", "}", "}", "metric    =    new   PrecisionAtK (  1  ,    false ,     3  )  ;", "task    =    new   RankEvalSpec ( specifications ,    metric )  ;", "builder    =    new   RankEvalRequestBuilder ( client (  )  ,    RankEvalAction . INSTANCE ,    new   RankEvalRequest ( task ,    new   String [  ]  {     \" test \"     }  )  )  ;", "response    =    client (  )  . execute ( RankEvalAction . INSTANCE ,    builder . request (  )  )  . actionGet (  )  ;", "expectedPrecision    =     (  (  1  .  0     /     3  .  0  )     +     (  2  .  0     /     3  .  0  )  )     /     2  .  0  ;", "assertEquals ( expectedPrecision ,    response . getEvaluationResult (  )  ,    Double . MIN _ VALUE )  ;", "}", "METHOD_END"], "methodName": ["testPrecisionAtRequest"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestIT"}, {"methodBody": ["METHOD_START", "{", "RankEvalRequestTests . rankEvalPlugin . close (  )  ;", "}", "METHOD_END"], "methodName": ["releasePluginResources"], "fileName": "org.elasticsearch.index.rankeval.RankEvalRequestTests"}, {"methodBody": ["METHOD_START", "{", "return   RankEvalResponse . PARSER . apply ( parser ,    null )  ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.index.rankeval.RankEvalResponse"}, {"methodBody": ["METHOD_START", "{", "return   evaluationResult ;", "}", "METHOD_END"], "methodName": ["getEvaluationResult"], "fileName": "org.elasticsearch.index.rankeval.RankEvalResponse"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( failures )  ;", "}", "METHOD_END"], "methodName": ["getFailures"], "fileName": "org.elasticsearch.index.rankeval.RankEvalResponse"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( details )  ;", "}", "METHOD_END"], "methodName": ["getPartialResults"], "fileName": "org.elasticsearch.index.rankeval.RankEvalResponse"}, {"methodBody": ["METHOD_START", "{", "int   numberOfRequests    =    randomIntBetween (  0  ,     5  )  ;", "Map < String ,    EvalQueryQuality >    partials    =    new   HashMap <  >  ( numberOfRequests )  ;", "for    ( int   i    =     0  ;    i    <    numberOfRequests ;    i +  +  )     {", "String   id    =    randomAlphaOfLengthBetween (  3  ,     1  0  )  ;", "EvalQueryQuality   evalQuality    =    new   EvalQueryQuality ( id ,    randomDoubleBetween (  0  .  0  ,     1  .  0  ,    true )  )  ;", "int   numberOfDocs    =    randomIntBetween (  0  ,     5  )  ;", "List < RatedSearchHit >    ratedHits    =    new   ArrayList <  >  ( numberOfDocs )  ;", "for    ( int   d    =     0  ;    d    <    numberOfDocs ;    d +  +  )     {", "ratedHits . add (  . searchHit ( randomAlphaOfLength (  1  0  )  ,    randomIntBetween (  0  ,     1  0  0  0  )  ,    randomIntBetween (  0  ,     1  0  )  )  )  ;", "}", "evalQuality . addHitsAndRatings ( ratedHits )  ;", "partials . put ( id ,    evalQuality )  ;", "}", "int   numberOfErrors    =    randomIntBetween (  0  ,     2  )  ;", "Map < String ,    Exception >    errors    =    new   HashMap <  >  ( numberOfRequests )  ;", "for    ( int   i    =     0  ;    i    <    numberOfErrors ;    i +  +  )     {", "errors . put ( randomAlphaOfLengthBetween (  3  ,     1  0  )  ,    randomFrom (  . RANDOM _ EXCEPTIONS )  )  ;", "}", "return   new   RankEvalResponse ( randomDouble (  )  ,    partials ,    errors )  ;", "}", "METHOD_END"], "methodName": ["createRandomResponse"], "fileName": "org.elasticsearch.index.rankeval.RankEvalResponseTests"}, {"methodBody": ["METHOD_START", "{", "SearchHit   hit    =    new   SearchHit ( docId ,     ( docId    +     \"  \"  )  ,    new   Text (  \"  \"  )  ,    Collections . emptyMap (  )  )  ;", "hit . shard ( new   search . SearchShardTarget (  \" testnode \"  ,    new   Index ( index ,     \" uuid \"  )  ,     0  ,    null )  )  ;", "hit . score (  1  .  0 F )  ;", "return   new   RatedSearchHit ( hit ,     ( rating    !  =    null    ?    Optional . of ( rating )     :    Optional . empty (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["searchHit"], "fileName": "org.elasticsearch.index.rankeval.RankEvalResponseTests"}, {"methodBody": ["METHOD_START", "{", "RankEvalResponse   randomResponse    =    RankEvalResponseTests . createRandomResponse (  )  ;", "try    ( BytesStreamOutput   output    =    new   BytesStreamOutput (  )  )     {", "randomResponse . writeTo ( output )  ;", "try    ( StreamInput   in    =    output . bytes (  )  . streamInput (  )  )     {", "RankEvalResponse   deserializedResponse    =    new   RankEvalResponse (  )  ;", "deserializedResponse . readFrom ( in )  ;", "assertEquals ( randomResponse . getEvaluationResult (  )  ,    deserializedResponse . getEvaluationResult (  )  ,    Double . MIN _ VALUE )  ;", "assertEquals ( randomResponse . getPartialResults (  )  ,    deserializedResponse . getPartialResults (  )  )  ;", "assertEquals ( randomResponse . getFailures (  )  . keySet (  )  ,    deserializedResponse . getFailures (  )  . keySet (  )  )  ;", "assertNotSame ( randomResponse ,    deserializedResponse )  ;", "assertEquals (  (  -  1  )  ,    in . read (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testSerialization"], "fileName": "org.elasticsearch.index.rankeval.RankEvalResponseTests"}, {"methodBody": ["METHOD_START", "{", "EvalQueryQuality   coffeeQueryQuality    =    new   EvalQueryQuality (  \" coffee _ query \"  ,     0  .  1  )  ;", "coffeeQueryQuality . addHitsAndRatings ( Arrays . asList (  . searchHit (  \" index \"  ,     1  2  3  ,     5  )  ,     . searchHit (  \" index \"  ,     4  5  6  ,    null )  )  )  ;", "RankEvalResponse   response    =    new   RankEvalResponse (  0  .  1  2  3  ,    Collections . singletonMap (  \" coffee _ query \"  ,    coffeeQueryQuality )  ,    Collections . singletonMap (  \" beer _ query \"  ,    new   ParsingException ( new   XContentLocation (  0  ,     0  )  ,     \" someMsg \"  )  )  )  ;", "XContentBuilder   builder    =    XContentFactory . contentBuilder ( JSON )  ;", "String   xContent    =    BytesReference . bytes ( response . toXContent ( builder ,    EMPTY _ PARAMS )  )  . utf 8 ToString (  )  ;", "assertEquals (  (  \"  {  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"              \\  \" quality _ level \\  \"  :     0  .  1  2  3  ,  \"     +     \"              \\  \" details \\  \"  :     {  \"  )     +     \"                          \\  \" coffee _ query \\  \"  :     {  \"  )     +     \"                                      \\  \" quality _ level \\  \"  :     0  .  1  ,  \"  )     +     \"                                      \\  \" unknown _ docs \\  \"  :     [  {  \\  \"  _ index \\  \"  :  \\  \" index \\  \"  ,  \\  \"  _ id \\  \"  :  \\  \"  4  5  6  \\  \"  }  ]  ,  \"  )     +     \"                                      \\  \" hits \\  \"  :  [  {  \\  \" hit \\  \"  :  {  \\  \"  _ index \\  \"  :  \\  \" index \\  \"  ,  \\  \"  _ type \\  \"  :  \\  \"  \\  \"  ,  \\  \"  _ id \\  \"  :  \\  \"  1  2  3  \\  \"  ,  \\  \"  _ score \\  \"  :  1  .  0  }  ,  \"  )     +     \"                                                                       \\  \" rating \\  \"  :  5  }  ,  \"  )     +     \"                                                                    {  \\  \" hit \\  \"  :  {  \\  \"  _ index \\  \"  :  \\  \" index \\  \"  ,  \\  \"  _ type \\  \"  :  \\  \"  \\  \"  ,  \\  \"  _ id \\  \"  :  \\  \"  4  5  6  \\  \"  ,  \\  \"  _ score \\  \"  :  1  .  0  }  ,  \"  )     +     \"                                                                       \\  \" rating \\  \"  : null }  \"  )     +     \"                                                                 ]  \"  )     +     \"                          }  \"  )     +     \"              }  ,  \"  )     +     \"              \\  \" failures \\  \"  :     {  \"  )     +     \"                          \\  \" beer _ query \\  \"  :     {  \"  )     +     \"                                \\  \" error \\  \"     :     {  \\  \" root _ cause \\  \"  :     [  {  \\  \" type \\  \"  :  \\  \" parsing _ exception \\  \"  ,     \\  \" reason \\  \"  :  \\  \" someMsg \\  \"  ,  \\  \" line \\  \"  :  0  ,  \\  \" col \\  \"  :  0  }  ]  ,  \"  )     +     \"                                                                       \\  \" type \\  \"  :  \\  \" parsing _ exception \\  \"  ,  \"  )     +     \"                                                                       \\  \" reason \\  \"  :  \\  \" someMsg \\  \"  ,  \"  )     +     \"                                                                       \\  \" line \\  \"  :  0  ,  \\  \" col \\  \"  :  0  \"  )     +     \"                                                                    }  \"  )     +     \"                          }  \"  )     +     \"              }  \"  )     +     \"  }  \"  )  )  . replaceAll (  \"  \\  \\ s +  \"  ,     \"  \"  )  ,    xContent )  ;", "}", "METHOD_END"], "methodName": ["testToXContent"], "fileName": "org.elasticsearch.index.rankeval.RankEvalResponseTests"}, {"methodBody": ["METHOD_START", "{", "RankEvalResponse   testItem    =    RankEvalResponseTests . createRandomResponse (  )  ;", "boolean   humanReadable    =    randomBoolean (  )  ;", "XContentType   xContentType    =    randomFrom ( XContentType . values (  )  )  ;", "BytesReference   originalBytes    =    toShuffledXContent ( testItem ,    xContentType ,    EMPTY _ PARAMS ,    humanReadable )  ;", "Predicate < String >    pathsToExclude    =     (    path )     -  >     (  ( path . endsWith (  \" details \"  )  )     |  |     ( path . contains (  \" failures \"  )  )  )     |  |     ( path . contains (  \" hits \"  )  )  ;", "BytesReference   withRandomFields    =    insertRandomFields ( xContentType ,    originalBytes ,    pathsToExclude ,    random (  )  )  ;", "RankEvalResponse   parsedItem ;", "try    ( XContentParser   parser    =    createParser ( xContentType . xContent (  )  ,    withRandomFields )  )     {", "parsedItem    =    RankEvalResponse . fromXContent ( parser )  ;", "assertNull ( parser . nextToken (  )  )  ;", "}", "assertNotSame ( testItem ,    parsedItem )  ;", "assertEquals ( testItem . getEvaluationResult (  )  ,    parsedItem . getEvaluationResult (  )  ,     0  .  0  )  ;", "assertEquals ( testItem . getPartialResults (  )  . keySet (  )  ,    parsedItem . getPartialResults (  )  . keySet (  )  )  ;", "for    ( EvalQueryQuality   metricDetail    :    testItem . getPartialResults (  )  . values (  )  )     {", "EvalQueryQuality   parsedEvalQueryQuality    =    parsedItem . getPartialResults (  )  . get ( metricDetail . getId (  )  )  ;", "assertToXContentEquivalent ( toXContent ( metricDetail ,    xContentType ,    humanReadable )  ,    toXContent ( parsedEvalQueryQuality ,    xContentType ,    humanReadable )  ,    xContentType )  ;", "}", "assertEquals ( testItem . getFailures (  )  . keySet (  )  ,    parsedItem . getFailures (  )  . keySet (  )  )  ;", "for    ( String   queryId    :    testItem . getFailures (  )  . keySet (  )  )     {", "Exception   ex    =    parsedItem . getFailures (  )  . get ( queryId )  ;", "assertThat ( ex ,    instanceOf ( ElasticsearchException . class )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentParsing"], "fileName": "org.elasticsearch.index.rankeval.RankEvalResponseTests"}, {"methodBody": ["METHOD_START", "{", "return   this . maxConcurrentSearches ;", "}", "METHOD_END"], "methodName": ["getMaxConcurrentSearches"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpec"}, {"methodBody": ["METHOD_START", "{", "return   metric ;", "}", "METHOD_END"], "methodName": ["getMetric"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpec"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableList ( ratedRequests )  ;", "}", "METHOD_END"], "methodName": ["getRatedRequests"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpec"}, {"methodBody": ["METHOD_START", "{", "return   this . templates ;", "}", "METHOD_END"], "methodName": ["getTemplates"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpec"}, {"methodBody": ["METHOD_START", "{", "return   RankEvalSpec . PARSER . apply ( parser ,    null )  ;", "}", "METHOD_END"], "methodName": ["parse"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpec"}, {"methodBody": ["METHOD_START", "{", "XContentParserUtils . ensureExpectedToken ( START _ OBJECT ,    parser . currentToken (  )  ,    parser :  : getTokenLocation )  ;", "XContentParserUtils . ensureExpectedToken ( FIELD _ NAME ,    parser . nextToken (  )  ,    parser :  : getTokenLocation )  ;", "uationMetric   metric    =    parser . namedObject ( uationMetric . class ,    parser . currentName (  )  ,    null )  ;", "XContentParserUtils . ensureExpectedToken ( END _ OBJECT ,    parser . nextToken (  )  ,    parser :  : getTokenLocation )  ;", "return   metric ;", "}", "METHOD_END"], "methodName": ["parseMetric"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpec"}, {"methodBody": ["METHOD_START", "{", "this . maxConcurrentSearches    =    maxConcurrentSearches ;", "}", "METHOD_END"], "methodName": ["setMaxConcurrentSearches"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpec"}, {"methodBody": ["METHOD_START", "{", "List < NamedWriteableRegistry . Entry >    namedWriteables    =    new   ArrayList <  >  (  )  ;", "namedWriteables . add ( new   NamedWriteableRegistry . Entry ( QueryBuilder . class ,    MatchAllQueryBuilder . NAME ,    MatchAllQueryBuilder :  : new )  )  ;", "namedWriteables . add ( new   NamedWriteableRegistry . Entry ( EvaluationMetric . class ,    PrecisionAtK . NAME ,    PrecisionAtK :  : new )  )  ;", "namedWriteables . add ( new   NamedWriteableRegistry . Entry ( EvaluationMetric . class ,    DiscountedCumulativeGain . NAME ,    DiscountedCumulativeGain :  : new )  )  ;", "namedWriteables . add ( new   NamedWriteableRegistry . Entry ( EvaluationMetric . class ,    MeanReciprocalRank . NAME ,    MeanReciprocalRank :  : new )  )  ;", "return   ESTestCase . copyWriteable ( original ,    new   NamedWriteableRegistry ( namedWriteables )  ,     :  : new )  ;", "}", "METHOD_END"], "methodName": ["copy"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "Supplier < EvaluationMetric >    metric    =    randomFrom ( Arrays . asList (  (  )     -  >    PrecisionAtKTests . createTestItem (  )  ,     (  )     -  >    MeanReciprocalRankTests . createTestItem (  )  ,     (  )     -  >    DiscountedCumulativeGainTests . createTestItem (  )  )  )  ;", "List < RatedRequest >    ratedRequests    =    null ;", "Collection <  . ScriptWithId >    templates    =    null ;", "if    ( randomBoolean (  )  )     {", "final   Map < String ,    Object >    params    =     ( randomBoolean (  )  )     ?    Collections . emptyMap (  )     :    Collections . singletonMap (  \" key \"  ,     \" value \"  )  ;", "String   script ;", "try    ( XContentBuilder   builder    =    XContentFactory . jsonBuilder (  )  )     {", "builder . startObject (  )  ;", "builder . field (  \" field \"  ,    randomAlphaOfLengthBetween (  1  ,     5  )  )  ;", "builder . endObject (  )  ;", "script    =    Strings . toString ( builder )  ;", "}    catch    ( IOException   e )     {", "throw   new   RuntimeException ( e )  ;", "}", "templates    =    new   HashSet <  >  (  )  ;", "templates . add ( new    . ScriptWithId (  \" templateId \"  ,    new   Script ( ScriptType . INLINE ,    Script . DEFAULT _ TEMPLATE _ LANG ,    script ,    params )  )  )  ;", "Map < String ,    Object >    templateParams    =    new   HashMap <  >  (  )  ;", "templateParams . put (  \" key \"  ,     \" value \"  )  ;", "RatedRequest   ratedRequest    =    new   RatedRequest (  \" id \"  ,    Arrays . asList ( RatedDocumentTests . createRatedDocument (  )  )  ,    templateParams ,     \" templateId \"  )  ;", "ratedRequests    =    Arrays . asList ( ratedRequest )  ;", "} else    {", "RatedRequest   ratedRequest    =    new   RatedRequest (  \" id \"  ,    Arrays . asList ( RatedDocumentTests . createRatedDocument (  )  )  ,    new   SearchSourceBuilder (  )  )  ;", "ratedRequests    =    Arrays . asList ( ratedRequest )  ;", "}", "spec    =    new    ( ratedRequests ,    metric . get (  )  ,    templates )  ;", "maybeSet ( spec :  : setMaxConcurrentSearches ,    randomInt (  1  0  0  )  )  ;", "List < String >    indices    =    new   ArrayList <  >  (  )  ;", "int   size    =    randomIntBetween (  0  ,     2  0  )  ;", "for    ( int   i    =     0  ;    i    <    size ;    i +  +  )     {", "indices . add ( randomAlphaOfLengthBetween (  0  ,     5  0  )  )  ;", "}", "return   spec ;", "}", "METHOD_END"], "methodName": ["createTestItem"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedRequest >    ratedRequests    =    new   ArrayList <  >  ( original . getRatedRequests (  )  )  ;", "EvaluationMetric   metric    =    original . getMetric (  )  ;", "Map < String ,    Script >    templates    =    new   HashMap ( original . getTemplates (  )  )  ;", "int   mutate    =    randomIntBetween (  0  ,     2  )  ;", "switch    ( mutate )     {", "case    0     :", "RatedRequest   request    =    RatedRequestsTests . createTestItem ( true )  ;", "ratedRequests . add ( request )  ;", "break ;", "case    1     :", "if    ( metric   instanceof   PrecisionAtK )     {", "metric    =    new   DiscountedCumulativeGain (  )  ;", "} else    {", "metric    =    new   PrecisionAtK (  )  ;", "}", "break ;", "case    2     :", "templates . put (  \" mutation \"  ,    new   Script ( ScriptType . INLINE ,     \" mustache \"  ,    randomAlphaOfLength (  1  0  )  ,    new   HashMap (  )  )  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  \" Requested   to   modify   more   than   available   parameters .  \"  )  ;", "}", "List <  . ScriptWithId >    scripts    =    new   ArrayList <  >  (  )  ;", "for    ( Map . Entry < String ,    Script >    entry    :    templates . entrySet (  )  )     {", "scripts . add ( new    . ScriptWithId ( entry . getKey (  )  ,    entry . getValue (  )  )  )  ;", "}", "result    =    new    ( ratedRequests ,    metric ,    scripts )  ;", "return   result ;", "}", "METHOD_END"], "methodName": ["mutateTestItem"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "List < T >    result    =    new   ArrayList <  >  (  )  ;", "int   size    =    domIntBetween (  1  ,     2  0  )  ;", "for    ( int   i    =     0  ;    i    <    size ;    i +  +  )     {", "result . add ( domSupplier . get (  )  )  ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["randomList"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "checkEqualsAndHashCode ( RankEvalSpecTests . createTestItem (  )  ,    RankEvalSpecTests :  : copy ,    RankEvalSpecTests :  : mutateTestItem )  ;", "}", "METHOD_END"], "methodName": ["testEqualsAndHash"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedRequest >    ratedRequests    =    RankEvalSpecTests . randomList (  (  )     -  >    RatedRequestsTests . createTestItem ( randomBoolean (  )  )  )  ;", "expectThrows ( NullPointerException . class ,     (  )     -  >    new   RankEvalSpec ( ratedRequests ,    null )  )  ;", "}", "METHOD_END"], "methodName": ["testMissingMetricFails"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "EvaluationMetric   metric    =    new   PrecisionAtK (  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    ( new   ArrayList <  >  (  )  ,    metric )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    ( null ,    metric )  )  ;", "}", "METHOD_END"], "methodName": ["testMissingRatedRequestsFails"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    ratedDocs    =    Arrays . asList ( new   RatedDocument (  \" index 1  \"  ,     \" id 1  \"  ,     1  )  )  ;", "Map < String ,    Object >    params    =    new   HashMap <  >  (  )  ;", "params . put (  \" key \"  ,     \" value \"  )  ;", "RatedRequest   request    =    new   RatedRequest (  \" id \"  ,    ratedDocs ,    params ,     \" templateId \"  )  ;", "List < RatedRequest >    ratedRequests    =    Arrays . asList ( request )  ;", "expectThrows ( IllegalStateException . class ,     (  )     -  >    new    ( ratedRequests ,    new   PrecisionAtK (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testMissingTemplateAndSearchRequestFails"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "RankEvalSpec   original    =    RankEvalSpecTests . createTestItem (  )  ;", "RankEvalSpec   deserialized    =    RankEvalSpecTests . copy ( original )  ;", "assertEquals ( deserialized ,    original )  ;", "assertEquals ( deserialized . hashCode (  )  ,    original . hashCode (  )  )  ;", "assertNotSame ( deserialized ,    original )  ;", "}", "METHOD_END"], "methodName": ["testSerialization"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "RankEvalSpec   testItem    =    RankEvalSpecTests . createTestItem (  )  ;", "XContentType   xContentType    =    randomFrom ( XContentType . values (  )  )  ;", "BytesReference   originalBytes    =    toShuffledXContent ( testItem ,    xContentType ,    EMPTY _ PARAMS ,    randomBoolean (  )  )  ;", "BytesReference   withRandomFields    =    insertRandomFields ( xContentType ,    originalBytes ,    null ,    random (  )  )  ;", "try    ( XContentParser   parser    =    createParser ( xContentType . xContent (  )  ,    withRandomFields )  )     {", "Exception   exception    =    expectThrows ( Exception . class ,     (  )     -  >    RankEvalSpec . parse ( parser )  )  ;", "assertThat ( exception . getMessage (  )  ,    containsString (  \"  [ rank _ eval ]    failed   to   parse   field \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentParsingIsNotLenient"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "RankEvalSpec   testItem    =    RankEvalSpecTests . createTestItem (  )  ;", "XContentBuilder   shuffled    =    shuffleXContent ( testItem . toXContent ( XContentFactory . jsonBuilder (  )  ,    EMPTY _ PARAMS )  )  ;", "try    ( XContentParser   parser    =    createParser ( jsonXContent ,    BytesReference . bytes ( shuffled )  )  )     {", "RankEvalSpec   parsedItem    =    RankEvalSpec . parse ( parser )  ;", "assertNotSame ( testItem ,    parsedItem )  ;", "assertEquals ( testItem ,    parsedItem )  ;", "assertEquals ( testItem . hashCode (  )  ,    parsedItem . hashCode (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentRoundtrip"], "fileName": "org.elasticsearch.index.rankeval.RankEvalSpecTests"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.index.rankeval.RankEvalYamlIT"}, {"methodBody": ["METHOD_START", "{", "return   RatedDocument . PARSER . apply ( parser ,    null )  ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.index.rankeval.RatedDocument"}, {"methodBody": ["METHOD_START", "{", "return   key . getDocId (  )  ;", "}", "METHOD_END"], "methodName": ["getDocID"], "fileName": "org.elasticsearch.index.rankeval.RatedDocument"}, {"methodBody": ["METHOD_START", "{", "return   key . getIndex (  )  ;", "}", "METHOD_END"], "methodName": ["getIndex"], "fileName": "org.elasticsearch.index.rankeval.RatedDocument"}, {"methodBody": ["METHOD_START", "{", "return   this . key ;", "}", "METHOD_END"], "methodName": ["getKey"], "fileName": "org.elasticsearch.index.rankeval.RatedDocument"}, {"methodBody": ["METHOD_START", "{", "return   rating ;", "}", "METHOD_END"], "methodName": ["getRating"], "fileName": "org.elasticsearch.index.rankeval.RatedDocument"}, {"methodBody": ["METHOD_START", "{", "return   new   RatedDocument ( randomAlphaOfLength (  1  0  )  ,    randomAlphaOfLength (  1  0  )  ,    randomInt (  )  )  ;", "}", "METHOD_END"], "methodName": ["createRatedDocument"], "fileName": "org.elasticsearch.index.rankeval.RatedDocumentTests"}, {"methodBody": ["METHOD_START", "{", "int   rating    =    original . getRating (  )  ;", "String   index    =    original . getIndex (  )  ;", "String   docId    =    original . getDocID (  )  ;", "switch    ( randomIntBetween (  0  ,     2  )  )     {", "case    0     :", "rating    =    randomValueOtherThan ( rating ,     (  )     -  >    randomInt (  )  )  ;", "break ;", "case    1     :", "index    =    randomValueOtherThan ( index ,     (  )     -  >    randomAlphaOfLength (  1  0  )  )  ;", "break ;", "case    2     :", "docId    =    randomValueOtherThan ( docId ,     (  )     -  >    randomAlphaOfLength (  1  0  )  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  \" The   test   should   only   allow   two   parameters   mutated \"  )  ;", "}", "return   new    ( index ,    docId ,    rating )  ;", "}", "METHOD_END"], "methodName": ["mutateTestItem"], "fileName": "org.elasticsearch.index.rankeval.RatedDocumentTests"}, {"methodBody": ["METHOD_START", "{", "checkEqualsAndHashCode ( RatedDocumentTests . createRatedDocument (  )  ,     (    original )     -  >     {", "return   new   RatedDocument ( original . getIndex (  )  ,    original . getDocID (  )  ,    original . getRating (  )  )  ;", "}  ,    RatedDocumentTests :  : mutateTestItem )  ;", "}", "METHOD_END"], "methodName": ["testEqualsAndHash"], "fileName": "org.elasticsearch.index.rankeval.RatedDocumentTests"}, {"methodBody": ["METHOD_START", "{", "RatedDocument   original    =    RatedDocumentTests . createRatedDocument (  )  ;", "RatedDocument   deserialized    =    ESTestCase . copyWriteable ( original ,    new   NamedWriteableRegistry ( Collections . emptyList (  )  )  ,    RatedDocument :  : new )  ;", "assertEquals ( deserialized ,    original )  ;", "assertEquals ( deserialized . hashCode (  )  ,    original . hashCode (  )  )  ;", "assertNotSame ( deserialized ,    original )  ;", "}", "METHOD_END"], "methodName": ["testSerialization"], "fileName": "org.elasticsearch.index.rankeval.RatedDocumentTests"}, {"methodBody": ["METHOD_START", "{", "RatedDocument   testItem    =    RatedDocumentTests . createRatedDocument (  )  ;", "XContentBuilder   builder    =    XContentFactory . contentBuilder ( randomFrom ( XContentType . values (  )  )  )  ;", "XContentBuilder   shuffled    =    shuffleXContent ( testItem . toXContent ( builder ,    EMPTY _ PARAMS )  )  ;", "try    ( XContentParser   itemParser    =    createParser ( shuffled )  )     {", "RatedDocument   parsedItem    =    RatedDocument . fromXContent ( itemParser )  ;", "assertNotSame ( testItem ,    parsedItem )  ;", "assertEquals ( testItem ,    parsedItem )  ;", "assertEquals ( testItem . hashCode (  )  ,    parsedItem . hashCode (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentParsing"], "fileName": "org.elasticsearch.index.rankeval.RatedDocumentTests"}, {"methodBody": ["METHOD_START", "{", "RatedDocument   testItem    =    RatedDocumentTests . createRatedDocument (  )  ;", "XContentType   xContentType    =    randomFrom ( XContentType . values (  )  )  ;", "BytesReference   originalBytes    =    toShuffledXContent ( testItem ,    xContentType ,    EMPTY _ PARAMS ,    randomBoolean (  )  )  ;", "BytesReference   withRandomFields    =    insertRandomFields ( xContentType ,    originalBytes ,    null ,    random (  )  )  ;", "try    ( XContentParser   parser    =    createParser ( xContentType . xContent (  )  ,    withRandomFields )  )     {", "Exception   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    RatedDocument . fromXContent ( parser )  )  ;", "assertThat ( exception . getMessage (  )  ,    startsWith (  \"  [ rated _ document ]    unknown   field \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentParsingIsNotLenient"], "fileName": "org.elasticsearch.index.rankeval.RatedDocumentTests"}, {"methodBody": ["METHOD_START", "{", "this . summaryFields . addAll ( Objects . requireNonNull ( summaryFields ,     \" no   summary   fields   supplied \"  )  )  ;", "}", "METHOD_END"], "methodName": ["addSummaryFields"], "fileName": "org.elasticsearch.index.rankeval.RatedRequest"}, {"methodBody": ["METHOD_START", "{", "return   RatedRequest . PARSER . apply ( parser ,    null )  ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.index.rankeval.RatedRequest"}, {"methodBody": ["METHOD_START", "{", "return   id ;", "}", "METHOD_END"], "methodName": ["getId"], "fileName": "org.elasticsearch.index.rankeval.RatedRequest"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( this . params )  ;", "}", "METHOD_END"], "methodName": ["getParams"], "fileName": "org.elasticsearch.index.rankeval.RatedRequest"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableList ( ratedDocs )  ;", "}", "METHOD_END"], "methodName": ["getRatedDocs"], "fileName": "org.elasticsearch.index.rankeval.RatedRequest"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableList ( summaryFields )  ;", "}", "METHOD_END"], "methodName": ["getSummaryFields"], "fileName": "org.elasticsearch.index.rankeval.RatedRequest"}, {"methodBody": ["METHOD_START", "{", "return   this . templateId ;", "}", "METHOD_END"], "methodName": ["getTemplateId"], "fileName": "org.elasticsearch.index.rankeval.RatedRequest"}, {"methodBody": ["METHOD_START", "{", "return   testRequest ;", "}", "METHOD_END"], "methodName": ["getTestRequest"], "fileName": "org.elasticsearch.index.rankeval.RatedRequest"}, {"methodBody": ["METHOD_START", "{", "RatedRequestsTests . xContentRegistry    =    null ;", "}", "METHOD_END"], "methodName": ["afterClass"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "List < NamedWriteableRegistry . Entry >    namedWriteables    =    new   ArrayList <  >  (  )  ;", "namedWriteables . add ( new   NamedWriteableRegistry . Entry ( QueryBuilder . class ,    MatchAllQueryBuilder . NAME ,    MatchAllQueryBuilder :  : new )  )  ;", "return   ESTestCase . copyWriteable ( original ,    new   NamedWriteableRegistry ( namedWriteables )  ,     :  : new )  ;", "}", "METHOD_END"], "methodName": ["copy"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "String   requestId    =    randomAlphaOfLength (  5  0  )  ;", "List < RatedDocument >    ratedDocs    =    new   ArrayList <  >  (  )  ;", "int   size    =    randomIntBetween (  0  ,     2  )  ;", "for    ( int   i    =     0  ;    i    <    size ;    i +  +  )     {", "ratedDocs . add ( RatedDocumentTests . createRatedDocument (  )  )  ;", "}", "Map < String ,    Object >    params    =    new   HashMap <  >  (  )  ;", "SearchSourceBuilder   testRequest    =    null ;", "if    (  ( randomBoolean (  )  )     |  |    forceRequest )     {", "testRequest    =    new   SearchSourceBuilder (  )  ;", "testRequest . size ( randomIntBetween (  0  ,    Integer . MAX _ VALUE )  )  ;", "testRequest . query ( new   MatchAllQueryBuilder (  )  )  ;", "} else    {", "int   randomSize    =    randomIntBetween (  1  ,     1  0  )  ;", "for    ( int   i    =     0  ;    i    <    randomSize ;    i +  +  )     {", "params . put ( randomAlphaOfLengthBetween (  1  ,     1  0  )  ,    randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "}", "}", "List < String >    summaryFields    =    new   ArrayList <  >  (  )  ;", "int   numSummaryFields    =    randomIntBetween (  0  ,     5  )  ;", "for    ( int   i    =     0  ;    i    <    numSummaryFields ;    i +  +  )     {", "summaryFields . add ( randomAlphaOfLength (  5  )  )  ;", "}", "ratedRequest    =    null ;", "if    (  ( params . size (  )  )     =  =     0  )     {", "ratedRequest    =    new    ( requestId ,    ratedDocs ,    testRequest )  ;", "ratedRequest . addSummaryFields ( summaryFields )  ;", "} else    {", "ratedRequest    =    new    ( requestId ,    ratedDocs ,    params ,    randomAlphaOfLength (  5  )  )  ;", "ratedRequest . addSummaryFields ( summaryFields )  ;", "}", "return   ratedRequest ;", "}", "METHOD_END"], "methodName": ["createTestItem"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "RatedRequestsTests . xContentRegistry    =    new   NamedXContentRegistry ( Stream . of ( new   SearchModule ( Settings . EMPTY ,    false ,    Collections . emptyList (  )  )  . getNamedXContents (  )  . stream (  )  )  . flatMap ( Function . identity (  )  )  . collect ( Collectors . toList (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "String   id    =    original . getId (  )  ;", "SearchSourceBuilder   testRequest    =    original . getTestRequest (  )  ;", "List < RatedDocument >    ratedDocs    =    original . getRatedDocs (  )  ;", "Map < String ,    Object >    params    =    original . getParams (  )  ;", "List < String >    summaryFields    =    original . getSummaryFields (  )  ;", "String   templateId    =    original . getTemplateId (  )  ;", "int   mutate    =    randomIntBetween (  0  ,     3  )  ;", "switch    ( mutate )     {", "case    0     :", "id    =    randomValueOtherThan ( id ,     (  )     -  >    randomAlphaOfLength (  1  0  )  )  ;", "break ;", "case    1     :", "if    ( testRequest    !  =    null )     {", "int   size    =    randomValueOtherThan ( testRequest . size (  )  ,     (  )     -  >    randomInt ( Integer . MAX _ VALUE )  )  ;", "testRequest    =    new   SearchSourceBuilder (  )  ;", "testRequest . size ( size )  ;", "testRequest . query ( new   MatchAllQueryBuilder (  )  )  ;", "} else    {", "if    ( randomBoolean (  )  )     {", "Map < String ,    Object >    mutated    =    new   HashMap <  >  (  )  ;", "mutated . putAll ( params )  ;", "mutated . put (  \" one _ more _ key \"  ,     \" one _ more _ value \"  )  ;", "params    =    mutated ;", "} else    {", "templateId    =    randomValueOtherThan ( templateId ,     (  )     -  >    randomAlphaOfLength (  5  )  )  ;", "}", "}", "break ;", "case    2     :", "ratedDocs    =    Arrays . asList ( randomValueOtherThanMany ( ratedDocs :  : contains ,     (  )     -  >    RatedDocumentTests . createRatedDocument (  )  )  )  ;", "break ;", "case    3     :", "summaryFields    =    Arrays . asList ( randomValueOtherThanMany ( summaryFields :  : contains ,     (  )     -  >    randomAlphaOfLength (  1  0  )  )  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  \" Requested   to   modify   more   than   available   parameters .  \"  )  ;", "}", "ratedRequest ;", "if    ( testRequest    =  =    null )     {", "ratedRequest    =    new    ( id ,    ratedDocs ,    params ,    templateId )  ;", "} else    {", "ratedRequest    =    new    ( id ,    ratedDocs ,    testRequest )  ;", "}", "ratedRequest . addSummaryFields ( summaryFields )  ;", "return   ratedRequest ;", "}", "METHOD_END"], "methodName": ["mutateTestItem"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    ratedDocs    =    Arrays . asList ( new   RatedDocument (  \" index 1  \"  ,     \" id 1  \"  ,     1  )  ,    new   RatedDocument (  \" index 1  \"  ,     \" id 1  \"  ,     5  )  )  ;", "IllegalArgumentException   ex    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    (  \" test _ query \"  ,    ratedDocs ,    new   SearchSourceBuilder (  )  )  )  ;", "assertEquals (  \" Found   duplicate   rated   document   key    [  {  \\  \"  _ index \\  \"  :  \\  \" index 1  \\  \"  ,  \\  \"  _ id \\  \"  :  \\  \" id 1  \\  \"  }  ]    in   evaluation   request    [ test _ query ]  \"  ,    ex . getMessage (  )  )  ;", "Map < String ,    Object >    params    =    new   HashMap <  >  (  )  ;", "params . put (  \" key \"  ,     \" value \"  )  ;", "ex    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    (  \" test _ query \"  ,    ratedDocs ,    params ,     \" templateId \"  )  )  ;", "assertEquals (  \" Found   duplicate   rated   document   key    [  {  \\  \"  _ index \\  \"  :  \\  \" index 1  \\  \"  ,  \\  \"  _ id \\  \"  :  \\  \" id 1  \\  \"  }  ]    in   evaluation   request    [ test _ query ]  \"  ,    ex . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testDuplicateRatedDocThrowsException"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "checkEqualsAndHashCode ( RatedRequestsTests . createTestItem ( randomBoolean (  )  )  ,    RatedRequestsTests :  : copy ,    RatedRequestsTests :  : mutateTestItem )  ;", "}", "METHOD_END"], "methodName": ["testEqualsAndHash"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    ratedDocs    =    Arrays . asList ( new   RatedDocument (  \" index 1  \"  ,     \" id 1  \"  ,     1  )  )  ;", "request    =    new    (  \" id \"  ,    ratedDocs ,    new   SearchSourceBuilder (  )  )  ;", "assertNotNull ( request . getParams (  )  )  ;", "assertEquals (  0  ,    request . getParams (  )  . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullParamsTreatment"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    ratedDocs    =    Arrays . asList ( new   RatedDocument (  \" index 1  \"  ,     \" id 1  \"  ,     1  )  )  ;", "request    =    new    (  \" id \"  ,    ratedDocs ,    new   SearchSourceBuilder (  )  )  ;", "expectThrows ( NullPointerException . class ,     (  )     -  >    request . addSummaryFields ( null )  )  ;", "}", "METHOD_END"], "methodName": ["testNullSummaryFieldsTreatment"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "String   querySpecString    =     \"     {  \\ n \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"           \\  \" id \\  \"  :     \\  \" my _ qa _ query \\  \"  ,  \\ n \"     +     \"           \\  \" request \\  \"  :     {  \\ n \"  )     +     \"                                   \\  \" query \\  \"  :     {  \\ n \"  )     +     \"                                               \\  \" bool \\  \"  :     {  \\ n \"  )     +     \"                                                           \\  \" must \\  \"  :     [  \\ n \"  )     +     \"                                                                       {  \\  \" match \\  \"  :     {  \\  \" beverage \\  \"  :     \\  \" coffee \\  \"  }  }  ,  \\ n \"  )     +     \"                                                                       {  \\  \" term \\  \"  :     {  \\  \" browser \\  \"  :     {  \\  \" value \\  \"  :     \\  \" safari \\  \"  }  }  }  ,  \\ n \"  )     +     \"                                                                       {  \\  \" term \\  \"  :     {  \\  \" time _ of _ day \\  \"  :     \"  )     +     \"                                                                                                        {  \\  \" value \\  \"  :     \\  \" morning \\  \"  ,  \\  \" boost \\  \"  :     2  }  }  }  ,  \\ n \"  )     +     \"                                                                       {  \\  \" term \\  \"  :     {  \\  \" ip _ location \\  \"  :     \"  )     +     \"                                                                                                        {  \\  \" value \\  \"  :     \\  \" ams \\  \"  ,  \\  \" boost \\  \"  :     1  0  }  }  }  ]  }  \\ n \"  )     +     \"                                   }  ,  \\ n \"  )     +     \"                                   \\  \" size \\  \"  :     1  0  \\ n \"  )     +     \"           }  ,  \\ n \"  )     +     \"           \\  \" summary _ fields \\  \"     :     [  \\  \" title \\  \"  ]  ,  \\ n \"  )     +     \"           \\  \" ratings \\  \"  :     [  \\ n \"  )     +     \"                          {  \\  \"  _ index \\  \"  :     \\  \" test \\  \"     ,     \\  \"  _ id \\  \"  :     \\  \"  1  \\  \"  ,     \\  \" rating \\  \"     :     1     }  ,  \\ n \"  )     +     \"                          {  \\  \"  _ index \\  \"  :     \\  \" test \\  \"  ,     \\  \" rating \\  \"     :     0  ,     \\  \"  _ id \\  \"  :     \\  \"  2  \\  \"  }  ,  \\ n \"  )     +     \"                          {  \\  \"  _ id \\  \"  :     \\  \"  3  \\  \"  ,     \\  \"  _ index \\  \"  :     \\  \" test \\  \"  ,     \\  \" rating \\  \"     :     1  }     ]  \"  )     +     \"  }  \\ n \"  )  ;", "try    ( XContentParser   parser    =    createParser ( jsonXContent ,    querySpecString )  )     {", "specification    =     . fromXContent ( parser )  ;", "assertEquals (  \" my _ qa _ query \"  ,    specification . getId (  )  )  ;", "assertNotNull ( specification . getTestRequest (  )  )  ;", "List < RatedDocument >    ratedDocs    =    specification . getRatedDocs (  )  ;", "assertEquals (  3  ,    ratedDocs . size (  )  )  ;", "for    ( int   i    =     0  ;    i    <     3  ;    i +  +  )     {", "assertEquals (  (  \"  \"     +     ( i    +     1  )  )  ,    ratedDocs . get ( i )  . getDocID (  )  )  ;", "assertEquals (  \" test \"  ,    ratedDocs . get ( i )  . getIndex (  )  )  ;", "if    ( i    =  =     1  )     {", "assertEquals (  0  ,    ratedDocs . get ( i )  . getRating (  )  )  ;", "} else    {", "assertEquals (  1  ,    ratedDocs . get ( i )  . getRating (  )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["testParseFromXContent"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "RatedRequest   original    =    RatedRequestsTests . createTestItem ( randomBoolean (  )  )  ;", "RatedRequest   deserialized    =    RatedRequestsTests . copy ( original )  ;", "assertEquals ( deserialized ,    original )  ;", "assertEquals ( deserialized . hashCode (  )  ,    original . hashCode (  )  )  ;", "assertNotSame ( deserialized ,    original )  ;", "}", "METHOD_END"], "methodName": ["testSerialization"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    ratedDocs    =    Arrays . asList ( new   RatedDocument (  \" index 1  \"  ,     \" id 1  \"  ,     1  )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    (  \" id \"  ,    ratedDocs ,    null ,    null )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    (  \" id \"  ,    ratedDocs ,    new   HashMap <  >  (  )  ,     \" templateId \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSettingNeitherParamsNorRequestThrows"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    ratedDocs    =    Arrays . asList ( new   RatedDocument (  \" index 1  \"  ,     \" id 1  \"  ,     1  )  )  ;", "Map < String ,    Object >    params    =    new   HashMap <  >  (  )  ;", "params . put (  \" key \"  ,     \" value \"  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    (  \" id \"  ,    ratedDocs ,    params ,    null )  )  ;", "}", "METHOD_END"], "methodName": ["testSettingParamsWithoutTemplateIdThrows"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    ratedDocs    =    Arrays . asList ( new   RatedDocument (  \" index 1  \"  ,     \" id 1  \"  ,     1  )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    (  \" id \"  ,    ratedDocs ,    null ,     \" templateId \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSettingTemplateIdNoParamsThrows"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "RatedRequest   testItem    =    RatedRequestsTests . createTestItem ( randomBoolean (  )  )  ;", "XContentType   xContentType    =    randomFrom ( XContentType . values (  )  )  ;", "BytesReference   originalBytes    =    toShuffledXContent ( testItem ,    xContentType ,    EMPTY _ PARAMS ,    randomBoolean (  )  )  ;", "BytesReference   withRandomFields    =    insertRandomFields ( xContentType ,    originalBytes ,    null ,    random (  )  )  ;", "try    ( XContentParser   parser    =    createParser ( xContentType . xContent (  )  ,    withRandomFields )  )     {", "Exception   exception    =    expectThrows ( Exception . class ,     (  )     -  >    RatedRequest . fromXContent ( parser )  )  ;", "if    ( exception   instanceof   XContentParseException )     {", "XContentParseException   xcpe    =     (  ( XContentParseException )     ( exception )  )  ;", "assertThat ( ExceptionsHelper . detailedMessage ( xcpe )  ,    containsString (  \" unknown   field \"  )  )  ;", "assertThat ( ExceptionsHelper . detailedMessage ( xcpe )  ,    containsString (  \" parser   not   found \"  )  )  ;", "}", "if    ( exception   instanceof   XContentParseException )     {", "assertThat ( exception . getMessage (  )  ,    containsString (  \"  [ request ]    failed   to   parse   field \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testXContentParsingIsNotLenient"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "RatedRequest   testItem    =    RatedRequestsTests . createTestItem ( randomBoolean (  )  )  ;", "XContentBuilder   builder    =    XContentFactory . contentBuilder ( randomFrom ( XContentType . values (  )  )  )  ;", "XContentBuilder   shuffled    =    shuffleXContent ( testItem . toXContent ( builder ,    EMPTY _ PARAMS )  )  ;", "try    ( XContentParser   itemParser    =    createParser ( shuffled )  )     {", "itemParser . nextToken (  )  ;", "RatedRequest   parsedItem    =    RatedRequest . fromXContent ( itemParser )  ;", "assertNotSame ( testItem ,    parsedItem )  ;", "assertEquals ( testItem ,    parsedItem )  ;", "assertEquals ( testItem . hashCode (  )  ,    parsedItem . hashCode (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentRoundtrip"], "fileName": "org.elasticsearch.index.rankeval.RatedRequestsTests"}, {"methodBody": ["METHOD_START", "{", "return   this . rating ;", "}", "METHOD_END"], "methodName": ["getRating"], "fileName": "org.elasticsearch.index.rankeval.RatedSearchHit"}, {"methodBody": ["METHOD_START", "{", "return   this . searchHit ;", "}", "METHOD_END"], "methodName": ["getSearchHit"], "fileName": "org.elasticsearch.index.rankeval.RatedSearchHit"}, {"methodBody": ["METHOD_START", "{", "return   RatedSearchHit . PARSER . apply ( parser ,    null )  ;", "}", "METHOD_END"], "methodName": ["parse"], "fileName": "org.elasticsearch.index.rankeval.RatedSearchHit"}, {"methodBody": ["METHOD_START", "{", "return   ESTestCase . copyWriteable ( original ,    new   NamedWriteableRegistry ( Collections . emptyList (  )  )  ,    RatedSearchHit :  : new )  ;", "}", "METHOD_END"], "methodName": ["copy"], "fileName": "org.elasticsearch.index.rankeval.RatedSearchHitTests"}, {"methodBody": ["METHOD_START", "{", "Optional < Integer >    rating    =    original . getRating (  )  ;", "SearchHit   hit    =    original . getSearchHit (  )  ;", "switch    ( randomIntBetween (  0  ,     1  )  )     {", "case    0     :", "rating    =     ( rating . isPresent (  )  )     ?    Optional . of (  (  ( rating . get (  )  )     +     1  )  )     :    Optional . of ( randomInt (  5  )  )  ;", "break ;", "case    1     :", "hit    =    new   SearchHit ( hit . docId (  )  ,     (  ( hit . getId (  )  )     +     ( randomAlphaOfLength (  1  0  )  )  )  ,    new   common . text . Text ( hit . getType (  )  )  ,    Collections . emptyMap (  )  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  \" The   test   should   only   allow   two   parameters   mutated \"  )  ;", "}", "return   new   RatedSearchHit ( hit ,    rating )  ;", "}", "METHOD_END"], "methodName": ["mutateTestItem"], "fileName": "org.elasticsearch.index.rankeval.RatedSearchHitTests"}, {"methodBody": ["METHOD_START", "{", "Optional < Integer >    rating    =     ( randomBoolean (  )  )     ?    Optional . empty (  )     :    Optional . of ( randomIntBetween (  0  ,     5  )  )  ;", "SearchHit   searchHit    =    new   SearchHit ( randomIntBetween (  0  ,     1  0  )  ,    randomAlphaOfLength (  1  0  )  ,    new   common . text . Text ( randomAlphaOfLength (  1  0  )  )  ,    Collections . emptyMap (  )  )  ;", "RatedSearchHit   ratedSearchHit    =    new   RatedSearchHit ( searchHit ,    rating )  ;", "return   ratedSearchHit ;", "}", "METHOD_END"], "methodName": ["randomRatedSearchHit"], "fileName": "org.elasticsearch.index.rankeval.RatedSearchHitTests"}, {"methodBody": ["METHOD_START", "{", "checkEqualsAndHashCode ( RatedSearchHitTests . randomRatedSearchHit (  )  ,    RatedSearchHitTests :  : copy ,    RatedSearchHitTests :  : mutateTestItem )  ;", "}", "METHOD_END"], "methodName": ["testEqualsAndHash"], "fileName": "org.elasticsearch.index.rankeval.RatedSearchHitTests"}, {"methodBody": ["METHOD_START", "{", "RatedSearchHit   original    =    RatedSearchHitTests . randomRatedSearchHit (  )  ;", "RatedSearchHit   deserialized    =    RatedSearchHitTests . copy ( original )  ;", "assertEquals ( deserialized ,    original )  ;", "assertEquals ( deserialized . hashCode (  )  ,    original . hashCode (  )  )  ;", "assertNotSame ( deserialized ,    original )  ;", "}", "METHOD_END"], "methodName": ["testSerialization"], "fileName": "org.elasticsearch.index.rankeval.RatedSearchHitTests"}, {"methodBody": ["METHOD_START", "{", "RatedSearchHit   testItem    =    RatedSearchHitTests . randomRatedSearchHit (  )  ;", "XContentType   xContentType    =    randomFrom ( XContentType . values (  )  )  ;", "BytesReference   originalBytes    =    toShuffledXContent ( testItem ,    xContentType ,    EMPTY _ PARAMS ,    randomBoolean (  )  )  ;", "BytesReference   withRandomFields    =    insertRandomFields ( xContentType ,    originalBytes ,    null ,    random (  )  )  ;", "try    ( XContentParser   parser    =    createParser ( xContentType . xContent (  )  ,    withRandomFields )  )     {", "RatedSearchHit   parsedItem    =    RatedSearchHit . parse ( parser )  ;", "assertNotSame ( testItem ,    parsedItem )  ;", "assertEquals ( testItem ,    parsedItem )  ;", "assertEquals ( testItem . hashCode (  )  ,    parsedItem . hashCode (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testXContentRoundtrip"], "fileName": "org.elasticsearch.index.rankeval.RatedSearchHitTests"}, {"methodBody": ["METHOD_START", "{", "rankEvalRequest . indices ( Strings . splitStringByCommaToArray ( request . param (  \" index \"  )  )  )  ;", "rankEvalRequest . indicesOptions ( IndicesOptions . fromRequest ( request ,    rankEvalRequest . indicesOptions (  )  )  )  ;", "RankEvalSpec   spec    =    RankEvalSpec . parse ( parser )  ;", "rankEvalRequest . seSpec ( spec )  ;", "}", "METHOD_END"], "methodName": ["parseRankEvalRequest"], "fileName": "org.elasticsearch.index.rankeval.RestRankEvalAction"}, {"methodBody": ["METHOD_START", "{", "if    (  ( doc . getSource (  )  )     =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  \"  [  \"     +     ( doc . getI (  )  )  )     +     \"  ]  [  \"  )     +     ( doc . getType (  )  )  )     +     \"  ]  [  \"  )     +     ( doc . getId (  )  )  )     +     \"  ]    didn ' t   store    _ source \"  )  )  ;", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["accept"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "destinationIndices . addAll ( indices )  ;", "}", "METHOD_END"], "methodName": ["addDestinationIndices"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "return   exponentialBackoff ( mainRequest . getRetryBackoffInitialTime (  )  ,    mainRequest . getMaxRetries (  )  )  ;", "}", "METHOD_END"], "methodName": ["buildBackoffPolicy"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "BulkRequest   bulkRequest    =    new   BulkRequest (  )  ;", "for    ( ScrollableHitSource . Hit   doc    :    docs )     {", "if    ( accept ( doc )  )     {", ". RequestWrapper <  ?  >    request    =    scriptApplier . apply ( copyMetadata ( buildRequest ( doc )  ,    doc )  ,    doc )  ;", "if    ( request    !  =    null )     {", "bulkRequest . add ( request . self (  )  )  ;", "}", "}", "}", "return   bulkRequest ;", "}", "METHOD_END"], "methodName": ["buildBulk"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "return   new   BulkByScrollResponse ( took ,    task . getStatus (  )  ,    indexingFailures ,    searchFailures ,    timedOut )  ;", "}", "METHOD_END"], "methodName": ["buildResponse"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "return    (    request ,    searchHit )     -  >    request ;", "}", "METHOD_END"], "methodName": ["buildScriptApplier"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "return   new   ClientScrollableHitSource ( logger ,    backoffPolicy ,    threadPool ,    worker :  : countSearchRetry ,    this :  : finishHim ,    client ,    mainRequest . getSearchRequest (  )  )  ;", "}", "METHOD_END"], "methodName": ["buildScrollableResultSource"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "copyRouting ( request ,    doc . getRouting (  )  )  ;", "return   request ;", "}", "METHOD_END"], "methodName": ["copyMetadata"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "request . setRouting ( routing )  ;", "}", "METHOD_END"], "methodName": ["copyRouting"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "logger . debug (  (  )     -  >    new   ParameterizedMessage (  \"  [  {  }  ]  :    finishing   with   a   catastrophic   failure \"  ,    task . getId (  )  )  ,    failure )  ;", "finishHim ( failure ,    Colles . emptyList (  )  ,    Colles . emptyList (  )  ,    false )  ;", "}", "METHOD_END"], "methodName": ["finishHim"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "logger . debug (  \"  [  {  }  ]  :    finishing   without   any   catastrophic   failures \"  ,    task . getId (  )  )  ;", "scrollSource . close (  (  )     -  >     {", "if    ( failure    =  =    null )     {", "Response   response    =    buildResponse ( timeValueNanos (  (  ( System . nanoTime (  )  )     -     ( startTime . get (  )  )  )  )  ,    indexingFailures ,    searchFailures ,    timedOut )  ;", "listener . onResponse ( response )  ;", "} else    {", "listener . onFailure ( failure )  ;", "}", "}  )  ;", "}", "METHOD_END"], "methodName": ["finishHim"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "try    {", "List < Failure >    failures    =    new   ArrayList <  >  (  )  ;", "Set < String >    destinationIndicesThisBatch    =    new   HashSet <  >  (  )  ;", "for    ( BulkItemResponse   item    :    response )     {", "if    ( item . isFailed (  )  )     {", "recordFailure ( item . getFailure (  )  ,    failures )  ;", "continue ;", "}", "switch    ( item . getOpType (  )  )     {", "case   CREATE    :", "case   INDEX    :", "if    (  ( item . getResponse (  )  . getResult (  )  )     =  =     ( Result . CREATED )  )     {", "worker . countCreated (  )  ;", "} else    {", "worker . countUpdated (  )  ;", "}", "break ;", "case   UPDATE    :", "worker . countUpdated (  )  ;", "break ;", "case   DELETE    :", "worker . countDeleted (  )  ;", "break ;", "}", "destinationIndicesThisBatch . add ( item . getIndex (  )  )  ;", "}", "if    ( task . isCancelled (  )  )     {", "logger . debug (  \"  [  {  }  ]  :    Finishing   early   because   the   task   was   cancelled \"  ,    task . getId (  )  )  ;", "finishHim ( null )  ;", "return ;", "}", "addDestinationIndices ( destinationIndicesThisBatch )  ;", "if    ( false    =  =     ( failures . isEmpty (  )  )  )     {", "refreshAndFinish ( Collections . unmodifiableList ( failures )  ,    Collections . emptyList (  )  ,    false )  ;", "return ;", "}", "if    (  (  ( mainRequest . getSize (  )  )     !  =     ( AbstractBulkByScrollRequest . SIZE _ ALL _ MATCHES )  )     &  &     (  ( worker . getSuccessfullyProcessed (  )  )     >  =     ( mainRequest . getSize (  )  )  )  )     {", "refreshAndFinish ( Collections . emptyList (  )  ,    Collections . emptyList (  )  ,    false )  ;", "return ;", "}", "startNextScroll ( thisBatchStartTime ,     . timeValueNanos ( System . nanoTime (  )  )  ,    response . getItems (  )  . length )  ;", "}    catch    ( Exception   t )     {", "finishHim ( t )  ;", "}", "}", "METHOD_END"], "methodName": ["onBulkResponse"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "logger . debug (  \"  [  {  }  ]  :    got   scroll   response   with    [  {  }  ]    hits \"  ,    task . getId (  )  ,    response . getHits (  )  . size (  )  )  ;", "if    ( task . isCancelled (  )  )     {", "logger . debug (  \"  [  {  }  ]  :    finishing   early   because   the   task   was   cancelled \"  ,    task . getId (  )  )  ;", "finishHim ( null )  ;", "return ;", "}", "if    (  (  ( response . getFailures (  )  . size (  )  )     >     0  )     |  |     ( response . isTimedOut (  )  )  )     {", "refreshAndFinish ( Collections . emptyList (  )  ,    response . getFailures (  )  ,    response . isTimedOut (  )  )  ;", "return ;", "}", "long   total    =    response . getTotalHits (  )  ;", "if    (  ( mainRequest . getSize (  )  )     >     0  )     {", "total    =    Math . min ( total ,    mainRequest . getSize (  )  )  ;", "}", "worker . setTotal ( total )  ;", "Runnable   prepareBulkRequestRunnable    =    new   Runnable (  )     {", "@ Override", "protected   void   doRun (  )    throws   Exception    {", "prepareBulkRequest ( timeValueNanos ( System . nanoTime (  )  )  ,    response )  ;", "}", "@ Override", "public   void   onFailure ( Exception   e )     {", "finishHim ( e )  ;", "}", "}  ;", "prepareBulkRequestRunnable    =     (  ( Runnable )     ( threadPool . getThreadContext (  )  . preserveContext ( prepareBulkRequestRunnable )  )  )  ;", "worker . delayPrepareBulkRequest ( threadPool ,    lastBatchStartTime ,    lastBatchSize ,    prepareBulkRequestRunnable )  ;", "}", "METHOD_END"], "methodName": ["onScrollResponse"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "logger . debug (  \"  [  {  }  ]  :    preparing   bulk   request \"  ,    task . getId (  )  )  ;", "if    ( task . isCancelled (  )  )     {", "logger . debug (  \"  [  {  }  ]  :    finishing   early   because   the   task   was   cancelled \"  ,    task . getId (  )  )  ;", "finishHim ( null )  ;", "return ;", "}", "if    ( response . getHits (  )  . isEmpty (  )  )     {", "refreshAndFinish ( Collections . emptyList (  )  ,    Collections . emptyList (  )  ,    false )  ;", "return ;", "}", "worker . countBatch (  )  ;", "List <  ?    extends   ScrollableHitSource . Hit >    hits    =    response . getHits (  )  ;", "if    (  ( mainRequest . getSize (  )  )     !  =     ( AbstractBulkByScrollRequest . SIZE _ ALL _ MATCHES )  )     {", "long   remaining    =    Math . max (  0  ,     (  ( mainRequest . getSize (  )  )     -     ( worker . getSuccessfullyProcessed (  )  )  )  )  ;", "if    ( remaining    <     ( hits . size (  )  )  )     {", "hits    =    hits . subList (  0  ,     (  ( int )     ( remaining )  )  )  ;", "}", "}", "BulkRequest   request    =    buildBulk ( hits )  ;", "if    ( request . requests (  )  . isEmpty (  )  )     {", "startNextScroll ( thisBatchStartTime ,     . timeValueNanos ( System . nanoTime (  )  )  ,     0  )  ;", "return ;", "}", "request . timeout ( mainRequest . getTimeout (  )  )  ;", "request . waitForActiveShards ( mainRequest . getWaitForActiveShards (  )  )  ;", "sendBulkRequest ( thisBatchStartTime ,    request )  ;", "}", "METHOD_END"], "methodName": ["prepareBulkRequest"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "if    (  ( failure . getStatus (  )  )     =  =     ( CONFLICT )  )     {", "worker . countVersionConflict (  )  ;", "if    ( false    =  =     ( mainRequest . isAbortOnVersionConflict (  )  )  )     {", "return ;", "}", "}", "failures . add ( failure )  ;", "}", "METHOD_END"], "methodName": ["recordFailure"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( task . isCancelled (  )  )     |  |     ( false    =  =     ( mainRequest . isRefresh (  )  )  )  )     |  |     ( destinationIndices . isEmpty (  )  )  )     {", "finishHim ( null ,    indexingFailures ,    Failures ,    timedOut )  ;", "return ;", "}", "RefreshRequest   refresh    =    new   RefreshRequest (  )  ;", "refresh . indices ( destinationIndices . toArray ( new   String [ destinationIndices . size (  )  ]  )  )  ;", "logger . debug (  \"  [  {  }  ]  :    refreshing \"  ,    task . getId (  )  )  ;", "client . admin (  )  . indices (  )  . refresh ( refresh ,    new   ActionListener < RefreshResponse >  (  )     {", "@ Override", "public   void   onResponse ( RefreshResponse   response )     {", "finishHim ( null ,    indexingFailures ,    Failures ,    timedOut )  ;", "}", "@ Override", "public   void   onFailure ( Exception   e )     {", "finishHim ( e )  ;", "}", "}  )  ;", "}", "METHOD_END"], "methodName": ["refreshAndFinish"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "if    ( logger . isDebugEnabled (  )  )     {", "logger . debug (  \"  [  {  }  ]  :    sending    [  {  }  ]    entry ,     [  {  }  ]    bulk   request \"  ,    task . getId (  )  ,    request . requests (  )  . size (  )  ,    new   common . unit . ByteSizeValue ( request . estimatedSizeInBytes (  )  )  )  ;", "}", "if    ( task . isCancelled (  )  )     {", "logger . debug (  \"  [  {  }  ]  :    finishing   early   because   the   task   was   cancelled \"  ,    task . getId (  )  )  ;", "finishHim ( null )  ;", "return ;", "}", "bulkRetry . withBackoff ( client :  : bulk ,    request ,    new   action . ActionListener < BulkResponse >  (  )     {", "@ Override", "public   void   onResponse ( BulkResponse   response )     {", "onBulkResponse ( thisBatchStartTime ,    response )  ;", "}", "@ Override", "public   void   onFailure ( Exception   e )     {", "finishHim ( e )  ;", "}", "}  ,    settings )  ;", "}", "METHOD_END"], "methodName": ["sendBulkRequest"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "scrollSource . setScroll ( scroll )  ;", "}", "METHOD_END"], "methodName": ["setScroll"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "logger . debug (  \"  [  {  }  ]  :    starting \"  ,    task . getId (  )  )  ;", "if    ( task . isCancelled (  )  )     {", "logger . debug (  \"  [  {  }  ]  :    finishing   early   because   the   task   was   cancelled \"  ,    task . getId (  )  )  ;", "finishHim ( null )  ;", "return ;", "}", "try    {", "startTime . set ( System . nanoTime (  )  )  ;", "scrollSource . start (  (    response )     -  >    onResponse ( timeValueNanos ( System . nanoTime (  )  )  ,     0  ,    response )  )  ;", "}    catch    ( Exception   e )     {", "finishHim ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["start"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "if    ( task . isCancelled (  )  )     {", "logger . debug (  \"  [  {  }  ]  :    finishing   early   because   the   task   was   cancelled \"  ,    task . getId (  )  )  ;", "finishHim ( null )  ;", "return ;", "}", "TimeValue   extraKeepAlive    =    worker . throttleWaitTime ( lastBatchStartTime ,    now ,    lastBatchSize )  ;", "scrollSource . startNext ( extraKeepAlive ,     (    response )     -  >     {", "onResponse ( lastBatchStartTime ,    lastBatchSize ,    response )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["startNextScroll"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "return   new   AbstractAsyncBulkByScrollAction . DeleteRequestWrapper ( request )  ;", "}", "METHOD_END"], "methodName": ["wrap"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "return   new   AbstractAsyncBulkByScrollAction . IndexRequestWrapper ( request )  ;", "}", "METHOD_END"], "methodName": ["wrap"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction"}, {"methodBody": ["METHOD_START", "{", "return   new   ScrollableHitSource . BasicHit (  \" index \"  ,     \" type \"  ,     \" id \"  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["doc"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollActionMetadataTestCase"}, {"methodBody": ["METHOD_START", "{", "IndexRequest   index    =    new   IndexRequest (  \" index \"  ,     \" type \"  ,     \"  1  \"  )  . source ( Collections . singletonMap (  \" foo \"  ,     \" bar \"  )  )  ;", "ScrollableHitSource . Hit   doc    =    new   ScrollableHitSource . BasicHit (  \" test \"  ,     \" type \"  ,     \" id \"  ,     0  )  ;", "ExecutableScript   executableScript    =    new   SimpleExecutableScript ( scriptBody )  ;", "ExecutableScript . Factory   factory    =     (    params )     -  >    executableScript ;", "when ( scriptService . compile (  . any (  )  ,    eq ( CONTEXT )  )  )  . thenReturn ( factory )  ;", "when ( scriptService . compile (  . any (  )  ,    eq ( UPDATE _ CONTEXT )  )  )  . thenReturn ( factory )  ;", "AbstractAsyncBulkByScrollAction < Request >    action    =    action ( scriptService ,     . request (  )  . setScript (  . mockScript (  \"  \"  )  )  )  ;", "AbstractAsyncBulkByScrollAction . RequestWrapper <  ?  >    result    =    action . buildScriptApplier (  )  . apply ( AbstractAsyncBulkByScrollAction . wrap ( index )  ,    doc )  ;", "return   result    !  =    null    ?     (  ( T )     ( result . self (  )  )  )     :    null ;", "}", "METHOD_END"], "methodName": ["applyScript"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollActionScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "scriptService    =    AbstractAsyncBulkByScrollActionScriptTestCase . mock ( ScriptService . class )  ;", "}", "METHOD_END"], "methodName": ["setupScriptService"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollActionScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "IndexRequest   index    =    applyScript (  ( Map < String ,    Object >    ctx )     -  >     {", "@ SuppressWarnings (  \" unchecked \"  )", "Map < String ,    Object >    source    =     (  ( Map < String ,    Object >  )     ( ctx . get (  \"  _ source \"  )  )  )  ;", "source . put (  \" bar \"  ,     \" cat \"  )  ;", "}  )  ;", "assertEquals (  \" cat \"  ,    index . sourceAsMap (  )  . get (  \" bar \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testChangeSource"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollActionScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "try    {", "applyScript (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \" junk \"  ,     \" junk \"  )  )  ;", ". fail (  \" Expected   error \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,     . equalTo (  \" Invalid   fields   added   to   context    [ junk ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testScriptAddingJunkToCtxIsError"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollActionScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "DeleteRequest   delete    =    applyScript (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \" op \"  ,    AbstractAsyncBulkByScrollAction . OpType . DELETE . toString (  )  )  )  ;", "assertThat ( delete . index (  )  ,     . equalTo (  \" index \"  )  )  ;", "assertThat ( delete . type (  )  ,     . equalTo (  \" type \"  )  )  ;", "assertThat ( delete . id (  )  ,     . equalTo (  \"  1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSetOpTypeDelete"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollActionScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "assertThat ( task . getStatus (  )  . getNoops (  )  ,    AbstractAsyncBulkByScrollActionScriptTestCase . equalTo (  0 L )  )  ;", "AbstractAsyncBulkByScrollActionScriptTestCase . assertNull ( applyScript (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \" op \"  ,    OpType . NOOP . toString (  )  )  )  )  ;", "assertThat ( task . getStatus (  )  . getNoops (  )  ,    AbstractAsyncBulkByScrollActionScriptTestCase . equalTo (  1 L )  )  ;", "}", "METHOD_END"], "methodName": ["testSetOpTypeNoop"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollActionScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   e    =    AbstractAsyncBulkByScrollActionScriptTestCase . expectThrows ( IllegalArgumentException . class ,     (  )     -  >    applyScript (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \" op \"  ,     \" unknown \"  )  )  )  ;", "assertThat ( e . getMessage (  )  ,    AbstractAsyncBulkByScrollActionScriptTestCase . equalTo (  \" Operation   type    [ unknown ]    not   allowed ,    only    [ noop ,    index ,    delete ]    are   allowed \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSetOpTypeUnknown"], "fileName": "org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollActionScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "Request   internal    =    setCommonOptions ( request ,    buildRequest ( request )  )  ;", "if    ( request . paramAsBoolean (  \" wait _ for _ completion \"  ,    true )  )     {", "Map < String ,    String >    params    =    new   HashMap <  >  (  )  ;", "params . put ( INCLUDE _ CREATED ,    Boolean . toString ( includeCreated )  )  ;", "params . put ( INCLUDE _ UPDATED ,    Boolean . toString ( includeUpdated )  )  ;", "return    (    channel )     -  >    client . executeLocally ( action ,    internal ,    new   BulkIByScrollResponseContentListener ( channel ,    params )  )  ;", "} else    {", "internal . setShouldStoreResult ( true )  ;", "}", "ActionRequestValidationException   validationException    =    internal . validate (  )  ;", "if    ( validationException    !  =    null )     {", "throw   validationException ;", "}", "return   sendTask ( client . getLocalNodeId (  )  ,    client . executeLocally ( action ,    internal ,    LoggingTaskListener . instance (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["doPrepareRequest"], "fileName": "org.elasticsearch.index.reindex.AbstractBaseReindexRestHandler"}, {"methodBody": ["METHOD_START", "{", "String   requestsPerSecondString    =    request . param (  \" requests _ per _ second \"  )  ;", "if    ( requestsPerSecondString    =  =    null )     {", "return   null ;", "}", "float   requestsPerSecond ;", "try    {", "requestsPerSecond    =    Float . parseFloat ( requestsPerSecondString )  ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   IllegalArgumentException (  \"  [ requests _ per _ second ]    must   be   a   float   greater   than    0  .    Use    -  1    to   disable   throttling .  \"  ,    e )  ;", "}", "if    ( requestsPerSecond    =  =     (  -  1  )  )     {", "return   Float . POSITIVE _ INFINITY ;", "}", "if    ( requestsPerSecond    <  =     0  )     {", "throw   new   IllegalArgumentException (  \"  [ requests _ per _ second ]    must   be   a   float   greater   than    0  .    Use    -  1    to   disable   throttling .  \"  )  ;", "}", "return   requestsPerSecond ;", "}", "METHOD_END"], "methodName": ["parseRequestsPerSecond"], "fileName": "org.elasticsearch.index.reindex.AbstractBaseReindexRestHandler"}, {"methodBody": ["METHOD_START", "{", "String   slicesString    =    request . param (  \" slices \"  )  ;", "if    ( slicesString    =  =    null )     {", "return   null ;", "}", "if    ( slicesString . equals ( AUTO _ SLICES _ VALUE )  )     {", "return   ulkByScrollRequest . AUTO _ SLICES ;", "}", "int   slices ;", "try    {", "slices    =    Integer . parseInt ( slicesString )  ;", "}    catch    ( NumberFormatException   e )     {", "throw   new   IllegalArgumentException (  (  (  \"  [ slices ]    must   be   a   positive   integer   or   the   string    \\  \" auto \\  \"  ,    but   was    [  \"     +    slicesString )     +     \"  ]  \"  )  ,    e )  ;", "}", "if    ( slices    <     1  )     {", "throw   new   IllegalArgumentException (  (  (  \"  [ slices ]    must   be   a   positive   integer   or   the   string    \\  \" auto \\  \"  ,    but   was    [  \"     +    slicesString )     +     \"  ]  \"  )  )  ;", "}", "return   slices ;", "}", "METHOD_END"], "methodName": ["parseSlices"], "fileName": "org.elasticsearch.index.reindex.AbstractBaseReindexRestHandler"}, {"methodBody": ["METHOD_START", "{", "return    (    channel )     -  >     {", "try    ( XContentBuilder   builder    =    channel . newBuilder (  )  )     {", "builder . startObject (  )  ;", "builder . field (  \" task \"  ,     (  ( localNodeId    +     \"  :  \"  )     +     ( task . getId (  )  )  )  )  ;", "builder . endObject (  )  ;", "channel . sendResponse ( new   BytesResponse ( Status . OK ,    builder )  )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["sendTask"], "fileName": "org.elasticsearch.index.reindex.AbstractBaseReindexRestHandler"}, {"methodBody": ["METHOD_START", "{", "assert   restRequest    !  =    null    :     \" RestRequest   should   not   be   null \"  ;", "assert   request    !  =    null    :     \" Request   should   not   be   null \"  ;", "request . setRefresh ( restRequest . paramAsBoolean (  \" refresh \"  ,    request . isRefresh (  )  )  )  ;", "request . setTimeout ( restRequest . paramAsTime (  \" timeout \"  ,    request . getTimeout (  )  )  )  ;", "Integer   slices    =     . parseSlices ( restRequest )  ;", "if    ( slices    !  =    null )     {", "request . setSlices ( slices )  ;", "}", "String   waitForActiveShards    =    restRequest . param (  \" wait _ for _ active _ shards \"  )  ;", "if    ( waitForActiveShards    !  =    null )     {", "request . setWaitForActiveShards ( ActiveShardCount . parseString ( waitForActiveShards )  )  ;", "}", "Float   requestsPerSecond    =     . parseRequestsPerSecond ( restRequest )  ;", "if    ( requestsPerSecond    !  =    null )     {", "request . setRequestsPerSecond ( requestsPerSecond )  ;", "}", "return   request ;", "}", "METHOD_END"], "methodName": ["setCommonOptions"], "fileName": "org.elasticsearch.index.reindex.AbstractBaseReindexRestHandler"}, {"methodBody": ["METHOD_START", "{", "if    (  ( restRequest . hasContentOrSourceParam (  )  )     =  =    false )     {", "return   null ;", "}", "try    ( XContentParser   parser    =    restRequest . contentOrSourceParamParser (  )  ; XContentBuilder   builder    =    XContentFactory . contentBuilder ( parser . contentType (  )  )  )     {", "Map < String ,    Object >    body    =    parser . map (  )  ;", "for    ( Map . Entry < String ,    Consumer < Object >  >    consumer    :    bodyConsumers . entrySet (  )  )     {", "Object   value    =    body . remove ( consumer . getKey (  )  )  ;", "if    ( value    !  =    null )     {", "consumer . getValue (  )  . accept ( value )  ;", "}", "}", "return   parser . contentType (  )  . xContent (  )  . createParser ( parser . getXContentRegistry (  )  ,    parser . getDeprecation (  )  ,    BytesReference . bytes ( builder . map ( body )  )  . streamInput (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["extractRequestSpecificFields"], "fileName": "org.elasticsearch.index.reindex.AbstractBulkByQueryRestHandler"}, {"methodBody": ["METHOD_START", "{", "assert   internal    !  =    null    :     \" Request   should   not   be   null \"  ;", "assert   restRequest    !  =    null    :     \" RestRequest   should   not   be   null \"  ;", "SearchRequest   Request    =    internal . getSearchRequest (  )  ;", "try    ( XContentParser   parser    =    extractRequestSpecificFields ( restRequest ,    bodyConsumers )  )     {", "RestSearchAction . parseSearchRequest ( Request ,    restRequest ,    parser ,    internal :  : setSize )  ;", "}", "Request . source (  )  . size ( restRequest . paramAsInt (  \" scroll _ size \"  ,    Request . source (  )  . size (  )  )  )  ;", "String   conflicts    =    restRequest . param (  \" conflicts \"  )  ;", "if    ( conflicts    !  =    null )     {", "internal . setConflicts ( conflicts )  ;", "}", "if    ( restRequest . hasParam (  \"  _ timeout \"  )  )     {", "Request . source (  )  . timeout ( restRequest . paramAsTime (  \"  _ timeout \"  ,    null )  )  ;", "}", "}", "METHOD_END"], "methodName": ["parseInternalRequest"], "fileName": "org.elasticsearch.index.reindex.AbstractBulkByQueryRestHandler"}, {"methodBody": ["METHOD_START", "{", "int   totalFailures    =    randomIntBetween (  1  ,    testRequest . getMaxRetries (  )  )  ;", "int   size    =    randomIntBetween (  1  ,     1  0  0  )  ;", "testRequest . setMaxRetries (  ( totalFailures    -     ( failWithRejection    ?     1     :     0  )  )  )  ;", "client . bulksToReject    =     ( client . bulksAttempts . get (  )  )     +    totalFailures ;", "CountDownLatch   successLatch    =    new   CountDownLatch (  1  )  ;", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyActionWithoutBackoff (  )     {", "@ Override", "void   startNextScroll ( TimeValue   lastBatchStartTime ,    TimeValue   now ,    int   lastBatchSize )     {", "successLatch . countDown (  )  ;", "}", "}  ;", "BulkRequest   request    =    new   BulkRequest (  )  ;", "for    ( int   i    =     0  ;    i    <     ( size    +     1  )  ;    i +  +  )     {", "request . add ( new   IndexRequest (  \" index \"  ,     \" type \"  ,     (  \" id \"     +    i )  )  )  ;", "}", "action . sendBulkRequest ( timeValueNanos ( System . nanoTime (  )  )  ,    request )  ;", "if    ( failWithRejection )     {", "BulkByScrollResponse   response    =    listener . get (  )  ;", "assertThat ( response . getBulkFailures (  )  ,    hasSize (  1  )  )  ;", "assertEquals ( response . getBulkFailures (  )  . get (  0  )  . getStatus (  )  ,    TOO _ MANY _ REQUESTS )  ;", "assertThat ( response . getSearchFailures (  )  ,    empty (  )  )  ;", "assertNull ( response . getReasonCancelled (  )  )  ;", "} else    {", "assertTrue ( successLatch . await (  1  0  ,    TimeUnit . SECONDS )  )  ;", "}", "}", "METHOD_END"], "methodName": ["bulkRetryTestCase"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "AsyncBulkByScrollActionTests . DummyAsyncBulkByScrollAction   action    =    new   AsyncBulkByScrollActionTests . DummyAsyncBulkByScrollAction (  )  ;", "boolean   previousScrollSet    =    usually (  )  ;", "if    ( previousScrollSet )     {", "action . setScroll ( scrollId (  )  )  ;", "}", "String   reason    =    randomSimpleString ( random (  )  )  ;", "taskManager . cancel ( testTask ,    reason ,     (  )     -  >     {", "}  )  ;", "testMe . accept ( action )  ;", "assertEquals ( reason ,    listener . get (  )  . getReasonCancelled (  )  )  ;", "if    ( previousScrollSet )     {", "assertThat ( client . scrollsCleared ,    contains ( scrollId )  )  ;", "}", "}", "METHOD_END"], "methodName": ["cancelTaskCase"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "if    ( refresh    !  =    null )     {", "testRequest . setRefresh ( refresh )  ;", "}", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyAsyncBulkByScrollAction (  )  ;", "if    ( addDestinationIndexes )     {", "action . addDestinationIndices ( Collections . singleton (  \" foo \"  )  )  ;", "}", "action . refreshAndFinish ( Collections . emptyList (  )  ,    Collections . emptyList (  )  ,    false )  ;", "if    ( shouldRefresh )     {", "assertArrayEquals ( new   String [  ]  {     \" foo \"     }  ,    client . lastRefreshRequest . get (  )  . indices (  )  )  ;", "} else    {", "assertNull (  \" No   refresh   was   attempted \"  ,    client . lastRefreshRequest . get (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["refreshTestCase"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "scrollId    =    randomSimpleString ( random (  )  ,     1  ,     1  0  )  ;", "return   scrollId ;", "}", "METHOD_END"], "methodName": ["scrollId"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( client )     !  =    null )     {", "client . close (  )  ;", "}", "client    =    new    . MyMockClient ( new   NoOpClient ( threadPool )  )  ;", "client . threadPool (  )  . getThreadContext (  )  . putHeader ( expectedHeaders )  ;", "}", "METHOD_END"], "methodName": ["setupClient"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "expectedHeaders . clear (  )  ;", "expectedHeaders . put ( randomSimpleString ( random (  )  )  ,    randomSimpleString ( random (  )  )  )  ;", "setupClient ( new   TestThreadPool ( getTestName (  )  )  )  ;", "firstSearchRequest    =    new   SearchRequest (  )  ;", "testRequest    =    new    . DummyAbstractBulkByScrollRequest ( firstSearchRequest )  ;", "listener    =    new   PlainActionFuture (  )  ;", "scrollId    =    null ;", "threadPool    =    new   TestThreadPool ( getClass (  )  . getName (  )  )  ;", "taskManager    =    new   TaskManager ( Settings . EMPTY ,    threadPool ,    Collections . emptySet (  )  )  ;", "testTask    =     (  ( BulkByScrollTask )     ( taskManager . register (  \" don ' tcare \"  ,     \" hereeither \"  ,    testRequest )  )  )  ;", "testTask . setWorker ( testRequest . getRequestsPerSecond (  )  ,    null )  ;", "worker    =    testTask . getWorkerState (  )  ;", "localNode    =    new   DiscoveryNode (  \" thenode \"  ,    buildNewFakeTransportAddress (  )  ,    Collections . emptyMap (  )  ,    Collections . emptySet (  )  ,    Version . CURRENT )  ;", "taskId    =    new   TaskId ( localNode . getId (  )  ,    testTask . getId (  )  )  ;", "}", "METHOD_END"], "methodName": ["setupForTest"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "action . setScroll ( scrollId (  )  )  ;", "action . onScrollResponse ( lastBatchTime ,    lastBatchSize ,    response )  ;", "}", "METHOD_END"], "methodName": ["simulateScrollResponse"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "client . close (  )  ;", "terminate ( threadPool )  ;", "}", "METHOD_END"], "methodName": ["tearDownAndVerifyCommonStuff"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "AsyncBulkByScrollActionTests . DummyAsyncBulkByScrollAction   action    =    new   AsyncBulkByScrollActionTests . DummyAsyncBulkByScrollAction (  )     {", "@ Override", "protected   AbstractAsyncBulkByScrollAction . RequestWrapper <  ?  >    buildRequest ( Hit   doc )     {", "throw   new   RuntimeException (  \" surprise \"  )  ;", "}", "}  ;", "ScrollableHitSource . BasicHit   hit    =    new   ScrollableHitSource . BasicHit (  \" index \"  ,     \" type \"  ,     \" id \"  ,     0  )  ;", "hit . setSource ( new   BytesArray (  \"  {  }  \"  )  ,    JSON )  ;", "ScrollableHitSource . Response   response    =    new   ScrollableHitSource . Response ( false ,    Collections . emptyList (  )  ,     1  ,    Collections . singletonList ( hit )  ,    null )  ;", "simulateScrollResponse ( action ,    timeValueNanos ( System . nanoTime (  )  )  ,     0  ,    response )  ;", "ExecutionException   e    =    expectThrows ( ExecutionException . class ,     (  )     -  >    listener . get (  )  )  ;", "assertThat ( e . getCause (  )  ,    instanceOf ( RuntimeException . class )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    equalTo (  \" surprise \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildRequestThrowsException"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "Failure   failure    =    new   Failure (  \" index \"  ,     \" type \"  ,     \" id \"  ,    new   RuntimeException (  \" test \"  )  )  ;", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyAsyncBulkByScrollAction (  )  ;", "BulkResponse   bulkResponse    =    new   BulkResponse ( new   BulkItemResponse [  ]  {    new   BulkItemResponse (  0  ,    OpType . CREATE ,    failure )     }  ,    randomLong (  )  )  ;", "action . onBulkResponse ( timeValueNanos ( System . nanoTime (  )  )  ,    bulkResponse )  ;", "BulkByScrollResponse   response    =    listener . get (  )  ;", "assertThat ( response . getBulkFailures (  )  ,    contains ( failure )  )  ;", "assertThat ( response . getSearchFailures (  )  ,    empty (  )  )  ;", "assertNull ( response . getReasonCancelled (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBulkFailuresAbortRequest"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "bulkRetryTestCase ( true )  ;", "assertEquals ( testRequest . getMaxRetries (  )  ,    testTask . getStatus (  )  . getBulkRetries (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBulkRejectionsRetryAndFailAnyway"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "int   bulksToTry    =    randomIntBetween (  1  ,     1  0  )  ;", "long   retryAttempts    =     0  ;", "for    ( int   i    =     0  ;    i    <    bulksToTry ;    i +  +  )     {", "bulkRetryCase ( false )  ;", "retryAttempts    +  =    testRequest . getMaxRetries (  )  ;", "assertEquals ( retryAttempts ,    testTask . getStatus (  )  . getBulkRetries (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testBulkRejectionsRetryWithEnoughRetries"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "testRequest . setAbortOnVersionConflict ( false )  ;", "int   maxBatches    =    randomIntBetween (  0  ,     1  0  0  )  ;", "long   versionConflicts    =     0  ;", "long   created    =     0  ;", "long   updated    =     0  ;", "long   deleted    =     0  ;", "for    ( int   batches    =     0  ;    batches    <    maxBatches ;    batches +  +  )     {", "BulkItemResponse [  ]    responses    =    new   BulkItemResponse [ randomIntBetween (  0  ,     1  0  0  )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( responses . length )  ;    i +  +  )     {", "ShardId   shardId    =    new   ShardId ( new   Index (  \" name \"  ,     \" uid \"  )  ,     0  )  ;", "if    ( rarely (  )  )     {", "versionConflicts +  +  ;", "responses [ i ]     =    new   BulkItemResponse ( i ,    randomFrom ( OpType . values (  )  )  ,    new   Failure ( shardId . getIndexName (  )  ,     \" type \"  ,     (  \" id \"     +    i )  ,    new   VersionConflictEngineException ( shardId ,     \" type \"  ,     \" id \"  ,     \" test \"  )  )  )  ;", "continue ;", "}", "boolean   createdResponse ;", "DocWriteRequest . OpType   opType ;", "switch    ( randomIntBetween (  0  ,     2  )  )     {", "case    0     :", "createdResponse    =    true ;", "opType    =    OpType . CREATE ;", "created +  +  ;", "break ;", "case    1     :", "createdResponse    =    false ;", "opType    =    randomFrom ( INDEX ,    UPDATE )  ;", "updated +  +  ;", "break ;", "case    2     :", "createdResponse    =    false ;", "opType    =    OpType . DELETE ;", "deleted +  +  ;", "break ;", "default    :", "throw   new   RuntimeException (  \" Bad   scenario \"  )  ;", "}", "final   int   seqNo    =    randomInt (  2  0  )  ;", "final   int   primaryTerm    =    randomIntBetween (  1  ,     1  6  )  ;", "final   IndexResponse   response    =    new   IndexResponse ( shardId ,     \" type \"  ,     (  \" id \"     +    i )  ,    seqNo ,    primaryTerm ,    randomInt (  )  ,    createdResponse )  ;", "responses [ i ]     =    new   BulkItemResponse ( i ,    opType ,    response )  ;", "}", "new    . DummyAsyncBulkByScrollAction (  )  . onBulkResponse ( timeValueNanos ( System . nanoTime (  )  )  ,    new   BulkResponse ( responses ,     0  )  )  ;", "assertEquals ( versionConflicts ,    testTask . getStatus (  )  . getVersionConflicts (  )  )  ;", "assertEquals ( updated ,    testTask . getStatus (  )  . getUpdated (  )  )  ;", "assertEquals ( created ,    testTask . getStatus (  )  . getCreated (  )  )  ;", "assertEquals ( deleted ,    testTask . getStatus (  )  . getDeleted (  )  )  ;", "assertEquals ( versionConflicts ,    testTask . getStatus (  )  . getVersionConflicts (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testBulkResponseSetsLotsOfStatus"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "cancelTaskCase (  ( AsyncBulkByScrollActionTests . DummyAsyncBulkByScrollAction   action )     -  >    action . start (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCancelBeforeInitialSearch"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "cancelTaskCase (  ( AsyncBulkByScrollActionTests . DummyAsyncBulkByScrollAction   action )     -  >    action . onBulkResponse ( timeValueNanos ( System . nanoTime (  )  )  ,    new   BulkResponse ( new   BulkItemResponse [  0  ]  ,     0  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCancelBeforeOnBulkResponse"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "testRequest . setRefresh ( usually (  )  )  ;", "cancelTaskCase (  (  . DummyAsyncBulkByScrollAction   action )     -  >    action . refreshAndFinish ( Collections . emptyList (  )  ,    Collections . emptyList (  )  ,    false )  )  ;", "assertNull (  \" No   refresh   was   attempted \"  ,    client . lastRefreshRequest . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCancelBeforeRefreshAndFinish"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "cancelTaskCase (  ( AsyncBulkByScrollActionTests . DummyAsyncBulkByScrollAction   action )     -  >    simulateScrollResponse ( action ,    timeValueNanos ( System . nanoTime (  )  )  ,     1  ,    new   ScrollableHitSource . Response ( false ,    Collections . emptyList (  )  ,    between (  1  ,     1  0  0  0  0  0  )  ,    Collections . emptyList (  )  ,    null )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCancelBeforeScrollResponse"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "cancelTaskCase (  ( AsyncBulkByScrollActionTests . DummyAsyncBulkByScrollAction   action )     -  >    action . sendBulkRequest ( timeValueNanos ( System . nanoTime (  )  )  ,    new   BulkRequest (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCancelBeforeSendBulkRequest"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "TimeValue   now    =    timeValueNanos ( System . nanoTime (  )  )  ;", "cancelTaskCase (  (  . DummyAsyncBulkByScrollAction   action )     -  >    action . startNextScroll ( now ,    now ,     0  )  )  ;", "}", "METHOD_END"], "methodName": ["testCancelBeforeStartNextScroll"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "String   reason    =    randomSimpleString ( random (  )  )  ;", "setupClient ( new   TestThreadPool ( getTestName (  )  )     {", "@ Override", "public   ScheduledFuture <  ?  >    schedule ( TimeValue   delay ,    String   name ,    Runnable   command )     {", "if    (  ( delay . nanos (  )  )     >     0  )     {", "generic (  )  . execute (  (  )     -  >    taskManager . cancel ( testTask ,    reason ,     (  )     -  >     {", "}  )  )  ;", "}", "return   super . schedule ( delay ,    name ,    command )  ;", "}", "}  )  ;", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyAsyncBulkByScrollAction (  )  ;", "boolean   previousScrollSet    =    usually (  )  ;", "if    ( previousScrollSet )     {", "action . setScroll ( scrollId (  )  )  ;", "}", "long   total    =    randomIntBetween (  0  ,    Integer . MAX _ VALUE )  ;", "ScrollableHitSource . Response   response    =    new   ScrollableHitSource . Response ( false ,    Collections . emptyList (  )  ,    total ,    Collections . emptyList (  )  ,    null )  ;", "worker . rethrottle (  1  )  ;", "simulateScrollResponse ( action ,    timeValueNanos ( System . nanoTime (  )  )  ,     1  0  0  0  ,    response )  ;", "assertEquals ( reason ,    listener . get (  1  0  ,    TimeUnit . SECONDS )  . getReasonCancelled (  )  )  ;", "if    ( previousScrollSet )     {", "assertThat ( client . scrollsCleared ,    contains ( scrollId )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCancelWhileDelayedAfterScrollResponse"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "Iterator < TimeValue >    policy    =    new   AsyncBulkByScrollActionTests . DummyAsyncBulkByScrollAction (  )  . buildBackoffPolicy (  )  . iterator (  )  ;", "long   millis    =     0  ;", "while    ( policy . hasNext (  )  )     {", "millis    +  =    policy . next (  )  . millis (  )  ;", "}", "int   defaultBackoffBeforeFailing    =     5  9  4  6  0  ;", "assertEquals ( defaultBackoffBeforeFailing ,    millis )  ;", "}", "METHOD_END"], "methodName": ["testDefaultRetryTimes"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "refreshTestCase ( false ,    true ,    false )  ;", "}", "METHOD_END"], "methodName": ["testRefreshFalseDoesntExecuteRefresh"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "refreshTestCase ( null ,    true ,    false )  ;", "}", "METHOD_END"], "methodName": ["testRefreshIsFalseByDefault"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "refreshTestCase ( true ,    true ,    true )  ;", "}", "METHOD_END"], "methodName": ["testRefreshTrueExecutesRefresh"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "refreshTestCase ( true ,    false ,    false )  ;", "}", "METHOD_END"], "methodName": ["testRefreshTrueSkipsRefreshIfNoDestinationIndexes"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "AtomicReference < TimeValue >    capturedDelay    =    new   AtomicReference <  >  (  )  ;", "AtomicReference < Runnable >    capturedCommand    =    new   AtomicReference <  >  (  )  ;", "setupClient ( new   TestThreadPool ( getTestName (  )  )     {", "@ Override", "public   ScheduledFuture <  ?  >    schedule ( TimeValue   delay ,    String   name ,    Runnable   command )     {", "capturedDelay . set ( delay )  ;", "capturedCommand . set ( command )  ;", "return   null ;", "}", "}  )  ;", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyAsyncBulkByScrollAction (  )  ;", "action . setScroll ( scrollId (  )  )  ;", "firstSearchRequest . scroll ( timeValueSeconds (  1  0  )  )  ;", "worker . rethrottle (  1  .  0 F )  ;", "TimeValue   lastBatchStartTime    =    timeValueNanos ( System . nanoTime (  )  )  ;", "TimeValue   now    =    timeValueNanos (  (  ( lastBatchStartTime . nanos (  )  )     +     1  )  )  ;", "action . startNextScroll ( lastBatchStartTime ,    now ,     1  0  0  )  ;", "assertThat ( client . lastScroll . get (  )  . request . scroll (  )  . keepAlive (  )  . seconds (  )  ,    either ( equalTo (  1  1  0 L )  )  . or ( equalTo (  1  0  9 L )  )  )  ;", "SearchHit   hit    =    new   SearchHit (  0  ,     \" id \"  ,    new   Text (  \" type \"  )  ,    Collections . emptyMap (  )  )  ;", "SearchHits   hits    =    new   SearchHits ( new   SearchHit [  ]  {    hit    }  ,     0  ,     0  )  ;", "InternalSearchResponse   internalResponse    =    new   InternalSearchResponse ( hits ,    null ,    null ,    null ,    false ,    false ,     1  )  ;", "SearchResponse   searchResponse    =    new   SearchResponse ( internalResponse ,    scrollId (  )  ,     5  ,     4  ,     0  ,    randomLong (  )  ,    null ,    Clusters . EMPTY )  ;", "if    ( randomBoolean (  )  )     {", "client . lastScroll . get (  )  . listener . onResponse ( searchResponse )  ;", "assertEquals (  9  9  ,    capturedDelay . get (  )  . seconds (  )  )  ;", "} else    {", "worker . rethrottle (  1  0  .  0 F )  ;", "client . lastScroll . get (  )  . listener . onResponse ( searchResponse )  ;", "assertEquals (  9  ,    capturedDelay . get (  )  . seconds (  )  )  ;", "}", "capturedCommand . get (  )  . run (  )  ;", "assertEquals ( capturedDelay . get (  )  ,    testTask . getStatus (  )  . getThrottled (  )  )  ;", "}", "METHOD_END"], "methodName": ["testScrollDelay"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "int   maxBatches    =    randomIntBetween (  0  ,     1  0  0  )  ;", "for    ( int   batches    =     1  ;    batches    <    maxBatches ;    batches +  +  )     {", "Hit   hit    =    new   ScrollableHitSource . BasicHit (  \" index \"  ,     \" type \"  ,     \" id \"  ,     0  )  ;", "ScrollableHitSource . Response   response    =    new   ScrollableHitSource . Response ( false ,    Collections . emptyList (  )  ,     1  ,    Collections . singletonList ( hit )  ,    null )  ;", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyAsyncBulkByScrollAction (  )  ;", "simulateScrollResponse ( action ,    timeValueNanos ( System . nanoTime (  )  )  ,     0  ,    response )  ;", "final   int   expectedBatches    =    batches ;", "assertBusy (  (  )     -  >    assertEquals ( expectedBatches ,    testTask . getStatus (  )  . getBatches (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testScrollResponseBatchingBehavior"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    testTask . getStatus (  )  . getTotal (  )  )  ;", "long   total    =    randomIntBetween (  0  ,    Integer . MAX _ VALUE )  ;", "ScrollableHitSource . Response   response    =    new   ScrollableHitSource . Response ( false ,    Collections . emptyList (  )  ,    total ,    Collections . emptyList (  )  ,    null )  ;", "simulateScrollResponse ( new    . DummyAsyncBulkByScrollAction (  )  ,    timeValueSeconds (  0  )  ,     0  ,    response )  ;", "assertEquals ( total ,    testTask . getStatus (  )  . getTotal (  )  )  ;", "}", "METHOD_END"], "methodName": ["testScrollResponseSetsTotal"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "ScrollableHitSource . Response   scrollResponse    =    new   ScrollableHitSource . Response ( true ,    Collections . emptyList (  )  ,     0  ,    Collections . emptyList (  )  ,    null )  ;", "simulateScrollResponse ( new    . DummyAsyncBulkByScrollAction (  )  ,    timeValueNanos ( System . nanoTime (  )  )  ,     0  ,    scrollResponse )  ;", "BulkByScrollResponse   response    =    listener . get (  )  ;", "assertThat ( response . getBulkFailures (  )  ,    empty (  )  )  ;", "assertThat ( response . getSearchFailures (  )  ,    empty (  )  )  ;", "assertTrue ( response . isTimedOut (  )  )  ;", "assertNull ( response . getReasonCancelled (  )  )  ;", "assertThat ( client . scrollsCleared ,    contains ( scrollId )  )  ;", "}", "METHOD_END"], "methodName": ["testSearchTimeoutsAbortRequest"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "SearchFailure   shardFailure    =    new   SearchFailure ( new   RuntimeException (  \" test \"  )  )  ;", "ScrollableHitSource . Response   scrollResponse    =    new   ScrollableHitSource . Response ( false ,    Collections . singletonList ( shardFailure )  ,     0  ,    Collections . emptyList (  )  ,    null )  ;", "simulateScrollResponse ( new    . DummyAsyncBulkByScrollAction (  )  ,    timeValueNanos ( System . nanoTime (  )  )  ,     0  ,    scrollResponse )  ;", "BulkByScrollResponse   response    =    listener . get (  )  ;", "assertThat ( response . getBulkFailures (  )  ,    empty (  )  )  ;", "assertThat ( response . getSearchFailures (  )  ,    contains ( shardFailure )  )  ;", "assertFalse ( response . isTimedOut (  )  )  ;", "assertNull ( response . getReasonCancelled (  )  )  ;", "assertThat ( client . scrollsCleared ,    contains ( scrollId )  )  ;", "}", "METHOD_END"], "methodName": ["testShardFailuresAbortRequest"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "client . scrollsToReject    =    randomIntBetween (  0  ,     (  ( testRequest . getMaxRetries (  )  )     -     1  )  )  ;", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyActionWithoutBackoff (  )  ;", "action . setScroll ( scrollId (  )  )  ;", "TimeValue   now    =    timeValueNanos ( System . nanoTime (  )  )  ;", "action . startNextScroll ( now ,    now ,     0  )  ;", "assertBusy (  (  )     -  >    assertEquals (  ( client . scrollsToReject    +     1  )  ,    client . scrollAttempts . get (  )  )  )  ;", "if    ( listener . isDone (  )  )     {", "Object   result    =    listener . get (  )  ;", "fail (  (  \" Expected   listener   not   to   be   done   but   it   was   and   had    \"     +    result )  )  ;", "}", "assertBusy (  (  )     -  >    assertNotNull (  \" There   should   be   a   scroll   attempt   pending   that   we   didn ' t   reject \"  ,    client . lastScroll . get (  )  )  )  ;", "assertEquals ( client . scrollsToReject ,    testTask . getStatus (  )  . getSearchRetries (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStartNextScrollRetriesOnRejectionAndSucceeds"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "client . scrollsToReject    =     ( testRequest . getMaxRetries (  )  )     +     ( randomIntBetween (  1  ,     1  0  0  )  )  ;", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyActionWithoutBackoff (  )  ;", "action . setScroll ( scrollId (  )  )  ;", "TimeValue   now    =    timeValueNanos ( System . nanoTime (  )  )  ;", "action . startNextScroll ( now ,    now ,     0  )  ;", "assertBusy (  (  )     -  >    assertEquals (  (  ( testRequest . getMaxRetries (  )  )     +     1  )  ,    client . scrollAttempts . get (  )  )  )  ;", "assertBusy (  (  )     -  >    assertTrue ( listener . isDone (  )  )  )  ;", "ExecutionException   e    =    expectThrows ( ExecutionException . class ,     (  )     -  >    listener . get (  )  )  ;", "assertThat ( ExceptionsHelper . stackTrace ( e )  ,    containsString ( EsRejectedExecutionException . class . getSimpleName (  )  )  )  ;", "assertNull (  \" There   shouldn ' t   be   a   scroll   attempt   pending   that   we   didn ' t   reject \"  ,    client . lastScroll . get (  )  )  ;", "assertEquals ( testRequest . getMaxRetries (  )  ,    testTask . getStatus (  )  . getSearchRetries (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStartNextScrollRetriesOnRejectionButFailsOnTooManyRejections"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "client . searchesToReject    =    randomIntBetween (  0  ,     (  ( testRequest . getMaxRetries (  )  )     -     1  )  )  ;", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyActionWithoutBackoff (  )  ;", "action . start (  )  ;", "assertBusy (  (  )     -  >    assertEquals (  ( client . searchesToReject    +     1  )  ,    client . searchAttempts . get (  )  )  )  ;", "if    ( listener . isDone (  )  )     {", "Object   result    =    listener . get (  )  ;", "fail (  (  \" Expected   listener   not   to   be   done   but   it   was   and   had    \"     +    result )  )  ;", "}", "assertBusy (  (  )     -  >    assertNotNull (  \" There   should   be   a   search   attempt   pending   that   we   didn ' t   reject \"  ,    client . lastSearch . get (  )  )  )  ;", "assertEquals ( client . searchesToReject ,    testTask . getStatus (  )  . getSearchRetries (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStartRetriesOnRejectionAndSucceeds"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "client . searchesToReject    =     ( testRequest . getMaxRetries (  )  )     +     ( randomIntBetween (  1  ,     1  0  0  )  )  ;", ". DummyAsyncBulkByScrollAction   action    =    new    . DummyActionWithoutBackoff (  )  ;", "action . start (  )  ;", "assertBusy (  (  )     -  >    assertEquals (  (  ( testRequest . getMaxRetries (  )  )     +     1  )  ,    client . searchAttempts . get (  )  )  )  ;", "assertBusy (  (  )     -  >    assertTrue ( listener . isDone (  )  )  )  ;", "ExecutionException   e    =    expectThrows ( ExecutionException . class ,     (  )     -  >    listener . get (  )  )  ;", "assertThat ( ExceptionsHelper . stackTrace ( e )  ,    containsString ( EsRejectedExecutionException . class . getSimpleName (  )  )  )  ;", "assertNull (  \" There   shouldn ' t   be   a   search   attempt   pending   that   we   didn ' t   reject \"  ,    client . lastSearch . get (  )  )  ;", "assertEquals ( testRequest . getMaxRetries (  )  ,    testTask . getStatus (  )  . getSearchRetries (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStartRetriesOnRejectionButFailsOnTooManyRejections"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "worker . rethrottle (  1  )  ;", "setupClient ( new   TestThreadPool ( getTestName (  )  )     {", "@ Override", "public   ScheduledFuture <  ?  >    schedule ( TimeValue   delay ,    String   name ,    Runnable   command )     {", "assertThat ( delay . nanos (  )  ,    greaterThan (  0 L )  )  ;", "assertThat ( delay . seconds (  )  ,    lessThanOrEqualTo (  1  0 L )  )  ;", "(  ( AbstractRunnable )     ( command )  )  . onRejection ( new   EsRejectedExecutionException (  \" test \"  )  )  ;", "return   null ;", "}", "}  )  ;", "ScrollableHitSource . Response   response    =    new   ScrollableHitSource . Response ( false ,    Collections . emptyList (  )  ,     0  ,    Collections . emptyList (  )  ,    null )  ;", "simulateScrollResponse ( new    . DummyAsyncBulkByScrollAction (  )  ,    timeValueNanos ( System . nanoTime (  )  )  ,     1  0  ,    response )  ;", "ExecutionException   e    =    expectThrows ( ExecutionException . class ,     (  )     -  >    listener . get (  )  )  ;", "assertThat ( e . getCause (  )  ,    instanceOf ( EsRejectedExecutionException . class )  )  ;", "assertThat ( e . getCause (  )  ,    hasToString ( containsString (  \" test \"  )  )  )  ;", "assertThat ( client . scrollsCleared ,    contains ( scrollId )  )  ;", "assertEquals ( timeValueMillis (  0  )  ,    testTask . getStatus (  )  . getThrottled (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThreadPoolRejectionsAbortRequest"], "fileName": "org.elasticsearch.index.reindex.AsyncBulkByScrollActionTests"}, {"methodBody": ["METHOD_START", "{", "Map < Index ,    Integer >    countsByIndex    =    Arrays . stream ( response . getGroups (  )  )  . collect ( Collectors . toMap (  (    group )     -  >    group . getShardId (  )  . getIndex (  )  ,     (    group )     -  >     1  ,     (    sum ,    term )     -  >    sum    +    term )  )  ;", "Set < Integer >    counts    =    new   HashSet ( countsByIndex . values (  )  )  ;", "int   leastShards    =    Collections . min ( counts )  ;", "return   Math . min ( leastShards ,     . AUTO _ SLICE _ CEILING )  ;", "}", "METHOD_END"], "methodName": ["countSlicesBasedOnShards"], "fileName": "org.elasticsearch.index.reindex.BulkByScrollParallelizationHelper"}, {"methodBody": ["METHOD_START", "{", "LeaderBulkByScrollTaskState   worker    =    task . getLeaderState (  )  ;", "int   totalSlices    =    worker . getSlices (  )  ;", "TaskId   parentTaskId    =    new   TaskId ( localNodeId ,    task . getId (  )  )  ;", "for    ( final   SearchRequest   slice    :     . sliceIntoSubRequests ( request . getSearchRequest (  )  ,    NAME ,    totalSlices )  )     {", "Request   requestForSlice    =    request . forSlice ( parentTaskId ,    slice ,    totalSlices )  ;", "ActionListener < BulkByScrollResponse >    sliceListener    =    ActionListener . wrap (  (    r )     -  >    worker . onSliceResponse ( listener ,    slice . source (  )  . slice (  )  . getId (  )  ,    r )  ,     (    e )     -  >    worker . onSliceFailure ( listener ,    slice . source (  )  . slice (  )  . getId (  )  ,    e )  )  ;", "client . execute ( action ,    requestForSlice ,    sliceListener )  ;", "}", "}", "METHOD_END"], "methodName": ["sendSubRequests"], "fileName": "org.elasticsearch.index.reindex.BulkByScrollParallelizationHelper"}, {"methodBody": ["METHOD_START", "{", "if    ( slices    >     1  )     {", "task . setWorkerCount ( slices )  ;", ". sendSubRequests ( client ,    action ,    node . getId (  )  ,    task ,    request ,    listener )  ;", "} else    {", "SliceBuilder   sliceBuilder    =    request . getSearchRequest (  )  . source (  )  . slice (  )  ;", "Integer   sliceId    =     ( sliceBuilder    =  =    null )     ?    null    :    sliceBuilder . getId (  )  ;", "task . setWorker ( request . getRequestsPerSecond (  )  ,    sliceId )  ;", "workerAction . run (  )  ;", "}", "}", "METHOD_END"], "methodName": ["sliceConditionally"], "fileName": "org.elasticsearch.index.reindex.BulkByScrollParallelizationHelper"}, {"methodBody": ["METHOD_START", "{", "SearchRequest [  ]    slices    =    new   SearchRequest [ times ]  ;", "for    ( int   slice    =     0  ;    slice    <    times ;    slice +  +  )     {", "SliceBuilder   sliceBuilder    =    new   SliceBuilder ( field ,    slice ,    times )  ;", "SearchSourceBuilder   slicedSource ;", "if    (  ( request . source (  )  )     =  =    null )     {", "slicedSource    =    new   SearchSourceBuilder (  )  . slice ( sliceBuilder )  ;", "} else    {", "if    (  ( request . source (  )  . slice (  )  )     !  =    null )     {", "throw   new   IllegalStateException (  \" Can ' t   slice   a   request   that   already   has   a   slice   configuration \"  )  ;", "}", "slicedSource    =    request . source (  )  . copyWithNewSlice ( sliceBuilder )  ;", "}", "slices [ slice ]     =    new   SearchRequest (  )  . source ( slicedSource )  . Type ( request . Type (  )  )  . indices ( request . indices (  )  )  . types ( request . types (  )  )  . routing ( request . routing (  )  )  . preference ( request . preference (  )  )  . requestCache ( request . requestCache (  )  )  . scroll ( request . scroll (  )  )  . indicesOptions ( request . indicesOptions (  )  )  ;", "if    (  ( request . allowPartialSearchResults (  )  )     !  =    null )     {", "slices [ slice ]  . allowPartialSearchResults ( request . allowPartialSearchResults (  )  )  ;", "}", "}", "return   slices ;", "}", "METHOD_END"], "methodName": ["sliceIntoSubRequests"], "fileName": "org.elasticsearch.index.reindex.BulkByScrollParallelizationHelper"}, {"methodBody": ["METHOD_START", "{", "if    (  ( request . getSlices (  )  )     =  =     ( AbstractBulkByScrollRequest . AUTO _ SLICES )  )     {", "ClusterSearchShardsRequest   shardsRequest    =    new   ClusterSearchShardsRequest (  )  ;", "shardsRequest . indices ( request . getSearchRequest (  )  . indices (  )  )  ;", "client . admin (  )  . cluster (  )  . searchShards ( shardsRequest ,    ActionListener . wrap (  (    response )     -  >     {", "int   actualNumSlices    =    countSlicesBasedOnShards ( response )  ;", "sliceConditionally ( request ,    task ,    action ,    listener ,    client ,    node ,    workerAction ,    actualNumSlices )  ;", "}  ,    listener :  : onFailure )  )  ;", "} else    {", ". sliceConditionally ( request ,    task ,    action ,    listener ,    client ,    node ,    workerAction ,    request . getSlices (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["startSlicedAction"], "fileName": "org.elasticsearch.index.reindex.BulkByScrollParallelizationHelper"}, {"methodBody": ["METHOD_START", "{", "SearchRequest   searchRequest    =    RandomSearchRequestGenerator . randomSearchRequest (  (  )     -  >    randomSearchSourceBuilder (  (  )     -  >    null ,     (  )     -  >    null ,     (  )     -  >    null ,     (  )     -  >    emptyList (  )  ,     (  )     -  >    null )  )  ;", "if    (  ( searchRequest . source (  )  )     !  =    null )     {", "searchRequest . source (  )  . slice ( null )  ;", "}", "int   times    =    between (  2  ,     1  0  0  )  ;", "String   field    =     ( randomBoolean (  )  )     ?    IdFieldMapper . NAME    :    randomAlphaOfLength (  5  )  ;", "int   currentSliceId    =     0  ;", "for    ( SearchRequest   slice    :     . sliceIntoSubRequests ( searchRequest ,    field ,    times )  )     {", "assertEquals ( field ,    slice . source (  )  . slice (  )  . getField (  )  )  ;", "assertEquals ( currentSliceId ,    slice . source (  )  . slice (  )  . getId (  )  )  ;", "assertEquals ( times ,    slice . source (  )  . slice (  )  . getMax (  )  )  ;", "slice . source (  )  . slice ( null )  ;", "if    (  ( searchRequest . source (  )  )     =  =    null )     {", "searchRequest . source ( new   SearchSourceBuilder (  )  )  ;", "}", "assertEquals ( searchRequest ,    slice )  ;", "currentSliceId +  +  ;", "}", "}", "METHOD_END"], "methodName": ["testSliceIntoSubRequests"], "fileName": "org.elasticsearch.index.reindex.BulkByScrollParallelizationHelperTests"}, {"methodBody": ["METHOD_START", "{", "RestStatus   status    =    OK ;", "if    ( response . isTimedOut (  )  )     {", "status    =    REQUEST _ TIMEOUT ;", "}", "for    ( Failure   failure    :    response . getBulkFailures (  )  )     {", "if    (  ( failure . getStatus (  )  . getStatus (  )  )     >     ( status . getStatus (  )  )  )     {", "status    =    failure . getStatus (  )  ;", "}", "}", "for    ( SearchFailure   failure    :    response . getSearchFailures (  )  )     {", "RestStatus   failureStatus    =    ExceptionsHelper . status ( failure . getReason (  )  )  ;", "if    (  ( failureStatus . getStatus (  )  )     >     ( status . getStatus (  )  )  )     {", "status    =    failureStatus ;", "}", "}", "return   status ;", "}", "METHOD_END"], "methodName": ["getStatus"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseContentListener"}, {"methodBody": ["METHOD_START", "{", "return   batches ( equalTo ( batches )  )  ;", "}", "METHOD_END"], "methodName": ["batches"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "return   batches (  (  (  ( total    +    batchSize )     -     1  )     /    batchSize )  )  ;", "}", "METHOD_END"], "methodName": ["batches"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "this . batchesMatcher    =    batchesMatcher ;", "return   this ;", "}", "METHOD_END"], "methodName": ["batches"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "return   created ( equalTo ( created )  )  ;", "}", "METHOD_END"], "methodName": ["created"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "this . createdMatcher    =    createdMatcher ;", "return   this ;", "}", "METHOD_END"], "methodName": ["created"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "return   deleted ( equalTo ( deleted )  )  ;", "}", "METHOD_END"], "methodName": ["deleted"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "this . deletedMatcher    =    deletedMatcher ;", "return   this ;", "}", "METHOD_END"], "methodName": ["deleted"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "return   failures ( equalTo ( failures )  )  ;", "}", "METHOD_END"], "methodName": ["failures"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "this . failuresMatcher    =    failuresMatcher ;", "return   this ;", "}", "METHOD_END"], "methodName": ["failures"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "this . reasonCancelledMatcher    =    reasonCancelledMatcher ;", "return   this ;", "}", "METHOD_END"], "methodName": ["reasonCancelled"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "this . slicesMatcher    =    slicesMatcher ;", "return   this ;", "}", "METHOD_END"], "methodName": ["slices"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "return   updated ( equalTo ( updated )  )  ;", "}", "METHOD_END"], "methodName": ["updated"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "this . updatedMatcher    =    updatedMatcher ;", "return   this ;", "}", "METHOD_END"], "methodName": ["updated"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "return   versionConflicts ( equalTo ( versionConflicts )  )  ;", "}", "METHOD_END"], "methodName": ["versionConflicts"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "this . versionConflictsMatcher    =    versionConflictsMatcher ;", "return   this ;", "}", "METHOD_END"], "methodName": ["versionConflicts"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseMatcher"}, {"methodBody": ["METHOD_START", "{", "int   mergeCount    =    between (  2  ,     1  0  )  ;", "List < Bulk >    responses    =    new   ArrayList <  >  ( mergeCount )  ;", "int   took    =    between (  1  0  0  0  ,     1  0  0  0  0  )  ;", "int   tookIndex    =    between (  0  ,     ( mergeCount    -     1  )  )  ;", "List < BulkItemResponse . Failure >    allBulkFailures    =    new   ArrayList <  >  (  )  ;", "List < SearchFailure >    allSearchFailures    =    new   ArrayList <  >  (  )  ;", "boolean   timedOut    =    false ;", "String   reasonCancelled    =     ( rarely (  )  )     ?    randomAlphaOfLength (  5  )     :    null ;", "for    ( int   i    =     0  ;    i    <    mergeCount ;    i +  +  )     {", "TimeValue   thisTook    =    timeValueMillis (  ( i    =  =    tookIndex    ?    took    :    between (  0  ,    took )  )  )  ;", "String   thisReasonCancelled    =     ( rarely (  )  )     ?    randomAlphaOfLength (  5  )     :    null ;", "BulkByScrollTask . Status   status    =    new   BulkByScrollTask . Status ( i ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,    timeValueMillis (  0  )  ,     0  .  0 F ,    thisReasonCancelled ,    timeValueMillis (  0  )  )  ;", "List < BulkItemResponse . Failure >    bulkFailures    =     ( frequently (  )  )     ?    Collections . emptyList (  )     :    IntStream . range (  0  ,    between (  1  ,     3  )  )  . mapToObj (  (    j )     -  >    new   BulkItemResponse . Failure (  \" idx \"  ,     \" type \"  ,     \" id \"  ,    new   Exception (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "allBulkFailures . addAll ( bulkFailures )  ;", "List < SearchFailure >    searchFailures    =     ( frequently (  )  )     ?    Collections . emptyList (  )     :    IntStream . range (  0  ,    between (  1  ,     3  )  )  . mapToObj (  (    j )     -  >    new   SearchFailure ( new   Exception (  )  )  )  . collect ( Collectors . toList (  )  )  ;", "allSearchFailures . addAll ( searchFailures )  ;", "boolean   thisTimedOut    =    rarely (  )  ;", "timedOut    |  =    thisTimedOut ;", "responses . add ( new   Bulk ( thisTook ,    status ,    bulkFailures ,    searchFailures ,    thisTimedOut )  )  ;", "}", "Bulk   merged    =    new   Bulk ( responses ,    reasonCancelled )  ;", "assertEquals ( timeValueMillis ( took )  ,    merged . getTook (  )  )  ;", "assertEquals ( allBulkFailures ,    merged . getBulkFailures (  )  )  ;", "assertEquals ( allSearchFailures ,    merged . getSearchFailures (  )  )  ;", "assertEquals ( timedOut ,    merged . isTimedOut (  )  )  ;", "assertEquals ( reasonCancelled ,    merged . getReasonCancelled (  )  )  ;", "}", "METHOD_END"], "methodName": ["testMergeConstructor"], "fileName": "org.elasticsearch.index.reindex.BulkIndexByScrollResponseTests"}, {"methodBody": ["METHOD_START", "{", "CancelTests . ALLOWED _ OPERATIONS . drainPermits (  )  ;", "}", "METHOD_END"], "methodName": ["clearAllowedOperations"], "fileName": "org.elasticsearch.index.reindex.CancelTests"}, {"methodBody": ["METHOD_START", "{", "ListTasksResponse   tasks ;", "long   start    =    System . nanoTime (  )  ;", "do    {", "tasks    =    client (  )  . admin (  )  . cluster (  )  . prepareListTasks (  )  . setActions ( actionName )  . setDetailed ( true )  . get (  )  ;", "tasks . rethrowFailures (  \" Find   tasks   to   c \"  )  ;", "for    ( TaskInfo   taskInfo    :    tasks . getTasks (  )  )     {", "if    ( false    =  =     ( taskInfo . getParentTaskId (  )  . isSet (  )  )  )     {", "return   taskInfo ;", "}", "}", "}    while    (  (  ( System . nanoTime (  )  )     -    start )     <     ( TimeUnit . SECONDS . toNanos (  1  0  )  )     )  ;", "throw   new   AssertionError (  (  \" Couldn ' t   find   task   to   rethrottle   after   waiting   tasks =  \"     +     ( tasks . getTasks (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["findTaskToCancel"], "fileName": "org.elasticsearch.index.reindex.CancelTests"}, {"methodBody": ["METHOD_START", "{", "createIndex ( CancelTests . INDEX )  ;", "int   numDocs    =     (  ( getNumShards ( CancelTests . INDEX )  . numPrimaries )     *     1  0  )     *     ( builder . request (  )  . getSlices (  )  )  ;", "CancelTests . ALLOWED _ OPERATIONS . release ( numDocs )  ;", "logger . debug (  \" setting   up    [  {  }  ]    docs \"  ,    numDocs )  ;", "indexRandom ( true ,    false ,    true ,    IntStream . range (  0  ,    numDocs )  . mapToObj (  (    i )     -  >    client (  )  . prepareIndex ( CancelTests . INDEX ,    CancelTests . TYPE ,    String . valueOf ( i )  )  . setSource (  \" n \"  ,    i )  )  . collect ( Collectors . toList (  )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch ( CancelTests . INDEX )  . setSize (  0  )  . get (  )  ,    numDocs )  ;", "assertThat ( CancelTests . ALLOWED _ OPERATIONS . drainPermits (  )  ,    equalTo (  0  )  )  ;", "builder . source (  )  . setSize (  1  )  ;", "int   numModifiedDocs    =    randomIntBetween (  (  ( builder . request (  )  . getSlices (  )  )     *     2  )  ,    numDocs )  ;", "logger . debug (  \" chose   to   modify    [  {  }  ]    out   of    [  {  }  ]    docs \"  ,    numModifiedDocs ,    numDocs )  ;", "CancelTests . ALLOWED _ OPERATIONS . release (  ( numModifiedDocs    -     ( builder . request (  )  . getSlices (  )  )  )  )  ;", "ActionFuture <  ?    extends   BulkByScrollResponse >    future    =    builder . execute (  )  ;", "logger . debug (  \" waiting   for   updates   to   be   blocked \"  )  ;", "boolean   blocked    =    awaitBusy (  (  )     -  >     ( CancelTests . ALLOWED _ OPERATIONS . hasQueuedThreads (  )  )     &  &     (  ( CancelTests . ALLOWED _ OPERATIONS . availablePermits (  )  )     =  =     0  )  ,     1  ,    TimeUnit . MINUTES )  ;", "assertTrue (  \" updates   blocked \"  ,    blocked )  ;", "TaskInfo   mainTask    =    findTaskToCancel ( action ,    builder . request (  )  . getSlices (  )  )  ;", "BulkByScrollTask . Status   status    =     (  ( BulkByScrollTask . Status )     ( mainTask . getStatus (  )  )  )  ;", "assertNull ( status . getReasonCancelled (  )  )  ;", "assertThat ( mainTask . getDescription (  )  ,    taskDescriptionMatcher )  ;", "ListTasksResponse   cancelTasksResponse    =    client (  )  . admin (  )  . cluster (  )  . prepareCancelTasks (  )  . setTaskId ( mainTask . getTaskId (  )  )  . get (  )  ;", "cancelTasksResponse . rethrowFailures (  \" Cancel \"  )  ;", "assertThat ( cancelTasksResponse . getTasks (  )  ,    hasSize (  1  )  )  ;", "mainTask    =    client (  )  . admin (  )  . cluster (  )  . prepareGetTask ( mainTask . getTaskId (  )  )  . get (  )  . getTask (  )  . getTask (  )  ;", "status    =     (  ( BulkByScrollTask . Status )     ( mainTask . getStatus (  )  )  )  ;", "logger . debug (  \" asserting   that   parent   is   marked   canceled    {  }  \"  ,    status )  ;", "assertEquals ( DEFAULT _ REASON ,    status . getReasonCancelled (  )  )  ;", "if    (  ( builder . request (  )  . getSlices (  )  )     >     1  )     {", "boolean   foundCancelled    =    false ;", "ListTasksResponse   sliceList    =    client (  )  . admin (  )  . cluster (  )  . prepareListTasks (  )  . setParentTaskId ( mainTask . getTaskId (  )  )  . setDetailed ( true )  . get (  )  ;", "sliceList . rethrowFailures (  \" Fetch   slice   tasks \"  )  ;", "logger . debug (  \" finding   at   least   one   canceled   child   among    {  }  \"  ,    sliceList . getTasks (  )  )  ;", "for    ( TaskInfo   slice    :    sliceList . getTasks (  )  )     {", "BulkByScrollTask . Status   sliceStatus    =     (  ( BulkByScrollTask . Status )     ( slice . getStatus (  )  )  )  ;", "if    (  ( sliceStatus . getReasonCancelled (  )  )     =  =    null )", "continue ;", "assertEquals ( DEFAULT _ REASON ,    sliceStatus . getReasonCancelled (  )  )  ;", "foundCancelled    =    true ;", "}", "assertTrue (  \" Didn ' t   find   at   least   one   sub   task   that   was   cancelled \"  ,    foundCancelled )  ;", "}", "logger . debug (  \" unblocking   the   blocked   update \"  )  ;", "CancelTests . ALLOWED _ OPERATIONS . release ( builder . request (  )  . getSlices (  )  )  ;", "assertBusy (  (  )     -  >     {", "if    (  ( builder . request (  )  . getSlices (  )  )     =  =     1  )     {", "assertEquals (  0  ,    CancelTests . ALLOWED _ OPERATIONS . availablePermits (  )  )  ;", "}", "assertEquals (  0  ,    CancelTests . ALLOWED _ OPERATIONS . getQueueLength (  )  )  ;", "}  )  ;", "BulkByScrollResponse   response ;", "try    {", "response    =    future . get (  3  0  ,    TimeUnit . SECONDS )  ;", "}    catch    ( Exception   e )     {", "String   tasks    =    client (  )  . admin (  )  . cluster (  )  . prepareListTasks (  )  . setParentTaskId ( mainTask . getTaskId (  )  )  . setDetailed ( true )  . get (  )  . toString (  )  ;", "throw   new   RuntimeException (  (  \" Exception   while   waiting   for   the   response .    Running   tasks :     \"     +    tasks )  ,    e )  ;", "}", "assertThat ( response . getReasonCancelled (  )  ,    equalTo (  \" by   user   request \"  )  )  ;", "assertThat ( response . getBulkFailures (  )  ,    emptyIterable (  )  )  ;", "assertThat ( response . getSearchFailures (  )  ,    emptyIterable (  )  )  ;", "if    (  ( builder . request (  )  . getSlices (  )  )     >  =     1  )     {", "numModifiedDocs    -  =    CancelTests . ALLOWED _ OPERATIONS . availablePermits (  )  ;", "}", "flushAndRefresh ( CancelTests . INDEX )  ;", "assertion . assertThat ( response ,    numDocs ,    numModifiedDocs )  ;", "}", "METHOD_END"], "methodName": ["testCancel"], "fileName": "org.elasticsearch.index.reindex.CancelTests"}, {"methodBody": ["METHOD_START", "{", "testCancel ( NAME ,    deleteByQuery (  )  . source ( CancelTests . INDEX )  . filter ( QueryBuilders . matchAllQuery (  )  )  ,     (    response ,    total ,    modified )     -  >     {", "assertThat ( response ,    matcher (  )  . deleted ( modified )  . reasonCancelled ( equalTo (  \" by   user   request \"  )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch ( CancelTests . INDEX )  . setSize (  0  )  . get (  )  ,     ( total    -    modified )  )  ;", "}  ,    equalTo (  (  (  \" delete - by - query    [  \"     +     ( CancelTests . INDEX )  )     +     \"  ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQueryCancel"], "fileName": "org.elasticsearch.index.reindex.CancelTests"}, {"methodBody": ["METHOD_START", "{", "testCancel ( NAME ,    deleteByQuery (  )  . source ( CancelTests . INDEX )  . filter ( QueryBuilders . matchAllQuery (  )  )  . setSlices (  5  )  ,     (    response ,    total ,    modified )     -  >     {", "assertThat ( response ,    matcher (  )  . deleted ( modified )  . reasonCancelled ( equalTo (  \" by   user   request \"  )  )  . slices ( hasSize (  5  )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch ( CancelTests . INDEX )  . setSize (  0  )  . get (  )  ,     ( total    -    modified )  )  ;", "}  ,    equalTo (  (  (  \" delete - by - query    [  \"     +     ( CancelTests . INDEX )  )     +     \"  ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQueryCancelWithWorkers"], "fileName": "org.elasticsearch.index.reindex.CancelTests"}, {"methodBody": ["METHOD_START", "{", "testCancel ( NAME ,    reindex (  )  . source ( CancelTests . INDEX )  . destination (  \" dest \"  ,    CancelTests . TYPE )  ,     (    response ,    total ,    modified )     -  >     {", "assertThat ( response ,    matcher (  )  . created ( modified )  . reasonCancelled ( equalTo (  \" by   user   request \"  )  )  )  ;", "refresh (  \" dest \"  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest \"  )  . setTypes ( CancelTests . TYPE )  . setSize (  0  )  . get (  )  ,    modified )  ;", "}  ,    equalTo (  (  (  (  (  \" reindex   from    [  \"     +     ( CancelTests . INDEX )  )     +     \"  ]    to    [ dest ]  [  \"  )     +     ( CancelTests . TYPE )  )     +     \"  ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testReindexCancel"], "fileName": "org.elasticsearch.index.reindex.CancelTests"}, {"methodBody": ["METHOD_START", "{", "testCancel ( NAME ,    reindex (  )  . source ( CancelTests . INDEX )  . filter ( QueryBuilders . matchAllQuery (  )  )  . destination (  \" dest \"  ,    CancelTests . TYPE )  . setSlices (  5  )  ,     (    response ,    total ,    modified )     -  >     {", "assertThat ( response ,    matcher (  )  . created ( modified )  . reasonCancelled ( equalTo (  \" by   user   request \"  )  )  . slices ( hasSize (  5  )  )  )  ;", "refresh (  \" dest \"  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest \"  )  . setTypes ( CancelTests . TYPE )  . setSize (  0  )  . get (  )  ,    modified )  ;", "}  ,    equalTo (  (  (  (  (  \" reindex   from    [  \"     +     ( CancelTests . INDEX )  )     +     \"  ]    to    [ dest ]  [  \"  )     +     ( CancelTests . TYPE )  )     +     \"  ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testReindexCancelWithWorkers"], "fileName": "org.elasticsearch.index.reindex.CancelTests"}, {"methodBody": ["METHOD_START", "{", "BytesReference   pipeline    =    new   BytesArray (  (  \"  {  \\ n \"     +     (  (  (  (  \"        \\  \" description \\  \"     :     \\  \" sets   processed   to   true \\  \"  ,  \\ n \"     +     \"        \\  \" processors \\  \"     :     [     {  \\ n \"  )     +     \"                    \\  \" test \\  \"     :     {  }  \\ n \"  )     +     \"        }     ]  \\ n \"  )     +     \"  }  \"  )  )  )  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutPipeline (  \" set - processed \"  ,    pipeline ,    JSON )  . get (  )  )  ;", "testCancel ( NAME ,    updateByQuery (  )  . setPipeline (  \" set - processed \"  )  . source (  . INDEX )  ,     (    response ,    total ,    modified )     -  >     {", "assertThat ( response ,    matcher (  )  . updated ( modified )  . reasonCancelled ( equalTo (  \" by   user   request \"  )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  . INDEX )  . setSize (  0  )  . setQuery ( termQuery (  \" processed \"  ,    true )  )  . get (  )  ,    modified )  ;", "}  ,    equalTo (  (  (  \" update - by - query    [  \"     +     (  . INDEX )  )     +     \"  ]  \"  )  )  )  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . deletePipeline ( new   DeletePipelineRequest (  \" set - processed \"  )  )  . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testUpdateByQueryCancel"], "fileName": "org.elasticsearch.index.reindex.CancelTests"}, {"methodBody": ["METHOD_START", "{", "BytesReference   pipeline    =    new   BytesArray (  (  \"  {  \\ n \"     +     (  (  (  (  \"        \\  \" description \\  \"     :     \\  \" sets   processed   to   true \\  \"  ,  \\ n \"     +     \"        \\  \" processors \\  \"     :     [     {  \\ n \"  )     +     \"                    \\  \" test \\  \"     :     {  }  \\ n \"  )     +     \"        }     ]  \\ n \"  )     +     \"  }  \"  )  )  )  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutPipeline (  \" set - processed \"  ,    pipeline ,    JSON )  . get (  )  )  ;", "testCancel ( NAME ,    updateByQuery (  )  . setPipeline (  \" set - processed \"  )  . source (  . INDEX )  . setSlices (  5  )  ,     (    response ,    total ,    modified )     -  >     {", "assertThat ( response ,    matcher (  )  . updated ( modified )  . reasonCancelled ( equalTo (  \" by   user   request \"  )  )  . slices ( hasSize (  5  )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  . INDEX )  . setSize (  0  )  . setQuery ( termQuery (  \" processed \"  ,    true )  )  . get (  )  ,    modified )  ;", "}  ,    equalTo (  (  (  \" update - by - query    [  \"     +     (  . INDEX )  )     +     \"  ]  \"  )  )  )  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . deletePipeline ( new   DeletePipelineRequest (  \" set - processed \"  )  )  . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testUpdateByQueryCancelWithWorkers"], "fileName": "org.elasticsearch.index.reindex.CancelTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  2  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  3  \"  )  . setSource (  \" foo \"  ,     \" b \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . setSource (  \" foo \"  ,     \" c \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  5  \"  )  . setSource (  \" foo \"  ,     \" d \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  6  \"  )  . setSource (  \" foo \"  ,     \" e \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  7  \"  )  . setSource (  \" foo \"  ,     \" f \"  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     7  )  ;", "assertThat ( deleteByQuery (  )  . source (  \" test \"  )  . filter ( termQuery (  \" foo \"  ,     \" a \"  )  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted (  2  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     5  )  ;", "RequestBuilder   request    =    deleteByQuery (  )  . source (  \" test \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  . size (  2  )  . refresh ( true )  ;", "request . source (  )  . addSort (  \" foo . keyword \"  ,    ASC )  ;", "assertThat ( request . get (  )  ,    ReindexTestCase . matcher (  )  . deleted (  2  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     3  )  ;", "assertThat ( deleteByQuery (  )  . source (  \" test \"  )  . filter ( termQuery (  \" foo \"  ,     \" no _ match \"  )  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted (  0  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     3  )  ;", "assertThat ( deleteByQuery (  )  . source (  \" test \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted (  3  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addAlias ( new   Alias (  \" alias \"  )  )  )  ;", "final   int   docs    =    scaledRandomIntBetween (  1  0  ,     1  0  0  )  ;", "List < IndexRequestBuilder >    builders    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    docs ;    i +  +  )     {", "builders . add ( client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,    Integer . toString ( i )  )  . setRouting ( randomAlphaOfLengthBetween (  1  ,     5  )  )  . setSource (  \" foo \"  ,     \" bar \"  )  )  ;", "}", "indexRandom ( true ,    true ,    true ,    builders )  ;", "int   n    =    between (  0  ,     ( docs    -     1  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . setQuery ( matchQuery (  \"  _ id \"  ,    Integer . toString ( n )  )  )  . get (  )  ,     1  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . setQuery ( QueryBuilders . matchAllQuery (  )  )  . get (  )  ,    docs )  ;", "RequestBuilder   delete    =    deleteByQuery (  )  . source (  \" alias \"  )  . filter ( matchQuery (  \"  _ id \"  ,    Integer . toString ( n )  )  )  ;", "assertThat ( delete . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted (  1 L )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . setQuery ( QueryBuilders . matchAllQuery (  )  )  . get (  )  ,     ( docs    -     1  )  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByMatchQuery"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "final   int   docs    =    randomIntBetween (  1  ,     5  0  )  ;", "List < IndexRequestBuilder >    builders    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    docs ;    i +  +  )     {", "builders . add ( client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,    Integer . toString ( i )  )  . setSource (  \" field \"  ,     1  )  )  ;", "}", "indexRandom ( true ,    true ,    true ,    builders )  ;", "String   block    =    randomFrom ( SETTING _ READ _ ONLY ,    SETTING _ READ _ ONLY _ ALLOW _ DELETE )  ;", "try    {", "enableIndexBlock (  \" test \"  ,    block )  ;", "assertThat ( d (  )  . source (  \" test \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted (  0  )  . failures ( docs )  )  ;", "}    finally    {", "disableIndexBlock (  \" test \"  ,    block )  ;", "}", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . get (  )  ,    docs )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQueryOnReadOnlyIndex"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource (  \" d \"  ,     \"  2  0  1  3  -  0  1  -  0  1  \"  )  )  ;", "RequestBuilder   delete    =    deleteByQuery (  )  . source (  \" test \"  )  . filter ( rangeQuery (  \" d \"  )  . to (  \" now -  1 h \"  )  )  ;", "assertThat ( delete . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted (  1 L )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . get (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQueryWithDateMath"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  )  . setSize (  0  )  . get (  )  ,     1  )  ;", "try    {", "d (  )  . source (  \" missing \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  . get (  )  ;", "fail (  \" should   have   thrown   an   exception   because   of   a   missing   index \"  )  ;", "}    catch    ( IndexNotFoundException   e )     {", "}", "}", "METHOD_END"], "methodName": ["testDeleteByQueryWithMissingIndex"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "final   int   indices    =    randomIntBetween (  2  ,     5  )  ;", "final   int   docs    =     ( randomIntBetween (  2  ,     1  0  )  )     *     2  ;", "long [  ]    candidates    =    new   long [ indices ]  ;", "long   deletions    =     0  ;", "List < IndexRequestBuilder >    builders    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    indices ;    i +  +  )     {", "candidates [ i ]     =    randomIntBetween (  1  ,    docs )  ;", "deletions    =    deletions    +     ( candidates [ i ]  )  ;", "for    ( int   j    =     0  ;    j    <    docs ;    j +  +  )     {", "boolean   candidate    =    j    <     ( candidates [ i ]  )  ;", "builders . add ( client (  )  . prepareIndex (  (  \" test -  \"     +    i )  ,     \" doc \"  ,    String . valueOf ( j )  )  . setSource (  \" candidate \"  ,    candidate )  )  ;", "}", "}", "indexRandom ( true ,    true ,    true ,    builders )  ;", "assertThat ( d (  )  . source (  \" test -  *  \"  )  . filter ( termQuery (  \" candidate \"  ,    true )  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted ( deletions )  )  ;", "for    ( int   i    =     0  ;    i    <    indices ;    i +  +  )     {", "long   remaining    =    docs    -     ( candidates [ i ]  )  ;", "assertHitCount ( client (  )  . prepareSearch (  (  \" test -  \"     +    i )  )  . setSize (  0  )  . get (  )  ,    remaining )  ;", "}", "assertHitCount ( client (  )  . prepareSearch (  )  . setSize (  0  )  . get (  )  ,     (  ( indices    *    docs )     -    deletions )  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQueryWithMultipleIndices"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "final   long   docs    =    randomIntBetween (  1  ,     5  0  )  ;", "List < IndexRequestBuilder >    builders    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    docs ;    i +  +  )     {", "builders . add ( client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,    String . valueOf ( i )  )  . setSource (  \" fields 1  \"  ,     1  )  )  ;", "}", "indexRandom ( true ,    true ,    true ,    builders )  ;", "assertThat ( d (  )  . source (  \" t *  \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted ( docs )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . get (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQueryWithOneIndex"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . setSettings ( Settings . builder (  )  . put (  \" number _ of _ shards \"  ,     2  )  )  )  ;", "ensureGreen (  \" test \"  )  ;", "final   int   docs    =    randomIntBetween (  2  ,     1  0  )  ;", "logger . info (  \"  -  -  >    indexing    [  {  }  ]    documents   with   routing \"  ,    docs )  ;", "List < IndexRequestBuilder >    builders    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    docs ;    i +  +  )     {", "builders . add ( client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,    String . valueOf ( i )  )  . setRouting ( String . valueOf ( i )  )  . setSource (  \" field 1  \"  ,     1  )  )  ;", "}", "indexRandom ( true ,    true ,    true ,    builders )  ;", "logger . info (  \"  -  -  >    counting   documents   with   no   routing ,    should   be   equal   to    [  {  }  ]  \"  ,    docs )  ;", "assertHitCount ( client (  )  . prepareSearch (  )  . setSize (  0  )  . get (  )  ,    docs )  ;", "String   routing    =    String . valueOf ( randomIntBetween (  2  ,    docs )  )  ;", "logger . info (  \"  -  -  >    counting   documents   with   routing    [  {  }  ]  \"  ,    routing )  ;", "long   expected    =    client (  )  . prepareSearch (  )  . setSize (  0  )  . setRouting ( routing )  . get (  )  . getHits (  )  . getTotalHits (  )  ;", "logger . info (  \"  -  -  >    delete   all   documents   with   routing    [  {  }  ]    with   a   delete - by - query \"  ,    routing )  ;", "RequestBuilder   delete    =    deleteByQuery (  )  . source (  \" test \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  ;", "delete . source (  )  . setRouting ( routing )  ;", "assertThat ( delete . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted ( expected )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  )  . setSize (  0  )  . get (  )  ,     ( docs    -    expected )  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQueryWithRouting"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "int   sourceIndices    =    between (  2  ,     5  )  ;", "Map < String ,    List < IndexRequestBuilder >  >    docs    =    new   HashMap <  >  (  )  ;", "for    ( int   sourceIndex    =     0  ;    sourceIndex    <    sourceIndices ;    sourceIndex +  +  )     {", "String   indexName    =     \" test \"     +    sourceIndex ;", "docs . put ( indexName ,    new   ArrayList (  )  )  ;", "int   numDocs    =    between (  5  ,     1  5  )  ;", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "docs . get ( indexName )  . add ( client (  )  . prepareIndex ( indexName ,     \" test \"  ,    Integer . toString ( i )  )  . setSource (  \" foo \"  ,     \" a \"  )  )  ;", "}", "}", "List < IndexRequestBuilder >    allDocs    =    docs . values (  )  . stream (  )  . flatMap ( Collection :  : stream )  . collect ( Collectors . toList (  )  )  ;", "indexRandom ( true ,    allDocs )  ;", "for    ( Map . Entry < String ,    List < IndexRequestBuilder >  >    entry    :    docs . entrySet (  )  )     {", "assertHitCount ( client (  )  . prepareSearch ( entry . getKey (  )  )  . setSize (  0  )  . get (  )  ,    entry . getValue (  )  . size (  )  )  ;", "}", "int   slices    =    ReindexTestCase . randomSlices (  1  ,     1  0  )  ;", "int   expectedSlices    =    expectedSliceStatuses ( slices ,    docs . keySet (  )  )  ;", "String [  ]    sourceIndexNames    =    docs . keySet (  )  . toArray ( new   String [ docs . size (  )  ]  )  ;", "assertThat ( d (  )  . source ( sourceIndexNames )  . filter ( QueryBuilders . matchAllQuery (  )  )  . refresh ( true )  . setSlices ( slices )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted ( allDocs . size (  )  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "for    ( String   index    :    docs . keySet (  )  )     {", "assertHitCount ( client (  )  . prepareSearch ( index )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     0  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMultipleSources"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  2  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  3  \"  )  . setSource (  \" foo \"  ,     \" b \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . setSource (  \" foo \"  ,     \" c \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  5  \"  )  . setSource (  \" foo \"  ,     \" d \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  6  \"  )  . setSource (  \" foo \"  ,     \" e \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  7  \"  )  . setSource (  \" foo \"  ,     \" f \"  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     7  )  ;", "int   slices    =    ReindexTestCase . randomSlices (  )  ;", "int   expectedSlices    =    expectedSliceStatuses ( slices ,     \" test \"  )  ;", "assertThat ( d (  )  . source (  \" test \"  )  . filter ( termQuery (  \" foo \"  ,     \" a \"  )  )  . refresh ( true )  . setSlices ( slices )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted (  2  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     5  )  ;", "assertThat ( d (  )  . source (  \" test \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  . refresh ( true )  . setSlices ( slices )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted (  5  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testSlices"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "final   Thread [  ]    threads    =    new   Thread [ scaledRandomIntBetween (  2  ,     5  )  ]  ;", "final   long   docs    =    randomIntBetween (  1  ,     5  0  )  ;", "List < IndexRequestBuilder >    builders    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    docs ;    i +  +  )     {", "for    ( int   t    =     0  ;    t    <     ( threads . length )  ;    t +  +  )     {", "builders . add ( client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  )  . setSource (  \" field \"  ,    t )  )  ;", "}", "}", "indexRandom ( true ,    true ,    true ,    builders )  ;", "final   CountDownLatch   start    =    new   CountDownLatch (  1  )  ;", "for    ( int   t    =     0  ;    t    <     ( threads . length )  ;    t +  +  )     {", "final   int   threadNum    =    t ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . setQuery ( QueryBuilders . termQuery (  \" field \"  ,    threadNum )  )  . get (  )  ,    docs )  ;", "Runnable   r    =     (  )     -  >     {", "try    {", "start . await (  )  ;", "assertThat ( d (  )  . source (  \"  _ all \"  )  . filter ( termQuery (  \" field \"  ,    threadNum )  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . deleted ( docs )  )  ;", "}    catch    ( InterruptedException   e )     {", "Thread . currentThread (  )  . interrupt (  )  ;", "}", "}  ;", "threads [ t ]     =    new   Thread ( r )  ;", "threads [ t ]  . start (  )  ;", "}", "start . countDown (  )  ;", "for    ( Thread   thread    :    threads )     {", "thread . join (  )  ;", "}", "for    ( int   t    =     0  ;    t    <     ( threads . length )  ;    t +  +  )     {", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . setQuery ( QueryBuilders . termQuery (  \" field \"  ,    t )  )  . get (  )  ,     0  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConcurrentDeleteByQueriesOnDifferentDocs"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryConcurrentTests"}, {"methodBody": ["METHOD_START", "{", "final   long   docs    =    randomIntBetween (  5  0  ,     1  0  0  )  ;", "List < IndexRequestBuilder >    builders    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    docs ;    i +  +  )     {", "builders . add ( client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,    String . valueOf ( i )  )  . setSource (  \" foo \"  ,     \" bar \"  )  )  ;", "}", "indexRandom ( true ,    true ,    true ,    builders )  ;", "final   Thread [  ]    threads    =    new   Thread [ scaledRandomIntBetween (  2  ,     9  )  ]  ;", "final   CountDownLatch   start    =    new   CountDownLatch (  1  )  ;", "final   MatchQueryBuilder   query    =    matchQuery (  \" foo \"  ,     \" bar \"  )  ;", "final   AtomicLong   deleted    =    new   AtomicLong (  0  )  ;", "for    ( int   t    =     0  ;    t    <     ( threads . length )  ;    t +  +  )     {", "Runnable   r    =     (  )     -  >     {", "try    {", "start . await (  )  ;", "BulkByScrollResponse   response    =    d (  )  . source (  \" test \"  )  . filter ( query )  . refresh ( true )  . get (  )  ;", "deleted . addAndGet ( response . getDeleted (  )  )  ;", "}    catch    ( InterruptedException   e )     {", "Thread . currentThread (  )  . interrupt (  )  ;", "}", "}  ;", "threads [ t ]     =    new   Thread ( r )  ;", "threads [ t ]  . start (  )  ;", "}", "start . countDown (  )  ;", "for    ( Thread   thread    :    threads )     {", "thread . join (  )  ;", "}", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . get (  )  ,     0 L )  ;", "assertThat ( deleted . get (  )  ,    equalTo ( docs )  )  ;", "}", "METHOD_END"], "methodName": ["testConcurrentDeleteByQueriesOnSameDocs"], "fileName": "org.elasticsearch.index.reindex.DeleteByQueryConcurrentTests"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   bulk    =    new   StringBuilder (  )  ;", "for    ( int   i    =     0  ;    i    <     ( count )  ;    i +  +  )     {", "bulk . append (  \"  {  \\  \"  \\  \"  :  {  }  }  \\ n \"  )  ;", "bulk . append (  \"  {  \\  \" test \\  \"  :  \\  \" test \\  \"  }  \\ n \"  )  ;", "}", "client (  )  . performRequest (  \" POST \"  ,     \"  / test / test /  _ bulk \"  ,    Collections . singletonMap (  \" refresh \"  ,     \" true \"  )  ,    new   StringEntity ( bulk . toString (  )  ,    ContentType . APPLICATION _ JSON )  )  ;", "}", "METHOD_END"], "methodName": ["setupTestIndex"], "fileName": "org.elasticsearch.index.reindex.ManyDocumentsIT"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    response    =    ManyDocumentsIT . toMap ( client (  )  . performRequest (  \" POST \"  ,     \"  / test /  _ delete _ by _ query \"  ,    Collections . emptyMap (  )  ,    new   StringEntity (  \"  {  \\  \" query \\  \"  :  {  \\  \" match _ all \\  \"  :  {  }  }  }  \"  ,    ContentType . APPLICATION _ JSON )  )  )  ;", "assertThat ( response ,    hasEntry (  \" total \"  ,    count )  )  ;", "assertThat ( response ,    hasEntry (  \" deleted \"  ,    count )  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQuery"], "fileName": "org.elasticsearch.index.reindex.ManyDocumentsIT"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    response    =    ManyDocumentsIT . toMap ( client (  )  . performRequest (  \" POST \"  ,     \"  /  _ reindex \"  ,    Collections . emptyMap (  )  ,    new   StringEntity (  \"  {  \\  \" source \\  \"  :  {  \\  \" index \\  \"  :  \\  \" test \\  \"  }  ,     \\  \" dest \\  \"  :  {  \\  \" index \\  \"  :  \\  \" des \\  \"  }  }  \"  ,    ContentType . APPLICATION _ JSON )  )  )  ;", "assertThat ( response ,    hasEntry (  \" total \"  ,    count )  )  ;", "assertThat ( response ,    hasEntry (  \" created \"  ,    count )  )  ;", "}", "METHOD_END"], "methodName": ["testReindex"], "fileName": "org.elasticsearch.index.reindex.ManyDocumentsIT"}, {"methodBody": ["METHOD_START", "{", "Map <  ?  ,     ?  >    nodesInfo    =    ManyDocumentsIT . toMap ( client (  )  . performRequest (  \" GET \"  ,     \"  /  _ nodes / http \"  )  )  ;", "nodesInfo    =     (  ( Map <  ?  ,     ?  >  )     ( nodesInfo . get (  \" nodes \"  )  )  )  ;", "Map <  ?  ,     ?  >    nodeInfo    =     (  ( Map <  ?  ,     ?  >  )     ( nodesInfo . values (  )  . iterator (  )  . next (  )  )  )  ;", "Map <  ?  ,     ?  >    http    =     (  ( Map <  ?  ,     ?  >  )     ( nodeInfo . get (  \" http \"  )  )  )  ;", "String   remote    =     \" http :  /  /  \"     +     ( http . get (  \" publish _ address \"  )  )  ;", "Map < String ,    Object >    response    =    ManyDocumentsIT . toMap ( client (  )  . performRequest (  \" POST \"  ,     \"  /  _ reindex \"  ,    Collections . emptyMap (  )  ,    new   StringEntity (  (  (  \"  {  \\  \" source \\  \"  :  {  \\  \" index \\  \"  :  \\  \" test \\  \"  ,  \\  \" remote \\  \"  :  {  \\  \" host \\  \"  :  \\  \"  \"     +    remote )     +     \"  \\  \"  }  }  ,     \\  \" dest \\  \"  :  {  \\  \" index \\  \"  :  \\  \" des \\  \"  }  }  \"  )  ,    ContentType . APPLICATION _ JSON )  )  )  ;", "assertThat ( response ,    hasEntry (  \" total \"  ,    count )  )  ;", "assertThat ( response ,    hasEntry (  \" created \"  ,    count )  )  ;", "}", "METHOD_END"], "methodName": ["testReindexFromRemote"], "fileName": "org.elasticsearch.index.reindex.ManyDocumentsIT"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    response    =    ManyDocumentsIT . toMap ( client (  )  . performRequest (  \" POST \"  ,     \"  / test /  _ update _ by _ query \"  )  )  ;", "assertThat ( response ,    hasEntry (  \" total \"  ,    count )  )  ;", "assertThat ( response ,    hasEntry (  \" updated \"  ,    count )  )  ;", "}", "METHOD_END"], "methodName": ["testUpdateByQuery"], "fileName": "org.elasticsearch.index.reindex.ManyDocumentsIT"}, {"methodBody": ["METHOD_START", "{", "return   XContentHelper . convertToMap ( jsonXContent ,    response . getEntity (  )  . getContent (  )  ,    false )  ;", "}", "METHOD_END"], "methodName": ["toMap"], "fileName": "org.elasticsearch.index.reindex.ManyDocumentsIT"}, {"methodBody": ["METHOD_START", "{", "List < IndexRequestBuilder >    docs    =    new   ArrayList <  >  (  )  ;", "int   max    =    between (  1  5  0  ,     5  0  0  )  ;", "for    ( int   i    =     0  ;    i    <    max ;    i +  +  )     {", "docs . add ( client (  )  . prepareIndex (  \" source \"  ,     \" test \"  ,    Integer . toString ( i )  )  . setSource (  \" foo \"  ,     \" a \"  )  )  ;", "}", "indexRandom ( true ,    docs )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" source \"  )  . setSize (  0  )  . get (  )  ,    max )  ;", "ReindexRequestBuilder   copy    =     (  )  . source (  \" source \"  )  . destination (  \" dest \"  ,     \" type \"  )  . refresh ( true )  ;", "copy . source (  )  . setSize (  5  )  ;", "assertThat ( copy . get (  )  ,    ReindexTestCase . matcher (  )  . created ( max )  . batches ( max ,     5  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest \"  )  . setSize (  0  )  . get (  )  ,    max )  ;", "int   half    =    max    /     2  ;", "copy    =     (  )  . source (  \" source \"  )  . destination (  \" dest _ half \"  ,     \" type \"  )  . refresh ( true )  ;", "copy . source (  )  . setSize (  5  )  ;", "copy . size ( half )  ;", "assertThat ( copy . get (  )  ,    ReindexTestCase . matcher (  )  . created ( half )  . batches ( half ,     5  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest _ half \"  )  . setSize (  0  )  . get (  )  ,    half )  ;", "}", "METHOD_END"], "methodName": ["testCopyMany"], "fileName": "org.elasticsearch.index.reindex.ReindexBasicTests"}, {"methodBody": ["METHOD_START", "{", "List < IndexRequestBuilder >    docs    =    new   ArrayList <  >  (  )  ;", "int   max    =    between (  1  5  0  ,     5  0  0  )  ;", "for    ( int   i    =     0  ;    i    <    max ;    i +  +  )     {", "docs . add ( client (  )  . prepareIndex (  \" source \"  ,     \" test \"  ,    Integer . toString ( i )  )  . setSource (  \" foo \"  ,     \" a \"  )  )  ;", "}", "indexRandom ( true ,    docs )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" source \"  )  . setSize (  0  )  . get (  )  ,    max )  ;", "int   slices    =    TestCase . randomSlices (  )  ;", "int   expectedSlices    =    expectedSliceStatuses ( slices ,     \" source \"  )  ;", "RequestBuilder   copy    =    reindex (  )  . source (  \" source \"  )  . destination (  \" dest \"  ,     \" type \"  )  . refresh ( true )  . setSlices ( slices )  ;", "copy . source (  )  . setSize (  5  )  ;", "assertThat ( copy . get (  )  ,    TestCase . matcher (  )  . created ( max )  . batches ( greaterThanOrEqualTo (  ( max    /     5  )  )  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest \"  )  . setTypes (  \" type \"  )  . setSize (  0  )  . get (  )  ,    max )  ;", "int   half    =    max    /     2  ;", "copy    =    reindex (  )  . source (  \" source \"  )  . destination (  \" dest _ half \"  ,     \" type \"  )  . refresh ( true )  . setSlices ( slices )  ;", "copy . source (  )  . setSize (  5  )  ;", "copy . size ( half )  ;", "BulkByScrollResponse   response    =    copy . get (  )  ;", "assertThat ( response ,    TestCase . matcher (  )  . created ( lessThanOrEqualTo (  (  ( long )     ( half )  )  )  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest _ half \"  )  . setSize (  0  )  . get (  )  ,    response . getCreated (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCopyManyWithSlices"], "fileName": "org.elasticsearch.index.reindex.ReindexBasicTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" source \"  ,     \" test \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" source \"  ,     \" test \"  ,     \"  2  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" source \"  ,     \" test \"  ,     \"  3  \"  )  . setSource (  \" foo \"  ,     \" b \"  )  ,    client (  )  . prepareIndex (  \" source \"  ,     \" test \"  ,     \"  4  \"  )  . setSource (  \" foo \"  ,     \" c \"  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" source \"  )  . setSize (  0  )  . get (  )  ,     4  )  ;", "ReindexRequestBuilder   copy    =     (  )  . source (  \" source \"  )  . destination (  \" dest \"  ,     \" type \"  )  . refresh ( true )  ;", "assertThat ( copy . get (  )  ,    ReindexTestCase . matcher (  )  . created (  4  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest \"  )  . setSize (  0  )  . get (  )  ,     4  )  ;", "createIndex (  \" none \"  )  ;", "copy    =     (  )  . source (  \" source \"  )  . destination (  \" none \"  ,     \" type \"  )  . filter ( termQuery (  \" foo \"  ,     \" no _ match \"  )  )  . refresh ( true )  ;", "assertThat ( copy . get (  )  ,    ReindexTestCase . matcher (  )  . created (  0  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" none \"  )  . setSize (  0  )  . get (  )  ,     0  )  ;", "copy    =     (  )  . source (  \" source \"  )  . destination (  \" dest _ half \"  ,     \" type \"  )  . filter ( termQuery (  \" foo \"  ,     \" a \"  )  )  . refresh ( true )  ;", "assertThat ( copy . get (  )  ,    ReindexTestCase . matcher (  )  . created (  2  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest _ half \"  )  . setSize (  0  )  . get (  )  ,     2  )  ;", "copy    =     (  )  . source (  \" source \"  )  . destination (  \" dest _ size _ one \"  ,     \" type \"  )  . size (  1  )  . refresh ( true )  ;", "assertThat ( copy . get (  )  ,    ReindexTestCase . matcher (  )  . created (  1  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest _ size _ one \"  )  . setSize (  0  )  . get (  )  ,     1  )  ;", "}", "METHOD_END"], "methodName": ["testFiltering"], "fileName": "org.elasticsearch.index.reindex.ReindexBasicTests"}, {"methodBody": ["METHOD_START", "{", "int   sourceIndices    =    between (  2  ,     5  )  ;", "Map < String ,    List < IndexRequestBuilder >  >    docs    =    new   HashMap <  >  (  )  ;", "for    ( int   sourceIndex    =     0  ;    sourceIndex    <    sourceIndices ;    sourceIndex +  +  )     {", "String   indexName    =     \" source \"     +    sourceIndex ;", "String   typeName    =     \" test \"     +    sourceIndex ;", "docs . put ( indexName ,    new   ArrayList (  )  )  ;", "int   numDocs    =    between (  5  0  ,     2  0  0  )  ;", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "docs . get ( indexName )  . add ( client (  )  . prepareIndex ( indexName ,    typeName ,     (  (  (  \" id _  \"     +    sourceIndex )     +     \"  _  \"  )     +    i )  )  . setSource (  \" foo \"  ,     \" a \"  )  )  ;", "}", "}", "List < IndexRequestBuilder >    allDocs    =    docs . values (  )  . stream (  )  . flatMap ( Collection :  : stream )  . collect ( Collectors . toList (  )  )  ;", "indexRandom ( true ,    allDocs )  ;", "for    ( Map . Entry < String ,    List < IndexRequestBuilder >  >    entry    :    docs . entrySet (  )  )     {", "assertHitCount ( client (  )  . prepareSearch ( entry . getKey (  )  )  . setSize (  0  )  . get (  )  ,    entry . getValue (  )  . size (  )  )  ;", "}", "int   slices    =    TestCase . randomSlices (  1  ,     1  0  )  ;", "int   expectedSlices    =    expectedSliceStatuses ( slices ,    docs . keySet (  )  )  ;", "String [  ]    sourceIndexNames    =    docs . keySet (  )  . toArray ( new   String [ docs . size (  )  ]  )  ;", "RequestBuilder   request    =    reindex (  )  . source ( sourceIndexNames )  . destination (  \" dest \"  ,     \" type \"  )  . refresh ( true )  . setSlices ( slices )  ;", "BulkByScrollResponse   response    =    request . get (  )  ;", "assertThat ( response ,    TestCase . matcher (  )  . created ( allDocs . size (  )  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" dest \"  )  . setSize (  0  )  . get (  )  ,    allDocs . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultipleSources"], "fileName": "org.elasticsearch.index.reindex.ReindexBasicTests"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.index.reindex.ReindexClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "List < IndexRequestBuilder >    docs    =    new   ArrayList <  >  ( count )  ;", "for    ( int   i    =     0  ;    i    <    count ;    i +  +  )     {", "docs . add ( client (  )  . prepareIndex (  \" source \"  ,     \" test \"  ,    Integer . toString ( i )  )  . setSource (  \" test \"  ,     \" words   words \"  )  )  ;", "}", "Random ( true ,    docs )  ;", "}", "METHOD_END"], "methodName": ["indexDocs"], "fileName": "org.elasticsearch.index.reindex.ReindexFailureTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" dest \"  ,     \" test \"  ,     \"  1  \"  )  . setSource (  \" test \"  ,     \" test \"  )  )  ;", "indexDocs (  1  0  0  )  ;", "ReindexRequestBuilder   copy    =     (  )  . source (  \" source \"  )  . destination (  \" dest \"  )  . abortOnVersionConflict ( true )  ;", "copy . destination (  )  . setOpType ( CREATE )  ;", "BulkByScrollResponse   response    =    copy . get (  )  ;", "assertThat ( response ,    ReindexTestCase . matcher (  )  . batches (  1  )  . versionConflicts (  1  )  . failures (  1  )  . created (  9  9  )  )  ;", "for    ( Failure   failure    :    response . getBulkFailures (  )  )     {", "assertThat ( failure . getMessage (  )  ,    containsString (  \" VersionConflictEngineException [  [ test ]  [  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testAbortOnVersionConflict"], "fileName": "org.elasticsearch.index.reindex.ReindexFailureTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" dest \"  ,     \" test \"  ,     \" test \"  )  . setSource (  \" test \"  ,     1  0  )  )  ;", "indexDocs (  1  0  0  )  ;", "ReindexRequestBuilder   copy    =     (  )  . source (  \" source \"  )  . destination (  \" dest \"  )  ;", "copy . source (  )  . setSize (  1  )  ;", "BulkByScrollResponse   response    =    copy . get (  )  ;", "assertThat ( response ,    ReindexTestCase . matcher (  )  . batches (  1  )  . failures ( both ( greaterThan (  0  )  )  . and ( lessThanOrEqualTo ( maximumNumberOfShards (  )  )  )  )  )  ;", "for    ( Failure   failure    :    response . getBulkFailures (  )  )     {", "assertThat ( failure . getMessage (  )  ,    containsString (  \" IllegalArgumentException [ For   input   string :     \\  \" words   words \\  \"  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testFailuresCauseAbortDefault"], "fileName": "org.elasticsearch.index.reindex.ReindexFailureTests"}, {"methodBody": ["METHOD_START", "{", "int   attempt    =     1  ;", "while    ( attempt    <     5  )     {", "indexDocs (  1  0  0  )  ;", "ReindexRequestBuilder   copy    =     (  )  . source (  \" source \"  )  . destination (  \" dest \"  )  ;", "copy . source (  )  . setSize (  1  0  )  ;", "Future < BulkByScrollResponse >    response    =    copy . execute (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareDelete (  \" source \"  )  . get (  )  ;", "try    {", "response . get (  )  ;", "logger . info (  \" Didn ' t   trigger   a      failure   on   the    {  }    attempt \"  ,    attempt )  ;", "attempt +  +  ;", "assertBusy (  (  )     -  >    assertFalse ( client (  )  . admin (  )  . indices (  )  . prepareExists (  \" source \"  )  . get (  )  . isExists (  )  )  )  ;", "}    catch    ( ExecutionException   e )     {", "logger . info (  \" Triggered   a      failure   on   the    {  }    attempt :     {  }  \"  ,    attempt ,    e . getMessage (  )  )  ;", "assertThat ( e . getMessage (  )  ,    either ( containsString (  \" all   shards   failed \"  )  )  . or ( containsString (  \" No   search   context   found \"  )  )  . or ( containsString (  \" no   such   index \"  )  )  )  ;", "return ;", "}", "}", "assumeFalse (  (  (  \" Wasn ' t   able   to   trigger   a      failure   in    \"     +    attempt )     +     \"    attempts .  \"  )  ,    true )  ;", "}", "METHOD_END"], "methodName": ["testResponseOnSearchFailure"], "fileName": "org.elasticsearch.index.reindex.ReindexFailureTests"}, {"methodBody": ["METHOD_START", "{", "RemoteInfo   remoteInfo    =    new   RemoteInfo (  \" https \"  ,     \" localhost \"  ,     9  2  0  0  ,    new   BytesArray (  \" ignored \"  )  ,    null ,    null ,    Collections . emptyMap (  )  ,    RemoteInfo . DEFAULT _ SOCKET _ TIMEOUT ,    RemoteInfo . DEFAULT _ CONNECT _ TIMEOUT )  ;", "long   taskId    =    randomLong (  )  ;", "List < Thread >    threads    =    Collections . synchronizedList ( new   ArrayList <  >  (  )  )  ;", "RestClient   client    =    TransportReindexAction . b ( remoteInfo ,    taskId ,    threads )  ;", "try    {", "assertBusy (  (  )     -  >    assertThat ( threads ,    hasSize (  2  )  )  )  ;", "int   i    =     0  ;", "for    ( Thread   thread    :    threads )     {", "assertEquals (  (  (  (  \" es - client -  \"     +    taskId )     +     \"  -  \"  )     +    i )  ,    thread . getName (  )  )  ;", "i +  +  ;", "}", "}    finally    {", "client . close (  )  ;", "}", "}", "METHOD_END"], "methodName": ["testBuildRestClient"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteBuildRestClientTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    headers    =    new   HashMap <  >  (  )  ;", "int   numHeaders    =    randomIntBetween (  1  ,     5  )  ;", "for    ( int   i    =     0  ;    i    <    numHeaders ;     +  + i )     {", "headers . put (  (  \" header \"     +    i )  ,    Integer . toString ( i )  )  ;", "}", "RemoteInfo   remoteInfo    =    new   RemoteInfo (  \" https \"  ,     \" localhost \"  ,     9  2  0  0  ,    new   BytesArray (  \" ignored \"  )  ,    null ,    null ,    headers ,    RemoteInfo . DEFAULT _ SOCKET _ TIMEOUT ,    RemoteInfo . DEFAULT _ CONNECT _ TIMEOUT )  ;", "long   taskId    =    randomLong (  )  ;", "List < Thread >    threads    =    Collections . synchronizedList ( new   ArrayList <  >  (  )  )  ;", "RestClient   client    =    TransportReindexAction . b ( remoteInfo ,    taskId ,    threads )  ;", "try    {", "assertHeaders ( client ,    headers )  ;", "}    finally    {", "client . close (  )  ;", "}", "}", "METHOD_END"], "methodName": ["testHeaders"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteBuildRestClientTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    buildRemoteWhitelist ( whitelist )  )  ;", "assertEquals (  (  (  (  (  \" Refusing   to   start   because   whitelist    \"     +    whitelist )     +     \"    accepts   all   addresses .     \"  )     +     \" This   would   allow   users   to   reindex - from - remote   any   URL   they   like   effectively   having   Elasticsearch   make   HTTP   GETs    \"  )     +     \" for   them .  \"  )  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertMatchesTooMuch"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "return   new   RemoteInfo ( randomAlphaOfLength (  5  )  ,    host ,    port ,    new   BytesArray (  \" test \"  )  ,    null ,    null ,    Collections . emptyMap (  )  ,    RemoteInfo . DEFAULT _ SOCKET _ TIMEOUT ,    RemoteInfo . DEFAULT _ CONNECT _ TIMEOUT )  ;", "}", "METHOD_END"], "methodName": ["newRemoteInfo"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "int   size    =    between (  1  ,     1  0  0  )  ;", "List < String >    w    =    new   ArrayList <  >  ( size )  ;", "for    ( int   i    =     0  ;    i    <    size ;    i +  +  )     {", "w . add (  (  (  ( randomAlphaOfLength (  5  )  )     +     '  :  '  )     +     ( between (  1  ,    Integer . MAX _ VALUE )  )  )  )  ;", "}", "return   w ;", "}", "METHOD_END"], "methodName": ["randomWhitelist"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "TransportReindexAction . checkRemoteWhitelist ( TransportReindexAction . buildRemoteWhitelist ( randomWhitelist (  )  )  ,    null )  ;", "}", "METHOD_END"], "methodName": ["testLocalRequestWithWhitelist"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "TransportReindexAction . checkRemoteWhitelist ( TransportReindexAction . buildRemoteWhitelist ( Collections . emptyList (  )  )  ,    null )  ;", "}", "METHOD_END"], "methodName": ["testLocalRequestWithoutWhitelist"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "List < String >    whitelist    =    randomWhitelist (  )  ;", "whitelist . add (  \"  1  2  7  .  0  .  0  .  1  :  *  \"  )  ;", "TransportReindexAction . check ( TransportReindexAction . build ( whitelist )  ,    newRemoteInfo (  \"  1  2  7  .  0  .  0  .  1  \"  ,     9  2  0  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testLoopbackInWhitelistRemote"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "assertMatchesTooMuch ( Collections . singletonList (  \"  *  \"  )  )  ;", "assertMatchesTooMuch ( Collections . singletonList (  \"  *  *  \"  )  )  ;", "assertMatchesTooMuch ( Collections . singletonList (  \"  *  *  *  \"  )  )  ;", "assertMatchesTooMuch ( Arrays . asList (  \" realstuff \"  ,     \"  *  \"  )  )  ;", "assertMatchesTooMuch ( Arrays . asList (  \"  *  \"  ,     \" realstuff \"  )  )  ;", "List < String >    random    =    random (  )  ;", "random . add (  \"  *  \"  )  ;", "assertMatchesTooMuch ( random )  ;", "}", "METHOD_END"], "methodName": ["testRejectMatchAll"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "int   port    =    between (  1  ,    Integer . MAX _ VALUE )  ;", "List < String >    whitelist    =     ( randomBoolean (  )  )     ?    randomWhitelist (  )     :    Collections . emptyList (  )  ;", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    check ( build ( whitelist )  ,    newRemoteInfo (  \" not   in   list \"  ,    port )  )  )  ;", "assertEquals (  (  (  \"  [ not   in   list :  \"     +    port )     +     \"  ]    not   whitelisted   in   reindex . remote . whitelist \"  )  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnwhitelistedRemote"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "TransportReindexAction . checkRemoteWhitelist ( TransportReindexAction . buildRemoteWhitelist ( Collections . singletonList (  \" es *  . example . com :  9  2  0  0  \"  )  )  ,    newRemoteInfo (  \" es 1  . example . com \"  ,     9  2  0  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testWhitelistedByInfix"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "TransportReindexAction . checkRemoteWhitelist ( TransportReindexAction . buildRemoteWhitelist ( Collections . singletonList (  \"  *  . example . com :  9  2  0  0  \"  )  )  ,    new   RemoteInfo ( randomAlphaOfLength (  5  )  ,     \" es . example . com \"  ,     9  2  0  0  ,    new   BytesArray (  \" test \"  )  ,    null ,    null ,    Collections . emptyMap (  )  ,    RemoteInfo . DEFAULT _ SOCKET _ TIMEOUT ,    RemoteInfo . DEFAULT _ CONNECT _ TIMEOUT )  )  ;", "TransportReindexAction . checkRemoteWhitelist ( TransportReindexAction . buildRemoteWhitelist ( Collections . singletonList (  \"  *  . example . com :  9  2  0  0  \"  )  )  ,    newRemoteInfo (  \"  6 e 1  3  4  1  3  4 a 1  . us - east -  1  . aws . example . com \"  ,     9  2  0  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testWhitelistedByPrefix"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "TransportReindexAction . checkRemoteWhitelist ( TransportReindexAction . buildRemoteWhitelist ( Collections . singletonList (  \" es . example . com :  *  \"  )  )  ,    newRemoteInfo (  \" es . example . com \"  ,     9  2  0  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testWhitelistedBySuffix"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "List < String >    whitelist    =    randomWhitelist (  )  ;", "String [  ]    inList    =    whitelist . iterator (  )  . next (  )  . split (  \"  :  \"  )  ;", "String   host    =    inList [  0  ]  ;", "int   port    =    Integer . valueOf ( inList [  1  ]  )  ;", "TransportReindexAction . check ( TransportReindexAction . build ( whitelist )  ,    newRemoteInfo ( host ,    port )  )  ;", "}", "METHOD_END"], "methodName": ["testWhitelistedRemote"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWhitelistTests"}, {"methodBody": ["METHOD_START", "{", "NodeInfo   nodeInfo    =    client (  )  . admin (  )  . cluster (  )  . prepareNodesInfo (  )  . get (  )  . getNodes (  )  . get (  0  )  ;", "address    =    nodeInfo . getHttp (  )  . getAddress (  )  . publishAddress (  )  ;", "}", "METHOD_END"], "methodName": ["fetchTransportAddress"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWithAuthTests"}, {"methodBody": ["METHOD_START", "{", "return   new   RemoteInfo (  \" http \"  ,    address . getAddress (  )  ,    address . getPort (  )  ,    new   BytesArray (  \"  {  \\  \" match _ all \\  \"  :  {  }  }  \"  )  ,    username ,    password ,    headers ,    RemoteInfo . DEFAULT _ SOCKET _ TIMEOUT ,    RemoteInfo . DEFAULT _ CONNECT _ TIMEOUT )  ;", "}", "METHOD_END"], "methodName": ["newRemoteInfo"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWithAuthTests"}, {"methodBody": ["METHOD_START", "{", "client (  )  . prepareIndex (  \" source \"  ,     \" test \"  )  . setSource (  \" test \"  ,     \" test \"  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["setupSourceIndex"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWithAuthTests"}, {"methodBody": ["METHOD_START", "{", "ReindexRequestBuilder   request    =    INSTANCE . newRequestBuilder ( client (  )  )  . source (  \" source \"  )  . destination (  \" dest \"  )  . setRemoteInfo ( newRemoteInfo (  \" Aladdin \"  ,     \" open   sesame \"  ,    Collections . emptyMap (  )  )  )  ;", "assertThat ( request . get (  )  ,    ReindexTestCase . matcher (  )  . created (  1  )  )  ;", "}", "METHOD_END"], "methodName": ["testReindexFromRemoteWithAuthentication"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWithAuthTests"}, {"methodBody": ["METHOD_START", "{", "ReindexRequestBuilder   request    =    INSTANCE . newRequestBuilder ( client (  )  )  . source (  \" source \"  )  . destination (  \" dest \"  )  . setRemoteInfo ( newRemoteInfo ( null ,    null ,    Collections . singletonMap ( ReindexFromRemoteWithAuthTests . TestFilter . EXAMPLE _ HEADER ,     \" doesn ' t   matter \"  )  )  )  ;", "ElasticsearchStatusException   e    =    expectThrows ( ElasticsearchStatusException . class ,     (  )     -  >    request . get (  )  )  ;", "assertEquals ( BAD _ REQUEST ,    e . status (  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" Hurray !    Sent   the   header !  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReindexSendsHeaders"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWithAuthTests"}, {"methodBody": ["METHOD_START", "{", "ReindexRequestBuilder   request    =    INSTANCE . newRequestBuilder ( client (  )  )  . source (  \" source \"  )  . destination (  \" dest \"  )  . setRemoteInfo ( newRemoteInfo (  \" junk \"  ,     \" auth \"  ,    Collections . emptyMap (  )  )  )  ;", "EStatusException   e    =    expectThrows ( EStatusException . class ,     (  )     -  >    request . get (  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \"  \\  \" reason \\  \"  :  \\  \" Bad   Authorization \\  \"  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReindexWithBadAuthentication"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWithAuthTests"}, {"methodBody": ["METHOD_START", "{", "ReindexRequestBuilder   request    =    INSTANCE . newRequestBuilder ( client (  )  )  . source (  \" source \"  )  . destination (  \" dest \"  )  . setRemoteInfo ( newRemoteInfo ( null ,    null ,    Collections . emptyMap (  )  )  )  ;", "EStatusException   e    =    expectThrows ( EStatusException . class ,     (  )     -  >    request . get (  )  )  ;", "assertEquals ( UNAUTHORIZED ,    e . status (  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \"  \\  \" reason \\  \"  :  \\  \" Authentication   required \\  \"  \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \"  \\  \" WWW - Authenticate \\  \"  :  \\  \" Basic   realm = auth - realm \\  \"  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReindexWithoutAuthenticationWhenRequired"], "fileName": "org.elasticsearch.index.reindex.ReindexFromRemoteWithAuthTests"}, {"methodBody": ["METHOD_START", "{", "IndexRequest   index    =    new   IndexRequest (  )  ;", "action (  )  . copy ( AbstractAsyncBulkByScrollAction . wrap ( index )  ,    doc (  )  . setRouting (  \" foo \"  )  )  ;", "assertEquals (  \" foo \"  ,    index . routing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoutingCopiedByDefault"], "fileName": "org.elasticsearch.index.reindex.ReindexMetadataTests"}, {"methodBody": ["METHOD_START", "{", "ReindexMetadataTests . TestAction   action    =    action (  )  ;", "action . mainRequest (  )  . getDestination (  )  . routing (  \" keep \"  )  ;", "IndexRequest   index    =    new   IndexRequest (  )  ;", "action . copyMetadata ( AbstractAsyncBulkByScrollAction . wrap ( index )  ,    doc (  )  . setRouting (  \" foo \"  )  )  ;", "assertEquals (  \" foo \"  ,    index . routing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoutingCopiedIfRequested"], "fileName": "org.elasticsearch.index.reindex.ReindexMetadataTests"}, {"methodBody": ["METHOD_START", "{", "ReindexMetadataTests . TestAction   action    =    action (  )  ;", "action . mainRequest (  )  . getDestination (  )  . routing (  \" discard \"  )  ;", "IndexRequest   index    =    new   IndexRequest (  )  ;", "action . copyMetadata ( AbstractAsyncBulkByScrollAction . wrap ( index )  ,    doc (  )  . setRouting (  \" foo \"  )  )  ;", "assertEquals ( null ,    index . routing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoutingDiscardedIfRequested"], "fileName": "org.elasticsearch.index.reindex.ReindexMetadataTests"}, {"methodBody": ["METHOD_START", "{", "ReindexMetadataTests . TestAction   action    =    action (  )  ;", "action . mainRequest (  )  . getDestination (  )  . routing (  \"  = cat \"  )  ;", "IndexRequest   index    =    new   IndexRequest (  )  ;", "action . copyMetadata ( AbstractAsyncBulkByScrollAction . wrap ( index )  ,    doc (  )  . setRouting (  \" foo \"  )  )  ;", "assertEquals (  \" cat \"  ,    index . routing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoutingSetIfRequested"], "fileName": "org.elasticsearch.index.reindex.ReindexMetadataTests"}, {"methodBody": ["METHOD_START", "{", "ReindexMetadataTests . TestAction   action    =    action (  )  ;", "action . mainRequest (  )  . getDestination (  )  . routing (  \"  =  =  ]  \"  )  ;", "IndexRequest   index    =    new   IndexRequest (  )  ;", "action . copyMetadata ( AbstractAsyncBulkByScrollAction . wrap ( index )  ,    doc (  )  . setRouting (  \" foo \"  )  )  ;", "assertEquals (  \"  =  ]  \"  ,    index . routing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoutingSetIfWithDegenerateValue"], "fileName": "org.elasticsearch.index.reindex.ReindexMetadataTests"}, {"methodBody": ["METHOD_START", "{", "Object   id    =    randomFrom ( new   Object [  ]  {    null ,     2  3  4  ,     2  3  4 L ,     \" pancake \"     }  )  ;", "IndexRequest   index    =    apply (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \"  _ id \"  ,    id )  )  ;", "if    ( id    =  =    null )     {", "assertNull ( index . id (  )  )  ;", "} else    {", "assertEquals ( id . toString (  )  ,    index . id (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSetId"], "fileName": "org.elasticsearch.index.reindex.ReindexScriptTests"}, {"methodBody": ["METHOD_START", "{", "Object   dest    =    randomFrom ( new   Object [  ]  {     2  3  4  ,     2  3  4 L ,     \" pancake \"     }  )  ;", "IndexRequest   index    =    apply (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \"  _ index \"  ,    dest )  )  ;", "assertEquals ( dest . toString (  )  ,    index . index (  )  )  ;", "}", "METHOD_END"], "methodName": ["testSetIndex"], "fileName": "org.elasticsearch.index.reindex.ReindexScriptTests"}, {"methodBody": ["METHOD_START", "{", "String   routing    =    randomRealisticUnicodeOfLengthBetween (  5  ,     2  0  )  ;", "IndexRequest   index    =    applyScript (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \"  _ routing \"  ,    routing )  )  ;", "assertEquals ( routing ,    outing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testSetRouting"], "fileName": "org.elasticsearch.index.reindex.ReindexScriptTests"}, {"methodBody": ["METHOD_START", "{", "Object   type    =    randomFrom ( new   Object [  ]  {     2  3  4  ,     2  3  4 L ,     \" pancake \"     }  )  ;", "IndexRequest   index    =    apply (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \"  _ type \"  ,    type )  )  ;", "assertEquals ( type . toString (  )  ,    index . type (  )  )  ;", "}", "METHOD_END"], "methodName": ["testSetType"], "fileName": "org.elasticsearch.index.reindex.ReindexScriptTests"}, {"methodBody": ["METHOD_START", "{", "Number   version    =    randomFrom ( new   Number [  ]  {    null ,     2  3  4  ,     2  3  4 L    }  )  ;", "IndexRequest   index    =    apply (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \"  _ version \"  ,    version )  )  ;", "if    ( version    =  =    null )     {", "assertEquals ( MATCH _ ANY ,    index . version (  )  )  ;", "} else    {", "assertEquals ( version . longValue (  )  ,    index . version (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSetVersion"], "fileName": "org.elasticsearch.index.reindex.ReindexScriptTests"}, {"methodBody": ["METHOD_START", "{", "try    {", "applyScript (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \"  _ index \"  ,    null )  )  ;", "}    catch    ( NullPointerException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \" Can ' t      without   a   destination   index !  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSettingIndexToNullIsError"], "fileName": "org.elasticsearch.index.reindex.ReindexScriptTests"}, {"methodBody": ["METHOD_START", "{", "try    {", "applyScript (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \"  _ type \"  ,    null )  )  ;", "}    catch    ( NullPointerException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \" Can ' t      without   a   destination   type !  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSettingTypeToNullIsError"], "fileName": "org.elasticsearch.index.reindex.ReindexScriptTests"}, {"methodBody": ["METHOD_START", "{", "Object   junkVersion    =    randomFrom ( new   Object [  ]  {     \" junk \"  ,    Math . PI    }  )  ;", "try    {", "apply (  ( Map < String ,    Object >    ctx )     -  >    ctx . put (  \"  _ version \"  ,    junkVersion )  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \"  _ version   may   only   be   set   to   an   int   or   a   long   but   was    [  \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString ( junkVersion . toString (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSettingVersionToJunkIsAnError"], "fileName": "org.elasticsearch.index.reindex.ReindexScriptTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    expectThrows ( ActionRequestValidationException . class ,     (  )     -  >    succeeds ( target ,    sources )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" reindex   cannot   write   into   an   index   its   reading   from    [ target ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["fails"], "fileName": "org.elasticsearch.index.reindex.ReindexSourceTargetValidationTests"}, {"methodBody": ["METHOD_START", "{", "IndexMetaData . Builder   builder    =    IndexMetaData . builder ( name )  . settings ( Settings . builder (  )  . put (  \" index . version . created \"  ,    id )  . put (  \" index . number _ of _ shards \"  ,     1  )  . put (  \" index . number _ of _ replicas \"  ,     1  )  )  ;", "for    ( String   alias    :    aliases )     {", "builder . putAlias ( AliasMetaData . builder ( alias )  . build (  )  )  ;", "}", "return   builder . build (  )  ;", "}", "METHOD_END"], "methodName": ["index"], "fileName": "org.elasticsearch.index.reindex.ReindexSourceTargetValidationTests"}, {"methodBody": ["METHOD_START", "{", "succeeds ( null ,    target ,    sources )  ;", "}", "METHOD_END"], "methodName": ["succeeds"], "fileName": "org.elasticsearch.index.reindex.ReindexSourceTargetValidationTests"}, {"methodBody": ["METHOD_START", "{", "TransportReindexAction . validateAgainstAliases ( new   SearchRequest ( sources )  ,    new   IndexRequest ( target )  ,    remoteInfo ,    ReindexSourceTargetValidationTests . INDEX _ NAME _ EXPRESSION _ RESOLVER ,    ReindexSourceTargetValidationTests . AUTO _ CREATE _ INDEX ,    ReindexSourceTargetValidationTests . STATE )  ;", "}", "METHOD_END"], "methodName": ["succeeds"], "fileName": "org.elasticsearch.index.reindex.ReindexSourceTargetValidationTests"}, {"methodBody": ["METHOD_START", "{", "fails (  \" target \"  ,     \" target _ alias \"  )  ;", "fails (  \" target _ alias \"  ,     \" target \"  )  ;", "fails (  \" target \"  ,     \" foo \"  ,     \" bar \"  ,     \" target _ alias \"  ,     \" baz \"  )  ;", "fails (  \" target _ alias \"  ,     \" foo \"  ,     \" bar \"  ,     \" target _ alias \"  ,     \" baz \"  )  ;", "fails (  \" target _ alias \"  ,     \" foo \"  ,     \" bar \"  ,     \" target \"  ,     \" baz \"  )  ;", "fails (  \" target \"  ,     \" foo \"  ,     \" bar \"  ,     \" target _ alias \"  ,     \" target _ alias \"  )  ;", "fails (  \" target \"  ,     \" target _ multi \"  )  ;", "fails (  \" target \"  ,     \" foo \"  ,     \" bar \"  ,     \" target _ multi \"  ,     \" baz \"  )  ;", "succeeds (  \" target \"  ,     \" source _ multi \"  )  ;", "succeeds (  \" target \"  ,     \" source \"  ,     \" source 2  \"  ,     \" source _ multi \"  )  ;", "}", "METHOD_END"], "methodName": ["testAliasesContainTarget"], "fileName": "org.elasticsearch.index.reindex.ReindexSourceTargetValidationTests"}, {"methodBody": ["METHOD_START", "{", "fails (  \" target \"  ,     \" target \"  )  ;", "fails (  \" target \"  ,     \" foo \"  ,     \" bar \"  ,     \" target \"  ,     \" baz \"  )  ;", "fails (  \" target \"  ,     \" foo \"  ,     \" bar \"  ,     \" target \"  ,     \" baz \"  ,     \" target \"  )  ;", "succeeds (  \" target \"  ,     \" source \"  )  ;", "succeeds (  \" target \"  ,     \" source \"  ,     \" source 2  \"  )  ;", "}", "METHOD_END"], "methodName": ["testObviousCases"], "fileName": "org.elasticsearch.index.reindex.ReindexSourceTargetValidationTests"}, {"methodBody": ["METHOD_START", "{", "succeeds ( new   RemoteInfo ( randomAlphaOfLength (  5  )  ,     \" test \"  ,     9  2  0  0  ,    new   BytesArray (  \" test \"  )  ,    null ,    null ,    Collections . emptyMap (  )  ,    RemoteInfo . DEFAULT _ SOCKET _ TIMEOUT ,    RemoteInfo . DEFAULT _ CONNECT _ TIMEOUT )  ,     \" does _ not _ exist \"  ,     \" target \"  )  ;", "succeeds ( new   RemoteInfo ( randomAlphaOfLength (  5  )  ,     \" test \"  ,     9  2  0  0  ,    new   BytesArray (  \" test \"  )  ,    null ,    null ,    Collections . emptyMap (  )  ,    RemoteInfo . DEFAULT _ SOCKET _ TIMEOUT ,    RemoteInfo . DEFAULT _ CONNECT _ TIMEOUT )  ,     \" target \"  ,     \" target \"  )  ;", "}", "METHOD_END"], "methodName": ["testRemoteInfoSkipsValidation"], "fileName": "org.elasticsearch.index.reindex.ReindexSourceTargetValidationTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    succeeds (  \" target _ multi \"  ,     \" foo \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" Alias    [ target _ multi ]    has   more   than   one   indices   associated   with   it    [  [  \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" target \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" target 2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testTargetIsAlias"], "fileName": "org.elasticsearch.index.reindex.ReindexSourceTargetValidationTests"}, {"methodBody": ["METHOD_START", "{", "return   INSTANCE . newRequestBuilder ( client (  )  )  ;", "}", "METHOD_END"], "methodName": ["deleteByQuery"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "return   expectedSliceStatuses ( slicesConfigured ,    Collections . singleton ( index )  )  ;", "}", "METHOD_END"], "methodName": ["expectedSliceStatuses"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "int   slicesConfigured    =    expectedSlices ( requestSlices ,    indices )  ;", "if    ( slicesConfigured    >     1  )     {", "return   slicesConfigured ;", "} else    {", "return    0  ;", "}", "}", "METHOD_END"], "methodName": ["expectedSliceStatuses"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "return   expectedSlices ( requestSlices ,    Collections . singleton ( index )  )  ;", "}", "METHOD_END"], "methodName": ["expectedSlices"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "if    ( requestSlices    =  =     ( AbstractBulkByScrollRequest . AUTO _ SLICES )  )     {", "int   leastNumShards    =    Collections . min ( indices . stream (  )  . map (  (    sourceI )     -  >    getNumShards ( sourceI )  . numPrimaries )  . collect ( Collectors . toList (  )  )  )  ;", "return   Math . min ( leastNumShards ,    BulkByScrollParallelizationHelper . AUTO _ SLICE _ CEILING )  ;", "} else    {", "return   requestSlices ;", "}", "}", "METHOD_END"], "methodName": ["expectedSlices"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "return   new   BulkIndexByScrollResponseMatcher (  )  ;", "}", "METHOD_END"], "methodName": ["matcher"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "return   ReindexTestCase . randomSlices (  2  ,     1  0  )  ;", "}", "METHOD_END"], "methodName": ["randomSlices"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "if    ( randomBoolean (  )  )     {", "return   AbstractBulkByScrollRequ . AUTO _ SLICES ;", "} else    {", "return   between ( min ,    max )  ;", "}", "}", "METHOD_END"], "methodName": ["randomSlices"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "return   INSTANCE . newRequestBuilder ( client (  )  )  ;", "}", "METHOD_END"], "methodName": ["reindex"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "return   RethrottleAction . INSTANCE . newRequestBuilder ( client (  )  )  ;", "}", "METHOD_END"], "methodName": ["rethrottle"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "return   INSTANCE . newRequestBuilder ( client (  )  )  ;", "}", "METHOD_END"], "methodName": ["updateByQuery"], "fileName": "org.elasticsearch.index.reindex.ReindexTestCase"}, {"methodBody": ["METHOD_START", "{", "GetResponse   get    =    client (  )  . prepareGet (  \" dest \"  ,     \" test \"  ,     \" test \"  )  . get (  )  ;", "assertEquals ( fooValue ,    get . getSource (  )  . get (  \" foo \"  )  )  ;", "assertEquals ( version ,    get . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertDest"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "ReindexRequestBuilder    =     )  . source (  \" source \"  )  . destination (  \" dest \"  )  . abortOnVersionConflict ( false )  ;", "destination (  )  . setOpType ( CREATE )  ;", "return   get (  )  ;", "}", "METHOD_END"], "methodName": ["reindexCreate"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "ReindexRequestBuilder    =     )  . source (  \" source \"  )  . destination (  \" dest \"  )  . abortOnVersionConflict ( false )  ;", "destination (  )  . setVersionType ( VersionType . EXTERNAL )  ;", "return   get (  )  ;", "}", "METHOD_END"], "methodName": ["reindexExternal"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "ReindexRequestBuilder    =     )  . source (  \" source \"  )  . destination (  \" dest \"  )  . abortOnVersionConflict ( false )  ;", "destination (  )  . setVersionType ( VersionType . INTERNAL )  ;", "return   get (  )  ;", "}", "METHOD_END"], "methodName": ["reindexInternal"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupSourceAbsent (  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" dest \"  ,     \" test \"  ,     \" test \"  )  . setType ( Type . EXTERNAL )  . set ( version )  . setSource (  \" foo \"  ,     \" dest \"  )  )  ;", "assertEquals ( version ,    client (  )  . prepareGet (  \" dest \"  ,     \" test \"  ,     \" test \"  )  . get (  )  . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["setupDest"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupDest ( ReindexVersioningTests . NEWER _ VERSION )  ;", "}", "METHOD_END"], "methodName": ["setupDestNewer"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupDest ( ReindexVersioningTests . OLDER _ VERSION )  ;", "}", "METHOD_END"], "methodName": ["setupDestOlder"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" source \"  ,     \" test \"  ,     \" test \"  )  . setVersionType ( VersionType . EXTERNAL )  . setVersion ( ReindexVersioningTests . SOURCE _ VERSION )  . setSource (  \" foo \"  ,     \" source \"  )  )  ;", "assertEquals ( ReindexVersioningTests . SOURCE _ VERSION ,    client (  )  . prepareGet (  \" source \"  ,     \" test \"  ,     \" test \"  )  . get (  )  . getVersion (  )  )  ;", "}", "METHOD_END"], "methodName": ["setupSourceAbsent"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupSourceAbsent (  )  ;", "assertThat ( Create (  )  ,    ReindexTestCase . matcher (  )  . created (  1  )  )  ;", "assertDest (  \" source \"  ,     1  )  ;", "}", "METHOD_END"], "methodName": ["testCreateCreatesWhenAbsent"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupDestNewer (  )  ;", "assertThat ( reindexCreate (  )  ,    ReindexTestCase . matcher (  )  . versionConflicts (  1  )  )  ;", "assertDest (  \" dest \"  ,     . NEWER _ VERSION )  ;", "}", "METHOD_END"], "methodName": ["testCreateVersionConflictsOnNewer"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupDestOlder (  )  ;", "assertThat ( reindexCreate (  )  ,    ReindexTestCase . matcher (  )  . versionConflicts (  1  )  )  ;", "assertDest (  \" dest \"  ,     . OLDER _ VERSION )  ;", "}", "METHOD_END"], "methodName": ["testCreateVersionConflictsOnOlder"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupSourceAbsent (  )  ;", "assertThat ( reindexExternal (  )  ,    ReindexTestCase . matcher (  )  . created (  1  )  )  ;", "assertDest (  \" source \"  ,     . SOURCE _ VERSION )  ;", "}", "METHOD_END"], "methodName": ["testExternalVersioningCreatesWhenAbsentAndSetsVersion"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupDestOlder (  )  ;", "assertThat ( reindexExternal (  )  ,    ReindexTestCase . matcher (  )  . updated (  1  )  )  ;", "assertDest (  \" source \"  ,     . SOURCE _ VERSION )  ;", "}", "METHOD_END"], "methodName": ["testExternalVersioningUpdatesOnOlderAndSetsVersion"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupDestNewer (  )  ;", "assertThat ( reindexExternal (  )  ,    ReindexTestCase . matcher (  )  . versionConflicts (  1  )  )  ;", "assertDest (  \" dest \"  ,     . NEWER _ VERSION )  ;", "}", "METHOD_END"], "methodName": ["testExternalVersioningVersionConflictsOnNewer"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupSourceAbsent (  )  ;", "assertThat ( Internal (  )  ,    ReindexTestCase . matcher (  )  . created (  1  )  )  ;", "assertDest (  \" source \"  ,     1  )  ;", "}", "METHOD_END"], "methodName": ["testInternalVersioningCreatesWhenAbsent"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupDestNewer (  )  ;", "assertThat ( reindexInternal (  )  ,    ReindexTestCase . matcher (  )  . updated (  1  )  )  ;", "assertDest (  \" source \"  ,     (  (  . NEWER _ VERSION )     +     1  )  )  ;", "}", "METHOD_END"], "methodName": ["testInternalVersioningUpdatesOnNewer"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "setupDestOlder (  )  ;", "assertThat ( reindexInternal (  )  ,    ReindexTestCase . matcher (  )  . updated (  1  )  )  ;", "assertDest (  \" source \"  ,     (  (  . OLDER _ VERSION )     +     1  )  )  ;", "}", "METHOD_END"], "methodName": ["testInternalVersioningUpdatesOnOlder"], "fileName": "org.elasticsearch.index.reindex.ReindexVersioningTests"}, {"methodBody": ["METHOD_START", "{", "ResponseException   responseException    =    expectThrows ( ResponseException . class ,     (  )     -  >    client (  )  . performRequest (  \" POST \"  ,     \"  /  _ reindex \"  )  )  ;", "assertEquals (  4  0  0  ,    responseException . getResponse (  )  . getStatusLine (  )  . getStatusCode (  )  )  ;", "assertThat ( responseException . getMessage (  )  ,    containsString (  \" request   body   is   required \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReindexMissingBody"], "fileName": "org.elasticsearch.index.reindex.ReindexWithoutContentIT"}, {"methodBody": ["METHOD_START", "{", "RestDeleteByQueryAction   action    =    new   RestDeleteByQueryAction ( Settings . EMPTY ,    mock ( RestController . class )  )  ;", "DeleteByQueryRequest   request    =    action . buildRequest ( new   Builder ( new   NamedXContentRegistry ( Collections . emptyList (  )  )  )  . build (  )  )  ;", "assertEquals ( SIZE _ ALL _ MATCHES ,    request . getSize (  )  )  ;", "assertEquals ( DEFAULT _ SCROLL _ SIZE ,    request . getSearchRequest (  )  . source (  )  . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseEmpty"], "fileName": "org.elasticsearch.index.reindex.RestDeleteByQueryActionTests"}, {"methodBody": ["METHOD_START", "{", "@ SuppressWarnings (  \" unchecked \"  )", "Map < String ,    Object >    remote    =     (  ( Map < String ,    Object >  )     ( source . remove (  \" remote \"  )  )  )  ;", "if    ( remote    =  =    null )     {", "return   null ;", "}", "String   username    =     . extractString ( remote ,     \" username \"  )  ;", "String   password    =     . extractString ( remote ,     \" password \"  )  ;", "String   hostInRequest    =    Objects . requireNonNull (  . extractString ( remote ,     \" host \"  )  ,     \"  [ host ]    must   be   specified   to   reindex   from   a   remote   cluster \"  )  ;", "Matcher   hostMatcher    =     . HOST _ PATTERN . matcher ( hostInRequest )  ;", "if    ( false    =  =     ( hostMatcher . matches (  )  )  )     {", "throw   new   IllegalArgumentException (  (  (  \"  [ host ]    must   be   of   the   form    [ scheme ]  :  /  /  [ host ]  :  [ port ]    but   was    [  \"     +    hostInRequest )     +     \"  ]  \"  )  )  ;", "}", "String   scheme    =    hostMatcher . group (  \" scheme \"  )  ;", "String   host    =    hostMatcher . group (  \" host \"  )  ;", "int   port    =    Integer . parseInt ( hostMatcher . group (  \" port \"  )  )  ;", "Map < String ,    String >    headers    =     . extractStringStringMap ( remote ,     \" headers \"  )  ;", "TimeValue   socketTimeout    =     . extractTimeValue ( remote ,     \" socket _ timeout \"  ,    DEFAULT _ SOCKET _ TIMEOUT )  ;", "TimeValue   connectTimeout    =     . extractTimeValue ( remote ,     \" connect _ timeout \"  ,    DEFAULT _ CONNECT _ TIMEOUT )  ;", "if    ( false    =  =     ( remote . isEmpty (  )  )  )     {", "throw   new   IllegalArgumentException (  (  (  \" Unsupported   fields   in    [ remote ]  :     [  \"     +     ( Strings . collectionToCommaDelimitedString ( remote . keySet (  )  )  )  )     +     \"  ]  \"  )  )  ;", "}", "return   new   RemoteInfo ( scheme ,    host ,    port ,     . queryForRemote ( source )  ,    username ,    password ,    headers ,    socketTimeout ,    connectTimeout )  ;", "}", "METHOD_END"], "methodName": ["buildRemoteInfo"], "fileName": "org.elasticsearch.index.reindex.RestReindexAction"}, {"methodBody": ["METHOD_START", "{", "Object   value    =    source . remove ( name )  ;", "if    ( value    =  =    null )     {", "return   null ;", "}", "if    ( value   instanceof   String )     {", "return    (  ( String )     ( value )  )  ;", "}", "throw   new   IllegalArgumentExcep (  (  (  (  (  \" Expected    [  \"     +    name )     +     \"  ]    to   be   a   string   but   was    [  \"  )     +    value )     +     \"  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["extractString"], "fileName": "org.elasticsearch.index.reindex.RestReindexAction"}, {"methodBody": ["METHOD_START", "{", "Object   value    =    source . remove ( name )  ;", "if    ( value    =  =    null )     {", "return   null ;", "}", "if    ( value   instanceof   List )     {", "@ SuppressWarnings (  \" unchecked \"  )", "List < String >    list    =     (  ( List < String >  )     ( value )  )  ;", "return   list . toArray ( new   String [ list . size (  )  ]  )  ;", "} else", "if    ( value   instanceof   String )     {", "return   new   String [  ]  {     (  ( String )     ( value )  )     }  ;", "} else    {", "throw   new   IllegalArgumentExcep (  (  (  (  (  \" Expected    [  \"     +    name )     +     \"  ]    to   be   a   list   of   a   string   but   was    [  \"  )     +    value )     +     '  ]  '  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["extractStringArray"], "fileName": "org.elasticsearch.index.reindex.RestReindexAction"}, {"methodBody": ["METHOD_START", "{", "Object   value    =    source . remove ( name )  ;", "if    ( value    =  =    null )     {", "return   Colles . emptyMap (  )  ;", "}", "if    ( false    =  =     ( value   instanceof   Map )  )     {", "throw   new   IllegalArgumentException (  (  (  (  (  \" Expected    [  \"     +    name )     +     \"  ]    to   be   an   object   containing   strings   but   was    [  \"  )     +    value )     +     \"  ]  \"  )  )  ;", "}", "Map <  ?  ,     ?  >    map    =     (  ( Map <  ?  ,     ?  >  )     ( value )  )  ;", "for    ( Map . Entry <  ?  ,     ?  >    entry    :    map . entrySet (  )  )     {", "if    (  ( false    =  =     (  ( entry . getKey (  )  )    instanceof   String )  )     |  |     ( false    =  =     (  ( entry . getValue (  )  )    instanceof   String )  )  )     {", "throw   new   IllegalArgumentException (  (  (  (  (  \" Expected    [  \"     +    name )     +     \"  ]    to   be   an   object   containing   strings   but   has    [  \"  )     +    entry )     +     \"  ]  \"  )  )  ;", "}", "}", "@ SuppressWarnings (  \" unchecked \"  )", "Map < String ,    String >    safe    =     (  ( Map < String ,    String >  )     ( map )  )  ;", "return   safe ;", "}", "METHOD_END"], "methodName": ["extractStringStringMap"], "fileName": "org.elasticsearch.index.reindex.RestReindexAction"}, {"methodBody": ["METHOD_START", "{", "String   string    =    RestReindexAction . extractString ( source ,    name )  ;", "return   string    =  =    null    ?    defaultValue    :    parseTimeValue ( string ,    name )  ;", "}", "METHOD_END"], "methodName": ["extractTimeValue"], "fileName": "org.elasticsearch.index.reindex.RestReindexAction"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   builder    =    JsonXContent . contentBuilder (  )  . prettyPrint (  )  ;", "Object   query    =    source . remove (  \" query \"  )  ;", "if    ( query    =  =    null )     {", "return   BytesReference . bytes ( matchAllQuery (  )  . toXContent ( builder ,    EMPTY _ PARAMS )  )  ;", "}", "if    (  !  ( query   instanceof   Map )  )     {", "throw   new   IllegalArgumentExcep (  (  (  \" Expected    [ query ]    to   be   an   object   but   was    [  \"     +    query )     +     \"  ]  \"  )  )  ;", "}", "@ SuppressWarnings (  \" unchecked \"  )", "Map < String ,    Object >    map    =     (  ( Map < String ,    Object >  )     ( query )  )  ;", "return   BytesReference . bytes ( builder . map ( map )  )  ;", "}", "METHOD_END"], "methodName": ["queryForRemote"], "fileName": "org.elasticsearch.index.reindex.RestReindexAction"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    remote    =    new   HashMap <  >  (  )  ;", "remote . put (  \" host \"  ,    hostInRest )  ;", "Map < String ,    Object >    source    =    new   HashMap <  >  (  )  ;", "source . put (  \" remote \"  ,    remote )  ;", "return    . buildRemoteInfo ( source )  ;", "}", "METHOD_END"], "methodName": ["buildRemoteInfoHostTestCase"], "fileName": "org.elasticsearch.index.reindex.RestReindexActionTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    headers    =    new   HashMap <  >  (  )  ;", "headers . put (  \" first \"  ,     \" a \"  )  ;", "headers . put (  \" second \"  ,     \" b \"  )  ;", "headers . put (  \" third \"  ,     \"  \"  )  ;", "Map < String ,    Object >    remote    =    new   HashMap <  >  (  )  ;", "remote . put (  \" host \"  ,     \" https :  /  / example . com :  9  2  0  0  \"  )  ;", "remote . put (  \" username \"  ,     \" testuser \"  )  ;", "remote . put (  \" password \"  ,     \" testpass \"  )  ;", "remote . put (  \" headers \"  ,    headers )  ;", "remote . put (  \" socket _ timeout \"  ,     \"  9  0 s \"  )  ;", "remote . put (  \" connect _ timeout \"  ,     \"  1  0 s \"  )  ;", "Map < String ,    Object >    query    =    new   HashMap <  >  (  )  ;", "query . put (  \" a \"  ,     \" b \"  )  ;", "Map < String ,    Object >    source    =    new   HashMap <  >  (  )  ;", "source . put (  \" remote \"  ,    remote )  ;", "source . put (  \" query \"  ,    query )  ;", "RemoteInfo   remoteInfo    =     . buildRemoteInfo ( source )  ;", "assertEquals (  \" https \"  ,    remoteInfo . getScheme (  )  )  ;", "assertEquals (  \" example . com \"  ,    remoteInfo . getHost (  )  )  ;", "assertEquals (  9  2  0  0  ,    remoteInfo . getPort (  )  )  ;", "assertEquals (  \"  {  \\ n       \\  \" a \\  \"     :     \\  \" b \\  \"  \\ n }  \"  ,    remoteInfo . getQuery (  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" testuser \"  ,    remoteInfo . getUsername (  )  )  ;", "assertEquals (  \" testpass \"  ,    remoteInfo . getPassword (  )  )  ;", "assertEquals ( headers ,    remoteInfo . getHeaders (  )  )  ;", "assertEquals ( timeValueSeconds (  9  0  )  ,    remoteInfo . getSocketTimeout (  )  )  ;", "assertEquals ( timeValueSeconds (  1  0  )  ,    remoteInfo . getConnectTimeout (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildRemoteInfoFullyLoaded"], "fileName": "org.elasticsearch.index.reindex.RestReindexActionTests"}, {"methodBody": ["METHOD_START", "{", "assertNull ( RestReindexAction . buildRemoteInfo ( new   HashMap <  >  (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildRemoteInfoNoRemote"], "fileName": "org.elasticsearch.index.reindex.RestReindexActionTests"}, {"methodBody": ["METHOD_START", "{", "RemoteInfo   info    =    buildRemoteInfoHostTestCase (  \" http :  /  / example . com :  9  2  0  0  \"  )  ;", "assertEquals (  \" http \"  ,    info . getScheme (  )  )  ;", "assertEquals (  \" example . com \"  ,    info . getHost (  )  )  ;", "assertEquals (  9  2  0  0  ,    info . getPort (  )  )  ;", "assertEquals ( DEFAULT _ SOCKET _ TIMEOUT ,    info . getSocketTimeout (  )  )  ;", "assertEquals ( DEFAULT _ CONNECT _ TIMEOUT ,    info . getConnectTimeout (  )  )  ;", "info    =    buildRemoteInfoHostTestCase (  \" https :  /  / other . example . com :  9  2  0  1  \"  )  ;", "assertEquals (  \" https \"  ,    info . getScheme (  )  )  ;", "assertEquals (  \" other . example . com \"  ,    info . getHost (  )  )  ;", "assertEquals (  9  2  0  1  ,    info . getPort (  )  )  ;", "assertEquals ( DEFAULT _ SOCKET _ TIMEOUT ,    info . getSocketTimeout (  )  )  ;", "assertEquals ( DEFAULT _ CONNECT _ TIMEOUT ,    info . getConnectTimeout (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildRemoteInfoWithAllHostParts"], "fileName": "org.elasticsearch.index.reindex.RestReindexActionTests"}, {"methodBody": ["METHOD_START", "{", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    buildRemoteInfoHostTestCase (  \" example . com \"  )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    buildRemoteInfoHostTestCase (  \" example . com :  9  2  0  0  \"  )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    buildRemoteInfoHostTestCase (  \" http :  /  / example . com \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildRemoteInfoWithoutAllParts"], "fileName": "org.elasticsearch.index.reindex.RestReindexActionTests"}, {"methodBody": ["METHOD_START", "{", "RestReindexAction   action    =    new   RestReindexAction ( Settings . EMPTY ,    mock ( RestController . class )  )  ;", "FakeRestRequest . Builder   request    =    new   FakeRestRequest . Builder ( xContentRegistry (  )  )  ;", "try    ( XContentBuilder   body    =    JsonXContent . contentBuilder (  )  . prettyPrint (  )  )     {", "body . startObject (  )  ;", "{", "body . startObject (  \" source \"  )  ;", "{", "body . field (  \" index \"  ,     \" source \"  )  ;", "}", "body . endObject (  )  ;", "body . startObject (  \" dest \"  )  ;", "{", "body . field (  \" index \"  ,     \" dest \"  )  ;", "}", "body . endObject (  )  ;", "}", "body . endObject (  )  ;", "request . withContent ( BytesReference . bytes ( body )  ,    body . contentType (  )  )  ;", "}", "request . withParams ( Collections . singletonMap (  \" pipeline \"  ,     \" doesn ' t   matter \"  )  )  ;", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    action . buildRequest ( request . build (  )  )  )  ;", "assertEquals (  \"  _ reindex   doesn ' t   support    [ pipeline ]    as   a   query   parmaeter .    Specify   it   in   the    [ dest ]    object   instead .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPipelineQueryParameterIsError"], "fileName": "org.elasticsearch.index.reindex.RestReindexActionTests"}, {"methodBody": ["METHOD_START", "{", "BytesReference   request ;", "try    ( XContentBuilder   b    =    JsonXContent . contentBuilder (  )  )     {", "b . startObject (  )  ;", "{", "b . startObject (  \" source \"  )  ;", "{", "b . startObject (  \" remote \"  )  ;", "{", "b . field (  \" host \"  ,     \" http :  /  / localhost :  9  2  0  0  \"  )  ;", "}", "b . endObject (  )  ;", "b . field (  \" index \"  ,     \" source \"  )  ;", "}", "b . endObject (  )  ;", "b . startObject (  \" dest \"  )  ;", "{", "b . field (  \" index \"  ,     \" dest \"  )  ;", "}", "b . endObject (  )  ;", "}", "b . endObject (  )  ;", "request    =    BytesReference . bytes ( b )  ;", "}", "try    ( XContentParser   p    =    createParser ( jsonXContent ,    request )  )     {", "ReindexRequest   r    =    new   ReindexRequest ( new   SearchRequest (  )  ,    new   IndexRequest (  )  )  ;", ". PARSER . parse ( p ,    r ,    null )  ;", "assertEquals (  \" localhost \"  ,    r . getRemoteInfo (  )  . getHost (  )  )  ;", "assertArrayEquals ( new   String [  ]  {     \" source \"     }  ,    r . getSearchRequest (  )  . indices (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testReindexFromRemoteRequestParsing"], "fileName": "org.elasticsearch.index.reindex.RestReindexActionTests"}, {"methodBody": ["METHOD_START", "{", "{", "RestReindexAction   action    =    new   RestReindexAction ( Settings . EMPTY ,    mock ( RestController . class )  )  ;", "FakeRestRequest . Builder   requestBuilder    =    new   FakeRestRequest . Builder ( xContentRegistry (  )  )  ;", "requestBuilder . withContent ( new   BytesArray (  \"  {  }  \"  )  ,    JSON )  ;", "ReindexRequest   request    =    action . buildRequest ( requestBuilder . build (  )  )  ;", "assertEquals ( DEFAULT _ SCROLL _ TIMEOUT ,    request . getScrollTime (  )  )  ;", "}", "{", "RestReindexAction   action    =    new   RestReindexAction ( Settings . EMPTY ,    mock ( RestController . class )  )  ;", "FakeRestRequest . Builder   requestBuilder    =    new   FakeRestRequest . Builder ( xContentRegistry (  )  )  ;", "requestBuilder . withParams ( Collections . singletonMap (  \" scroll \"  ,     \"  1  0 m \"  )  )  ;", "requestBuilder . withContent ( new   BytesArray (  \"  {  }  \"  )  ,    JSON )  ;", "ReindexRequest   request    =    action . buildRequest ( requestBuilder . build (  )  )  ;", "assertEquals (  \"  1  0 m \"  ,    request . getScrollTime (  )  . toString (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSetScrollTimeout"], "fileName": "org.elasticsearch.index.reindex.RestReindexActionTests"}, {"methodBody": ["METHOD_START", "{", "assert   config    !  =    null    :     \" Script   should   not   be   null \"  ;", "if    ( config   instanceof   String )     {", "return   new   Script (  (  ( String )     ( config )  )  )  ;", "} else", "if    ( config   instanceof   Map )     {", "Map < String ,    Object >    configMap    =     (  ( Map < String ,    Object >  )     ( config )  )  ;", "String   script    =    null ;", "script . ScriptType   type    =    null ;", "String   lang    =    null ;", "Map < String ,    Object >    params    =    emptyMap (  )  ;", "for    ( Iterator < Entry < String ,    Object >  >    itr    =    configMap . entrySet (  )  . iterator (  )  ;    itr . hasNext (  )  ;  )     {", "Entry < String ,    Object >    entry    =    itr . next (  )  ;", "String   parameterName    =    entry . getKey (  )  ;", "Object   parameterValue    =    entry . getValue (  )  ;", "if    ( Script . LANG _ PARSE _ FIELD . match ( parameterName ,    LoggingDeprecationHandler . INSTANCE )  )     {", "if    (  ( parameterValue   instanceof   String )     |  |     ( parameterValue    =  =    null )  )     {", "lang    =     (  ( String )     ( parameterValue )  )  ;", "} else    {", "throw   new   ElasticsearchParseException (  (  (  \" Value   must   be   of   type   String :     [  \"     +    parameterName )     +     \"  ]  \"  )  )  ;", "}", "} else", "if    ( Script . PARAMS _ PARSE _ FIELD . match ( parameterName ,    LoggingDeprecationHandler . INSTANCE )  )     {", "if    (  ( parameterValue   instanceof   Map )     |  |     ( parameterValue    =  =    null )  )     {", "params    =     (  ( Map < String ,    Object >  )     ( parameterValue )  )  ;", "} else    {", "throw   new   ElasticsearchParseException (  (  (  \" Value   must   be   of   type   String :     [  \"     +    parameterName )     +     \"  ]  \"  )  )  ;", "}", "} else", "if    ( ScriptType . INLINE . getParseField (  )  . match ( parameterName ,    LoggingDeprecationHandler . INSTANCE )  )     {", "if    (  ( parameterValue   instanceof   String )     |  |     ( parameterValue    =  =    null )  )     {", "script    =     (  ( String )     ( parameterValue )  )  ;", "type    =    script . ScriptType . INLINE ;", "} else    {", "throw   new   ElasticsearchParseException (  (  (  \" Value   must   be   of   type   String :     [  \"     +    parameterName )     +     \"  ]  \"  )  )  ;", "}", "} else", "if    ( ScriptType . STORED . getParseField (  )  . match ( parameterName ,    LoggingDeprecationHandler . INSTANCE )  )     {", "if    (  ( parameterValue   instanceof   String )     |  |     ( parameterValue    =  =    null )  )     {", "script    =     (  ( String )     ( parameterValue )  )  ;", "type    =    script . ScriptType . STORED ;", "} else    {", "throw   new   ElasticsearchParseException (  (  (  \" Value   must   be   of   type   String :     [  \"     +    parameterName )     +     \"  ]  \"  )  )  ;", "}", "}", "}", "if    ( script    =  =    null )     {", "throw   new   ElasticsearchParseException (  \" expected   one   of    [  {  }  ]    or    [  {  }  ]    fields ,    but   found   none \"  ,    ScriptType . INLINE . getParseField (  )  . getPreferredName (  )  ,    ScriptType . STORED . getParseField (  )  . getPreferredName (  )  )  ;", "}", "assert   type    !  =    null    :     \" if   script   is   not   null ,    type   should   definitely   not   be   null \"  ;", "if    ( type    =  =     ( script . ScriptType . STORED )  )     {", "if    ( lang    !  =    null )     {", "throw   new   IllegalArgumentException (  \" lang   cannot   be   specified   for   stored   scripts \"  )  ;", "}", "return   new   Script ( type ,    null ,    script ,    null ,    params )  ;", "} else    {", "return   new   Script ( type ,     ( lang    =  =    null    ?    Script . DEFAULT _ SCRIPT _ LANG    :    lang )  ,    script ,    params )  ;", "}", "} else    {", "throw   new   IllegalArgumentException (  \" Script   value   should   be   a   String   or   a   Map \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["parseScript"], "fileName": "org.elasticsearch.index.reindex.RestUpdateByQueryAction"}, {"methodBody": ["METHOD_START", "{", "RestUpdateByQueryAction   action    =    new   RestUpdateByQueryAction ( Settings . EMPTY ,    mock ( RestController . class )  )  ;", "UpdateByQueryRequest   request    =    action . buildRequest ( new   Builder ( new   NamedXContentRegistry ( Collections . emptyList (  )  )  )  . build (  )  )  ;", "assertEquals ( SIZE _ ALL _ MATCHES ,    request . getSize (  )  )  ;", "assertEquals ( DEFAULT _ SCROLL _ SIZE ,    request . getSearchRequest (  )  . source (  )  . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseEmpty"], "fileName": "org.elasticsearch.index.reindex.RestUpdateByQueryActionTests"}, {"methodBody": ["METHOD_START", "{", "return   requestsPerSecond ;", "}", "METHOD_END"], "methodName": ["getRequestsPerSecond"], "fileName": "org.elasticsearch.index.reindex.RethrottleRequest"}, {"methodBody": ["METHOD_START", "{", "if    ( requestsPerSecond    <  =     0  )     {", "throw   new   IllegalArgumentException (  \"  [ requests _ per _ second ]    must   be   greater   than    0  .    Use   Float . POSITIVE _ INFINITY   to   disable   ing .  \"  )  ;", "}", "this . requestsPerSecond    =    requestsPerSecond ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setRequestsPerSecond"], "fileName": "org.elasticsearch.index.reindex.RethrottleRequest"}, {"methodBody": ["METHOD_START", "{", "request . setRequestsPerSecond ( requestsPerSecond )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setRequestsPerSecond"], "fileName": "org.elasticsearch.index.reindex.RethrottleRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "long   start    =    System . nanoTime (  )  ;", "do    {", "ListTasksResponse   tasks    =    client (  )  . admin (  )  . cluster (  )  . prepareListTasks (  )  . setActions ( actionName )  . setDetailed ( true )  . get (  )  ;", "tasks . rethrowFailures (  \" Finding   tasks   to   r \"  )  ;", "assertThat (  \" tasks   are   left   over   from   the   last   execution   of   this   test \"  ,    tasks . getTaskGroups (  )  ,    hasSize ( lessThan (  2  )  )  )  ;", "if    (  0     =  =     ( tasks . getTaskGroups (  )  . size (  )  )  )     {", "continue ;", "}", "TaskGroup   taskGroup    =    tasks . getTaskGroups (  )  . get (  0  )  ;", "if    ( sliceCount    !  =     1  )     {", "BulkByScrollTask . Status   status    =     (  ( BulkByScrollTask . Status )     ( taskGroup . getTaskInfo (  )  . getStatus (  )  )  )  ;", "long   finishedChildStatuses    =    status . getSliceStatuses (  )  . stream (  )  . filter (  (    n )     -  >    n    !  =    null )  . count (  )  ;", "logger . info (  \" Expected    [  {  }  ]    total   children ,     [  {  }  ]    are   running   and    [  {  }  ]    are   finished \\ n {  }  \"  ,    sliceCount ,    taskGroup . getChildTasks (  )  . size (  )  ,    finishedChildStatuses ,    status . getSliceStatuses (  )  )  ;", "if    ( sliceCount    =  =    finishedChildStatuses )     {", "fail (  (  \" all   slices   finished :  \\ n \"     +    status )  )  ;", "}", "if    ( sliceCount    !  =     (  ( taskGroup . getChildTasks (  )  . size (  )  )     +    finishedChildStatuses )  )     {", "continue ;", "}", "}", "return   taskGroup ;", "}    while    (  (  ( System . nanoTime (  )  )     -    start )     <     ( TimeUnit . SECONDS . toNanos (  1  0  )  )     )  ;", "throw   new   AssertionError (  (  \" Couldn ' t   find   tasks   to   r .    Here   are   the   running   tasks    \"     +     ( client (  )  . admin (  )  . cluster (  )  . prepareListTasks (  )  . get (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["findTaskToRethrottle"], "fileName": "org.elasticsearch.index.reindex.RethrottleTests"}, {"methodBody": ["METHOD_START", "{", "AtomicReference < ListTasksResponse >    response    =    new   AtomicReference <  >  (  )  ;", "assertBusy (  (  )     -  >     {", "try    {", "ListTasksResponse   rethrottleResponse    =    rethrottle (  )  . setTaskId ( taskTo )  . setRequestsPerSecond ( newRequestsPerSecond )  . get (  )  ;", "rethrottleResponse . rethrowFailures (  \"  \"  )  ;", "assertThat ( rethrottleResponse . getTasks (  )  ,    hasSize (  1  )  )  ;", "response . set ( rethrottleResponse )  ;", "}    catch    (    e )     {", "if    (  ( e . getCause (  )  )    instanceof   IllegalArgumentException )     {", "logger . info (  \" caught   unprepared   task ,    retrying   until   prepared \"  )  ;", "throw   new    < e > AssertionError (  (  (  \"    request   for   task    [  \"     +     ( taskTo . getId (  )  )  )     +     \"  ]    failed \"  )  )  ;", "} else    {", "throw   e ;", "}", "}", "}  )  ;", "return   response . get (  )  ;", "}", "METHOD_END"], "methodName": ["rethrottleTask"], "fileName": "org.elasticsearch.index.reindex.RethrottleTests"}, {"methodBody": ["METHOD_START", "{", "logger . info (  \" Starting   test   for    [  {  }  ]    with    [  {  }  ]    slices \"  ,    actionName ,    request . request (  )  . getSlices (  )  )  ;", "createIndex (  \" test \"  )  ;", "int   numSlices    =    expectedSlices ( request . request (  )  . getSlices (  )  ,     \" test \"  )  ;", "List < IndexRequestBuilder >    docs    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( numSlices    *     1  0  )  ;    i +  +  )     {", "docs . add ( client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,    Integer . toString ( i )  )  . setSource (  \" foo \"  ,     \" bar \"  )  )  ;", "}", "indexRandom ( true ,    docs )  ;", "request . setRequestsPerSecond (  1  .  0 E -  6 F )  ;", "request . source (  )  . setSize (  1  )  ;", "ActionFuture <  ?    extends   BulkByScrollResponse >    responseListener    =    request . execute (  )  ;", "TaskGroup   taskGroupTo    =    findTaskTo ( actionName ,    numSlices )  ;", "TaskId   taskTo    =    taskGroupTo . getTaskInfo (  )  . getTaskId (  )  ;", "if    ( numSlices    =  =     1  )     {", "assertThat ( taskGroupTo . getChildTasks (  )  ,    empty (  )  )  ;", "} else    {", "assertThat ( taskGroupTo . getChildTasks (  )  ,    hasSize ( allOf ( greaterThanOrEqualTo (  1  )  ,    lessThanOrEqualTo ( numSlices )  )  )  )  ;", "assertBusy (  (  )     -  >     {", "BulkByScrollTask . Status   parent    =     (  ( BulkByScrollTask . Status )     ( client (  )  . admin (  )  . cluster (  )  . prepareGetTask ( taskTo )  . get (  )  . getTask (  )  . getTask (  )  . getStatus (  )  )  )  ;", "long   finishedSubTasks    =    parent . getSliceStatuses (  )  . stream (  )  . filter ( Objects :  : nonNull )  . count (  )  ;", "ListTasksResponse   list    =    client (  )  . admin (  )  . cluster (  )  . prepareListTasks (  )  . setParentTaskId ( taskTo )  . get (  )  ;", "list . rethrowFailures (  \" subtasks \"  )  ;", "assertThat (  ( finishedSubTasks    +     ( list . getTasks (  )  . size (  )  )  )  ,    greaterThanOrEqualTo (  (  ( long )     ( numSlices )  )  )  )  ;", "assertThat ( list . getTasks (  )  . size (  )  ,    greaterThan (  0  )  )  ;", "}  )  ;", "}", "float   newRequestsPerSecond    =     ( randomBoolean (  )  )     ?    Float . POSITIVE _ INFINITY    :     ( between (  1  ,     1  0  0  0  )  )     *     1  0  0  0  0  0  ;", "ListTasksResponse   rethrottleResponse    =    rethrottleTask ( taskTo ,    newRequestsPerSecond )  ;", "BulkByScrollTask . Status   status    =     (  ( BulkByScrollTask . Status )     ( rethrottleResponse . getTasks (  )  . get (  0  )  . getStatus (  )  )  )  ;", "if    ( numSlices    =  =     1  )     {", "assertEquals ( newRequestsPerSecond ,    status . getRequestsPerSecond (  )  ,    Float . MIN _ NORMAL )  ;", "} else    {", "long   unfinished    =    status . getSliceStatuses (  )  . stream (  )  . filter ( Objects :  : nonNull )  . filter (  (    slice )     -  >     ( slice . getStatus (  )  . getTotal (  )  )     >     ( slice . getStatus (  )  . getSuccessfullyProcessed (  )  )  )  . count (  )  ;", "float   maxExpectedSliceRequestsPerSecond    =     ( newRequestsPerSecond    =  =     ( Float . POSITIVE _ INFINITY )  )     ?    Float . POSITIVE _ INFINITY    :     ( newRequestsPerSecond    /    unfinished )     *     1  .  0  1 F ;", "float   minExpectedSliceRequestsPerSecond    =     ( newRequestsPerSecond    =  =     ( Float . POSITIVE _ INFINITY )  )     ?    Float . POSITIVE _ INFINITY    :     ( newRequestsPerSecond    /    numSlices )     *     0  .  9  9 F ;", "boolean   oneSliced    =    false ;", "float   totalRequestsPerSecond    =     0  ;", "for    ( BulkByScrollTask . StatusOrException   statusOrException    :    status . getSliceStatuses (  )  )     {", "if    ( statusOrException    =  =    null )     {", "continue ;", "}", "assertNull ( statusOrException . getException (  )  )  ;", "BulkByScrollTask . Status   slice    =    statusOrException . getStatus (  )  ;", "if    (  ( slice . getTotal (  )  )     >     ( slice . getSuccessfullyProcessed (  )  )  )     {", "assertThat ( slice . getRequestsPerSecond (  )  ,    both ( greaterThanOrEqualTo ( minExpectedSliceRequestsPerSecond )  )  . and ( lessThanOrEqualTo ( maxExpectedSliceRequestsPerSecond )  )  )  ;", "}", "if    (  ( minExpectedSliceRequestsPerSecond    <  =     ( slice . getRequestsPerSecond (  )  )  )     &  &     (  ( slice . getRequestsPerSecond (  )  )     <  =    maxExpectedSliceRequestsPerSecond )  )     {", "oneSliced    =    true ;", "}", "totalRequestsPerSecond    +  =    slice . getRequestsPerSecond (  )  ;", "}", "assertTrue (  \" At   least   one   slice   must   be   rethrottled \"  ,    oneSliced )  ;", "assertEquals ( totalRequestsPerSecond ,    status . getRequestsPerSecond (  )  ,     ( totalRequestsPerSecond    *     1  .  0 E -  4 F )  )  ;", "}", "BulkByScrollResponse   response    =    responseListener . get (  )  ;", "assertThat (  \" Entire   request   completed   in   a   single   batch .    This   may   invalidate   the   test   as   throttling   is   done   between   batches .  \"  ,    response . getBatches (  )  ,    greaterThanOrEqualTo ( numSlices )  )  ;", "}", "METHOD_END"], "methodName": ["testCase"], "fileName": "org.elasticsearch.index.reindex.RethrottleTests"}, {"methodBody": ["METHOD_START", "{", "testCase ( deleteByQuery (  )  . source (  \" test \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  ,    NAME )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQuery"], "fileName": "org.elasticsearch.index.reindex.RethrottleTests"}, {"methodBody": ["METHOD_START", "{", "testCase ( deleteByQuery (  )  . source (  \" test \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  . setSlices ( ReindexTestCase . randomSlices (  )  )  ,    NAME )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQueryWithWorkers"], "fileName": "org.elasticsearch.index.reindex.RethrottleTests"}, {"methodBody": ["METHOD_START", "{", "testCase ( reindex (  )  . source (  \" test \"  )  . destination (  \" dest \"  )  ,    NAME )  ;", "}", "METHOD_END"], "methodName": ["testReindex"], "fileName": "org.elasticsearch.index.reindex.RethrottleTests"}, {"methodBody": ["METHOD_START", "{", "testCase ( reindex (  )  . source (  \" test \"  )  . destination (  \" dest \"  )  . setSlices ( ReindexTestCase . randomSlices (  )  )  ,    NAME )  ;", "}", "METHOD_END"], "methodName": ["testReindexWithWorkers"], "fileName": "org.elasticsearch.index.reindex.RethrottleTests"}, {"methodBody": ["METHOD_START", "{", "testCase ( updateByQuery (  )  . source (  \" test \"  )  ,    NAME )  ;", "}", "METHOD_END"], "methodName": ["testUpdateByQuery"], "fileName": "org.elasticsearch.index.reindex.RethrottleTests"}, {"methodBody": ["METHOD_START", "{", "testCase ( updateByQuery (  )  . source (  \" test \"  )  . setSlices ( ReindexTestCase . randomSlices (  )  )  ,    NAME )  ;", "}", "METHOD_END"], "methodName": ["testUpdateByQueryWithWorkers"], "fileName": "org.elasticsearch.index.reindex.RethrottleTests"}, {"methodBody": ["METHOD_START", "{", "ThreadPool   threadPool    =    internalCluster (  )  . getInstance ( ThreadPool . class ,    node )  ;", "CyclicBarrier   barrier    =    new   CyclicBarrier (  2  )  ;", "logger . info (  \" Blocking   the    [  {  }  ]    executor \"  ,    name )  ;", "threadPool . executor ( name )  . execute (  (  )     -  >     {", "try    {", "threadPool . executor ( name )  . execute (  (  )     -  >     {", "}  )  ;", "barrier . await (  )  ;", "logger . info (  \" Blocked   the    [  {  }  ]    executor \"  ,    name )  ;", "barrier . await (  )  ;", "logger . info (  \" Unblocking   the    [  {  }  ]    executor \"  ,    name )  ;", "}    catch    (    e )     {", "throw   new    < e > RuntimeException (  )  ;", "}", "}  )  ;", "barrier . await (  )  ;", "blockedExecutors . add ( barrier )  ;", "return   barrier ;", "}", "METHOD_END"], "methodName": ["blockExecutor"], "fileName": "org.elasticsearch.index.reindex.RetryTests"}, {"methodBody": ["METHOD_START", "{", "for    ( CyclicBarrier   barrier    :    blockedExecutors )     {", "barrierset (  )  ;", "}", "}", "METHOD_END"], "methodName": ["forceUnblockAllExecutors"], "fileName": "org.elasticsearch.index.reindex.RetryTests"}, {"methodBody": ["METHOD_START", "{", "return   Settings . builder (  )  . put ( HTTP _ ENABLED . getKey (  )  ,    true )  . put ( TransportReindexAction . REMOTE _ CLUSTER _ WHITELIST . getKey (  )  ,     \"  1  2  7  .  0  .  0  .  1  :  *  \"  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["nodeSettings"], "fileName": "org.elasticsearch.index.reindex.RetryTests"}, {"methodBody": ["METHOD_START", "{", "ListTasksResponse   response    =    client (  )  . admin (  )  . cluster (  )  . prepareListTasks (  )  . setActions ( action )  . setDetailed ( true )  . get (  )  ;", "assertThat ( response . getTasks (  )  ,    hasSize (  1  )  )  ;", "return    (  ( BulkByScrollTask . Status )     ( response . getTasks (  )  . get (  0  )  . getStatus (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["taskStatus"], "fileName": "org.elasticsearch.index.reindex.RetryTests"}, {"methodBody": ["METHOD_START", "{", "final   Settings   nodeSettings    =    Settings . builder (  )  . put (  \" thread _ pool . bulk . size \"  ,     1  )  . put (  \" thread _ pool . search . size \"  ,     1  )  . put (  \" thread _ pool . bulk . queue _ size \"  ,     1  )  . put (  \" thread _ pool . search . queue _ size \"  ,     1  )  . put (  \" node . attr . color \"  ,     \" blue \"  )  . build (  )  ;", "final   String   node    =    internalCluster (  )  . startDataOnlyNode ( nodeSettings )  ;", "final   Settings   indexSettings    =    Settings . builder (  )  . put (  \" index . number _ of _ shards \"  ,     1  )  . put (  \" index . number _ of _ replicas \"  ,     0  )  . put (  \" index . routing . allocation . include . color \"  ,     \" blue \"  )  . build (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" source \"  )  . setSettings ( indexSettings )  . execute (  )  . actionGet (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" dest \"  )  . setSettings ( indexSettings )  . execute (  )  . actionGet (  )  ;", "BulkRequestBuilder   bulk    =    client (  )  . prepareBulk (  )  ;", "for    ( int   i    =     0  ;    i    <     (  . DOC _ COUNT )  ;    i +  +  )     {", "bulk . add ( client (  )  . prepareIndex (  \" source \"  ,     \" test \"  )  . setSource (  \" foo \"  ,     (  \" bar    \"     +    i )  )  )  ;", "}", "Retry   retry    =    new   Retry ( EsRejectedExecutionException . class ,    BackoffPolicy . exponentialBackoff (  )  ,    client (  )  . threadPool (  )  )  ;", "BulkResponse   initialBulkResponse    =    retry . withBackoff ( client (  )  :  : bulk ,    bulk . request (  )  ,    client (  )  . settings (  )  )  . actionGet (  )  ;", "assertFalse ( initialBulkResponse . buildFailureMessage (  )  ,    initialBulkResponse . hasFailures (  )  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  \" source \"  )  . get (  )  ;", "logger . info (  \" Blocking   search \"  )  ;", "CyclicBarrier   initialSearchBlock    =    blockExecutor ( SEARCH ,    node )  ;", "AbstractBulkByScrollRequestBuilder <  ?  ,     ?  >    builder    =    request . apply ( internalCluster (  )  . masterClient (  )  )  ;", "builder . source (  )  . setSize (  (  (  . DOC _ COUNT )     /     ( randomIntBetween (  2  ,     1  0  )  )  )  )  ;", "logger . info (  \" Starting   request \"  )  ;", "ActionFuture < BulkByScrollResponse >    responseListener    =    builder . execute (  )  ;", "try    {", "logger . info (  \" Waiting   for   search   rejections   on   the   initial   search \"  )  ;", "assertBusy (  (  )     -  >    assertThat ( taskStatus ( action )  . getSearchRetries (  )  ,    greaterThan (  0 L )  )  )  ;", "logger . info (  \" Blocking   bulk   and   unblocking   search   so   we   start   to   get   bulk   rejections \"  )  ;", "CyclicBarrier   bulkBlock    =    blockExecutor ( BULK ,    node )  ;", "initialSearchBlock . await (  )  ;", "logger . info (  \" Waiting   for   bulk   rejections \"  )  ;", "assertBusy (  (  )     -  >    assertThat ( taskStatus ( action )  . getBulkRetries (  )  ,    greaterThan (  0 L )  )  )  ;", "long   initialSearchRejections    =    taskStatus ( action )  . getSearchRetries (  )  ;", "logger . info (  \" Blocking   search   and   unblocking   bulk   so   we   should   get   search   rejections   for   the   scroll \"  )  ;", "CyclicBarrier   scrollBlock    =    blockExecutor ( SEARCH ,    node )  ;", "bulkBlock . await (  )  ;", "logger . info (  \" Waiting   for   search   rejections   for   the   scroll \"  )  ;", "assertBusy (  (  )     -  >    assertThat ( taskStatus ( action )  . getSearchRetries (  )  ,    greaterThan ( initialSearchRejections )  )  )  ;", "logger . info (  \" Unblocking   the   scroll \"  )  ;", "scrollBlock . await (  )  ;", "logger . info (  \" Waiting   for   the   request   to   finish \"  )  ;", "BulkByScrollResponse   response    =    responseListener . get (  )  ;", "assertThat ( response ,    matcher )  ;", "assertThat ( response . getBulkRetries (  )  ,    greaterThan (  0 L )  )  ;", "assertThat ( response . getSearchRetries (  )  ,    greaterThan ( initialSearchRejections )  )  ;", "}    finally    {", "BulkByScrollResponse   response    =    responseListener . get (  )  ;", "assertThat ( response . getSearchFailures (  )  ,    empty (  )  )  ;", "assertThat ( response . getBulkFailures (  )  ,    empty (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCase"], "fileName": "org.elasticsearch.index.reindex.RetryTests"}, {"methodBody": ["METHOD_START", "{", "testCase ( NAME ,     (    client )     -  >    DeleteByQueryAction . INSTANCE . newRequestBuilder ( client )  . source (  \" source \"  )  . filter ( QueryBuilders . matchAllQuery (  )  )  ,    ReindexTestCase . matcher (  )  . deleted ( RetryTests . DOC _ COUNT )  )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQuery"], "fileName": "org.elasticsearch.index.reindex.RetryTests"}, {"methodBody": ["METHOD_START", "{", "testCase ( NAME ,     (    client )     -  >    ReindexAction . INSTANCE . newRequestBuilder ( client )  . source (  \" source \"  )  . destination (  \" dest \"  )  ,    ReindexTestCase . matcher (  )  . created ( RetryTests . DOC _ COUNT )  )  ;", "}", "METHOD_END"], "methodName": ["testReindex"], "fileName": "org.elasticsearch.index.reindex.RetryTests"}, {"methodBody": ["METHOD_START", "{", "Function < Client ,    AbstractBulkByScrollRequestBuilder <  ?  ,     ?  >  >    function    =     (    client )     -  >     {", "NodeInfo   masterNode    =    null ;", "for    ( NodeInfo   candidate    :    client . admin (  )  . cluster (  )  . prepareNodesInfo (  )  . get (  )  . getNodes (  )  )     {", "if    ( candidate . getNode (  )  . isMasterNode (  )  )     {", "masterNode    =    candidate ;", "}", "}", "assertNotNull ( masterNode )  ;", "TransportAddress   address    =    masterNode . getHttp (  )  . getAddress (  )  . publishAddress (  )  ;", "RemoteInfo   remote    =    new   RemoteInfo (  \" http \"  ,    address . getAddress (  )  ,    address . getPort (  )  ,    new   BytesArray (  \"  {  \\  \" match _ all \\  \"  :  {  }  }  \"  )  ,    null ,    null ,    Collections . emptyMap (  )  ,    RemoteInfo . DEFAULT _ SOCKET _ TIMEOUT ,    RemoteInfo . DEFAULT _ CONNECT _ TIMEOUT )  ;", "ReindexRequestBuilder   request    =    INSTANCE . newRequestBuilder ( client )  . source (  \" source \"  )  . destination (  \" dest \"  )  . setRemoteInfo ( remote )  ;", "return   request ;", "}  ;", "testCase ( NAME ,    function ,    ReindexTestCase . matcher (  )  . created (  . DOC _ COUNT )  )  ;", "}", "METHOD_END"], "methodName": ["testReindexFromRemote"], "fileName": "org.elasticsearch.index.reindex.RetryTests"}, {"methodBody": ["METHOD_START", "{", "testCase ( NAME ,     (    client )     -  >    UpdateByQueryAction . INSTANCE . newRequestBuilder ( client )  . source (  \" source \"  )  ,    ReindexTestCase . matcher (  )  . updated ( RetryTests . DOC _ COUNT )  )  ;", "}", "METHOD_END"], "methodName": ["testUpdateByQuery"], "fileName": "org.elasticsearch.index.reindex.RetryTests"}, {"methodBody": ["METHOD_START", "{", "assertRequestEquals (  (  ( AbstractBulkIndexByScrollRequest <  ?  >  )     ( request )  )  ,     (  ( AbstractBulkIndexByScrollRequest <  ?  >  )     ( tripped )  )  )  ;", "assertEquals ( request . getDestination (  )  . version (  )  ,    tripped . getDestination (  )  . version (  )  )  ;", "assertEquals ( request . getDestination (  )  (  )  ,    tripped . getDestination (  )  (  )  )  ;", "if    (  ( request . getRemoteInfo (  )  )     =  =    null )     {", "assertNull ( tripped . getRemoteInfo (  )  )  ;", "} else    {", "assertNotNull ( tripped . getRemoteInfo (  )  )  ;", "assertEquals ( request . getRemoteInfo (  )  . getScheme (  )  ,    tripped . getRemoteInfo (  )  . getScheme (  )  )  ;", "assertEquals ( request . getRemoteInfo (  )  . getHost (  )  ,    tripped . getRemoteInfo (  )  . getHost (  )  )  ;", "assertEquals ( request . getRemoteInfo (  )  . getQuery (  )  ,    tripped . getRemoteInfo (  )  . getQuery (  )  )  ;", "assertEquals ( request . getRemoteInfo (  )  . getUsername (  )  ,    tripped . getRemoteInfo (  )  . getUsername (  )  )  ;", "assertEquals ( request . getRemoteInfo (  )  . getPassword (  )  ,    tripped . getRemoteInfo (  )  . getPassword (  )  )  ;", "assertEquals ( request . getRemoteInfo (  )  . getHeaders (  )  ,    tripped . getRemoteInfo (  )  . getHeaders (  )  )  ;", "if    ( version . onOrAfter ( V _  5  _  2  _  0  )  )     {", "assertEquals ( request . getRemoteInfo (  )  . getSocketTimeout (  )  ,    tripped . getRemoteInfo (  )  . getSocketTimeout (  )  )  ;", "assertEquals ( request . getRemoteInfo (  )  . getConnectTimeout (  )  ,    tripped . getRemoteInfo (  )  . getConnectTimeout (  )  )  ;", "} else    {", "assertEquals ( DEFAULT _ SOCKET _ TIMEOUT ,    tripped . getRemoteInfo (  )  . getSocketTimeout (  )  )  ;", "assertEquals ( DEFAULT _ CONNECT _ TIMEOUT ,    tripped . getRemoteInfo (  )  . getConnectTimeout (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["assertRequestEquals"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "assertArrayEquals ( request . getSearchRequest (  )  . indices (  )  ,    tripped . getSearchRequest (  )  . indices (  )  )  ;", "assertEquals ( request . getSearchRequest (  )  . source (  )  . size (  )  ,    tripped . getSearchRequest (  )  . source (  )  . size (  )  )  ;", "assertEquals ( request . isAbortOnVersionConflict (  )  ,    tripped . isAbortOnVersionConflict (  )  )  ;", "assertEquals ( request . isRefresh (  )  ,    tripped . isRefresh (  )  )  ;", "assertEquals ( request . getTimeout (  )  ,    tripped . getTimeout (  )  )  ;", "assertEquals ( request . getWaitForActiveShards (  )  ,    tripped . getWaitForActiveShards (  )  )  ;", "assertEquals ( request . getRetryBackoffInitialTime (  )  ,    tripped . getRetryBackoffInitialTime (  )  )  ;", "assertEquals ( request . getMaxRetries (  )  ,    tripped . getMaxRetries (  )  )  ;", "assertEquals ( request . getRequestsPerSecond (  )  ,    tripped . getRequestsPerSecond (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["assertRequestEquals"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "assertRequestEquals (  (  ( AbstractBulkByScrollRequest <  ?  >  )     ( request )  )  ,     (  ( AbstractBulkByScrollRequest <  ?  >  )     ( tripped )  )  )  ;", "assertEquals ( request . getScript (  )  ,    tripped . getScript (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertRequestEquals"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "request . getSearchRequest (  )  . indices (  \" test \"  )  ;", "request . getSearchRequest (  )  . source (  )  . size ( between (  1  ,     1  0  0  0  )  )  ;", "if    ( randomBoolean (  )  )     {", "request . setSize ( between (  1  ,    Integer . MAX _ VALUE )  )  ;", "}", "request . setAbortOnVersionConflict ( random (  )  . nextBoolean (  )  )  ;", "request . setRefresh ( rarely (  )  )  ;", "request . setTimeout ( TimeValue . parseTimeValue ( randomTimeValue (  )  ,    null ,     \" test \"  )  )  ;", "request . setWaitForActiveShards ( randomIntBetween (  0  ,     1  0  )  )  ;", "request . setRequestsPerSecond ( between (  0  ,    Integer . MAX _ VALUE )  )  ;", "int   slices    =    RTestCase . randomSlices (  1  ,    Integer . MAX _ VALUE )  ;", "request . setSlices ( slices )  ;", "}", "METHOD_END"], "methodName": ["randomRequest"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "randomRequest (  (  ( AbstractBulkByScrollRequest <  ?  >  )     ( request )  )  )  ;", "request . setScript (  ( random (  )  . nextBoolean (  )     ?    null    :    randomScript (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["randomRequest"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "ScriptType   type    =    randomFrom ( ScriptType . values (  )  )  ;", "String   lang    =     ( random (  )  . nextBoolean (  )  )     ?    Script . DEFAULT _ SCRIPT _ LANG    :    randomSimpleString ( random (  )  )  ;", "String   idOrCode    =    randomSimpleString ( random (  )  )  ;", "Map < String ,    Object >    params    =    Collections . emptyMap (  )  ;", "type    =    ScriptType . STORED ;", "return   new   Script ( type ,     ( type    =  =     ( ScriptType . STORED )     ?    null    :    lang )  ,    idOrCode ,    params )  ;", "}", "METHOD_END"], "methodName": ["randomScript"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "BytesSamOutput   out    =    new   BytesSamOutput (  )  ;", "out . setVersion ( version )  ;", "example . writeTo ( out )  ;", "SamInput   in    =    out . bytes (  )  . samInput (  )  ;", "in . setVersion ( version )  ;", "emptyadFrom ( in )  ;", "}", "METHOD_END"], "methodName": ["roundTrip"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "roundTrip ( CURRENT ,    example ,    empty )  ;", "}", "METHOD_END"], "methodName": ["roundTrip"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "DeleteByQueryRequest   delete    =    new   DeleteByQueryRequest ( new   SearchRequest (  )  )  ;", "randomRequest ( delete )  ;", "DeleteByQueryRequest   tripped    =    new   DeleteByQueryRequest (  )  ;", "r ( delete ,    tripped )  ;", "assertRequestEquals ( delete ,    tripped )  ;", "delete . setSlices ( AUTO _ SLICES )  ;", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    r ( Version . V _  6  _  0  _  0  _ alpha 1  ,    delete ,    null )  )  ;", "assertEquals (  \" Slices   set   as    \\  \" auto \\  \"    are   not   supported   before   version    [  6  .  1  .  0  ]  .    Found   version    [  6  .  0  .  0  - alpha 1  ]  \"  ,    e . getMessage (  )  )  ;", "tripped    =    new   DeleteByQueryRequest (  )  ;", "delete . setSlices ( between (  1  ,    Integer . MAX _ VALUE )  )  ;", "r ( V _  6  _  0  _  0  _ alpha 1  ,    delete ,    tripped )  ;", "assertRequestEquals ( delete ,    tripped )  ;", "}", "METHOD_END"], "methodName": ["testDeleteByQueryRequest"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "ReindexRequest   reindex    =    new   ReindexRequest ( new   SearchRequest (  )  ,    new   IndexRequest (  )  )  ;", "randomRequest ( reindex )  ;", "reindex . getDestination (  )  . version ( randomFrom ( MATCH _ ANY ,    MATCH _ DELETED ,     1  2 L ,     1 L ,     1  2  3  1  2  4 L ,     1  2 L )  )  ;", "reindex . getDestination (  )  . index (  \" test \"  )  ;", "if    ( randomBoolean (  )  )     {", "int   port    =    between (  1  ,    Integer . MAX _ VALUE )  ;", "BytesReference   query    =    new   common . bytes . BytesArray ( randomAlphaOfLength (  5  )  )  ;", "String   username    =     ( randomBoolean (  )  )     ?    randomAlphaOfLength (  5  )     :    null ;", "String   password    =     (  ( username    !  =    null )     &  &     ( randomBoolean (  )  )  )     ?    randomAlphaOfLength (  5  )     :    null ;", "int   headersCount    =     ( randomBoolean (  )  )     ?     0     :    between (  1  ,     1  0  )  ;", "Map < String ,    String >    headers    =    new   HashMap <  >  ( headersCount )  ;", "while    (  ( headers . size (  )  )     <    headersCount )     {", "headers . put ( randomAlphaOfLength (  5  )  ,    randomAlphaOfLength (  5  )  )  ;", "}", "TimeValue   socketTimeout    =    parseTimeValue ( randomPositiveTimeValue (  )  ,     \" socketTimeout \"  )  ;", "TimeValue   connectTimeout    =    parseTimeValue ( randomPositiveTimeValue (  )  ,     \" connectTimeout \"  )  ;", "reindex . setRemoteInfo ( new   RemoteInfo ( randomAlphaOfLength (  5  )  ,    randomAlphaOfLength (  5  )  ,    port ,    query ,    username ,    password ,    headers ,    socketTimeout ,    connectTimeout )  )  ;", "}", "ReindexRequest   tripped    =    new   ReindexRequest (  )  ;", "roundTrip ( reindex ,    tripped )  ;", "assertRequestEquals ( reindex ,    tripped )  ;", "reindex . setSlices ( AUTO _ SLICES )  ;", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    roundTrip ( Version . V _  6  _  0  _  0  _ alpha 1  ,    reindex ,    null )  )  ;", "assertEquals (  \" Slices   set   as    \\  \" auto \\  \"    are   not   supported   before   version    [  6  .  1  .  0  ]  .    Found   version    [  6  .  0  .  0  - alpha 1  ]  \"  ,    e . getMessage (  )  )  ;", "tripped    =    new   ReindexRequest (  )  ;", "reindex . setSlices ( between (  1  ,    Integer . MAX _ VALUE )  )  ;", "roundTrip ( V _  6  _  0  _  0  _ alpha 1  ,    reindex ,    tripped )  ;", "assertRequestEquals ( V _  6  _  0  _  0  _ alpha 1  ,    reindex ,    tripped )  ;", "}", "METHOD_END"], "methodName": ["testReindexRequest"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "RethrottleRequest   request    =    new   RethrottleRequest (  )  ;", "request . setRequestsPerSecond (  (  ( float )     ( randomDoubleBetween (  0  ,    Float . POSITIVE _ INFINITY ,    false )  )  )  )  ;", "if    ( randomBoolean (  )  )     {", "request . setActions ( randomFrom ( NAME ,    ReindexAction . NAME )  )  ;", "} else    {", "request . setTaskId ( new   tasks . TaskId ( randomAlphaOfLength (  5  )  ,    randomLong (  )  )  )  ;", "}", "RethrottleRequest   tripped    =    new   RethrottleRequest (  )  ;", "roundTrip ( request ,    tripped )  ;", "assertEquals ( request . getRequestsPerSecond (  )  ,    tripped . getRequestsPerSecond (  )  ,     1  .  0 E -  5  )  ;", "assertArrayEquals ( request . getActions (  )  ,    tripped . getActions (  )  )  ;", "assertEquals ( request . getTaskId (  )  ,    tripped . getTaskId (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRethrottleRequest"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "UpdateByQueryRequest   update    =    new   UpdateByQueryRequest ( new   SearchRequest (  )  )  ;", "randomRequest ( update )  ;", "if    ( randomBoolean (  )  )     {", "update . setPipeline ( randomAlphaOfLength (  5  )  )  ;", "}", "UpdateByQueryRequest   tripped    =    new   UpdateByQueryRequest (  )  ;", "r ( update ,    tripped )  ;", "assertRequestEquals ( update ,    tripped )  ;", "assertEquals ( update . getPipeline (  )  ,    tripped . getPipeline (  )  )  ;", "update . setSlices ( AUTO _ SLICES )  ;", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    r ( Version . V _  6  _  0  _  0  _ alpha 1  ,    update ,    null )  )  ;", "assertEquals (  \" Slices   set   as    \\  \" auto \\  \"    are   not   supported   before   version    [  6  .  1  .  0  ]  .    Found   version    [  6  .  0  .  0  - alpha 1  ]  \"  ,    e . getMessage (  )  )  ;", "tripped    =    new   UpdateByQueryRequest (  )  ;", "update . setSlices ( between (  1  ,    Integer . MAX _ VALUE )  )  ;", "r ( V _  6  _  0  _  0  _ alpha 1  ,    update ,    tripped )  ;", "assertRequestEquals ( update ,    tripped )  ;", "assertEquals ( update . getPipeline (  )  ,    tripped . getPipeline (  )  )  ;", "}", "METHOD_END"], "methodName": ["testUpdateByQueryRequest"], "fileName": "org.elasticsearch.index.reindex.RoundTripTests"}, {"methodBody": ["METHOD_START", "{", "if    ( whitelist . isEmpty (  )  )     {", "return   new   CharacterRunAutomaton ( Automata . makeEmpty (  )  )  ;", "}", "Automaton   automaton    =    Regex . simpleMatchToAutomaton ( whitelist . toArray ( EMPTY _ ARRAY )  )  ;", "automaton    =    MinimizationOperations . minimize ( automaton ,    DEFAULT _ MAX _ DETERMINIZED _ STATES )  ;", "if    ( Operations . isTotal ( automaton )  )     {", "throw   new   IllegalArgumentException (  (  (  (  (  \" Refusing   to   start   because   whitelist    \"     +    whitelist )     +     \"    accepts   all   addresses .     \"  )     +     \" This   would   allow   users   to   reindex - from - remote   any   URL   they   like   effectively   having   E   make   HTTP   GETs    \"  )     +     \" for   them .  \"  )  )  ;", "}", "return   new   CharacterRunAutomaton ( automaton )  ;", "}", "METHOD_END"], "methodName": ["buildRemoteWhitelist"], "fileName": "org.elasticsearch.index.reindex.TransportReindexAction"}, {"methodBody": ["METHOD_START", "{", "Header [  ]    clientHeaders    =    new   Header [ remoteInfo . getHeaders (  )  . size (  )  ]  ;", "int   i    =     0  ;", "for    ( Map . Entry < String ,    String >    header    :    remoteInfo . getHeaders (  )  . entrySet (  )  )     {", "clientHeaders [  ( i +  +  )  ]     =    new   BasicHeader ( header . getKey (  )  ,    header . getValue (  )  )  ;", "}", "return   RestClient . builder ( new   apache . http . HttpHost ( remoteInfo . getHost (  )  ,    remoteInfo . getPort (  )  ,    remoteInfo . getScheme (  )  )  )  . setDefaultHeaders ( clientHeaders )  . setRequestConfigCallback (  (    c )     -  >     {", "c . setConnectTimeout ( Math . toIntExact ( remoteInfo . getConnectTimeout (  )  . millis (  )  )  )  ;", "c . setSocketTimeout ( Math . toIntExact ( remoteInfo . getSocketTimeout (  )  . millis (  )  )  )  ;", "return   c ;", "}  )  . setHttpClientConfigCallback (  (    c )     -  >     {", "if    (  ( remoteInfo . getUsername (  )  )     !  =    null )     {", "UsernamePasswordCredentials   creds    =    new   UsernamePasswordCredentials ( remoteInfo . getUsername (  )  ,    remoteInfo . getPassword (  )  )  ;", "CredentialsProvider   credentialsProvider    =    new   BasicCredentialsProvider (  )  ;", "credentialsProvider . setCredentials ( AuthScope . ANY ,    creds )  ;", "c . setDefaultCredentialsProvider ( credentialsProvider )  ;", "}", "AtomicInteger   threads    =    new   AtomicInteger (  )  ;", "c . setThreadFactory (  (    r )     -  >     {", "String   name    =     (  (  \" es - client -  \"     +    taskId )     +     \"  -  \"  )     +     ( threads . getAndIncrement (  )  )  ;", "Thread   t    =    new   Thread ( r ,    name )  ;", "threadCollector . add ( t )  ;", "return   t ;", "}  )  ;", "c . setDefaultIOReactorConfig ( IOReactorConfig . custom (  )  . setIoThreadCount (  1  )  . build (  )  )  ;", "return   c ;", "}  )  . build (  )  ;", "}", "METHOD_END"], "methodName": ["buildRestClient"], "fileName": "org.elasticsearch.index.reindex.TransportReindexAction"}, {"methodBody": ["METHOD_START", "{", "if    ( remoteInfo    =  =    null )     {", "return ;", "}", "String   check    =     (  ( remoteInfo . getHost (  )  )     +     '  :  '  )     +     ( remoteInfo . getPort (  )  )  ;", "if    ( whitelist . run ( check )  )     {", "return ;", "}", "throw   new   IllegalArgumentException (  (  (  (  '  [  '     +    check )     +     \"  ]    not   whitelisted   in    \"  )     +     (  . REMOTE _ CLUSTER _ WHITELIST . getKey (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["checkRemoteWhitelist"], "fileName": "org.elasticsearch.index.reindex.TransportReindexAction"}, {"methodBody": ["METHOD_START", "{", "if    ( remoteInfo    !  =    null )     {", "return ;", "}", "String   target    =    destination . index (  )  ;", "if    ( false    =  =     ( autoCreateIndex . shouldAutoCreate ( target ,    clusterState )  )  )     {", "target    =    indexNameExpressionResolver . concreteIndexNames ( clusterState ,    destination )  [  0  ]  ;", "}", "for    ( String   sourceIndex    :    indexNameExpressionResolver . concreteIndexNames ( clusterState ,    source )  )     {", "if    ( sourceIndex . equals ( target )  )     {", "ActionRequestValidationException   e    =    new   ActionRequestValidationException (  )  ;", "e . addValidationError (  (  (  \"    cannot   write   into   an   index   its   reading   from    [  \"     +    target )     +     '  ]  '  )  )  ;", "throw   e ;", "}", "}", "}", "METHOD_END"], "methodName": ["validateAgainstAliases"], "fileName": "org.elasticsearch.index.reindex.TransportReindexAction"}, {"methodBody": ["METHOD_START", "{", "if    ( task . isWorker (  )  )     {", ". rethrottleChildTask ( logger ,    localNodeId ,    task ,    newRequestsPerSecond ,    listener )  ;", "return ;", "}", "if    ( task . isLeader (  )  )     {", ". rethrottleParentTask ( logger ,    localNodeId ,    client ,    task ,    newRequestsPerSecond ,    listener )  ;", "return ;", "}", "throw   new   IllegalArgumentException (  (  (  (  \" task    [  \"     +     ( task . getId (  )  )  )     +     \"  ]    has   not   yet   been   initialized   to   the   point   where   it   knows   how   to    \"  )     +     \" rethrottle   itself \"  )  )  ;", "}", "METHOD_END"], "methodName": ["rethrottle"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleAction"}, {"methodBody": ["METHOD_START", "{", "logger . debug (  \" rethrottling   local   task    [  {  }  ]    to    [  {  }  ]    requests   per   second \"  ,    task . getId (  )  ,    newRequestsPerSecond )  ;", "task . getWorkerState (  )  . r ( newRequestsPerSecond )  ;", "listener . onResponse ( task . taskInfo ( localNodeId ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["rethrottleChildTask"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleAction"}, {"methodBody": ["METHOD_START", "{", "final   LeaderBulkByScrollTaskState   leaderState    =    task . getLeaderState (  )  ;", "final   int   runningSubtasks    =    leaderState . runningSliceSubTasks (  )  ;", "if    ( runningSubtasks    >     0  )     {", "RethrottleRequest   subRequest    =    new   RethrottleRequest (  )  ;", "subRequest . setRequestsPerSecond (  ( newRequestsPerSecond    /    runningSubtasks )  )  ;", "subRequest . setParentTaskId ( new   tasks . TaskId ( localNodeId ,    task . getId (  )  )  )  ;", "logger . debug (  \" rethrottling   children   of   task    [  {  }  ]    to    [  {  }  ]    requests   per   second \"  ,    task . getId (  )  ,    subRequest . getRequestsPerSecond (  )  )  ;", "client . execute ( RethrottleAction . INSTANCE ,    subRequest ,    ActionListener . wrap (  (    r )     -  >     {", "r . rethrowFailures (  \" Rethrottle \"  )  ;", "listener . onResponse ( task . taskInfoGivenSubtaskInfo ( localNodeId ,    r . getTasks (  )  )  )  ;", "}  ,    listener :  : onFailure )  )  ;", "} else    {", "logger . debug (  \" children   of   task    [  {  }  ]    are   already   finished ,    nothing   to   rethrottle \"  ,    task . getId (  )  )  ;", "listener . onResponse ( task . taskInfo ( localNodeId ,    true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["rethrottleParentTask"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleAction"}, {"methodBody": ["METHOD_START", "{", "return   new   BulkByScrollTask . Status ( sliceId ,     1  0  ,     1  0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,    timeValueMillis (  0  )  ,     0  ,    null ,    timeValueMillis (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["believeableCompletedStatus"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "return   new   BulkByScrollTask . Status ( sliceId ,     1  0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,     0  ,    timeValueMillis (  0  )  ,     0  ,    null ,    timeValueMillis (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["believeableInProgressStatus"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "ArgumentCaptor < Exception >    failure    =    ArgumentCaptor . forClass ( Exception . class )  ;", "verify ( listener ,    atMost (  1  )  )  . onFailure ( failure . capture (  )  )  ;", "if    ( false    =  =     ( failure . getAllValues (  )  . isEmpty (  )  )  )     {", "throw   new   AssertionError ( failure . getValue (  )  )  ;", "}", "ArgumentCaptor < T >    response    =    ArgumentCaptor . forClass ( responseClass )  ;", "verify ( listener )  . onResponse ( response . capture (  )  )  ;", "return   response . getValue (  )  ;", "}", "METHOD_END"], "methodName": ["captureResponse"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "slices    =    between (  2  ,     5  0  )  ;", "task    =    new   BulkByScrollTask (  1  ,     \" test _ type \"  ,     \" test _ a \"  ,     \" test \"  ,    TaskId . EMPTY _ TASK _ ID ,    Colles . emptyMap (  )  )  ;", "task . setWorkerCount ( slices )  ;", "}", "METHOD_END"], "methodName": ["createTask"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "return    (    listener )     -  >     {", "ArgumentCaptor < Excep >    failure    =    ArgumentCaptor . forClass ( Excep . class )  ;", "verify ( listener )  . onFailure ( failure . capture (  )  )  ;", "assertThat ( failure . getValue (  )  ,    excepMatcher )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["expectException"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "return    (    listener )     -  >     {", "TaskInfo   taskInfo    =    captureResponse ( TaskInfo . cs ,    listener )  ;", "assertEquals ( sliceStatuses ,     (  ( BulkByScrollTask . Status )     ( taskInfo . getStatus (  )  )  )  . getSliceStatuses (  )  )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["expectSuccessfulRethrottleWithStatuses"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "return   new   ActionListener < T >  (  )     {", "@ Override", "public   void   onResponse ( T   response )     {", "throw   new   RuntimeException (  (  (  \" Expected   no   interactions   but   got    [  \"     +    response )     +     \"  ]  \"  )  )  ;", "}", "@ Override", "public   void   onFailure ( Exception   e )     {", "throw   new   RuntimeException (  \" Expected   no   interations   but   was   received   a   failure \"  ,    e )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["neverCalled"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "Client   client    =    mock ( Client . class )  ;", "String   localNodeId    =    randomAlphaOfLength (  5  )  ;", "float   newRequestsPerSecond    =    randomValueOtherThanMany (  (    f )     -  >    f    <  =     0  ,     (  )     -  >    randomFloat (  )  )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "ActionListener < TaskInfo >    listener    =    mock ( ActionListener . class )  ;", ". rethrottle ( logger ,    localNodeId ,    client ,    task ,    newRequestsPerSecond ,    listener )  ;", "ArgumentCaptor < RethrottleRequest >    subRequest    =    ArgumentCaptor . forClass ( RethrottleRequest . class )  ;", "@ SuppressWarnings (  {     \" unchecked \"  ,     \" rawtypes \"     }  )", "ArgumentCaptor < ActionListener < ListTasksResponse >  >    subListener    =    ArgumentCaptor . forClass (  (  ( Class )     ( ActionListener . class )  )  )  ;", "if    ( runningSlices    >     0  )     {", "verify ( client )  . execute ( eq ( RethrottleAction . INSTANCE )  ,    subRequest . capture (  )  ,    subListener . capture (  )  )  ;", "assertEquals ( new   TaskId ( localNodeId ,    task . getId (  )  )  ,    subRequest . getValue (  )  . getParentTaskId (  )  )  ;", "assertEquals (  ( newRequestsPerSecond    /    runningSlices )  ,    subRequest . getValue (  )  . getRequestsPerSecond (  )  ,     1  .  0 E -  5 F )  ;", "simulator . accept ( subListener . getValue (  )  )  ;", "}", "verifier . accept ( listener )  ;", "}", "METHOD_END"], "methodName": ["rethrottleTestCase"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    new   Exception (  )  ;", "rTestCase ( slices ,     (    listener )     -  >    listener . onFailure ( e )  ,    expectException ( theInstance ( e )  )  )  ;", "}", "METHOD_END"], "methodName": ["testRethrottleCatastrophicFailures"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "FailedNodeException   e    =    new   FailedNodeException (  \" test \"  ,     \" test \"  ,    new   Exception (  )  )  ;", "rTestCase ( slices ,     (    listener )     -  >    listener . onResponse ( new   ListTasksResponse ( emptyList (  )  ,    emptyList (  )  ,    singletonList ( e )  )  )  ,    expectException ( theInstance ( e )  )  )  ;", "}", "METHOD_END"], "methodName": ["testRethrottleNodeFailure"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "List < TaskInfo >    tasks    =    new   ArrayList <  >  (  )  ;", "List < BulkByScrollTask . StatusOrException >    sliceStatuses    =    new   ArrayList <  >  ( slices )  ;", "for    ( int   i    =     0  ;    i    <     ( slices )  ;    i +  +  )     {", "BulkByScrollTask . Status   status    =    believeableInProgressStatus ( i )  ;", "tasks . add ( new   TaskInfo ( new   TaskId (  \" test \"  ,     1  2  3  )  ,     \" test \"  ,     \" test \"  ,     \" test \"  ,    status ,     0  ,     0  ,    true ,    new   TaskId (  \" test \"  ,    task . getId (  )  )  ,    Collections . emptyMap (  )  )  )  ;", "sliceStatuses . add ( new   BulkByScrollTask . StatusOrException ( status )  )  ;", "}", "rethrottleTestCase ( slices ,     (    listener )     -  >    listener . onResponse ( new   ListTasksResponse ( tasks ,    emptyList (  )  ,    emptyList (  )  )  )  ,    expectSuccessfulWithStatuses ( sliceStatuses )  )  ;", "}", "METHOD_END"], "methodName": ["testRethrottleSuccessfulResponse"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    new   Exception (  )  ;", "TaskOperationFailure   failure    =    new   TaskOperationFailure (  \" test \"  ,     1  2  3  ,    e )  ;", "rethrottleTestCase ( slices ,     (    listener )     -  >    listener . onResponse ( new   ListTasksResponse ( emptyList (  )  ,    singletonList ( failure )  ,    emptyList (  )  )  )  ,    expectException ( hasToString ( containsString (  \"    of    [ test :  1  2  3  ]    failed \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testRethrottleTaskOperationFailure"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "List < BulkByScrollTask . StatusOrException >    sliceStatuses    =    new   ArrayList <  >  ( slices )  ;", "for    ( int   i    =     0  ;    i    <     ( slices )  ;    i +  +  )     {", "@ SuppressWarnings (  \" unchecked \"  )", "ActionListener < BulkByScrollResponse >    listener    =     ( i    <     (  ( slices )     -     1  )  )     ?    neverCalled (  )     :    mock ( ActionListener . class )  ;", "BulkByScrollTask . Status   status    =    believeableCompletedStatus ( i )  ;", "task . getLeaderState (  )  . onSliceResponse ( listener ,    i ,    new   BulkByScrollResponse ( timeValueMillis (  1  0  )  ,    status ,    Collections . emptyList (  )  ,    Collections . emptyList (  )  ,    false )  )  ;", "if    ( i    =  =     (  ( slices )     -     1  )  )     {", "captureResponse ( BulkByScrollResponse . class ,    listener )  . getStatus (  )  ;", "}", "sliceStatuses . add ( new   BulkByScrollTask . StatusOrException ( status )  )  ;", "}", "rethrottleTestCase (  0  ,     (    listener )     -  >     {", "}  ,    expectSuccessfulWithStatuses ( sliceStatuses )  )  ;", "}", "METHOD_END"], "methodName": ["testRethrottleWithAllSucceeded"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "int   succeeded    =    between (  1  ,     (  ( slices )     -     1  )  )  ;", "List < BulkByScrollTask . StatusOrException >    sliceStatuses    =    new   ArrayList <  >  ( slices )  ;", "for    ( int   i    =     0  ;    i    <    succeeded ;    i +  +  )     {", "BulkByScrollTask . Status   status    =    believeableCompletedStatus ( i )  ;", "task . getLeaderState (  )  . onSliceResponse ( neverCalled (  )  ,    i ,    new   BulkByScrollResponse ( timeValueMillis (  1  0  )  ,    status ,    Collections . emptyList (  )  ,    Collections . emptyList (  )  ,    false )  )  ;", "sliceStatuses . add ( new   BulkByScrollTask . StatusOrException ( status )  )  ;", "}", "List < TaskInfo >    tasks    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =    succeeded ;    i    <     ( slices )  ;    i +  +  )     {", "BulkByScrollTask . Status   status    =    believeableInProgressStatus ( i )  ;", "tasks . add ( new   TaskInfo ( new   TaskId (  \" test \"  ,     1  2  3  )  ,     \" test \"  ,     \" test \"  ,     \" test \"  ,    status ,     0  ,     0  ,    true ,    new   TaskId (  \" test \"  ,    task . getId (  )  )  ,    Collections . emptyMap (  )  )  )  ;", "sliceStatuses . add ( new   BulkByScrollTask . StatusOrException ( status )  )  ;", "}", "rethrottleTestCase (  (  ( slices )     -    succeeded )  ,     (    listener )     -  >    listener . onResponse ( new   ListTasksResponse ( tasks ,    emptyList (  )  ,    emptyList (  )  )  )  ,    expectSuccessfulWithStatuses ( sliceStatuses )  )  ;", "}", "METHOD_END"], "methodName": ["testRethrottleWithSomeSucceeded"], "fileName": "org.elasticsearch.index.reindex.TransportRethrottleActionTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  2  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  3  \"  )  . setSource (  \" foo \"  ,     \" b \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . setSource (  \" foo \"  ,     \" c \"  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     4  )  ;", "assertEquals (  1  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  1  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . get (  )  . getVersion (  )  )  ;", "assertThat ( updateByQuery (  )  . source (  \" test \"  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . updated (  4  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . get (  )  . getVersion (  )  )  ;", "assertThat ( updateByQuery (  )  . source (  \" test \"  )  . filter ( termQuery (  \" foo \"  ,     \" no _ match \"  )  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . updated (  0  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . get (  )  . getVersion (  )  )  ;", "assertThat ( updateByQuery (  )  . source (  \" test \"  )  . filter ( termQuery (  \" foo \"  ,     \" a \"  )  )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . updated (  2  )  )  ;", "assertEquals (  3  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  3  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  2  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  3  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . get (  )  . getVersion (  )  )  ;", "RequestBuilder   request    =    updateByQuery (  )  . source (  \" test \"  )  . size (  3  )  . refresh ( true )  ;", "request . source (  )  . addSort (  \" foo . keyword \"  ,    ASC )  ;", "assertThat ( request . get (  )  ,    ReindexTestCase . matcher (  )  . updated (  3  )  )  ;", "assertEquals (  4  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  4  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  2  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  3  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  3  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . get (  )  . getVersion (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.index.reindex.UpdateByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "int   sourceIndices    =    between (  2  ,     5  )  ;", "Map < String ,    List < IndexRequestBuilder >  >    docs    =    new   HashMap <  >  (  )  ;", "for    ( int   sourceIndex    =     0  ;    sourceIndex    <    sourceIndices ;    sourceIndex +  +  )     {", "String   indexName    =     \" test \"     +    sourceIndex ;", "docs . put ( indexName ,    new   ArrayList (  )  )  ;", "int   numDocs    =    between (  5  ,     1  5  )  ;", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "docs . get ( indexName )  . add ( client (  )  . prepareIndex ( indexName ,     \" test \"  ,    Integer . toString ( i )  )  . setSource (  \" foo \"  ,     \" a \"  )  )  ;", "}", "}", "List < IndexRequestBuilder >    allDocs    =    docs . values (  )  . stream (  )  . flatMap ( Collection :  : stream )  . collect ( Collectors . toList (  )  )  ;", "indexRandom ( true ,    allDocs )  ;", "for    ( Map . Entry < String ,    List < IndexRequestBuilder >  >    entry    :    docs . entrySet (  )  )     {", "assertHitCount ( client (  )  . prepareSearch ( entry . getKey (  )  )  . setSize (  0  )  . get (  )  ,    entry . getValue (  )  . size (  )  )  ;", "}", "int   slices    =    ReindexTestCase . randomSlices (  1  ,     1  0  )  ;", "int   expectedSlices    =    expectedSliceStatuses ( slices ,    docs . keySet (  )  )  ;", "String [  ]    sourceIndexNames    =    docs . keySet (  )  . toArray ( new   String [ docs . size (  )  ]  )  ;", "BulkByScrollResponse   response    =    u (  )  . source ( sourceIndexNames )  . refresh ( true )  . setSlices ( slices )  . get (  )  ;", "assertThat ( response ,    ReindexTestCase . matcher (  )  . updated ( allDocs . size (  )  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "for    ( Map . Entry < String ,    List < IndexRequestBuilder >  >    entry    :    docs . entrySet (  )  )     {", "String   index    =    entry . getKey (  )  ;", "List < IndexRequestBuilder >    indexDocs    =    entry . getValue (  )  ;", "int   randomDoc    =    between (  0  ,     (  ( indexDocs . size (  )  )     -     1  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet ( index ,     \" test \"  ,    Integer . toString ( randomDoc )  )  . get (  )  . getVersion (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMultipleSources"], "fileName": "org.elasticsearch.index.reindex.UpdateByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  2  \"  )  . setSource (  \" foo \"  ,     \" a \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  3  \"  )  . setSource (  \" foo \"  ,     \" b \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . setSource (  \" foo \"  ,     \" c \"  )  )  ;", "assertHitCount ( client (  )  . prepareSearch (  \" test \"  )  . setTypes (  \" test \"  )  . setSize (  0  )  . get (  )  ,     4  )  ;", "assertEquals (  1  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  1  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . get (  )  . getVersion (  )  )  ;", "int   slices    =    ReindexTestCase . randomSlices (  2  ,     1  0  )  ;", "int   expectedSlices    =    expectedSliceStatuses ( slices ,     \" test \"  )  ;", "assertThat ( u (  )  . source (  \" test \"  )  . refresh ( true )  . setSlices ( slices )  . get (  )  ,    ReindexTestCase . matcher (  )  . updated (  4  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . get (  )  . getVersion (  )  )  ;", "assertThat ( u (  )  . source (  \" test \"  )  . filter ( termQuery (  \" foo \"  ,     \" no _ match \"  )  )  . setSlices ( slices )  . refresh ( true )  . get (  )  ,    ReindexTestCase . matcher (  )  . updated (  0  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . get (  )  . getVersion (  )  )  ;", "assertThat ( u (  )  . source (  \" test \"  )  . filter ( termQuery (  \" foo \"  ,     \" a \"  )  )  . refresh ( true )  . setSlices ( slices )  . get (  )  ,    ReindexTestCase . matcher (  )  . updated (  2  )  . slices ( hasSize ( expectedSlices )  )  )  ;", "assertEquals (  3  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  1  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  3  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  2  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  3  \"  )  . get (  )  . getVersion (  )  )  ;", "assertEquals (  2  ,    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \"  4  \"  )  . get (  )  . getVersion (  )  )  ;", "}", "METHOD_END"], "methodName": ["testSlices"], "fileName": "org.elasticsearch.index.reindex.UpdateByQueryBasicTests"}, {"methodBody": ["METHOD_START", "{", "IndexRequest   index    =    new   IndexRequest (  )  ;", "action (  )  . cop ( AbstractAsyncBulkByScrollAction . wrap ( index )  ,    doc (  )  . setRouting (  \" foo \"  )  )  ;", "assertEquals (  \" foo \"  ,    index . routing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoutingIsCopied"], "fileName": "org.elasticsearch.index.reindex.UpdateByQueryMetadataTests"}, {"methodBody": ["METHOD_START", "{", "AtomicReference < String >    value    =    new   AtomicReference ( randomSimpleString ( random (  )  )  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \" test \"  )  . setSource (  \" test \"  ,    value . get (  )  )  )  ;", "AtomicReference < Exception >    failure    =    new   AtomicReference <  >  (  )  ;", "AtomicBoolean   keepUpdating    =    new   AtomicBoolean ( true )  ;", "Thread   updater    =    new   Thread (  (  )     -  >     {", "while    ( keepUpdating . get (  )  )     {", "try    {", "BulkByScrollResponse   response    =    updateByQuery (  )  . source (  \" test \"  )  . refresh ( true )  . abortOnVersionConflict ( false )  . get (  )  ;", "assertThat ( response ,    ReindexTestCase . matcher (  )  . updated ( either ( equalTo (  0 L )  )  . or ( equalTo (  1 L )  )  )  . versionConflicts ( either ( equalTo (  0 L )  )  . or ( equalTo (  1 L )  )  )  )  ;", "}    catch    ( Exception   e )     {", "failure . set ( e )  ;", "}", "}", "}  )  ;", "updater . start (  )  ;", "try    {", "for    ( int   i    =     0  ;    i    <     (  . MAX _ MUTATIONS )  ;    i +  +  )     {", "GetResponse   get    =    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \" test \"  )  . get (  )  ;", "assertEquals ( value . get (  )  ,    get . getSource (  )  . get (  \" test \"  )  )  ;", "value . set ( randomSimpleString ( random (  )  )  )  ;", "IndexRequestBuilder   index    =    client (  )  . prepareIndex (  \" test \"  ,     \" test \"  ,     \" test \"  )  . setSource (  \" test \"  ,    value . get (  )  )  . setRefreshPolicy ( IMMEDIATE )  ;", "int   attempts    =     0  ;", "while    ( true )     {", "attempts +  +  ;", "try    {", "index . setVersion ( get . getVersion (  )  )  . get (  )  ;", "break ;", "}    catch    ( VersionConflictEngineException   e )     {", "if    ( attempts    >  =     (  . MAX _ ATTEMPTS )  )     {", "throw   new   RuntimeException (  (  (  \" Failed   to   index   after    [  \"     +     (  . MAX _ ATTEMPTS )  )     +     \"  ]    attempts .    Too   many   version   conflicts !  \"  )  )  ;", "}", "logger . info (  (  \" Caught   expected   version   conflict   trying   to   perform   mutation   number    [  {  }  ]    with   version    [  {  }  ]     \"     +     \" on   attempt    [  {  }  ]  .    Retrying .  \"  )  ,    i ,    get . getVersion (  )  ,    attempts )  ;", "get    =    client (  )  . prepareGet (  \" test \"  ,     \" test \"  ,     \" test \"  )  . get (  )  ;", "}", "}", "}", "}    finally    {", "keepUpdating . set ( false )  ;", "updater . join ( TimeUnit . SECONDS . toMillis (  1  0  )  )  ;", "if    (  ( failure . get (  )  )     !  =    null )     {", "throw   new   RuntimeException ( failure . get (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testUpdateWhileReindexing"], "fileName": "org.elasticsearch.index.reindex.UpdateByQueryWhileModifyingTests"}, {"methodBody": ["METHOD_START", "{", "Object [  ]    options    =    new   Object [  ]  {     \" cat \"  ,    new   Object (  )  ,     1  2  3  ,    new   Date (  )  ,    Math . PI    }  ;", "for    ( String   ctxVar    :    new   String [  ]  {     \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,     \"  _ version \"  ,     \"  _ routing \"     }  )     {", "try    {", "apply (  ( Map < String ,    Object >    ctx )     -  >    ctx . put ( ctxVar ,    randomFrom ( options )  )  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \" Modifying    [  \"     +    ctxVar )     +     \"  ]    not   allowed \"  )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testModifyingCtxNotAllowed"], "fileName": "org.elasticsearch.index.reindex.UpdateByQueryWithScriptTests"}, {"methodBody": ["METHOD_START", "{", "return   new   RemoteInfo ( scheme ,     \" testhost \"  ,     1  2  3  4  4  ,    new   BytesArray (  \" testquery \"  )  ,    username ,    password ,    Collections . emptyMap (  )  ,    RemoteInfo . DEFAULT _ SOCKET _ TIMEOUT ,    RemoteInfo . DEFAULT _ CONNECT _ TIMEOUT )  ;", "}", "METHOD_END"], "methodName": ["newRemoteInfo"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteInfoTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" host = testhost   port =  1  2  3  4  4    query = testquery \"  ,    newRemoteInfo (  \" http \"  ,    null ,    null )  . toString (  )  )  ;", "assertEquals (  \" host = testhost   port =  1  2  3  4  4    query = testquery   username = testuser \"  ,    newRemoteInfo (  \" http \"  ,     \" testuser \"  ,    null )  . toString (  )  )  ;", "assertEquals (  \" host = testhost   port =  1  2  3  4  4    query = testquery   username = testuser   password =  <  <  >  >  \"  ,    newRemoteInfo (  \" http \"  ,     \" testuser \"  ,     \" testpass \"  )  . toString (  )  )  ;", "assertEquals (  \" scheme = https   host = testhost   port =  1  2  3  4  4    query = testquery   username = testuser   password =  <  <  >  >  \"  ,    newRemoteInfo (  \" https \"  ,     \" testuser \"  ,     \" testpass \"  )  . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testToString"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteInfoTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( indicesOrTypes    =  =    null )     |  |     (  ( indicesOrTypes . length )     =  =     0  )  )     {", "return ;", "}", "for    ( String   indexOrType    :    indicesOrTypes )     {", ". checkIndexOrType ( name ,    indexOrType )  ;", "}", "path . append ( Strings . arrayToCommaDelimitedString ( indicesOrTypes )  )  . append (  '  /  '  )  ;", "}", "METHOD_END"], "methodName": ["addIndexesOrTypes"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "if    (  ( indexOrType . indexOf (  '  ,  '  )  )     >  =     0  )     {", "throw   new   IllegalArgumentException (  (  (  ( name    +     \"    containing    [  ,  ]    not   supported   but   got    [  \"  )     +    indexOrType )     +     \"  ]  \"  )  )  ;", "}", "if    (  ( indexOrType . indexOf (  '  /  '  )  )     >  =     0  )     {", "throw   new   IllegalArgumentException (  (  (  ( name    +     \"    containing    [  /  ]    not   supported   but   got    [  \"  )     +    indexOrType )     +     \"  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkIndexOrType"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "if    ( remoteVersion . before ( Version . fromId (  2  0  0  0  0  9  9  )  )  )     {", "return   new   StringEntity ( scroll ,    ContentType . TEXT _ PLAIN )  ;", "}", "try    ( XContentBuilder   entity    =    JsonXContent . contentBuilder (  )  )     {", "return   new   StringEntity ( Strings . toString ( entity . startObject (  )  . array (  \" scroll _ id \"  ,    scroll )  . endObject (  )  )  ,    ContentType . APPLICATION _ JSON )  ;", "}    catch    ( IOException   e )     {", "throw   new   EException (  \" failed   to   build   clear   scroll   entity \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["clearScrollEntity"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "try    ( XContentBuilder   entity    =    JsonXContent . contentBuilder (  )  ; XContentParser   queryParser    =    XContentHelper . createParser ( EMPTY ,    INSTANCE ,    query )  )     {", "entity . startObject (  )  ;", "entity . field (  \" query \"  )  ;", "{", "entity . copyCurrentStructure ( queryParser )  ;", "XContentParser . Token   shouldBeEof    =    queryParser . nextToken (  )  ;", "if    ( shouldBeEof    !  =    null )     {", "throw   new   EException (  (  (  \" query   was   more   than   a   single   object .    This   first   token   after   the   object   is    [  \"     +    shouldBeEof )     +     \"  ]  \"  )  )  ;", "}", "}", "if    (  ( searchRequest . source (  )  . fetchSource (  )  )     !  =    null )     {", "entity . field (  \"  _ source \"  ,    searchRequest . source (  )  . fetchSource (  )  )  ;", "} else    {", "if    ( remoteVersion . onOrAfter ( Version . fromId (  1  0  0  0  0  9  9  )  )  )     {", "entity . field (  \"  _ source \"  ,    true )  ;", "}", "}", "entity . endObject (  )  ;", "BytesRef   bytes    =    BytesReference . bytes ( entity )  . toBytesRef (  )  ;", "return   new   ByteArrayEntity ( bytes . bytes ,    bytes . offset ,    bytes . length ,    ContentType . APPLICATION _ JSON )  ;", "}    catch    ( IOException   e )     {", "throw   new   EException (  \" unexpected   error   building   entity \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["initialSearchEntity"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    params    =    new   HashMap <  >  (  )  ;", "if    (  ( searchRequest . scroll (  )  )     !  =    null )     {", "TimeValue   keepAlive    =    searchRequest . scroll (  )  . keepAlive (  )  ;", "if    ( remoteVersion . before ( V _  5  _  0  _  0  )  )     {", "keepAlive    =    timeValueMillis (  (  ( long )     ( Math . ceil ( keepAlive . millisFrac (  )  )  )  )  )  ;", "}", "params . put (  \" scroll \"  ,    keepAlive . getStringRep (  )  )  ;", "}", "params . put (  \" size \"  ,    Integer . toString ( searchRequest . source (  )  . size (  )  )  )  ;", "if    (  (  ( searchRequest . source (  )  . version (  )  )     =  =    null )     |  |     (  ( searchRequest . source (  )  . version (  )  )     =  =    true )  )     {", "params . put (  \" version \"  ,    null )  ;", "}", "if    (  ( searchRequest . source (  )  . sorts (  )  )     !  =    null )     {", "boolean   useScan    =    false ;", "if    ( remoteVersion . before ( Version . fromId (  2  0  1  0  0  9  9  )  )  )     {", "for    ( SortBuilder <  ?  >    sort    :    searchRequest . source (  )  . sorts (  )  )     {", "if    ( sort   instanceof   FieldSortBuilder )     {", "FieldSortBuilder   f    =     (  ( FieldSortBuilder )     ( sort )  )  ;", "if    ( f . getFieldName (  )  . equals ( DOC _ FIELD _ NAME )  )     {", "useScan    =    true ;", "break ;", "}", "}", "}", "}", "if    ( useScan )     {", "params . put (  \" search _ type \"  ,     \" scan \"  )  ;", "} else    {", "StringBuilder   sorts    =    new   StringBuilder (  . sortToUri ( searchRequest . source (  )  . sorts (  )  . get (  0  )  )  )  ;", "for    ( int   i    =     1  ;    i    <     ( searchRequest . source (  )  . sorts (  )  . size (  )  )  ;    i +  +  )     {", "sorts . append (  '  ,  '  )  . append (  . sortToUri ( searchRequest . source (  )  . sorts (  )  . get ( i )  )  )  ;", "}", "params . put (  \" sort \"  ,    sorts . toString (  )  )  ;", "}", "}", "if    ( remoteVersion . before ( Version . fromId (  2  0  0  0  0  9  9  )  )  )     {", "searchRequest . source (  )  . storedField (  \"  _ parent \"  )  . storedField (  \"  _ routing \"  )  . storedField (  \"  _ ttl \"  )  ;", "if    ( remoteVersion . before ( Version . fromId (  1  0  0  0  0  9  9  )  )  )     {", "if    ( false    =  =     ( searchRequest . source (  )  . storedFields (  )  . fieldNames (  )  . contains (  \"  _ source \"  )  )  )     {", "searchRequest . source (  )  . storedField (  \"  _ source \"  )  ;", "}", "}", "}", "if    (  (  ( searchRequest . source (  )  . storedFields (  )  )     !  =    null )     &  &     ( false    =  =     ( searchRequest . source (  )  . storedFields (  )  . fieldNames (  )  . isEmpty (  )  )  )  )     {", "StringBuilder   fields    =    new   StringBuilder ( searchRequest . source (  )  . storedFields (  )  . fieldNames (  )  . get (  0  )  )  ;", "for    ( int   i    =     1  ;    i    <     ( searchRequest . source (  )  . storedFields (  )  . fieldNames (  )  . size (  )  )  ;    i +  +  )     {", "fields . append (  '  ,  '  )  . append ( searchRequest . source (  )  . storedFields (  )  . fieldNames (  )  . get ( i )  )  ;", "}", "String   storedFieldsParamName    =     ( remoteVersion . before ( V _  5  _  0  _  0  _ alpha 4  )  )     ?     \" fields \"     :     \" stored _ fields \"  ;", "params . put ( storedFieldsParamName ,    fields . toString (  )  )  ;", "}", "return   params ;", "}", "METHOD_END"], "methodName": ["initialSearchParams"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   path    =    new   StringBuilder (  \"  /  \"  )  ;", ". addIndexesOrTypes ( path ,     \" Index \"  ,    searchRequest . indices (  )  )  ;", ". addIndexesOrTypes ( path ,     \" Type \"  ,    searchRequest . types (  )  )  ;", "path . append (  \"  _ search \"  )  ;", "return   path . toString (  )  ;", "}", "METHOD_END"], "methodName": ["initialSearchPath"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "if    ( remoteVersion . before ( Version . fromId (  2  0  0  0  0  9  9  )  )  )     {", "return   new   StringEntity ( scroll ,    ContentType . TEXT _ PLAIN )  ;", "}", "try    ( XContentBuilder   entity    =    JsonXContent . contentBuilder (  )  )     {", "return   new   StringEntity ( Strings . toString ( entity . startObject (  )  . field (  \" scroll _ id \"  ,    scroll )  . endObject (  )  )  ,    ContentType . APPLICATION _ JSON )  ;", "}    catch    ( IOException   e )     {", "throw   new   EException (  \" failed   to   build   scroll   entity \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["scrollEntity"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "if    ( remoteVersion . before ( V _  5  _  0  _  0  )  )     {", "keepAlive    =    timeValueMillis (  (  ( long )     ( Math . ceil ( keepAlive . millisFrac (  )  )  )  )  )  ;", "}", "return   Collections . singletonMap (  \" scroll \"  ,    keepAlive . getStringRep (  )  )  ;", "}", "METHOD_END"], "methodName": ["scrollParams"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "return    \"  /  _ search / scroll \"  ;", "}", "METHOD_END"], "methodName": ["scrollPath"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "if    ( sort   instanceof   FieldSortBuilder )     {", "FieldSortBuilder   f    =     (  ( FieldSortBuilder )     ( sort )  )  ;", "return    (  ( f . getFieldName (  )  )     +     \"  :  \"  )     +     ( f . order (  )  )  ;", "}", "throw   new   IllegalArgumentException (  (  (  \" Unsupported   sort    [  \"     +    sort )     +     \"  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["sortToUri"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuilders"}, {"methodBody": ["METHOD_START", "{", "if    ( remoteVersion . before ( V _  5  _  0  _  0  )  )     {", "assertThat ( params . get (  \" scroll \"  )  ,    not ( either ( endsWith (  \" nanos \"  )  )  . or ( endsWith (  \" micros \"  )  )  )  )  ;", "if    (  ( requested . getStringRep (  )  . endsWith (  \" nanos \"  )  )     |  |     ( requested . getStringRep (  )  . endsWith (  \" micros \"  )  )  )     {", "long   millis    =     (  ( long )     ( Math . ceil ( requested . millisFrac (  )  )  )  )  ;", "assertEquals ( TimeValue . parseTimeValue ( params . get (  \" scroll \"  )  ,     \" scroll \"  )  ,    timeValueMillis ( millis )  )  ;", "return ;", "}", "}", "assertEquals ( requested ,    TimeValue . parseTimeValue ( params . get (  \" scroll \"  )  ,     \" scroll \"  )  )  ;", "}", "METHOD_END"], "methodName": ["assertScroll"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    initialSearchPath ( searchRequest )  )  ;", "assertEquals (  (  (  (  (  ( type    +     \"    containing    [  \"  )     +    bad )     +     \"  ]    not   supported   but   got    [  \"  )     +    failed )     +     \"  ]  \"  )  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["expectBadStartRequest"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "String   scroll    =    randomAlphaOfLength (  3  0  )  ;", "HttpEntity   entity    =     . clearScrollEntity ( scroll ,    V _  5  _  0  _  0  )  ;", "assertEquals ( APPLICATION _ JSON . toString (  )  ,    entity . getContentType (  )  . getValue (  )  )  ;", "assertThat ( Streams . copyToString ( new   InputStreamReader ( entity . getContent (  )  ,    StandardCharsets . UTF _  8  )  )  ,    containsString (  (  (  \"  \\  \"  \"     +    scroll )     +     \"  \\  \"  \"  )  )  )  ;", "entity    =     . clearScrollEntity ( scroll ,    Version . fromId (  1  0  7  0  4  9  9  )  )  ;", "assertEquals ( TEXT _ PLAIN . toString (  )  ,    entity . getContentType (  )  . getValue (  )  )  ;", "assertEquals ( scroll ,    Streams . copyToString ( new   InputStreamReader ( entity . getContent (  )  ,    StandardCharsets . UTF _  8  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testClearScrollEntity"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "Version   remoteVersion    =    Version . fromId ( between (  0  ,    id )  )  ;", "SearchRequest   searchRequest    =    new   SearchRequest (  )  ;", "searchRequest . source ( new   SearchSourceBuilder (  )  )  ;", "String   query    =     \"  {  \\  \" match _ all \\  \"  :  {  }  }  \"  ;", "HttpEntity   entity    =     . initialSearchEntity ( searchRequest ,    new   BytesArray ( query )  ,    remoteVersion )  ;", "assertEquals ( APPLICATION _ JSON . toString (  )  ,    entity . getContentType (  )  . getValue (  )  )  ;", "if    ( remoteVersion . onOrAfter ( Version . fromId (  1  0  0  0  0  9  9  )  )  )     {", "assertEquals (  (  (  \"  {  \\  \" query \\  \"  :  \"     +    query )     +     \"  ,  \\  \"  _ source \\  \"  : true }  \"  )  ,    Streams . copyToString ( new   InputStreamReader ( entity . getContent (  )  ,    StandardCharsets . UTF _  8  )  )  )  ;", "} else    {", "assertEquals (  (  (  \"  {  \\  \" query \\  \"  :  \"     +    query )     +     \"  }  \"  )  ,    Streams . copyToString ( new   InputStreamReader ( entity . getContent (  )  ,    StandardCharsets . UTF _  8  )  )  )  ;", "}", "searchRequest . source (  )  . fetchSource ( new   String [  ]  {     \" in 1  \"  ,     \" in 2  \"     }  ,    new   String [  ]  {     \" out \"     }  )  ;", "entity    =     . initialSearchEntity ( searchRequest ,    new   BytesArray ( query )  ,    remoteVersion )  ;", "assertEquals ( APPLICATION _ JSON . toString (  )  ,    entity . getContentType (  )  . getValue (  )  )  ;", "assertEquals (  (  (  \"  {  \\  \" query \\  \"  :  \"     +    query )     +     \"  ,  \\  \"  _ source \\  \"  :  {  \\  \" includes \\  \"  :  [  \\  \" in 1  \\  \"  ,  \\  \" in 2  \\  \"  ]  ,  \\  \" excludes \\  \"  :  [  \\  \" out \\  \"  ]  }  }  \"  )  ,    Streams . copyToString ( new   InputStreamReader ( entity . getContent (  )  ,    StandardCharsets . UTF _  8  )  )  )  ;", "RuntimeException   e    =    expectThrows ( RuntimeException . class ,     (  )     -  >    initialSearchEntity ( searchRequest ,    new   BytesArray (  \"  {  }  ,     \\  \" trailing \\  \"  :     {  }  \"  )  ,    remoteVersion )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    containsString (  \" Unexpected   character    (  '  ,  '     ( code    4  4  )  )  \"  )  )  ;", "e    =    expectThrows ( RuntimeException . class ,     (  )     -  >    initialSearchEntity ( searchRequest ,    new   BytesArray (  \"  {  \"  )  ,    remoteVersion )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    containsString (  \" Unexpected   end - of - input \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInitialSearchEntity"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "SearchRequest   searchRequest    =    new   SearchRequest (  )  . source ( new   SearchSourceBuilder (  )  )  ;", "Version   remoteVersion    =    Version . fromId ( between (  2  0  0  0  0  9  9  ,    id )  )  ;", "assertThat (  . initialSearchParams ( searchRequest ,    remoteVersion )  ,    not ( either ( hasKey (  \" stored _ fields \"  )  )  . or ( hasKey (  \" fields \"  )  )  )  )  ;", "searchRequest    =    new   SearchRequest (  )  . source ( new   SearchSourceBuilder (  )  )  ;", "searchRequest . source (  )  . storedField (  \"  _ source \"  )  . storedField (  \"  _ id \"  )  ;", "remoteVersion    =    Version . fromId ( between ( V _  5  _  0  _  0  _ alpha 4  _ ID ,    id )  )  ;", "assertThat (  . initialSearchParams ( searchRequest ,    remoteVersion )  ,    hasEntry (  \" stored _ fields \"  ,     \"  _ source ,  _ id \"  )  )  ;", "searchRequest    =    new   SearchRequest (  )  . source ( new   SearchSourceBuilder (  )  )  ;", "searchRequest . source (  )  . storedField (  \"  _ source \"  )  . storedField (  \"  _ id \"  )  ;", "remoteVersion    =    Version . fromId ( between (  2  0  0  0  0  9  9  ,     (  ( Version . V _  5  _  0  _  0  _ alpha 4  _ ID )     -     1  )  )  )  ;", "assertThat (  . initialSearchParams ( searchRequest ,    remoteVersion )  ,    hasEntry (  \" fields \"  ,     \"  _ source ,  _ id \"  )  )  ;", "searchRequest    =    new   SearchRequest (  )  . source ( new   SearchSourceBuilder (  )  )  ;", "searchRequest . source (  )  . storedField (  \"  _ source \"  )  . storedField (  \"  _ id \"  )  ;", "remoteVersion    =    Version . fromId ( between (  0  ,     (  2  0  0  0  0  9  9     -     1  )  )  )  ;", "assertThat (  . initialSearchParams ( searchRequest ,    remoteVersion )  ,    hasEntry (  \" fields \"  ,     \"  _ source ,  _ id ,  _ parent ,  _ routing ,  _ ttl \"  )  )  ;", "searchRequest    =    new   SearchRequest (  )  . source ( new   SearchSourceBuilder (  )  )  ;", "searchRequest . source (  )  . storedField (  \"  _ id \"  )  ;", "remoteVersion    =    Version . fromId ( between (  1  0  0  0  0  9  9  ,     (  2  0  0  0  0  9  9     -     1  )  )  )  ;", "assertThat (  . initialSearchParams ( searchRequest ,    remoteVersion )  ,    hasEntry (  \" fields \"  ,     \"  _ id ,  _ parent ,  _ routing ,  _ ttl \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInitialSearchParamsFields"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "SearchRequest   searchRequest    =    new   SearchRequest (  )  . source ( new   SearchSourceBuilder (  )  )  ;", "Version   remoteVersion    =    Version . fromId ( between (  0  ,    id )  )  ;", "TimeValue   scroll    =    null ;", "if    ( randomBoolean (  )  )     {", "scroll    =    TimeValue . parseTimeValue ( randomPositiveTimeValue (  )  ,     \" test \"  )  ;", "searchRequest . scroll ( scroll )  ;", "}", "int   size    =    between (  0  ,    Integer . MAX _ VALUE )  ;", "searchRequest . source (  )  . size ( size )  ;", "Boolean   fetchVersion    =    null ;", "if    ( randomBoolean (  )  )     {", "fetchVersion    =    randomBoolean (  )  ;", "searchRequest . source (  )  . version ( fetchVersion )  ;", "}", "Map < String ,    String >    params    =     . initialSearchParams ( searchRequest ,    remoteVersion )  ;", "if    ( scroll    =  =    null )     {", "assertThat ( params ,    not ( hasKey (  \" scroll \"  )  )  )  ;", "} else    {", "assertScroll ( remoteVersion ,    params ,    scroll )  ;", "}", "assertThat ( params ,    hasEntry (  \" size \"  ,    Integer . toString ( size )  )  )  ;", "assertThat ( params ,     (  ( fetchVersion    =  =    null )     |  |     ( fetchVersion    =  =    true )     ?    hasEntry (  \" version \"  ,    null )     :    not ( hasEntry (  \" version \"  ,    null )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testInitialSearchParamsMisc"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "SearchRequest   searchRequest    =    new   SearchRequest (  )  . source ( new   SearchSourceBuilder (  )  )  ;", "Version   remoteVersion    =    Version . fromId ( between (  2  0  1  0  0  9  9  ,    id )  )  ;", "searchRequest . source (  )  . sort (  \"  _ doc \"  )  ;", "assertThat (  . initialSearchParams ( searchRequest ,    remoteVersion )  ,    hasEntry (  \" sort \"  ,     \"  _ doc : asc \"  )  )  ;", "remoteVersion    =    Version . fromId ( between (  0  ,     (  2  0  1  0  0  9  9     -     1  )  )  )  ;", "assertThat (  . initialSearchParams ( searchRequest ,    remoteVersion )  ,    hasEntry (  \" search _ type \"  ,     \" scan \"  )  )  ;", "remoteVersion    =    Version . fromId ( between (  0  ,    id )  )  ;", "searchRequest . source (  )  . sorts (  )  . clear (  )  ;", "searchRequest . source (  )  . sort (  \" foo \"  )  ;", "assertThat (  . initialSearchParams ( searchRequest ,    remoteVersion )  ,    hasEntry (  \" sort \"  ,     \" foo : asc \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInitialSearchParamsSort"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "SearchRequest   searchRequest    =    new   SearchRequest (  )  . source ( new   SearchSourceBuilder (  )  )  ;", "assertEquals (  \"  /  _ search \"  ,     . initialSearchPath ( searchRequest )  )  ;", "searchRequest . indices (  \" a \"  )  ;", "searchRequest . types (  \" b \"  )  ;", "assertEquals (  \"  / a / b /  _ search \"  ,     . initialSearchPath ( searchRequest )  )  ;", "searchRequest . indices (  \" a \"  ,     \" b \"  )  ;", "searchRequest . types (  \" c \"  ,     \" d \"  )  ;", "assertEquals (  \"  / a , b / c , d /  _ search \"  ,     . initialSearchPath ( searchRequest )  )  ;", "searchRequest . indices (  \" cat ,  \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Index \"  ,     \"  ,  \"  ,     \" cat ,  \"  )  ;", "searchRequest . indices (  \" cat ,  \"  ,     \" dog \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Index \"  ,     \"  ,  \"  ,     \" cat ,  \"  )  ;", "searchRequest . indices (  \" dog \"  ,     \" cat ,  \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Index \"  ,     \"  ,  \"  ,     \" cat ,  \"  )  ;", "searchRequest . indices (  \" cat /  \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Index \"  ,     \"  /  \"  ,     \" cat /  \"  )  ;", "searchRequest . indices (  \" cat /  \"  ,     \" dog \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Index \"  ,     \"  /  \"  ,     \" cat /  \"  )  ;", "searchRequest . indices (  \" dog \"  ,     \" cat /  \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Index \"  ,     \"  /  \"  ,     \" cat /  \"  )  ;", "searchRequest . indices (  \" ok \"  )  ;", "searchRequest . types (  \" cat ,  \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Type \"  ,     \"  ,  \"  ,     \" cat ,  \"  )  ;", "searchRequest . types (  \" cat ,  \"  ,     \" dog \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Type \"  ,     \"  ,  \"  ,     \" cat ,  \"  )  ;", "searchRequest . types (  \" dog \"  ,     \" cat ,  \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Type \"  ,     \"  ,  \"  ,     \" cat ,  \"  )  ;", "searchRequest . types (  \" cat /  \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Type \"  ,     \"  /  \"  ,     \" cat /  \"  )  ;", "searchRequest . types (  \" cat /  \"  ,     \" dog \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Type \"  ,     \"  /  \"  ,     \" cat /  \"  )  ;", "searchRequest . types (  \" dog \"  ,     \" cat /  \"  )  ;", "expectBadStartRequest ( searchRequest ,     \" Type \"  ,     \"  /  \"  ,     \" cat /  \"  )  ;", "}", "METHOD_END"], "methodName": ["testIntialSearchPath"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "String   scroll    =    randomAlphaOfLength (  3  0  )  ;", "HttpEntity   entity    =     . scrollEntity ( scroll ,    V _  5  _  0  _  0  )  ;", "assertEquals ( APPLICATION _ JSON . toString (  )  ,    entity . getContentType (  )  . getValue (  )  )  ;", "assertThat ( Streams . copyToString ( new   InputStreamReader ( entity . getContent (  )  ,    StandardCharsets . UTF _  8  )  )  ,    containsString (  (  (  \"  \\  \"  \"     +    scroll )     +     \"  \\  \"  \"  )  )  )  ;", "entity    =     . scrollEntity ( scroll ,    Version . fromId (  1  0  7  0  4  9  9  )  )  ;", "assertEquals ( TEXT _ PLAIN . toString (  )  ,    entity . getContentType (  )  . getValue (  )  )  ;", "assertEquals ( scroll ,    Streams . copyToString ( new   InputStreamReader ( entity . getContent (  )  ,    StandardCharsets . UTF _  8  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testScrollEntity"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "Version   remoteVersion    =    Version . fromId ( between (  0  ,    id )  )  ;", "TimeValue   scroll    =    TimeValue . parseTimeValue ( randomPositiveTimeValue (  )  ,     \" test \"  )  ;", "assertScroll ( remoteVersion ,     . scrollParams ( scroll ,    remoteVersion )  ,    scroll )  ;", "}", "METHOD_END"], "methodName": ["testScrollParams"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteRequestBuildersTests"}, {"methodBody": ["METHOD_START", "{", "if    ( entity    =  =    null )     {", "return    \" No   error   body .  \"  ;", "} else    {", "return    \" body =  \"     +     ( EntityUtils . toString ( entity )  )  ;", "}", "}", "METHOD_END"], "methodName": ["bodyMessage"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSource"}, {"methodBody": ["METHOD_START", "{", "Supplier < ThreadContext . StoredContext >    contextSupplier    =    threadPool . getThreadContext (  )  . newRestorableContext ( true )  ;", "class   RetryHelper   extends   AbstractRunnable    {", "private   final   Iterator < TimeValue >    retries    =    backoffPolicy . iterator (  )  ;", "@ Override", "protected   void   doRun (  )    throws   Exception    {", "client . performRequestAsync ( method ,    uri ,    params ,    entity ,    new   ResponseListener (  )     {", "@ Override", "public   void   onSuccess ( Response   response )     {", "try    ( ThreadContext . StoredContext   ctx    =    contextSupplier . get (  )  )     {", "assert   ctx    !  =    null ;", "T   parsedResponse ;", "try    {", "HttpEntity   responseEntity    =    response . getEntity (  )  ;", "InputStream   content    =    responseEntity . getContent (  )  ;", "XContentType   xContentType    =    null ;", "if    (  ( responseEntity . getContentType (  )  )     !  =    null )     {", "final   String   mimeType    =    ContentType . parse ( responseEntity . getContentType (  )  . getValue (  )  )  . getMimeType (  )  ;", "xContentType    =    XContentType . fromMediaType ( mimeType )  ;", "}", "if    ( xContentType    =  =    null )     {", "try    {", "throw   new   ElasticsearchException (  (  \" Response   didn ' t   include   Content - Type :     \"     +     (  . bodyMessage ( response . getEntity (  )  )  )  )  )  ;", "}    catch    ( IOException   e )     {", "ElasticsearchException   ee    =    new   ElasticsearchException (  \" Error   extracting   body   from   response \"  )  ;", "ee . addSuppressed ( e )  ;", "throw   ee ;", "}", "}", "try    ( XContentParser   xContentParser    =    xContentType . xContent (  )  . createParser ( EMPTY ,    INSTANCE ,    content )  )     {", "parsedResponse    =    parser . apply ( xContentParser ,    xContentType )  ;", "}    catch    ( XContentParseException   e )     {", "throw   new   ElasticsearchException (  \" Error   parsing   the   response ,    remote   is   likely   not   an   Elasticsearch   instance \"  ,    e )  ;", "}", "}    catch    ( IOException   e )     {", "throw   new   ElasticsearchException (  \" Error   deserializing   response ,    remote   is   likely   not   an   Elasticsearch   instance \"  ,    e )  ;", "}", "listener . accept ( parsedResponse )  ;", "}", "}", "@ Override", "public   void   onFailure ( Exception   e )     {", "try    ( ThreadContext . StoredContext   ctx    =    contextSupplier . get (  )  )     {", "assert   ctx    !  =    null ;", "if    ( e   instanceof   ResponseException )     {", "ResponseException   re    =     (  ( ResponseException )     ( e )  )  ;", "if    (  ( TOO _ MANY _ REQUESTS . getStatus (  )  )     =  =     ( re . getResponse (  )  . getStatusLine (  )  . getStatusCode (  )  )  )     {", "if    ( retries . hasNext (  )  )     {", "TimeValue   delay    =    retries . next (  )  ;", "logger . trace (  (  ( Supplier <  ?  >  )     (  (  )     -  >    new   ParameterizedMessage (  \" retrying   rejected   search   after    [  {  }  ]  \"  ,    delay )  )  )  ,    e )  ;", "countSearchRetry . run (  )  ;", "threadPool . schedule ( delay ,    SAME ,    RetryHelper . this )  ;", "return ;", "}", "}", "e    =     . wrapExceptionToPreserveStatus ( re . getResponse (  )  . getStatusLine (  )  . getStatusCode (  )  ,    re . getResponse (  )  . getEntity (  )  ,    re )  ;", "} else", "if    ( e   instanceof   ContentTooLongException )     {", "e    =    new   IllegalArgumentException (  \" Remote   responded   with   a   chunk   that   was   too   large .    Use   a   smaller   batch   size .  \"  ,    e )  ;", "}", "fail . accept ( e )  ;", "}", "}", "}  )  ;", "}", "@ Override", "public   void   onFailure ( Exception   t )     {", "fail . accept ( t )  ;", "}", "}", "new   RetryHelper (  )  . run (  )  ;", "}", "METHOD_END"], "methodName": ["execute"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSource"}, {"methodBody": ["METHOD_START", "{", "execute (  \" GET \"  ,     \"  \"  ,    Collections . emptyMap (  )  ,    null ,    RemoteResponseParsers . MAIN _ ACTION _ PARSER ,    onVersion )  ;", "}", "METHOD_END"], "methodName": ["lookupRemoteVersion"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSource"}, {"methodBody": ["METHOD_START", "{", "if    (  ( Strings . hasLength ( response . getScrollId (  )  )  )     &  &     ( response . getHits (  )  . isEmpty (  )  )  )     {", "logger . debug (  \" First   response   looks   like   a   scan   response .    Jumping   right   to   the   second .    scroll =  [  {  }  ]  \"  ,    response . getScrollId (  )  )  ;", "doStartNextScroll ( response . getScrollId (  )  ,    timeValueMillis (  0  )  ,    onResponse )  ;", "} else    {", "onResponse . accept ( response )  ;", "}", "}", "METHOD_END"], "methodName": ["onStartResponse"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSource"}, {"methodBody": ["METHOD_START", "{", "RestStatus   status    =    fromCode ( statusCode )  ;", "String   messagePrefix    =     \"  \"  ;", "if    ( status    =  =    null )     {", "messagePrefix    =     (  \" Couldn ' t   extract   status    [  \"     +    statusCode )     +     \"  ]  .     \"  ;", "status    =    INTERNAL _ SERVER _ ERROR ;", "}", "try    {", "return   new   ElasticsearchStatusException (  ( messagePrefix    +     (  . bodyMessage ( entity )  )  )  ,    status ,    cause )  ;", "}    catch    ( IOException   ioe )     {", "ElasticsearchStatusException   e    =    new   ElasticsearchStatusException (  ( messagePrefix    +     \" Failed   to   extract   body .  \"  )  ,    status ,    cause )  ;", "e . addSuppressed ( ioe )  ;", "return   e ;", "}", "}", "METHOD_END"], "methodName": ["wrapExceptionToPreserveStatus"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSource"}, {"methodBody": ["METHOD_START", "{", "return   BackoffPolicy . constantBackoff ( timeValueMillis (  0  )  ,    retriesAllowed )  ;", "}", "METHOD_END"], "methodName": ["backoff"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "retries    +  =     1  ;", "}", "METHOD_END"], "methodName": ["countRetry"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "throw   new   RuntimeException (  \" failed \"  ,    t )  ;", "}", "METHOD_END"], "methodName": ["failRequest"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "HttpAsyncClientBuilder   clientBuilder    =    mock ( HttpAsyncClientBuilder . class )  ;", "when ( clientBuilder . build (  )  )  . thenReturn ( httpClient )  ;", "RestClient   restClient    =    RestClient . builder ( new   HttpHost (  \" localhost \"  ,     9  2  0  0  )  )  . setHttpClientConfigCallback (  (    httpClientBuilder )     -  >    clientBuilder )  . build (  )  ;", ". TestRemoteScrollableHitSource   hitSource    =    new    . TestRemoteScrollableHitSource ( restClient )     {", "@ Override", "void   lookupRemoteVersion ( Consumer < Version >    onVersion )     {", "if    ( mockRemoteVersion )     {", "onVersion . accept ( CURRENT )  ;", "} else    {", "super . lookupRemoteVersion ( onVersion )  ;", "}", "}", "}  ;", "if    ( mockRemoteVersion )     {", "hitSource . remoteVersion    =    Version . CURRENT ;", "}", "return   hitSource ;", "}", "METHOD_END"], "methodName": ["sourceWithMockedClient"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "URL [  ]    resources    =    new   URL [ paths . length ]  ;", "for    ( int   i    =     0  ;    i    <     ( paths . length )  ;    i +  +  )     {", "resources [ i ]     =    Thread . currentThread (  )  . getContextClassLoader (  )  . getResource (  (  \" responses /  \"     +     ( paths [ i ]  . replace (  \" fail :  \"  ,     \"  \"  )  )  )  )  ;", "if    (  ( resources [ i ]  )     =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  \" Couldn ' t   find    [  \"     +     ( paths [ i ]  )  )     +     \"  ]  \"  )  )  ;", "}", "}", "CloseableHttpAsyncClient   httpClient    =    mock ( CloseableHttpAsyncClient . class )  ;", "when ( httpClient .  < HttpResponse > execute ( any ( HttpAsyncRequestProducer . class )  ,    any ( HttpAsyncResponseConsumer . class )  ,    any ( HttpClientContext . class )  ,    any ( FutureCallback . class )  )  )  . thenAnswer ( new   Answer < Future < HttpResponse >  >  (  )     {", "int   responseCount    =     0  ;", "@ Override", "public   Future < HttpResponse >    answer ( InvocationOnMock   invocationOnMock )    throws   Throwable    {", "threadPool . getThreadContext (  )  . stashContext (  )  ;", "HttpAsyncRequestProducer   requestProducer    =     (  ( HttpAsyncRequestProducer )     ( invocationOnMock . getArguments (  )  [  0  ]  )  )  ;", "FutureCallback < HttpResponse >    futureCallback    =     (  ( FutureCallback < HttpResponse >  )     ( invocationOnMock . getArguments (  )  [  3  ]  )  )  ;", "HttpEntityEnclosingRequest   request    =     (  ( HttpEntityEnclosingRequest )     ( requestProducer . generateRequest (  )  )  )  ;", "URL   resource    =    resources [ responseCount ]  ;", "String   path    =    paths [  (  ( responseCount )  +  +  )  ]  ;", "ProtocolVersion   protocolVersion    =    new   ProtocolVersion (  \" http \"  ,     1  ,     1  )  ;", "if    ( path . startsWith (  \" fail :  \"  )  )     {", "String   body    =    Streams . copyToString ( new   InputStreamReader ( request . getEntity (  )  . getContent (  )  ,    StandardCharsets . UTF _  8  )  )  ;", "if    ( path . equals (  \" fail : rejection . json \"  )  )     {", "StatusLine   statusLine    =    new   BasicStatusLine ( protocolVersion ,    TOO _ MANY _ REQUESTS . getStatus (  )  ,     \"  \"  )  ;", "BasicHttpResponse   httpResponse    =    new   BasicHttpResponse ( statusLine )  ;", "futureCallback . completed ( httpResponse )  ;", "} else    {", "futureCallback . failed ( new   RuntimeException ( body )  )  ;", "}", "} else    {", "StatusLine   statusLine    =    new   BasicStatusLine ( protocolVersion ,     2  0  0  ,     \"  \"  )  ;", "HttpResponse   httpResponse    =    new   BasicHttpResponse ( statusLine )  ;", "httpResponse . setEntity ( new   InputStreamEntity ( FileSystemUtils . openFileURLStream ( resource )  ,    contentType )  )  ;", "futureCallback . completed ( httpResponse )  ;", "}", "return   null ;", "}", "}  )  ;", "return   sourceWithMockedClient ( mockVersion ,    httpClient )  ;", "}", "METHOD_END"], "methodName": ["sourceWithMockedRemoteCall"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "return   sourceWithMockedRemoteCall ( true ,    APPLICATION _ JSON ,    paths )  ;", "}", "METHOD_END"], "methodName": ["sourceWithMockedRemoteCall"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   cleanupCallbackCalled    =    new   AtomicBoolean (  )  ;", "RestClient   client    =    mock ( RestClient . class )  ;", "doThrow ( new   RuntimeException (  \" test \"  )  )  . when ( client )  . close (  )  ;", ". TestRemoteScrollableHitSource   hitSource    =    new    . TestRemoteScrollableHitSource ( client )  ;", "hitSource . cleanup (  (  )     -  >    cleanupCallbackCalled . set ( true )  )  ;", "verify ( client )  . close (  )  ;", "assertTrue ( cleanupCallbackCalled . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCleanupFailure"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   cleanupCallbackCalled    =    new   AtomicBoolean (  )  ;", "RestClient   client    =    mock ( RestClient . class )  ;", ". TestRemoteScrollableHitSource   hitSource    =    new    . TestRemoteScrollableHitSource ( client )  ;", "hitSource . cleanup (  (  )     -  >    cleanupCallbackCalled . set ( true )  )  ;", "verify ( client )  . close (  )  ;", "assertTrue ( cleanupCallbackCalled . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCleanupSuccessful"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    expectThrows ( RuntimeException . class ,     (  )     -  >    sourceWithMockedRemoteCall (  \" some _ text . txt \"  )  . doStart ( null )  )  ;", "assertEquals (  \" Error   parsing   the   response ,    remote   is   likely   not   an   E   instance \"  ,    e . getCause (  )  . getCause (  )  . getCause (  )  . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidJsonThinksRemoveIsNotES"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "sourceWithMockedCall ( false ,    APPLICATION _ JSON ,     \" main /  0  _  2  0  _  5  . json \"  )  . lookupVersion (  (    v )     -  >     {", "assertEquals ( Version . fromString (  \"  0  .  2  0  .  5  \"  )  ,    v )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "called . set ( false )  ;", "sourceWithMockedCall ( false ,    APPLICATION _ JSON ,     \" main /  0  _  9  0  _  1  3  . json \"  )  . lookupVersion (  (    v )     -  >     {", "assertEquals ( Version . fromString (  \"  0  .  9  0  .  1  3  \"  )  ,    v )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "called . set ( false )  ;", "sourceWithMockedCall ( false ,    APPLICATION _ JSON ,     \" main /  1  _  7  _  5  . json \"  )  . lookupVersion (  (    v )     -  >     {", "assertEquals ( Version . fromString (  \"  1  .  7  .  5  \"  )  ,    v )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "called . set ( false )  ;", "sourceWithMockedCall ( false ,    APPLICATION _ JSON ,     \" main /  2  _  3  _  3  . json \"  )  . lookupVersion (  (    v )     -  >     {", "assertEquals ( Version . fromId (  2  0  3  0  3  9  9  )  ,    v )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "called . set ( false )  ;", "sourceWithMockedCall ( false ,    APPLICATION _ JSON ,     \" main /  5  _  0  _  0  _ alpha _  3  . json \"  )  . lookupVersion (  (    v )     -  >     {", "assertEquals ( Version . V _  5  _  0  _  0  _ alpha 3  ,    v )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "called . set ( false )  ;", "sourceWithMockedCall ( false ,    APPLICATION _ JSON ,     \" main / with _ unknown _ fields . json \"  )  . lookupVersion (  (    v )     -  >     {", "assertEquals ( Version . V _  5  _  0  _  0  _ alpha 3  ,    v )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testLookupRemoteVersion"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    expectThrows ( RuntimeException . class ,     (  )     -  >    sourceWithMockedRemoteCall ( false ,    null ,     \" main /  0  _  2  0  _  5  . json \"  )  . lookupRemoteVersion ( null )  )  ;", "assertThat ( e . getCause (  )  . getCause (  )  . getCause (  )  . getMessage (  )  ,    containsString (  \" Response   didn ' t   include   Content - Type :    body =  {  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoContentTypeIsError"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "Consumer < Response >    checkResponse    =     (    r )     -  >     {", "assertFalse ( r . isTimedOut (  )  )  ;", "assertEquals (  . FAKE _ SCROLL _ ID ,    r . getScrollId (  )  )  ;", "assertEquals (  1  0  0  0  0  ,    r . getTotalHits (  )  )  ;", "assertThat ( r . getFailures (  )  ,    hasSize (  1  )  )  ;", "assertEquals ( null ,    r . getFailures (  )  . get (  0  )  . getIndex (  )  )  ;", "assertEquals ( null ,    r . getFailures (  )  . get (  0  )  . getShardId (  )  )  ;", "assertEquals ( null ,    r . getFailures (  )  . get (  0  )  . getNodeId (  )  )  ;", "assertThat ( r . getFailures (  )  . get (  0  )  . getReason (  )  ,    instanceOf ( RuntimeException . class )  )  ;", "assertEquals (  \" Unknown   remote   exception   with   reason =  [ SearchContextMissingException [ No   search   context   found   for   id    [  8  2  ]  ]  ]  \"  ,    r . getFailures (  )  . get (  0  )  . getReason (  )  . getMessage (  )  )  ;", "assertThat ( r . getHits (  )  ,    hasSize (  1  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getIndex (  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getType (  )  )  ;", "assertEquals (  \"  1  0  0  0  0  \"  ,    r . getHits (  )  . get (  0  )  . getId (  )  )  ;", "assertEquals (  \"  {  \\  \" test \\  \"  :  \\  \" test 1  0  0  0  0  \\  \"  }  \"  ,    r . getHits (  )  . get (  0  )  . getSource (  )  . utf 8 ToString (  )  )  ;", "called . set ( true )  ;", "}  ;", "sourceWithMockedRemoteCall (  \" failure _ with _ status . json \"  )  . doStart ( checkResponse )  ;", "assertTrue ( called . get (  )  )  ;", "called . set ( false )  ;", "sourceWithMockedRemoteCall (  \" failure _ with _ status . json \"  )  . doStartNextScroll (  \" scroll \"  ,    timeValueMillis (  0  )  ,    checkResponse )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseFailureWithStatus"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "Consumer < Response >    checkResponse    =     (    r )     -  >     {", "assertFalse ( r . isTimedOut (  )  )  ;", "assertEquals (  . FAKE _ SCROLL _ ID ,    r . getScrollId (  )  )  ;", "assertEquals (  4  ,    r . getTotalHits (  )  )  ;", "assertThat ( r . getFailures (  )  ,    hasSize (  1  )  )  ;", "assertEquals (  \" test \"  ,    r . getFailures (  )  . get (  0  )  . getIndex (  )  )  ;", "assertEquals (  (  ( Integer )     (  0  )  )  ,    r . getFailures (  )  . get (  0  )  . getShardId (  )  )  ;", "assertEquals (  \"  8  7 A 7 NvevQxSrEwMbtRCecg \"  ,    r . getFailures (  )  . get (  0  )  . getNodeId (  )  )  ;", "assertThat ( r . getFailures (  )  . get (  0  )  . getReason (  )  ,    instanceOf ( EsRejectedExecutionException . class )  )  ;", "assertEquals (  (  \" rejected   execution   of   TransportService $  5  @  5  2 d 0  6 af 2    on    \"     +     (  (  \" EsThreadPoolExecutor [ search ,    queue   capacity    =     1  0  0  0  ,    \"     +     \" EsThreadPoolExecutor @  7  7  8 ea 5  5  3  [ Running ,    pool   size    =     7  ,    active   threads    =     7  ,    queued   tasks    =     1  0  0  0  ,     \"  )     +     \" completed   tasks    =     4  1  8  2  ]  ]  \"  )  )  ,    r . getFailures (  )  . get (  0  )  . getReason (  )  . getMessage (  )  )  ;", "assertThat ( r . getHits (  )  ,    hasSize (  1  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getIndex (  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getType (  )  )  ;", "assertEquals (  \" AVToMiC 2  5  0 DjIiBO 3 yJ _  \"  ,    r . getHits (  )  . get (  0  )  . getId (  )  )  ;", "assertEquals (  \"  {  \\  \" test \\  \"  :  \\  \" test 1  \\  \"  }  \"  ,    r . getHits (  )  . get (  0  )  . getSource (  )  . utf 8 ToString (  )  )  ;", "called . set ( true )  ;", "}  ;", "sourceWithMockedRemoteCall (  \" rejection . json \"  )  . doStart ( checkResponse )  ;", "assertTrue ( called . get (  )  )  ;", "called . set ( false )  ;", "sourceWithMockedRemoteCall (  \" rejection . json \"  )  . doStartNextScroll (  \" scroll \"  ,    timeValueMillis (  0  )  ,    checkResponse )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseRejection"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "Consumer < Response >    checkResponse    =     (    r )     -  >     {", "assertFalse ( r . isTimedOut (  )  )  ;", "assertNull ( r . getId (  )  )  ;", "assertEquals (  0  ,    r . getTotalHits (  )  )  ;", "assertThat ( r . getFailures (  )  ,    hasSize (  1  )  )  ;", "assertThat ( r . getFailures (  )  . get (  0  )  . getReason (  )  ,    instanceOf ( ParsingException . class )  )  ;", "ParsingException   failure    =     (  ( ParsingException )     ( r . getFailures (  )  . get (  0  )  . getReason (  )  )  )  ;", "assertEquals (  \" Unknown   key   for   a   VALUE _ STRING   in    [ invalid ]  .  \"  ,    failure . getMessage (  )  )  ;", "assertEquals (  2  ,    failure . getLineNumber (  )  )  ;", "assertEquals (  1  4  ,    failure . getColumnNumber (  )  )  ;", "called . set ( true )  ;", "}  ;", "sourceWithMockedRemoteCall (  \" request _ failure . json \"  )  . doStart ( checkResponse )  ;", "assertTrue ( called . get (  )  )  ;", "called . set ( false )  ;", "sourceWithMockedRemoteCall (  \" request _ failure . json \"  )  . doStartNext (  \" scroll \"  ,    timeValueMillis (  0  )  ,    checkResponse )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseRequestFailure"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "sourceWithMockedRemoteCall (  \" scroll _ fully _ loaded . json \"  )  . doStartNextScroll (  \"  \"  ,    timeValueMillis (  0  )  ,     (    r )     -  >     {", "assertEquals (  \" AVToMiDL 5  0 DjIiBO 3 yKA \"  ,    r . getHits (  )  . get (  0  )  . getId (  )  )  ;", "assertEquals (  \"  {  \\  \" test \\  \"  :  \\  \" test 3  \\  \"  }  \"  ,    r . getHits (  )  . get (  0  )  . ge (  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" testrouting \"  ,    r . getHits (  )  . get (  0  )  . getRouting (  )  )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseScrollFullyLoaded"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "sourceWithMockedRemoteCall (  \" scroll _ fully _ loaded _  1  _  7  . json \"  )  . doStartNextScroll (  \"  \"  ,    timeValueMillis (  0  )  ,     (    r )     -  >     {", "assertEquals (  \" AVToMiDL 5  0 DjIiBO 3 yKA \"  ,    r . getHits (  )  . get (  0  )  . getId (  )  )  ;", "assertEquals (  \"  {  \\  \" test \\  \"  :  \\  \" test 3  \\  \"  }  \"  ,    r . getHits (  )  . get (  0  )  . ge (  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" testrouting \"  ,    r . getHits (  )  . get (  0  )  . getRouting (  )  )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseScrollFullyLoadedFrom1_7"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "sourceWithMockedRemoteCall (  \" scroll _ ok . json \"  )  . doStartNextScroll (  \"  \"  ,    timeValueMillis (  0  )  ,     (    r )     -  >     {", "assertFalse ( r . isTimedOut (  )  )  ;", "assertEquals (  . FAKE _ SCROLL _ ID ,    r . getScrollId (  )  )  ;", "assertEquals (  4  ,    r . getTotalHits (  )  )  ;", "assertThat ( r . getFailures (  )  ,    empty (  )  )  ;", "assertThat ( r . getHits (  )  ,    hasSize (  1  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getIndex (  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getType (  )  )  ;", "assertEquals (  \" AVToMiDL 5  0 DjIiBO 3 yKA \"  ,    r . getHits (  )  . get (  0  )  . getId (  )  )  ;", "assertEquals (  \"  {  \\  \" test \\  \"  :  \\  \" test 3  \\  \"  }  \"  ,    r . getHits (  )  . get (  0  )  . getSource (  )  . utf 8 ToString (  )  )  ;", "assertNull ( r . getHits (  )  . get (  0  )  . getRouting (  )  )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseScrollOk"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "sourceWithMockedRemoteCall (  \" start _ ok . json \"  )  . doStart (  (    r )     -  >     {", "assertFalse ( r . isTimedOut (  )  )  ;", "assertEquals (  . FAKE _ SCROLL _ ID ,    r . getScrollId (  )  )  ;", "assertEquals (  4  ,    r . getTotalHits (  )  )  ;", "assertThat ( r . getFailures (  )  ,    empty (  )  )  ;", "assertThat ( r . getHits (  )  ,    hasSize (  1  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getIndex (  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getType (  )  )  ;", "assertEquals (  \" AVToMiC 2  5  0 DjIiBO 3 yJ _  \"  ,    r . getHits (  )  . get (  0  )  . getId (  )  )  ;", "assertEquals (  \"  {  \\  \" test \\  \"  :  \\  \" test 2  \\  \"  }  \"  ,    r . getHits (  )  . get (  0  )  . getSource (  )  . utf 8 ToString (  )  )  ;", "assertNull ( r . getHits (  )  . get (  0  )  . getRouting (  )  )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseStartOk"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "Consumer < Response >    checkResponse    =     (    r )     -  >     {", "assertThat ( r . getFailures (  )  ,    hasSize (  0  )  )  ;", "called . set ( true )  ;", "}  ;", "retriesAllowed    =    between (  1  ,    Integer . MAX _ VALUE )  ;", "sourceWithMockedCall (  \" fail : rejection . json \"  ,     \" start _ ok . json \"  )  . doStart ( checkResponse )  ;", "assertTrue ( called . get (  )  )  ;", "assertEquals (  1  ,    retries )  ;", "retries    =     0  ;", "called . set ( false )  ;", "sourceWithMockedCall (  \" fail : rejection . json \"  ,     \" scroll _ ok . json \"  )  . doStartNextScroll (  \" scroll \"  ,    timeValueMillis (  0  )  ,    checkResponse )  ;", "assertTrue ( called . get (  )  )  ;", "assertEquals (  1  ,    retries )  ;", "}", "METHOD_END"], "methodName": ["testRetryAndSucceed"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "Consumer < Response >    checkResponse    =     (    r )     -  >    called . set ( true )  ;", "retriesAllowed    =    between (  0  ,     1  0  )  ;", "String [  ]    paths    =    new   String [  ( retriesAllowed )     +     2  ]  ;", "for    ( int   i    =     0  ;    i    <     (  ( retriesAllowed )     +     2  )  ;    i +  +  )     {", "paths [ i ]     =     \" fail : rejection . json \"  ;", "}", "RuntimeException   e    =    expectThrows ( RuntimeException . class ,     (  )     -  >    sourceWithMockedCall ( paths )  . doStart ( checkResponse )  )  ;", "assertEquals (  \" failed \"  ,    e . getMessage (  )  )  ;", "assertFalse ( called . get (  )  )  ;", "assertEquals ( retriesAllowed ,    retries )  ;", "retries    =     0  ;", "e    =    expectThrows ( RuntimeException . class ,     (  )     -  >    sourceWithMockedCall ( paths )  . doStartNextScroll (  \" scroll \"  ,    timeValueMillis (  0  )  ,    checkResponse )  )  ;", "assertEquals (  \" failed \"  ,    e . getMessage (  )  )  ;", "assertFalse ( called . get (  )  )  ;", "assertEquals ( retriesAllowed ,    retries )  ;", "}", "METHOD_END"], "methodName": ["testRetryUntilYouRunOutOfTries"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "sourceWithMockedRemoteCall (  \" start _ scan . json \"  ,     \" scroll _ ok . json \"  )  . doStart (  (    r )     -  >     {", "assertFalse ( r . isTimedOut (  )  )  ;", "assertEquals (  . FAKE _ SCROLL _ ID ,    r . getScrollId (  )  )  ;", "assertEquals (  4  ,    r . getTotalHits (  )  )  ;", "assertThat ( r . getFailures (  )  ,    empty (  )  )  ;", "assertThat ( r . getHits (  )  ,    hasSize (  1  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getIndex (  )  )  ;", "assertEquals (  \" test \"  ,    r . getHits (  )  . get (  0  )  . getType (  )  )  ;", "assertEquals (  \" AVToMiDL 5  0 DjIiBO 3 yKA \"  ,    r . getHits (  )  . get (  0  )  . getId (  )  )  ;", "assertEquals (  \"  {  \\  \" test \\  \"  :  \\  \" test 3  \\  \"  }  \"  ,    r . getHits (  )  . get (  0  )  . getSource (  )  . utf 8 ToString (  )  )  ;", "assertNull ( r . getHits (  )  . get (  0  )  . getRouting (  )  )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testScanJumpStart"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "String   header    =    randomAlphaOfLength (  5  )  ;", "threadPool . getThreadContext (  )  . putHeader (  \" test \"  ,    header )  ;", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "sourceWithMockedCall (  \" start _ ok . json \"  )  . doStart (  (    r )     -  >     {", "assertEquals ( header ,    threadPool . getThreadContext (  )  . getHeader (  \" test \"  )  )  ;", "called . set ( true )  ;", "}  )  ;", "assertTrue ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThreadContextRestored"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "ContentTooLongException   tooLong    =    new   ContentTooLongException (  \" too   long !  \"  )  ;", "CloseableHttpAsyncClient   httpClient    =    mock ( CloseableHttpAsyncClient . class )  ;", "when ( httpClient .  < HttpResponse > execute ( any ( HttpAsyncRequestProducer . class )  ,    any ( HttpAsyncResponseConsumer . class )  ,    any ( HttpClientContext . class )  ,    any ( FutureCallback . class )  )  )  . then ( new   Answer < Future < HttpResponse >  >  (  )     {", "@ Override", "public   Future < HttpResponse >    answer ( InvocationOnMock   invocationOnMock )    throws   Throwable    {", "HeapBufferedAsyncResponseConsumer   consumer    =     (  ( HeapBufferedAsyncResponseConsumer )     ( invocationOnMock . getArguments (  )  [  1  ]  )  )  ;", "FutureCallback   callback    =     (  ( FutureCallback )     ( invocationOnMock . getArguments (  )  [  3  ]  )  )  ;", "assertEquals ( new   ByteSizeValue (  1  0  0  ,    ByteSizeUnit . MB )  . bytesAsInt (  )  ,    consumer . getBufferLimit (  )  )  ;", "callback . failed ( tooLong )  ;", "return   null ;", "}", "}  )  ;", "RemoteScrollableHitSource   source    =    sourceWithMockedClient ( true ,    httpClient )  ;", "AtomicBoolean   called    =    new   AtomicBoolean (  )  ;", "Consumer < Response >    checkResponse    =     (    r )     -  >    called . set ( true )  ;", "Throwable   e    =    expectThrows ( RuntimeException . class ,     (  )     -  >    source . doStartNextScroll (  . FAKE _ SCROLL _ ID ,    timeValueMillis (  0  )  ,    checkResponse )  )  ;", "while    ( e . getMessage (  )  . equals (  \" failed \"  )  )     {", "e    =    e . getCause (  )  ;", "}", "assertEquals (  \" Remote   responded   with   a   chunk   that   was   too   large .    Use   a   smaller   batch   size .  \"  ,    e . getMessage (  )  )  ;", "assertSame ( tooLong ,    e . getCause (  )  )  ;", "assertFalse ( called . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testTooLargeResponse"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    expectThrows ( RuntimeException . class ,     (  )     -  >    sourceWithMockedRemoteCall (  \" main /  2  _  3  _  3  . json \"  )  . doStart ( null )  )  ;", "assertEquals (  \" Error   parsing   the   response ,    remote   is   likely   not   an   E   instance \"  ,    e . getCause (  )  . getCause (  )  . getCause (  )  . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnexpectedJsonThinksRemoveIsNotES"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "Exception   cause    =    new   Exception (  )  ;", "RestStatus   status    =    randomFrom ( values (  )  )  ;", "ElasticsearchStatusException   wrapped    =     . wrapExceptionToPreserveStatus ( status . getStatus (  )  ,    null ,    cause )  ;", "assertEquals ( status ,    wrapped . status (  )  )  ;", "assertEquals ( cause ,    wrapped . getCause (  )  )  ;", "assertEquals (  \" No   error   body .  \"  ,    wrapped . getMessage (  )  )  ;", "HttpEntity   okEntity    =    new   StringEntity (  \" test   body \"  ,    ContentType . TEXT _ PLAIN )  ;", "wrapped    =     . wrapExceptionToPreserveStatus ( status . getStatus (  )  ,    okEntity ,    cause )  ;", "assertEquals ( status ,    wrapped . status (  )  )  ;", "assertEquals ( cause ,    wrapped . getCause (  )  )  ;", "assertEquals (  \" body = test   body \"  ,    wrapped . getMessage (  )  )  ;", "IOException   badEntityException    =    new   IOException (  )  ;", "HttpEntity   badEntity    =    mock ( HttpEntity . class )  ;", "when ( badEntity . getContent (  )  )  . thenThrow ( badEntityException )  ;", "wrapped    =     . wrapExceptionToPreserveStatus ( status . getStatus (  )  ,    badEntity ,    cause )  ;", "assertEquals ( status ,    wrapped . status (  )  )  ;", "assertEquals ( cause ,    wrapped . getCause (  )  )  ;", "assertEquals (  \" Failed   to   extract   body .  \"  ,    wrapped . getMessage (  )  )  ;", "assertEquals ( badEntityException ,    wrapped . getSuppressed (  )  [  0  ]  )  ;", "int   notAnHttpStatus    =     -  1  ;", "assertNull ( fromCode ( notAnHttpStatus )  )  ;", "wrapped    =     . wrapExceptionToPreserveStatus ( notAnHttpStatus ,    null ,    cause )  ;", "assertEquals ( INTERNAL _ SERVER _ ERROR ,    wrapped . status (  )  )  ;", "assertEquals ( cause ,    wrapped . getCause (  )  )  ;", "assertEquals (  (  (  \" Couldn ' t   extract   status    [  \"     +    notAnHttpStatus )     +     \"  ]  .    No   error   body .  \"  )  ,    wrapped . getMessage (  )  )  ;", "wrapped    =     . wrapExceptionToPreserveStatus ( notAnHttpStatus ,    okEntity ,    cause )  ;", "assertEquals ( INTERNAL _ SERVER _ ERROR ,    wrapped . status (  )  )  ;", "assertEquals ( cause ,    wrapped . getCause (  )  )  ;", "assertEquals (  (  (  \" Couldn ' t   extract   status    [  \"     +    notAnHttpStatus )     +     \"  ]  .    body = test   body \"  )  ,    wrapped . getMessage (  )  )  ;", "wrapped    =     . wrapExceptionToPreserveStatus ( notAnHttpStatus ,    badEntity ,    cause )  ;", "assertEquals ( INTERNAL _ SERVER _ ERROR ,    wrapped . status (  )  )  ;", "assertEquals ( cause ,    wrapped . getCause (  )  )  ;", "assertEquals (  (  (  \" Couldn ' t   extract   status    [  \"     +    notAnHttpStatus )     +     \"  ]  .    Failed   to   extract   body .  \"  )  ,    wrapped . getMessage (  )  )  ;", "assertEquals ( badEntityException ,    wrapped . getSuppressed (  )  [  0  ]  )  ;", "}", "METHOD_END"], "methodName": ["testWrapExceptionToPreserveStatus"], "fileName": "org.elasticsearch.index.reindex.remote.RemoteScrollableHitSourceTests"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessor"}, {"methodBody": ["METHOD_START", "{", "return   targetField ;", "}", "METHOD_END"], "methodName": ["getTargetField"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessor"}, {"methodBody": ["METHOD_START", "{", "return   ignoreMissing ;", "}", "METHOD_END"], "methodName": ["isIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessor"}, {"methodBody": ["METHOD_START", "{", "return   config ;", "}", "METHOD_END"], "methodName": ["modifyConfig"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "AbstractStringProcessor . Factory   factory    =    newFactory (  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    fieldName )  ;", "AbstractStringProcessor   processor    =    factory . create ( null ,    processorTag ,    modifyConfig ( config )  )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo ( fieldName )  )  ;", "assertThat ( processor . isIgnoreMissing (  )  ,    is ( false )  )  ;", "assertThat ( processor . getTargetField (  )  ,    equalTo ( fieldName )  )  ;", "assertProcessor ( processor )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "AbstractStringProcessor . Factory   factory    =    newFactory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateMissingField"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "AbstractStringProcessor . Factory   factory    =    newFactory (  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    fieldName )  ;", "config . put (  \" ignore _ missing \"  ,    true )  ;", "AbstractStringProcessor   processor    =    factory . create ( null ,    processorTag ,    modifyConfig ( config )  )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo ( fieldName )  )  ;", "assertThat ( processor . isIgnoreMissing (  )  ,    is ( true )  )  ;", "assertThat ( processor . getTargetField (  )  ,    equalTo ( fieldName )  )  ;", "assertProcessor ( processor )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "AbstractStringProcessor . Factory   factory    =    newFactory (  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   targetFieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    fieldName )  ;", "config . put (  \" target _ field \"  ,    targetFieldName )  ;", "AbstractStringProcessor   processor    =    factory . create ( null ,    processorTag ,    modifyConfig ( config )  )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo ( fieldName )  )  ;", "assertThat ( processor . isIgnoreMissing (  )  ,    is ( false )  )  ;", "assertThat ( processor . getTargetField (  )  ,    equalTo ( targetFieldName )  )  ;", "assertProcessor ( processor )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithTargetField"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorFactoryTestCase"}, {"methodBody": ["METHOD_START", "{", "return   input ;", "}", "METHOD_END"], "methodName": ["modifyInput"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorTestCase"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "processor    =    new ( fieldName ,    false ,    fieldName )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "Exception   e    =    expectThrows ( Exception . class ,     (  )     -  >    processor . execute ( ingestDocument )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \" not   present   as   part   of   path    [  \"     +    fieldName )     +     \"  ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testFieldNotFound"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorTestCase"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "processor    =    new ( fieldName ,    true ,    fieldName )  ;", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testFieldNotFoundWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorTestCase"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "processor    =    new ( fieldName ,    false ,    fieldName )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    randomInt (  )  )  ;", "Exception   e    =    expectThrows ( Exception . class ,     (  )     -  >    processor . execute ( ingestDocument )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    of   type    [ Integer ]    cannot   be   cast   to    [ String ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNonStringValue"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorTestCase"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "processor    =    new ( fieldName ,    true ,    fieldName )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    randomInt (  )  )  ;", "Exception   e    =    expectThrows ( Exception . class ,     (  )     -  >    processor . execute ( ingestDocument )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    of   type    [ Integer ]    cannot   be   cast   to    [ String ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNonStringValueWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorTestCase"}, {"methodBody": ["METHOD_START", "{", "Processor   processor    =    newProcessor (  \" field \"  ,    false ,     \" field \"  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    null )  )  ;", "Exception   e    =    expectThrows ( Exception . class ,     (  )     -  >    processor . execute ( ingestDocument )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" field    [ field ]    is   null ,    cannot   process   it .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullValue"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorTestCase"}, {"methodBody": ["METHOD_START", "{", "Processor   processor    =    newProcessor (  \" field \"  ,    true ,     \" field \"  )  ;", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    null )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testNullValueWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorTestCase"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldValue    =    RandomDocumentPicks . randomString ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    modifyInput ( fieldValue )  )  ;", "processor    =    new ( fieldName ,    randomBoolean (  )  ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    String . class )  ,    equalTo ( expectedResult ( fieldValue )  )  )  ;", "}", "METHOD_END"], "methodName": ["testProcessor"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorTestCase"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . emptyMap (  )  )  ;", "String   fieldValue    =    RandomDocumentPicks . randomString ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    modifyInput ( fieldValue )  )  ;", "String   targetFieldName    =    fieldName    +     \" foo \"  ;", "processor    =    new ( fieldName ,    randomBoolean (  )  ,    targetFieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( targetFieldName ,    String . class )  ,    equalTo ( expectedResult ( fieldValue )  )  )  ;", "}", "METHOD_END"], "methodName": ["testTargetField"], "fileName": "org.elasticsearch.ingest.common.AbstractStringProcessorTestCase"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.AppendProcessor"}, {"methodBody": ["METHOD_START", "{", "return   value ;", "}", "METHOD_END"], "methodName": ["getValue"], "fileName": "org.elasticsearch.ingest.common.AppendProcessor"}, {"methodBody": ["METHOD_START", "{", "factory    =    new   AppendProcessor . Factory ( TestTemplateService . instance (  )  )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "Object   value ;", "if    ( randomBoolean (  )  )     {", "value    =     \" value 1  \"  ;", "} else    {", "value    =    Arrays . asList (  \" value 1  \"  ,     \" value 2  \"  ,     \" value 3  \"  )  ;", "}", "config . put (  \" value \"  ,    value )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "appendProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( appendProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( appendProcessor . getField (  )  . newInstance ( Collections . emptyMap (  )  )  . execute (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( appendProcessor . getValue (  )  . copyAndResolve ( Collections . emptyMap (  )  )  ,    equalTo ( value )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" value \"  ,     \" value 1  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoFieldPresent"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ value ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoValuePresent"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" value \"  ,    null )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ value ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNullValue"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "AppendProcessor . Factory   factory    =    new   AppendProcessor . Factory ( TestTemplateService . instance ( true )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" value \"  ,     \" value 1  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchException . class ,     (  )     -  >    factory . create ( null ,    processorTag ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \" RuntimeException :    could   not   compile   script \"  )  )  ;", "assertThat ( exception . getHeader (  \" processor _ tag \"  )  . get (  0  )  ,    equalTo ( processorTag )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidMustacheTemplate"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   new   AppendProcessor ( randomAlphaOfLength (  1  0  )  ,    new   TestTemplateService . MockTemplateScript . Factory ( fieldName )  ,    ValueSource . wrap ( fieldValue ,    TestTemplateService . instance (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["createAppendProcessor"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorTests"}, {"methodBody": ["METHOD_START", "{", "MetaData   randomMetaData    =    randomFrom ( INDEX ,    TYPE ,    ID ,    ROUTING )  ;", "List < String >    values    =    new   ArrayList <  >  (  )  ;", "Processor   appendProcessor ;", "if    ( randomBoolean (  )  )     {", "String   value    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "values . add ( value )  ;", "appendProcessor    =     . createAppendProcessor ( randomMetaData . getFieldName (  )  ,    value )  ;", "} else    {", "int   valuesSize    =    randomIntBetween (  0  ,     1  0  )  ;", "for    ( int   i    =     0  ;    i    <    valuesSize ;    i +  +  )     {", "values . add ( randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "}", "appendProcessor    =     . createAppendProcessor ( randomMetaData . getFieldName (  )  ,    values )  ;", "}", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "Object   initialValue    =    ingestDocument . getSourceAndMetadata (  )  . get ( randomMetaData . getFieldName (  )  )  ;", "appendProcessor . execute ( ingestDocument )  ;", "List   list    =    ingestDocument . getFieldValue ( randomMetaData . getFieldName (  )  ,    List . class )  ;", "if    ( initialValue    =  =    null )     {", "assertThat ( list ,    equalTo ( values )  )  ;", "} else    {", "assertThat ( list . size (  )  ,    equalTo (  (  ( values . size (  )  )     +     1  )  )  )  ;", "assertThat ( list . get (  0  )  ,    equalTo ( initialValue )  )  ;", "for    ( int   i    =     1  ;    i    <     ( list . size (  )  )  ;    i +  +  )     {", "assertThat ( list . get ( i )  ,    equalTo ( values . get (  ( i    -     1  )  )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testAppendMetadataExceptVersion"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", ". Scalar   scalar    =    randomFrom (  . Scalar . values (  )  )  ;", "List < Object >    list    =    new   ArrayList <  >  (  )  ;", "int   size    =    randomIntBetween (  0  ,     1  0  )  ;", "for    ( int   i    =     0  ;    i    <    size ;    i +  +  )     {", "list . add ( scalar . randomValue (  )  )  ;", "}", "List < Object >    checkList    =    new   ArrayList <  >  ( list )  ;", "String   field    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    list )  ;", "List < Object >    values    =    new   ArrayList <  >  (  )  ;", "Processor   appendProcessor ;", "if    ( randomBoolean (  )  )     {", "Object   value    =    scalar . randomValue (  )  ;", "values . add ( value )  ;", "appendProcessor    =     . createAppendProcessor ( field ,    value )  ;", "} else    {", "int   valuesSize    =    randomIntBetween (  0  ,     1  0  )  ;", "for    ( int   i    =     0  ;    i    <    valuesSize ;    i +  +  )     {", "values . add ( scalar . randomValue (  )  )  ;", "}", "appendProcessor    =     . createAppendProcessor ( field ,    values )  ;", "}", "appendProcessor . execute ( ingestDocument )  ;", "Object   fieldValue    =    ingestDocument . getFieldValue ( field ,    Object . class )  ;", "assertThat ( fieldValue ,    sameInstance ( list )  )  ;", "assertThat ( list . size (  )  ,    equalTo (  ( size    +     ( values . size (  )  )  )  )  )  ;", "for    ( int   i    =     0  ;    i    <    size ;    i +  +  )     {", "assertThat ( list . get ( i )  ,    equalTo ( checkList . get ( i )  )  )  ;", "}", "for    ( int   i    =    size ;    i    <     ( size    +     ( values . size (  )  )  )  ;    i +  +  )     {", "assertThat ( list . get ( i )  ,    equalTo ( values . get (  ( i    -    size )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testAppendValuesToExistingList"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   field    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", ". Scalar   scalar    =    randomFrom (  . Scalar . values (  )  )  ;", "List < Object >    values    =    new   ArrayList <  >  (  )  ;", "Processor   appendProcessor ;", "if    ( randomBoolean (  )  )     {", "Object   value    =    scalar . randomValue (  )  ;", "values . add ( value )  ;", "appendProcessor    =     . createAppendProcessor ( field ,    value )  ;", "} else    {", "int   valuesSize    =    randomIntBetween (  0  ,     1  0  )  ;", "for    ( int   i    =     0  ;    i    <    valuesSize ;    i +  +  )     {", "values . add ( scalar . randomValue (  )  )  ;", "}", "appendProcessor    =     . createAppendProcessor ( field ,    values )  ;", "}", "appendProcessor . execute ( ingestDocument )  ;", "List   list    =    ingestDocument . getFieldValue ( field ,    List . class )  ;", "assertThat ( list ,    not ( sameInstance ( values )  )  )  ;", "assertThat ( list ,    equalTo ( values )  )  ;", "}", "METHOD_END"], "methodName": ["testAppendValuesToNonExistingList"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", ". Scalar   scalar    =    randomFrom (  . Scalar . values (  )  )  ;", "Object   initialValue    =    scalar . randomValue (  )  ;", "String   field    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    initialValue )  ;", "List < Object >    values    =    new   ArrayList <  >  (  )  ;", "Processor   appendProcessor ;", "if    ( randomBoolean (  )  )     {", "Object   value    =    scalar . randomValue (  )  ;", "values . add ( value )  ;", "appendProcessor    =     . createAppendProcessor ( field ,    value )  ;", "} else    {", "int   valuesSize    =    randomIntBetween (  0  ,     1  0  )  ;", "for    ( int   i    =     0  ;    i    <    valuesSize ;    i +  +  )     {", "values . add ( scalar . randomValue (  )  )  ;", "}", "appendProcessor    =     . createAppendProcessor ( field ,    values )  ;", "}", "appendProcessor . execute ( ingestDocument )  ;", "List   fieldValue    =    ingestDocument . getFieldValue ( field ,    List . class )  ;", "assertThat ( fieldValue . size (  )  ,    equalTo (  (  ( values . size (  )  )     +     1  )  )  )  ;", "assertThat ( fieldValue . get (  0  )  ,    equalTo ( initialValue )  )  ;", "for    ( int   i    =     1  ;    i    <     (  ( values . size (  )  )     +     1  )  ;    i +  +  )     {", "assertThat ( fieldValue . get ( i )  ,    equalTo ( values . get (  ( i    -     1  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConvertScalarToList"], "fileName": "org.elasticsearch.ingest.common.AppendProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   convertType ;", "}", "METHOD_END"], "methodName": ["getConvertType"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessor"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessor"}, {"methodBody": ["METHOD_START", "{", "return   targetField ;", "}", "METHOD_END"], "methodName": ["getTargetField"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessor"}, {"methodBody": ["METHOD_START", "{", "return   ignoreMissing ;", "}", "METHOD_END"], "methodName": ["isIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessor"}, {"methodBody": ["METHOD_START", "{", "ConvertProcessor . Factory   factory    =    new   ConvertProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "ConvertProcessor . Type   type    =    randomFrom ( ConvertProcessor . Type . values (  )  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" type \"  ,    type . toString (  )  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ConvertProcessor   convertProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( convertProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( convertProcessor . getField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( convertProcessor . getTargetField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( convertProcessor . getConvertType (  )  ,    equalTo ( type )  )  ;", "assertThat ( convertProcessor . isIgnoreMissing (  )  ,    is ( false )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ConvertProcessor . Factory   factory    =    new   ConvertProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   type    =     \" type -  \"     +     ( randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "config . put (  \" type \"  ,    type )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    Matchers . equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoFieldPresent"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ConvertProcessor . Factory   factory    =    new   ConvertProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    Matchers . equalTo (  \"  [ type ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoTypePresent"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ConvertProcessor . Factory   factory    =    new   ConvertProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   type    =     \" type -  \"     +     ( randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" type \"  ,    type )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    Matchers . equalTo (  (  (  \"  [ type ]    type    [  \"     +    type )     +     \"  ]    not   supported ,    cannot   convert   field .  \"  )  )  )  ;", "assertThat ( e . getHeader (  \" processor _ type \"  )  . get (  0  )  ,    equalTo ( ConvertProcessor . TYPE )  )  ;", "assertThat ( e . getHeader (  \" property _ name \"  )  . get (  0  )  ,    equalTo (  \" type \"  )  )  ;", "assertThat ( e . getHeader (  \" processor _ tag \"  )  ,    nullValue (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateUnsupportedType"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ConvertProcessor . Factory   factory    =    new   ConvertProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "ConvertProcessor . Type   type    =    randomFrom ( ConvertProcessor . Type . values (  )  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" target _ field \"  ,     \" field 2  \"  )  ;", "config . put (  \" type \"  ,    type . toString (  )  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ConvertProcessor   convertProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( convertProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( convertProcessor . getField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( convertProcessor . getTargetField (  )  ,    equalTo (  \" field 2  \"  )  )  ;", "assertThat ( convertProcessor . getConvertType (  )  ,    equalTo ( type )  )  ;", "assertThat ( convertProcessor . isIgnoreMissing (  )  ,    is ( false )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithExplicitTargetField"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ConvertProcessor . Factory   factory    =    new   ConvertProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "ConvertProcessor . Type   type    =    randomFrom ( ConvertProcessor . Type . values (  )  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" type \"  ,    type . toString (  )  )  ;", "config . put (  \" ignore _ missing \"  ,    true )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ConvertProcessor   convertProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( convertProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( convertProcessor . getField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( convertProcessor . getTargetField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( convertProcessor . getConvertType (  )  ,    equalTo ( type )  )  ;", "assertThat ( convertProcessor . isIgnoreMissing (  )  ,    is ( true )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "double   randomDouble    =    randomDouble (  )  ;", "String   randomString    =    Double . toString ( randomDouble )  ;", "float   randomFloat    =    Float . parseFloat ( randomString )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    randomString )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \" field \"  ,     . Type . AUTO ,    false )  ;", "processor . execute ( ingestDocument )  ;", "Object   convertedValue    =    ingestDocument . getFieldValue (  \" field \"  ,    Object . class )  ;", "assertThat ( convertedValue ,    not ( randomDouble )  )  ;", "assertThat ( convertedValue ,    equalTo ( randomFloat )  )  ;", "}", "METHOD_END"], "methodName": ["testAutoConvertDoubleNotMatched"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "boolean   randomBoolean    =    randomBoolean (  )  ;", "String   booleanString    =    Boolean . toString ( randomBoolean )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    booleanString )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \" field \"  ,     . Type . AUTO ,    false )  ;", "processor . execute ( ingestDocument )  ;", "Object   convertedValue    =    ingestDocument . getFieldValue (  \" field \"  ,    Object . class )  ;", "assertThat ( convertedValue ,    equalTo ( randomBoolean )  )  ;", "}", "METHOD_END"], "methodName": ["testAutoConvertMatchBoolean"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "float   randomFloat    =    randomFloat (  )  ;", "String   randomString    =    Float . toString ( randomFloat )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    randomString )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \" field \"  ,     . Type . AUTO ,    false )  ;", "processor . execute ( ingestDocument )  ;", "Object   convertedValue    =    ingestDocument . getFieldValue (  \" field \"  ,    Object . class )  ;", "assertThat ( convertedValue ,    equalTo ( randomFloat )  )  ;", "}", "METHOD_END"], "methodName": ["testAutoConvertMatchFloat"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "int   randomInt    =    randomInt (  )  ;", "String   randomString    =    Integer . toString ( randomInt )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    randomString )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \" field \"  ,     . Type . AUTO ,    false )  ;", "processor . execute ( ingestDocument )  ;", "Object   convertedValue    =    ingestDocument . getFieldValue (  \" field \"  ,    Object . class )  ;", "assertThat ( convertedValue ,    equalTo ( randomInt )  )  ;", "}", "METHOD_END"], "methodName": ["testAutoConvertMatchInteger"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "long   randomLong    =    randomLong (  )  ;", "String   randomString    =    Long . toString ( randomLong )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    randomString )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \" field \"  ,     . Type . AUTO ,    false )  ;", "processor . execute ( ingestDocument )  ;", "Object   convertedValue    =    ingestDocument . getFieldValue (  \" field \"  ,    Object . class )  ;", "assertThat ( convertedValue ,    equalTo ( randomLong )  )  ;", "}", "METHOD_END"], "methodName": ["testAutoConvertMatchLong"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Object   randomValue ;", "switch    ( randomIntBetween (  0  ,     2  )  )     {", "case    0     :", "float   randomFloat    =    randomFloat (  )  ;", "randomValue    =    randomFloat ;", "break ;", "case    1     :", "int   randomInt    =    randomInt (  )  ;", "randomValue    =    randomInt ;", "break ;", "case    2     :", "boolean   randomBoolean    =    randomBoolean (  )  ;", "randomValue    =    randomBoolean ;", "break ;", "default    :", "throw   new   UnsupportedOperationException (  )  ;", "}", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    randomValue )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \" field \"  ,     . Type . AUTO ,    false )  ;", "processor . execute ( ingestDocument )  ;", "Object   convertedValue    =    ingestDocument . getFieldValue (  \" field \"  ,    Object . class )  ;", "assertThat ( convertedValue ,    sameInstance ( randomValue )  )  ;", "}", "METHOD_END"], "methodName": ["testAutoConvertNotString"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   value    =     \" notAnIntFloatOrBool \"  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    value )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \" field \"  ,     . Type . AUTO ,    false )  ;", "processor . execute ( ingestDocument )  ;", "Object   convertedValue    =    ingestDocument . getFieldValue (  \" field \"  ,    Object . class )  ;", "assertThat ( convertedValue ,    sameInstance ( value )  )  ;", "}", "METHOD_END"], "methodName": ["testAutoConvertStringNotMatched"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "boolean   randomBoolean    =    randomBoolean (  )  ;", "String   booleanString    =    Boolean . toString ( randomBoolean )  ;", "if    ( randomBoolean )     {", "booleanString    =    booleanString . toUpperCase ( Locale . ROOT )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    booleanString )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . BOOLEAN ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Boolean . class )  ,    equalTo ( randomBoolean )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertBoolean"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   fieldValue ;", "if    ( randomBoolean (  )  )     {", "fieldValue    =     \" string -  \"     +     ( randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "} else    {", "fieldValue    =    randomFrom (  \" on \"  ,     \" off \"  ,     \" yes \"  ,     \" no \"  ,     \"  0  \"  ,     \"  1  \"  )  ;", "}", "ingestDocument . setFieldValue ( fieldName ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . BOOLEAN ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( Exception   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \"  [  \"     +    fieldValue )     +     \"  ]    is   not   a   boolean   value ,    cannot   convert   to   boolean \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConvertBooleanError"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  (  )  ;", "List < Boolean >    expectedList    =    new   ArrayList <  >  (  )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "boolean   randomBoolean    =    randomBoolean (  )  ;", "String   booleanString    =    Boolean . toString ( randomBoolean )  ;", "if    ( randomBoolean )     {", "booleanString    =    booleanString . toUpperCase ( Locale . ROOT )  ;", "}", "fieldValue . add ( booleanString )  ;", "expectedList . add ( randomBoolean )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . BOOLEAN ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    equalTo ( expectedList )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertBooleanList"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "Map < String ,    Double >    expectedResult    =    new   HashMap <  >  (  )  ;", "double   randomDouble    =    randomDouble (  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    randomDouble )  ;", "expectedResult . put ( fieldName ,    randomDouble )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . DOUBLE ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Double . class )  ,    equalTo ( randomDouble )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertDouble"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   value    =     \" string -  \"     +     ( randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    value )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . DOUBLE ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" unable   to   convert    [  \"     +    value )     +     \"  ]    to   double \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConvertDoubleError"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  (  )  ;", "List < Double >    expectedList    =    new   ArrayList <  >  (  )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "double   randomDouble    =    randomDouble (  )  ;", "fieldValue . add ( Double . toString ( randomDouble )  )  ;", "expectedList . add ( randomDouble )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . DOUBLE ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    equalTo ( expectedList )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertDoubleList"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "Map < String ,    Float >    expectedResult    =    new   HashMap <  >  (  )  ;", "float   randomFloat    =    randomFloat (  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    randomFloat )  ;", "expectedResult . put ( fieldName ,    randomFloat )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . FLOAT ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Float . class )  ,    equalTo ( randomFloat )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertFloat"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   value    =     \" string -  \"     +     ( randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    value )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . FLOAT ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" unable   to   convert    [  \"     +    value )     +     \"  ]    to   float \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConvertFloatError"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  (  )  ;", "List < Float >    expectedList    =    new   ArrayList <  >  (  )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "float   randomFloat    =    randomFloat (  )  ;", "fieldValue . add ( Float . toString ( randomFloat )  )  ;", "expectedList . add ( randomFloat )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . FLOAT ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    equalTo ( expectedList )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertFloatList"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   randomInt    =    randomInt (  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    randomInt )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . INTEGER ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Integer . class )  ,    equalTo ( randomInt )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertInt"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   value    =     \" string -  \"     +     ( randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    value )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . INTEGER ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" unable   to   convert    [  \"     +    value )     +     \"  ]    to   integer \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConvertIntError"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  (  )  ;", "List < Integer >    expectedList    =    new   ArrayList <  >  (  )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "int   randomInt    =    randomInt (  )  ;", "fieldValue . add ( Integer . toString ( randomInt )  )  ;", "expectedList . add ( randomInt )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . INTEGER ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    equalTo ( expectedList )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertIntList"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "Map < String ,    Long >    expectedResult    =    new   HashMap <  >  (  )  ;", "long   randomLong    =    randomLong (  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    randomLong )  ;", "expectedResult . put ( fieldName ,    randomLong )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . LONG ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Long . class )  ,    equalTo ( randomLong )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertLong"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   value    =     \" string -  \"     +     ( randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    value )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . LONG ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" unable   to   convert    [  \"     +    value )     +     \"  ]    to   long \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConvertLongError"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  (  )  ;", "List < Long >    expectedList    =    new   ArrayList <  >  (  )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "long   randomLong    =    randomLong (  )  ;", "fieldValue . add ( Long . toString ( randomLong )  )  ;", "expectedList . add ( randomLong )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . LONG ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    equalTo ( expectedList )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertLongList"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", ". Type   type    =    randomFrom (  . Type . values (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,    type ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \" not   present   as   part   of   path    [  \"     +    fieldName )     +     \"  ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConvertNonExistingField"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", ". Type   type    =    randomFrom (  . Type . values (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,    type ,    true )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testConvertNonExistingFieldWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    null )  )  ;", ". Type   type    =    randomFrom (  . Type . values (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \" field \"  ,    type ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" Field    [ field ]    is   null ,    cannot   be   converted   to   type    [  \"     +    type )     +     \"  ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConvertNullField"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    null )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", ". Type   type    =    randomFrom (  . Type . values (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \" field \"  ,    type ,    true )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testConvertNullFieldWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "Object   fieldValue ;", "String   expectedFieldValue ;", "switch    ( randomIntBetween (  0  ,     2  )  )     {", "case    0     :", "float   randomFloat    =    randomFloat (  )  ;", "fieldValue    =    randomFloat ;", "expectedFieldValue    =    Float . toString ( randomFloat )  ;", "break ;", "case    1     :", "int   randomInt    =    randomInt (  )  ;", "fieldValue    =    randomInt ;", "expectedFieldValue    =    Integer . toString ( randomInt )  ;", "break ;", "case    2     :", "boolean   randomBoolean    =    randomBoolean (  )  ;", "fieldValue    =    randomBoolean ;", "expectedFieldValue    =    Boolean . toString ( randomBoolean )  ;", "break ;", "default    :", "throw   new   UnsupportedOperationException (  )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . STRING ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    String . class )  ,    equalTo ( expectedFieldValue )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertString"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < Object >    fieldValue    =    new   ArrayList <  >  (  )  ;", "List < String >    expectedList    =    new   ArrayList <  >  (  )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "Object   randomValue ;", "String   randomValueString ;", "switch    ( randomIntBetween (  0  ,     2  )  )     {", "case    0     :", "float   randomFloat    =    randomFloat (  )  ;", "randomValue    =    randomFloat ;", "randomValueString    =    Float . toString ( randomFloat )  ;", "break ;", "case    1     :", "int   randomInt    =    randomInt (  )  ;", "randomValue    =    randomInt ;", "randomValueString    =    Integer . toString ( randomInt )  ;", "break ;", "case    2     :", "boolean   randomBoolean    =    randomBoolean (  )  ;", "randomValue    =    randomBoolean ;", "randomValueString    =    Boolean . toString ( randomBoolean )  ;", "break ;", "case    3     :", "long   randomLong    =    randomLong (  )  ;", "randomValue    =    randomLong ;", "randomValueString    =    Long . toString ( randomLong )  ;", "break ;", "case    4     :", "double   randomDouble    =    randomDouble (  )  ;", "randomValue    =    randomDouble ;", "randomValueString    =    Double . toString ( randomDouble )  ;", "break ;", "default    :", "throw   new   UnsupportedOperationException (  )  ;", "}", "fieldValue . add ( randomValue )  ;", "expectedList . add ( randomValueString )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    fieldName ,     . Type . STRING ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    equalTo ( expectedList )  )  ;", "}", "METHOD_END"], "methodName": ["testConvertStringList"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    new   IngestDocument ( new   HashMap (  )  ,    new   HashMap (  )  )  ;", "int   randomInt    =    randomInt (  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    String . valueOf ( randomInt )  )  ;", "String   targetField    =    fieldName    +     ( randomAlphaOfLength (  5  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    targetField ,     . Type . INTEGER ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    String . class )  ,    equalTo ( String . valueOf ( randomInt )  )  )  ;", "assertThat ( ingestDocument . getFieldValue ( targetField ,    Integer . class )  ,    equalTo ( randomInt )  )  ;", "}", "METHOD_END"], "methodName": ["testTargetField"], "fileName": "org.elasticsearch.ingest.common.ConvertProcessorTests"}, {"methodBody": ["METHOD_START", "{", "switch    ( format )     {", "case    \" ISO 8  6  0  1  \"     :", "return    . Iso 8  6  0  1  ;", "case    \" UNIX \"     :", "return    . Unix ;", "case    \" UNIX _ MS \"     :", "return    . UnixMs ;", "case    \" TAI 6  4 N \"     :", "return    . Tai 6  4 n ;", "default    :", "return    . Joda ;", "}", "}", "METHOD_END"], "methodName": ["fromString"], "fileName": "org.elasticsearch.ingest.common.DateFormat"}, {"methodBody": ["METHOD_START", "{", "assertThat ( DateFormat . fromString (  \" UNIX _ MS \"  )  ,    equalTo ( DateFormat . UnixMs )  )  ;", "assertThat ( DateFormat . fromString (  \" unix _ ms \"  )  ,    equalTo ( DateFormat . Joda )  )  ;", "assertThat ( DateFormat . fromString (  \" UNIX \"  )  ,    equalTo ( DateFormat . Unix )  )  ;", "assertThat ( DateFormat . fromString (  \" unix \"  )  ,    equalTo ( DateFormat . Joda )  )  ;", "assertThat ( DateFormat . fromString (  \" ISO 8  6  0  1  \"  )  ,    equalTo ( DateFormat . Iso 8  6  0  1  )  )  ;", "assertThat ( DateFormat . fromString (  \" iso 8  6  0  1  \"  )  ,    equalTo ( DateFormat . Joda )  )  ;", "assertThat ( DateFormat . fromString (  \" TAI 6  4 N \"  )  ,    equalTo ( DateFormat . Tai 6  4 n )  )  ;", "assertThat ( DateFormat . fromString (  \" tai 6  4 n \"  )  ,    equalTo ( DateFormat . Joda )  )  ;", "assertThat ( DateFormat . fromString (  (  \" prefix -  \"     +     ( randomAlphaOfLengthBetween (  1  ,     1  0  )  )  )  )  ,    equalTo ( DateFormat . Joda )  )  ;", "}", "METHOD_END"], "methodName": ["testFromString"], "fileName": "org.elasticsearch.ingest.common.DateFormatTests"}, {"methodBody": ["METHOD_START", "{", "assertThat ( DateFormat . Iso 8  6  0  1  . getFunction ( null ,    UTC ,    null )  . apply (  \"  2  0  0  1  -  0  1  -  0  1 T 0  0  :  0  0  :  0  0  -  0  8  0  0  \"  )  . getMillis (  )  ,    equalTo (  9  7  8  3  3  6  0  0  0  0  0  0 L )  )  ;", "}", "METHOD_END"], "methodName": ["testParseISO8601"], "fileName": "org.elasticsearch.ingest.common.DateFormatTests"}, {"methodBody": ["METHOD_START", "{", "Function < String ,    DateTime >    function    =    DateFormat . Iso 8  6  0  1  . getFunction ( null ,    UTC ,    null )  ;", "try    {", "function . apply (  \"  2  0  0  1  -  0  1  -  0  :  0  0  -  0  8  0  0  \"  )  ;", "fail (  \" parse   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "}", "}", "METHOD_END"], "methodName": ["testParseISO8601Failure"], "fileName": "org.elasticsearch.ingest.common.DateFormatTests"}, {"methodBody": ["METHOD_START", "{", "Function < String ,    DateTime >    jodaFunction    =    DateFormat . Joda . getFunction (  \" MMM   dd   HH : mm : ss   Z \"  ,    DateTimeZone . forOffsetHours (  (  -  8  )  )  ,    Locale . ENGLISH )  ;", "assertThat ( Instant . ofEpochMilli ( jodaFunction . apply (  \" Nov    2  4     0  1  :  2  9  :  0  1     -  0  8  0  0  \"  )  . getMillis (  )  )  . atZone ( ZoneId . of (  \" GMT -  8  \"  )  )  . format ( DateTimeFormatter . ofPattern (  \" MM   dd   HH : mm : ss \"  ,    Locale . ENGLISH )  )  ,    equalTo (  \"  1  1     2  4     0  1  :  2  9  :  0  1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseJoda"], "fileName": "org.elasticsearch.ingest.common.DateFormatTests"}, {"methodBody": ["METHOD_START", "{", "assertThat ( DateFormat . Unix . getFunction ( null ,    UTC ,    null )  . apply (  \"  1  0  0  0  .  5  \"  )  . getMillis (  )  ,    equalTo (  1  0  0  0  5  0  0 L )  )  ;", "}", "METHOD_END"], "methodName": ["testParseUnix"], "fileName": "org.elasticsearch.ingest.common.DateFormatTests"}, {"methodBody": ["METHOD_START", "{", "assertThat ( DateFormat . UnixMs . getFunction ( null ,    UTC ,    null )  . apply (  \"  1  0  0  0  5  0  0  \"  )  . getMillis (  )  ,    equalTo (  1  0  0  0  5  0  0 L )  )  ;", "}", "METHOD_END"], "methodName": ["testParseUnixMs"], "fileName": "org.elasticsearch.ingest.common.DateFormatTests"}, {"methodBody": ["METHOD_START", "{", "assertThat ( DateFormat . Unix . getFunction ( null ,    UTC ,    null )  . apply (  \"  1  4  9  5  7  1  8  0  1  5  \"  )  . getMillis (  )  ,    equalTo (  1  4  9  5  7  1  8  0  1  5  0  0  0 L )  )  ;", "}", "METHOD_END"], "methodName": ["testParseUnixWithMsPrecision"], "fileName": "org.elasticsearch.ingest.common.DateFormatTests"}, {"methodBody": ["METHOD_START", "{", "String   input    =     \"  4  0  0  0  0  0  0  0  5  0 d 5  0  6  4  8  2 dbdf 0  2  4  \"  ;", "String   expected    =     \"  2  0  1  2  -  1  2  -  2  2 T 0  3  :  0  0  :  4  6  .  7  6  7  +  0  2  :  0  0  \"  ;", "assertThat (  . Tai 6  4 n . getFunction ( null ,    DateTimeZone . forOffsetHours (  2  )  ,    null )  . apply (  (  ( randomBoolean (  )     ?     \"  @  \"     :     \"  \"  )     +    input )  )  . toString (  )  ,    equalTo ( expected )  )  ;", "}", "METHOD_END"], "methodName": ["testTAI64NParse"], "fileName": "org.elasticsearch.ingest.common.DateFormatTests"}, {"methodBody": ["METHOD_START", "{", "DateIndexNameProcessor . Factory   factory    =    new   DateIndexNameProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" date _ rounding \"  ,     \" y \"  )  ;", "DateIndexNameProcessor   processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getDateFormats (  )  . size (  )  ,    Matchers . equalTo (  1  )  )  ;", "assertThat ( processor . getField (  )  ,    Matchers . equalTo (  \"  _ field \"  )  )  ;", "assertThat ( processor . getIndexNamePrefix (  )  ,    Matchers . equalTo (  \"  \"  )  )  ;", "assertThat ( processor . getDateRounding (  )  ,    Matchers . equalTo (  \" y \"  )  )  ;", "assertThat ( processor . getIndexNameFormat (  )  ,    Matchers . equalTo (  \" yyyy - MM - dd \"  )  )  ;", "assertThat ( processor . getTimezone (  )  ,    Matchers . equalTo ( UTC )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameFactoryTests"}, {"methodBody": ["METHOD_START", "{", "DateIndexNameProcessor . Factory   factory    =    new   DateIndexNameProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" date _ rounding \"  ,     \" y \"  )  ;", "ElasticsearchParseException   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    null ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    Matchers . equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "config . clear (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    null ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    Matchers . equalTo (  \"  [ date _ rounding ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRequiredFields"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameFactoryTests"}, {"methodBody": ["METHOD_START", "{", "DateIndexNameProcessor . Factory   factory    =    new   DateIndexNameProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" index _ name _ prefix \"  ,     \"  _ prefix \"  )  ;", "config . put (  \" date _ rounding \"  ,     \" y \"  )  ;", "config . put (  \" date _ formats \"  ,    Arrays . asList (  \" UNIX \"  ,     \" UNIX _ MS \"  )  )  ;", "DateIndexNameProcessor   processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getDateFormats (  )  . size (  )  ,    Matchers . equalTo (  2  )  )  ;", "config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" index _ name _ prefix \"  ,     \"  _ prefix \"  )  ;", "config . put (  \" date _ rounding \"  ,     \" y \"  )  ;", "config . put (  \" index _ name _ format \"  ,     \" yyyyMMdd \"  )  ;", "processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getIndexNameFormat (  )  ,    Matchers . equalTo (  \" yyyyMMdd \"  )  )  ;", "config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" index _ name _ prefix \"  ,     \"  _ prefix \"  )  ;", "config . put (  \" date _ rounding \"  ,     \" y \"  )  ;", "config . put (  \" timezone \"  ,     \"  +  0  2  :  0  0  \"  )  ;", "processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getTimezone (  )  ,    Matchers . equalTo ( DateTimeZone . forOffsetHours (  2  )  )  )  ;", "config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" index _ name _ prefix \"  ,     \"  _ prefix \"  )  ;", "config . put (  \" date _ rounding \"  ,     \" y \"  )  ;", "processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getIndexNamePrefix (  )  ,    Matchers . equalTo (  \"  _ prefix \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSpecifyOptionalSettings"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameFactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   dateFormats ;", "}", "METHOD_END"], "methodName": ["getDateFormats"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessor"}, {"methodBody": ["METHOD_START", "{", "return   dateRounding ;", "}", "METHOD_END"], "methodName": ["getDateRounding"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessor"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessor"}, {"methodBody": ["METHOD_START", "{", "return   indexNameFormat ;", "}", "METHOD_END"], "methodName": ["getIndexNameFormat"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessor"}, {"methodBody": ["METHOD_START", "{", "return   indexNamePrefix ;", "}", "METHOD_END"], "methodName": ["getIndexNamePrefix"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessor"}, {"methodBody": ["METHOD_START", "{", "return   timezone ;", "}", "METHOD_END"], "methodName": ["getTimezone"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessor"}, {"methodBody": ["METHOD_START", "{", "Function < String ,    DateTime >    function    =    DateFormat . Joda . getFunction (  \" yyyy - MM - dd ' T ' HH : mm : ss . SSSZ \"  ,    UTC ,    Locale . ROOT )  ;", "processor    =    new    (  \"  _ tag \"  ,     \"  _ field \"  ,    Collections . singletonList ( function )  ,    DateTimeZone . UTC ,     \" events -  \"  ,     \" y \"  ,     \" yyyyMMdd \"  )  ;", "IngestDocument   document    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \"  _ field \"  ,     \"  2  0  1  6  -  0  4  -  2  5 T 1  2  :  2  4  :  2  0  .  1  0  1 Z \"  )  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getSourceAndMetadata (  )  . get (  \"  _ index \"  )  ,    equalTo (  \"  < events -  {  2  0  1  6  0  4  2  5  |  |  / y { yyyyMMdd | UTC }  }  >  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testJodaPattern"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Function < String ,    DateTime >    function    =    DateFormat . Tai 6  4 n . getFunction ( null ,    UTC ,    null )  ;", "dateProcessor    =    new    (  \"  _ tag \"  ,     \"  _ field \"  ,    Collections . singletonList ( function )  ,    DateTimeZone . UTC ,     \" events -  \"  ,     \" m \"  ,     \" yyyyMMdd \"  )  ;", "IngestDocument   document    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \"  _ field \"  ,     (  ( randomBoolean (  )     ?     \"  @  \"     :     \"  \"  )     +     \"  4  0  0  0  0  0  0  0  5  0 d 5  0  6  4  8  2 dbdf 0  2  4  \"  )  )  )  ;", "dateProcessor . execute ( document )  ;", "assertThat ( document . getSourceAndMetadata (  )  . get (  \"  _ index \"  )  ,    equalTo (  \"  < events -  {  2  0  1  2  1  2  2  2  |  |  / m { yyyyMMdd | UTC }  }  >  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testTAI64N"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Function < String ,    DateTime >    function    =    DateFormat . Unix . getFunction ( null ,    UTC ,    null )  ;", "dateProcessor    =    new    (  \"  _ tag \"  ,     \"  _ field \"  ,    Collections . singletonList ( function )  ,    DateTimeZone . UTC ,     \" events -  \"  ,     \" m \"  ,     \" yyyyMMdd \"  )  ;", "IngestDocument   document    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \"  _ field \"  ,     \"  1  0  0  0  .  5  \"  )  )  ;", "dateProcessor . execute ( document )  ;", "assertThat ( document . getSourceAndMetadata (  )  . get (  \"  _ index \"  )  ,    equalTo (  \"  < events -  {  1  9  7  0  0  1  0  1  |  |  / m { yyyyMMdd | UTC }  }  >  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnix"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Function < String ,    DateTime >    function    =    DateFormat . UnixMs . getFunction ( null ,    UTC ,    null )  ;", "dateProcessor    =    new    (  \"  _ tag \"  ,     \"  _ field \"  ,    Collections . singletonList ( function )  ,    DateTimeZone . UTC ,     \" events -  \"  ,     \" m \"  ,     \" yyyyMMdd \"  )  ;", "IngestDocument   document    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \"  _ field \"  ,     \"  1  0  0  0  5  0  0  \"  )  )  ;", "dateProcessor . execute ( document )  ;", "assertThat ( document . getSourceAndMetadata (  )  . get (  \"  _ index \"  )  ,    equalTo (  \"  < events -  {  1  9  7  0  0  1  0  1  |  |  / m { yyyyMMdd | UTC }  }  >  \"  )  )  ;", "document    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \"  _ field \"  ,     1  0  0  0  5  0  0 L )  )  ;", "dateProcessor . execute ( document )  ;", "assertThat ( document . getSourceAndMetadata (  )  . get (  \"  _ index \"  )  ,    equalTo (  \"  < events -  {  1  9  7  0  0  1  0  1  |  |  / m { yyyyMMdd | UTC }  }  >  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnixMs"], "fileName": "org.elasticsearch.ingest.common.DateIndexNameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.DateProcessor"}, {"methodBody": ["METHOD_START", "{", "return   formats ;", "}", "METHOD_END"], "methodName": ["getFormats"], "fileName": "org.elasticsearch.ingest.common.DateProcessor"}, {"methodBody": ["METHOD_START", "{", "return   locale ;", "}", "METHOD_END"], "methodName": ["getLocale"], "fileName": "org.elasticsearch.ingest.common.DateProcessor"}, {"methodBody": ["METHOD_START", "{", "return   targetField ;", "}", "METHOD_END"], "methodName": ["getTargetField"], "fileName": "org.elasticsearch.ingest.common.DateProcessor"}, {"methodBody": ["METHOD_START", "{", "return   timezone ;", "}", "METHOD_END"], "methodName": ["getTimezone"], "fileName": "org.elasticsearch.ingest.common.DateProcessor"}, {"methodBody": ["METHOD_START", "{", "return    ( timezone )     =  =    null    ?    DateTimeZone . UTC    :    DateTimeZone . forID ( timezone . newInstance ( params )  . execute (  )  )  ;", "}", "METHOD_END"], "methodName": ["newDateTimeZone"], "fileName": "org.elasticsearch.ingest.common.DateProcessor"}, {"methodBody": ["METHOD_START", "{", "return    ( locale )     =  =    null    ?    Locale . ROOT    :    LocaleUtils . parse ( locale . newInstance ( params )  . execute (  )  )  ;", "}", "METHOD_END"], "methodName": ["newLocale"], "fileName": "org.elasticsearch.ingest.common.DateProcessor"}, {"methodBody": ["METHOD_START", "{", "factory    =    new   DateProcessor . Factory ( TestTemplateService . instance (  )  )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.ingest.common.DateProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   sourceField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "config . put (  \" field \"  ,    sourceField )  ;", "config . put (  \" formats \"  ,    Collections . singletonList (  \" dd / MM / yyyyy \"  )  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "processor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo ( sourceField )  )  ;", "assertThat ( processor . getTargetField (  )  ,    equalTo (  . DEFAULT _ TARGET _ FIELD )  )  ;", "assertThat ( processor . getFormats (  )  ,    equalTo ( Collections . singletonList (  \" dd / MM / yyyyy \"  )  )  )  ;", "assertNull ( processor . getLocale (  )  )  ;", "assertNull ( processor . getTimezone (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildDefaults"], "fileName": "org.elasticsearch.ingest.common.DateProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   targetField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "config . put (  \" target _ field \"  ,    targetField )  ;", "config . put (  \" formats \"  ,    Collections . singletonList (  \" dd / MM / yyyyy \"  )  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" processor   creation   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMatchFieldIsMandatory"], "fileName": "org.elasticsearch.ingest.common.DateProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   sourceField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "String   targetField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "config . put (  \" field \"  ,    sourceField )  ;", "config . put (  \" target _ field \"  ,    targetField )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" processor   creation   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \"  [ formats ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMatchFormatsIsMandatory"], "fileName": "org.elasticsearch.ingest.common.DateProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   sourceField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "config . put (  \" field \"  ,    sourceField )  ;", "config . put (  \" formats \"  ,    Collections . singletonList (  \" dd / MM / yyyyy \"  )  )  ;", "Locale   locale    =    randomFrom ( Locale . GERMANY ,    Locale . FRENCH ,    Locale . ROOT )  ;", "config . put (  \" locale \"  ,    locale . toLanguageTag (  )  )  ;", "processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getLocale (  )  . newInstance ( Collections . emptyMap (  )  )  . execute (  )  ,    equalTo ( locale . toLanguageTag (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseLocale"], "fileName": "org.elasticsearch.ingest.common.DateProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   sourceField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "config . put (  \" field \"  ,    sourceField )  ;", "config . put (  \" formats \"  ,    Arrays . asList (  \" dd / MM / yyyy \"  ,     \" dd - MM - yyyy \"  )  )  ;", "processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getFormats (  )  ,    equalTo ( Arrays . asList (  \" dd / MM / yyyy \"  ,     \" dd - MM - yyyy \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseMatchFormats"], "fileName": "org.elasticsearch.ingest.common.DateProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   sourceField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "config . put (  \" field \"  ,    sourceField )  ;", "config . put (  \" formats \"  ,     \" dd / MM / yyyy \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" processor   creation   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \"  [ formats ]    property   isn ' t   a   list ,    but   of   type    [ String ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testParseMatchFormatsFailure"], "fileName": "org.elasticsearch.ingest.common.DateProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   sourceField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "String   targetField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "config . put (  \" field \"  ,    sourceField )  ;", "config . put (  \" target _ field \"  ,    targetField )  ;", "config . put (  \" formats \"  ,    Arrays . asList (  \" dd / MM / yyyy \"  ,     \" dd - MM - yyyy \"  )  )  ;", "processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getTargetField (  )  ,    equalTo ( targetField )  )  ;", "}", "METHOD_END"], "methodName": ["testParseTargetField"], "fileName": "org.elasticsearch.ingest.common.DateProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   sourceField    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "config . put (  \" field \"  ,    sourceField )  ;", "config . put (  \" formats \"  ,    Collections . singletonList (  \" dd / MM / yyyyy \"  )  )  ;", "DateTimeZone   timezone    =    randomDateTimeZone (  )  ;", "config . put (  \" timezone \"  ,    timezone . getID (  )  )  ;", "processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getTimezone (  )  . newInstance ( Collections . emptyMap (  )  )  . execute (  )  ,    equalTo ( timezone . getID (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseTimezone"], "fileName": "org.elasticsearch.ingest.common.DateProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   new   TestTemplateService . MockTemplateScript . Factory ( locale . getLanguage (  )  )  ;", "}", "METHOD_END"], "methodName": ["templatize"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   new   Factory ( timezone . getID (  )  )  ;", "}", "METHOD_END"], "methodName": ["templatize"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "try    {", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    templatize ( UTC )  ,    templatize ( randomLocale ( random (  )  )  )  ,     \" date _ as _ string \"  ,    Collections . singletonList (  \" invalid   pattern \"  )  ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  2  0  1  0  \"  )  ;", "processor . execute ( RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  )  ;", "fail (  \" date   processor   execution   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \" unable   to   parse   date    [  2  0  1  0  ]  \"  )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    equalTo (  \" Illegal   pattern   component :    i \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testInvalidJodaPattern"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "DateProcessor   processor    =    new   DateProcessor ( randomAlphaOfLength (  1  0  )  ,    templatize ( UTC )  ,    new   TestTemplateService . MockTemplateScript . Factory (  \" invalid _ locale \"  )  ,     \" date _ as _ string \"  ,    Collections . singletonList (  \" yyyy \"  )  ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  2  0  1  0  \"  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    processor . execute ( RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" unable   to   parse   date    [  2  0  1  0  ]  \"  )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    equalTo (  \" Unknown   language :    invalid \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidLocale"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "DateProcessor   processor    =    new   DateProcessor ( randomAlphaOfLength (  1  0  )  ,    new   TestTemplateService . MockTemplateScript . Factory (  \" invalid _ timezone \"  )  ,    templatize ( randomLocale ( random (  )  )  )  ,     \" date _ as _ string \"  ,    Collections . singletonList (  \" yyyy \"  )  ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  2  0  1  0  \"  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    processor . execute ( RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" unable   to   parse   date    [  2  0  1  0  ]  \"  )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    equalTo (  \" The   datetime   zone   id    ' invalid _ timezone '    is   not   recognised \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidTimezone"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "DateProcessor   dateProcessor    =    new   DateProcessor ( randomAlphaOfLength (  1  0  )  ,    templatize ( DateTimeZone . forID (  \" Europe / Amsterdam \"  )  )  ,    templatize ( Locale . ENGLISH )  ,     \" date _ as _ string \"  ,    Collections . singletonList (  \" yyyy   dd   MM   hh : mm : ss \"  )  ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  2  0  1  0     1  2     0  6     1  1  :  0  5  :  1  5  \"  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  \"  2  0  1  0  -  0  6  -  1  2 T 1  1  :  0  5  :  1  5  .  0  0  0  +  0  2  :  0  0  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testJodaPattern"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "DateProcessor   dateProcessor    =    new   DateProcessor ( randomAlphaOfLength (  1  0  )  ,    templatize ( DateTimeZone . forID (  \" Europe / Amsterdam \"  )  )  ,    templatize ( Locale . ENGLISH )  ,     \" date _ as _ string \"  ,    Collections . singletonList (  \" dd / MM \"  )  ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  1  2  /  0  6  \"  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  (  ( DateTime . now (  )  . getYear (  )  )     +     \"  -  0  6  -  1  2 T 0  0  :  0  0  :  0  0  .  0  0  0  +  0  2  :  0  0  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testJodaPatternDefaultYear"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "DateProcessor   dateProcessor    =    new   DateProcessor ( randomAlphaOfLength (  1  0  )  ,    templatize ( DateTimeZone . forID (  \" Europe / Amsterdam \"  )  )  ,    templatize ( Locale . ITALIAN )  ,     \" date _ as _ string \"  ,    Collections . singletonList (  \" yyyy   dd   MMM \"  )  ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  2  0  1  0     1  2    giugno \"  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  \"  2  0  1  0  -  0  6  -  1  2 T 0  0  :  0  0  :  0  0  .  0  0  0  +  0  2  :  0  0  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testJodaPatternLocale"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "List < String >    matchFormats    =    new   ArrayList <  >  (  )  ;", "matchFormats . add (  \" yyyy   dd   MM \"  )  ;", "matchFormats . add (  \" dd / MM / yyyy \"  )  ;", "matchFormats . add (  \" dd - MM - yyyy \"  )  ;", "dateProcessor    =    new    ( randomAlphaOfLength (  1  0  )  ,    templatize ( DateTimeZone . forID (  \" Europe / Amsterdam \"  )  )  ,    templatize ( Locale . ENGLISH )  ,     \" date _ as _ string \"  ,    matchFormats ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  2  0  1  0     1  2     0  6  \"  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  \"  2  0  1  0  -  0  6  -  1  2 T 0  0  :  0  0  :  0  0  .  0  0  0  +  0  2  :  0  0  \"  )  )  ;", "document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  1  2  /  0  6  /  2  0  1  0  \"  )  ;", "ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  \"  2  0  1  0  -  0  6  -  1  2 T 0  0  :  0  0  :  0  0  .  0  0  0  +  0  2  :  0  0  \"  )  )  ;", "document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  1  2  -  0  6  -  2  0  1  0  \"  )  ;", "ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  \"  2  0  1  0  -  0  6  -  1  2 T 0  0  :  0  0  :  0  0  .  0  0  0  +  0  2  :  0  0  \"  )  )  ;", "document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  2  0  1  0  \"  )  ;", "ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "try    {", "dateProcessor . execute ( ingestDocument )  ;", "fail (  \" processor   should   have   failed   due   to   not   supported   date   format \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \" unable   to   parse   date    [  2  0  1  0  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testJodaPatternMultipleFormats"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "DateProcessor   dateProcessor    =    new   DateProcessor ( randomAlphaOfLength (  1  0  )  ,    templatize ( DateTimeZone . forOffsetHours (  2  )  )  ,    templatize ( randomLocale ( random (  )  )  )  ,     \" date _ as _ string \"  ,    Collections . singletonList (  \" TAI 6  4 N \"  )  ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "String   dateAsString    =     ( randomBoolean (  )     ?     \"  @  \"     :     \"  \"  )     +     \"  4  0  0  0  0  0  0  0  5  0 d 5  0  6  4  8  2 dbdf 0  2  4  \"  ;", "document . put (  \" date _ as _ string \"  ,    dateAsString )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  \"  2  0  1  2  -  1  2  -  2  2 T 0  3  :  0  0  :  4  6  .  7  6  7  +  0  2  :  0  0  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testTAI64N"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "DateProcessor   dateProcessor    =    new   DateProcessor ( randomAlphaOfLength (  1  0  )  ,    templatize ( UTC )  ,    templatize ( randomLocale ( random (  )  )  )  ,     \" date _ as _ string \"  ,    Collections . singletonList (  \" UNIX \"  )  ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  1  0  0  0  .  5  \"  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  \"  1  9  7  0  -  0  1  -  0  1 T 0  0  :  1  6  :  4  0  .  5  0  0 Z \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnix"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "DateProcessor   dateProcessor    =    new   DateProcessor ( randomAlphaOfLength (  1  0  )  ,    templatize ( UTC )  ,    templatize ( randomLocale ( random (  )  )  )  ,     \" date _ as _ string \"  ,    Collections . singletonList (  \" UNIX _ MS \"  )  ,     \" date _ as _ date \"  )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     \"  1  0  0  0  5  0  0  \"  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  \"  1  9  7  0  -  0  1  -  0  1 T 0  0  :  1  6  :  4  0  .  5  0  0 Z \"  )  )  ;", "document    =    new   HashMap <  >  (  )  ;", "document . put (  \" date _ as _ string \"  ,     1  0  0  0  5  0  0 L )  ;", "ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "dateProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" date _ as _ date \"  ,    String . class )  ,    equalTo (  \"  1  9  7  0  -  0  1  -  0  1 T 0  0  :  1  6  :  4  0  .  5  0  0 Z \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnixMs"], "fileName": "org.elasticsearch.ingest.common.DateProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.DotExpanderProcessor"}, {"methodBody": ["METHOD_START", "{", "return   path ;", "}", "METHOD_END"], "methodName": ["getPath"], "fileName": "org.elasticsearch.ingest.common.DotExpanderProcessor"}, {"methodBody": ["METHOD_START", "{", "DotExpanderProcessor . Factory   factory    =    new   DotExpanderProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field . field \"  )  ;", "config . put (  \" path \"  ,     \"  _ path \"  )  ;", "DotExpanderProcessor   processor    =     (  ( DotExpanderProcessor )     ( factory . create ( null ,     \"  _ tag \"  ,    config )  )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo (  \"  _ field . field \"  )  )  ;", "assertThat ( processor . getPath (  )  ,    equalTo (  \"  _ path \"  )  )  ;", "config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field . field \"  )  ;", "processor    =     (  ( DotExpanderProcessor )     ( factory . create ( null ,     \"  _ tag \"  ,    config )  )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo (  \"  _ field . field \"  )  )  ;", "assertThat ( processor . getPath (  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.DotExpanderProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "DotExpanderProcessor . Factory   factory    =    new   DotExpanderProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" path \"  ,     \"  _ path \"  )  ;", "Exception   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,     \"  _ tag \"  ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate_fieldMissing"], "fileName": "org.elasticsearch.ingest.common.DotExpanderProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "DotExpanderProcessor . Factory   factory    =    new   DotExpanderProcessor . Factory (  )  ;", "String [  ]    fields    =    new   String [  ]  {     \" a \"  ,     \" abc \"     }  ;", "for    ( String   field    :    fields )     {", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    field )  ;", "Exception   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,     \"  _ tag \"  ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    field   does   not   contain   a   dot \"  )  )  ;", "}", "fields    =    new   String [  ]  {     \"  . a \"  ,     \" a .  \"  ,     \"  .  \"     }  ;", "for    ( String   field    :    fields )     {", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    field )  ;", "Exception   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,     \"  _ tag \"  ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    Field   can ' t   start   or   end   with   a   dot \"  )  )  ;", "}", "fields    =    new   String [  ]  {     \" a .  . b \"  ,     \" a .  .  . b \"  ,     \" a . b .  . c \"  ,     \" abc . def .  . hij \"     }  ;", "for    ( String   field    :    fields )     {", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    field )  ;", "Exception   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,     \"  _ tag \"  ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    No   space   between   dots \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreate_invalidFields"], "fileName": "org.elasticsearch.ingest.common.DotExpanderProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "DotExpanderProcessor . Factory   factory    =    new   DotExpanderProcessor . Factory (  )  ;", "String [  ]    fields    =    new   String [  ]  {     \" a . b \"  ,     \" a . b . c \"  ,     \" a . b . c . d \"  ,     \" ab . cd \"     }  ;", "for    ( String   field    :    fields )     {", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    field )  ;", "config . put (  \" path \"  ,     \"  _ path \"  )  ;", "DotExpanderProcessor   processor    =     (  ( DotExpanderProcessor )     ( factory . create ( null ,     \"  _ tag \"  ,    config )  )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo ( field )  )  ;", "assertThat ( processor . getPath (  )  ,    equalTo (  \"  _ path \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testValidFields"], "fileName": "org.elasticsearch.ingest.common.DotExpanderProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo . bar \"  ,     \" baz 1  \"  )  ;", "IngestDocument   document    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "processor    =    new    (  \"  _ tag \"  ,    null ,     \" foo . bar \"  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getFieldValue (  \" foo \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar \"  ,    String . class )  ,    equalTo (  \" baz 1  \"  )  )  ;", "source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo . bar . baz \"  ,     \" value \"  )  ;", "document    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "processor    =    new    (  \"  _ tag \"  ,    null ,     \" foo . bar . baz \"  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getFieldValue (  \" foo \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar . baz \"  ,    String . class )  ,    equalTo (  \" value \"  )  )  ;", "source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo . bar \"  ,     \" baz 1  \"  )  ;", "source . put (  \" foo \"  ,    new   HashMap <  >  ( Collections . singletonMap (  \" bar \"  ,     \" baz 2  \"  )  )  )  ;", "document    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "processor    =    new    (  \"  _ tag \"  ,    null ,     \" foo . bar \"  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getSourceAndMetadata (  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar \"  ,    List . class )  . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar .  0  \"  ,    String . class )  ,    equalTo (  \" baz 2  \"  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar .  1  \"  ,    String . class )  ,    equalTo (  \" baz 1  \"  )  )  ;", "source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo . bar \"  ,     \"  2  \"  )  ;", "source . put (  \" foo \"  ,    new   HashMap <  >  ( Collections . singletonMap (  \" bar \"  ,     1  )  )  )  ;", "document    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "processor    =    new    (  \"  _ tag \"  ,    null ,     \" foo . bar \"  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getSourceAndMetadata (  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar \"  ,    List . class )  . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar .  0  \"  ,    Integer . class )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar .  1  \"  ,    String . class )  ,    equalTo (  \"  2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEscapeFields"], "fileName": "org.elasticsearch.ingest.common.DotExpanderProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo \"  ,    new   HashMap <  >  ( Collections . singletonMap (  \" bar . baz \"  ,     \" value \"  )  )  )  ;", "IngestDocument   document    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "processor    =    new    (  \"  _ tag \"  ,     \" foo \"  ,     \" bar . baz \"  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getFieldValue (  \" foo \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar . baz \"  ,    String . class )  ,    equalTo (  \" value \"  )  )  ;", "source    =    new   HashMap <  >  (  )  ;", "source . put (  \" field \"  ,    new   HashMap <  >  ( Collections . singletonMap (  \" foo . bar . baz \"  ,     \" value \"  )  )  )  ;", "document    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "processor    =    new    (  \"  _ tag \"  ,     \" field \"  ,     \" foo . bar . baz \"  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getFieldValue (  \" field . foo \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" field . foo . bar \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" field . foo . bar . baz \"  ,    String . class )  ,    equalTo (  \" value \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEscapeFields_path"], "fileName": "org.elasticsearch.ingest.common.DotExpanderProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo . bar \"  ,     \" baz 1  \"  )  ;", "source . put (  \" foo \"  ,     \" baz 2  \"  )  ;", "IngestDocument   document 1     =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "Processor   processor 1     =    new    (  \"  _ tag \"  ,    null ,     \" foo . bar \"  )  ;", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    processor 1  . execute ( document 1  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" cannot   expend    [ foo . bar ]  ,    because    [ foo ]    is   not   an   object   field ,    but   a   value   field \"  )  )  ;", "IngestDocument   document    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "Processor   processor    =    new   RenameProcessor (  \"  _ tag \"  ,     \" foo \"  ,     \" foo . bar \"  ,    false )  ;", "processor . execute ( document )  ;", "processor    =    new    (  \"  _ tag \"  ,    null ,     \" foo . bar \"  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getFieldValue (  \" foo \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar .  0  \"  ,    String . class )  ,    equalTo (  \" baz 2  \"  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar .  1  \"  ,    String . class )  ,    equalTo (  \" baz 1  \"  )  )  ;", "source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo . bar \"  ,     \" baz 1  \"  )  ;", "document    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "processor    =    new    (  \"  _ tag \"  ,    null ,     \" foo . bar \"  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getFieldValue (  \" foo \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar \"  ,    String . class )  ,    equalTo (  \" baz 1  \"  )  )  ;", "source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo . bar . baz \"  ,     \" baz 1  \"  )  ;", "source . put (  \" foo \"  ,    new   HashMap <  >  ( Collections . singletonMap (  \" bar \"  ,    new   HashMap <  >  (  )  )  )  )  ;", "document    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "processor    =    new    (  \"  _ tag \"  ,    null ,     \" foo . bar . baz \"  )  ;", "processor . execute ( document )  ;", "assertThat ( document . getFieldValue (  \" foo \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar \"  ,    Map . class )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getFieldValue (  \" foo . bar . baz \"  ,    String . class )  ,    equalTo (  \" baz 1  \"  )  )  ;", "source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo . bar . baz \"  ,     \" baz 1  \"  )  ;", "source . put (  \" foo \"  ,    new   HashMap <  >  ( Collections . singletonMap (  \" bar \"  ,     \" baz 2  \"  )  )  )  ;", "IngestDocument   document 2     =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "Processor   processor 2     =    new    (  \"  _ tag \"  ,    null ,     \" foo . bar . baz \"  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    processor 2  . execute ( document 2  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" cannot   expend    [ foo . bar . baz ]  ,    because    [ foo . bar ]    is   not   an   object   field ,    but   a   value   field \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEscapeFields_valueField"], "fileName": "org.elasticsearch.ingest.common.DotExpanderProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   message ;", "}", "METHOD_END"], "methodName": ["getMessage"], "fileName": "org.elasticsearch.ingest.common.FailProcessor"}, {"methodBody": ["METHOD_START", "{", "factory    =    new   FailProcessor . Factory ( TestTemplateService . instance (  )  )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.ingest.common.FailProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" message \"  ,     \" error \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "failProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( failProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( failProcessor . getMessage (  )  . newInstance ( Collections . emptyMap (  )  )  . execute (  )  ,    equalTo (  \" error \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.FailProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ message ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateMissingMessageField"], "fileName": "org.elasticsearch.ingest.common.FailProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "FailProcessor . Factory   factory    =    new   FailProcessor . Factory ( TestTemplateService . instance ( true )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" message \"  ,     \" error \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchException . class ,     (  )     -  >    factory . create ( null ,    processorTag ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \" RuntimeException :    could   not   compile   script \"  )  )  ;", "assertThat ( exception . getHeader (  \" processor _ tag \"  )  . get (  0  )  ,    equalTo ( processorTag )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidMustacheTemplate"], "fileName": "org.elasticsearch.ingest.common.FailProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   message    =    randomAlphaOfLength (  1  0  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    new   TestTemplateService . MockTemplateScript . Factory ( message )  )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" fail   processor   should   throw   an   exception \"  )  ;", "}    catch    ( Exception   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo ( message )  )  ;", "}", "}", "METHOD_END"], "methodName": ["test"], "fileName": "org.elasticsearch.ingest.common.FailProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessor"}, {"methodBody": ["METHOD_START", "{", "return   processor ;", "}", "METHOD_END"], "methodName": ["getProcessor"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessor"}, {"methodBody": ["METHOD_START", "{", "Processor   processor    =    new   TestProcessor (  (    ingestDocument )     -  >     {", "}  )  ;", "Map < String ,    Processor . Factory >    registry    =    new   HashMap <  >  (  )  ;", "registry . put (  \"  _ name \"  ,     (    r ,    t ,    c )     -  >    processor )  ;", ". Factory   forEachFactory    =    new    . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" processor \"  ,    Collections . singletonMap (  \"  _ name \"  ,    Collections . emptyMap (  )  )  )  ;", "forEachProcessor    =    forEachFactory . create ( registry ,    null ,    config )  ;", "assertThat ( forEachProcessor ,    Matchers . notNullValue (  )  )  ;", "assertThat ( forEachProcessor . getField (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( forEachProcessor . getProcessor (  )  ,    Matchers . sameInstance ( processor )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Processor   processor    =    new   TestProcessor (  (    ingestDocument )     -  >     {", "}  )  ;", "Map < String ,    Processor . Factory >    registry    =    new   HashMap <  >  (  )  ;", "registry . put (  \"  _ name \"  ,     (    r ,    t ,    c )     -  >    processor )  ;", ". Factory   forEachFactory    =    new    . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" processor \"  ,    Collections . singletonList ( Collections . singletonMap (  \"  _ name \"  ,    Collections . emptyMap (  )  )  )  )  ;", "Exception   exception    =    expectThrows ( Exception . class ,     (  )     -  >    forEachFactory . create ( registry ,    null ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithMissingField"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ForEachProcessor . Factory   forEachFactory    =    new   ForEachProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "Exception   exception    =    expectThrows ( Exception . class ,     (  )     -  >    forEachFactory . create ( Collections . emptyMap (  )  ,    null ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \"  [ processor ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithMissingProcessor"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "ForEachProcessor . Factory   forEachFactory    =    new   ForEachProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" processor \"  ,    Collections . singletonMap (  \"  _ name \"  ,    Collections . emptyMap (  )  )  )  ;", "Exception   expectedException    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    forEachFactory . create ( Collections . emptyMap (  )  ,    null ,    config )  )  ;", "assertThat ( expectedException . getMessage (  )  ,    equalTo (  \" No   processor   type   exists   with   name    [  _ name ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithNonExistingProcessorType"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Processor   processor    =    new   TestProcessor (  (    ingestDocument )     -  >     {", "}  )  ;", "Map < String ,    Processor . Factory >    registry    =    new   HashMap <  >  (  )  ;", "registry . put (  \"  _ first \"  ,     (    r ,    t ,    c )     -  >    processor )  ;", "registry . put (  \"  _ second \"  ,     (    r ,    t ,    c )     -  >    processor )  ;", ". Factory   forEachFactory    =    new    . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "Map < String ,    Object >    processorTypes    =    new   HashMap <  >  (  )  ;", "processorTypes . put (  \"  _ first \"  ,    Collections . emptyMap (  )  )  ;", "processorTypes . put (  \"  _ second \"  ,    Collections . emptyMap (  )  )  ;", "config . put (  \" processor \"  ,    processorTypes )  ;", "Exception   exception    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    forEachFactory . create ( registry ,    null ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \"  [ processor ]    Must   specify   exactly   one   processor   type \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithTooManyProcessorTypes"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "List < String >    values    =    new   ArrayList <  >  (  )  ;", "values . add (  \" foo \"  )  ;", "values . add (  \" bar \"  )  ;", "values . add (  \" baz \"  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \" values \"  ,    values )  )  ;", "processor    =    new    (  \"  _ tag \"  ,     \" values \"  ,    new   UppercaseProcessor (  \"  _ tag \"  ,     \"  _ ingest .  _ value \"  ,    false ,     \"  _ ingest .  _ value \"  )  )  ;", "processor . execute ( ingestDocument )  ;", "List   result    =    ingestDocument . getFieldValue (  \" values \"  ,    List . class )  ;", "assertThat ( result . get (  0  )  ,    equalTo (  \" FOO \"  )  )  ;", "assertThat ( result . get (  1  )  ,    equalTo (  \" BAR \"  )  )  ;", "assertThat ( result . get (  2  )  ,    equalTo (  \" BAZ \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExecute"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \" values \"  ,    Arrays . asList (  \" a \"  ,     \" b \"  ,     \" c \"  )  )  )  ;", "TestProcessor   testProcessor    =    new   TestProcessor (  (    id )     -  >     {", "if    (  \" c \"  . equals ( id . getFieldValue (  \"  _ ingest .  _ value \"  ,     . class )  )  )     {", "throw   new   RuntimeException (  \" failure \"  )  ;", "}", "}  )  ;", "ForEachProcessor   processor    =    new   ForEachProcessor (  \"  _ tag \"  ,     \" values \"  ,    testProcessor )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" exception   expected \"  )  ;", "}    catch    ( RuntimeException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \" failure \"  )  )  ;", "}", "assertThat ( testProcessor . getInvokedCounter (  )  ,    equalTo (  3  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values \"  ,    List . class )  ,    equalTo ( Arrays . asList (  \" a \"  ,     \" b \"  ,     \" c \"  )  )  )  ;", "testProcessor    =    new   TestProcessor (  (    id )     -  >     {", "String   value    =    id . getFieldValue (  \"  _ ingest .  _ value \"  ,     . class )  ;", "if    (  \" c \"  . equals ( value )  )     {", "throw   new   RuntimeException (  \" failure \"  )  ;", "} else    {", "id . setFieldValue (  \"  _ ingest .  _ value \"  ,    value . toUpperCase ( Locale . ROOT )  )  ;", "}", "}  )  ;", "Processor   onFailureProcessor    =    new   TestProcessor (  (    ingestDocument 1  )     -  >     {", "}  )  ;", "processor    =    new   ForEachProcessor (  \"  _ tag \"  ,     \" values \"  ,    new   CompoundProcessor ( false ,    Arrays . asList ( testProcessor )  ,    Arrays . asList ( onFailureProcessor )  )  )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( testProcessor . getInvokedCounter (  )  ,    equalTo (  3  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values \"  ,    List . class )  ,    equalTo ( Arrays . asList (  \" A \"  ,     \" B \"  ,     \" c \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExecuteWithFailure"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorTests"}, {"methodBody": ["METHOD_START", "{", "List < Map < String ,    Object >  >    values    =    new   ArrayList <  >  (  )  ;", "values . add ( new   HashMap <  >  (  )  )  ;", "values . add ( new   HashMap <  >  (  )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \" values \"  ,    values )  )  ;", "TestProcessor   innerProcessor    =    new   TestProcessor (  (    id )     -  >     {", "id . setFieldValue (  \"  _ ingest .  _ value . index \"  ,    id . getSourceAndMetadata (  )  . get (  \"  _ index \"  )  )  ;", "id . setFieldValue (  \"  _ ingest .  _ value . type \"  ,    id . getSourceAndMetadata (  )  . get (  \"  _ type \"  )  )  ;", "id . setFieldValue (  \"  _ ingest .  _ value . id \"  ,    id . getSourceAndMetadata (  )  . get (  \"  _ id \"  )  )  ;", "}  )  ;", "processor    =    new    (  \"  _ tag \"  ,     \" values \"  ,    innerProcessor )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( innerProcessor . getInvokedCounter (  )  ,    equalTo (  2  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  0  . index \"  ,    String . class )  ,    equalTo (  \"  _ index \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  0  . type \"  ,    String . class )  ,    equalTo (  \"  _ type \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  0  . id \"  ,    String . class )  ,    equalTo (  \"  _ id \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  1  . index \"  ,    String . class )  ,    equalTo (  \"  _ index \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  1  . type \"  ,    String . class )  ,    equalTo (  \"  _ type \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  1  . id \"  ,    String . class )  ,    equalTo (  \"  _ id \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMetaDataAvailable"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorTests"}, {"methodBody": ["METHOD_START", "{", "List < Object >    values    =    new   ArrayList <  >  (  )  ;", "values . add (  \" string \"  )  ;", "values . add (  1  )  ;", "values . add ( null )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \" values \"  ,    values )  )  ;", "TemplateScript . Factory   template    =    new   TestTemplateService . MockTemplateScript . Factory (  \" errors \"  )  ;", "ForEachProcessor   processor    =    new   ForEachProcessor (  \"  _ tag \"  ,     \" values \"  ,    new   CompoundProcessor ( false ,    Collections . singletonList ( new   UppercaseProcessor (  \"  _ tag _ upper \"  ,     \"  _ ingest .  _ value \"  ,    false ,     \"  _ ingest .  _ value \"  )  )  ,    Collections . singletonList ( new   AppendProcessor (  \"  _ tag \"  ,    template ,     (    model )     -  >    Collections . singletonList (  \" added \"  )  )  )  )  )  ;", "processor . execute ( ingestDocument )  ;", "List   result    =    ingestDocument . getFieldValue (  \" values \"  ,    List . class )  ;", "assertThat ( result . get (  0  )  ,    equalTo (  \" STRING \"  )  )  ;", "assertThat ( result . get (  1  )  ,    equalTo (  1  )  )  ;", "assertThat ( result . get (  2  )  ,    equalTo ( null )  )  ;", "List   errors    =    ingestDocument . getFieldValue (  \" errors \"  ,    List . class )  ;", "assertThat ( errors . size (  )  ,    equalTo (  2  )  )  ;", "}", "METHOD_END"], "methodName": ["testModifyFieldsOutsideArray"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorTests"}, {"methodBody": ["METHOD_START", "{", "List < Map < String ,    Object >  >    values    =    new   ArrayList <  >  (  )  ;", "List < Object >    innerValues    =    new   ArrayList <  >  (  )  ;", "innerValues . add (  \" abc \"  )  ;", "innerValues . add (  \" def \"  )  ;", "Map < String ,    Object >    value    =    new   HashMap <  >  (  )  ;", "value . put (  \" values 2  \"  ,    innerValues )  ;", "values . add ( value )  ;", "innerValues    =    new   ArrayList <  >  (  )  ;", "innerValues . add (  \" ghi \"  )  ;", "innerValues . add (  \" jkl \"  )  ;", "value    =    new   HashMap <  >  (  )  ;", "value . put (  \" values 2  \"  ,    innerValues )  ;", "values . add ( value )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \" values 1  \"  ,    values )  )  ;", "TestProcessor   testProcessor    =    new   TestProcessor (  (    doc )     -  >    doc . setFieldValue (  \"  _ ingest .  _ value \"  ,    doc . getFieldValue (  \"  _ ingest .  _ value \"  ,     . class )  . toUpperCase ( Locale . ENGLISH )  )  )  ;", "processor    =    new    (  \"  _ tag \"  ,     \" values 1  \"  ,    new    (  \"  _ tag \"  ,     \"  _ ingest .  _ value . values 2  \"  ,    testProcessor )  )  ;", "processor . execute ( ingestDocument )  ;", "List   result    =    ingestDocument . getFieldValue (  \" values 1  .  0  . values 2  \"  ,    List . class )  ;", "assertThat ( result . get (  0  )  ,    equalTo (  \" ABC \"  )  )  ;", "assertThat ( result . get (  1  )  ,    equalTo (  \" DEF \"  )  )  ;", "result    =    ingestDocument . getFieldValue (  \" values 1  .  1  . values 2  \"  ,    List . class )  ;", "assertThat ( result . get (  0  )  ,    equalTo (  \" GHI \"  )  )  ;", "assertThat ( result . get (  1  )  ,    equalTo (  \" JKL \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNestedForEach"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Processor   innerProcessor    =    new   Processor (  )     {", "@ Override", "public   void   execute ( IngestDocument   ingestDocument )    throws   Exception    {", "String   existingValue    =    ingestDocument . getFieldValue (  \"  _ ingest .  _ value \"  ,    String . class )  ;", "ingestDocument . setFieldValue (  \"  _ ingest .  _ value \"  ,     ( existingValue    +     \"  .  \"  )  )  ;", "}", "@ Override", "public   String   getType (  )     {", "return   null ;", "}", "@ Override", "public   String   getTag (  )     {", "return   null ;", "}", "}  ;", "int   numValues    =    randomIntBetween (  1  ,     3  2  )  ;", "List < String >    values    =    new   ArrayList <  >  ( numValues )  ;", "for    ( int   i    =     0  ;    i    <    numValues ;    i +  +  )     {", "values . add (  \"  \"  )  ;", "}", "IngestDocument   ingestDocument    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    Collections . singletonMap (  \" values \"  ,    values )  )  ;", "processor    =    new    (  \"  _ tag \"  ,     \" values \"  ,    innerProcessor )  ;", "processor . execute ( ingestDocument )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "List < String >    result    =    ingestDocument . getFieldValue (  \" values \"  ,    List . class )  ;", "assertThat ( result . size (  )  ,    equalTo ( numValues )  )  ;", "for    ( String   r    :    result )     {", "assertThat ( r ,    equalTo (  \"  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRandom"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorTests"}, {"methodBody": ["METHOD_START", "{", "List < Map < String ,    Object >  >    values    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     5  ;    i +  +  )     {", "Map < String ,    Object >    object    =    new   HashMap <  >  (  )  ;", "object . put (  \" field \"  ,     \" value \"  )  ;", "values . add ( object )  ;", "}", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" values \"  ,    values )  ;", "document . put (  \" flat _ values \"  ,    new   ArrayList <  >  (  )  )  ;", "document . put (  \" other \"  ,     \" value \"  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    document )  ;", "processor    =    new    (  \"  _ tag \"  ,     \" values \"  ,    new   SetProcessor (  \"  _ tag \"  ,    new   TestTemplateService . MockTemplateScript . Factory (  \"  _ ingest .  _ value . new _ field \"  )  ,     (    model )     -  >    model . get (  \" other \"  )  )  )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  0  . new _ field \"  ,    String . class )  ,    equalTo (  \" value \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  1  . new _ field \"  ,    String . class )  ,    equalTo (  \" value \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  2  . new _ field \"  ,    String . class )  ,    equalTo (  \" value \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  3  . new _ field \"  ,    String . class )  ,    equalTo (  \" value \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" values .  4  . new _ field \"  ,    String . class )  ,    equalTo (  \" value \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRestOfTheDocumentIsAvailable"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorTests"}, {"methodBody": ["METHOD_START", "{", "List < Object >    values    =    new   ArrayList <  >  (  )  ;", "values . add (  \" please \"  )  ;", "values . add (  \" change \"  )  ;", "values . add (  \" me \"  )  ;", "Map < String ,    Object >    source    =    new   HashMap <  >  (  )  ;", "source . put (  \"  _ value \"  ,     \" new _ value \"  )  ;", "source . put (  \" values \"  ,    values )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument (  \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null ,    source )  ;", "TestProcessor   processor    =    new   TestProcessor (  (    doc )     -  >    doc . setFieldValue (  \"  _ ingest .  _ value \"  ,    doc . getFieldValue (  \"  _ source .  _ value \"  ,     . class )  )  )  ;", "forEachProcessor    =    new    (  \"  _ tag \"  ,     \" values \"  ,    processor )  ;", "forEachProcessor . execute ( ingestDocument )  ;", "List   result    =    ingestDocument . getFieldValue (  \" values \"  ,    List . class )  ;", "assertThat ( result . get (  0  )  ,    equalTo (  \" new _ value \"  )  )  ;", "assertThat ( result . get (  1  )  ,    equalTo (  \" new _ value \"  )  )  ;", "assertThat ( result . get (  2  )  ,    equalTo (  \" new _ value \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testScalarValueAllowsUnderscoreValueFieldToRemainAccessible"], "fileName": "org.elasticsearch.ingest.common.ForEachProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   combinedPattern ;", "if    (  ( patterns . size (  )  )     >     1  )     {", "combinedPattern    =     \"  \"  ;", "for    ( int   i    =     0  ;    i    <     ( patterns . size (  )  )  ;    i +  +  )     {", "String   pattern    =    patterns . get ( i )  ;", "String   valueWrap ;", "if    ( traceMatch )     {", "valueWrap    =     (  (  (  (  (  \"  (  ?  <  \"     +     (  . PATTERN _ MATCH _ KEY )  )     +     \"  .  \"  )     +    i )     +     \"  >  \"  )     +    pattern )     +     \"  )  \"  ;", "} else    {", "valueWrap    =     (  \"  (  ?  :  \"     +     ( patterns . get ( i )  )  )     +     \"  )  \"  ;", "}", "if    ( combinedPattern . equals (  \"  \"  )  )     {", "combinedPattern    =    valueWrap ;", "} else    {", "combinedPattern    =     ( combinedPattern    +     \"  |  \"  )     +    valueWrap ;", "}", "}", "} else    {", "combinedPattern    =    patterns . get (  0  )  ;", "}", "return   combinedPattern ;", "}", "METHOD_END"], "methodName": ["combinePatterns"], "fileName": "org.elasticsearch.ingest.common.GrokProcessor"}, {"methodBody": ["METHOD_START", "{", "return   grok ;", "}", "METHOD_END"], "methodName": ["getGrok"], "fileName": "org.elasticsearch.ingest.common.GrokProcessor"}, {"methodBody": ["METHOD_START", "{", "return   matchField ;", "}", "METHOD_END"], "methodName": ["getMatchField"], "fileName": "org.elasticsearch.ingest.common.GrokProcessor"}, {"methodBody": ["METHOD_START", "{", "return   matchPatterns ;", "}", "METHOD_END"], "methodName": ["getMatchPatterns"], "fileName": "org.elasticsearch.ingest.common.GrokProcessor"}, {"methodBody": ["METHOD_START", "{", "return   ignoreMissing ;", "}", "METHOD_END"], "methodName": ["isIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.GrokProcessor"}, {"methodBody": ["METHOD_START", "{", "GrokProcessor . Factory   factory    =    new   GrokProcessor . Factory ( Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" patterns \"  ,    Collections . singletonList (  \"  (  ?  < foo >  \\  \\ w +  )  \"  )  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "GrokProcessor   processor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getMatchField (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( processor . getGrok (  )  ,    notNullValue (  )  )  ;", "assertThat ( processor . isIgnoreMissing (  )  ,    is ( false )  )  ;", "}", "METHOD_END"], "methodName": ["testBuild"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessor . Factory   factory    =    new   GrokProcessor . Factory ( Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" foo \"  )  ;", "config . put (  \" patterns \"  ,    Collections . emptyList (  )  )  ;", "ElasticsearchParseException   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    null ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ patterns ]    List   of   patterns   must   not   be   empty \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildEmptyPatternsList"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessor . Factory   factory    =    new   GrokProcessor . Factory ( Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" patterns \"  ,    Collections . singletonList (  \"  (  ?  < foo >  \\  \\ w +  )  \"  )  )  ;", "ElasticsearchParseException   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    null ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildMissingField"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessor . Factory   factory    =    new   GrokProcessor . Factory ( Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" foo \"  )  ;", "ElasticsearchParseException   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    null ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ patterns ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildMissingPatterns"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessor . Factory   factory    =    new   GrokProcessor . Factory ( Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" patterns \"  ,    Collections . singletonList (  \"  (  ?  < foo >  \\  \\ w +  )  \"  )  )  ;", "config . put (  \" ignore _ missing \"  ,    true )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "GrokProcessor   processor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getMatchField (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( processor . getGrok (  )  ,    notNullValue (  )  )  ;", "assertThat ( processor . isIgnoreMissing (  )  ,    is ( true )  )  ;", "}", "METHOD_END"], "methodName": ["testBuildWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessor . Factory   factory    =    new   GrokProcessor . Factory ( Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" patterns \"  ,    Collections . singletonList (  \"  %  { MY _ PATTERN : name }  !  \"  )  )  ;", "config . put (  \" pattern _ definitions \"  ,    Collections . singletonMap (  \" MY _ PATTERN \"  ,     \" foo \"  )  )  ;", "GrokProcessor   processor    =    factory . create ( null ,    null ,    config )  ;", "assertThat ( processor . getMatchField (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( processor . getGrok (  )  ,    notNullValue (  )  )  ;", "assertThat ( processor . getGrok (  )  . match (  \" foo !  \"  )  ,    equalTo ( true )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithCustomPatterns"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessor . Factory   factory    =    new   GrokProcessor . Factory ( Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" patterns \"  ,    Collections . singletonList (  \"  [  \"  )  )  ;", "ElasticsearchParseException   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    null ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ patterns ]    Invalid   regex   pattern   found   in :     [  [  ]  .    premature   end   of   char - class \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithInvalidPattern"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessor . Factory   factory    =    new   GrokProcessor . Factory ( Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \"  _ field \"  )  ;", "config . put (  \" patterns \"  ,    Collections . singletonList (  \"  %  { MY _ PATTERN : name }  !  \"  )  )  ;", "config . put (  \" pattern _ definitions \"  ,    Collections . singletonMap (  \" MY _ PATTERN \"  ,     \"  [  \"  )  )  ;", "ElasticsearchParseException   e    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    null ,    config )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ patterns ]    Invalid   regex   pattern   found   in :     [  %  { MY _ PATTERN : name }  !  ]  .    premature   end   of   char - class \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithInvalidPatternDefinition"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessorGetAction . Request   request    =    new   GrokProcessorGetAction . Request (  )  ;", "BytesStreamOutput   out    =    new   BytesStreamOutput (  )  ;", "request . writeTo ( out )  ;", "StreamInput   streamInput    =    out . bytes (  )  . streamInput (  )  ;", "GrokProcessorGetAction . Request   otherRequest    =    new   GrokProcessorGetAction . Request (  )  ;", "otherRequest . readFrom ( streamInput )  ;", "assertThat ( otherRequest . validate (  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRequest"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorGetActionTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessorGetAction . Response   response    =    new   GrokProcessorGetAction . Response ( GrokProcessorGetActionTests . TEST _ PATTERNS )  ;", "BytesStreamOutput   out    =    new   BytesStreamOutput (  )  ;", "response . writeTo ( out )  ;", "StreamInput   streamInput    =    out . bytes (  )  . streamInput (  )  ;", "GrokProcessorGetAction . Response   otherResponse    =    new   GrokProcessorGetAction . Response ( null )  ;", "otherResponse . readFrom ( streamInput )  ;", "assertThat ( response . getGrokPatterns (  )  ,    equalTo ( GrokProcessorGetActionTests . TEST _ PATTERNS )  )  ;", "assertThat ( response . getGrokPatterns (  )  ,    equalTo ( otherResponse . getGrokPatterns (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testResponseSerialization"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorGetActionTests"}, {"methodBody": ["METHOD_START", "{", "GrokProcessorGetAction . Response   response    =    new   GrokProcessorGetAction . Response ( GrokProcessorGetActionTests . TEST _ PATTERNS )  ;", "try    ( XContentBuilder   builder    =    JsonXContent . contentBuilder (  )  )     {", "response . toXContent ( builder ,    EMPTY _ PARAMS )  ;", "Map < String ,    Object >    converted    =    XContentHelper . convertToMap ( BytesReference . bytes ( builder )  ,    false ,    builder . contentType (  )  )  . v 2  (  )  ;", "Map < String ,    String >    patterns    =     (  ( Map < String ,    String >  )     ( converted . get (  \" patterns \"  )  )  )  ;", "assertThat ( patterns . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( patterns . get (  \" PATTERN \"  )  ,    equalTo (  \" foo \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testResponseToXContent"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorGetActionTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     \"  1  -  3  \"  )  ;", "Map < String ,    String >    patternBank    =    new   HashMap <  >  (  )  ;", "patternBank . put (  \" ONE \"  ,     \"  1  \"  )  ;", "patternBank . put (  \" TWO \"  ,     \"  2  \"  )  ;", "patternBank . put (  \" THREE \"  ,     \"  3  \"  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    patternBank ,    Arrays . asList (  \"  %  { ONE : first }  -  %  { TWO : second }  \"  ,     \"  %  { ONE : first }  -  %  { THREE : second }  \"  )  ,    fieldName ,    randomBoolean (  )  ,    randomBoolean (  )  )  ;", "processor . execute ( doc )  ;", "assertThat ( doc . getFieldValue (  \" first \"  ,    String . class )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( doc . getFieldValue (  \" second \"  ,    String . class )  ,    equalTo (  \"  3  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCombineSamePatternNameAcrossPatterns"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   combined ;", "combined    =     . combinePatterns ( Arrays . asList (  \"  \"  )  ,    false )  ;", "assertThat ( combined ,    equalTo (  \"  \"  )  )  ;", "combined    =     . combinePatterns ( Arrays . asList (  \"  \"  )  ,    true )  ;", "assertThat ( combined ,    equalTo (  \"  \"  )  )  ;", "combined    =     . combinePatterns ( Arrays . asList (  \" foo \"  )  ,    false )  ;", "assertThat ( combined ,    equalTo (  \" foo \"  )  )  ;", "combined    =     . combinePatterns ( Arrays . asList (  \" foo \"  )  ,    true )  ;", "assertThat ( combined ,    equalTo (  \" foo \"  )  )  ;", "combined    =     . combinePatterns ( Arrays . asList (  \" foo \"  ,     \" bar \"  )  ,    false )  ;", "assertThat ( combined ,    equalTo (  \"  (  ?  : foo )  |  (  ?  : bar )  \"  )  )  ;", "combined    =     . combinePatterns ( Arrays . asList (  \" foo \"  ,     \" bar \"  )  ,    true )  ;", "assertThat ( combined ,    equalTo (  \"  (  ?  <  _ ingest .  _ grok _ match _ index .  0  > foo )  |  (  ?  <  _ ingest .  _ grok _ match _ index .  1  > bar )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCombinedPatterns"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     \"  1  2  \"  )  ;", "Map < String ,    String >    patternBank    =    new   HashMap <  >  (  )  ;", "patternBank . put (  \" ONETWO \"  ,     \"  1  |  2  \"  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    patternBank ,    Collections . singletonList (  \"  %  { ONETWO : first }  %  { ONETWO : first }  \"  )  ,    fieldName ,    randomBoolean (  )  ,    randomBoolean (  )  )  ;", "processor . execute ( doc )  ;", "assertThat ( doc . getFieldValue (  \" first \"  ,    String . class )  ,    equalTo (  \"  1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFirstWinNamedCapture"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     \"  1  \"  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonMap (  \" ONE \"  ,     \"  1  \"  )  ,    Collections . singletonList (  \"  %  { ONE : one }  \"  )  ,    fieldName ,    false ,    false )  ;", "processor . execute ( doc )  ;", "assertThat ( doc . getFieldValue (  \" one \"  ,    String . class )  ,    equalTo (  \"  1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMatch"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =     \" value \"  ;", "IngestDocument   originalDoc    =    new   IngestDocument ( new   HashMap (  )  ,    new   HashMap (  )  )  ;", "originalDoc . setFieldValue ( fieldName ,    fieldName )  ;", "IngestDocument   doc    =    new   IngestDocument ( originalDoc )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . emptyMap (  )  ,    Collections . singletonList ( fieldName )  ,    fieldName ,    false ,    false )  ;", "processor . execute ( doc )  ;", "assertThat ( doc ,    equalTo ( originalDoc )  )  ;", "}", "METHOD_END"], "methodName": ["testMatchWithoutCaptures"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =     \" foo . bar \"  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonMap (  \" ONE \"  ,     \"  1  \"  )  ,    Collections . singletonList (  \"  %  { ONE : one }  \"  )  ,    fieldName ,    false ,    false )  ;", "Exception   e    =    expectThrows ( Exception . class ,     (  )     -  >    processor . execute ( doc )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" field    [ foo ]    not   present   as   part   of   path    [ foo . bar ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMissingField"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =     \" foo . bar \"  ;", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonMap (  \" ONE \"  ,     \"  1  \"  )  ,    Collections . singletonList (  \"  %  { ONE : one }  \"  )  ,    fieldName ,    false ,    true )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testMissingFieldWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     \"  2  \"  )  ;", "Map < String ,    String >    patternBank    =    new   HashMap <  >  (  )  ;", "patternBank . put (  \" ONE \"  ,     \"  1  \"  )  ;", "patternBank . put (  \" TWO \"  ,     \"  2  \"  )  ;", "patternBank . put (  \" THREE \"  ,     \"  3  \"  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    patternBank ,    Arrays . asList (  \"  %  { ONE : one }  \"  ,     \"  %  { TWO : two }  \"  ,     \"  %  { THREE : three }  \"  )  ,    fieldName ,    false ,    false )  ;", "processor . execute ( doc )  ;", "assertThat ( doc . hasField (  \" one \"  )  ,    equalTo ( false )  )  ;", "assertThat ( doc . getFieldValue (  \" two \"  ,    String . class )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( doc . hasField (  \" three \"  )  ,    equalTo ( false )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiplePatternsWithMatchReturn"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     \"  2  3  \"  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonMap (  \" ONE \"  ,     \"  1  \"  )  ,    Collections . singletonList (  \"  %  { ONE : one }  \"  )  ,    fieldName ,    false ,    false )  ;", "Exception   e    =    expectThrows ( Exception . class ,     (  )     -  >    processor . execute ( doc )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" Provided   Grok   expressions   do   not   match   field   value :     [  2  3  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoMatch"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     \"  2  3  \"  )  ;", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonMap (  \" ONE \"  ,     \"  1  \"  )  ,    Collections . singletonList (  \"  %  { NOTONE : not _ one }  \"  )  ,    fieldName ,    false ,    false )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" Unable   to   find   pattern    [ NOTONE ]    in   Grok ' s   pattern   dictionary \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoMatchingPatternName"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     1  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonMap (  \" ONE \"  ,     \"  1  \"  )  ,    Collections . singletonList (  \"  %  { ONE : one }  \"  )  ,    fieldName ,    false ,    false )  ;", "Exception   e    =    expectThrows ( Exception . class ,     (  )     -  >    processor . execute ( doc )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    of   type    [ Integer ]    cannot   be   cast   to    [ String ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNotStringField"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     1  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonMap (  \" ONE \"  ,     \"  1  \"  )  ,    Collections . singletonList (  \"  %  { ONE : one }  \"  )  ,    fieldName ,    false ,    true )  ;", "Exception   e    =    expectThrows ( Exception . class ,     (  )     -  >    processor . execute ( doc )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    of   type    [ Integer ]    cannot   be   cast   to    [ String ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNotStringFieldWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,    null )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonMap (  \" ONE \"  ,     \"  1  \"  )  ,    Collections . singletonList (  \"  %  { ONE : one }  \"  )  ,    fieldName ,    false ,    false )  ;", "Exception   e    =    expectThrows ( Exception . class ,     (  )     -  >    processor . execute ( doc )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    is   null ,    cannot   process   it .  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullField"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "originalIngestDocument . setFieldValue ( fieldName ,    null )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonMap (  \" ONE \"  ,     \"  1  \"  )  ,    Collections . singletonList (  \"  %  { ONE : one }  \"  )  ,    fieldName ,    false ,    true )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testNullFieldWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     \" abc 2  3  \"  )  ;", "Map < String ,    String >    patternBank    =    new   HashMap <  >  (  )  ;", "patternBank . put (  \" ONE \"  ,     \"  1  \"  )  ;", "patternBank . put (  \" TWO \"  ,     \"  2  \"  )  ;", "patternBank . put (  \" THREE \"  ,     \"  3  \"  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    patternBank ,    Arrays . asList (  \"  %  { ONE : one }  \"  ,     \"  %  { TWO : two }  \"  ,     \"  %  { THREE : three }  \"  )  ,    fieldName ,    true ,    false )  ;", "processor . execute ( doc )  ;", "assertThat ( doc . hasField (  \" one \"  )  ,    equalTo ( false )  )  ;", "assertThat ( doc . getFieldValue (  \" two \"  ,    String . class )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( doc . hasField (  \" three \"  )  ,    equalTo ( false )  )  ;", "assertThat ( doc . getFieldValue (  \"  _ ingest .  _ grok _ match _ index \"  ,    String . class )  ,    equalTo (  \"  1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSetMetadata"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     \" first 1  \"  )  ;", "Map < String ,    String >    patternBank    =    new   HashMap <  >  (  )  ;", "patternBank . put (  \" ONE \"  ,     \"  1  \"  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    patternBank ,    Arrays . asList (  \"  %  { ONE : one }  \"  )  ,    fieldName ,    true ,    false )  ;", "processor . execute ( doc )  ;", "assertThat ( doc . hasField (  \" one \"  )  ,    equalTo ( true )  )  ;", "assertThat ( doc . getFieldValue (  \"  _ ingest .  _ grok _ match _ index \"  ,    String . class )  ,    equalTo (  \"  0  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testTraceWithOnePattern"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   doc    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "doc . setFieldValue ( fieldName ,     \"  3  \"  )  ;", "Map < String ,    String >    patternBank    =    new   HashMap <  >  (  )  ;", "patternBank . put (  \" ONETWO \"  ,     \"  1  |  2  \"  )  ;", "patternBank . put (  \" THREE \"  ,     \"  3  \"  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    patternBank ,    Collections . singletonList (  \"  %  { ONETWO : first }  |  %  { THREE : second }  \"  )  ,    fieldName ,    randomBoolean (  )  ,    randomBoolean (  )  )  ;", "processor . execute ( doc )  ;", "assertFalse ( doc . hasField (  \" first \"  )  )  ;", "assertThat ( doc . getFieldValue (  \" second \"  ,    String . class )  ,    equalTo (  \"  3  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnmatchedNamesNotIncludedInDocument"], "fileName": "org.elasticsearch.ingest.common.GrokProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   pattern ;", "}", "METHOD_END"], "methodName": ["getPattern"], "fileName": "org.elasticsearch.ingest.common.GsubProcessor"}, {"methodBody": ["METHOD_START", "{", "return   replacement ;", "}", "METHOD_END"], "methodName": ["getReplacement"], "fileName": "org.elasticsearch.ingest.common.GsubProcessor"}, {"methodBody": ["METHOD_START", "{", "GsubProcessor . Factory   factory    =    new   GsubProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" pattern \"  ,     \"  [  \"  )  ;", "config . put (  \" replacement \"  ,     \"  -  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \"  [ pattern ]    Invalid   regex   pattern .    Unclosed   character   class \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateInvalidPattern"], "fileName": "org.elasticsearch.ingest.common.GsubProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GsubProcessor . Factory   factory    =    new   GsubProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" replacement \"  ,     \"  -  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ pattern ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoPatternPresent"], "fileName": "org.elasticsearch.ingest.common.GsubProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "GsubProcessor . Factory   factory    =    new   GsubProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" pattern \"  ,     \"  \\  \\  .  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ replacement ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoReplacementPresent"], "fileName": "org.elasticsearch.ingest.common.GsubProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.ingest.common.IngestCommonClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "internalCluster (  )  . startNode (  )  ;", "client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \"  1  \"  )  . setContent ( new   BytesArray (  (  (  \"  {  \\  \" script \\  \"  :     {  \\  \" lang \\  \"  :     \\  \"  \"     +     ( MockScriptEngine . NAME )  )     +     \"  \\  \"  ,     \\  \" source \\  \"  :     \\  \" my _ script \\  \"  }     }  \"  )  )  ,    JSON )  . get (  )  ;", "BytesReference   pipeline    =    new   BytesArray (  (  \"  {  \\ n \"     +     (  (  (  (  \"        \\  \" processors \\  \"     :     [  \\ n \"     +     \"                    {  \\  \" set \\  \"     :     {  \\  \" field \\  \"  :     \\  \" y \\  \"  ,     \\  \" value \\  \"  :     0  }  }  ,  \\ n \"  )     +     \"                    {  \\  \" script \\  \"     :     {  \\  \" id \\  \"  :     \\  \"  1  \\  \"  }  }  \\ n \"  )     +     \"        ]  \\ n \"  )     +     \"  }  \"  )  )  )  ;", "client (  )  . admin (  )  . cluster (  )  . preparePutPipeline (  \"  _ id \"  ,    pipeline ,    JSON )  . get (  )  ;", "client (  )  . prepareIndex (  \" index \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" x \"  ,     0  )  . setPipeline (  \"  _ id \"  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "Map < String ,    Object >    source    =    client (  )  . prepareGet (  \" index \"  ,     \" doc \"  ,     \"  1  \"  )  . get (  )  . getSource (  )  ;", "assertThat ( source . get (  \" x \"  )  ,    equalTo (  0  )  )  ;", "assertThat ( source . get (  \" y \"  )  ,    equalTo (  0  )  )  ;", "assertThat ( source . get (  \" z \"  )  ,    equalTo (  0  )  )  ;", "internalCluster (  )  . full (  )  ;", "ensureYellow (  \" index \"  )  ;", "client (  )  . prepareIndex (  \" index \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" x \"  ,     0  )  . setPipeline (  \"  _ id \"  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "source    =    client (  )  . prepareGet (  \" index \"  ,     \" doc \"  ,     \"  2  \"  )  . get (  )  . getSource (  )  ;", "assertThat ( source . get (  \" x \"  )  ,    equalTo (  0  )  )  ;", "assertThat ( source . get (  \" y \"  )  ,    equalTo (  0  )  )  ;", "assertThat ( source . get (  \" z \"  )  ,    equalTo (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testPipelineWithScriptProcessorThatHasStoredScript"], "fileName": "org.elasticsearch.ingest.common.IngestRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   pipelineIdWithoutScript    =    randomAlphaOfLengthBetween (  5  ,     1  0  )  ;", "String   pipelineIdWithScript    =    pipelineIdWithoutScript    +     \"  _ script \"  ;", "internalCluster (  )  . startNode (  )  ;", "BytesReference   pipelineWithScript    =    new   BytesArray (  (  (  (  (  (  \"  {  \\ n \"     +     (  \"        \\  \" processors \\  \"     :     [  \\ n \"     +     \"                    {  \\  \" script \\  \"     :     {  \\  \" lang \\  \"  :     \\  \"  \"  )  )     +     ( MockScriptEngine . NAME )  )     +     \"  \\  \"  ,     \\  \" source \\  \"  :     \\  \" my _ script \\  \"  }  }  \\ n \"  )     +     \"        ]  \\ n \"  )     +     \"  }  \"  )  )  ;", "BytesReference   pipelineWithoutScript    =    new   BytesArray (  (  \"  {  \\ n \"     +     (  (  (  \"        \\  \" processors \\  \"     :     [  \\ n \"     +     \"                    {  \\  \" set \\  \"     :     {  \\  \" field \\  \"  :     \\  \" y \\  \"  ,     \\  \" value \\  \"  :     0  }  }  \\ n \"  )     +     \"        ]  \\ n \"  )     +     \"  }  \"  )  )  )  ;", "Consumer < String >    checkPipelineExists    =     (    id )     -  >    assertThat ( client (  )  . admin (  )  . cluster (  )  . prepareGetPipeline ( id )  . get (  )  . pipelines (  )  . get (  0  )  . getId (  )  ,    equalTo ( id )  )  ;", "client (  )  . admin (  )  . cluster (  )  . preparePutPipeline ( pipelineIdWithScript ,    pipelineWithScript ,    JSON )  . get (  )  ;", "client (  )  . admin (  )  . cluster (  )  . preparePutPipeline ( pipelineIdWithoutScript ,    pipelineWithoutScript ,    JSON )  . get (  )  ;", "checkPipelineExists . accept ( pipelineIdWithScript )  ;", "checkPipelineExists . accept ( pipelineIdWithoutScript )  ;", "internalCluster (  )  . stopCurrentMasterNode (  )  ;", "internalCluster (  )  . startNode ( Settings . builder (  )  . put (  \" script . allowed _ types \"  ,     \" none \"  )  )  ;", "checkPipelineExists . accept ( pipelineIdWithoutScript )  ;", "checkPipelineExists . accept ( pipelineIdWithScript )  ;", "client (  )  . prepareIndex (  \" index \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" x \"  ,     0  )  . setPipeline ( pipelineIdWithoutScript )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "EException   exception    =    expectThrows ( EException . class ,     (  )     -  >    client (  )  . prepareIndex (  \" index \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" x \"  ,     0  )  . setPipeline ( pipelineIdWithScript )  . setRefreshPolicy ( WriteRequest . RefreshPolicy . IMMEDIATE )  . get (  )  )  ;", "assertThat ( exception . getHeaderKeys (  )  ,    equalTo ( Sets . newHashSet (  \" processor _ type \"  )  )  )  ;", "assertThat ( exception . getHeader (  \" processor _ type \"  )  ,    equalTo ( Arrays . asList (  \" unknown \"  )  )  )  ;", "assertThat ( exception . getRootCause (  )  . getMessage (  )  ,    equalTo (  (  (  (  (  (  (  (  (  (  (  \" pipeline   with   id    [  \"     +    pipelineIdWithScript )     +     \"  ]    could   not   be   loaded ,    caused   by    \"  )     +     \"  [ EParseException [ Error   updating   pipeline   with   id    [  \"  )     +    pipelineIdWithScript )     +     \"  ]  ]  ;     \"  )     +     \" nested :    EException [ IllegalArgumentException :    cannot   execute    [ inline ]    scripts ]  ;     \"  )     +     \" nested :    IllegalArgumentException [ cannot   execute    [ inline ]    scripts ]  ;  ;     \"  )     +     \" EException [ IllegalArgumentException :    cannot   execute    [ inline ]    scripts ]  ;     \"  )     +     \" nested :    IllegalArgumentException [ cannot   execute    [ inline ]    scripts ]  ;  ;    IllegalArgumentException :     \"  )     +     \" cannot   execute    [ inline ]    scripts ]  \"  )  )  )  ;", "Map < String ,    Object >    source    =    client (  )  . prepareGet (  \" index \"  ,     \" doc \"  ,     \"  1  \"  )  . get (  )  . getSource (  )  ;", "assertThat ( source . get (  \" x \"  )  ,    equalTo (  0  )  )  ;", "assertThat ( source . get (  \" y \"  )  ,    equalTo (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testScriptDisabled"], "fileName": "org.elasticsearch.ingest.common.IngestRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   node    =    internalCluster (  )  . startNode (  )  ;", "String   ingestNode    =    internalCluster (  )  . startNode ( Settings . builder (  )  . put (  \" node . master \"  ,    false )  . put (  \" node . data \"  ,    false )  )  ;", "BytesReference   pipeline    =    new   BytesArray (  (  \"  {  \\ n \"     +     (  (  (  \"        \\  \" processors \\  \"     :     [  \\ n \"     +     \"                    {  \\  \" set \\  \"     :     {  \\  \" field \\  \"  :     \\  \" y \\  \"  ,     \\  \" value \\  \"  :     0  }  }  \\ n \"  )     +     \"        ]  \\ n \"  )     +     \"  }  \"  )  )  )  ;", "client (  )  . admin (  )  . cluster (  )  . preparePutPipeline (  \"  _ id \"  ,    pipeline ,    JSON )  . get (  )  ;", "client (  )  . prepareIndex (  \" index \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" x \"  ,     0  )  . setPipeline (  \"  _ id \"  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "Map < String ,    Object >    source    =    client (  )  . prepareGet (  \" index \"  ,     \" doc \"  ,     \"  1  \"  )  . get (  )  . getSource (  )  ;", "assertThat ( source . get (  \" x \"  )  ,    equalTo (  0  )  )  ;", "assertThat ( source . get (  \" y \"  )  ,    equalTo (  0  )  )  ;", "logger . info (  \" Stopping \"  )  ;", "internalCluster (  )  . restartNode ( node ,    new   InternalTestCluster . Callback (  )  )  ;", "client ( ingestNode )  . prepareIndex (  \" index \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" x \"  ,     0  )  . setPipeline (  \"  _ id \"  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "source    =    client ( ingestNode )  . prepareGet (  \" index \"  ,     \" doc \"  ,     \"  2  \"  )  . get (  )  . getSource (  )  ;", "assertThat ( source . get (  \" x \"  )  ,    equalTo (  0  )  )  ;", "assertThat ( source . get (  \" y \"  )  ,    equalTo (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testWithDedicatedIngestNode"], "fileName": "org.elasticsearch.ingest.common.IngestRestartIT"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.JoinProcessor"}, {"methodBody": ["METHOD_START", "{", "return   separator ;", "}", "METHOD_END"], "methodName": ["getSeparator"], "fileName": "org.elasticsearch.ingest.common.JoinProcessor"}, {"methodBody": ["METHOD_START", "{", "return   targetField ;", "}", "METHOD_END"], "methodName": ["getTargetField"], "fileName": "org.elasticsearch.ingest.common.JoinProcessor"}, {"methodBody": ["METHOD_START", "{", "JoinProcessor . Factory   factory    =    new   JoinProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" separator \"  ,     \"  -  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "JoinProcessor   joinProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( joinProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( joinProcessor . getField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( joinProcessor . getSeparator (  )  ,    equalTo (  \"  -  \"  )  )  ;", "assertThat ( joinProcessor . getTargetField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "JoinProcessor . Factory   factory    =    new   JoinProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" separator \"  ,     \"  -  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoFieldPresent"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "JoinProcessor . Factory   factory    =    new   JoinProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ separator ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoSeparatorPresent"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "JoinProcessor . Factory   factory    =    new   JoinProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" separator \"  ,     \"  -  \"  )  ;", "config . put (  \" target _ field \"  ,     \" target \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "JoinProcessor   joinProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( joinProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( joinProcessor . getField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( joinProcessor . getSeparator (  )  ,    equalTo (  \"  -  \"  )  )  ;", "assertThat ( joinProcessor . getTargetField (  )  ,    equalTo (  \" target \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithTargetField"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "String   separator    =    randomFrom (  . SEPARATORS )  ;", "List < Integer >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "String   expectedResult    =     \"  \"  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "int   value    =    randomInt (  )  ;", "fieldValue . add ( value )  ;", "expectedResult    +  =    value ;", "if    ( j    <     ( numItems    -     1  )  )     {", "expectedResult    +  =    separator ;", "}", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new   JoinProcessor ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    separator ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    String . class )  ,    equalTo ( expectedResult )  )  ;", "}", "METHOD_END"], "methodName": ["testJoinIntegers"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  -  \"  ,    fieldName )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \" not   present   as   part   of   path    [  \"     +    fieldName )     +     \"  ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testJoinNonExistingField"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  -  \"  ,    fieldName )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    of   type    [ String ]    cannot   be   cast   to    [ List ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testJoinNonListField"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    null )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \"  -  \"  ,     \" field \"  )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \" field    [ field ]    is   null ,    cannot   join .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testJoinNullValue"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "String   separator    =    randomFrom (  . SEPARATORS )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "String   expectedResult    =     \"  \"  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "String   value    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "fieldValue . add ( value )  ;", "expectedResult    +  =    value ;", "if    ( j    <     ( numItems    -     1  )  )     {", "expectedResult    +  =    separator ;", "}", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new   JoinProcessor ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    separator ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    String . class )  ,    equalTo ( expectedResult )  )  ;", "}", "METHOD_END"], "methodName": ["testJoinStrings"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "String   separator    =    randomFrom (  . SEPARATORS )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "String   expectedResult    =     \"  \"  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "String   value    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "fieldValue . add ( value )  ;", "expectedResult    +  =    value ;", "if    ( j    <     ( numItems    -     1  )  )     {", "expectedResult    +  =    separator ;", "}", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "String   targetFieldName    =    fieldName    +     ( randomAlphaOfLength (  5  )  )  ;", "Processor   processor    =    new   JoinProcessor ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    separator ,    targetFieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( targetFieldName ,    String . class )  ,    equalTo ( expectedResult )  )  ;", "}", "METHOD_END"], "methodName": ["testJoinWithTargetField"], "fileName": "org.elasticsearch.ingest.common.JoinProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.JsonProcessor"}, {"methodBody": ["METHOD_START", "{", "return   targetField ;", "}", "METHOD_END"], "methodName": ["getTargetField"], "fileName": "org.elasticsearch.ingest.common.JsonProcessor"}, {"methodBody": ["METHOD_START", "{", "return   addToRoot ;", "}", "METHOD_END"], "methodName": ["isAddToRoot"], "fileName": "org.elasticsearch.ingest.common.JsonProcessor"}, {"methodBody": ["METHOD_START", "{", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "String   randomField    =    randomAlphaOfLength (  1  0  )  ;", "String   randomTargetField    =    randomAlphaOfLength (  5  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    randomField )  ;", "config . put (  \" target _ field \"  ,    randomTargetField )  ;", "JsonProcessor   jsonProcessor    =     . FACTORY . create ( null ,    processorTag ,    config )  ;", "assertThat ( jsonProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( jsonProcessor . getField (  )  ,    equalTo ( randomField )  )  ;", "assertThat ( jsonProcessor . getTargetField (  )  ,    equalTo ( randomTargetField )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "String   randomField    =    randomAlphaOfLength (  1  0  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    randomField )  ;", "config . put (  \" add _ to _ root \"  ,    true )  ;", "JsonProcessor   jsonProcessor    =     . FACTORY . create ( null ,    processorTag ,    config )  ;", "assertThat ( jsonProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( jsonProcessor . getField (  )  ,    equalTo ( randomField )  )  ;", "assertThat ( jsonProcessor . getTargetField (  )  ,    equalTo ( randomField )  )  ;", "assertTrue ( jsonProcessor . isAddToRoot (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithAddToRoot"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "String   randomField    =    randomAlphaOfLength (  1  0  )  ;", "String   randomTargetField    =    randomAlphaOfLength (  5  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    randomField )  ;", "config . put (  \" target _ field \"  ,    randomTargetField )  ;", "config . put (  \" add _ to _ root \"  ,    true )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >     . FACTORY . create ( null ,    randomAlphaOfLength (  1  0  )  ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \"  [ target _ field ]    Cannot   set   a   target   field   while   also   setting    ` add _ to _ root `    to   true \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithBothTargetFieldAndAddToRoot"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "String   randomField    =    randomAlphaOfLength (  1  0  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    randomField )  ;", "JsonProcessor   jsonProcessor    =     . FACTORY . create ( null ,    processorTag ,    config )  ;", "assertThat ( jsonProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( jsonProcessor . getField (  )  ,    equalTo ( randomField )  )  ;", "assertThat ( jsonProcessor . getTargetField (  )  ,    equalTo ( randomField )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithDefaultTarget"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >     . FACTORY . create ( null ,    processorTag ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithMissingField"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    true )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" field \"  ,    true )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "Exception   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    jsonProcessor . execute ( ingestDocument )  )  ;", "assertThat ( exception . getMessage (  )  ,    containsString (  \" cannot   add   non - map   fields   to   root   of   document \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAddBoolToRoot"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   processorTag    =    randomAlphaOfLength (  3  )  ;", "String   randomTargetField    =    randomAlphaOfLength (  2  )  ;", "jsonProcessor    =    new    ( processorTag ,     \" a \"  ,    randomTargetField ,    true )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "String   json    =     \"  {  \\  \" a \\  \"  :     1  ,     \\  \" b \\  \"  :     2  }  \"  ;", "document . put (  \" a \"  ,    json )  ;", "document . put (  \" c \"  ,     \" see \"  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "jsonProcessor . execute ( ingestDocument )  ;", "Map < String ,    Object >    expected    =    new   HashMap <  >  (  )  ;", "expected . put (  \" a \"  ,     1  )  ;", "expected . put (  \" b \"  ,     2  )  ;", "expected . put (  \" c \"  ,     \" see \"  )  ;", "IngestDocument   expectedIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    expected )  ;", "IngestDocumentMatcher . assertIngestDocument ( ingestDocument ,    expectedIngestDocument )  ;", "}", "METHOD_END"], "methodName": ["testAddToRoot"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "List < Boolean >    value    =    Arrays . asList ( true ,    true ,    false )  ;", "document . put (  \" field \"  ,    value . toString (  )  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "jsonProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target _ field \"  ,    Object . class )  ,    equalTo ( value )  )  ;", "}", "METHOD_END"], "methodName": ["testArray"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "boolean   value    =    true ;", "document . put (  \" field \"  ,    value )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "jsonProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target _ field \"  ,    Object . class )  ,    equalTo ( value )  )  ;", "}", "METHOD_END"], "methodName": ["testBoolean"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" field \"  ,    new   byte [  ]  {     0  ,     1     }  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "Exception   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    jsonProcessor . execute ( ingestDocument )  )  ;", "assertThat ( exception . getCause (  )  . getMessage (  )  ,    containsString (  \" Unrecognized   token    ' B '  :    was   expecting    (  ' true '  ,     ' false '    or    ' null '  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testByteArray"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "double   value    =     3  .  0  ;", "document . put (  \" field \"  ,    value )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "jsonProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target _ field \"  ,    Object . class )  ,    equalTo ( value )  )  ;", "}", "METHOD_END"], "methodName": ["testDouble"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   processorTag    =    randomAlphaOfLength (  3  )  ;", "String   randomField    =    randomAlphaOfLength (  3  )  ;", "String   randomTargetField    =    randomAlphaOfLength (  2  )  ;", "jsonProcessor    =    new    ( processorTag ,    randomField ,    randomTargetField ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    randomJsonMap    =    RandomDocumentPicks . randomSource ( random (  )  )  ;", "XContentBuilder   builder    =    JsonXContent . contentBuilder (  )  . map ( randomJsonMap )  ;", "String   randomJson    =    XContentHelper . convertToJson ( BytesReference . bytes ( builder )  ,    false ,    JSON )  ;", "document . put ( randomField ,    randomJson )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "jsonProcessor . execute ( ingestDocument )  ;", "Map < String ,    Object >    jsonified    =    ingestDocument . getFieldValue ( randomTargetField ,    Map . class )  ;", "IngestDocumentMatcher . assertIngestDocument ( ingestDocument . getFieldValue ( randomTargetField ,    Object . class )  ,    jsonified )  ;", "}", "METHOD_END"], "methodName": ["testExecute"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "Exception   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    jsonProcessor . execute ( ingestDocument )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \" field    [ field ]    not   present   as   part   of   path    [ field ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFieldMissing"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "int   value    =     3  ;", "document . put (  \" field \"  ,    value )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "jsonProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target _ field \"  ,    Object . class )  ,    equalTo ( value )  )  ;", "}", "METHOD_END"], "methodName": ["testInteger"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" field \"  ,     \" blah   blah \"  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "Exception   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    jsonProcessor . execute ( ingestDocument )  )  ;", "assertThat ( exception . getCause (  )  . getMessage (  )  ,    containsString (  (  \" Unrecognized   token    ' blah '  :     \"     +     \" was   expecting    (  ' true '  ,     ' false '    or    ' null '  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidValue"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" field \"  ,    null )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "jsonProcessor . execute ( ingestDocument )  ;", "assertNull ( ingestDocument . getFieldValue (  \" target _ field \"  ,    Object . class )  )  ;", "}", "METHOD_END"], "methodName": ["testNull"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "JsonProcessor   jsonProcessor    =    new   JsonProcessor (  \" tag \"  ,     \" field \"  ,     \" target _ field \"  ,    false )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "String   value    =     \" hello   world \"  ;", "document . put (  \" field \"  ,     (  (  \"  \\  \"  \"     +    value )     +     \"  \\  \"  \"  )  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "jsonProcessor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target _ field \"  ,    Object . class )  ,    equalTo ( value )  )  ;", "}", "METHOD_END"], "methodName": ["testString"], "fileName": "org.elasticsearch.ingest.common.JsonProcessorTests"}, {"methodBody": ["METHOD_START", "{", "if    ( document . hasField ( targetField )  )     {", "document . appendField ( targetField ,    value )  ;", "} else    {", "document . setField ( targetField ,    value )  ;", "}", "}", "METHOD_END"], "methodName": ["append"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessor"}, {"methodBody": ["METHOD_START", "{", "return   excludeKeys ;", "}", "METHOD_END"], "methodName": ["getExcludeKeys"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessor"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessor"}, {"methodBody": ["METHOD_START", "{", "return   fieldSplit ;", "}", "METHOD_END"], "methodName": ["getFieldSplit"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessor"}, {"methodBody": ["METHOD_START", "{", "return   includeKeys ;", "}", "METHOD_END"], "methodName": ["getIncludeKeys"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessor"}, {"methodBody": ["METHOD_START", "{", "return   targetField ;", "}", "METHOD_END"], "methodName": ["getTargetField"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessor"}, {"methodBody": ["METHOD_START", "{", "return   valueSplit ;", "}", "METHOD_END"], "methodName": ["getValueSplit"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessor"}, {"methodBody": ["METHOD_START", "{", "return   ignoreMissing ;", "}", "METHOD_END"], "methodName": ["isIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessor"}, {"methodBody": ["METHOD_START", "{", "KeyValueProcessor . Factory   factory    =    new   KeyValueProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" field _ split \"  ,     \"  &  \"  )  ;", "config . put (  \" value _ split \"  ,     \"  =  \"  )  ;", "config . put (  \" target _ field \"  ,     \" target \"  )  ;", "config . put (  \" include _ keys \"  ,    Arrays . asList (  \" a \"  ,     \" b \"  )  )  ;", "config . put (  \" exclude _ keys \"  ,    Collections . emptyList (  )  )  ;", "config . put (  \" ignore _ missing \"  ,    true )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "KeyValueProcessor   processor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( processor . getFieldSplit (  )  ,    equalTo (  \"  &  \"  )  )  ;", "assertThat ( processor . getValueSplit (  )  ,    equalTo (  \"  =  \"  )  )  ;", "assertThat ( processor . getIncludeKeys (  )  ,    equalTo ( Sets . newHashSet (  \" a \"  ,     \" b \"  )  )  )  ;", "assertThat ( processor . getExcludeKeys (  )  ,    equalTo ( Collections . emptySet (  )  )  )  ;", "assertThat ( processor . getTargetField (  )  ,    equalTo (  \" target \"  )  )  ;", "assertTrue ( processor . isIgnoreMissing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithAllFieldsSet"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "KeyValueProcessor . Factory   factory    =    new   KeyValueProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" field _ split \"  ,     \"  &  \"  )  ;", "config . put (  \" value _ split \"  ,     \"  =  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "KeyValueProcessor   processor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( processor . getFieldSplit (  )  ,    equalTo (  \"  &  \"  )  )  ;", "assertThat ( processor . getValueSplit (  )  ,    equalTo (  \"  =  \"  )  )  ;", "assertThat ( processor . getIncludeKeys (  )  ,    is ( nullValue (  )  )  )  ;", "assertThat ( processor . getTargetField (  )  ,    is ( nullValue (  )  )  )  ;", "assertFalse ( processor . isIgnoreMissing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithDefaults"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "KeyValueProcessor . Factory   factory    =    new   KeyValueProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    processorTag ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithMissingField"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "KeyValueProcessor . Factory   factory    =    new   KeyValueProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    processorTag ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \"  [ field _ split ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithMissingFieldSplit"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "KeyValueProcessor . Factory   factory    =    new   KeyValueProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" field _ split \"  ,     \"  &  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchParseException . class ,     (  )     -  >    factory . create ( null ,    processorTag ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \"  [ value _ split ]    required   property   is   missing \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithMissingValueSplit"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,     \" first = hello & second = world & second = universe \"  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  &  \"  ,     \"  =  \"  ,    null ,    null ,     \" target \"  ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target . first \"  ,    String . class )  ,    equalTo (  \" hello \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target . second \"  ,    List . class )  ,    equalTo ( Arrays . asList (  \" world \"  ,     \" universe \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["test"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,     \" first = hello & second = world & second = universe \"  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  &  \"  ,     \"  =  \"  ,    null ,    Sets . newHashSet (  \" second \"  )  ,     \" target \"  ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target . first \"  ,    String . class )  ,    equalTo (  \" hello \"  )  )  ;", "assertFalse ( ingestDocument . hasField (  \" target . second \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExcludeKeys"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,     \" first = hello | second = world | second = universe \"  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  &  \"  ,     \"  =  \"  ,    null ,    null ,     \" target \"  ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target . first \"  ,    String . class )  ,    equalTo (  \" hello | second = world | second = universe \"  )  )  ;", "assertFalse ( ingestDocument . hasField (  \" target . second \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFailFieldSplitMatch"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" foo \"  ,     \" bar \"  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" foo \"  ,     \"  &  \"  ,     \"  =  \"  ,    null ,    null ,     \" target \"  ,    false )  ;", "Exception   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    processor . execute ( ingestDocument )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \" field    [ foo ]    does   not   contain   value _ split    [  =  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFailValueSplitMatch"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,     \" first = hello & second = world & second = universe & third = bar \"  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  &  \"  ,     \"  =  \"  ,    Sets . newHashSet (  \" first \"  ,     \" second \"  )  ,    Sets . newHashSet (  \" first \"  ,     \" second \"  )  ,     \" target \"  ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertFalse ( ingestDocument . hasField (  \" target . first \"  )  )  ;", "assertFalse ( ingestDocument . hasField (  \" target . second \"  )  )  ;", "assertFalse ( ingestDocument . hasField (  \" target . third \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncludeAndExcludeKeys"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,     \" first = hello & second = world & second = universe \"  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  &  \"  ,     \"  =  \"  ,    Sets . newHashSet (  \" first \"  )  ,    null ,     \" target \"  ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" target . first \"  ,    String . class )  ,    equalTo (  \" hello \"  )  )  ;", "assertFalse ( ingestDocument . hasField (  \" target . second \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncludeKeys"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . emptyMap (  )  )  ;", "ingestDocument . setFieldValue (  \" first \"  ,     \" first = hello \"  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" first \"  ,     \"  &  \"  ,     \"  =  \"  ,    null ,    null ,    null ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" first \"  ,    List . class )  ,    equalTo ( Arrays . asList (  \" first = hello \"  ,     \" hello \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testKeySameAsSourceField"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . emptyMap (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" unknown \"  ,     \"  &  \"  ,     \"  =  \"  ,    null ,    null ,     \" target \"  ,    false )  ;", "IllegalArgumentException   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    processor . execute ( ingestDocument )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \" field    [ unknown ]    not   present   as   part   of   path    [ unknown ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMissingField"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . emptyMap (  )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" unknown \"  ,     \"  \"  ,     \"  \"  ,    null ,    null ,     \" target \"  ,    true )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testNonExistentWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap ( fieldName ,    null )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  \"  ,     \"  \"  ,    null ,    null ,     \" target \"  ,    true )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testNullValueWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . emptyMap (  )  )  ;", "ingestDocument . setFieldValue (  \" myField \"  ,     \" first = hello & second = world & second = universe \"  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" myField \"  ,     \"  &  \"  ,     \"  =  \"  ,    null ,    null ,    null ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" first \"  ,    String . class )  ,    equalTo (  \" hello \"  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" second \"  ,    List . class )  ,    equalTo ( Arrays . asList (  \" world \"  ,     \" universe \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testRootTarget"], "fileName": "org.elasticsearch.ingest.common.KeyValueProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   fields ;", "}", "METHOD_END"], "methodName": ["getFields"], "fileName": "org.elasticsearch.ingest.common.RemoveProcessor"}, {"methodBody": ["METHOD_START", "{", "factory    =    new   RemoveProcessor . Factory ( TestTemplateService . instance (  )  )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.ingest.common.RemoveProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "removeProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( removeProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( removeProcessor . getFields (  )  . get (  0  )  . newInstance ( Collections . emptyMap (  )  )  . execute (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.RemoveProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateMissingField"], "fileName": "org.elasticsearch.ingest.common.RemoveProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    Arrays . asList (  \" field 1  \"  ,     \" field 2  \"  )  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "removeProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( removeProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( removeProcessor . getFields (  )  . stream (  )  . map (  (    template )     -  >    template . newInstance ( Collections . emptyMap (  )  )  . execute (  )  )  . collect ( Collectors . toList (  )  )  ,    equalTo ( Arrays . asList (  \" field 1  \"  ,     \" field 2  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateMultipleFields"], "fileName": "org.elasticsearch.ingest.common.RemoveProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "RemoveProcessor . Factory   factory    =    new   RemoveProcessor . Factory ( TestTemplateService . instance ( true )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchException . class ,     (  )     -  >    factory . create ( null ,    processorTag ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \" RuntimeException :    could   not   compile   script \"  )  )  ;", "assertThat ( exception . getHeader (  \" processor _ tag \"  )  . get (  0  )  ,    equalTo ( processorTag )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidMustacheTemplate"], "fileName": "org.elasticsearch.ingest.common.RemoveProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   field    =    RandomDocumentPicks . randomExistingFieldName ( random (  )  ,    ingestDocument )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonList ( new   TestTemplateService . MockTemplateScript . Factory ( field )  )  )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . hasField ( field )  ,    equalTo ( false )  )  ;", "}", "METHOD_END"], "methodName": ["testRemoveFields"], "fileName": "org.elasticsearch.ingest.common.RemoveProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    Collections . singletonList ( new   TestTemplateService . MockTemplateScript . Factory ( fieldName )  )  )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" remove   field   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \" not   present   as   part   of   path    [  \"     +    fieldName )     +     \"  ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRemoveNonExistingField"], "fileName": "org.elasticsearch.ingest.common.RemoveProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.RenameProcessor"}, {"methodBody": ["METHOD_START", "{", "return   targetField ;", "}", "METHOD_END"], "methodName": ["getTargetField"], "fileName": "org.elasticsearch.ingest.common.RenameProcessor"}, {"methodBody": ["METHOD_START", "{", "return   ignoreMissing ;", "}", "METHOD_END"], "methodName": ["isIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.RenameProcessor"}, {"methodBody": ["METHOD_START", "{", "RenameProcessor . Factory   factory    =    new   RenameProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" old _ field \"  )  ;", "config . put (  \" target _ field \"  ,     \" new _ field \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "RenameProcessor   renameProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( renameProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( renameProcessor . getField (  )  ,    equalTo (  \" old _ field \"  )  )  ;", "assertThat ( renameProcessor . getTargetField (  )  ,    equalTo (  \" new _ field \"  )  )  ;", "assertThat ( renameProcessor . isIgnoreMissing (  )  ,    equalTo ( false )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "RenameProcessor . Factory   factory    =    new   RenameProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" target _ field \"  ,     \" new _ field \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoFieldPresent"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "RenameProcessor . Factory   factory    =    new   RenameProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" old _ field \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ target _ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoToPresent"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "RenameProcessor . Factory   factory    =    new   RenameProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" old _ field \"  )  ;", "config . put (  \" target _ field \"  ,     \" new _ field \"  )  ;", "config . put (  \" ignore _ missing \"  ,    true )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "RenameProcessor   renameProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( renameProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( renameProcessor . getField (  )  ,    equalTo (  \" old _ field \"  )  )  ;", "assertThat ( renameProcessor . getTargetField (  )  ,    equalTo (  \" new _ field \"  )  )  ;", "assertThat ( renameProcessor . isIgnoreMissing (  )  ,    equalTo ( true )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomExistingFieldName ( random (  )  ,    ingestDocument )  ;", "Object   fieldValue    =    ingestDocument . getFieldValue ( fieldName ,    Object . class )  ;", "String   newFieldName ;", "do    {", "newFieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "}    while    (  (  ( RandomDocumentPicks . canAddField ( newFieldName ,    ingestDocument )  )     =  =    false )     |  |     ( newFieldName . equals ( fieldName )  )     )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    newFieldName ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( newFieldName ,    Object . class )  ,    equalTo ( fieldValue )  )  ;", "}", "METHOD_END"], "methodName": ["testRename"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "List < String >    list    =    new   ArrayList <  >  (  )  ;", "list . add (  \" item 1  \"  )  ;", "list . add (  \" item 2  \"  )  ;", "list . add (  \" item 3  \"  )  ;", "document . put (  \" list \"  ,    list )  ;", "List < Map < String ,    String >  >    one    =    new   ArrayList <  >  (  )  ;", "one . add ( Collections . singletonMap (  \" one \"  ,     \" one \"  )  )  ;", "one . add ( Collections . singletonMap (  \" two \"  ,     \" two \"  )  )  ;", "document . put (  \" one \"  ,    one )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" list .  0  \"  ,     \" item \"  ,    false )  ;", "processor . execute ( ingestDocument )  ;", "Object   actualObject    =    ingestDocument . getSourceAndMetadata (  )  . get (  \" list \"  )  ;", "assertThat ( actualObject ,    instanceOf ( List . class )  )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "List < String >    actualList    =     (  ( List < String >  )     ( actualObject )  )  ;", "assertThat ( actualList . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( actualList . get (  0  )  ,    equalTo (  \" item 2  \"  )  )  ;", "assertThat ( actualList . get (  1  )  ,    equalTo (  \" item 3  \"  )  )  ;", "actualObject    =    ingestDocument . getSourceAndMetadata (  )  . get (  \" item \"  )  ;", "assertThat ( actualObject ,    instanceOf ( String . class )  )  ;", "assertThat ( actualObject ,    equalTo (  \" item 1  \"  )  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" list .  0  \"  ,     \" list .  3  \"  ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [  3  ]    is   out   of   bounds   for   array   with   length    [  2  ]    as   part   of   path    [ list .  3  ]  \"  )  )  ;", "assertThat ( actualList . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( actualList . get (  0  )  ,    equalTo (  \" item 2  \"  )  )  ;", "assertThat ( actualList . get (  1  )  ,    equalTo (  \" item 3  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRenameArrayElement"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    source    =    new   HashMap < String ,    Object >  (  )     {", "@ Override", "public   Object   remove ( Object   key )     {", "if    ( key . equals (  \" list \"  )  )     {", "throw   new   UnsupportedOperationException (  )  ;", "}", "return   super . remove ( key )  ;", "}", "}  ;", "source . put (  \" list \"  ,    Collections . singletonList (  \" item \"  )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" list \"  ,     \" new _ field \"  ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( UnsupportedOperationException   e )     {", "assertThat ( ingestDocument . getSourceAndMetadata (  )  . containsKey (  \" list \"  )  ,    equalTo ( true )  )  ;", "assertThat ( ingestDocument . getSourceAndMetadata (  )  . containsKey (  \" new _ field \"  )  ,    equalTo ( false )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRenameAtomicOperationRemoveFails"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    source    =    new   HashMap < String ,    Object >  (  )     {", "@ Override", "public   Object   put ( String   key ,    Object   value )     {", "if    ( key . equals (  \" new _ field \"  )  )     {", "throw   new   UnsupportedOperationException (  )  ;", "}", "return   super . put ( key ,    value )  ;", "}", "}  ;", "source . put (  \" list \"  ,    Collections . singletonList (  \" item \"  )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" list \"  ,     \" new _ field \"  ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( UnsupportedOperationException   e )     {", "assertThat ( ingestDocument . getSourceAndMetadata (  )  . containsKey (  \" list \"  )  ,    equalTo ( true )  )  ;", "assertThat ( ingestDocument . getSourceAndMetadata (  )  . containsKey (  \" new _ field \"  )  ,    equalTo ( false )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRenameAtomicOperationSetFails"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    null )  ;", "String   newFieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    newFieldName ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . hasField ( fieldName )  ,    equalTo ( false )  )  ;", "assertThat ( ingestDocument . hasField ( newFieldName )  ,    equalTo ( true )  )  ;", "assertThat ( ingestDocument . getFieldValue ( newFieldName ,    Object . class )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRenameExistingFieldNullValue"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    source    =    new   HashMap <  >  (  )  ;", "source . put (  \" foo \"  ,     \" bar \"  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( source ,    Collections . emptyMap (  )  )  ;", "Processor   processor 1     =    new    ( randomAlphaOfLength (  1  0  )  ,     \" foo \"  ,     \" foo . bar \"  ,    false )  ;", "processor 1  . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" foo \"  ,    Map . class )  ,    equalTo ( Collections . singletonMap (  \" bar \"  ,     \" bar \"  )  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" foo . bar \"  ,    String . class )  ,    equalTo (  \" bar \"  )  )  ;", "Processor   processor 2     =    new    ( randomAlphaOfLength (  1  0  )  ,     \" foo . bar \"  ,     \" foo . bar . baz \"  ,    false )  ;", "processor 2  . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue (  \" foo \"  ,    Map . class )  ,    equalTo ( Collections . singletonMap (  \" bar \"  ,    Collections . singletonMap (  \" baz \"  ,     \" bar \"  )  )  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" foo . bar \"  ,    Map . class )  ,    equalTo ( Collections . singletonMap (  \" baz \"  ,     \" bar \"  )  )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" foo . bar . baz \"  ,    String . class )  ,    equalTo (  \" bar \"  )  )  ;", "Processor   processor 3     =    new    ( randomAlphaOfLength (  1  0  )  ,     \" foo . bar . baz \"  ,     \" foo \"  ,    false )  ;", "Exception   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    processor 3  . execute ( ingestDocument )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" field    [ foo ]    already   exists \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRenameLeafIntoBranch"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomExistingFieldName ( random (  )  ,    ingestDocument )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    RandomDocumentPicks . randomExistingFieldName ( random (  )  ,    ingestDocument )  ,    fieldName ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    already   exists \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRenameNewFieldAlreadyExists"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    RandomDocumentPicks . randomFieldName ( random (  )  )  ,    false )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    doesn ' t   exist \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRenameNonExistingField"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    RandomDocumentPicks . randomFieldName ( random (  )  )  ,    true )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testRenameNonExistingFieldWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.RenameProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   script ;", "}", "METHOD_END"], "methodName": ["getScript"], "fileName": "org.elasticsearch.ingest.common.ScriptProcessor"}, {"methodBody": ["METHOD_START", "{", "factory    =    new   ScriptProcessor . Factory ( mock ( ScriptService . class )  )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.ingest.common.ScriptProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "String   randomType    =    randomFrom (  \" source \"  ,     \" id \"  )  ;", "ScriptService   mockedScriptService    =    mock ( ScriptService . class )  ;", "ScriptException   thrownException    =    new   ScriptException (  \" compile - time   exception \"  ,    new   RuntimeException (  )  ,    Collections . emptyList (  )  ,     \" script \"  ,     \" mockscript \"  )  ;", "when ( mockedScriptService . compile ( any (  )  ,    any (  )  )  )  . thenThrow ( thrownException )  ;", "factory    =    new    . Factory ( mockedScriptService )  ;", "Map < String ,    Object >    configMap    =    new   HashMap <  >  (  )  ;", "configMap . put ( randomType ,     \" my _ script \"  )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchException . class ,     (  )     -  >    factory . create ( null ,    randomAlphaOfLength (  1  0  )  ,    configMap )  )  ;", "assertThat ( exception . getMessage (  )  ,    is (  \" compile - time   exception \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFactoryInvalidateWithInvalidCompiledScript"], "fileName": "org.elasticsearch.ingest.common.ScriptProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    configMap    =    new   HashMap <  >  (  )  ;", "configMap . put (  \" lang \"  ,     \" mockscript \"  )  ;", "IllegalArgumentException   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    f . create ( null ,    randomAlphaOfLength (  1  0  )  ,    configMap )  )  ;", "assertThat ( exception . getMessage (  )  ,    is (  \" must   specify   either    [ source ]    for   an   inline   script   or    [ id ]    for   a   stored   script \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFactoryValidationAtLeastOneScriptingType"], "fileName": "org.elasticsearch.ingest.common.ScriptProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    configMap    =    new   HashMap <  >  (  )  ;", "configMap . put (  \" id \"  ,     \" foo \"  )  ;", "configMap . put (  \" source \"  ,     \" bar \"  )  ;", "configMap . put (  \" lang \"  ,     \" mockscript \"  )  ;", "XContentParseException   exception    =    expectThrows ( XContentParseException . class ,     (  )     -  >    f . create ( null ,    randomAlphaOfLength (  1  0  )  ,    configMap )  )  ;", "assertThat ( exception . getMessage (  )  ,    containsString (  \"  [ script ]    failed   to   parse   field    [ source ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFactoryValidationForMultipleScriptingTypes"], "fileName": "org.elasticsearch.ingest.common.ScriptProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    configMap    =    new   HashMap <  >  (  )  ;", "String   randomType    =    randomFrom (  \" id \"  ,     \" source \"  )  ;", "configMap . put ( randomType ,     \" foo \"  )  ;", "ScriptProcessor   processor    =    factory . create ( null ,    randomAlphaOfLength (  1  0  )  ,    configMap )  ;", "assertThat ( processor . getScript (  )  . getLang (  )  ,    equalTo (  ( randomType . equals (  \" id \"  )     ?    null    :    Script . DEFAULT _ SCRIPT _ LANG )  )  )  ;", "assertThat ( processor . getScript (  )  . getType (  )  . toString (  )  ,    equalTo (  . ingestScriptParamToType . get ( randomType )  )  )  ;", "assertThat ( processor . getScript (  )  . getParams (  )  ,    equalTo ( Collections . emptyMap (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testFactoryValidationWithDefaultLang"], "fileName": "org.elasticsearch.ingest.common.ScriptProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    configMap    =    new   HashMap <  >  (  )  ;", "String   randomType    =    randomFrom (  \" id \"  ,     \" source \"  )  ;", "Map < String ,    Object >    randomParams    =    Collections . singletonMap ( randomAlphaOfLength (  1  0  )  ,    randomAlphaOfLength (  1  0  )  )  ;", "configMap . put ( randomType ,     \" foo \"  )  ;", "configMap . put (  \" params \"  ,    randomParams )  ;", "ScriptProcessor   processor    =    factory . create ( null ,    randomAlphaOfLength (  1  0  )  ,    configMap )  ;", "assertThat ( processor . getScript (  )  . getLang (  )  ,    equalTo (  ( randomType . equals (  \" id \"  )     ?    null    :    Script . DEFAULT _ SCRIPT _ LANG )  )  )  ;", "assertThat ( processor . getScript (  )  . getType (  )  . toString (  )  ,    equalTo (  . ingestScriptParamToType . get ( randomType )  )  )  ;", "assertThat ( processor . getScript (  )  . getParams (  )  ,    equalTo ( randomParams )  )  ;", "}", "METHOD_END"], "methodName": ["testFactoryValidationWithParams"], "fileName": "org.elasticsearch.ingest.common.ScriptProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    configMap    =    new   HashMap <  >  (  )  ;", "configMap . put (  \" inline \"  ,     \" code \"  )  ;", "f . create ( null ,    randomAlphaOfLength (  1  0  )  ,    configMap )  ;", "assertWarnings (  \" Deprecated   field    [ inline ]    used ,    expected    [ source ]    instead \"  )  ;", "}", "METHOD_END"], "methodName": ["testInlineBackcompat"], "fileName": "org.elasticsearch.ingest.common.ScriptProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "int   randomBytesIn    =    randomInt (  )  ;", "int   randomBytesOut    =    randomInt (  )  ;", "int   randomBytesTotal    =    randomBytesIn    +    randomBytesOut ;", "ScriptService   scriptService    =    mock ( ScriptService . class )  ;", "Script   script    =    mockScript (  \"  _ script \"  )  ;", "ExecutableScript . Factory   factory    =    mock ( Factory . class )  ;", "ExecutableScript   executableScript    =    mock ( ExecutableScript . class )  ;", "when ( scriptService . compile ( script ,    INGEST _ CONTEXT )  )  . thenReturn ( factory )  ;", "when ( factory . newInstance ( any (  )  )  )  . thenReturn ( executableScript )  ;", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" bytes _ in \"  ,    randomInt (  )  )  ;", "document . put (  \" bytes _ out \"  ,    randomInt (  )  )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    document )  ;", "doAnswer (  (    invocationOnMock )     -  >     {", "ingestDocument . setFieldValue (  \" bytes _ total \"  ,    randomBytesTotal )  ;", "return   null ;", "}  )  . when ( executableScript )  . run (  )  ;", "processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    script ,    scriptService )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getSourceAndMetadata (  )  ,    hasKey (  \" bytes _ in \"  )  )  ;", "assertThat ( ingestDocument . getSourceAndMetadata (  )  ,    hasKey (  \" bytes _ out \"  )  )  ;", "assertThat ( ingestDocument . getSourceAndMetadata (  )  ,    hasKey (  \" bytes _ total \"  )  )  ;", "assertThat ( ingestDocument . getSourceAndMetadata (  )  . get (  \" bytes _ total \"  )  ,    is ( randomBytesTotal )  )  ;", "}", "METHOD_END"], "methodName": ["testScripting"], "fileName": "org.elasticsearch.ingest.common.ScriptProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.SetProcessor"}, {"methodBody": ["METHOD_START", "{", "return   value ;", "}", "METHOD_END"], "methodName": ["getValue"], "fileName": "org.elasticsearch.ingest.common.SetProcessor"}, {"methodBody": ["METHOD_START", "{", "return   overrideEnabled ;", "}", "METHOD_END"], "methodName": ["isOverrideEnabled"], "fileName": "org.elasticsearch.ingest.common.SetProcessor"}, {"methodBody": ["METHOD_START", "{", "factory    =    new   SetProcessor . Factory ( TestTemplateService . instance (  )  )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.ingest.common.SetProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" value \"  ,     \" value 1  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "setProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( setProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( setProcessor . getField (  )  . newInstance ( Collections . emptyMap (  )  )  . execute (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( setProcessor . getValue (  )  . copyAndResolve ( Collections . emptyMap (  )  )  ,    equalTo (  \" value 1  \"  )  )  ;", "assertThat ( setProcessor . isOverrideEnabled (  )  ,    equalTo ( true )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.SetProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" value \"  ,     \" value 1  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoFieldPresent"], "fileName": "org.elasticsearch.ingest.common.SetProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ value ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoValuePresent"], "fileName": "org.elasticsearch.ingest.common.SetProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" value \"  ,    null )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( EParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ value ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNullValue"], "fileName": "org.elasticsearch.ingest.common.SetProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "boolean   overrideEnabled    =    randomBoolean (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" value \"  ,     \" value 1  \"  )  ;", "config . put (  \" override \"  ,    overrideEnabled )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "setProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( setProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( setProcessor . getField (  )  . newInstance ( Collections . emptyMap (  )  )  . execute (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( setProcessor . getValue (  )  . copyAndResolve ( Collections . emptyMap (  )  )  ,    equalTo (  \" value 1  \"  )  )  ;", "assertThat ( setProcessor . isOverrideEnabled (  )  ,    equalTo ( overrideEnabled )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithOverride"], "fileName": "org.elasticsearch.ingest.common.SetProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "SetProcessor . Factory   factory    =    new   SetProcessor . Factory ( TestTemplateService . instance ( true )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" value \"  ,     \" value 1  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchException . class ,     (  )     -  >    factory . create ( null ,    processorTag ,    config )  )  ;", "assertThat ( exception . getMessage (  )  ,    equalTo (  \" RuntimeException :    could   not   compile   script \"  )  )  ;", "assertThat ( exception . getHeader (  \" processor _ tag \"  )  . get (  0  )  ,    equalTo ( processorTag )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidMustacheTemplate"], "fileName": "org.elasticsearch.ingest.common.SetProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   new   SetProcessor ( randomAlphaOfLength (  1  0  )  ,    new   TestTemplateService . MockTemplateScript . Factory ( fieldName )  ,    ValueSource . wrap ( fieldValue ,    TestTemplateService . instance (  )  )  ,    overrideEnabled )  ;", "}", "METHOD_END"], "methodName": ["createSetProcessor"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    new   IngestDocument ( new   HashMap (  )  ,    new   HashMap (  )  )  ;", "Object   fieldValue    =     \" foo \"  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =     . createSetProcessor ( fieldName ,     \" bar \"  ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . hasField ( fieldName )  ,    equalTo ( true )  )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Object . class )  ,    equalTo ( fieldValue )  )  ;", "}", "METHOD_END"], "methodName": ["testSetExistingFieldWithOverrideDisabled"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomExistingFieldName ( random (  )  ,    ingestDocument )  ;", "Object   fieldValue    =    RandomDocumentPicks . randomFieldValue ( random (  )  )  ;", "Processor   processor    =     . createSetProcessor ( fieldName ,    fieldValue ,    true )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . hasField ( fieldName )  ,    equalTo ( true )  )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Object . class )  ,    equalTo ( fieldValue )  )  ;", "}", "METHOD_END"], "methodName": ["testSetExistingFields"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    new   IngestDocument ( new   HashMap (  )  ,    new   HashMap (  )  )  ;", "Object   fieldValue    =    null ;", "Object   newValue    =     \" bar \"  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =     . createSetProcessor ( fieldName ,    newValue ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . hasField ( fieldName )  ,    equalTo ( true )  )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Object . class )  ,    equalTo ( newValue )  )  ;", "}", "METHOD_END"], "methodName": ["testSetExistingNullFieldWithOverrideDisabled"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "ingestDocument . setFieldValue (  \" field \"  ,     \" value \"  )  ;", "Processor   processor    =     . createSetProcessor (  \" field . inner \"  ,     \" value \"  ,    true )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" processor   execute   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  \" cannot   set    [ inner ]    with   parent   object   of   type    [ String ]    as    \"     +     \" part   of   path    [ field . inner ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSetFieldsTypeMismatch"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "MetaData   randomMetaData    =    randomFrom ( INDEX ,    TYPE ,    ID ,    ROUTING )  ;", "Processor   processor    =     . createSetProcessor ( randomMetaData . getFieldName (  )  ,     \"  _ value \"  ,    true )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( randomMetaData . getFieldName (  )  ,    String . class )  ,    Matchers . equalTo (  \"  _ value \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSetMetadataExceptVersion"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "long   version    =    randomNonNegativeLong (  )  ;", "Processor   processor    =     . createSetProcessor ( VERSION . getFieldName (  )  ,    version ,    true )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( VERSION . getFieldName (  )  ,    Long . class )  ,    Matchers . equalTo ( version )  )  ;", "}", "METHOD_END"], "methodName": ["testSetMetadataVersion"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   versionType    =    randomFrom (  \" internal \"  ,     \" external \"  ,     \" external _ gte \"  )  ;", "Processor   processor    =     . createSetProcessor ( VERSION _ TYPE . getFieldName (  )  ,    versionType ,    true )  ;", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( VERSION _ TYPE . getFieldName (  )  ,    String . class )  ,    Matchers . equalTo ( versionType )  )  ;", "}", "METHOD_END"], "methodName": ["testSetMetadataVersionType"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    new   IngestDocument ( new   HashMap (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Object   fieldValue    =    RandomDocumentPicks . randomFieldValue ( random (  )  )  ;", "Processor   processor    =     . createSetProcessor ( fieldName ,    fieldValue ,    false )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . hasField ( fieldName )  ,    equalTo ( true )  )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Object . class )  ,    equalTo ( fieldValue )  )  ;", "}", "METHOD_END"], "methodName": ["testSetNewFieldWithOverrideDisabled"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "IngestDocument   testIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "Object   fieldValue    =    RandomDocumentPicks . randomFieldValue ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    testIngestDocument ,    fieldValue )  ;", "Processor   processor    =     . createSetProcessor ( fieldName ,    fieldValue ,    true )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . hasField ( fieldName )  ,    equalTo ( true )  )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    Object . class )  ,    equalTo ( fieldValue )  )  ;", "}", "METHOD_END"], "methodName": ["testSetNewFields"], "fileName": "org.elasticsearch.ingest.common.SetProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.SortProcessor"}, {"methodBody": ["METHOD_START", "{", "return   order ;", "}", "METHOD_END"], "methodName": ["getOrder"], "fileName": "org.elasticsearch.ingest.common.SortProcessor"}, {"methodBody": ["METHOD_START", "{", "return   targetField ;", "}", "METHOD_END"], "methodName": ["getTargetField"], "fileName": "org.elasticsearch.ingest.common.SortProcessor"}, {"methodBody": ["METHOD_START", "{", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    fieldName )  ;", ". Factory   factory    =    new    . Factory (  )  ;", "processor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo ( fieldName )  )  ;", "assertThat ( processor . getOrder (  )  ,    equalTo (  . SortOrder . ASCENDING )  )  ;", "assertThat ( processor . getTargetField (  )  ,    equalTo ( fieldName )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.SortProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "SortProcessor . Factory   factory    =    new   SortProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateMissingField"], "fileName": "org.elasticsearch.ingest.common.SortProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    fieldName )  ;", "config . put (  \" order \"  ,     \" invalid \"  )  ;", ". Factory   factory    =    new    . Factory (  )  ;", "try    {", "factory . create ( null ,    processorTag ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ order ]    Sort   direction    [ invalid ]    not   recognized .    Valid   values   are :     [ asc ,    desc ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateWithInvalidOrder"], "fileName": "org.elasticsearch.ingest.common.SortProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    fieldName )  ;", "config . put (  \" order \"  ,     \" desc \"  )  ;", ". Factory   factory    =    new    . Factory (  )  ;", "processor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo ( fieldName )  )  ;", "assertThat ( processor . getOrder (  )  ,    equalTo (  . SortOrder . DESCENDING )  )  ;", "assertThat ( processor . getTargetField (  )  ,    equalTo ( fieldName )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithOrder"], "fileName": "org.elasticsearch.ingest.common.SortProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "String   targetFieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,    fieldName )  ;", "config . put (  \" target _ field \"  ,    targetFieldName )  ;", ". Factory   factory    =    new    . Factory (  )  ;", "processor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( processor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( processor . getField (  )  ,    equalTo ( fieldName )  )  ;", "assertThat ( processor . getOrder (  )  ,    equalTo (  . SortOrder . ASCENDING )  )  ;", "assertThat ( processor . getTargetField (  )  ,    equalTo ( targetFieldName )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithTargetField"], "fileName": "org.elasticsearch.ingest.common.SortProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . emptyMap (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < String >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "String   value    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "String   targetFieldName    =    fieldName    +     \" foo \"  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     . SortOrder . ASCENDING ,    targetFieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( targetFieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testAscendingSortWithTargetField"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . emptyMap (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < String >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "String   value    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult ,    Collections . reverseOrder (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "String   targetFieldName    =    fieldName    +     \" foo \"  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     . SortOrder . DESCENDING ,    targetFieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( targetFieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testDescendingSortWithTargetField"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < Boolean >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < Boolean >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "Boolean   value    =    randomBoolean (  )  ;", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "if    ( order . equals (  . SortOrder . DESCENDING )  )     {", "Collections . reverse ( expectedResult )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testSortBooleans"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < Byte >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < Byte >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "Byte   value    =    randomByte (  )  ;", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "if    ( order . equals (  . SortOrder . DESCENDING )  )     {", "Collections . reverse ( expectedResult )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testSortBytes"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < Double >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < Double >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "Double   value    =    randomDoubleBetween (  0  .  0  ,     1  0  0  .  0  ,    true )  ;", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "if    ( order . equals (  . SortOrder . DESCENDING )  )     {", "Collections . reverse ( expectedResult )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testSortDoubles"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < Float >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < Float >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "Float   value    =    randomFloat (  )  ;", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "if    ( order . equals (  . SortOrder . DESCENDING )  )     {", "Collections . reverse ( expectedResult )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testSortFloats"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < Integer >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < Integer >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "Integer   value    =    randomIntBetween (  1  ,     1  0  0  )  ;", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "if    ( order . equals (  . SortOrder . DESCENDING )  )     {", "Collections . reverse ( expectedResult )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testSortIntegers"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "Integer [  ]    expectedResult    =    new   Integer [  ]  {     1  ,     2  ,     3  ,     4  ,     5  ,     1  0  ,     2  0  ,     2  1  ,     2  2  ,     5  0  ,     1  0  0     }  ;", "List < Integer >    fieldValue    =    new   ArrayList <  >  ( expectedResult . length )  ;", "fieldValue . addAll ( Arrays . asList ( expectedResult )  . subList (  0  ,    expectedResult . length )  )  ;", "Collections . shuffle ( fieldValue ,    random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     . SortOrder . ASCENDING ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    List . class )  . toArray (  )  ,    equalTo ( expectedResult )  )  ;", "}", "METHOD_END"], "methodName": ["testSortIntegersNonRandom"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < String >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "String   value ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "if    ( randomBoolean (  )  )     {", "value    =    String . valueOf ( randomIntBetween (  0  ,     1  0  0  )  )  ;", "} else    {", "value    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "}", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "if    ( order . equals (  . SortOrder . DESCENDING )  )     {", "Collections . reverse ( expectedResult )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testSortMixedStrings"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \" not   present   as   part   of   path    [  \"     +    fieldName )     +     \"  ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSortNonExistingField"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    randomAlphaOfLengthBetween (  1  ,     1  0  )  )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    of   type    [ String ]    cannot   be   cast   to    [ List ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSortNonListField"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    null )  )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,    order ,     \" field \"  )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \" field    [ field ]    is   null ,    cannot   sort .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSortNullValue"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < Short >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < Short >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "Short   value    =    randomShort (  )  ;", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "if    ( order . equals (  . SortOrder . DESCENDING )  )     {", "Collections . reverse ( expectedResult )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testSortShorts"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "int   numItems    =    randomIntBetween (  1  ,     1  0  )  ;", "List < String >    fieldValue    =    new   ArrayList <  >  ( numItems )  ;", "List < String >    expectedResult    =    new   ArrayList <  >  ( numItems )  ;", "for    ( int   j    =     0  ;    j    <    numItems ;    j +  +  )     {", "String   value    =    randomAlphaOfLengthBetween (  1  ,     1  0  )  ;", "fieldValue . add ( value )  ;", "expectedResult . add ( value )  ;", "}", "Collections . sort ( expectedResult )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "if    ( order . equals (  . SortOrder . DESCENDING )  )     {", "Collections . reverse ( expectedResult )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    fieldValue )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    expectedResult )  ;", "}", "METHOD_END"], "methodName": ["testSortStrings"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . emptyMap (  )  )  ;", "List < Integer >    fieldValue    =    Arrays . asList (  1  ,     5  ,     4  )  ;", "List < Integer >    expectedResult    =    new   ArrayList <  >  ( fieldValue )  ;", "Collections . sort ( expectedResult )  ;", ". SortOrder   order    =     ( randomBoolean (  )  )     ?     . SortOrder . ASCENDING    :     . SortOrder . DESCENDING ;", "if    ( order . equals (  . SortOrder . DESCENDING )  )     {", "Collections . reverse ( expectedResult )  ;", "}", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,    new   ArrayList ( fieldValue )  )  ;", "String   targetFieldName    =    fieldName    +     \" foo \"  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,    order ,    targetFieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertEquals ( ingestDocument . getFieldValue ( targetFieldName ,    List . class )  ,    expectedResult )  ;", "assertEquals ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    fieldValue )  ;", "}", "METHOD_END"], "methodName": ["testSortWithTargetFieldLeavesOriginalUntouched"], "fileName": "org.elasticsearch.ingest.common.SortProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.ingest.common.SplitProcessor"}, {"methodBody": ["METHOD_START", "{", "return   separator ;", "}", "METHOD_END"], "methodName": ["getSeparator"], "fileName": "org.elasticsearch.ingest.common.SplitProcessor"}, {"methodBody": ["METHOD_START", "{", "return   targetField ;", "}", "METHOD_END"], "methodName": ["getTargetField"], "fileName": "org.elasticsearch.ingest.common.SplitProcessor"}, {"methodBody": ["METHOD_START", "{", "return   ignoreMissing ;", "}", "METHOD_END"], "methodName": ["isIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.SplitProcessor"}, {"methodBody": ["METHOD_START", "{", "SplitProcessor . Factory   factory    =    new   SplitProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" separator \"  ,     \"  \\  \\  .  \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "SplitProcessor   splitProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( splitProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( splitProcessor . getField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( splitProcessor . getSeparator (  )  ,    equalTo (  \"  \\  \\  .  \"  )  )  ;", "assertFalse ( splitProcessor . isIgnoreMissing (  )  )  ;", "assertThat ( splitProcessor . getTargetField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreate"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "SplitProcessor . Factory   factory    =    new   SplitProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" separator \"  ,     \"  \\  \\  .  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoFieldPresent"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "SplitProcessor . Factory   factory    =    new   SplitProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "try    {", "factory . create ( null ,    null ,    config )  ;", "fail (  \" factory   create   should   have   failed \"  )  ;", "}    catch    ( ElasticsearchParseException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ separator ]    required   property   is   missing \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCreateNoSeparatorPresent"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "SplitProcessor . Factory   factory    =    new   SplitProcessor . Factory (  )  ;", "Map < String ,    Object >    config    =    new   HashMap <  >  (  )  ;", "config . put (  \" field \"  ,     \" field 1  \"  )  ;", "config . put (  \" separator \"  ,     \"  \\  \\  .  \"  )  ;", "config . put (  \" target _ field \"  ,     \" target \"  )  ;", "String   processorTag    =    randomAlphaOfLength (  1  0  )  ;", "SplitProcessor   splitProcessor    =    factory . create ( null ,    processorTag ,    config )  ;", "assertThat ( splitProcessor . getTag (  )  ,    equalTo ( processorTag )  )  ;", "assertThat ( splitProcessor . getField (  )  ,    equalTo (  \" field 1  \"  )  )  ;", "assertThat ( splitProcessor . getSeparator (  )  ,    equalTo (  \"  \\  \\  .  \"  )  )  ;", "assertFalse ( splitProcessor . isIgnoreMissing (  )  )  ;", "assertThat ( splitProcessor . getTargetField (  )  ,    equalTo (  \" target \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateWithTargetField"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorFactoryTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,     \"  1  2  7  .  0  .  0  .  1  \"  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  \\  \\  .  \"  ,    false ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( fieldName ,    List . class )  ,    equalTo ( Arrays . asList (  \"  1  2  7  \"  ,     \"  0  \"  ,     \"  0  \"  ,     \"  1  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSplit"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    splitConfig    =    new   HashMap <  >  (  )  ;", "splitConfig . put (  \" field \"  ,     \" flags \"  )  ;", "splitConfig . put (  \" separator \"  ,     \"  \\  \\  |  \"  )  ;", "Processor   splitProcessor    =    new    . Factory (  )  . create ( null ,    null ,    splitConfig )  ;", "Map < String ,    Object >    source    =    new   HashMap <  >  (  )  ;", "source . put (  \" flags \"  ,     \" new | hot | super | fun | interesting \"  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( source ,    new   HashMap (  )  )  ;", "splitProcessor . execute ( ingestDocument )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "List < String >    flags    =     (  ( List < String >  )     ( ingestDocument . getFieldValue (  \" flags \"  ,    List . class )  )  )  ;", "assertThat ( flags ,    equalTo ( Arrays . asList (  \" new \"  ,     \" hot \"  ,     \" super \"  ,     \" fun \"  ,     \" interesting \"  )  )  )  ;", "ingestDocument . appendFieldValue (  \" flags \"  ,     \" additional _ flag \"  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" flags \"  ,    List . class )  ,    equalTo ( Arrays . asList (  \" new \"  ,     \" hot \"  ,     \" super \"  ,     \" fun \"  ,     \" interesting \"  ,     \" additional _ flag \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSplitAppendable"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  \\  \\  .  \"  ,    false ,    fieldName )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" split   processor   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \" not   present   as   part   of   path    [  \"     +    fieldName )     +     \"  ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSplitFieldNotFound"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . emptyMap (  )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \"  \\  \\  .  \"  ,    true ,     \" field \"  )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testSplitNonExistentWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    new   HashMap (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "ingestDocument . setFieldValue ( fieldName ,    randomInt (  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  \\  \\  .  \"  ,    false ,    fieldName )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" split   processor   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  (  (  (  \" field    [  \"     +    fieldName )     +     \"  ]    of   type    [ Integer ]    cannot   be   cast    \"  )     +     \" to    [ String ]  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSplitNonStringValue"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap (  \" field \"  ,    null )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,     \" field \"  ,     \"  \\  \\  .  \"  ,    false ,     \" field \"  )  ;", "try    {", "processor . execute ( ingestDocument )  ;", "fail (  \" split   processor   should   have   failed \"  )  ;", "}    catch    ( IllegalArgumentException   e )     {", "assertThat ( e . getMessage (  )  ,    equalTo (  \" field    [ field ]    is   null ,    cannot   split .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSplitNullValue"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldName    =    RandomDocumentPicks . randomFieldName ( random (  )  )  ;", "IngestDocument   originalIngestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  ,    Collections . singletonMap ( fieldName ,    null )  )  ;", "IngestDocument   ingestDocument    =    new   IngestDocument ( originalIngestDocument )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  \\  \\  .  \"  ,    true ,    fieldName )  ;", "processor . execute ( ingestDocument )  ;", "IngestDocumentMatcher . assertIngestDocument ( originalIngestDocument ,    ingestDocument )  ;", "}", "METHOD_END"], "methodName": ["testSplitNullValueWithIgnoreMissing"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorTests"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    RandomDocumentPicks . randomIngestDocument ( random (  )  )  ;", "String   fieldName    =    RandomDocumentPicks . addRandomField ( random (  )  ,    ingestDocument ,     \"  1  2  7  .  0  .  0  .  1  \"  )  ;", "String   targetFieldName    =    fieldName    +     ( randomAlphaOfLength (  5  )  )  ;", "Processor   processor    =    new    ( randomAlphaOfLength (  1  0  )  ,    fieldName ,     \"  \\  \\  .  \"  ,    false ,    targetFieldName )  ;", "processor . execute ( ingestDocument )  ;", "assertThat ( ingestDocument . getFieldValue ( targetFieldName ,    List . class )  ,    equalTo ( Arrays . asList (  \"  1  2  7  \"  ,     \"  0  \"  ,     \"  0  \"  ,     \"  1  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSplitWithTargetField"], "fileName": "org.elasticsearch.ingest.common.SplitProcessorTests"}, {"methodBody": ["METHOD_START", "{", "int   prefixLength    =    randomIntBetween (  0  ,     1  0  )  ;", "for    ( int   i    =     0  ;    i    <    prefixLength ;    i +  +  )     {", "input    +  =     '     '  ;", "}", "return   input ;", "}", "METHOD_END"], "methodName": ["addWhitespaces"], "fileName": "org.elasticsearch.ingest.common.TrimProcessorTests"}, {"methodBody": ["METHOD_START", "{", "return   createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.join.ParentChildClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "ParentJoinFieldMapper   parentJoinFieldMapper    =    ParentJoinFieldMapper . getMapper ( context . mapperService (  )  )  ;", "ParentIdFieldMapper   parentIdFieldMapper    =    parentJoinFieldMapper . getParentIdFieldMapper ( childType ,    false )  ;", "if    ( parentIdFieldMapper    !  =    null )     {", "parentFilter    =    parentIdFieldMapper . getParentFilter (  )  ;", "childFilter    =    parentIdFieldMapper . getChildFilter ( childType )  ;", "MappedFieldType   fieldType    =    parentIdFieldMapper . fieldType (  )  ;", "final   SortedSetDVOrdinalsIndexFieldData   fieldData    =    context . getForField ( fieldType )  ;", "config . fieldContext ( new   search . aggregations . support . FieldContext ( fieldType . name (  )  ,    fieldData ,    fieldType )  )  ;", "} else    {", "config . unmapped ( true )  ;", "}", "}", "METHOD_END"], "methodName": ["joinFieldResolveConfig"], "fileName": "org.elasticsearch.join.aggregations.ChildrenAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "String   childType    =    null ;", "XContentParser . Token   token ;", "String   currentFieldName    =    null ;", "while    (  ( token    =    parser . nextToken (  )  )     !  =     ( Token . END _ OBJECT )  )     {", "if    ( token    =  =     ( Token . FIELD _ NAME )  )     {", "currentFieldName    =    parser . currentName (  )  ;", "} else", "if    ( token    =  =     ( Token . VALUE _ STRING )  )     {", "if    (  \" type \"  . equals ( currentFieldName )  )     {", "childType    =    parser . text (  )  ;", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  (  (  (  (  \" Unknown   key   for   a    \"     +    token )     +     \"    in    [  \"  )     +    aggregationName )     +     \"  ]  :     [  \"  )     +    currentFieldName )     +     \"  ]  .  \"  )  )  ;", "}", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  (  (  \" Unexpected   token    \"     +    token )     +     \"    in    [  \"  )     +    aggregationName )     +     \"  ]  .  \"  )  )  ;", "}", "}", "if    ( childType    =  =    null )     {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  \" Missing    [ child _ type ]    field   for   children   aggregation    [  \"     +    aggregationName )     +     \"  ]  \"  )  )  ;", "}", "return   new    ( aggregationName ,    childType )  ;", "}", "METHOD_END"], "methodName": ["parse"], "fileName": "org.elasticsearch.join.aggregations.ChildrenAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "ChildrenIT . categoryToControl . clear (  )  ;", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" article \"  ,     \" comment \"  )  ,     \" commenter \"  ,     \" keyword \"  ,     \" category \"  ,     \" keyword \"  )  )  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "String [  ]    uniqueCategories    =    new   String [ randomIntBetween (  1  ,     2  5  )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( uniqueCategories . length )  ;    i +  +  )     {", "uniqueCategories [ i ]     =    Integer . toString ( i )  ;", "}", "int   catIndex    =     0  ;", "int   numParentDocs    =    randomIntBetween ( uniqueCategories . length ,     (  ( uniqueCategories . length )     *     5  )  )  ;", "for    ( int   i    =     0  ;    i    <    numParentDocs ;    i +  +  )     {", "String   id    =     \" article -  \"     +    i ;", "String [  ]    categories    =    new   String [ randomIntBetween (  1  ,     1  )  ]  ;", "for    ( int   j    =     0  ;    j    <     ( categories . length )  ;    j +  +  )     {", "String   category    =    categories [ j ]     =    uniqueCategories [  (  ( catIndex +  +  )     %     ( uniqueCategories . length )  )  ]  ;", "ChildrenIT . Control   control    =    ChildrenIT . categoryToControl . get ( category )  ;", "if    ( control    =  =    null )     {", "ChildrenIT . categoryToControl . put ( category ,     ( control    =    new   ChildrenIT . Control ( category )  )  )  ;", "}", "control . articleIds . add ( id )  ;", "}", "requests . add ( createIndexRequest (  \" test \"  ,     \" article \"  ,    id ,    null ,     \" category \"  ,    categories ,     \" randomized \"  ,    true )  )  ;", "}", "String [  ]    commenters    =    new   String [ randomIntBetween (  5  ,     5  0  )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( commenters . length )  ;    i +  +  )     {", "commenters [ i ]     =    Integer . toString ( i )  ;", "}", "int   id    =     0  ;", "for    ( ChildrenIT . Control   control    :    ChildrenIT . categoryToControl . values (  )  )     {", "for    ( String   articleId    :    control . articleIds )     {", "int   numChildDocsPerParent    =    randomIntBetween (  0  ,     5  )  ;", "for    ( int   i    =     0  ;    i    <    numChildDocsPerParent ;    i +  +  )     {", "String   commenter    =    commenters [  ( id    %     ( commenters . length )  )  ]  ;", "String   idValue    =     \" comment -  \"     +     ( id +  +  )  ;", "control . commentIds . add ( idValue )  ;", "Set < String >    ids    =    control . commenterToCommentId . get ( commenter )  ;", "if    ( ids    =  =    null )     {", "control . commenterToCommentId . put ( commenter ,     ( ids    =    new   HashSet <  >  (  )  )  )  ;", "}", "ids . add ( idValue )  ;", "requests . add ( createIndexRequest (  \" test \"  ,     \" comment \"  ,    idValue ,    articleId ,     \" commenter \"  ,    commenter )  )  ;", "}", "}", "}", "requests . add ( createIndexRequest (  \" test \"  ,     \" article \"  ,     \" a \"  ,    null ,     \" category \"  ,    new   String [  ]  {     \" a \"     }  ,     \" randomized \"  ,    false )  )  ;", "requests . add ( createIndexRequest (  \" test \"  ,     \" article \"  ,     \" b \"  ,    null ,     \" category \"  ,    new   String [  ]  {     \" a \"  ,     \" b \"     }  ,     \" randomized \"  ,    false )  )  ;", "requests . add ( createIndexRequest (  \" test \"  ,     \" article \"  ,     \" c \"  ,    null ,     \" category \"  ,    new   String [  ]  {     \" a \"  ,     \" b \"  ,     \" c \"     }  ,     \" randomized \"  ,    false )  )  ;", "requests . add ( createIndexRequest (  \" test \"  ,     \" article \"  ,     \" d \"  ,    null ,     \" category \"  ,    new   String [  ]  {     \" c \"     }  ,     \" randomized \"  ,    false )  )  ;", "requests . add ( createIndexRequest (  \" test \"  ,     \" comment \"  ,     \" e \"  ,     \" a \"  )  )  ;", "requests . add ( createIndexRequest (  \" test \"  ,     \" comment \"  ,     \" f \"  ,     \" c \"  )  )  ;", "indexRandom ( true ,    requests )  ;", "ensureSearchable (  \" test \"  )  ;", "}", "METHOD_END"], "methodName": ["setupCluster"], "fileName": "org.elasticsearch.join.aggregations.ChildrenIT"}, {"methodBody": ["METHOD_START", "{", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( matchQuery (  \" randomized \"  ,    true )  )  . addAggregation ( AggregationBuilders . terms (  \" category \"  )  . field (  \" category \"  )  . size (  1  0  0  0  0  )  . subAggregation ( JoinAggregationBuilders . children (  \" to _ comment \"  ,     \" comment \"  )  . subAggregation ( AggregationBuilders . terms (  \" commenters \"  )  . field (  \" commenter \"  )  . size (  1  0  0  0  0  )  . subAggregation ( AggregationBuilders . topHits (  \" top _ comments \"  )  )  )  )  )  . get (  )  ;", "assertSearchResponse ( searchResponse )  ;", "Terms   categoryTerms    =    searchResponse . getA (  )  . get (  \" category \"  )  ;", "assertThat ( categoryTerms . getBuckets (  )  . size (  )  ,    equalTo ( ChildrenIT . categoryToControl . size (  )  )  )  ;", "for    ( Map . Entry < String ,    ChildrenIT . Control >    entry 1     :    ChildrenIT . categoryToControl . entrySet (  )  )     {", "Terms . Bucket   categoryBucket    =    categoryTerms . getBucketByKey ( entry 1  . getKey (  )  )  ;", "assertThat ( categoryBucket . getKeyAsString (  )  ,    equalTo ( entry 1  . getKey (  )  )  )  ;", "assertThat ( categoryBucket . getDocCount (  )  ,    equalTo (  (  ( long )     ( entry 1  . getValue (  )  . articleIds . size (  )  )  )  )  )  ;", "Children   childrenBucket    =    categoryBucket . getA (  )  . get (  \" to _ comment \"  )  ;", "assertThat ( childrenBucket . getName (  )  ,    equalTo (  \" to _ comment \"  )  )  ;", "assertThat ( childrenBucket . getDocCount (  )  ,    equalTo (  (  ( long )     ( entry 1  . getValue (  )  . commentIds . size (  )  )  )  )  )  ;", "assertThat (  (  ( InternalAggregation )     ( childrenBucket )  )  . getProperty (  \"  _ count \"  )  ,    equalTo (  (  ( long )     ( entry 1  . getValue (  )  . commentIds . size (  )  )  )  )  )  ;", "Terms   commentersTerms    =    childrenBucket . getA (  )  . get (  \" commenters \"  )  ;", "assertThat (  (  ( InternalAggregation )     ( childrenBucket )  )  . getProperty (  \" commenters \"  )  ,    sameInstance ( commentersTerms )  )  ;", "assertThat ( commentersTerms . getBuckets (  )  . size (  )  ,    equalTo ( entry 1  . getValue (  )  . commenterToCommentId . size (  )  )  )  ;", "for    ( Map . Entry < String ,    Set < String >  >    entry 2     :    entry 1  . getValue (  )  . commenterToCommentId . entrySet (  )  )     {", "Terms . Bucket   commentBucket    =    commentersTerms . getBucketByKey ( entry 2  . getKey (  )  )  ;", "assertThat ( commentBucket . getKeyAsString (  )  ,    equalTo ( entry 2  . getKey (  )  )  )  ;", "assertThat ( commentBucket . getDocCount (  )  ,    equalTo (  (  ( long )     ( entry 2  . getValue (  )  . size (  )  )  )  )  )  ;", "TopHits   topHits    =    commentBucket . getA (  )  . get (  \" top _ comments \"  )  ;", "for    ( SearchHit   searchHit    :    topHits . getHits (  )  . getHits (  )  )     {", "assertThat ( entry 2  . getValue (  )  . contains ( searchHit . getId (  )  )  ,    is ( true )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["testChildrenAggs"], "fileName": "org.elasticsearch.join.aggregations.ChildrenIT"}, {"methodBody": ["METHOD_START", "{", "String   indexName    =     \" geo \"  ;", "String   grandParentType    =     \" continent \"  ;", "String   parentType    =     \" country \"  ;", "String   childType    =     \" city \"  ;", "assertAcked ( prepareCreate ( indexName )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,    grandParentType ,    parentType ,    parentType ,    childType )  ,     \" name \"  ,     \" keyword \"  )  )  )  ;", "createIndexRequest ( indexName ,    grandParentType ,     \"  1  \"  ,    null ,     \" name \"  ,     \" europe \"  )  . get (  )  ;", "createIndexRequest ( indexName ,    parentType ,     \"  2  \"  ,     \"  1  \"  ,     \" name \"  ,     \" belgium \"  )  . get (  )  ;", "createIndexRequest ( indexName ,    childType ,     \"  3  \"  ,     \"  2  \"  ,     \" name \"  ,     \" brussels \"  )  . setRouting (  \"  1  \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch ( indexName )  . setQuery ( matchQuery (  \" name \"  ,     \" europe \"  )  )  . addAggregation ( JoinAggregationBuilders . children ( parentType ,    parentType )  . subAggregation ( JoinAggregationBuilders . children ( childType ,    childType )  . subAggregation ( AggregationBuilders . terms (  \" name \"  )  . field (  \" name \"  )  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     1  )  ;", "Children   children    =    response . getA (  )  . get ( parentType )  ;", "assertThat ( children . getName (  )  ,    equalTo ( parentType )  )  ;", "assertThat ( children . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "children    =    children . getA (  )  . get ( childType )  ;", "assertThat ( children . getName (  )  ,    equalTo ( childType )  )  ;", "assertThat ( children . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "Terms   terms    =    children . getA (  )  . get (  \" name \"  )  ;", "assertThat ( terms . getBuckets (  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( terms . getBuckets (  )  . get (  0  )  . getKey (  )  . toString (  )  ,    equalTo (  \" brussels \"  )  )  ;", "assertThat ( terms . getBuckets (  )  . get (  0  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "}", "METHOD_END"], "methodName": ["testHierarchicalChildrenAggs"], "fileName": "org.elasticsearch.join.aggregations.ChildrenIT"}, {"methodBody": ["METHOD_START", "{", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . addAggregation ( JoinAggregationBuilders . children (  \" non - existing \"  ,     \" xyz \"  )  )  . get (  )  ;", "assertSearchResponse ( searchResponse )  ;", "Children   children    =    searchResponse . getA (  )  . get (  \" non - existing \"  )  ;", "assertThat ( children . getName (  )  ,    equalTo (  \" non - existing \"  )  )  ;", "assertThat ( children . getDocCount (  )  ,    equalTo (  0 L )  )  ;", "}", "METHOD_END"], "methodName": ["testNonExistingChildType"], "fileName": "org.elasticsearch.join.aggregations.ChildrenIT"}, {"methodBody": ["METHOD_START", "{", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( matchQuery (  \" randomized \"  ,    false )  )  . addAggregation ( AggregationBuilders . terms (  \" category \"  )  . field (  \" category \"  )  . size (  1  0  0  0  0  )  . subAggregation ( JoinAggregationBuilders . children (  \" to _ comment \"  ,     \" comment \"  )  . subAggregation ( AggregationBuilders . topHits (  \" top _ comments \"  )  . sort (  \"  _ id \"  ,    ASC )  )  )  )  . get (  )  ;", "assertSearchResponse ( searchResponse )  ;", "Terms   categoryTerms    =    searchResponse . getA (  )  . get (  \" category \"  )  ;", "assertThat ( categoryTerms . getBuckets (  )  . size (  )  ,    equalTo (  3  )  )  ;", "for    ( Terms . Bucket   bucket    :    categoryTerms . getBuckets (  )  )     {", "logger . info (  \" bucket =  {  }  \"  ,    bucket . getKey (  )  )  ;", "Children   childrenBucket    =    bucket . getA (  )  . get (  \" to _ comment \"  )  ;", "TopHits   topHits    =    childrenBucket . getA (  )  . get (  \" top _ comments \"  )  ;", "logger . info (  \" total _ hits =  {  }  \"  ,    topHits . getHits (  )  . getTotalHits (  )  )  ;", "for    ( SearchHit   searchHit    :    topHits . getHits (  )  )     {", "logger . info (  \" hit =     {  }     {  }     {  }  \"  ,    searchHit . getSortValues (  )  [  0  ]  ,    searchHit . getType (  )  ,    searchHit . getId (  )  )  ;", "}", "}", "Terms . Bucket   categoryBucket    =    categoryTerms . getBucketByKey (  \" a \"  )  ;", "assertThat ( categoryBucket . getKeyAsString (  )  ,    equalTo (  \" a \"  )  )  ;", "assertThat ( categoryBucket . getDocCount (  )  ,    equalTo (  3 L )  )  ;", "Children   childrenBucket    =    categoryBucket . getA (  )  . get (  \" to _ comment \"  )  ;", "assertThat ( childrenBucket . getName (  )  ,    equalTo (  \" to _ comment \"  )  )  ;", "assertThat ( childrenBucket . getDocCount (  )  ,    equalTo (  2 L )  )  ;", "TopHits   topHits    =    childrenBucket . getA (  )  . get (  \" top _ comments \"  )  ;", "assertThat ( topHits . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( topHits . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" e \"  )  )  ;", "assertThat ( topHits . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \" f \"  )  )  ;", "categoryBucket    =    categoryTerms . getBucketByKey (  \" b \"  )  ;", "assertThat ( categoryBucket . getKeyAsString (  )  ,    equalTo (  \" b \"  )  )  ;", "assertThat ( categoryBucket . getDocCount (  )  ,    equalTo (  2 L )  )  ;", "childrenBucket    =    categoryBucket . getA (  )  . get (  \" to _ comment \"  )  ;", "assertThat ( childrenBucket . getName (  )  ,    equalTo (  \" to _ comment \"  )  )  ;", "assertThat ( childrenBucket . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "topHits    =    childrenBucket . getA (  )  . get (  \" top _ comments \"  )  ;", "assertThat ( topHits . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( topHits . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" f \"  )  )  ;", "categoryBucket    =    categoryTerms . getBucketByKey (  \" c \"  )  ;", "assertThat ( categoryBucket . getKeyAsString (  )  ,    equalTo (  \" c \"  )  )  ;", "assertThat ( categoryBucket . getDocCount (  )  ,    equalTo (  2 L )  )  ;", "childrenBucket    =    categoryBucket . getA (  )  . get (  \" to _ comment \"  )  ;", "assertThat ( childrenBucket . getName (  )  ,    equalTo (  \" to _ comment \"  )  )  ;", "assertThat ( childrenBucket . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "topHits    =    childrenBucket . getA (  )  . get (  \" top _ comments \"  )  ;", "assertThat ( topHits . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( topHits . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" f \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testParentWithMultipleBuckets"], "fileName": "org.elasticsearch.join.aggregations.ChildrenIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" index \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parentType \"  ,     \" childType \"  )  ,     \" name \"  ,     \" keyword \"  ,     \" town \"  ,     \" keyword \"  ,     \" age \"  ,     \" integer \"  )  )  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" parentType \"  ,     \"  1  \"  ,    null ,     \" name \"  ,     \" Bob \"  ,     \" town \"  ,     \" Memphis \"  )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" parentType \"  ,     \"  2  \"  ,    null ,     \" name \"  ,     \" Alice \"  ,     \" town \"  ,     \" Chicago \"  )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" parentType \"  ,     \"  3  \"  ,    null ,     \" name \"  ,     \" Bill \"  ,     \" town \"  ,     \" Chicago \"  )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" childType \"  ,     \"  4  \"  ,     \"  1  \"  ,     \" name \"  ,     \" Jill \"  ,     \" age \"  ,     5  )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" childType \"  ,     \"  5  \"  ,     \"  1  \"  ,     \" name \"  ,     \" Joey \"  ,     \" age \"  ,     3  )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" childType \"  ,     \"  6  \"  ,     \"  2  \"  ,     \" name \"  ,     \" John \"  ,     \" age \"  ,     2  )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" childType \"  ,     \"  7  \"  ,     \"  3  \"  ,     \" name \"  ,     \" Betty \"  ,     \" age \"  ,     6  )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" childType \"  ,     \"  8  \"  ,     \"  3  \"  ,     \" name \"  ,     \" Dan \"  ,     \" age \"  ,     1  )  )  ;", "indexRandom ( true ,    requests )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" index \"  )  . setSize (  0  )  . addAggregation ( AggregationBuilders . terms (  \" towns \"  )  . field (  \" town \"  )  . subAggregation ( AggregationBuilders . terms (  \" parent _ names \"  )  . field (  \" name \"  )  . subAggregation ( JoinAggregationBuilders . children (  \" child _ docs \"  ,     \" childType \"  )  )  )  )  . get (  )  ;", "Terms   towns    =    response . getA (  )  . get (  \" towns \"  )  ;", "assertThat ( towns . getBuckets (  )  . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( towns . getBuckets (  )  . get (  0  )  . getKeyAsString (  )  ,    equalTo (  \" Chicago \"  )  )  ;", "assertThat ( towns . getBuckets (  )  . get (  0  )  . getDocCount (  )  ,    equalTo (  2 L )  )  ;", "Terms   parents    =    towns . getBuckets (  )  . get (  0  )  . getA (  )  . get (  \" parent _ names \"  )  ;", "assertThat ( parents . getBuckets (  )  . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( parents . getBuckets (  )  . get (  0  )  . getKeyAsString (  )  ,    equalTo (  \" Alice \"  )  )  ;", "assertThat ( parents . getBuckets (  )  . get (  0  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "Children   children    =    parents . getBuckets (  )  . get (  0  )  . getA (  )  . get (  \" child _ docs \"  )  ;", "assertThat ( children . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( parents . getBuckets (  )  . get (  1  )  . getKeyAsString (  )  ,    equalTo (  \" Bill \"  )  )  ;", "assertThat ( parents . getBuckets (  )  . get (  1  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "children    =    parents . getBuckets (  )  . get (  1  )  . getA (  )  . get (  \" child _ docs \"  )  ;", "assertThat ( children . getDocCount (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( towns . getBuckets (  )  . get (  1  )  . getKeyAsString (  )  ,    equalTo (  \" Memphis \"  )  )  ;", "assertThat ( towns . getBuckets (  )  . get (  1  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "parents    =    towns . getBuckets (  )  . get (  1  )  . getA (  )  . get (  \" parent _ names \"  )  ;", "assertThat ( parents . getBuckets (  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( parents . getBuckets (  )  . get (  0  )  . getKeyAsString (  )  ,    equalTo (  \" Bob \"  )  )  ;", "assertThat ( parents . getBuckets (  )  . get (  0  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "children    =    parents . getBuckets (  )  . get (  0  )  . getA (  )  . get (  \" child _ docs \"  )  ;", "assertThat ( children . getDocCount (  )  ,    equalTo (  2 L )  )  ;", "}", "METHOD_END"], "methodName": ["testPostCollectAllLeafReaders"], "fileName": "org.elasticsearch.join.aggregations.ChildrenIT"}, {"methodBody": ["METHOD_START", "{", "String   indexName    =     \" prodcatalog \"  ;", "String   masterType    =     \" masterprod \"  ;", "String   childType    =     \" variantsku \"  ;", "assertAcked ( prepareCreate ( indexName )  . setSettings ( Settings . builder (  )  . put ( SETTING _ NUMBER _ OF _ SHARDS ,     1  )  . put ( SETTING _ NUMBER _ OF _ REPLICAS ,     0  )  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,    masterType ,    childType )  ,     \" brand \"  ,     \" text \"  ,     \" name \"  ,     \" keyword \"  ,     \" material \"  ,     \" text \"  ,     \" color \"  ,     \" keyword \"  ,     \" size \"  ,     \" keyword \"  )  )  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "requests . add ( createIndexRequest ( indexName ,    masterType ,     \"  1  \"  ,    null ,     \" brand \"  ,     \" Levis \"  ,     \" name \"  ,     \" Style    5  0  1  \"  ,     \" material \"  ,     \" Denim \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  3  \"  ,     \"  1  \"  ,     \" color \"  ,     \" blue \"  ,     \" size \"  ,     \"  3  2  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  4  \"  ,     \"  1  \"  ,     \" color \"  ,     \" blue \"  ,     \" size \"  ,     \"  3  4  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  5  \"  ,     \"  1  \"  ,     \" color \"  ,     \" blue \"  ,     \" size \"  ,     \"  3  6  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  6  \"  ,     \"  1  \"  ,     \" color \"  ,     \" black \"  ,     \" size \"  ,     \"  3  8  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  7  \"  ,     \"  1  \"  ,     \" color \"  ,     \" black \"  ,     \" size \"  ,     \"  4  0  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  8  \"  ,     \"  1  \"  ,     \" color \"  ,     \" gray \"  ,     \" size \"  ,     \"  3  6  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    masterType ,     \"  2  \"  ,    null ,     \" brand \"  ,     \" Wrangler \"  ,     \" name \"  ,     \" Regular   Cut \"  ,     \" material \"  ,     \" Leather \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  9  \"  ,     \"  2  \"  ,     \" color \"  ,     \" blue \"  ,     \" size \"  ,     \"  3  2  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  1  0  \"  ,     \"  2  \"  ,     \" color \"  ,     \" blue \"  ,     \" size \"  ,     \"  3  4  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  1  2  \"  ,     \"  2  \"  ,     \" color \"  ,     \" black \"  ,     \" size \"  ,     \"  3  6  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  1  3  \"  ,     \"  2  \"  ,     \" color \"  ,     \" black \"  ,     \" size \"  ,     \"  3  8  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  1  4  \"  ,     \"  2  \"  ,     \" color \"  ,     \" black \"  ,     \" size \"  ,     \"  4  0  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  1  5  \"  ,     \"  2  \"  ,     \" color \"  ,     \" orange \"  ,     \" size \"  ,     \"  3  6  \"  )  )  ;", "requests . add ( createIndexRequest ( indexName ,    childType ,     \"  1  6  \"  ,     \"  2  \"  ,     \" color \"  ,     \" green \"  ,     \" size \"  ,     \"  4  4  \"  )  )  ;", "indexRandom ( true ,    requests )  ;", "SearchResponse   response    =    client (  )  . prepareSearch ( indexName )  . setQuery ( JoinQueryBuilders . hasChildQuery ( childType ,    termQuery (  \" color \"  ,     \" orange \"  )  ,    None )  )  . addAggregation ( JoinAggregationBuilders . children (  \" my - refinements \"  ,    childType )  . subAggregation ( AggregationBuilders . terms (  \" my - colors \"  )  . field (  \" color \"  )  )  . subAggregation ( AggregationBuilders . terms (  \" my - sizes \"  )  . field (  \" size \"  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     1  )  ;", "Children   childrenAgg    =    response . getA (  )  . get (  \" my - refinements \"  )  ;", "assertThat ( childrenAgg . getDocCount (  )  ,    equalTo (  7 L )  )  ;", "Terms   termsAgg    =    childrenAgg . getA (  )  . get (  \" my - colors \"  )  ;", "assertThat ( termsAgg . getBuckets (  )  . size (  )  ,    equalTo (  4  )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \" black \"  )  . getDocCount (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \" blue \"  )  . getDocCount (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \" green \"  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \" orange \"  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "termsAgg    =    childrenAgg . getA (  )  . get (  \" my - sizes \"  )  ;", "assertThat ( termsAgg . getBuckets (  )  . size (  )  ,    equalTo (  6  )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \"  3  6  \"  )  . getDocCount (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \"  3  2  \"  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \"  3  4  \"  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \"  3  8  \"  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \"  4  0  \"  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( termsAgg . getBucketByKey (  \"  4  4  \"  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "}", "METHOD_END"], "methodName": ["testPostCollection"], "fileName": "org.elasticsearch.join.aggregations.ChildrenIT"}, {"methodBody": ["METHOD_START", "{", "String   indexName    =     \" xyz \"  ;", "assertAcked ( prepareCreate ( indexName )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  ,     \" name \"  ,     \" keyword \"  )  )  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "requests . add ( createIndexRequest ( indexName ,     \" parent \"  ,     \"  1  \"  ,    null )  )  ;", "requests . add ( createIndexRequest ( indexName ,     \" child \"  ,     \"  2  \"  ,     \"  1  \"  ,     \" count \"  ,     1  )  )  ;", "requests . add ( createIndexRequest ( indexName ,     \" child \"  ,     \"  3  \"  ,     \"  1  \"  ,     \" count \"  ,     1  )  )  ;", "requests . add ( createIndexRequest ( indexName ,     \" child \"  ,     \"  4  \"  ,     \"  1  \"  ,     \" count \"  ,     1  )  )  ;", "requests . add ( createIndexRequest ( indexName ,     \" child \"  ,     \"  5  \"  ,     \"  1  \"  ,     \" count \"  ,     1  )  )  ;", "indexRandom ( true ,    requests )  ;", "for    ( int   i    =     0  ;    i    <     1  0  ;    i +  +  )     {", "SearchResponse   searchResponse    =    client (  )  . prepareSearch ( indexName )  . addAggregation ( JoinAggregationBuilders . children (  \" children \"  ,     \" child \"  )  . subAggregation ( AggregationBuilders . sum (  \" counts \"  )  . field (  \" count \"  )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "Children   children    =    searchResponse . getA (  )  . get (  \" children \"  )  ;", "assertThat ( children . getDocCount (  )  ,    equalTo (  4 L )  )  ;", "Sum   count    =    children . getA (  )  . get (  \" counts \"  )  ;", "assertThat ( count . getValue (  )  ,    equalTo (  4  .  0  )  )  ;", "String   idToUpdate    =    Integer . toString (  (  2     +     ( randomInt (  3  )  )  )  )  ;", "UpdateResponse   updateResponse ;", "updateResponse    =    client (  )  . prepareUpdate ( indexName ,     \" doc \"  ,    idToUpdate )  . setRouting (  \"  1  \"  )  . setDoc ( INDEX _ CONTENT _ TYPE ,     \" count \"  ,     1  )  . setDetectNoop ( false )  . get (  )  ;", "assertThat ( updateResponse . getVersion (  )  ,    greaterThan (  1 L )  )  ;", "refresh (  )  ;", "}", "}", "METHOD_END"], "methodName": ["testWithDeletes"], "fileName": "org.elasticsearch.join.aggregations.ChildrenIT"}, {"methodBody": ["METHOD_START", "{", "return   new   ChildrenAggregationBuilder ( name ,    childType )  ;", "}", "METHOD_END"], "methodName": ["children"], "fileName": "org.elasticsearch.join.aggregations.JoinAggregationBuilders"}, {"methodBody": ["METHOD_START", "{", "return   Arrays . asList ( new   StringField ( IdFieldMapper . NAME ,    Uid . encodeId ( childId )  ,    Store . NO )  ,    new   StringField (  \" join _ field \"  ,    ParentToChildrenAggregatorTests . CHILD _ TYPE ,    Store . NO )  ,    ParentToChildrenAggregatorTests . createJoinField ( ParentToChildrenAggregatorTests . PARENT _ TYPE ,    parentId )  ,    new   SortedNumericDocValuesField (  \" number \"  ,    value )  )  ;", "}", "METHOD_END"], "methodName": ["createChildDocument"], "fileName": "org.elasticsearch.join.aggregations.ParentToChildrenAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "return   new   SortedDocValuesField (  (  \" join _ field #  \"     +    parentType )  ,    new   BytesRef ( id )  )  ;", "}", "METHOD_END"], "methodName": ["createJoinField"], "fileName": "org.elasticsearch.join.aggregations.ParentToChildrenAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put ( SETTING _ VERSION _ CREATED ,    CURRENT )  . build (  )  ;", "return   new   ParentJoinFieldMapper . Builder (  \" join _ field \"  )  . addParent (  . PARENT _ TYPE ,    Collections . singleton (  . CHILD _ TYPE )  )  . build ( new   BuilderContext ( settings ,    new   ContentPath (  0  )  )  )  ;", "}", "METHOD_END"], "methodName": ["createJoinFieldMapper"], "fileName": "org.elasticsearch.join.aggregations.ParentToChildrenAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "return   Arrays . asList ( new   StringField ( IdFieldMapper . NAME ,    Uid . encodeId ( id )  ,    Store . NO )  ,    new   StringField (  \" join _ field \"  ,    ParentToChildrenAggregatorTests . PARENT _ TYPE ,    Store . NO )  ,    ParentToChildrenAggregatorTests . createJoinField ( ParentToChildrenAggregatorTests . PARENT _ TYPE ,    id )  )  ;", "}", "METHOD_END"], "methodName": ["createParentDocument"], "fileName": "org.elasticsearch.join.aggregations.ParentToChildrenAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Tuple < Integer ,    Integer >  >    expectedValues    =    new   HashMap <  >  (  )  ;", "int   numParents    =    randomIntBetween (  1  ,     1  0  )  ;", "for    ( int   i    =     0  ;    i    <    numParents ;    i +  +  )     {", "String   parent    =     \" parent \"     +    i ;", "iw . addDocument (  . createParentDocument ( parent )  )  ;", "int   numChildren    =    randomIntBetween (  1  ,     1  0  )  ;", "int   minValue    =    Integer . MAX _ VALUE ;", "for    ( int   c    =     0  ;    c    <    numChildren ;    c +  +  )     {", "int   randomValue    =    randomIntBetween (  0  ,     1  0  0  )  ;", "minValue    =    Math . min ( minValue ,    randomValue )  ;", "iw . addDocument (  . createChildDocument (  (  (  (  \" child \"     +    c )     +     \"  _  \"  )     +    parent )  ,    parent ,    randomValue )  )  ;", "}", "expectedValues . put ( parent ,    new   Tuple ( numChildren ,    minValue )  )  ;", "}", "return   expectedValues ;", "}", "METHOD_END"], "methodName": ["setupIndex"], "fileName": "org.elasticsearch.join.aggregations.ParentToChildrenAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "ChildrenAggregationBuilder   aggregationBuilder    =    new   ChildrenAggregationBuilder (  \"  _ name \"  ,    ParentToChildrenAggregatorTests . CHILD _ TYPE )  ;", "aggregationBuilder . subAggregation ( new   MinAggregationBuilder (  \" in _ child \"  )  . field (  \" number \"  )  )  ;", "MappedFieldType   fieldType    =    new   NumberFieldType ( NumberType . LONG )  ;", "fieldType . setName (  \" number \"  )  ;", "InternalChildren   result    =    search ( indexSearcher ,    query ,    aggregationBuilder ,    fieldType )  ;", "verify . accept ( result )  ;", "}", "METHOD_END"], "methodName": ["testCase"], "fileName": "org.elasticsearch.join.aggregations.ParentToChildrenAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "Directory   directory    =    newDirectory (  )  ;", "RandomIndexWriter   indexWriter    =    new   RandomIndexWriter ( random (  )  ,    directory )  ;", "indexWriter . close (  )  ;", "IndexReader   indexReader    =    DirectoryReader . open ( directory )  ;", "testCase ( new   MatchAllDocsQuery (  )  ,    newSearcher ( indexReader ,    false ,    true )  ,     (    p )     -  >     {", "assertEquals (  0  ,    p . getDocCount (  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,     (  ( InternalMin )     ( p . getAggregations (  )  . get (  \" in _ child \"  )  )  )  . getValue (  )  ,    Double . MIN _ VALUE )  ;", "}  )  ;", "indexReader . close (  )  ;", "directory . close (  )  ;", "}", "METHOD_END"], "methodName": ["testNoDocs"], "fileName": "org.elasticsearch.join.aggregations.ParentToChildrenAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "Directory   directory    =    newDirectory (  )  ;", "RandomIndexWriter   indexWriter    =    new   RandomIndexWriter ( random (  )  ,    directory )  ;", "final   Map < String ,    Tuple < Integer ,    Integer >  >    expectedParentChildRelations    =     . setupIndex ( indexWriter )  ;", "indexWriter . close (  )  ;", "IndexReader   indexReader    =    ElasticsearchDirectoryReader . wrap ( DirectoryReader . open ( directory )  ,    new   ShardId ( new   Index (  \" foo \"  ,     \"  _ na _  \"  )  ,     1  )  )  ;", "IndexSearcher   indexSearcher    =    newSearcher ( indexReader ,    false ,    true )  ;", "testCase ( new   MatchAllDocsQuery (  )  ,    indexSearcher ,     (    child )     -  >     {", "int   expectedTotalChildren    =     0  ;", "int   expectedMinValue    =    Integer . MAX _ VALUE ;", "for    ( Tuple < Integer ,    Integer >    expectedValues    :    expectedParentChildRelations . values (  )  )     {", "expectedTotalChildren    +  =    expectedValues . v 1  (  )  ;", "expectedMinValue    =    Math . min ( expectedMinValue ,    expectedValues . v 2  (  )  )  ;", "}", "assertEquals ( expectedTotalChildren ,    child . getDocCount (  )  )  ;", "assertEquals ( expectedMinValue ,     (  ( InternalMin )     ( child . getAggregations (  )  . get (  \" in _ child \"  )  )  )  . getValue (  )  ,    Double . MIN _ VALUE )  ;", "}  )  ;", "for    ( String   parent    :    expectedParentChildRelations . keySet (  )  )     {", "testCase ( new   TermInSetQuery ( IdFieldMapper . NAME ,    Uid . encodeId ( parent )  )  ,    indexSearcher ,     (    child )     -  >     {", "assertEquals (  (  ( long )     ( expectedParentChildRelations . get ( parent )  . v 1  (  )  )  )  ,    child . getDocCount (  )  )  ;", "assertEquals ( expectedParentChildRelations . get ( parent )  . v 2  (  )  ,     (  ( InternalMin )     ( child . getAggregations (  )  . get (  \" in _ child \"  )  )  )  . getValue (  )  ,    Double . MIN _ VALUE )  ;", "}  )  ;", "}", "indexReader . close (  )  ;", "directory . close (  )  ;", "}", "METHOD_END"], "methodName": ["testParentChild"], "fileName": "org.elasticsearch.join.aggregations.ParentToChildrenAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "return   parseXContent ( parser ,    new   ParsedChildren (  )  ,    name )  ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.join.aggregations.ParsedChildren"}, {"methodBody": ["METHOD_START", "{", "fieldType (  )  . mapper    =    mapper ;", "}", "METHOD_END"], "methodName": ["setFieldMapper"], "fileName": "org.elasticsearch.join.mapper.MetaJoinFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   new   TermQuery ( new   Term ( name (  )  . substring (  0  ,    name (  )  . indexOf (  '  #  '  )  )  ,    type )  )  ;", "}", "METHOD_END"], "methodName": ["getChildFilter"], "fileName": "org.elasticsearch.join.mapper.ParentIdFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   children ;", "}", "METHOD_END"], "methodName": ["getChildren"], "fileName": "org.elasticsearch.join.mapper.ParentIdFieldMapper"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "for    ( String   child    :    children )     {", "builder . add ( getChildFilter ( child )  ,    SHOULD )  ;", "}", "return   new   ConstantScoreQuery ( builder . build (  )  )  ;", "}", "METHOD_END"], "methodName": ["getChildrenFilter"], "fileName": "org.elasticsearch.join.mapper.ParentIdFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   new   TermQuery ( new   Term ( name (  )  . substring (  0  ,    name (  )  . indexOf (  '  #  '  )  )  ,    parentName )  )  ;", "}", "METHOD_END"], "methodName": ["getParentFilter"], "fileName": "org.elasticsearch.join.mapper.ParentIdFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   parentName ;", "}", "METHOD_END"], "methodName": ["getParentName"], "fileName": "org.elasticsearch.join.mapper.ParentIdFieldMapper"}, {"methodBody": ["METHOD_START", "{", "if    ( settings . getIndexMetaData (  )  . isRoutingPartitionedIndex (  )  )     {", "throw   new   IllegalStateException (  (  (  (  (  (  (  \" cannot   create      field    [  \"     +    name )     +     \"  ]     \"  )     +     \" for   the   partitioned   index    \"  )     +     \"  [  \"  )     +     ( settings . getIndex (  )  . getName (  )  )  )     +     \"  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkIndexCompatibility"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapper"}, {"methodBody": ["METHOD_START", "{", "if    ( path . pathAsText ( name )  . contains (  \"  .  \"  )  )     {", "throw   new   IllegalArgumentException (  (  (  (  \"    field    [  \"     +     ( path . pathAsText ( name )  )  )     +     \"  ]     \"  )     +     \" cannot   be   added   inside   an   object   or   in   a   multi - field \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkObjectOrNested"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapper"}, {"methodBody": ["METHOD_START", "{", "Set < String >    children    =    new   HashSet <  >  (  )  ;", "List < String >    conflicts    =    new   ArrayList <  >  (  )  ;", "for    ( ParentId   mapper    :    mappers )     {", "for    ( String   child    :    mapper . getChildren (  )  )     {", "if    (  ( children . add ( child )  )     =  =    false )     {", "conflicts . add (  (  (  \"  [  \"     +    child )     +     \"  ]    cannot   have   multiple   parents \"  )  )  ;", "}", "}", "}", "if    (  ( conflicts . isEmpty (  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  (  \" invalid   definition   for   join   field    [  \"     +    name )     +     \"  ]  :  \\ n \"  )     +     ( conflicts . toString (  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkParentFields"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapper"}, {"methodBody": ["METHOD_START", "{", "MetaJoinFieldMapper . MetaJoinFieldType   fieldType    =     (  ( MetaJoinFieldMapper . MetaJoinFieldType )     ( service . fullName ( MetaJoinFieldMapper . NAME )  )  )  ;", "return   fieldType    =  =    null    ?    null    :    fieldType . getMapper (  )  ;", "}", "METHOD_END"], "methodName": ["getMapper"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapper"}, {"methodBody": ["METHOD_START", "{", "for    ( ParentIdFieldMapper   mapper    :    parentIdFields )     {", "if    ( isParent    &  &     ( name . equals ( mapper . getParentName (  )  )  )  )     {", "return   mapper ;", "} else", "if    (  ( isParent    =  =    false )     &  &     ( mapper . getChildren (  )  . contains ( name )  )  )     {", "return   mapper ;", "}", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["getParentIdFieldMapper"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return    ( joinFieldName    +     \"  #  \"  )     +    parentName ;", "}", "METHOD_END"], "methodName": ["getParentIdFieldName"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   parentIdFields . stream (  )  . anyMatch (  (    mapper )     -  >    mapper . getChildren (  )  . contains ( name )  )  ;", "}", "METHOD_END"], "methodName": ["hasChild"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   parentIdFields . stream (  )  . anyMatch (  (    mapper )     -  >    name . equals ( mapper . getParentName (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["hasParent"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapper"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . field (  \" child \"  ,     \" grand _ child \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IndexService   service    =    createIndex (  \" test \"  )  ;", "DocumentMapper   docMapper    =    service . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MAPPING _ UPDATE )  ;", "assertTrue (  (  ( docMapper . mappers (  )  . getMapper (  \" join _ field \"  )  )     =  =     (  . getMapper ( service . mapperService (  )  )  )  )  )  ;", "assertFalse ( service . mapperService (  )  . fullName (  \" join _ field \"  )  . eagerGlobalOrdinals (  )  )  ;", "assertNotNull ( service . mapperService (  )  . fullName (  \" join _ field # parent \"  )  )  ;", "assertTrue ( service . mapperService (  )  . fullName (  \" join _ field # parent \"  )  . eagerGlobalOrdinals (  )  )  ;", "assertNotNull ( service . mapperService (  )  . fullName (  \" join _ field # child \"  )  )  ;", "assertTrue ( service . mapperService (  )  . fullName (  \" join _ field # child \"  )  . eagerGlobalOrdinals (  )  )  ;", "mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . field (  \" eager _ global _ ordinals \"  ,    false )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . field (  \" child \"  ,     \" grand _ child \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "service . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MAPPING _ UPDATE )  ;", "assertFalse ( service . mapperService (  )  . fullName (  \" join _ field \"  )  . eagerGlobalOrdinals (  )  )  ;", "assertNotNull ( service . mapperService (  )  . fullName (  \" join _ field # parent \"  )  )  ;", "assertFalse ( service . mapperService (  )  . fullName (  \" join _ field # parent \"  )  . eagerGlobalOrdinals (  )  )  ;", "assertNotNull ( service . mapperService (  )  . fullName (  \" join _ field # child \"  )  )  ;", "assertFalse ( service . mapperService (  )  . fullName (  \" join _ field # child \"  )  . eagerGlobalOrdinals (  )  )  ;", "}", "METHOD_END"], "methodName": ["testEagerGlobalOrdinals"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" number \"  )  . field (  \" type \"  ,     \" integer \"  )  . startObject (  \" fields \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IndexService   indexService    =    createIndex (  \" test \"  )  ;", "MapperParsingException   exc    =    expectThrows ( MapperParsingException . class ,     (  )     -  >    indexServiceService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MapperService . MergeReason . MAPPING _ UPDATE )  )  ;", "assertThat ( exc . getRootCause (  )  . getMessage (  )  ,    containsString (  \" join   field    [ number . join _ field ]    cannot   be   added   inside   an   object   or   in   a   multi - field \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidJoinFieldInsideMultiFields"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" object \"  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IndexService   indexService    =    createIndex (  \" test \"  )  ;", "MapperParsingException   exc    =    expectThrows ( MapperParsingException . class ,     (  )     -  >    indexServiceService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MapperService . MergeReason . MAPPING _ UPDATE )  )  ;", "assertThat ( exc . getRootCause (  )  . getMessage (  )  ,    containsString (  \" join   field    [ object . join _ field ]    cannot   be   added   inside   an   object   or   in   a   multi - field \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidJoinFieldInsideObject"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "IndexService   indexService    =    createIndex (  \" test \"  )  ;", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . field (  \" child \"  ,     \" grand _ child \"  )  . endObject (  )  . endObject (  )  . startObject (  \" another _ join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" product \"  ,     \" item \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalArgumentException   exc    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    indexServiceService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MapperService . MergeReason . MAPPING _ UPDATE )  )  ;", "assertThat ( exc . getMessage (  )  ,    containsString (  \" Field    [  _ parent _ join ]    is   defined   twice   in    [ type ]  \"  )  )  ;", "}", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . field (  \" child \"  ,     \" grand _ child \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "indexServiceService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MAPPING _ UPDATE )  ;", "String   updateMapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" another _ join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalArgumentException   exc    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    indexServiceService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( updateMapping )  ,    MapperService . MergeReason . MAPPING _ UPDATE )  )  ;", "assertThat ( exc . getMessage (  )  ,    containsString (  \" Field    [  _ parent _ join ]    is   defined   twice   in    [ type ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMultipleJoinFields"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . field (  \" child \"  ,     \" grand _ child \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IndexService   service    =    createIndex (  \" test \"  )  ;", "DocumentMapper   docMapper    =    service . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MAPPING _ UPDATE )  ;", "assertTrue (  (  ( docMapper . mappers (  )  . getMapper (  \" join _ field \"  )  )     =  =     (  . getMapper ( service . mapperService (  )  )  )  )  )  ;", "ParsedDocument   doc    =    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  0  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . endObject (  )  )  ,    JSON )  )  ;", "assertNull ( doc . rootDoc (  )  . getBinaryValue (  \" join _ field \"  )  )  ;", "doc    =    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" join _ field \"  ,     \" parent \"  )  . endObject (  )  )  ,    JSON )  )  ;", "assertEquals (  \"  1  \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field # parent \"  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" parent \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field \"  )  . utf 8 ToString (  )  )  ;", "doc    =    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  2  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" join _ field \"  )  . field (  \" name \"  ,     \" child \"  )  . field (  \" parent \"  ,     \"  1  \"  )  . endObject (  )  . endObject (  )  )  ,    JSON )  . routing (  \"  1  \"  )  )  ;", "assertEquals (  \"  1  \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field # parent \"  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \"  2  \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field # child \"  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" child \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field \"  )  . utf 8 ToString (  )  )  ;", "MapperException   exc    =    expectThrows ( MapperParsingException . class ,     (  )     -  >    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  2  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" join _ field \"  ,     \" child \"  )  . endObject (  )  )  ,    XContentType . JSON )  . routing (  \"  1  \"  )  )  )  ;", "assertThat ( exc . getRootCause (  )  . getMessage (  )  ,    containsString (  \"  [ parent ]    is   missing   for   join   field    [ join _ field ]  \"  )  )  ;", "exc    =    expectThrows ( MapperParsingException . class ,     (  )     -  >    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  2  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" join _ field \"  )  . field (  \" name \"  ,     \" child \"  )  . field (  \" parent \"  ,     \"  1  \"  )  . endObject (  )  . endObject (  )  )  ,    XContentType . JSON )  )  )  ;", "assertThat ( exc . getRootCause (  )  . getMessage (  )  ,    containsString (  \"  [ routing ]    is   missing   for   join   field    [ join _ field ]  \"  )  )  ;", "doc    =    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  3  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" join _ field \"  )  . field (  \" name \"  ,     \" grand _ child \"  )  . field (  \" parent \"  ,     \"  2  \"  )  . endObject (  )  . endObject (  )  )  ,    JSON )  . routing (  \"  1  \"  )  )  ;", "assertEquals (  \"  2  \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field # child \"  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" grand _ child \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field \"  )  . utf 8 ToString (  )  )  ;", "exc    =    expectThrows ( MapperParsingException . class ,     (  )     -  >    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" join _ field \"  ,     \" unknown \"  )  . endObject (  )  )  ,    XContentType . JSON )  )  )  ;", "assertThat ( exc . getRootCause (  )  . getMessage (  )  ,    containsString (  \" unknown   join   name    [ unknown ]    for   field    [ join _ field ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultipleLevels"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IndexService   service    =    createIndex (  \" test \"  )  ;", "DocumentMapper   docMapper    =    serviceService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MAPPING _ UPDATE )  ;", "ParsedDocument   doc    =    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  2  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" join _ field \"  )  . field (  \" name \"  ,     \" child \"  )  . field (  \" parent \"  ,     1  )  . endObject (  )  . endObject (  )  )  ,    JSON )  . routing (  \"  1  \"  )  )  ;", "assertEquals (  \"  1  \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field # parent \"  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" child \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field \"  )  . utf 8 ToString (  )  )  ;", "doc    =    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  2  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" join _ field \"  )  . field (  \" name \"  ,     \" child \"  )  . field (  \" parent \"  ,     1  .  0  )  . endObject (  )  . endObject (  )  )  ,    JSON )  . routing (  \"  1  \"  )  )  ;", "assertEquals (  \"  1  .  0  \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field # parent \"  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" child \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field \"  )  . utf 8 ToString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParentIdSpecifiedAsNumber"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IndexService   service    =    createIndex (  \" test \"  )  ;", "DocumentMapper   docMapper    =    service . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MAPPING _ UPDATE )  ;", "assertTrue (  (  ( docMapper . mappers (  )  . getMapper (  \" join _ field \"  )  )     =  =     (  . getMapper ( service . mapperService (  )  )  )  )  )  ;", "ParsedDocument   doc    =    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  0  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . endObject (  )  )  ,    JSON )  )  ;", "assertNull ( doc . rootDoc (  )  . getBinaryValue (  \" join _ field \"  )  )  ;", "doc    =    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" join _ field \"  ,     \" parent \"  )  . endObject (  )  )  ,    JSON )  )  ;", "assertEquals (  \"  1  \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field # parent \"  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" parent \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field \"  )  . utf 8 ToString (  )  )  ;", "doc    =    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  2  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" join _ field \"  )  . field (  \" name \"  ,     \" child \"  )  . field (  \" parent \"  ,     \"  1  \"  )  . endObject (  )  . endObject (  )  )  ,    JSON )  . routing (  \"  1  \"  )  )  ;", "assertEquals (  \"  1  \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field # parent \"  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" child \"  ,    doc . rootDoc (  )  . getBinaryValue (  \" join _ field \"  )  . utf 8 ToString (  )  )  ;", "MapperException   exc    =    expectThrows ( MapperParsingException . class ,     (  )     -  >    docMapper . parse ( SourceToParse . source (  \" test \"  ,     \" type \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" join _ field \"  ,     \" unknown \"  )  . endObject (  )  )  ,    XContentType . JSON )  )  )  ;", "assertThat ( exc . getRootCause (  )  . getMessage (  )  ,    containsString (  \" unknown   join   name    [ unknown ]    for   field    [ join _ field ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSingleLevel"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . array (  \" child \"  ,     \" grand _ child 1  \"  ,     \" grand _ child 2  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IndexService   indexService    =    createIndex (  \" test \"  )  ;", "DocumentMapper   docMapper    =    indexService . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( mapping )  ,    MAPPING _ UPDATE )  ;", "assertTrue (  (  ( docMapper . mappers (  )  . getMapper (  \" join _ field \"  )  )     =  =     (  . getMapper ( indexService . mapperService (  )  )  )  )  )  ;", "{", "final   String   updateMapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . array (  \" child \"  ,     \" grand _ child 1  \"  ,     \" grand _ child 2  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalStateException   exc    =    expectThrows ( IllegalStateException . class ,     (  )     -  >    indexService . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( updateMapping )  ,    MapperService . MergeReason . MAPPING _ UPDATE )  )  ;", "assertThat ( exc . getMessage (  )  ,    containsString (  \" cannot   remove   parent    [ parent ]    in   join   field    [ join _ field ]  \"  )  )  ;", "}", "{", "final   String   updateMapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . field (  \" child \"  ,     \" grand _ child 1  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalStateException   exc    =    expectThrows ( IllegalStateException . class ,     (  )     -  >    indexService . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( updateMapping )  ,    MapperService . MergeReason . MAPPING _ UPDATE )  )  ;", "assertThat ( exc . getMessage (  )  ,    containsString (  \" cannot   remove   child    [ grand _ child 2  ]    in   join   field    [ join _ field ]  \"  )  )  ;", "}", "{", "final   String   updateMapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" uber _ parent \"  ,     \" parent \"  )  . field (  \" parent \"  ,     \" child \"  )  . array (  \" child \"  ,     \" grand _ child 1  \"  ,     \" grand _ child 2  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalStateException   exc    =    expectThrows ( IllegalStateException . class ,     (  )     -  >    indexService . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( updateMapping )  ,    MapperService . MergeReason . MAPPING _ UPDATE )  )  ;", "assertThat ( exc . getMessage (  )  ,    containsString (  \" cannot   create   child    [ parent ]    from   an   existing   parent \"  )  )  ;", "}", "{", "final   String   updateMapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,     \" child \"  )  . array (  \" child \"  ,     \" grand _ child 1  \"  ,     \" grand _ child 2  \"  )  . field (  \" grand _ child 2  \"  ,     \" grand _ grand _ child \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "IllegalStateException   exc    =    expectThrows ( IllegalStateException . class ,     (  )     -  >    indexService . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( updateMapping )  ,    MapperService . MergeReason . MAPPING _ UPDATE )  )  ;", "assertThat ( exc . getMessage (  )  ,    containsString (  \" cannot   create   parent    [ grand _ child 2  ]    from   an   existing   child ]  \"  )  )  ;", "}", "{", "final   String   updateMapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . array (  \" parent \"  ,     \" child \"  ,     \" child 2  \"  )  . array (  \" child \"  ,     \" grand _ child 1  \"  ,     \" grand _ child 2  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "docMapper    =    indexService . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( updateMapping )  ,    MAPPING _ UPDATE )  ;", "assertTrue (  (  ( docMapper . mappers (  )  . getMapper (  \" join _ field \"  )  )     =  =     (  . getMapper ( indexService . mapperService (  )  )  )  )  )  ;", "mapper    =     . getMapper ( indexService . mapperService (  )  )  ;", "assertTrue ( mapper . hasChild (  \" child 2  \"  )  )  ;", "assertFalse ( mapper . hasParent (  \" child 2  \"  )  )  ;", "assertTrue ( mapper . hasChild (  \" grand _ child 2  \"  )  )  ;", "assertFalse ( mapper . hasParent (  \" grand _ child 2  \"  )  )  ;", "}", "{", "final   String   updateMapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . array (  \" parent \"  ,     \" child \"  ,     \" child 2  \"  )  . array (  \" child \"  ,     \" grand _ child 1  \"  ,     \" grand _ child 2  \"  )  . array (  \" other \"  ,     \" child _ other 1  \"  ,     \" child _ other 2  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "docMapper    =    indexService . mapperService (  )  . merge (  \" type \"  ,    new   CompressedXContent ( updateMapping )  ,    MAPPING _ UPDATE )  ;", "assertTrue (  (  ( docMapper . mappers (  )  . getMapper (  \" join _ field \"  )  )     =  =     (  . getMapper ( indexService . mapperService (  )  )  )  )  )  ;", "mapper    =     . getMapper ( indexService . mapperService (  )  )  ;", "assertTrue ( mapper . hasParent (  \" other \"  )  )  ;", "assertFalse ( mapper . hasChild (  \" other \"  )  )  ;", "assertTrue ( mapper . hasChild (  \" child _ other 1  \"  )  )  ;", "assertFalse ( mapper . hasParent (  \" child _ other 1  \"  )  )  ;", "assertTrue ( mapper . hasChild (  \" child _ other 2  \"  )  )  ;", "assertFalse ( mapper . hasParent (  \" child _ other 2  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testUpdateRelations"], "fileName": "org.elasticsearch.join.mapper.ParentJoinFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "List < IndexRequestBuilder >    indexBuilders    =    new   ArrayList <  >  (  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  4  \"  ,     \"  1  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     0  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  5  \"  ,     \"  1  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     0  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  6  \"  ,     \"  1  \"  ,     \" c _ field 1  \"  ,     2  ,     \" c _ field 2  \"  ,     0  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  7  \"  ,     \"  1  \"  ,     \" c _ field 1  \"  ,     2  ,     \" c _ field 2  \"  ,     0  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  8  \"  ,     \"  1  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     1  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  9  \"  ,     \"  1  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     2  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  0  \"  ,     \"  2  \"  ,     \" c _ field 1  \"  ,     3  ,     \" c _ field 2  \"  ,     0  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  1  \"  ,     \"  2  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     1  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  2  \"  ,     \" p \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     1  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  3  \"  ,     \"  2  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     1  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  4  \"  ,     \"  2  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     1  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  5  \"  ,     \"  2  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     2  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  3  \"  ,    null ,     \" p _ field 1  \"  ,     \" p _ value 3  \"  ,     \" p _ field 2  \"  ,     5  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  6  \"  ,     \"  3  \"  ,     \" c _ field 1  \"  ,     4  ,     \" c _ field 2  \"  ,     0  ,     \" c _ field 3  \"  ,     0  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  7  \"  ,     \"  3  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     1  ,     \" c _ field 3  \"  ,     1  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  8  \"  ,     \"  3  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     2  ,     \" c _ field 3  \"  ,     2  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  9  \"  ,     \"  3  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     2  ,     \" c _ field 3  \"  ,     3  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  2  0  \"  ,     \"  3  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     2  ,     \" c _ field 3  \"  ,     4  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  2  1  \"  ,     \"  3  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     2  ,     \" c _ field 3  \"  ,     5  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c 1  \"  ,     \"  2  2  \"  ,     \"  3  \"  ,     \" c _ field 1  \"  ,     1  ,     \" c _ field 2  \"  ,     2  ,     \" c _ field 3  \"  ,     6  )  )  ;", "return   indexBuilders ;", "}", "METHOD_END"], "methodName": ["createDocBuilders"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "List < IndexRequestBuilder >    indexBuilders    =    new   ArrayList <  >  (  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  1  \"  ,    null ,     \" id \"  ,     1  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  0  \"  ,     \"  1  \"  ,     \" foo \"  ,     \" one \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  2  \"  ,    null ,     \" id \"  ,     2  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  1  \"  ,     \"  2  \"  ,     \" foo \"  ,     \" one \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  2  \"  ,     \"  2  \"  ,     \" foo \"  ,     \" one   two \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  3  \"  ,    null ,     \" id \"  ,     3  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  3  \"  ,     \"  3  \"  ,     \" foo \"  ,     \" one \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  4  \"  ,     \"  3  \"  ,     \" foo \"  ,     \" one   two \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  5  \"  ,     \"  3  \"  ,     \" foo \"  ,     \" one   two   three \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  4  \"  ,    null ,     \" id \"  ,     4  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  6  \"  ,     \"  4  \"  ,     \" foo \"  ,     \" one \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  7  \"  ,     \"  4  \"  ,     \" foo \"  ,     \" one   two \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  8  \"  ,     \"  4  \"  ,     \" foo \"  ,     \" one   two   three \"  )  )  ;", "indexBuilders . add ( createIndexRequest (  \" test \"  ,     \" c \"  ,     \"  1  9  \"  ,     \"  4  \"  ,     \" foo \"  ,     \" one   two   three   four \"  )  )  ;", "return   indexBuilders ;", "}", "METHOD_END"], "methodName": ["createMinMaxDocBuilders"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "HasChildQueryBuilder   hasChildQuery    =    JoinQueryBuilders . hasChildQuery (  \" child \"  ,    functionScoreQuery ( constantScoreQuery ( termQuery (  \" foo \"  ,     \" two \"  )  )  ,    new   FilterFunctionBuilder [  ]  {    new   FilterFunctionBuilder ( weightFactorFunction (  1  )  )  ,    new   FilterFunctionBuilder ( termQuery (  \" foo \"  ,     \" three \"  )  ,    weightFactorFunction (  1  )  )  ,    new   FilterFunctionBuilder ( termQuery (  \" foo \"  ,     \" four \"  )  ,    weightFactorFunction (  1  )  )     }  )  . boostMode ( CombineFunction . REPLACE )  . scoreMode ( FunctionScoreQuery . ScoreMode . SUM )  ,    scoreMode )  . minMaxChildren ( minChildren ,     ( maxChildren    !  =    null    ?    maxChildren    :    HasChildQueryBuilder . DEFAULT _ MAX _ CHILDREN )  )  ;", "return   client (  )  . prepareSearch (  \" test \"  )  . setQuery ( hasChildQuery )  . addSort (  \"  _ score \"  ,    DESC )  . addSort (  \" id \"  ,    ASC )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["minMaxQuery"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "if    ( randomBoolean (  )  )     {", "if    ( randomBoolean (  )  )     {", "return   constantScoreQuery ( JoinQueryBuilders . has ( type ,    termQuery ( field ,    value )  ,    None )  )  ;", "} else    {", "return   boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . has ( type ,    termQuery ( field ,    value )  ,    None )  )  ;", "}", "} else    {", "return   JoinQueryBuilders . has ( type ,    termQuery ( field ,    value )  ,    None )  ;", "}", "}", "METHOD_END"], "methodName": ["randomHasChild"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "if    ( randomBoolean (  )  )     {", "if    ( randomBoolean (  )  )     {", "return   constantScore ( JoinBuilders . hasParent ( type ,    term ( field ,    value )  ,    false )  )  ;", "} else    {", "return   bool (  )  . must ( matchAll (  )  )  . filter ( JoinBuilders . hasParent ( type ,    term ( field ,    value )  ,    false )  )  ;", "}", "} else    {", "return   JoinBuilders . hasParent ( type ,    term ( field ,    value )  ,    false )  ;", "}", "}", "METHOD_END"], "methodName": ["randomHasParent"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" foo \"  ,     \" test \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" foo \"  ,     \"  1  \"  ,    null ,     \" foo \"  ,     1  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" test \"  ,     \"  2  \"  ,     \"  1  \"  ,     \" foo \"  ,     1  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" test \"  ,    matchQuery (  \" foo \"  ,     1  )  ,    None )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["test2744"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" my - index \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "createIndexRequest (  \" my - index \"  ,     \" parent \"  ,     \"  1  \"  ,    null )  . get (  )  ;", "createIndexRequest (  \" my - index \"  ,     \" child \"  ,     \"  2  \"  ,     \"  1  \"  )  . get (  )  ;", "refresh (  )  ;", "assertAcked ( admin (  )  . indices (  )  . prepareAliases (  )  . addAlias (  \" my - index \"  ,     \" filter 1  \"  ,    JoinQueryBuilders . has (  \" child \"  ,    matchAllQuery (  )  ,    None )  )  )  ;", "assertAcked ( admin (  )  . indices (  )  . prepareAliases (  )  . addAlias (  \" my - index \"  ,     \" filter 2  \"  ,    JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    matchAllQuery (  )  ,    false )  )  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" filter 1  \"  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "response    =    client (  )  . prepareSearch (  \" filter 2  \"  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAliasesFilterWithHasChildQuery"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "List < IndexRequestBuilder >    builders    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     1  0  ;    i +  +  )     {", "builders . add ( createIndexRequest (  \" test \"  ,     \" parent \"  ,    Integer . toString ( i )  ,    null ,     \" p _ field \"  ,    i )  )  ;", "}", "indexRandom ( randomBoolean (  )  ,    builders )  ;", "builders . clear (  )  ;", "for    ( int   j    =     0  ;    j    <     2  ;    j +  +  )     {", "for    ( int   i    =     0  ;    i    <     1  0  ;    i +  +  )     {", "builders . add ( createIndexRequest (  \" test \"  ,     \" child \"  ,     (  ( j    +     \"  -  \"  )     +    i )  ,     \"  0  \"  ,     \" c _ field \"  ,    i )  )  ;", "}", "for    ( int   i    =     1  0  ;    i    <     2  0  ;    i +  +  )     {", "builders . add ( createIndexRequest (  \" test \"  ,     \" child \"  ,     (  ( j    +     \"  -  \"  )     +    i )  ,    Integer . toString ( i )  ,     \" c _ field \"  ,    i )  )  ;", "}", "if    ( randomBoolean (  )  )     {", "break ;", "}", "}", "indexRandom ( true ,    builders )  ;", "for    ( int   i    =     1  ;    i    <  =     1  0  ;    i +  +  )     {", "logger . info (  \" Round    {  }  \"  ,    i )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    matchAllQuery (  )  ,    Max )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    matchAllQuery (  )  ,    true )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "}", "}", "METHOD_END"], "methodName": ["testCachingBugWithFqueryFilter"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "String   parentId    =     \" p 1  \"  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,    parentId ,    null ,     \" p _ field \"  ,     \"  1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,    parentId ,     \" c _ field \"  ,     \"  1  \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   countResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \"  1  \"  )  ,    Max )  )  . get (  )  ;", "assertHitCount ( countResponse ,     1 L )  ;", "countResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \"  1  \"  )  ,    true )  )  . get (  )  ;", "assertHitCount ( countResponse ,     1 L )  ;", "countResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \"  1  \"  )  ,    None )  )  )  . get (  )  ;", "assertHitCount ( countResponse ,     1 L )  ;", "countResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setSize (  0  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \"  1  \"  )  ,    false )  )  )  . get (  )  ;", "assertHitCount ( countResponse ,     1 L )  ;", "}", "METHOD_END"], "methodName": ["testCountApiUsage"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" yellow \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 4  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" yellow \"  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 1  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getSourceAsString (  )  ,    containsString (  \"  \\  \" p _ value 1  \\  \"  \"  )  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  _ updated \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" yellow \"  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 1  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getSourceAsString (  )  ,    containsString (  \"  \\  \" p _ value 1  _ updated \\  \"  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDeletedParent"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" yellow \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 3  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 4  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setSearchType ( DFS _ QUERY _ THEN _ FETCH )  . setQuery ( boolQuery (  )  . mustNot ( JoinQueryBuilders . has (  \" child \"  ,    boolQuery (  )  . should ( queryStringQuery (  \" c _ field :  *  \"  )  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setSearchType ( DFS _ QUERY _ THEN _ FETCH )  . setQuery ( boolQuery (  )  . mustNot ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    boolQuery (  )  . should ( queryStringQuery (  \" p _ field :  *  \"  )  )  ,    false )  )  )  . execute (  )  . actionGet (  )  ;", "assertNoFailures ( searchResponse )  ;", "}", "METHOD_END"], "methodName": ["testDfsSearchType"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "String   parentId    =     \" p 1  \"  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,    parentId ,    null ,     \" p _ field \"  ,     \"  1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,    parentId ,     \" c _ field \"  ,     \"  1  \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setExplain ( true )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \"  1  \"  )  ,    Max )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getExplanation (  )  . getDescription (  )  ,    containsString (  \" join   value   p 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setExplain ( true )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \"  1  \"  )  ,    true )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getExplanation (  )  . getDescription (  )  ,    containsString (  \" join   value   p 1  \"  )  )  ;", "ExplainResponse   explainResponse    =    client (  )  . prepareExplain (  \" test \"  ,     \" doc \"  ,    parentId )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \"  1  \"  )  ,    Max )  )  . get (  )  ;", "assertThat ( explainResponse . isExists (  )  ,    equalTo ( true )  )  ;", "assertThat ( explainResponse . getExplanation (  )  . toString (  )  ,    containsString (  \" join   value   p 1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExplainUsage"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  1  \"  ,    null ,     \" p _ field \"  ,     1  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \"  2  \"  ,     \"  1  \"  ,     \" c _ field \"  ,     1  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  3  \"  )  . setSource (  \" p _ field \"  ,     1  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . has (  \" child \"  ,    matchAllQuery (  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    matchAllQuery (  )  ,    false )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "}", "METHOD_END"], "methodName": ["testHasChildAndHasParentFailWhenSomeSegmentsDontContainAnyParentOrChildDocs"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  1  \"  ,    null ,     \" p _ field \"  ,     1  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \"  2  \"  ,     \"  1  \"  ,     \" c _ field \"  ,     1  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  \" test \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  3  \"  )  . setSource (  \" p _ field \"  ,     2  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     1  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     1  )  ,    false )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testHasChildAndHasParentFilter_withFilter"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  1  \"  ,    null ,     \" p _ field \"  ,     1  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  \" test \"  )  . setForce ( true )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \"  2  \"  ,     \"  1  \"  ,     \" c _ field \"  ,     1  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . has (  \" child \"  ,    matchQuery (  \" c _ field \"  ,     1  )  ,    None )  )  )  . get (  )  ;", "assertSearchHit ( searchResponse ,     1  ,    hasId (  \"  1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    matchQuery (  \" p _ field \"  ,     1  )  ,    false )  )  )  . get (  )  ;", "assertSearchHit ( searchResponse ,     1  ,    hasId (  \"  2  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( boolQuery (  )  . must ( JoinQueryBuilders . has (  \" child \"  ,    matchQuery (  \" c _ field \"  ,     1  )  ,    None )  )  )  )  . get (  )  ;", "assertSearchHit ( searchResponse ,     1  ,    hasId (  \"  1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( boolQuery (  )  . must ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    matchQuery (  \" p _ field \"  ,     1  )  ,    false )  )  )  )  . get (  )  ;", "assertSearchHit ( searchResponse ,     1  ,    hasId (  \"  2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testHasChildAndHasParentWrappedInAQueryFilter"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \"  1  \"  ,    null ,     \" p _ field \"  ,     1  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \"  2  \"  ,     \"  1  \"  ,     \" c _ field \"  ,     \" foo   bar \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    matchQuery (  \" c _ field \"  ,     \" foo \"  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  . setHighlightBuilder ( new   HighlightBuilder (  )  . field ( new   Field (  \" c _ field \"  )  . highlightQuery ( QueryBuilders . matchQuery (  \" c _ field \"  ,     \" bar \"  )  )  )  )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "SearchHit [  ]    searchHits    =    searchResponse . getHits (  )  . getHits (  )  [  0  ]  . getInnerHits (  )  . get (  \" child \"  )  . getHits (  )  ;", "assertThat ( searchHits . length ,    equalTo (  1  )  )  ;", "assertThat ( searchHits [  0  ]  . getHighlightFields (  )  . get (  \" c _ field \"  )  . getFragments (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( searchHits [  0  ]  . getHighlightFields (  )  . get (  \" c _ field \"  )  . getFragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" foo    < em > bar <  / em >  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testHasChildInnerHitsHighlighting"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 3  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 3  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 4  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 4  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 5  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 5  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 6  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 6  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 7  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 7  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 8  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 8  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 9  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 9  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  0  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  0  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  \" test \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  \" test \"  )  . get (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" blue \"  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  \" test \"  )  . get (  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" blue \"  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "}", "METHOD_END"], "methodName": ["testHasChildNotBeingCached"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" grandissue \"  )  . addMapping (  \" doc \"  ,    jsonBuilder (  )  . startObject (  )  . startObject (  \" doc \"  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" grandparent \"  ,     \" parent \"  )  . field (  \" parent \"  ,    new   String [  ]  {     \" child _ type _ one \"  ,     \" child _ type _ two \"     }  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  )  ;", "createIndexRequest (  \" grandissue \"  ,     \" grandparent \"  ,     \"  1  \"  ,    null ,     \" name \"  ,     \" Grandpa \"  )  . get (  )  ;", "createIndexRequest (  \" grandissue \"  ,     \" parent \"  ,     \"  2  \"  ,     \"  1  \"  ,     \" name \"  ,     \" Dana \"  )  . get (  )  ;", "createIndexRequest (  \" grandissue \"  ,     \" child _ type _ one \"  ,     \"  3  \"  ,     \"  2  \"  ,     \" name \"  ,     \" William \"  )  . setRouting (  \"  1  \"  )  . get (  )  ;", "createIndexRequest (  \" grandissue \"  ,     \" child _ type _ two \"  ,     \"  4  \"  ,     \"  2  \"  ,     \" name \"  ,     \" Kate \"  )  . setRouting (  \"  1  \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" grandissue \"  )  . setQuery ( boolQuery (  )  . must ( JoinQueryBuilders . has (  \" parent \"  ,    boolQuery (  )  . must ( JoinQueryBuilders . has (  \" child _ type _ one \"  ,    boolQuery (  )  . must ( queryStringQuery (  \" name : William *  \"  )  )  ,    None )  )  ,    None )  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1 L )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" grandissue \"  )  . setQuery ( boolQuery (  )  . must ( JoinQueryBuilders . has (  \" parent \"  ,    boolQuery (  )  . must ( JoinQueryBuilders . has (  \" child _ type _ two \"  ,    boolQuery (  )  . must ( queryStringQuery (  \" name : William *  \"  )  )  ,    None )  )  ,    None )  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     0 L )  ;", "}", "METHOD_END"], "methodName": ["testHasChildQueryOnlyReturnsSingleChildType"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" x \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" x \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 4  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" x \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 5  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" x \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    matchAllQuery (  )  ,    Total )  )  . setMinScore (  3  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 2  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "}", "METHOD_END"], "methodName": ["testHasChildQueryWithMinimumScore"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  ,     \" objects \"  ,     \" nested \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,    jsonBuilder (  )  . startObject (  )  . field (  \" p _ field \"  ,     \"  1  \"  )  . startArray (  \" objects \"  )  . startObject (  )  . field (  \" i _ field \"  ,     \"  1  \"  )  . endObject (  )  . startObject (  )  . field (  \" i _ field \"  ,     \"  2  \"  )  . endObject (  )  . startObject (  )  . field (  \" i _ field \"  ,     \"  3  \"  )  . endObject (  )  . startObject (  )  . field (  \" i _ field \"  ,     \"  4  \"  )  . endObject (  )  . startObject (  )  . field (  \" i _ field \"  ,     \"  5  \"  )  . endObject (  )  . startObject (  )  . field (  \" i _ field \"  ,     \"  6  \"  )  . endObject (  )  . endArray (  )  . endObject (  )  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,    jsonBuilder (  )  . startObject (  )  . field (  \" p _ field \"  ,     \"  2  \"  )  . startArray (  \" objects \"  )  . startObject (  )  . field (  \" i _ field \"  ,     \"  1  \"  )  . endObject (  )  . startObject (  )  . field (  \" i _ field \"  ,     \"  2  \"  )  . endObject (  )  . endArray (  )  . endObject (  )  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "refresh (  )  ;", "ScoreMode   scoreMode    =    randomFrom ( ScoreMode . values (  )  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" blue \"  )  ,    scoreMode )  )  . filter ( boolQuery (  )  . mustNot ( termQuery (  \" p _ field \"  ,     \"  3  \"  )  )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" red \"  )  ,    scoreMode )  )  . filter ( boolQuery (  )  . mustNot ( termQuery (  \" p _ field \"  ,     \"  3  \"  )  )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "}", "METHOD_END"], "methodName": ["testHasChildQueryWithNestedInnerObjects"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "Map < String ,    Set < String >  >    parentToChildren    =    new   HashMap <  >  (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 0  \"  ,    null ,     \" p _ field \"  ,     \" p 0  \"  )  . get (  )  ;", "parentToChildren . put (  \" p 0  \"  ,    new   HashSet <  >  (  )  )  ;", "String   previousParentId    =    null ;", "int   numChildDocs    =     3  2  ;", "int   numChildDocsPerParent    =     0  ;", "List < IndexRequestBuilder >    builders    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     1  ;    i    <  =    numChildDocs ;    i +  +  )     {", "if    (  ( previousParentId    =  =    null )     |  |     (  ( i    %    numChildDocsPerParent )     =  =     0  )  )     {", "previousParentId    =     \" p \"     +    i ;", "builders . add ( createIndexRequest (  \" test \"  ,     \" parent \"  ,    previousParentId ,    null ,     \" p _ field \"  ,    previousParentId )  )  ;", "numChildDocsPerParent +  +  ;", "}", "String   childId    =     \" c \"     +    i ;", "builders . add ( createIndexRequest (  \" test \"  ,     \" child \"  ,    childId ,    previousParentId ,     \" c _ field \"  ,    childId )  )  ;", "if    (  !  ( parentToChildren . containsKey ( previousParentId )  )  )     {", "parentToChildren . put ( previousParentId ,    new   HashSet <  >  (  )  )  ;", "}", "assertThat ( parentToChildren . get ( previousParentId )  . add ( childId )  ,    is ( true )  )  ;", "}", "indexRandom ( true ,    builders . toArray ( new   IndexRequestBuilder [ builders . size (  )  ]  )  )  ;", "assertThat ( parentToChildren . isEmpty (  )  ,    equalTo ( false )  )  ;", "for    ( Map . Entry < String ,    Set < String >  >    parentToChildrenEntry    :    parentToChildren . entrySet (  )  )     {", "SearchResponse   Response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,    parentToChildrenEntry . getKey (  )  )  ,    false )  )  )  . setSize ( numChildDocsPerParent )  . get (  )  ;", "assertNoFailures ( Response )  ;", "Set < String >    childIds    =    parentToChildrenEntry . getValue (  )  ;", "assertThat ( Response . getHits (  )  . getTotalHits (  )  ,    equalTo (  (  ( long )     ( childIds . size (  )  )  )  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( Response . getHits (  )  . getTotalHits (  )  )  ;    i +  +  )     {", "assertThat ( childIds . remove ( Response . getHits (  )  . getAt ( i )  . getId (  )  )  ,    is ( true )  )  ;", "assertThat ( Response . getHits (  )  . getAt ( i )  . getScore (  )  ,    is (  1  .  0 F )  )  ;", "}", "assertThat ( childIds . size (  )  ,    is (  0  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testHasParentFilter"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent - type \"  ,     \" child - type \"  )  )  )  ;", "createIndexRequest (  \" test \"  ,     \" child - type \"  ,     \" child - id \"  ,     \" parent - id \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent - type \"  ,     \" parent - id \"  ,    null )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child - type \"  ,    new   IdsQueryBuilder (  )  . addIds (  \" child - id \"  )  ,    None )  )  . get (  )  ;", "assertSearchHits ( searchResponse ,     \" parent - id \"  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent - type \"  ,    new   IdsQueryBuilder (  )  . addIds (  \" parent - id \"  )  ,    false )  )  . get (  )  ;", "assertSearchHits ( searchResponse ,     \" child - id \"  )  ;", "}", "METHOD_END"], "methodName": ["testHasParentInnerQueryType"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    jsonBuilder (  )  . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent - type \"  ,     \" child - type \"  )  . endObject (  )  . endObject (  )  . startObject (  \" searchText \"  )  . field (  \" type \"  ,     \" text \"  )  . field (  \" term _ vector \"  ,     \" with _ positions _ offsets \"  )  . field (  \" index _ options \"  ,     \" offsets \"  )  . endObject (  )  . endObject (  )  . endObject (  )  )  )  ;", "createIndexRequest (  \" test \"  ,     \" parent - type \"  ,     \" parent - id \"  ,    null ,     \" searchText \"  ,     \" quick   brown   fox \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child - type \"  ,     \" child - id \"  ,     \" parent - id \"  ,     \" searchText \"  ,     \" quick   brown   fox \"  )  . get (  )  ;", "refresh (  )  ;", "String [  ]    highlightTypes    =    new   String [  ]  {     \" plain \"  ,     \" fvh \"  ,     \" unified \"     }  ;", "for    ( String   highlightType    :    highlightTypes )     {", "logger . info (  \" Testing   with   highlight   type    [  {  }  ]  \"  ,    highlightType )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( new   BoolQueryBuilder (  )  . must ( new   MatchQueryBuilder (  \" searchText \"  ,     \" fox \"  )  )  . must ( new   HasBuilder (  \" child - type \"  ,    new   MatchAllQueryBuilder (  )  ,    ScoreMode . None )  )  )  . highlighter ( new   HighlightBuilder (  )  . field ( new   HighlightBuilder . Field (  \" searchText \"  )  . highlighterType ( highlightType )  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" parent - id \"  )  )  ;", "HighlightField   highlightField    =    searchResponse . getHits (  )  . getAt (  0  )  . getHighlightFields (  )  . get (  \" searchText \"  )  ;", "assertThat ( highlightField . getFragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" quick   brown    < em > fox <  / em >  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( new   BoolQueryBuilder (  )  . must ( new   MatchQueryBuilder (  \" searchText \"  ,     \" fox \"  )  )  . must ( new   HasParentQueryBuilder (  \" parent - type \"  ,    new   MatchAllQueryBuilder (  )  ,    false )  )  )  . highlighter ( new   HighlightBuilder (  )  . field ( new   HighlightBuilder . Field (  \" searchText \"  )  . highlighterType ( highlightType )  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" child - id \"  )  )  ;", "highlightField    =    searchResponse . getHits (  )  . getAt (  0  )  . getHighlightFields (  )  . get (  \" searchText \"  )  ;", "assertThat ( highlightField . getFragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" quick   brown    < em > fox <  / em >  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testHighlightersIgnoreParentChild"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "indexRandom ( true ,    createMinMaxDocBuilders (  )  . toArray ( new   IndexRequestBuilder [  0  ]  )  )  ;", "Response   response ;", "response    =    minMaxQuery ( None ,     0  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( None ,     1  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( None ,     2  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( None ,     3  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( None ,     4  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  0 L )  )  ;", "response    =    minMaxQuery ( None ,     0  ,     4  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( None ,     0  ,     3  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( None ,     0  ,     2  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( None ,     2  ,     2  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    minMaxQuery ( ScoreMode . None ,     3  ,     2  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ has _ child ]     ' max _ children '    is   less   than    ' min _ children '  \"  )  )  ;", "response    =    minMaxQuery ( Total ,     0  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  6  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Total ,     1  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  6  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Total ,     2  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  6  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "response    =    minMaxQuery ( Total ,     3  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  6  .  0 F )  )  ;", "response    =    minMaxQuery ( Total ,     4  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  0 L )  )  ;", "response    =    minMaxQuery ( Total ,     0  ,     4  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  6  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Total ,     0  ,     3  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  6  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Total ,     0  ,     2  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Total ,     2  ,     2  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    minMaxQuery ( ScoreMode . Total ,     3  ,     2  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ has _ child ]     ' max _ children '    is   less   than    ' min _ children '  \"  )  )  ;", "response    =    minMaxQuery ( Max ,     0  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Max ,     1  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Max ,     2  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "response    =    minMaxQuery ( Max ,     3  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "response    =    minMaxQuery ( Max ,     4  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  0 L )  )  ;", "response    =    minMaxQuery ( Max ,     0  ,     4  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Max ,     0  ,     3  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Max ,     0  ,     2  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Max ,     2  ,     2  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    minMaxQuery ( ScoreMode . Max ,     3  ,     2  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ has _ child ]     ' max _ children '    is   less   than    ' min _ children '  \"  )  )  ;", "response    =    minMaxQuery ( Avg ,     0  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  5 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Avg ,     1  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  5 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Avg ,     2  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  5 F )  )  ;", "response    =    minMaxQuery ( Avg ,     3  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "response    =    minMaxQuery ( Avg ,     4  ,    null )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  0 L )  )  ;", "response    =    minMaxQuery ( Avg ,     0  ,     4  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  5 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Avg ,     0  ,     3  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  5 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Avg ,     0  ,     2  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  5 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  1  .  0 F )  )  ;", "response    =    minMaxQuery ( Avg ,     2  ,     2  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  1  .  5 F )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    minMaxQuery ( ScoreMode . Avg ,     3  ,     2  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ has _ child ]     ' max _ children '    is   less   than    ' min _ children '  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMinMaxChildren"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  ,     \" child \"  ,     \" grandchild \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" c _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" grandchild \"  ,     \" gc 1  \"  ,     \" c 1  \"  ,     \" gc _ field \"  ,     \" gc _ value 1  \"  )  . setRouting (  \" p 1  \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . has (  \" child \"  ,    boolQuery (  )  . must ( termQuery (  \" c _ field \"  ,     \" c _ value 1  \"  )  )  . filter ( JoinQueryBuilders . has (  \" grandchild \"  ,    termQuery (  \" gc _ field \"  ,     \" gc _ value 1  \"  )  ,    None )  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \" p _ value 1  \"  )  ,    false )  )  )  . execute (  )  . actionGet (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" c 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . hasParentQuery (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" c _ value 1  \"  )  ,    false )  )  )  . execute (  )  . actionGet (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" gc 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \" p _ value 1  \"  )  ,    false )  )  . execute (  )  . actionGet (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" c 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" c _ value 1  \"  )  ,    false )  )  . execute (  )  . actionGet (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" gc 1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiLevelChild"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "String   parentId    =     \" p 1  \"  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,    parentId ,    null ,     \" p _ field \"  ,     \"  1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,    parentId ,     \" c _ field \"  ,     \"  1  \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \"  1  \"  )  ,    Max )  . queryName (  \" test \"  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getMatchedQueries (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getMatchedQueries (  )  [  0  ]  ,    equalTo (  \" test \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \"  1  \"  )  ,    true )  . queryName (  \" test \"  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getMatchedQueries (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getMatchedQueries (  )  [  0  ]  ,    equalTo (  \" test \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \"  1  \"  )  ,    None )  . queryName (  \" test \"  )  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getMatchedQueries (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getMatchedQueries (  )  [  0  ]  ,    equalTo (  \" test \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \"  1  \"  )  ,    false )  . queryName (  \" test \"  )  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getMatchedQueries (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getMatchedQueries (  )  [  0  ]  ,    equalTo (  \" test \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNamedFilters"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . setSettings ( Settings . builder (  )  . put (  \" index . refresh _ interval \"  ,     (  -  1  )  )  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareForceMerge (  \" test \"  )  . setMaxNumSegments (  1  )  . setFlush ( true )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 3  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 3  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 4  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 4  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 4  \"  ,     \" p 3  \"  ,     \" c _ field \"  ,     \" green \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 5  \"  ,     \" p 3  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 6  \"  ,     \" p 4  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  \" test \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  \" test \"  )  . get (  )  ;", "for    ( int   i    =     0  ;    i    <     2  ;    i +  +  )     {", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( boolQuery (  )  . must ( JoinQueryBuilders . has (  \" child \"  ,    matchQuery (  \" c _ field \"  ,     \" red \"  )  ,    None )  )  . must ( matchAllQuery (  )  )  )  )  . get (  )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "}", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  \" test \"  )  . get (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  )  . setQuery ( boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( boolQuery (  )  . must ( JoinQueryBuilders . has (  \" child \"  ,    matchQuery (  \" c _ field \"  ,     \" red \"  )  ,    None )  )  . must ( matchAllQuery (  )  )  )  )  . get (  )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "}", "METHOD_END"], "methodName": ["testParentChildCaching"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    matchQuery (  \" text \"  ,     \" value \"  )  ,    None )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  0 L )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" text \"  ,     \" value \"  )  . endObject (  )  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    matchQuery (  \" text \"  ,     \" value \"  )  ,    None )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  0 L )  )  ;", "response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    matchQuery (  \" text \"  ,     \" value \"  )  ,    Max )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  0 L )  )  ;", "response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    matchQuery (  \" text \"  ,     \" value \"  )  ,    false )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  0 L )  )  ;", "response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    matchQuery (  \" text \"  ,     \" value \"  )  ,    true )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  0 L )  )  ;", "}", "METHOD_END"], "methodName": ["testParentChildQueriesCanHandleNoRelevantTypesInIndex"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . setSettings ( Settings . builder (  )  . put ( indexSettings (  )  )  . put (  \" index . refresh _ interval \"  ,     (  -  1  )  )  )  )  ;", "ensureGreen (  )  ;", "String   parentId    =     \" p 1  \"  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,    parentId )  . setSource (  \" p _ field \"  ,     \"  1  \"  )  . get (  )  ;", "refresh (  )  ;", "try    {", "client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \"  1  \"  )  ,    None )  )  . get (  )  ;", "fail (  )  ;", "}    catch    ( SearchPhaseExecutionException   e )     {", "assertThat ( e . status (  )  ,    equalTo ( BAD _ REQUEST )  )  ;", "}", "try    {", "client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \"  1  \"  )  ,    Max )  )  . get (  )  ;", "fail (  )  ;", "}    catch    ( SearchPhaseExecutionException   e )     {", "assertThat ( e . status (  )  ,    equalTo ( BAD _ REQUEST )  )  ;", "}", "try    {", "client (  )  . prepareSearch (  \" test \"  )  . setPostFilter ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \"  1  \"  )  ,    None )  )  . get (  )  ;", "fail (  )  ;", "}    catch    ( SearchPhaseExecutionException   e )     {", "assertThat ( e . status (  )  ,    equalTo ( BAD _ REQUEST )  )  ;", "}", "try    {", "client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \"  1  \"  )  ,    true )  )  . get (  )  ;", "fail (  )  ;", "}    catch    ( SearchPhaseExecutionException   e )     {", "assertThat ( e . status (  )  ,    equalTo ( BAD _ REQUEST )  )  ;", "}", "try    {", "client (  )  . prepareSearch (  \" test \"  )  . setPostFilter ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \"  1  \"  )  ,    false )  )  . get (  )  ;", "fail (  )  ;", "}    catch    ( SearchPhaseExecutionException   e )     {", "assertThat ( e . status (  )  ,    equalTo ( BAD _ REQUEST )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testParentChildQueriesNoParentType"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "for    ( int   i    =     0  ;    i    <     1  0  ;    i +  +  )     {", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     (  \" p \"     +    i )  ,    null )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     (  \" c \"     +    i )  ,     (  \" p \"     +    i )  )  . get (  )  ;", "}", "refresh (  )  ;", "QueryBuilder [  ]    queries    =    new   QueryBuilder [  ]  {    JoinQueryBuilders . has (  \" child \"  ,    matchAllQuery (  )  ,    None )  ,    boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . has (  \" child \"  ,    matchAllQuery (  )  ,    None )  )  ,    JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    matchAllQuery (  )  ,    false )  ,    boolQuery (  )  . must ( matchAllQuery (  )  )  . filter ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    matchAllQuery (  )  ,    false )  )     }  ;", "for    ( QueryBuilder   query    :    queries )     {", "SearchResponse   scrollResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setScroll ( TimeValue . timeValueSeconds (  3  0  )  )  . setSize (  1  )  . addStoredField (  \"  _ id \"  )  . setQuery ( query )  . execute (  )  . actionGet (  )  ;", "assertNoFailures ( scrollResponse )  ;", "assertThat ( scrollResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1  0 L )  )  ;", "int   scannedDocs    =     0  ;", "do    {", "assertThat ( scrollResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1  0 L )  )  ;", "scannedDocs    +  =    scrollResponse . getHits (  )  . getHits (  )  . length ;", "scrollResponse    =    client (  )  . prepareSearchScroll ( scrollResponse . getScrollId (  )  )  . setScroll ( TimeValue . timeValueSeconds (  3  0  )  )  . get (  )  ;", "}    while    (  ( scrollResponse . getHits (  )  . getHits (  )  . length )     >     0     )  ;", "clearScroll ( scrollResponse . getScrollId (  )  )  ;", "assertThat ( scannedDocs ,    equalTo (  1  0  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testParentChildQueriesViaScrollApi"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . setSettings ( Settings . builder (  )  . put (  \" index . refresh _ interval \"  ,     (  -  1  )  )  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "Response   response    =    client (  )  . prepare (  \" test \"  )  . setQuery ( boolQuery (  )  . filter ( termQuery (  \" join _ field # parent \"  ,     \" p 1  \"  )  )  . filter ( termQuery (  \" join _ field \"  ,     \" child \"  )  )  )  . get (  )  ;", "assertHitCount ( response ,     0 L )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  )  . get (  )  ;", "refresh (  )  ;", "response    =    client (  )  . prepare (  \" test \"  )  . setQuery ( boolQuery (  )  . filter ( termQuery (  \" join _ field # parent \"  ,     \" p 1  \"  )  )  . filter ( termQuery (  \" join _ field \"  ,     \" child \"  )  )  )  . get (  )  ;", "assertHitCount ( response ,     1 L )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 2  \"  )  . get (  )  ;", "refresh (  )  ;", "response    =    client (  )  . prepare (  \" test \"  )  . setQuery ( boolQuery (  )  . should ( boolQuery (  )  . filter ( termQuery (  \" join _ field # parent \"  ,     \" p 1  \"  )  )  . filter ( termQuery (  \" join _ field \"  ,     \" child \"  )  )  )  . should ( boolQuery (  )  . filter ( termQuery (  \" join _ field # parent \"  ,     \" p 2  \"  )  )  . filter ( termQuery (  \" join _ field \"  ,     \" child \"  )  )  )  )  . get (  )  ;", "assertHitCount ( response ,     2 L )  ;", "}", "METHOD_END"], "methodName": ["testParentFieldQuery"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . setSettings ( Settings . builder (  )  . put ( indexSettings (  )  )  . put (  \" index . refresh _ interval \"  ,     (  -  1  )  )  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  )  . get (  )  ;", "refresh (  )  ;", "Response   response    =    client (  )  . prepare (  \" test \"  )  . setQuery ( JoinQueryBuilders . parentId (  \" child \"  ,     \" p 1  \"  )  )  . get (  )  ;", "assertHitCount ( response ,     1 L )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 2  \"  )  . get (  )  ;", "refresh (  )  ;", "response    =    client (  )  . prepare (  \" test \"  )  . setQuery ( boolQuery (  )  . should ( JoinQueryBuilders . parentId (  \" child \"  ,     \" p 1  \"  )  )  . should ( JoinQueryBuilders . parentId (  \" child \"  ,     \" p 2  \"  )  )  )  . get (  )  ;", "assertHitCount ( response ,     2 L )  ;", "}", "METHOD_END"], "methodName": ["testParentIdQuery"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" yellow \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" x \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 4  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" x \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" yellow \"  )  ,    Total )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 1  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getSourceAsString (  )  ,    containsString (  \"  \\  \" p _ value 1  \\  \"  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchQuery (  \" c _ field \"  ,     \" x \"  )  )  . must ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \" p _ value 2  \"  )  ,    true )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" c 3  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \" c 4  \"  )  )  ;", "for    ( int   i    =     0  ;    i    <     1  0  ;    i +  +  )     {", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     (  \" d \"     +    i )  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" x \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  \" test \"  )  . get (  )  ;", "}", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" yellow \"  )  ,    Total )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 1  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getSourceAsString (  )  ,    containsString (  \"  \\  \" p _ value 1  \\  \"  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchQuery (  \" c _ field \"  ,     \" x \"  )  )  . must ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    termQuery (  \" p _ field \"  ,     \" p _ value 2  \"  )  ,    true )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    Matchers . anyOf ( equalTo (  \" c 3  \"  )  ,    equalTo (  \" c 4  \"  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getId (  )  ,    Matchers . anyOf ( equalTo (  \" c 3  \"  )  ,    equalTo (  \" c 4  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testReIndexingParentAndChildDocuments"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  ,     \" c _ field \"  ,     \" keyword \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" yellow \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 4  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    boolQuery (  )  . should ( termQuery (  \" c _ field \"  ,     \" red \"  )  )  . should ( termQuery (  \" c _ field \"  ,     \" yellow \"  )  )  ,    None )  )  . addAggregation ( AggregationBuilders . global (  \" global \"  )  . subAggregation ( AggregationBuilders . filter (  \" filter \"  ,    boolQuery (  )  . should ( termQuery (  \" c _ field \"  ,     \" red \"  )  )  . should ( termQuery (  \" c _ field \"  ,     \" yellow \"  )  )  )  . subAggregation ( AggregationBuilders . terms (  \" facet 1  \"  )  . field (  \" c _ field \"  )  )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    anyOf ( equalTo (  \" p 2  \"  )  ,    equalTo (  \" p 1  \"  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getId (  )  ,    anyOf ( equalTo (  \" p 2  \"  )  ,    equalTo (  \" p 1  \"  )  )  )  ;", "Global   global    =    searchResponse . getAggregations (  )  . get (  \" global \"  )  ;", "Filter   filter    =    global . getAggregations (  )  . get (  \" filter \"  )  ;", "Terms   termsFacet    =    filter . getAggregations (  )  . get (  \" facet 1  \"  )  ;", "assertThat ( termsFacet . getBuckets (  )  . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( termsFacet . getBuckets (  )  . get (  0  )  . getKeyAsString (  )  ,    equalTo (  \" red \"  )  )  ;", "assertThat ( termsFacet . getBuckets (  )  . get (  0  )  . getDocCount (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( termsFacet . getBuckets (  )  . get (  1  )  . getKeyAsString (  )  ,    equalTo (  \" yellow \"  )  )  ;", "assertThat ( termsFacet . getBuckets (  )  . get (  1  )  . getDocCount (  )  ,    equalTo (  1 L )  )  ;", "}", "METHOD_END"], "methodName": ["testScopedFacet"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    jsonBuilder (  )  . startObject (  )  . startObject (  \" doc \"  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,    new   String [  ]  {     \" child \"  ,     \" child 1  \"     }  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  )  ;", "ensureGreen (  )  ;", "indexRandom ( true ,    createDocBuilders (  )  . toArray ( new   IndexRequestBuilder [  0  ]  )  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    QueryBuilders . functionScoreQuery ( matchQuery (  \" c _ field 2  \"  ,     0  )  ,    fieldValueFactorFunction (  \" c _ field 1  \"  )  )  . boostMode ( REPLACE )  ,    Total )  )  . get (  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  6  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  4  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    QueryBuilders . functionScoreQuery ( matchQuery (  \" c _ field 2  \"  ,     0  )  ,    fieldValueFactorFunction (  \" c _ field 1  \"  )  )  . boostMode ( REPLACE )  ,    Max )  )  . get (  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  4  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  2  .  0 F )  )  ;", "response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    QueryBuilders . functionScoreQuery ( matchQuery (  \" c _ field 2  \"  ,     0  )  ,    fieldValueFactorFunction (  \" c _ field 1  \"  )  )  . boostMode ( REPLACE )  ,    Avg )  )  . get (  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  4  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  3  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  1  .  5 F )  )  ;", "response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    QueryBuilders . functionScoreQuery ( matchQuery (  \" p _ field 1  \"  ,     \" p _ value 3  \"  )  ,    fieldValueFactorFunction (  \" p _ field 2  \"  )  )  . boostMode ( REPLACE )  ,    true )  )  . addSort ( SortBuilders . fieldSort (  \" c _ field 3  \"  )  )  . addSort ( SortBuilders . scoreSort (  )  )  . get (  )  ;", "assertThat ( response . getHits (  )  . getTotalHits (  )  ,    equalTo (  7 L )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \"  1  6  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  0  ]  . getScore (  )  ,    equalTo (  5  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \"  1  7  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  1  ]  . getScore (  )  ,    equalTo (  5  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \"  1  8  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  2  ]  . getScore (  )  ,    equalTo (  5  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  3  ]  . getId (  )  ,    equalTo (  \"  1  9  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  3  ]  . getScore (  )  ,    equalTo (  5  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  4  ]  . getId (  )  ,    equalTo (  \"  2  0  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  4  ]  . getScore (  )  ,    equalTo (  5  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  5  ]  . getId (  )  ,    equalTo (  \"  2  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  5  ]  . getScore (  )  ,    equalTo (  5  .  0 F )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  6  ]  . getId (  )  ,    equalTo (  \"  2  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getHits (  )  [  6  ]  . getScore (  )  ,    equalTo (  5  .  0 F )  )  ;", "}", "METHOD_END"], "methodName": ["testScoreForParentChildQueriesWithFunctionScore"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" yellow \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 4  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "refresh (  )  ;", "Response   searchResponse ;", "searchResponse    =    client (  )  . prepare (  \" test \"  )  . setQuery ( idsQuery (  \" doc \"  )  . addIds (  \" c 1  \"  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" c 1  \"  )  )  ;", "assertThat ( extractValue (  \" join _ field . name \"  ,    searchResponse . getHits (  )  . getAt (  0  )  . getSourceAsMap (  )  )  ,    equalTo (  \" child \"  )  )  ;", "assertThat ( extractValue (  \" join _ field . parent \"  ,    searchResponse . getHits (  )  . getAt (  0  )  . getSourceAsMap (  )  )  ,    equalTo (  \" p 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepare (  \" test \"  )  . setQuery ( boolQuery (  )  . filter ( termQuery (  \" join _ field # parent \"  ,     \" p 1  \"  )  )  . filter ( termQuery (  \" join _ field \"  ,     \" child \"  )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    anyOf ( equalTo (  \" c 1  \"  )  ,    equalTo (  \" c 2  \"  )  )  )  ;", "assertThat ( extractValue (  \" join _ field . name \"  ,    searchResponse . getHits (  )  . getAt (  0  )  . getSourceAsMap (  )  )  ,    equalTo (  \" child \"  )  )  ;", "assertThat ( extractValue (  \" join _ field . parent \"  ,    searchResponse . getHits (  )  . getAt (  0  )  . getSourceAsMap (  )  )  ,    equalTo (  \" p 1  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getId (  )  ,    anyOf ( equalTo (  \" c 1  \"  )  ,    equalTo (  \" c 2  \"  )  )  )  ;", "assertThat ( extractValue (  \" join _ field . name \"  ,    searchResponse . getHits (  )  . getAt (  1  )  . getSourceAsMap (  )  )  ,    equalTo (  \" child \"  )  )  ;", "assertThat ( extractValue (  \" join _ field . parent \"  ,    searchResponse . getHits (  )  . getAt (  1  )  . getSourceAsMap (  )  )  ,    equalTo (  \" p 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepare (  \" test \"  )  . setQuery ( randomHasChild (  \" child \"  ,     \" c _ field \"  ,     \" yellow \"  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     1 L )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepare (  \" test \"  )  . setQuery ( randomHasChild (  \" child \"  ,     \" c _ field \"  ,     \" blue \"  )  )  . execute (  )  . actionGet (  )  ;", "assertHitCount ( searchResponse ,     1 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 2  \"  )  )  ;", "searchResponse    =    client (  )  . prepare (  \" test \"  )  . setQuery ( randomHasChild (  \" child \"  ,     \" c _ field \"  ,     \" red \"  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     2 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    anyOf ( equalTo (  \" p 2  \"  )  ,    equalTo (  \" p 1  \"  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getId (  )  ,    anyOf ( equalTo (  \" p 2  \"  )  ,    equalTo (  \" p 1  \"  )  )  )  ;", "searchResponse    =    client (  )  . prepare (  \" test \"  )  . setQuery ( randomHasParent (  \" parent \"  ,     \" p _ field \"  ,     \" p _ value 2  \"  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertHitCount ( searchResponse ,     2 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" c 3  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \" c 4  \"  )  )  ;", "searchResponse    =    client (  )  . prepare (  \" test \"  )  . setQuery ( randomHasParent (  \" parent \"  ,     \" p _ field \"  ,     \" p _ value 1  \"  )  )  . get (  )  ;", "assertHitCount ( searchResponse ,     2 L )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" c 1  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \" c 2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimpleChildQuery"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "ensureGreen (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 1  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 1  \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 2  \"  ,     \" p 1  \"  ,     \" c _ field \"  ,     \" yellow \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,     \" p 2  \"  ,    null ,     \" p _ field \"  ,     \" p _ value 2  \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 3  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" blue \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,     \" c 4  \"  ,     \" p 2  \"  ,     \" c _ field \"  ,     \" red \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareFlush (  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" yellow \"  )  ,    None )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" blue \"  )  ,    None )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 2  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" red \"  )  ,    None )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    anyOf ( equalTo (  \" p 2  \"  )  ,    equalTo (  \" p 1  \"  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getId (  )  ,    anyOf ( equalTo (  \" p 2  \"  )  ,    equalTo (  \" p 1  \"  )  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" yellow \"  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 1  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" blue \"  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" p 2  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( constantScoreQuery ( JoinQueryBuilders . has (  \" child \"  ,    termQuery (  \" c _ field \"  ,     \" red \"  )  ,    None )  )  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getId (  )  ,    anyOf ( equalTo (  \" p 2  \"  )  ,    equalTo (  \" p 1  \"  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getId (  )  ,    anyOf ( equalTo (  \" p 2  \"  )  ,    equalTo (  \" p 1  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimpleChildQueryWithFlush"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  ,     \" c _ field \"  ,     \" keyword \"  ,     \" p _ field \"  ,     \" keyword \"  )  )  )  ;", "ensureGreen (  )  ;", "int   childId    =     0  ;", "for    ( int   i    =     0  ;    i    <     1  0  ;    i +  +  )     {", "String   parentId    =    String . format ( Locale . ROOT ,     \" p %  0  3 d \"  ,    i )  ;", "createIndexRequest (  \" test \"  ,     \" parent \"  ,    parentId ,    null ,     \" p _ field \"  ,    parentId )  . get (  )  ;", "int   j    =    childId ;", "for    (  ;    j    <     ( childId    +     5  0  )  ;    j +  +  )     {", "String   childUid    =    String . format ( Locale . ROOT ,     \" c %  0  3 d \"  ,    j )  ;", "createIndexRequest (  \" test \"  ,     \" child \"  ,    childUid ,    parentId ,     \" c _ field \"  ,    childUid )  . get (  )  ;", "}", "childId    =    j ;", "}", "refresh (  )  ;", "SearchType [  ]    searchTypes    =    new   SearchType [  ]  {    SearchType . QUERY _ THEN _ FETCH ,    SearchType . DFS _ QUERY _ THEN _ FETCH    }  ;", "for    ( SearchType   searchType    :    searchTypes )     {", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setSearchType ( searchType )  . setQuery ( JoinQueryBuilders . has (  \" child \"  ,    prefixQuery (  \" c _ field \"  ,     \" c \"  )  ,    Max )  )  . addSort (  \" p _ field \"  ,    ASC )  . setSize (  5  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  1  0 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \" p 0  0  0  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \" p 0  0  1  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \" p 0  0  2  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  3  ]  . getId (  )  ,    equalTo (  \" p 0  0  3  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  4  ]  . getId (  )  ,    equalTo (  \" p 0  0  4  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  \" test \"  )  . setSearchType ( searchType )  . setQuery ( JoinQueryBuilders . hasParentQuery (  \" parent \"  ,    prefixQuery (  \" p _ field \"  ,     \" p \"  )  ,    true )  )  . addSort (  \" c _ field \"  ,    ASC )  . setSize (  5  )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    equalTo (  5  0  0 L )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  0  ]  . getId (  )  ,    equalTo (  \" c 0  0  0  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  1  ]  . getId (  )  ,    equalTo (  \" c 0  0  1  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  2  ]  . getId (  )  ,    equalTo (  \" c 0  0  2  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  3  ]  . getId (  )  ,    equalTo (  \" c 0  0  3  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  [  4  ]  . getId (  )  ,    equalTo (  \" c 0  0  4  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSimpleQueryRewrite"], "fileName": "org.elasticsearch.join.query.ChildQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "return   type ;", "}", "METHOD_END"], "methodName": ["childType"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "float   boost    =    AbstractQueryBuilder . DEFAULT _ BOOST ;", "String   childType    =    null ;", "ScoreMode   scoreMode    =    ScoreMode . None ;", "int   minChildren    =     . DEFAULT _ MIN _ CHILDREN ;", "int   maxChildren    =     . DEFAULT _ MAX _ CHILDREN ;", "boolean   ignoreUnmapped    =     . DEFAULT _ IGNORE _ UNMAPPED ;", "String   queryName    =    null ;", "InnerHitBuilder   innerHitBuilder    =    null ;", "String   currentFieldName    =    null ;", "XContentParser . Token   token ;", "QueryBuilder   iqb    =    null ;", "while    (  ( token    =    parser . nextToken (  )  )     !  =     ( Token . END _ OBJECT )  )     {", "if    ( token    =  =     ( Token . FIELD _ NAME )  )     {", "currentFieldName    =    parser . currentName (  )  ;", "} else", "if    ( token    =  =     ( Token . START _ OBJECT )  )     {", "if    (  . QUERY _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "iqb    =    parseInnerQueryBuilder ( parser )  ;", "} else", "if    (  . INNER _ HITS _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "innerHitBuilder    =    InnerHitBuilder . fromXContent ( parser )  ;", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  \"  [ has _ child ]    query   does   not   support    [  \"     +    currentFieldName )     +     \"  ]  \"  )  )  ;", "}", "} else", "if    ( token . isValue (  )  )     {", "if    (  . TYPE _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "childType    =    parser . text (  )  ;", "} else", "if    (  . SCORE _ MODE _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "scoreMode    =    parseScoreMode ( parser . text (  )  )  ;", "} else", "if    ( AbstractQueryBuilder . BOOST _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "boost    =    parser . floatValue (  )  ;", "} else", "if    (  . MIN _ CHILDREN _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "minChildren    =    parser . intValue ( true )  ;", "} else", "if    (  . MAX _ CHILDREN _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "maxChildren    =    parser . intValue ( true )  ;", "} else", "if    (  . IGNORE _ UNMAPPED _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "ignoreUnmapped    =    parser . booleanValue (  )  ;", "} else", "if    ( AbstractQueryBuilder . NAME _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "queryName    =    parser . text (  )  ;", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  \"  [ has _ child ]    query   does   not   support    [  \"     +    currentFieldName )     +     \"  ]  \"  )  )  ;", "}", "}", "}", "hasChildQueryBuilder    =    new    ( childType ,    iqb ,    scoreMode )  ;", "hasChildQueryBuilder . minMaxChildren ( minChildren ,    maxChildren )  ;", "hasChildQueryBuilder . queryName ( queryName )  ;", "hasChildQueryBuilder . boost ( boost )  ;", "hasChildQueryBuilder . ignoreUnmapped ( ignoreUnmapped )  ;", "if    ( innerHitBuilder    !  =    null )     {", "hasChildQueryBuilder . innerHit ( innerHitBuilder )  ;", "}", "return   hasChildQueryBuilder ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   ignoreUnmapped ;", "}", "METHOD_END"], "methodName": ["ignoreUnmapped"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "this . ignoreUnmapped    =    ignoreUnmapped ;", "if    (  ( innerHit )     !  =    null )     {", "innerHit . setIgnoreUnmapped ( ignoreUnmapped )  ;", "}", "return   this ;", "}", "METHOD_END"], "methodName": ["ignoreUnmapped"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   innerHitBuilder ;", "}", "METHOD_END"], "methodName": ["innerHit"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "this . innerHitBuilder    =    innerHit ;", "innerHitBuilder . setIgnoreUnmapped ( ignoreUnmapped )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["innerHit"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   maxChildren ;", "}", "METHOD_END"], "methodName": ["maxChildren"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   minChildren ;", "}", "METHOD_END"], "methodName": ["minChildren"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "if    ( minChildren    <     0  )     {", "throw   new   IllegalArgumentException (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    requires   non - negative    ' min _ children '    field \"  )  )  ;", "}", "if    ( maxChildren    <     0  )     {", "throw   new   IllegalArgumentException (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    requires   non - negative    ' max _ children '    field \"  )  )  ;", "}", "if    ( maxChildren    <    minChildren )     {", "throw   new   IllegalArgumentException (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]     ' max _ children '    is   less   than    ' min _ children '  \"  )  )  ;", "}", "this . minChildren    =    minChildren ;", "this . maxChildren    =    maxChildren ;", "return   this ;", "}", "METHOD_END"], "methodName": ["minMaxChildren"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   query ;", "}", "METHOD_END"], "methodName": ["query"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   scoreMode ;", "}", "METHOD_END"], "methodName": ["scoreMode"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "assertThat ( query ,    instanceOf ( HasChildQueryBuilder . LateParsingQuery . class )  )  ;", "HasChildQueryBuilder . LateParsingQuery   lateParsingQuery    =     (  ( HasChildQueryBuilder . LateParsingQuery )     ( query )  )  ;", "assertThat ( lateParsingQuery . getInnerQuery (  )  ,    instanceOf ( BooleanQuery . class )  )  ;", "BooleanQuery   booleanQuery    =     (  ( BooleanQuery )     ( lateParsingQuery . getInnerQuery (  )  )  )  ;", "assertThat ( booleanQuery . clauses (  )  . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( booleanQuery . clauses (  )  . get (  0  )  . getOccur (  )  ,    equalTo ( MUST )  )  ;", "assertThat ( booleanQuery . clauses (  )  . get (  0  )  . getQuery (  )  ,    instanceOf ( TermInSetQuery . class )  )  ;", "TermInSetQuery   termsQuery    =     (  ( TermInSetQuery )     ( booleanQuery . clauses (  )  . get (  0  )  . getQuery (  )  )  )  ;", "Query   rewrittenTermsQuery    =    termsQuery . rewrite ( null )  ;", "assertThat ( rewrittenTermsQuery ,    instanceOf ( ConstantScoreQuery . class )  )  ;", "ConstantScoreQuery   constantScoreQuery    =     (  ( ConstantScoreQuery )     ( rewrittenTermsQuery )  )  ;", "assertThat ( constantScoreQuery . getQuery (  )  ,    instanceOf ( BooleanQuery . class )  )  ;", "BooleanQuery   booleanTermsQuery    =     (  ( BooleanQuery )     ( constantScoreQuery . getQuery (  )  )  )  ;", "assertThat ( booleanTermsQuery . clauses (  )  . toString (  )  ,    booleanTermsQuery . clauses (  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( booleanTermsQuery . clauses (  )  . get (  0  )  . getOccur (  )  ,    equalTo ( SHOULD )  )  ;", "assertThat ( booleanTermsQuery . clauses (  )  . get (  0  )  . getQuery (  )  ,    instanceOf ( TermQuery . class )  )  ;", "TermQuery   termQuery    =     (  ( TermQuery )     ( booleanTermsQuery . clauses (  )  . get (  0  )  . getQuery (  )  )  )  ;", "assertThat ( termQuery . getTerm (  )  . field (  )  ,    equalTo ( NAME )  )  ;", "assertThat ( termQuery . getTerm (  )  . bytes (  )  ,    equalTo ( Uid . encodeId ( id )  )  )  ;", "assertThat ( booleanQuery . clauses (  )  . get (  1  )  . getOccur (  )  ,    equalTo ( FILTER )  )  ;", "assertEquals ( new   TermQuery ( new   Term (  \" join _ field \"  ,    type )  )  ,    booleanQuery . clauses (  )  . get (  1  )  . getQuery (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertLateParsingQuery"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "String   query    =     \"  {  \\ n \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"        \\  \" has _ child \\  \"     :     {  \\ n \"     +     \"              \\  \" query \\  \"     :     {  \\ n \"  )     +     \"                    \\  \" range \\  \"     :     {  \\ n \"  )     +     \"                          \\  \" mapped _ string \\  \"     :     {  \\ n \"  )     +     \"                                \\  \" from \\  \"     :     \\  \" agJhRET \\  \"  ,  \\ n \"  )     +     \"                                \\  \" to \\  \"     :     \\  \" zvqIq \\  \"  ,  \\ n \"  )     +     \"                                \\  \" include _ lower \\  \"     :    true ,  \\ n \"  )     +     \"                                \\  \" include _ upper \\  \"     :    true ,  \\ n \"  )     +     \"                                \\  \" boost \\  \"     :     1  .  0  \\ n \"  )     +     \"                          }  \\ n \"  )     +     \"                    }  \\ n \"  )     +     \"              }  ,  \\ n \"  )     +     \"              \\  \" type \\  \"     :     \\  \" child \\  \"  ,  \\ n \"  )     +     \"              \\  \" score _ mode \\  \"     :     \\  \" avg \\  \"  ,  \\ n \"  )     +     \"              \\  \" min _ children \\  \"     :     8  8  3  1  7  0  8  7  3  ,  \\ n \"  )     +     \"              \\  \" max _ children \\  \"     :     1  2  1  7  2  3  5  4  4  2  ,  \\ n \"  )     +     \"              \\  \" ignore _ unmapped \\  \"     :    false ,  \\ n \"  )     +     \"              \\  \" boost \\  \"     :     2  .  0  ,  \\ n \"  )     +     \"              \\  \"  _ name \\  \"     :     \\  \" WNzYMJKRwePuRBh \\  \"  ,  \\ n \"  )     +     \"              \\  \" inner _ hits \\  \"     :     {  \\ n \"  )     +     \"                    \\  \" name \\  \"     :     \\  \" inner _ hits _ name \\  \"  ,  \\ n \"  )     +     \"                    \\  \" ignore _ unmapped \\  \"     :    false ,  \\ n \"  )     +     \"                    \\  \" from \\  \"     :     0  ,  \\ n \"  )     +     \"                    \\  \" size \\  \"     :     1  0  0  ,  \\ n \"  )     +     \"                    \\  \" version \\  \"     :    false ,  \\ n \"  )     +     \"                    \\  \" explain \\  \"     :    false ,  \\ n \"  )     +     \"                    \\  \" track _ scores \\  \"     :    false ,  \\ n \"  )     +     \"                    \\  \" sort \\  \"     :     [     {  \\ n \"  )     +     \"                          \\  \" mapped _ string \\  \"     :     {  \\ n \"  )     +     \"                                \\  \" order \\  \"     :     \\  \" asc \\  \"  \\ n \"  )     +     \"                          }  \\ n \"  )     +     \"                    }     ]  \\ n \"  )     +     \"              }  \\ n \"  )     +     \"        }  \\ n \"  )     +     \"  }  \"  )  ;", "queryBuilder    =     (  (  )     ( parseQuery ( query )  )  )  ;", "checkGeneratedJson ( query ,    queryBuilder )  ;", "assertEquals ( query ,    queryBuilder . maxChildren (  )  ,     1  2  1  7  2  3  5  4  4  2  )  ;", "assertEquals ( query ,    queryBuilder . minChildren (  )  ,     8  8  3  1  7  0  8  7  3  )  ;", "assertEquals ( query ,    queryBuilder . boost (  )  ,     2  .  0 F ,     0  .  0 F )  ;", "assertEquals ( query ,    queryBuilder . queryName (  )  ,     \" WNzYMJKRwePuRBh \"  )  ;", "assertEquals ( query ,    queryBuilder . childType (  )  ,     \" child \"  )  ;", "assertEquals ( query ,    queryBuilder . scoreMode (  )  ,    Avg )  ;", "assertNotNull ( query ,    queryBuilder . innerHit (  )  )  ;", "InnerHitBuilder   expected    =    new   InnerHitBuilder (  \" child \"  )  . setName (  \" inner _ hits _ name \"  )  . setSize (  1  0  0  )  . addSort ( new   FieldSortBuilder (  \" mapped _ string \"  )  . order ( ASC )  )  ;", "assertEquals ( query ,    queryBuilder . innerHit (  )  ,    expected )  ;", "}", "METHOD_END"], "methodName": ["testFromJson"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "final   HasChildQueryBuilder   queryBuilder    =    new   HasChildQueryBuilder (  \" unmapped \"  ,    new   MatchAllQueryBuilder (  )  ,    ScoreMode . None )  ;", "queryBuilder . innerHit ( new   InnerHitBuilder (  )  )  ;", "assertFalse ( queryBuilder . innerHit (  )  . isIgnoreUnmapped (  )  )  ;", "queryBuilder . ignoreUnmapped ( true )  ;", "assertTrue ( queryBuilder . innerHit (  )  . isIgnoreUnmapped (  )  )  ;", "Query   query    =    queryBuilder . toQuery ( createShardContext (  )  )  ;", "assertThat ( query ,    notNullValue (  )  )  ;", "assertThat ( query ,    instanceOf ( MatchNoDocsQuery . class )  )  ;", "final   HasChildQueryBuilder   failingQueryBuilder    =    new   HasChildQueryBuilder (  \" unmapped \"  ,    new   MatchAllQueryBuilder (  )  ,    ScoreMode . None )  ;", "failingQueryBuilder . innerHit ( new   InnerHitBuilder (  )  )  ;", "assertFalse ( failingQueryBuilder . innerHit (  )  . isIgnoreUnmapped (  )  )  ;", "failingQueryBuilder . ignoreUnmapped ( false )  ;", "assertFalse ( failingQueryBuilder . innerHit (  )  . isIgnoreUnmapped (  )  )  ;", "QueryShardException   e    =    expectThrows ( QueryShardException . class ,     (  )     -  >    failingQueryBuilder . toQuery ( createShardContext (  )  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \"  [  \"     +     ( HasChildQueryBuilder . NAME )  )     +     \"  ]    join   field    [ join _ field ]    doesn ' t   hold    [ unmapped ]    as   a   child \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testIgnoreUnmapped"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "final   HasChildQueryBuilder   queryBuilder    =    new   HasChildQueryBuilder (  \" unmapped \"  ,    new   WrapperQueryBuilder ( new   MatchAllQueryBuilder (  )  . toString (  )  )  ,    ScoreMode . None )  ;", "queryBuilder . ignoreUnmapped ( true )  ;", "QueryShardContext   queryShardContext    =    createShardContext (  )  ;", "Query   query    =    queryBuilder . rewrite ( queryShardContext )  . toQuery ( queryShardContext )  ;", "assertThat ( query ,    notNullValue (  )  )  ;", "assertThat ( query ,    instanceOf ( MatchNoDocsQuery . class )  )  ;", "}", "METHOD_END"], "methodName": ["testIgnoreUnmappedWithRewrite"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "QueryBuilder   query    =    new   MatchAllQueryBuilder (  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    hasChildQuery ( null ,    query ,    ScoreMode . None )  )  ;", "assertEquals (  \"  [ has _ child ]    requires    ' type '    field \"  ,    e . getMessage (  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    hasChildQuery (  \" foo \"  ,    null ,    ScoreMode . None )  )  ;", "assertEquals (  \"  [ has _ child ]    requires    ' query '    field \"  ,    e . getMessage (  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    hasChildQuery (  \" foo \"  ,    query ,    null )  )  ;", "assertEquals (  \"  [ has _ child ]    requires    ' score _ mode '    field \"  ,    e . getMessage (  )  )  ;", "int   positiveValue    =    randomIntBetween (  0  ,    Integer . MAX _ VALUE )  ;", "foo    =    JoinQueryBuilders . hasChildQuery (  \" foo \"  ,    query ,    None )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    foo . minMaxChildren ( randomIntBetween ( Integer . MIN _ VALUE ,     (  -  1  )  )  ,    positiveValue )  )  ;", "assertEquals (  \"  [ has _ child ]    requires   non - negative    ' min _ children '    field \"  ,    e . getMessage (  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    foo . minMaxChildren ( positiveValue ,    randomIntBetween ( Integer . MIN _ VALUE ,     (  -  1  )  )  )  )  ;", "assertEquals (  \"  [ has _ child ]    requires   non - negative    ' max _ children '    field \"  ,    e . getMessage (  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    foo . minMaxChildren ( positiveValue ,     ( positiveValue    -     1  0  )  )  )  ;", "assertEquals (  \"  [ has _ child ]     ' max _ children '    is   less   than    ' min _ children '  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalValues"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "QueryShardContext   shardContext    =    createShardContext (  )  ;", "HasChildQueryBuilder   hasChildQueryBuilder    =    JoinQueryBuilders . hasChildQuery (  . CHILD _ DOC ,    new   TermQueryBuilder (  \" custom _ string \"  ,     \" value \"  )  ,    None )  ;", "HasChildQueryBuilder . LateParsingQuery   query    =     (  ( HasChildQueryBuilder . LateParsingQuery )     ( hasChildQueryBuilder . toQuery ( shardContext )  )  )  ;", "Similarity   expected    =    BUILT _ IN . get (  . similarity )  . apply ( EMPTY ,    CURRENT ,    null )  ;", "assertThat (  (  ( PerFieldSimilarityWrapper )     ( query . getSimilarity (  )  )  )  . get (  \" custom _ string \"  )  ,    instanceOf ( expected . getClass (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNonDefaultSimilarity"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "for    ( Version   version    :    VersionUtils . allReleasedVersions (  )  )     {", "testQuery    =    createTestQueryBuilder (  )  ;", "if    (  ( version . before ( V _  5  _  2  _  0  )  )     &  &     (  ( testQuery . innerHit (  )  )     !  =    null )  )     {", "testQuery . innerHit (  )  . setIgnoreUnmapped ( false )  ;", "}", "assertSerialization ( testQuery ,    version )  ;", "}", "}", "METHOD_END"], "methodName": ["testSerializationBWC"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "String [  ]    searchTypes    =    new   String [  ]  {    HasChildQueryBuilderTests . TYPE    }  ;", "QueryShardContext   shardContext    =    createShardContext (  )  ;", "shardContext . setTypes ( searchTypes )  ;", "HasChildQueryBuilder   hasChildQueryBuilder    =    JoinQueryBuilders . hasChildQuery ( HasChildQueryBuilderTests . CHILD _ DOC ,    new   IdsQueryBuilder (  )  . addIds (  \" id \"  )  ,    None )  ;", "Query   query    =    hasChildQueryBuilder . toQuery ( shardContext )  ;", "assertThat ( shardContext . getTypes (  )  ,    equalTo ( searchTypes )  )  ;", "HasChildQueryBuilderTests . assertLateParsingQuery ( query ,    HasChildQueryBuilderTests . CHILD _ DOC ,     \" id \"  )  ;", "}", "METHOD_END"], "methodName": ["testToQueryInnerQueryType"], "fileName": "org.elasticsearch.join.query.HasChildQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "float   boost    =    AbstractQueryBuilder . DEFAULT _ BOOST ;", "String   parentType    =    null ;", "boolean   score    =    false ;", "String   queryName    =    null ;", "InnerHitBuilder   innerHits    =    null ;", "boolean   ignoreUnmapped    =     . DEFAULT _ IGNORE _ UNMAPPED ;", "String   currentFieldName    =    null ;", "XContentParser . Token   token ;", "QueryBuilder   iqb    =    null ;", "while    (  ( token    =    parser . nextToken (  )  )     !  =     ( Token . END _ OBJECT )  )     {", "if    ( token    =  =     ( Token . FIELD _ NAME )  )     {", "currentFieldName    =    parser . currentName (  )  ;", "} else", "if    ( token    =  =     ( Token . START _ OBJECT )  )     {", "if    (  . QUERY _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "iqb    =    parseInnerQueryBuilder ( parser )  ;", "} else", "if    (  . INNER _ HITS _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "innerHits    =    InnerHitBuilder . fromXContent ( parser )  ;", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  \"  [ has _ parent ]    query   does   not   support    [  \"     +    currentFieldName )     +     \"  ]  \"  )  )  ;", "}", "} else", "if    ( token . isValue (  )  )     {", "if    (  . TYPE _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "parentType    =    parser . text (  )  ;", "} else", "if    (  . SCORE _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "score    =    parser . booleanValue (  )  ;", "} else", "if    (  . IGNORE _ UNMAPPED _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "ignoreUnmapped    =    parser . booleanValue (  )  ;", "} else", "if    ( AbstractQueryBuilder . BOOST _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "boost    =    parser . floatValue (  )  ;", "} else", "if    ( AbstractQueryBuilder . NAME _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "queryName    =    parser . text (  )  ;", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  \"  [ has _ parent ]    query   does   not   support    [  \"     +    currentFieldName )     +     \"  ]  \"  )  )  ;", "}", "}", "}", "queryBuilder    =    new    ( parentType ,    iqb ,    score )  . ignoreUnmapped ( ignoreUnmapped )  . queryName ( queryName )  . boost ( boost )  ;", "if    ( innerHits    !  =    null )     {", "queryBuilder . innerHit ( innerHits )  ;", "}", "return   queryBuilder ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   ignoreUnmapped ;", "}", "METHOD_END"], "methodName": ["ignoreUnmapped"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "this . ignoreUnmapped    =    ignoreUnmapped ;", "if    (  ( innerHit )     !  =    null )     {", "innerHit . setIgnoreUnmapped ( ignoreUnmapped )  ;", "}", "return   this ;", "}", "METHOD_END"], "methodName": ["ignoreUnmapped"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   innerHitBuilder ;", "}", "METHOD_END"], "methodName": ["innerHit"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "this . innerHitBuilder    =    innerHit ;", "innerHitBuilder . setIgnoreUnmapped ( ignoreUnmapped )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["innerHit"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   query ;", "}", "METHOD_END"], "methodName": ["query"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   score ;", "}", "METHOD_END"], "methodName": ["score"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   type ;", "}", "METHOD_END"], "methodName": ["type"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "String   json    =     \"  {  \\ n \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  \"        \\  \" has _ parent \\  \"     :     {  \\ n \"     +     \"              \\  \" query \\  \"     :     {  \\ n \"  )     +     \"                    \\  \" term \\  \"     :     {  \\ n \"  )     +     \"                          \\  \" tag \\  \"     :     {  \\ n \"  )     +     \"                                \\  \" value \\  \"     :     \\  \" something \\  \"  ,  \\ n \"  )     +     \"                                \\  \" boost \\  \"     :     1  .  0  \\ n \"  )     +     \"                          }  \\ n \"  )     +     \"                    }  \\ n \"  )     +     \"              }  ,  \\ n \"  )     +     \"              \\  \" parent _ type \\  \"     :     \\  \" blog \\  \"  ,  \\ n \"  )     +     \"              \\  \" score \\  \"     :    true ,  \\ n \"  )     +     \"              \\  \" ignore _ unmapped \\  \"     :    false ,  \\ n \"  )     +     \"              \\  \" boost \\  \"     :     1  .  0  \\ n \"  )     +     \"        }  \\ n \"  )     +     \"  }  \"  )  ;", "parsed    =     (  (  )     ( parseQuery ( json )  )  )  ;", "checkGeneratedJson ( json ,    parsed )  ;", "assertEquals ( json ,     \" blog \"  ,    parsed . type (  )  )  ;", "assertEquals ( json ,     \" something \"  ,     (  ( TermQueryBuilder )     ( parsed . query (  )  )  )  . value (  )  )  ;", "}", "METHOD_END"], "methodName": ["testFromJson"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "final   HasParentQueryBuilder   queryBuilder    =    new   HasParentQueryBuilder (  \" unmapped \"  ,    new   MatchAllQueryBuilder (  )  ,    false )  ;", "queryBuilder . innerHit ( new   InnerHitBuilder (  )  )  ;", "assertFalse ( queryBuilder . innerHit (  )  . isIgnoreUnmapped (  )  )  ;", "queryBuilder . ignoreUnmapped ( true )  ;", "assertTrue ( queryBuilder . innerHit (  )  . isIgnoreUnmapped (  )  )  ;", "Query   query    =    queryBuilder . toQuery ( createShardContext (  )  )  ;", "assertThat ( query ,    notNullValue (  )  )  ;", "assertThat ( query ,    instanceOf ( MatchNoDocsQuery . class )  )  ;", "final   HasParentQueryBuilder   failingQueryBuilder    =    new   HasParentQueryBuilder (  \" unmapped \"  ,    new   MatchAllQueryBuilder (  )  ,    false )  ;", "failingQueryBuilder . innerHit ( new   InnerHitBuilder (  )  )  ;", "assertFalse ( failingQueryBuilder . innerHit (  )  . isIgnoreUnmapped (  )  )  ;", "failingQueryBuilder . ignoreUnmapped ( false )  ;", "assertFalse ( failingQueryBuilder . innerHit (  )  . isIgnoreUnmapped (  )  )  ;", "QueryShardException   e    =    expectThrows ( QueryShardException . class ,     (  )     -  >    failingQueryBuilder . toQuery ( createShardContext (  )  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \"  [ has _ parent ]    join   field    [ join _ field ]    doesn ' t   hold    [ unmapped ]    as   a   parent \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIgnoreUnmapped"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "final   HasParentQueryBuilder   queryBuilder    =    new   HasParentQueryBuilder (  \" unmapped \"  ,    new   WrapperQueryBuilder ( new   MatchAllQueryBuilder (  )  . toString (  )  )  ,    false )  ;", "queryBuilder . ignoreUnmapped ( true )  ;", "QueryShardContext   queryShardContext    =    createShardContext (  )  ;", "Query   query    =    queryBuilder . rewrite ( queryShardContext )  . toQuery ( queryShardContext )  ;", "assertThat ( query ,    notNullValue (  )  )  ;", "assertThat ( query ,    instanceOf ( MatchNoDocsQuery . class )  )  ;", "}", "METHOD_END"], "methodName": ["testIgnoreUnmappedWithRewrite"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "QueryBuilder   query    =    new   MatchAllQueryBuilder (  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    hasParentQuery ( null ,    query ,    false )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ has _ parent ]    requires    ' type '    field \"  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    hasParentQuery (  \" foo \"  ,    null ,    false )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ has _ parent ]    requires    ' query '    field \"  )  )  ;", "QueryShardContext   context    =    createShardContext (  )  ;", "qb    =    JoinQueryBuilders . hasParentQuery (  \" just _ a _ type \"  ,    new   MatchAllQueryBuilder (  )  ,    false )  ;", "QueryShardException   qse    =    expectThrows ( QueryShardException . class ,     (  )     -  >    qb . doToQuery ( context )  )  ;", "assertThat ( qse . getMessage (  )  ,    equalTo (  \"  [ has _ parent ]    join   field    [ join _ field ]    doesn ' t   hold    [ just _ a _ type ]    as   a   parent \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalValues"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "for    ( Version   version    :    VersionUtils . allReleasedVersions (  )  )     {", "testQuery    =    createTestQueryBuilder (  )  ;", "if    (  ( version . before ( V _  5  _  2  _  0  )  )     &  &     (  ( testQuery . innerHit (  )  )     !  =    null )  )     {", "testQuery . innerHit (  )  . setIgnoreUnmapped ( false )  ;", "}", "assertSerialization ( testQuery ,    version )  ;", "}", "}", "METHOD_END"], "methodName": ["testSerializationBWC"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "String [  ]    searchTypes    =    new   String [  ]  {    HasParentQueryBuilderTests . TYPE    }  ;", "QueryShardContext   shardContext    =    createShardContext (  )  ;", "shardContext . setTypes ( searchTypes )  ;", "HasParentQueryBuilder   hasParentQueryBuilder    =    new   HasParentQueryBuilder ( HasParentQueryBuilderTests . PARENT _ DOC ,    new   IdsQueryBuilder (  )  . addIds (  \" id \"  )  ,    false )  ;", "Query   query    =    hasParentQueryBuilder . toQuery ( shardContext )  ;", "assertThat ( shardContext . getTypes (  )  ,    equalTo ( searchTypes )  )  ;", "HasChildQueryBuilderTests . assertLateParsingQuery ( query ,    HasParentQueryBuilderTests . PARENT _ DOC ,     \" id \"  )  ;", "}", "METHOD_END"], "methodName": ["testToQueryInnerQueryType"], "fileName": "org.elasticsearch.join.query.HasParentQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" stack \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" question \"  ,     \" answer \"  )  ,     \" body \"  ,     \" text \"  )  )  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "requests . add ( createIndexRequest (  \" stack \"  ,     \" question \"  ,     \"  1  \"  ,    null ,     \" body \"  ,     (  \" I ' m   using   HTTPS    +    Basic   authentication    \"     +     \" to   protect   a   resource .    How   can   I   throttle   authentication   attempts   to   protect   against   brute   force   attacks ?  \"  )  )  )  ;", "requests . add ( createIndexRequest (  \" stack \"  ,     \" answer \"  ,     \"  3  \"  ,     \"  1  \"  ,     \" body \"  ,     \" install   fail 2 ban   and   enable   rules   for   apache \"  )  )  ;", "requests . add ( createIndexRequest (  \" stack \"  ,     \" question \"  ,     \"  2  \"  ,    null ,     \" body \"  ,     \" I   have   firewall   rules   set   up   and   also   denyhosts   installed .  \\  \\ ndo   I   also   need   to   install   fail 2 ban ?  \"  )  )  ;", "requests . add ( createIndexRequest (  \" stack \"  ,     \" answer \"  ,     \"  4  \"  ,     \"  2  \"  ,     \" body \"  ,     \" Denyhosts   protects   only   ssh ;    Fail 2 Ban   protects   all   daemons .  \"  )  )  ;", "indexRandom ( true ,    requests )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" stack \"  )  . addSort (  \"  _ id \"  ,    ASC )  . setQuery ( boolQuery (  )  . must ( matchQuery (  \" body \"  ,     \" fail 2 ban \"  )  )  . must ( JoinQueryBuilders . hasParentQuery (  \" question \"  ,    matchAllQuery (  )  ,    false )  . innerHit ( new   InnerHitBuilder (  )  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     2  )  ;", "SearchHit   searchHit    =    response . getHits (  )  . getAt (  0  )  ;", "assertThat ( searchHit . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( searchHit . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "assertThat ( searchHit . get (  )  . get (  \" question \"  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchHit . get (  )  . get (  \" question \"  )  . getAt (  0  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "assertThat ( searchHit . get (  )  . get (  \" question \"  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "searchHit    =    response . getHits (  )  . getAt (  1  )  ;", "assertThat ( searchHit . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( searchHit . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "assertThat ( searchHit . get (  )  . get (  \" question \"  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( searchHit . get (  )  . get (  \" question \"  )  . getAt (  0  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "assertThat ( searchHit . get (  )  . get (  \" question \"  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInnerHitsOnHasParent"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" index 1  \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent _ type \"  ,     \" child _ type \"  )  ,     \" nested _ type \"  ,     \" nested \"  )  )  )  ;", "assertAcked ( prepareCreate (  \" index 2  \"  )  )  ;", "createIndexRequest (  \" index 1  \"  ,     \" parent _ type \"  ,     \"  1  \"  ,    null ,     \" nested _ type \"  ,    Collections . singletonMap (  \" key \"  ,     \" value \"  )  )  . get (  )  ;", "createIndexRequest (  \" index 1  \"  ,     \" child _ type \"  ,     \"  2  \"  ,     \"  1  \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" index 2  \"  ,     \" type \"  ,     \"  3  \"  )  . setSource (  \" key \"  ,     \" value \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" index 1  \"  ,     \" index 2  \"  )  . setQuery ( boolQuery (  )  . should ( JoinQueryBuilders . hasChildQuery (  \" child _ type \"  ,    matchAllQuery (  )  ,    None )  . ignoreUnmapped ( true )  . innerHit ( new   Builder (  )  . setIgnoreUnmapped ( true )  )  )  . should ( termQuery (  \" key \"  ,     \" value \"  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     2  )  ;", "assertSearchHits ( response ,     \"  1  \"  ,     \"  3  \"  )  ;", "}", "METHOD_END"], "methodName": ["testInnerHitsWithIgnoreUnmapped"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" index \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" parent \"  ,     \"  1  \"  ,    null )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" child \"  ,     \"  3  \"  ,     \"  1  \"  ,     \" field \"  ,     \" value 1  \"  )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" child \"  ,     \"  4  \"  ,     \"  1  \"  ,     \" field \"  ,     \" value 2  \"  )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" parent \"  ,     \"  2  \"  ,    null )  )  ;", "requests . add ( createIndexRequest (  \" index \"  ,     \" child \"  ,     \"  5  \"  ,     \"  2  \"  ,     \" field \"  ,     \" value 1  \"  )  )  ;", "indexRandom ( true ,    requests )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" index \"  )  . setQuery ( JoinQueryBuilders . hasChildQuery (  \" child \"  ,    matchQuery (  \" field \"  ,     \" value 1  \"  )  . queryName (  \"  _ name 1  \"  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     2  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" child \"  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" child \"  )  . getAt (  0  )  . getMatchedQueries (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" child \"  )  . getAt (  0  )  . getMatchedQueries (  )  [  0  ]  ,    equalTo (  \"  _ name 1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . get (  )  . get (  \" child \"  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . get (  )  . get (  \" child \"  )  . getAt (  0  )  . getMatchedQueries (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . get (  )  . get (  \" child \"  )  . getAt (  0  )  . getMatchedQueries (  )  [  0  ]  ,    equalTo (  \"  _ name 1  \"  )  )  ;", "QueryBuilder   query    =    JoinQueryBuilders . hasChildQuery (  \" child \"  ,    matchQuery (  \" field \"  ,     \" value 2  \"  )  . queryName (  \"  _ name 2  \"  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  ;", "response    =    client (  )  . prepareSearch (  \" index \"  )  . setQuery ( query )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" child \"  )  . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" child \"  )  . getAt (  0  )  . getMatchedQueries (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" child \"  )  . getAt (  0  )  . getMatchedQueries (  )  [  0  ]  ,    equalTo (  \"  _ name 2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMatchesQueriesParentChildInnerHits"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent _ type \"  ,     \" child _ type \"  )  ,     \" nested _ type \"  ,     \" nested \"  )  )  )  ;", "createIndexRequest (  \" test \"  ,     \" parent _ type \"  ,     \"  1  \"  ,    null ,     \" key \"  ,     \" value \"  )  . get (  )  ;", "createIndexRequest (  \" test \"  ,     \" child _ type \"  ,     \"  2  \"  ,     \"  1  \"  ,     \" nested _ type \"  ,    Collections . singletonMap (  \" key \"  ,     \" value \"  )  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( boolQuery (  )  . must ( matchQuery (  \" key \"  ,     \" value \"  )  )  . should ( JoinQueryBuilders . hasChildQuery (  \" child _ type \"  ,    nestedQuery (  \" nested _ type \"  ,    matchAllQuery (  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "SearchHit   hit    =    response . getHits (  )  . getAt (  0  )  ;", "String   parentId    =     (  ( String )     ( extractValue (  \" join _ field . parent \"  ,    hit . get (  )  . get (  \" child _ type \"  )  . getAt (  0  )  . getSourceAsMap (  )  )  )  )  ;", "assertThat ( parentId ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( hit . get (  )  . get (  \" child _ type \"  )  . getAt (  0  )  . get (  )  . get (  \" nested _ type \"  )  . getAt (  0  )  . field (  \"  _ parent \"  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNestedInnerHitWrappedInParentChildInnerhit"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" articles \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" article \"  ,     \" comment \"  ,     \" comment \"  ,     \" remark \"  )  ,     \" title \"  ,     \" text \"  ,     \" message \"  ,     \" text \"  )  )  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" article \"  ,     \"  1  \"  ,    null ,     \" title \"  ,     \" quick   brown   fox \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" comment \"  ,     \"  3  \"  ,     \"  1  \"  ,     \" message \"  ,     \" fox   eat   quick \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" remark \"  ,     \"  5  \"  ,     \"  3  \"  ,     \" message \"  ,     \" good \"  )  . setRouting (  \"  1  \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" article \"  ,     \"  2  \"  ,    null ,     \" title \"  ,     \" big   gray   elephant \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" comment \"  ,     \"  4  \"  ,     \"  2  \"  ,     \" message \"  ,     \" elephant   captured \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" remark \"  ,     \"  6  \"  ,     \"  4  \"  ,     \" message \"  ,     \" bad \"  )  . setRouting (  \"  2  \"  )  )  ;", "indexRandom ( true ,    requests )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" articles \"  )  . setQuery ( JoinQueryBuilders . hasChildQuery (  \" comment \"  ,    JoinQueryBuilders . hasChildQuery (  \" remark \"  ,    matchQuery (  \" message \"  ,     \" good \"  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     1  )  ;", "assertSearchHit ( response ,     1  ,    hasId (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . get (  )  . size (  )  ,    equalTo (  1  )  )  ;", "SearchHits   innerHits    =    response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" comment \"  )  ;", "assertThat ( innerHits . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "innerHits    =    innerHits . getAt (  0  )  . get (  )  . get (  \" remark \"  )  ;", "assertThat ( innerHits . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getId (  )  ,    equalTo (  \"  5  \"  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "response    =    client (  )  . prepareSearch (  \" articles \"  )  . setQuery ( JoinQueryBuilders . hasChildQuery (  \" comment \"  ,    JoinQueryBuilders . hasChildQuery (  \" remark \"  ,    matchQuery (  \" message \"  ,     \" bad \"  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     1  )  ;", "assertSearchHit ( response ,     1  ,    hasId (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . get (  )  . size (  )  ,    equalTo (  1  )  )  ;", "innerHits    =    response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" comment \"  )  ;", "assertThat ( innerHits . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "innerHits    =    innerHits . getAt (  0  )  . get (  )  . get (  \" remark \"  )  ;", "assertThat ( innerHits . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getId (  )  ,    equalTo (  \"  6  \"  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testParentChildMultipleLayers"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" idx \"  )  . addMapping (  \" doc \"  ,    jsonBuilder (  )  . startObject (  )  . startObject (  \" doc \"  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" parent \"  ,    new   String [  ]  {     \" child 1  \"  ,     \" child 2  \"     }  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  )  ;", "int   numDocs    =    scaledRandomIntBetween (  5  ,     5  0  )  ;", "List < IndexRequestBuilder >    requestBuilders    =    new   ArrayList <  >  (  )  ;", "int   child 1     =     0  ;", "int   child 2     =     0  ;", "int [  ]    child 1 InnerObjects    =    new   int [ numDocs ]  ;", "int [  ]    child 2 InnerObjects    =    new   int [ numDocs ]  ;", "for    ( int   parent    =     0  ;    parent    <    numDocs ;    parent +  +  )     {", "String   parentId    =    String . format ( Locale . ENGLISH ,     \" p _  %  0  3 d \"  ,    parent )  ;", "requestBuilders . add ( createIndexRequest (  \" idx \"  ,     \" parent \"  ,    parentId ,    null )  )  ;", "int   numChildDocs    =    child 1 InnerObjects [ parent ]     =    scaledRandomIntBetween (  1  ,    numDocs )  ;", "int   limit    =    child 1     +    numChildDocs ;", "for    (  ;    child 1     <    limit ;    child 1  +  +  )     {", "requestBuilders . add ( createIndexRequest (  \" idx \"  ,     \" child 1  \"  ,    String . format ( Locale . ENGLISH ,     \" c 1  _  %  0  4 d \"  ,    child 1  )  ,    parentId )  )  ;", "}", "numChildDocs    =    child 2 InnerObjects [ parent ]     =    scaledRandomIntBetween (  1  ,    numDocs )  ;", "limit    =    child 2     +    numChildDocs ;", "for    (  ;    child 2     <    limit ;    child 2  +  +  )     {", "requestBuilders . add ( createIndexRequest (  \" idx \"  ,     \" child 2  \"  ,    String . format ( Locale . ENGLISH ,     \" c 2  _  %  0  4 d \"  ,    child 2  )  ,    parentId )  )  ;", "}", "}", "indexRandom ( true ,    requestBuilders )  ;", "int   size    =    randomIntBetween (  0  ,    numDocs )  ;", "BoolQueryBuilder   boolQuery    =    new   BoolQueryBuilder (  )  ;", "boolQuery . should ( constantScoreQuery ( JoinQueryBuilders . hasChildQuery (  \" child 1  \"  ,    matchAllQuery (  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  . setName (  \" a \"  )  . addSort ( new   FieldSortBuilder (  \"  _ id \"  )  . order ( ASC )  )  . setSize ( size )  )  )  )  ;", "boolQuery . should ( constantScoreQuery ( JoinQueryBuilders . hasChildQuery (  \" child 2  \"  ,    matchAllQuery (  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  . setName (  \" b \"  )  . addSort ( new   FieldSortBuilder (  \"  _ id \"  )  . order ( ASC )  )  . setSize ( size )  )  )  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  \" idx \"  )  . setSize ( numDocs )  . addSort (  \"  _ id \"  ,    ASC )  . setQuery ( boolQuery )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertHitCount ( searchResponse ,    numDocs )  ;", "assertThat ( searchResponse . getHits (  )  . getHits (  )  . length ,    equalTo ( numDocs )  )  ;", "int   offset 1     =     0  ;", "int   offset 2     =     0  ;", "for    ( int   parent    =     0  ;    parent    <    numDocs ;    parent +  +  )     {", "SearchHit   searchHit    =    searchResponse . getHits (  )  . getAt ( parent )  ;", "assertThat ( searchHit . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "assertThat ( searchHit . getId (  )  ,    equalTo ( String . format ( Locale . ENGLISH ,     \" p _  %  0  3 d \"  ,    parent )  )  )  ;", "assertThat ( searchHit . getShard (  )  ,    notNullValue (  )  )  ;", "SearchHits   inner    =    searchHit . get (  )  . get (  \" a \"  )  ;", "assertThat ( inner . getTotalHits (  )  ,    equalTo (  (  ( long )     ( child 1 InnerObjects [ parent ]  )  )  )  )  ;", "for    ( int   child    =     0  ;     ( child    <     ( child 1 InnerObjects [ parent ]  )  )     &  &     ( child    <    size )  ;    child +  +  )     {", "SearchHit   innerHit    =    inner . getAt ( child )  ;", "assertThat ( innerHit . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "String   childId    =    String . format ( Locale . ENGLISH ,     \" c 1  _  %  0  4 d \"  ,     ( offset 1     +    child )  )  ;", "assertThat ( innerHit . getId (  )  ,    equalTo ( childId )  )  ;", "assertThat ( innerHit . getNestedIdentity (  )  ,    nullValue (  )  )  ;", "}", "offset 1     +  =    child 1 InnerObjects [ parent ]  ;", "inner    =    searchHit . get (  )  . get (  \" b \"  )  ;", "assertThat ( inner . getTotalHits (  )  ,    equalTo (  (  ( long )     ( child 2 InnerObjects [ parent ]  )  )  )  )  ;", "for    ( int   child    =     0  ;     ( child    <     ( child 2 InnerObjects [ parent ]  )  )     &  &     ( child    <    size )  ;    child +  +  )     {", "SearchHit   innerHit    =    inner . getAt ( child )  ;", "assertThat ( innerHit . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "String   childId    =    String . format ( Locale . ENGLISH ,     \" c 2  _  %  0  4 d \"  ,     ( offset 2     +    child )  )  ;", "assertThat ( innerHit . getId (  )  ,    equalTo ( childId )  )  ;", "assertThat ( innerHit . getNestedIdentity (  )  ,    nullValue (  )  )  ;", "}", "offset 2     +  =    child 2 InnerObjects [ parent ]  ;", "}", "}", "METHOD_END"], "methodName": ["testRandomParentChild"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" royals \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" king \"  ,     \" prince \"  ,     \" prince \"  ,     \" duke \"  ,     \" duke \"  ,     \" earl \"  ,     \" earl \"  ,     \" baron \"  )  )  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" king \"  ,     \" king \"  ,    null )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" prince \"  ,     \" prince \"  ,     \" king \"  )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" duke \"  ,     \" duke \"  ,     \" prince \"  )  . setRouting (  \" king \"  )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" earl \"  ,     \" earl 1  \"  ,     \" duke \"  )  . setRouting (  \" king \"  )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" earl \"  ,     \" earl 2  \"  ,     \" duke \"  )  . setRouting (  \" king \"  )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" earl \"  ,     \" earl 3  \"  ,     \" duke \"  )  . setRouting (  \" king \"  )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" earl \"  ,     \" earl 4  \"  ,     \" duke \"  )  . setRouting (  \" king \"  )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" baron \"  ,     \" baron 1  \"  ,     \" earl 1  \"  )  . setRouting (  \" king \"  )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" baron \"  ,     \" baron 2  \"  ,     \" earl 2  \"  )  . setRouting (  \" king \"  )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" baron \"  ,     \" baron 3  \"  ,     \" earl 3  \"  )  . setRouting (  \" king \"  )  )  ;", "requests . add ( createIndexRequest (  \" royals \"  ,     \" baron \"  ,     \" baron 4  \"  ,     \" earl 4  \"  )  . setRouting (  \" king \"  )  )  ;", "indexRandom ( true ,    requests )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" royals \"  )  . setQuery ( boolQuery (  )  . filter ( JoinQueryBuilders . hasParentQuery (  \" prince \"  ,    JoinQueryBuilders . hasParentQuery (  \" king \"  ,    matchAllQuery (  )  ,    false )  . innerHit ( new   InnerHitBuilder (  )  . setName (  \" kings \"  )  )  ,    false )  . innerHit ( new   InnerHitBuilder (  )  . setName (  \" princes \"  )  )  )  . filter ( JoinQueryBuilders . hasChildQuery (  \" earl \"  ,    JoinQueryBuilders . hasChildQuery (  \" baron \"  ,    matchAllQuery (  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  . setName (  \" barons \"  )  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  . addSort ( SortBuilders . fieldSort (  \"  _ id \"  )  . order ( ASC )  )  . setName (  \" earls \"  )  . setSize (  4  )  )  )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" duke \"  )  )  ;", "SearchHits   innerHits    =    response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" earls \"  )  ;", "assertThat ( innerHits . getTotalHits (  )  ,    equalTo (  4 L )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getId (  )  ,    equalTo (  \" earl 1  \"  )  )  ;", "assertThat ( innerHits . getAt (  1  )  . getId (  )  ,    equalTo (  \" earl 2  \"  )  )  ;", "assertThat ( innerHits . getAt (  2  )  . getId (  )  ,    equalTo (  \" earl 3  \"  )  )  ;", "assertThat ( innerHits . getAt (  3  )  . getId (  )  ,    equalTo (  \" earl 4  \"  )  )  ;", "SearchHits   inner    =    innerHits . getAt (  0  )  . get (  )  . get (  \" barons \"  )  ;", "assertThat ( inner . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( inner . getAt (  0  )  . getId (  )  ,    equalTo (  \" baron 1  \"  )  )  ;", "inner    =    innerHits . getAt (  1  )  . get (  )  . get (  \" barons \"  )  ;", "assertThat ( inner . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( inner . getAt (  0  )  . getId (  )  ,    equalTo (  \" baron 2  \"  )  )  ;", "inner    =    innerHits . getAt (  2  )  . get (  )  . get (  \" barons \"  )  ;", "assertThat ( inner . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( inner . getAt (  0  )  . getId (  )  ,    equalTo (  \" baron 3  \"  )  )  ;", "inner    =    innerHits . getAt (  3  )  . get (  )  . get (  \" barons \"  )  ;", "assertThat ( inner . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( inner . getAt (  0  )  . getId (  )  ,    equalTo (  \" baron 4  \"  )  )  ;", "innerHits    =    response . getHits (  )  . getAt (  0  )  . get (  )  . get (  \" princes \"  )  ;", "assertThat ( innerHits . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getId (  )  ,    equalTo (  \" prince \"  )  )  ;", "inner    =    innerHits . getAt (  0  )  . get (  )  . get (  \" kings \"  )  ;", "assertThat ( inner . getTotalHits (  )  ,    equalTo (  1 L )  )  ;", "assertThat ( inner . getAt (  0  )  . getId (  )  ,    equalTo (  \" king \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRoyals"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" articles \"  )  . addMapping (  \" doc \"  ,    jsonBuilder (  )  . startObject (  )  . startObject (  \" doc \"  )  . startObject (  \" properties \"  )  . startObject (  \" join _ field \"  )  . field (  \" type \"  ,     \" join \"  )  . startObject (  \" relations \"  )  . field (  \" article \"  ,     \" comment \"  )  . endObject (  )  . endObject (  )  . startObject (  \" title \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . startObject (  \" message \"  )  . field (  \" type \"  ,     \" text \"  )  . field (  \" fielddata \"  ,    true )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" article \"  ,     \" p 1  \"  ,    null ,     \" title \"  ,     \" quick   brown   fox \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" comment \"  ,     \" c 1  \"  ,     \" p 1  \"  ,     \" message \"  ,     \" fox   eat   quick \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" comment \"  ,     \" c 2  \"  ,     \" p 1  \"  ,     \" message \"  ,     \" fox   ate   rabbit   x   y   z \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" comment \"  ,     \" c 3  \"  ,     \" p 1  \"  ,     \" message \"  ,     \" rabbit   got   away \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" article \"  ,     \" p 2  \"  ,    null ,     \" title \"  ,     \" big   gray   elephant \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" comment \"  ,     \" c 4  \"  ,     \" p 2  \"  ,     \" message \"  ,     \" elephant   captured \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" comment \"  ,     \" c 5  \"  ,     \" p 2  \"  ,     \" message \"  ,     \" mice   squashed   by   elephant   x \"  )  )  ;", "requests . add ( createIndexRequest (  \" articles \"  ,     \" comment \"  ,     \" c 6  \"  ,     \" p 2  \"  ,     \" message \"  ,     \" elephant   scared   by   mice   x   y \"  )  )  ;", "indexRandom ( true ,    requests )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" articles \"  )  . setQuery ( JoinQueryBuilders . hasChildQuery (  \" comment \"  ,    matchQuery (  \" message \"  ,     \" fox \"  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     1  )  ;", "assertSearchHit ( response ,     1  ,    hasId (  \" p 1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getShard (  )  ,    notNullValue (  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getInnerHits (  )  . size (  )  ,    equalTo (  1  )  )  ;", "SearchHits   innerHits    =    response . getHits (  )  . getAt (  0  )  . getInnerHits (  )  . get (  \" comment \"  )  ;", "assertThat ( innerHits . getTotalHits (  )  ,    equalTo (  2 L )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getId (  )  ,    equalTo (  \" c 1  \"  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "assertThat ( innerHits . getAt (  1  )  . getId (  )  ,    equalTo (  \" c 2  \"  )  )  ;", "assertThat ( innerHits . getAt (  1  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "response    =    client (  )  . prepareSearch (  \" articles \"  )  . setQuery ( JoinQueryBuilders . hasChildQuery (  \" comment \"  ,    matchQuery (  \" message \"  ,     \" elephant \"  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     1  )  ;", "assertSearchHit ( response ,     1  ,    hasId (  \" p 2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getInnerHits (  )  . size (  )  ,    equalTo (  1  )  )  ;", "innerHits    =    response . getHits (  )  . getAt (  0  )  . getInnerHits (  )  . get (  \" comment \"  )  ;", "assertThat ( innerHits . getTotalHits (  )  ,    equalTo (  3 L )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getId (  )  ,    equalTo (  \" c 4  \"  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "assertThat ( innerHits . getAt (  1  )  . getId (  )  ,    equalTo (  \" c 5  \"  )  )  ;", "assertThat ( innerHits . getAt (  1  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "assertThat ( innerHits . getAt (  2  )  . getId (  )  ,    equalTo (  \" c 6  \"  )  )  ;", "assertThat ( innerHits . getAt (  2  )  . getType (  )  ,    equalTo (  \" doc \"  )  )  ;", "response    =    client (  )  . prepareSearch (  \" articles \"  )  . setQuery ( JoinQueryBuilders . hasChildQuery (  \" comment \"  ,    matchQuery (  \" message \"  ,     \" fox \"  )  ,    None )  . innerHit ( new   InnerHitBuilder (  )  . addDocValueField (  \" message \"  )  . setHighlightBuilder ( new   HighlightBuilder (  )  . field (  \" message \"  )  )  . setExplain ( true )  . setSize (  1  )  . addScriptField (  \" script \"  ,    new   script . Script ( ScriptType . INLINE ,    MockScriptEngine . NAME ,     \"  5  \"  ,    Collections . emptyMap (  )  )  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "innerHits    =    response . getHits (  )  . getAt (  0  )  . getInnerHits (  )  . get (  \" comment \"  )  ;", "assertThat ( innerHits . getHits (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getHighlightFields (  )  . get (  \" message \"  )  . getFragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > fox <  / em >    eat   quick \"  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getExplanation (  )  . toString (  )  ,    containsString (  \" weight ( message : fox \"  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getFields (  )  . get (  \" message \"  )  . getValue (  )  . toString (  )  ,    equalTo (  \" eat \"  )  )  ;", "assertThat ( innerHits . getAt (  0  )  . getFields (  )  . get (  \" script \"  )  . getValue (  )  . toString (  )  ,    equalTo (  \"  5  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimpleParentChild"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" index 1  \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . addFieldMappings ( ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent _ type \"  ,     \" child _ type \"  )  ,     \" nested _ type \"  ,     \" nested \"  )  )  )  ;", "createIndexRequest (  \" index 1  \"  ,     \" parent _ type \"  ,     \"  1  \"  ,    null ,     \" nested _ type \"  ,    Collections . singletonMap (  \" key \"  ,     \" value \"  )  )  . get (  )  ;", "createIndexRequest (  \" index 1  \"  ,     \" child _ type \"  ,     \"  2  \"  ,     \"  1  \"  )  . get (  )  ;", "refresh (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" index 1  \"  )  . setQuery ( JoinQueryBuilders . hasChildQuery (  \" child _ type \"  ,    matchAllQuery (  )  ,    None )  . ignoreUnmapped ( true )  . innerHit ( new   Builder (  )  . setFrom (  5  0  )  . setSize (  1  0  )  . setName (  \"  _ name \"  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     1  )  ;", "Exception   e    =    expectThrows ( SearchPhaseExecutionException . class ,     (  )     -  >    client (  )  . prepareSearch (  \" index 1  \"  )  . setQuery ( hasChildQuery (  \" child _ type \"  ,    matchAllQuery (  )  ,    ScoreMode . None )  . ignoreUnmapped ( true )  . innerHit ( new   Builder (  )  . setFrom (  1  0  0  )  . setSize (  1  0  )  . setName (  \"  _ name \"  )  )  )  . get (  )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    containsString (  \" the   inner   hit   definition ' s    [  _ name ]  ' s   from    +    size   must   be   less   than   or   equal   to :     [  1  0  0  ]    but   was    [  1  1  0  ]  \"  )  )  ;", "e    =    expectThrows ( SearchPhaseExecutionException . class ,     (  )     -  >    client (  )  . prepareSearch (  \" index 1  \"  )  . setQuery ( hasChildQuery (  \" child _ type \"  ,    matchAllQuery (  )  ,    ScoreMode . None )  . ignoreUnmapped ( true )  . innerHit ( new   Builder (  )  . setFrom (  1  0  )  . setSize (  1  0  0  )  . setName (  \"  _ name \"  )  )  )  . get (  )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    containsString (  \" the   inner   hit   definition ' s    [  _ name ]  ' s   from    +    size   must   be   less   than   or   equal   to :     [  1  0  0  ]    but   was    [  1  1  0  ]  \"  )  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareUpdateSettings (  \" index 1  \"  )  . setSettings ( Collections . singletonMap ( MAX _ INNER _ RESULT _ WINDOW _ SETTING . getKey (  )  ,     1  1  0  )  )  . get (  )  ;", "response    =    client (  )  . prepareSearch (  \" index 1  \"  )  . setQuery ( JoinQueryBuilders . hasChildQuery (  \" child _ type \"  ,    matchAllQuery (  )  ,    None )  . ignoreUnmapped ( true )  . innerHit ( new   Builder (  )  . setFrom (  1  0  0  )  . setSize (  1  0  )  . setName (  \"  _ name \"  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "response    =    client (  )  . prepareSearch (  \" index 1  \"  )  . setQuery ( JoinQueryBuilders . hasChildQuery (  \" child _ type \"  ,    matchAllQuery (  )  ,    None )  . ignoreUnmapped ( true )  . innerHit ( new   Builder (  )  . setFrom (  1  0  )  . setSize (  1  0  0  )  . setName (  \"  _ name \"  )  )  )  . get (  )  ;", "assertNoFailures ( response )  ;", "}", "METHOD_END"], "methodName": ["testTooHighResultWindow"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( prepareCreate (  \" index 1  \"  )  . addMapping (  \" doc \"  ,    ParentChildTestCase . buildParentJoinFieldMappingFromSimplifiedDef (  \" join _ field \"  ,    true ,     \" parent \"  ,     \" child \"  )  )  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareUpdateSettings (  \" index 1  \"  )  . setSettings ( Collections . singletonMap ( MAX _ INNER _ RESULT _ WINDOW _ SETTING . getKey (  )  ,    MAX _ ARRAY _ LENGTH )  )  . get (  )  ;", "List < IndexRequestBuilder >    requests    =    new   ArrayList <  >  (  )  ;", "requests . add ( createIndexRequest (  \" index 1  \"  ,     \" parent \"  ,     \"  1  \"  ,    null )  )  ;", "requests . add ( createIndexRequest (  \" index 1  \"  ,     \" child \"  ,     \"  2  \"  ,     \"  1  \"  ,     \" field \"  ,     \" value 1  \"  )  )  ;", "indexRandom ( true ,    requests )  ;", "QueryBuilder   query    =    JoinQueryBuilders . hasChildQuery (  \" child \"  ,    matchQuery (  \" field \"  ,     \" value 1  \"  )  ,    None )  . innerHit ( new   Builder (  )  . setSize (  (  ( ArrayUtil . MAX _ ARRAY _ LENGTH )     -     1  )  )  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" index 1  \"  )  . setQuery ( query )  . get (  )  ;", "assertNoFailures ( response )  ;", "assertHitCount ( response ,     1  )  ;", "}", "METHOD_END"], "methodName": ["testUseMaxDocInsteadOfSize"], "fileName": "org.elasticsearch.join.query.InnerHitsIT"}, {"methodBody": ["METHOD_START", "{", "return   new   HasChildQueryBuilder ( type ,    query ,    scoreMode )  ;", "}", "METHOD_END"], "methodName": ["hasChildQuery"], "fileName": "org.elasticsearch.join.query.JoinQueryBuilders"}, {"methodBody": ["METHOD_START", "{", "return   new   HasParentQueryBuilder ( type ,    query ,    score )  ;", "}", "METHOD_END"], "methodName": ["hasParentQuery"], "fileName": "org.elasticsearch.join.query.JoinQueryBuilders"}, {"methodBody": ["METHOD_START", "{", "return   new   ParentIdQueryBuilder ( type ,    id )  ;", "}", "METHOD_END"], "methodName": ["parentId"], "fileName": "org.elasticsearch.join.query.JoinQueryBuilders"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    propsMap    =     (  ( Map < String ,    Object >  )     ( map . get (  \" properties \"  )  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( fields . length )  ;    i    +  =     2  )     {", "String   field    =    fields [ i ]  ;", "String   type    =    fields [  ( i    +     1  )  ]  ;", "propsMap . put ( field ,    Collections . singletonMap (  \" type \"  ,    type )  )  ;", "}", "return   map ;", "}", "METHOD_END"], "methodName": ["addFieldMappings"], "fileName": "org.elasticsearch.join.query.ParentChildTestCase"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    fields    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    Field    =    new   HashMap <  >  (  )  ;", "Field . put (  \" type \"  ,     \"  \"  )  ;", "Field . put (  \" eager _ global _ ordinals \"  ,    eagerGlobalOrdinals )  ;", "Map < String ,    Object >    relationMap    =    new   HashMap <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( relations . length )  ;    i    +  =     2  )     {", "String [  ]    children    =    relations [  ( i    +     1  )  ]  . split (  \"  ,  \"  )  ;", "if    (  ( children . length )     >     1  )     {", "relationMap . put ( relations [ i ]  ,    children )  ;", "} else    {", "relationMap . put ( relations [ i ]  ,    children [  0  ]  )  ;", "}", "}", "Field . put (  \" relations \"  ,    relationMap )  ;", "fields . put ( FieldName ,    Field )  ;", "return   Collections . singletonMap (  \" properties \"  ,    fields )  ;", "}", "METHOD_END"], "methodName": ["buildParentJoinFieldMappingFromSimplifiedDef"], "fileName": "org.elasticsearch.join.query.ParentChildTestCase"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    source    =    new   HashMap <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( fields . length )  ;    i    +  =     2  )     {", "source . put (  (  ( String )     ( fields [ i ]  )  )  ,    fields [  ( i    +     1  )  ]  )  ;", "}", "return   createIndexRequest ( index ,    type ,    id ,    pId ,    source )  ;", "}", "METHOD_END"], "methodName": ["createIndexRequest"], "fileName": "org.elasticsearch.join.query.ParentChildTestCase"}, {"methodBody": ["METHOD_START", "{", "String   name    =    type ;", "type    =     \" doc \"  ;", "IndexRequestBuilder   indexRequestBuilder    =    client (  )  . prepareIndex ( index ,    type ,    id )  ;", "Map < String ,    Object >    joinField    =    new   HashMap <  >  (  )  ;", "if    ( pId    !  =    null )     {", "joinField . put (  \" name \"  ,    name )  ;", "joinField . put (  \" p \"  ,    pId )  ;", "indexRequestBuilder . setRouting ( pId )  ;", "} else    {", "joinField . put (  \" name \"  ,    name )  ;", "}", "source . put (  \" join _ field \"  ,    joinField )  ;", "indexRequestBuilder . setSource ( source )  ;", "return   indexRequestBuilder ;", "}", "METHOD_END"], "methodName": ["createIndexRequest"], "fileName": "org.elasticsearch.join.query.ParentChildTestCase"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    source    =    XContentHelper . convertToMap ( jsonXContent ,    Strings . toString ( builder )  ,    false )  ;", "return   createIndexRequest ( index ,    type ,    id ,    pId ,    source )  ;", "}", "METHOD_END"], "methodName": ["createIndexRequest"], "fileName": "org.elasticsearch.join.query.ParentChildTestCase"}, {"methodBody": ["METHOD_START", "{", "float   boost    =    AbstractQueryBuilder . DEFAULT _ BOOST ;", "String   type    =    null ;", "String   id    =    null ;", "String   queryName    =    null ;", "String   currentFieldName    =    null ;", "boolean   ignoreUnmapped    =     . DEFAULT _ IGNORE _ UNMAPPED ;", "XContentParser . Token   token ;", "while    (  ( token    =    parser . nextToken (  )  )     !  =     ( Token . END _ OBJECT )  )     {", "if    ( token    =  =     ( Token . FIELD _ NAME )  )     {", "currentFieldName    =    parser . currentName (  )  ;", "} else", "if    ( token . isValue (  )  )     {", "if    (  . TYPE _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "type    =    parser . text (  )  ;", "} else", "if    (  . ID _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "id    =    parser . text (  )  ;", "} else", "if    (  . IGNORE _ UNMAPPED _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "ignoreUnmapped    =    parser . booleanValue (  )  ;", "} else", "if    ( AbstractQueryBuilder . BOOST _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "boost    =    parser . floatValue (  )  ;", "} else", "if    ( AbstractQueryBuilder . NAME _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "queryName    =    parser . text (  )  ;", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  \"  [ parent _ id ]    query   does   not   support    [  \"     +    currentFieldName )     +     \"  ]  \"  )  )  ;", "}", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  \"  [ parent _ id ]    query   does   not   support    [  \"     +    currentFieldName )     +     \"  ]  \"  )  )  ;", "}", "}", "queryBuilder    =    new    ( type ,    id )  ;", "queryBuilder . queryName ( queryName )  ;", "queryBuilder . boost ( boost )  ;", "queryBuilder . ignoreUnmapped ( ignoreUnmapped )  ;", "return   queryBuilder ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.join.query.ParentIdQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   id ;", "}", "METHOD_END"], "methodName": ["getId"], "fileName": "org.elasticsearch.join.query.ParentIdQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   type ;", "}", "METHOD_END"], "methodName": ["getType"], "fileName": "org.elasticsearch.join.query.ParentIdQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   ignoreUnmapped ;", "}", "METHOD_END"], "methodName": ["ignoreUnmapped"], "fileName": "org.elasticsearch.join.query.ParentIdQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "this . ignoreUnmapped    =    ignoreUnmapped ;", "return   this ;", "}", "METHOD_END"], "methodName": ["ignoreUnmapped"], "fileName": "org.elasticsearch.join.query.ParentIdQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "String   query    =     \"  {  \\ n \"     +     (  (  (  (  (  (  (  \"        \\  \" parent _ id \\  \"     :     {  \\ n \"     +     \"              \\  \" type \\  \"     :     \\  \" child \\  \"  ,  \\ n \"  )     +     \"              \\  \" id \\  \"     :     \\  \"  1  2  3  \\  \"  ,  \\ n \"  )     +     \"              \\  \" ignore _ unmapped \\  \"     :    false ,  \\ n \"  )     +     \"              \\  \" boost \\  \"     :     3  .  0  ,  \\ n \"  )     +     \"              \\  \"  _ name \\  \"     :     \\  \" name \\  \"  \"  )     +     \"        }  \\ n \"  )     +     \"  }  \"  )  ;", "queryBuilder    =     (  (  )     ( parseQuery ( query )  )  )  ;", "checkGeneratedJson ( query ,    queryBuilder )  ;", "assertThat ( queryBuilder . getType (  )  ,    Matchers . equalTo (  \" child \"  )  )  ;", "assertThat ( queryBuilder . getId (  )  ,    Matchers . equalTo (  \"  1  2  3  \"  )  )  ;", "assertThat ( queryBuilder . boost (  )  ,    Matchers . equalTo (  3  .  0 F )  )  ;", "assertThat ( queryBuilder . queryName (  )  ,    Matchers . equalTo (  \" name \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFromJson"], "fileName": "org.elasticsearch.join.query.ParentIdQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "final   ParentIdQueryBuilder   queryBuilder    =    new   ParentIdQueryBuilder (  \" unmapped \"  ,     \" foo \"  )  ;", "queryBuilder . ignoreUnmapped ( true )  ;", "Query   query    =    queryBuilder . toQuery ( createShardContext (  )  )  ;", "assertThat ( query ,    notNullValue (  )  )  ;", "assertThat ( query ,    instanceOf ( MatchNoDocsQuery . class )  )  ;", "final   ParentIdQueryBuilder   failingQueryBuilder    =    new   ParentIdQueryBuilder (  \" unmapped \"  ,     \" foo \"  )  ;", "failingQueryBuilder . ignoreUnmapped ( false )  ;", "QueryShardException   e    =    expectThrows ( QueryShardException . class ,     (  )     -  >    failingQueryBuilder . toQuery ( createShardContext (  )  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \"  [  \"     +     ( ParentIdQueryBuilder . NAME )  )     +     \"  ]    no   relation   found   for   child    [ unmapped ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testIgnoreUnmapped"], "fileName": "org.elasticsearch.join.query.ParentIdQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  3  .  0  ,    exec (  \" double   x    =     1  ;    byte   y    =     2  ;    return   x    +    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  2  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     2  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  5  )  )     +     (  ( byte )     (  1  0  )  )  )  ,    exec (  \" byte   x    =     5  ;    byte   y    =     1  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  1  )  )  )     +     (  ( byte )     (  2  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    byte   z    =     2  ;    return   x + y + z ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  1  )  )  )     +     (  ( byte )     (  2  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    byte   z    =     2  ;    return    ( x + y )  + z ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  2  )  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    byte   z    =     2  ;    return   x +  ( y + z )  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  0  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" byte   x    =     0  ;    byte   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  0  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  0  )  )     +     (  ( byte )     (  0  )  )  )  ,    exec (  \" byte   x    =     0  ;    byte   y    =     0  ;    return   x + y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testByte"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    ( byte )  1  +  ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  2  )  )  )  ,    exec (  \" return    ( byte )  1  +  ( byte )  2  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  5  )  )     +     (  ( byte )     (  1  0  )  )  )  ,    exec (  \" return    ( byte )  5  +  ( byte )  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  1  )  )  )     +     (  ( byte )     (  2  )  )  )  ,    exec (  \" return    ( byte )  1  +  ( byte )  1  +  ( byte )  2  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  1  )  )  )     +     (  ( byte )     (  2  )  )  )  ,    exec (  \" return    (  ( byte )  1  +  ( byte )  1  )  +  ( byte )  2  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  2  )  )  )  )  ,    exec (  \" return    ( byte )  1  +  (  ( byte )  1  +  ( byte )  2  )  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  0  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    ( byte )  0  +  ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  0  )  )  )  ,    exec (  \" return    ( byte )  1  +  ( byte )  0  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  0  )  )     +     (  ( byte )     (  0  )  )  )  ,    exec (  \" return    ( byte )  0  +  ( byte )  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testByteConst"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  2  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     2  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  5  )  )     +     (  ( char )     (  1  0  )  )  )  ,    exec (  \" char   x    =     5  ;    char   y    =     1  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  1  )  )  )     +     (  ( char )     (  2  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     1  ;    char   z    =     2  ;    return   x + y + z ;  \"  )  )  ;", "assertEquals (  (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  1  )  )  )     +     (  ( char )     (  2  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     1  ;    char   z    =     2  ;    return    ( x + y )  + z ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  (  ( char )     (  1  )  )     +     (  ( char )     (  2  )  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     1  ;    char   z    =     2  ;    return   x +  ( y + z )  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  0  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" char   x    =     0  ;    char   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  0  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  0  )  )     +     (  ( char )     (  0  )  )  )  ,    exec (  \" char   x    =     0  ;    char   y    =     0  ;    return   x + y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testChar"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" return    ( char )  1  +  ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  2  )  )  )  ,    exec (  \" return    ( char )  1  +  ( char )  2  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  5  )  )     +     (  ( char )     (  1  0  )  )  )  ,    exec (  \" return    ( char )  5  +  ( char )  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  1  )  )  )     +     (  ( char )     (  2  )  )  )  ,    exec (  \" return    ( char )  1  +  ( char )  1  +  ( char )  2  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  1  )  )  )     +     (  ( char )     (  2  )  )  )  ,    exec (  \" return    (  ( char )  1  +  ( char )  1  )  +  ( char )  2  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  (  ( char )     (  1  )  )     +     (  ( char )     (  2  )  )  )  )  ,    exec (  \" return    ( char )  1  +  (  ( char )  1  +  ( char )  2  )  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  0  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" return    ( char )  0  +  ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  0  )  )  )  ,    exec (  \" return    ( char )  1  +  ( char )  0  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  0  )  )     +     (  ( char )     (  0  )  )  )  ,    exec (  \" return    ( char )  0  +  ( char )  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCharConst"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" byte   x    =     5  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  5  )  )  ,    exec (  \" byte   x    =     5  ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" short   x    =     5  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  5  )  )  ,    exec (  \" short   x    =     5  ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" char   x    =     5  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  5  )  )  ,    exec (  \" char   x    =     1  0  ;    x    +  =     -  5  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" int   x    =     5  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  )  ,    exec (  \" int   x    =     5  ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" long   x    =     5  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5 L )  ,    exec (  \" long   x    =     5  ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0 F ,    exec (  \" float   x    =     5 f ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0 F )  ,    exec (  \" float   x    =     5 f ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0  ,    exec (  \" double   x    =     5  .  0  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0  )  ,    exec (  \" double   x    =     5  .  0  ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignment"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" def   x    =     ( byte )  5  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  5  )  )  ,    exec (  \" def   x    =     ( byte )  5  ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" def   x    =     ( short )  5  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  5  )  )  ,    exec (  \" def   x    =     ( short )  5  ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" def   x    =     ( char )  5  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  5  )  )  ,    exec (  \" def   x    =     ( char )  1  0  ;    x    +  =     -  5  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" def   x    =     5  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  )  ,    exec (  \" def   x    =     5  ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" def   x    =     5 L ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5 L )  ,    exec (  \" def   x    =     5 L ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0 F ,    exec (  \" def   x    =     5 f ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0 F )  ,    exec (  \" def   x    =     5 f ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0  ,    exec (  \" def   x    =     5  .  0  ;    x    +  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0  )  ,    exec (  \" def   x    =     5  .  0  ;    x    +  =     -  1  0  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefCompoundAssignmentLHS"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" byte   x    =     5  ;    def   y    =     1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  5  )  )  ,    exec (  \" byte   x    =     5  ;    def   y    =     -  1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" short   x    =     5  ;    def   y    =     1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  5  )  )  ,    exec (  \" short   x    =     5  ;    def   y    =     -  1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" char   x    =     5  ;    def   y    =     1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  5  )  )  ,    exec (  \" char   x    =     1  0  ;    def   y    =     -  5  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" int   x    =     5  ;    def   y    =     1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  )  ,    exec (  \" int   x    =     5  ;    def   y    =     -  1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" long   x    =     5  ;    def   y    =     1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5 L )  ,    exec (  \" long   x    =     5  ;    def   y    =     -  1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0 F ,    exec (  \" float   x    =     5 f ;    def   y    =     1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0 F )  ,    exec (  \" float   x    =     5 f ;    def   y    =     -  1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0  ,    exec (  \" double   x    =     5  .  0  ;    def   y    =     1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0  )  ,    exec (  \" double   x    =     5  .  0  ;    def   y    =     -  1  0  ;    x    +  =    y ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefCompoundAssignmentRHS"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( NullPointerException . class ,     (  )     -  >     {", "exec (  \" def   x    =    null ;    int   y    =     1  ;    return   x    +    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( NullPointerException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1  ;    def   y    =    null ;    return   x    +    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( NullPointerException . class ,     (  )     -  >     {", "exec (  \" def   x    =    null ;    def   y    =     1  ;    return   x    +    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDefNulls"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedLHS"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    byte   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    byte   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    byte   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    byte   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    byte   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    byte   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    byte   y    =     ( byte )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    short   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    short   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    short   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    short   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    short   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    short   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    short   y    =     ( short )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    char   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    char   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    char   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    char   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    char   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    char   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    char   y    =     ( char )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    int   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    int   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    int   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    int   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    int   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    int   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    int   y    =     ( int )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( byte )  1  ;    long   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( short )  1  ;    long   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( char )  1  ;    long   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( int )  1  ;    long   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    long   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    long   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    long   y    =     ( long )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( byte )  1  ;    float   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( short )  1  ;    float   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( char )  1  ;    float   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( int )  1  ;    float   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( long )  1  ;    float   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    float   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    float   y    =     ( float )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( byte )  1  ;    double   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( short )  1  ;    double   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( char )  1  ;    double   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( int )  1  ;    double   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( long )  1  ;    double   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( float )  1  ;    double   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    double   y    =     ( double )  1  ;    return   x    +    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedRHS"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     +     1  .  0  )  ,    exec (  \" double   x    =     1  .  0  ;    double   y    =     1  .  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     2  .  0  )  ,    exec (  \" double   x    =     1  .  0  ;    double   y    =     2  .  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  5  .  0     +     1  0  .  0  )  ,    exec (  \" double   x    =     5  .  0  ;    double   y    =     1  0  .  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     +     1  .  0  )     +     2  .  0  )  ,    exec (  \" double   x    =     1  .  0  ;    double   y    =     1  .  0  ;    double   z    =     2  .  0  ;    return   x + y + z ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     +     1  .  0  )     +     2  .  0  )  ,    exec (  \" double   x    =     1  .  0  ;    double   y    =     1  .  0  ;    double   z    =     2  .  0  ;    return    ( x + y )  + z ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     (  1  .  0     +     2  .  0  )  )  ,    exec (  \" double   x    =     1  .  0  ;    double   y    =     1  .  0  ;    double   z    =     2  .  0  ;    return   x +  ( y + z )  ;  \"  )  )  ;", "assertEquals (  (  0  .  0     +     1  .  0  )  ,    exec (  \" double   x    =     0  .  0  ;    double   y    =     1  .  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     0  .  0  )  ,    exec (  \" double   x    =     1  .  0  ;    double   y    =     0  .  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  0  .  0     +     0  .  0  )  ,    exec (  \" double   x    =     0  .  0  ;    double   y    =     0  .  0  ;    return   x + y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDouble"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     +     1  .  0  )  ,    exec (  \" return    1  .  0  +  1  .  0  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     2  .  0  )  ,    exec (  \" return    1  .  0  +  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  5  .  0     +     1  0  .  0  )  ,    exec (  \" return    5  .  0  +  1  0  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     +     1  .  0  )     +     2  .  0  )  ,    exec (  \" return    1  .  0  +  1  .  0  +  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     +     1  .  0  )     +     2  .  0  )  ,    exec (  \" return    (  1  .  0  +  1  .  0  )  +  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     (  1  .  0     +     2  .  0  )  )  ,    exec (  \" return    1  .  0  +  (  1  .  0  +  2  .  0  )  ;  \"  )  )  ;", "assertEquals (  (  0  .  0     +     1  .  0  )  ,    exec (  \" return    0  .  0  +  1  .  0  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     0  .  0  )  ,    exec (  \" return    1  .  0  +  0  .  0  ;  \"  )  )  ;", "assertEquals (  (  0  .  0     +     0  .  0  )  ,    exec (  \" return    0  .  0  +  0  .  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleConst"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    +     1  .  0 F )  ,    exec (  \" float   x    =     1 F ;    float   y    =     1 F ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     2  .  0 F )  ,    exec (  \" float   x    =     1 F ;    float   y    =     2 F ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    +     1  0  .  0 F )  ,    exec (  \" float   x    =     5 F ;    float   y    =     1  0 F ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    +     1  .  0 F )     +     2  .  0 F )  ,    exec (  \" float   x    =     1 F ;    float   y    =     1 F ;    float   z    =     2 F ;    return   x + y + z ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    +     1  .  0 F )     +     2  .  0 F )  ,    exec (  \" float   x    =     1 F ;    float   y    =     1 F ;    float   z    =     2 F ;    return    ( x + y )  + z ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    +     1  .  0 F )     +     2  .  0 F )  ,    exec (  \" float   x    =     1 F ;    float   y    =     1 F ;    float   z    =     2 F ;    return   x +  ( y + z )  ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    +     1  .  0 F )  ,    exec (  \" float   x    =     0 F ;    float   y    =     1 F ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     0  .  0 F )  ,    exec (  \" float   x    =     1 F ;    float   y    =     0 F ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    +     0  .  0 F )  ,    exec (  \" float   x    =     0 F ;    float   y    =     0 F ;    return   x + y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloat"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    +     1  .  0 F )  ,    exec (  \" return    1 F +  1 F ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     2  .  0 F )  ,    exec (  \" return    1 F +  2 F ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    +     1  0  .  0 F )  ,    exec (  \" return    5 F +  1  0 F ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    +     1  .  0 F )     +     2  .  0 F )  ,    exec (  \" return    1 F +  1 F +  2 F ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    +     1  .  0 F )     +     2  .  0 F )  ,    exec (  \" return    (  1 F +  1 F )  +  2 F ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     (  1  .  0 F    +     2  .  0 F )  )  ,    exec (  \" return    1 F +  (  1 F +  2 F )  ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    +     1  .  0 F )  ,    exec (  \" return    0 F +  1 F ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     0  .  0 F )  ,    exec (  \" return    1 F +  0 F ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    +     0  .  0 F )  ,    exec (  \" return    0 F +  0 F ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloatConst"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     +     1  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1     +     2  )  ,    exec (  \" int   x    =     1  ;    int   y    =     2  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  5     +     1  0  )  ,    exec (  \" int   x    =     5  ;    int   y    =     1  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  1     +     1  )     +     2  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    int   z    =     2  ;    return   x + y + z ;  \"  )  )  ;", "assertEquals (  (  (  1     +     1  )     +     2  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    int   z    =     2  ;    return    ( x + y )  + z ;  \"  )  )  ;", "assertEquals (  (  1     +     (  1     +     2  )  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    int   z    =     2  ;    return   x +  ( y + z )  ;  \"  )  )  ;", "assertEquals (  (  0     +     1  )  ,    exec (  \" int   x    =     0  ;    int   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1     +     0  )  ,    exec (  \" int   x    =     1  ;    int   y    =     0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  0     +     0  )  ,    exec (  \" int   x    =     0  ;    int   y    =     0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  0     +     0  )  ,    exec (  \" int   x    =     0  ;    int   y    =     0  ;    return   x + y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInt"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     +     1  )  ,    exec (  \" return    1  +  1  ;  \"  )  )  ;", "assertEquals (  (  1     +     2  )  ,    exec (  \" return    1  +  2  ;  \"  )  )  ;", "assertEquals (  (  5     +     1  0  )  ,    exec (  \" return    5  +  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  1     +     1  )     +     2  )  ,    exec (  \" return    1  +  1  +  2  ;  \"  )  )  ;", "assertEquals (  (  (  1     +     1  )     +     2  )  ,    exec (  \" return    (  1  +  1  )  +  2  ;  \"  )  )  ;", "assertEquals (  (  1     +     (  1     +     2  )  )  ,    exec (  \" return    1  +  (  1  +  2  )  ;  \"  )  )  ;", "assertEquals (  (  0     +     1  )  ,    exec (  \" return    0  +  1  ;  \"  )  )  ;", "assertEquals (  (  1     +     0  )  ,    exec (  \" return    1  +  0  ;  \"  )  )  ;", "assertEquals (  (  0     +     0  )  ,    exec (  \" return    0  +  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIntConst"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    +     1 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1 L    +     2 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     2  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  5 L    +     1  0 L )  ,    exec (  \" long   x    =     5  ;    long   y    =     1  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  1 L    +     1 L )     +     2 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    long   z    =     2  ;    return   x + y + z ;  \"  )  )  ;", "assertEquals (  (  (  1 L    +     1 L )     +     2 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    long   z    =     2  ;    return    ( x + y )  + z ;  \"  )  )  ;", "assertEquals (  (  1 L    +     (  1 L    +     2 L )  )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    long   z    =     2  ;    return   x +  ( y + z )  ;  \"  )  )  ;", "assertEquals (  (  0 L    +     1 L )  ,    exec (  \" long   x    =     0  ;    long   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1 L    +     0 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  0 L    +     0 L )  ,    exec (  \" long   x    =     0  ;    long   y    =     0  ;    return   x + y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLong"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    +     1 L )  ,    exec (  \" return    1 L +  1 L ;  \"  )  )  ;", "assertEquals (  (  1 L    +     2 L )  ,    exec (  \" return    1 L +  2 L ;  \"  )  )  ;", "assertEquals (  (  5 L    +     1  0 L )  ,    exec (  \" return    5 L +  1  0 L ;  \"  )  )  ;", "assertEquals (  (  (  1 L    +     1 L )     +     2 L )  ,    exec (  \" return    1 L +  1 L +  2 L ;  \"  )  )  ;", "assertEquals (  (  (  1 L    +     1 L )     +     2 L )  ,    exec (  \" return    (  1 L +  1 L )  +  2 L ;  \"  )  )  ;", "assertEquals (  (  1 L    +     (  1 L    +     2 L )  )  ,    exec (  \" return    1 L +  (  1 L +  2 L )  ;  \"  )  )  ;", "assertEquals (  (  0 L    +     1 L )  ,    exec (  \" return    0 L +  1 L ;  \"  )  )  ;", "assertEquals (  (  1 L    +     0 L )  ,    exec (  \" return    1 L +  0 L ;  \"  )  )  ;", "assertEquals (  (  0 L    +     0 L )  ,    exec (  \" return    0 L +  0 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongConst"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  2  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     2  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  5  )  )     +     (  ( short )     (  1  0  )  )  )  ,    exec (  \" short   x    =     5  ;    short   y    =     1  0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  1  )  )  )     +     (  ( short )     (  2  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     1  ;    short   z    =     2  ;    return   x + y + z ;  \"  )  )  ;", "assertEquals (  (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  1  )  )  )     +     (  ( short )     (  2  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     1  ;    short   z    =     2  ;    return    ( x + y )  + z ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  (  ( short )     (  1  )  )     +     (  ( short )     (  2  )  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     1  ;    short   z    =     2  ;    return   x +  ( y + z )  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  0  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" short   x    =     0  ;    short   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  0  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     0  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  0  )  )     +     (  ( short )     (  0  )  )  )  ,    exec (  \" short   x    =     0  ;    short   y    =     0  ;    return   x + y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testShort"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" return    ( short )  1  +  ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  2  )  )  )  ,    exec (  \" return    ( short )  1  +  ( short )  2  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  5  )  )     +     (  ( short )     (  1  0  )  )  )  ,    exec (  \" return    ( short )  5  +  ( short )  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  1  )  )  )     +     (  ( short )     (  2  )  )  )  ,    exec (  \" return    ( short )  1  +  ( short )  1  +  ( short )  2  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  1  )  )  )     +     (  ( short )     (  2  )  )  )  ,    exec (  \" return    (  ( short )  1  +  ( short )  1  )  +  ( short )  2  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  (  ( short )     (  1  )  )     +     (  ( short )     (  2  )  )  )  )  ,    exec (  \" return    ( short )  1  +  (  ( short )  1  +  ( short )  2  )  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  0  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" return    ( short )  0  +  ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  0  )  )  )  ,    exec (  \" return    ( short )  1  +  ( short )  0  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  0  )  )     +     (  ( short )     (  0  )  )  )  ,    exec (  \" return    ( short )  0  +  ( short )  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testShortConst"], "fileName": "org.elasticsearch.painless.AdditionTests"}, {"methodBody": ["METHOD_START", "{", "Class <  ?  >    fsort    =    cast . from ;", "Class <  ?  >    tsort    =    cast . to ;", "if    ( fsort    =  =    tsort )     {", "return   constant ;", "} else", "if    (  ( fsort    =  =     ( String . class )  )     &  &     ( tsort    =  =     ( char . class )  )  )     {", "return   Utility . StringTochar (  (  ( String )     ( constant )  )  )  ;", "} else", "if    (  ( fsort    =  =     ( char . class )  )     &  &     ( tsort    =  =     ( String . class )  )  )     {", "return   Utility . charToString (  (  ( char )     ( constant )  )  )  ;", "} else", "if    (  (  (  ( fsort . isPrimitive (  )  )     &  &     ( fsort    !  =     ( boolean . class )  )  )     &  &     ( tsort . isPrimitive (  )  )  )     &  &     ( tsort    !  =     ( boolean . class )  )  )     {", "Number   number ;", "if    ( fsort    =  =     ( char . class )  )     {", "number    =     (  ( int )     (  ( char )     ( constant )  )  )  ;", "} else    {", "number    =     (  ( Number )     ( constant )  )  ;", "}", "if    ( tsort    =  =     ( byte . class )  )", "return   number . byteValue (  )  ;", "else", "if    ( tsort    =  =     ( short . class )  )", "return   number . shortValue (  )  ;", "else", "if    ( tsort    =  =     ( char . class )  )", "return    (  ( char )     ( number . intValue (  )  )  )  ;", "else", "if    ( tsort    =  =     ( int . class )  )", "return   number . intValue (  )  ;", "else", "if    ( tsort    =  =     ( long . class )  )", "return   number . longValue (  )  ;", "else", "if    ( tsort    =  =     ( float . class )  )", "return   number . floatValue (  )  ;", "else", "if    ( tsort    =  =     ( double . class )  )", "return   number . doubleValue (  )  ;", "else    {", "throw   location . createError ( new   IllegalStateException (  (  (  (  (  (  \" Cannot   cast   from    \"     +     \"  [  \"  )     +     ( cast . from . getCanonicalName (  )  )  )     +     \"  ]    to    [  \"  )     +     ( cast . to . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "} else    {", "throw   location . createError ( new   IllegalStateException (  (  (  (  (  (  \" Cannot   cast   from    \"     +     \"  [  \"  )     +     ( cast . from . getCanonicalName (  )  )  )     +     \"  ]    to    [  \"  )     +     ( cast . to . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["constCast"], "fileName": "org.elasticsearch.painless.AnalyzerCaster"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( actual )  ;", "Objects . requireNonNull ( expected )  ;", "if    ( actual    =  =    expected )     {", "return   null ;", "}", "if    ( actual    =  =     ( Definition . def . class )  )     {", "if    ( expected    =  =     ( boolean . class )  )     {", "return   Definition .  . unboxTo ( Definition . def . class ,    Boolean . class ,    explicit ,    boolean . class )  ;", "} else", "if    ( expected    =  =     ( byte . class )  )     {", "return   Definition .  . unboxTo ( Definition . def . class ,    Byte . class ,    explicit ,    byte . class )  ;", "} else", "if    ( expected    =  =     ( short . class )  )     {", "return   Definition .  . unboxTo ( Definition . def . class ,    Short . class ,    explicit ,    short . class )  ;", "} else", "if    ( expected    =  =     ( char . class )  )     {", "return   Definition .  . unboxTo ( Definition . def . class ,    Character . class ,    explicit ,    char . class )  ;", "} else", "if    ( expected    =  =     ( int . class )  )     {", "return   Definition .  . unboxTo ( Definition . def . class ,    Integer . class ,    explicit ,    int . class )  ;", "} else", "if    ( expected    =  =     ( long . class )  )     {", "return   Definition .  . unboxTo ( Definition . def . class ,    Long . class ,    explicit ,    long . class )  ;", "} else", "if    ( expected    =  =     ( float . class )  )     {", "return   Definition .  . unboxTo ( Definition . def . class ,    Float . class ,    explicit ,    float . class )  ;", "} else", "if    ( expected    =  =     ( double . class )  )     {", "return   Definition .  . unboxTo ( Definition . def . class ,    Double . class ,    explicit ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( Object . class )  )     {", "if    (  (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Object . class ,    Byte . class ,    true ,    byte . class )  ;", "} else", "if    (  (  ( expected    =  =     ( short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Object . class ,    Short . class ,    true ,    short . class )  ;", "} else", "if    (  (  ( expected    =  =     ( char . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Object . class ,    Character . class ,    true ,    char . class )  ;", "} else", "if    (  (  ( expected    =  =     ( int . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Object . class ,    Integer . class ,    true ,    int . class )  ;", "} else", "if    (  (  ( expected    =  =     ( long . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Object . class ,    Long . class ,    true ,    long . class )  ;", "} else", "if    (  (  ( expected    =  =     ( float . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Object . class ,    Float . class ,    true ,    float . class )  ;", "} else", "if    (  (  ( expected    =  =     ( double . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Object . class ,    Double . class ,    true ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( Number . class )  )     {", "if    (  (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Number . class ,    Byte . class ,    true ,    byte . class )  ;", "} else", "if    (  (  ( expected    =  =     ( short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Number . class ,    Short . class ,    true ,    short . class )  ;", "} else", "if    (  (  ( expected    =  =     ( char . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Number . class ,    Character . class ,    true ,    char . class )  ;", "} else", "if    (  (  ( expected    =  =     ( int . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Number . class ,    Integer . class ,    true ,    int . class )  ;", "} else", "if    (  (  ( expected    =  =     ( long . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Number . class ,    Long . class ,    true ,    long . class )  ;", "} else", "if    (  (  ( expected    =  =     ( float . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Number . class ,    Float . class ,    true ,    float . class )  ;", "} else", "if    (  (  ( expected    =  =     ( double . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxTo ( Number . class ,    Double . class ,    true ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( String . class )  )     {", "if    (  ( expected    =  =     ( char . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( String . class ,    char . class ,    true )  ;", "}", "} else", "if    ( actual    =  =     ( boolean . class )  )     {", "if    ( expected    =  =     ( Definition . def . class )  )     {", "return   Definition .  . boxFrom ( Boolean . class ,    Definition . def . class ,    explicit ,    boolean . class )  ;", "} else", "if    (  ( expected    =  =     ( Object . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Boolean . class ,    Object . class ,    explicit ,    boolean . class )  ;", "} else", "if    (  ( expected    =  =     ( Boolean . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( boolean . class ,    boolean . class ,    explicit ,    boolean . class )  ;", "}", "} else", "if    ( actual    =  =     ( byte . class )  )     {", "if    ( expected    =  =     ( Definition . def . class )  )     {", "return   Definition .  . boxFrom ( Byte . class ,    Definition . def . class ,    explicit ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( Object . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Byte . class ,    Object . class ,    explicit ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( Number . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Byte . class ,    Number . class ,    explicit ,    byte . class )  ;", "} else", "if    ( expected    =  =     ( short . class )  )     {", "return   Definition .  . standard ( byte . class ,    short . class ,    explicit )  ;", "} else", "if    (  ( expected    =  =     ( char . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( byte . class ,    char . class ,    true )  ;", "} else", "if    ( expected    =  =     ( int . class )  )     {", "return   Definition .  . standard ( byte . class ,    int . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( long . class )  )     {", "return   Definition .  . standard ( byte . class ,    long . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( float . class )  )     {", "return   Definition .  . standard ( byte . class ,    float . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( double . class )  )     {", "return   Definition .  . standard ( byte . class ,    double . class ,    explicit )  ;", "} else", "if    (  ( expected    =  =     ( Byte . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( byte . class ,    byte . class ,    explicit ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( Short . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( byte . class ,    short . class ,    explicit ,    short . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Character . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( byte . class ,    char . class ,    true ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( Integer . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( byte . class ,    int . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( Long . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( byte . class ,    long . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( Float . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( byte . class ,    float . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( Double . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( byte . class ,    double . class ,    explicit ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( short . class )  )     {", "if    ( expected    =  =     ( Definition . def . class )  )     {", "return   Definition .  . boxFrom ( Short . class ,    Definition . def . class ,    explicit ,    short . class )  ;", "} else", "if    (  ( expected    =  =     ( Object . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Short . class ,    Object . class ,    explicit ,    short . class )  ;", "} else", "if    (  ( expected    =  =     ( Number . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Short . class ,    Number . class ,    explicit ,    short . class )  ;", "} else", "if    (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( short . class ,    byte . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( char . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( short . class ,    char . class ,    true )  ;", "} else", "if    ( expected    =  =     ( int . class )  )     {", "return   Definition .  . standard ( short . class ,    int . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( long . class )  )     {", "return   Definition .  . standard ( short . class ,    long . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( float . class )  )     {", "return   Definition .  . standard ( short . class ,    float . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( double . class )  )     {", "return   Definition .  . standard ( short . class ,    double . class ,    explicit )  ;", "} else", "if    (  (  ( expected    =  =     ( Byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( short . class ,    byte . class ,    true ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( Short . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( short . class ,    short . class ,    explicit ,    short . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Character . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( short . class ,    char . class ,    true ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( Integer . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( short . class ,    int . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( Long . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( short . class ,    long . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( Float . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( short . class ,    float . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( Double . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( short . class ,    double . class ,    explicit ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( char . class )  )     {", "if    ( expected    =  =     ( Definition . def . class )  )     {", "return   Definition .  . boxFrom ( Character . class ,    Definition . def . class ,    explicit ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( Object . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Character . class ,    Object . class ,    explicit ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( Number . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Character . class ,    Number . class ,    explicit ,    char . class )  ;", "} else", "if    ( expected    =  =     ( String . class )  )     {", "return   Definition .  . standard ( char . class ,    String . class ,    explicit )  ;", "} else", "if    (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( char . class ,    byte . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( short . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( char . class ,    short . class ,    true )  ;", "} else", "if    ( expected    =  =     ( int . class )  )     {", "return   Definition .  . standard ( char . class ,    int . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( long . class )  )     {", "return   Definition .  . standard ( char . class ,    long . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( float . class )  )     {", "return   Definition .  . standard ( char . class ,    float . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( double . class )  )     {", "return   Definition .  . standard ( char . class ,    double . class ,    explicit )  ;", "} else", "if    (  (  ( expected    =  =     ( Byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( char . class ,    byte . class ,    true ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( Short . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( char . class ,    short . class ,    explicit ,    short . class )  ;", "} else", "if    (  ( expected    =  =     ( Character . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( char . class ,    char . class ,    true ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( Integer . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( char . class ,    int . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( Long . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( char . class ,    long . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( Float . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( char . class ,    float . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( Double . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( char . class ,    double . class ,    explicit ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( int . class )  )     {", "if    ( expected    =  =     ( Definition . def . class )  )     {", "return   Definition .  . boxFrom ( Integer . class ,    Definition . def . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( Object . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Integer . class ,    Object . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( Number . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Integer . class ,    Number . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( int . class ,    byte . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( char . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( int . class ,    char . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( short . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( int . class ,    short . class ,    true )  ;", "} else", "if    ( expected    =  =     ( long . class )  )     {", "return   Definition .  . standard ( int . class ,    long . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( float . class )  )     {", "return   Definition .  . standard ( int . class ,    float . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( double . class )  )     {", "return   Definition .  . standard ( int . class ,    double . class ,    explicit )  ;", "} else", "if    (  (  ( expected    =  =     ( Byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( int . class ,    byte . class ,    true ,    byte . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( int . class ,    short . class ,    true ,    short . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Character . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( int . class ,    char . class ,    true ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( Integer . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( int . class ,    int . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( Long . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( int . class ,    long . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( Float . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( int . class ,    float . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( Double . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( int . class ,    double . class ,    explicit ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( long . class )  )     {", "if    ( expected    =  =     ( Definition . def . class )  )     {", "return   Definition .  . boxFrom ( Long . class ,    Definition . def . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( Object . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Long . class ,    Object . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( Number . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Long . class ,    Number . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( long . class ,    byte . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( char . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( long . class ,    char . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( short . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( long . class ,    short . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( int . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( long . class ,    int . class ,    true )  ;", "} else", "if    ( expected    =  =     ( float . class )  )     {", "return   Definition .  . standard ( long . class ,    float . class ,    explicit )  ;", "} else", "if    ( expected    =  =     ( double . class )  )     {", "return   Definition .  . standard ( long . class ,    double . class ,    explicit )  ;", "} else", "if    (  (  ( expected    =  =     ( Byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( long . class ,    byte . class ,    true ,    byte . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( long . class ,    short . class ,    true ,    short . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Character . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( long . class ,    char . class ,    true ,    char . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Integer . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( long . class ,    int . class ,    true ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( Long . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( long . class ,    long . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( Float . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( long . class ,    float . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( Double . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( long . class ,    double . class ,    explicit ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( float . class )  )     {", "if    ( expected    =  =     ( Definition . def . class )  )     {", "return   Definition .  . boxFrom ( Float . class ,    Definition . def . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( Object . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Float . class ,    Object . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( Number . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Float . class ,    Number . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( float . class ,    byte . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( char . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( float . class ,    char . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( short . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( float . class ,    short . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( int . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( float . class ,    int . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( long . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( float . class ,    long . class ,    true )  ;", "} else", "if    ( expected    =  =     ( double . class )  )     {", "return   Definition .  . standard ( float . class ,    double . class ,    explicit )  ;", "} else", "if    (  (  ( expected    =  =     ( Byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( float . class ,    byte . class ,    true ,    byte . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( float . class ,    short . class ,    true ,    short . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Character . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( float . class ,    char . class ,    true ,    char . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Integer . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( float . class ,    int . class ,    true ,    int . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Long . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( float . class ,    long . class ,    true ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( Float . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( float . class ,    float . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( Double . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( float . class ,    double . class ,    explicit ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( double . class )  )     {", "if    ( expected    =  =     ( Definition . def . class )  )     {", "return   Definition .  . boxFrom ( Double . class ,    Definition . def . class ,    explicit ,    double . class )  ;", "} else", "if    (  ( expected    =  =     ( Object . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Double . class ,    Object . class ,    explicit ,    double . class )  ;", "} else", "if    (  ( expected    =  =     ( Number . class )  )     &  &    internal )     {", "return   Definition .  . boxFrom ( Double . class ,    Number . class ,    explicit ,    double . class )  ;", "} else", "if    (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( double . class ,    byte . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( char . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( double . class ,    char . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( short . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( double . class ,    short . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( int . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( double . class ,    int . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( long . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( double . class ,    long . class ,    true )  ;", "} else", "if    (  ( expected    =  =     ( float . class )  )     &  &    explicit )     {", "return   Definition .  . standard ( double . class ,    float . class ,    true )  ;", "} else", "if    (  (  ( expected    =  =     ( Byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( double . class ,    byte . class ,    true ,    byte . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( double . class ,    short . class ,    true ,    short . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Character . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( double . class ,    char . class ,    true ,    char . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Integer . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( double . class ,    int . class ,    true ,    int . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Long . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( double . class ,    long . class ,    true ,    long . class )  ;", "} else", "if    (  (  ( expected    =  =     ( Float . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . boxTo ( double . class ,    float . class ,    true ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( Double . class )  )     &  &    internal )     {", "return   Definition .  . boxTo ( double . class ,    double . class ,    explicit ,    double . class )  ;", "}", "} else", "if    ( actual    =  =     ( Boolean . class )  )     {", "if    (  ( expected    =  =     ( boolean . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( boolean . class ,    boolean . class ,    explicit ,    boolean . class )  ;", "}", "} else", "if    ( actual    =  =     ( Byte . class )  )     {", "if    (  ( expected    =  =     ( byte . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( byte . class ,    byte . class ,    explicit ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( short . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( byte . class ,    short . class ,    explicit ,    byte . class )  ;", "} else", "if    (  (  ( expected    =  =     ( char . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( byte . class ,    char . class ,    true ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( int . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( byte . class ,    int . class ,    explicit ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( long . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( byte . class ,    long . class ,    explicit ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( float . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( byte . class ,    float . class ,    explicit ,    byte . class )  ;", "} else", "if    (  ( expected    =  =     ( double . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( byte . class ,    double . class ,    explicit ,    byte . class )  ;", "}", "} else", "if    ( actual    =  =     ( Short . class )  )     {", "if    (  (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( short . class ,    byte . class ,    true ,    short . class )  ;", "} else", "if    (  ( expected    =  =     ( short . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( short . class ,    short . class ,    explicit ,    short . class )  ;", "} else", "if    (  (  ( expected    =  =     ( char . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( short . class ,    char . class ,    true ,    short . class )  ;", "} else", "if    (  ( expected    =  =     ( int . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( short . class ,    int . class ,    explicit ,    short . class )  ;", "} else", "if    (  ( expected    =  =     ( long . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( short . class ,    long . class ,    explicit ,    short . class )  ;", "} else", "if    (  ( expected    =  =     ( float . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( short . class ,    float . class ,    explicit ,    short . class )  ;", "} else", "if    (  ( expected    =  =     ( double . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( short . class ,    double . class ,    explicit ,    short . class )  ;", "}", "} else", "if    ( actual    =  =     ( Character . class )  )     {", "if    (  (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( char . class ,    byte . class ,    true ,    char . class )  ;", "} else", "if    (  (  ( expected    =  =     ( short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( char . class ,    short . class ,    true ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( char . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( char . class ,    char . class ,    explicit ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( int . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( char . class ,    int . class ,    explicit ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( long . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( char . class ,    long . class ,    explicit ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( float . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( char . class ,    float . class ,    explicit ,    char . class )  ;", "} else", "if    (  ( expected    =  =     ( double . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( char . class ,    double . class ,    explicit ,    char . class )  ;", "}", "} else", "if    ( actual    =  =     ( Integer . class )  )     {", "if    (  (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( int . class ,    byte . class ,    true ,    int . class )  ;", "} else", "if    (  (  ( expected    =  =     ( short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( int . class ,    short . class ,    true ,    int . class )  ;", "} else", "if    (  (  ( expected    =  =     ( char . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( int . class ,    char . class ,    true ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( int . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( int . class ,    int . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( long . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( int . class ,    long . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( float . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( int . class ,    float . class ,    explicit ,    int . class )  ;", "} else", "if    (  ( expected    =  =     ( double . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( int . class ,    double . class ,    explicit ,    int . class )  ;", "}", "} else", "if    ( actual    =  =     ( Long . class )  )     {", "if    (  (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( long . class ,    byte . class ,    true ,    long . class )  ;", "} else", "if    (  (  ( expected    =  =     ( short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( long . class ,    short . class ,    true ,    long . class )  ;", "} else", "if    (  (  ( expected    =  =     ( char . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( long . class ,    char . class ,    true ,    long . class )  ;", "} else", "if    (  (  ( expected    =  =     ( int . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( long . class ,    int . class ,    true ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( long . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( long . class ,    long . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( float . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( long . class ,    float . class ,    explicit ,    long . class )  ;", "} else", "if    (  ( expected    =  =     ( double . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( long . class ,    double . class ,    explicit ,    long . class )  ;", "}", "} else", "if    ( actual    =  =     ( Float . class )  )     {", "if    (  (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( float . class ,    byte . class ,    true ,    float . class )  ;", "} else", "if    (  (  ( expected    =  =     ( short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( float . class ,    short . class ,    true ,    float . class )  ;", "} else", "if    (  (  ( expected    =  =     ( char . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( float . class ,    char . class ,    true ,    float . class )  ;", "} else", "if    (  (  ( expected    =  =     ( int . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( float . class ,    int . class ,    true ,    float . class )  ;", "} else", "if    (  (  ( expected    =  =     ( long . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( float . class ,    long . class ,    true ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( float . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( float . class ,    float . class ,    explicit ,    float . class )  ;", "} else", "if    (  ( expected    =  =     ( double . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( float . class ,    double . class ,    explicit ,    float . class )  ;", "}", "} else", "if    ( actual    =  =     ( Double . class )  )     {", "if    (  (  ( expected    =  =     ( byte . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( double . class ,    byte . class ,    true ,    double . class )  ;", "} else", "if    (  (  ( expected    =  =     ( short . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( double . class ,    short . class ,    true ,    double . class )  ;", "} else", "if    (  (  ( expected    =  =     ( char . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( double . class ,    char . class ,    true ,    double . class )  ;", "} else", "if    (  (  ( expected    =  =     ( int . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( double . class ,    int . class ,    true ,    double . class )  ;", "} else", "if    (  (  ( expected    =  =     ( long . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( double . class ,    long . class ,    true ,    double . class )  ;", "} else", "if    (  (  ( expected    =  =     ( float . class )  )     &  &    explicit )     &  &    internal )     {", "return   Definition .  . unboxFrom ( double . class ,    float . class ,    true ,    double . class )  ;", "} else", "if    (  ( expected    =  =     ( double . class )  )     &  &    internal )     {", "return   Definition .  . unboxFrom ( double . class ,    double . class ,    explicit ,    double . class )  ;", "}", "}", "if    (  (  (  ( actual    =  =     ( Definition . def . class )  )     |  |     (  ( actual    !  =     ( void . class )  )     &  &     ( expected    =  =     ( Definition . def . class )  )  )  )     |  |     ( expected . isAssignableFrom ( actual )  )  )     |  |     (  ( actual . isAssignableFrom ( expected )  )     &  &    explicit )  )     {", "return   Definition .  . standard ( actual ,    expected ,    explicit )  ;", "} else    {", "throw   location . createError ( new   ClassException (  (  (  (  (  \" Cannot   cast   from    [  \"     +     ( Definition . ClassToName ( actual )  )  )     +     \"  ]    to    [  \"  )     +     ( Definition . ClassToName ( expected )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getLegalCast"], "fileName": "org.elasticsearch.painless.AnalyzerCaster"}, {"methodBody": ["METHOD_START", "{", "if    (  ( from 0     =  =     ( String . class )  )     |  |     ( from 1     =  =     ( String . class )  )  )     {", "return   String . class ;", "}", "return    . promoteNumeric ( from 0  ,    from 1  ,    true )  ;", "}", "METHOD_END"], "methodName": ["promoteAdd"], "fileName": "org.elasticsearch.painless.AnalyzerCaster"}, {"methodBody": ["METHOD_START", "{", "if    ( from 0     =  =    from 1  )     {", "return   from 0  ;", "}", "if    (  ( from 0     =  =     ( Definition . def . cs )  )     |  |     ( from 1     =  =     ( Definition . def . cs )  )  )     {", "return   Definition . def . cs ;", "}", "if    (  ( from 0  . isPrimitive (  )  )     &  &     ( from 1  . isPrimitive (  )  )  )     {", "if    (  ( from 0     =  =     ( boolean . cs )  )     &  &     ( from 1     =  =     ( boolean . cs )  )  )     {", "return   boolean . cs ;", "}", "if    (  ( from 0     =  =     ( double . cs )  )     |  |     ( from 1     =  =     ( double . cs )  )  )     {", "return   double . cs ;", "} else", "if    (  ( from 0     =  =     ( float . cs )  )     |  |     ( from 1     =  =     ( float . cs )  )  )     {", "return   float . cs ;", "} else", "if    (  ( from 0     =  =     ( long . cs )  )     |  |     ( from 1     =  =     ( long . cs )  )  )     {", "return   long . cs ;", "} else    {", "if    ( from 0     =  =     ( byte . cs )  )     {", "if    ( from 1     =  =     ( byte . cs )  )     {", "return   byte . cs ;", "} else", "if    ( from 1     =  =     ( short . cs )  )     {", "if    ( const 1     !  =    null )     {", "final   short   constant    =     (  ( short )     ( const 1  )  )  ;", "if    (  ( constant    <  =     ( Byte . MAX _ VALUE )  )     &  &     ( constant    >  =     ( Byte . MIN _ VALUE )  )  )     {", "return   byte . cs ;", "}", "}", "return   short . cs ;", "} else", "if    ( from 1     =  =     ( char . cs )  )     {", "return   int . cs ;", "} else", "if    ( from 1     =  =     ( int . cs )  )     {", "if    ( const 1     !  =    null )     {", "final   int   constant    =     (  ( int )     ( const 1  )  )  ;", "if    (  ( constant    <  =     ( Byte . MAX _ VALUE )  )     &  &     ( constant    >  =     ( Byte . MIN _ VALUE )  )  )     {", "return   byte . cs ;", "}", "}", "return   int . cs ;", "}", "} else", "if    ( from 0     =  =     ( short . cs )  )     {", "if    ( from 1     =  =     ( byte . cs )  )     {", "if    ( const 0     !  =    null )     {", "final   short   constant    =     (  ( short )     ( const 0  )  )  ;", "if    (  ( constant    <  =     ( Byte . MAX _ VALUE )  )     &  &     ( constant    >  =     ( Byte . MIN _ VALUE )  )  )     {", "return   byte . cs ;", "}", "}", "return   short . cs ;", "} else", "if    ( from 1     =  =     ( short . cs )  )     {", "return   short . cs ;", "} else", "if    ( from 1     =  =     ( char . cs )  )     {", "return   int . cs ;", "} else", "if    ( from 1     =  =     ( int . cs )  )     {", "if    ( const 1     !  =    null )     {", "final   int   constant    =     (  ( int )     ( const 1  )  )  ;", "if    (  ( constant    <  =     ( Short . MAX _ VALUE )  )     &  &     ( constant    >  =     ( Short . MIN _ VALUE )  )  )     {", "return   short . cs ;", "}", "}", "return   int . cs ;", "}", "} else", "if    ( from 0     =  =     ( char . cs )  )     {", "if    ( from 1     =  =     ( byte . cs )  )     {", "return   int . cs ;", "} else", "if    ( from 1     =  =     ( short . cs )  )     {", "return   int . cs ;", "} else", "if    ( from 1     =  =     ( char . cs )  )     {", "return   char . cs ;", "} else", "if    ( from 1     =  =     ( int . cs )  )     {", "if    ( const 1     !  =    null )     {", "final   int   constant    =     (  ( int )     ( const 1  )  )  ;", "if    (  ( constant    <  =     ( Character . MAX _ VALUE )  )     &  &     ( constant    >  =     ( Character . MIN _ VALUE )  )  )     {", "return   byte . cs ;", "}", "}", "return   int . cs ;", "}", "} else", "if    ( from 0     =  =     ( int . cs )  )     {", "if    ( from 1     =  =     ( byte . cs )  )     {", "if    ( const 0     !  =    null )     {", "final   int   constant    =     (  ( int )     ( const 0  )  )  ;", "if    (  ( constant    <  =     ( Byte . MAX _ VALUE )  )     &  &     ( constant    >  =     ( Byte . MIN _ VALUE )  )  )     {", "return   byte . cs ;", "}", "}", "return   int . cs ;", "} else", "if    ( from 1     =  =     ( short . cs )  )     {", "if    ( const 0     !  =    null )     {", "final   int   constant    =     (  ( int )     ( const 0  )  )  ;", "if    (  ( constant    <  =     ( Short . MAX _ VALUE )  )     &  &     ( constant    >  =     ( Short . MIN _ VALUE )  )  )     {", "return   byte . cs ;", "}", "}", "return   int . cs ;", "} else", "if    ( from 1     =  =     ( char . cs )  )     {", "if    ( const 0     !  =    null )     {", "final   int   constant    =     (  ( int )     ( const 0  )  )  ;", "if    (  ( constant    <  =     ( Character . MAX _ VALUE )  )     &  &     ( constant    >  =     ( Character . MIN _ VALUE )  )  )     {", "return   byte . cs ;", "}", "}", "return   int . cs ;", "} else", "if    ( from 1     =  =     ( int . cs )  )     {", "return   int . cs ;", "}", "}", "}", "}", "return   Object . cs ;", "}", "METHOD_END"], "methodName": ["promoteConditional"], "fileName": "org.elasticsearch.painless.AnalyzerCaster"}, {"methodBody": ["METHOD_START", "{", "if    (  ( from 0     =  =     ( Definition . def . class )  )     |  |     ( from 1     =  =     ( Definition . def . class )  )  )     {", "return   Definition . def . class ;", "}", "if    (  ( from 0  . isPrimitive (  )  )     &  &     ( from 1  . isPrimitive (  )  )  )     {", "if    (  ( from 0     =  =     ( boolean . class )  )     &  &     ( from 1     =  =     ( boolean . class )  )  )     {", "return   boolean . class ;", "}", "return    . promoteNumeric ( from 0  ,    from 1  ,    true )  ;", "}", "return   Object . class ;", "}", "METHOD_END"], "methodName": ["promoteEquality"], "fileName": "org.elasticsearch.painless.AnalyzerCaster"}, {"methodBody": ["METHOD_START", "{", "if    (  (  (  ( from    =  =     ( Definition . def . class )  )     |  |     (  ( from    =  =     ( double . class )  )     &  &    decimal )  )     |  |     (  ( from    =  =     ( float . class )  )     &  &    decimal )  )     |  |     ( from    =  =     ( long . class )  )  )     {", "return   from ;", "} else", "if    (  (  (  ( from    =  =     ( int . class )  )     |  |     ( from    =  =     ( char . class )  )  )     |  |     ( from    =  =     ( short . class )  )  )     |  |     ( from    =  =     ( byte . class )  )  )     {", "return   int . class ;", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["promoteNumeric"], "fileName": "org.elasticsearch.painless.AnalyzerCaster"}, {"methodBody": ["METHOD_START", "{", "if    (  ( from 0     =  =     ( Definition . def . class )  )     |  |     ( from 1     =  =     ( Definition . def . class )  )  )     {", "return   Definition . def . class ;", "}", "if    ( decimal )     {", "if    (  ( from 0     =  =     ( double . class )  )     |  |     ( from 1     =  =     ( double . class )  )  )     {", "return   double . class ;", "} else", "if    (  ( from 0     =  =     ( float . class )  )     |  |     ( from 1     =  =     ( float . class )  )  )     {", "return   float . class ;", "}", "}", "if    (  ( from 0     =  =     ( long . class )  )     |  |     ( from 1     =  =     ( long . class )  )  )     {", "return   long . class ;", "} else", "if    (  (  (  (  (  (  (  ( from 0     =  =     ( int . class )  )     |  |     ( from 1     =  =     ( int . class )  )  )     |  |     ( from 0     =  =     ( char . class )  )  )     |  |     ( from 1     =  =     ( char . class )  )  )     |  |     ( from 0     =  =     ( short . class )  )  )     |  |     ( from 1     =  =     ( short . class )  )  )     |  |     ( from 0     =  =     ( byte . class )  )  )     |  |     ( from 1     =  =     ( byte . class )  )  )     {", "return   int . class ;", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["promoteNumeric"], "fileName": "org.elasticsearch.painless.AnalyzerCaster"}, {"methodBody": ["METHOD_START", "{", "if    (  ( from 0     =  =     ( Definition . def . class )  )     |  |     ( from 1     =  =     ( Definition . def . class )  )  )     {", "return   Definition . def . class ;", "}", "if    (  ( from 0     =  =     ( boolean . class )  )     |  |     ( from 1     =  =     ( boolean . class )  )  )     {", "return   boolean . class ;", "}", "return    . promoteNumeric ( from 0  ,    from 1  ,    false )  ;", "}", "METHOD_END"], "methodName": ["promoteXor"], "fileName": "org.elasticsearch.painless.AnalyzerCaster"}, {"methodBody": ["METHOD_START", "{", "Location   location    =    new   Location (  \" dummy \"  ,     0  )  ;", "if    ( actual . equals ( expected )  )     {", "assertFalse ( mustBeExplicit )  ;", "assertNull (  . getLegalCast ( location ,    actual ,    expected ,    false ,    false )  )  ;", "assertNull (  . getLegalCast ( location ,    actual ,    expected ,    true ,    false )  )  ;", "return ;", "}", "Definition . Cast   cast    =     . getLegalCast ( location ,    actual ,    expected ,    true ,    false )  ;", "assertEquals ( actual ,    cast . from )  ;", "assertEquals ( expected ,    cast . to )  ;", "if    ( mustBeExplicit )     {", "ClassCastException   error    =    expectThrows ( ClassCastException . class ,     (  )     -  >     . getLegalCast ( location ,    actual ,    expected ,    false ,    false )  )  ;", "assertTrue ( error . getMessage (  )  . startsWith (  \" Cannot   cast \"  )  )  ;", "} else    {", "cast    =     . getLegalCast ( location ,    actual ,    expected ,    false ,    false )  ;", "assertEquals ( actual ,    cast . from )  ;", "assertEquals ( expected ,    cast . to )  ;", "}", "}", "METHOD_END"], "methodName": ["assertCast"], "fileName": "org.elasticsearch.painless.AnalyzerCasterTests"}, {"methodBody": ["METHOD_START", "{", "AnalyzerCasterTests . assertCast ( byte . class ,    byte . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( byte . class ,    short . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( byte . class ,    int . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( byte . class ,    long . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( byte . class ,    float . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( byte . class ,    double . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( short . class ,    byte . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( short . class ,    short . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( short . class ,    int . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( short . class ,    long . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( short . class ,    float . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( short . class ,    double . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( int . class ,    byte . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( int . class ,    short . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( int . class ,    int . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( int . class ,    long . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( int . class ,    float . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( int . class ,    double . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( long . class ,    byte . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( long . class ,    short . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( long . class ,    int . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( long . class ,    long . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( long . class ,    float . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( long . class ,    double . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( float . class ,    byte . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( float . class ,    short . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( float . class ,    int . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( float . class ,    long . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( float . class ,    float . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( float . class ,    double . class ,    false )  ;", "AnalyzerCasterTests . assertCast ( double . class ,    byte . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( double . class ,    short . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( double . class ,    int . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( double . class ,    long . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( double . class ,    float . class ,    true )  ;", "AnalyzerCasterTests . assertCast ( double . class ,    double . class ,    false )  ;", "}", "METHOD_END"], "methodName": ["testNumericCasts"], "fileName": "org.elasticsearch.painless.AnalyzerCasterTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5     &     3  )  ,    exec (  \" return    5     &     3  ;  \"  )  )  ;", "assertEquals (  (  5     &     3 L )  ,    exec (  \" return    5     &     3 L ;  \"  )  )  ;", "assertEquals (  (  5 L    &     3  )  ,    exec (  \" return    5 L    &     3  ;  \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" int   x    =     5  ;    long   y    =     3  ;    return   x    &    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     4  ;    int   y    =     1  ;    x    &  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     4  ;    int   y    =     1  ;    x    &  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    float   y    =     1  ;    x    &  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    double   y    =     1  ;    x    &  =    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusCompoundAssignment"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;    x    &  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    true ;    x    &  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    x    &  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    x    &  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     &  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     &  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     &  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     &  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  3     &     1  4  )  )  ,    exec (  \" byte   x    =     1  3  ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  3     &     1  4  )  )  ,    exec (  \" short   x    =     1  3  ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  3     &     1  4  )  )  ,    exec (  \" char   x    =     1  3  ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1  3     &     1  4  )  ,    exec (  \" int   x    =     1  3  ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( long )     (  1  3     &     1  4  )  )  ,    exec (  \" long   x    =     1  3 L ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignment"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( float )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( double )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  ;", "}  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       def   y    =    true ;    return   x    &    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;       def   y    =    false ;    return   x    &    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    def   y    =    true ;    return   x    &    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    def   y    =    false ;    return   x    &    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     4 F ;    int   y    =     1  ;    x    &  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     4 D ;    int   y    =     1  ;    x    &  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    def   y    =     1 F ;    x    &  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    def   y    =     1 D ;    x    &  =    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDefBogusCompoundAssignment"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =    true ;    x    &  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;    x    &  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    x    &  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    x    &  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     &  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     &  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     &  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     &  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  3     &     1  4  )  )  ,    exec (  \" def   x    =     ( byte )  1  3  ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  3     &     1  4  )  )  ,    exec (  \" def   x    =     ( short )  1  3  ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  3     &     1  4  )  )  ,    exec (  \" def   x    =     ( char )  1  3  ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1  3     &     1  4  )  ,    exec (  \" def   x    =     1  3  ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( long )     (  1  3     &     1  4  )  )  ,    exec (  \" def   x    =     1  3 L ;    x    &  =     1  4  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefCompoundAssignment"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     ( float )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     ( double )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  ;", "}  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;       def   y    =    true ;    return   x    &    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    true ;       def   y    =    false ;    return   x    &    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    def   y    =    true ;    return   x    &    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    def   y    =    false ;    return   x    &    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedLHS"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( float )  4  ;    byte   y    =     ( byte )  1  ;    return   x    &    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( double )  4  ;    byte   y    =     ( byte )  1  ;    return   x    &    y \"  )  ;", "}  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    byte   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    byte   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    byte   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    byte   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    short   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    short   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    short   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    short   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    char   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    char   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    char   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    char   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    int   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    int   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    int   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    int   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( byte )  4  ;    long   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( short )  4  ;    long   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( char )  4  ;    long   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( int )  4  ;    long   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    &    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       boolean   y    =    true ;    return   x    &    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;       boolean   y    =    false ;    return   x    &    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    boolean   y    =    true ;    return   x    &    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    boolean   y    =    false ;    return   x    &    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedRHS"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     ( float )  4  ;    int   y    =     1  ;    return   x    &    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     ( double )  4  ;    int   y    =     1  ;    return   x    &    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIllegal"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5     &     1  2  )  ,    exec (  \" int   x    =     5  ;    int   y    =     1  2  ;    return   x    &    y ;  \"  )  )  ;", "assertEquals (  (  5     &     (  -  1  2  )  )  ,    exec (  \" int   x    =     5  ;    int   y    =     -  1  2  ;    return   x    &    y ;  \"  )  )  ;", "assertEquals (  (  (  7     &     1  5  )     &     3  )  ,    exec (  \" int   x    =     7  ;    int   y    =     1  5  ;    int   z    =     3  ;    return   x    &    y    &    z ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInt"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5     &     1  2  )  ,    exec (  \" return    5     &     1  2  ;  \"  )  )  ;", "assertEquals (  (  5     &     (  -  1  2  )  )  ,    exec (  \" return    5     &     -  1  2  ;  \"  )  )  ;", "assertEquals (  (  (  7     &     1  5  )     &     3  )  ,    exec (  \" return    7     &     1  5     &     3  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIntConst"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5 L    &     1  2 L )  ,    exec (  \" long   x    =     5  ;    long   y    =     1  2  ;    return   x    &    y ;  \"  )  )  ;", "assertEquals (  (  5 L    &     (  -  1  2 L )  )  ,    exec (  \" long   x    =     5  ;    long   y    =     -  1  2  ;    return   x    &    y ;  \"  )  )  ;", "assertEquals (  (  (  7 L    &     1  5 L )     &     3 L )  ,    exec (  \" long   x    =     7  ;    long   y    =     1  5  ;    long   z    =     3  ;    return   x    &    y    &    z ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLong"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5 L    &     1  2 L )  ,    exec (  \" return    5 L    &     1  2 L ;  \"  )  )  ;", "assertEquals (  (  5 L    &     (  -  1  2 L )  )  ,    exec (  \" return    5 L    &     -  1  2 L ;  \"  )  )  ;", "assertEquals (  (  (  7 L    &     1  5 L )     &     3 L )  ,    exec (  \" return    7 L    &     1  5 L    &     3 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongConst"], "fileName": "org.elasticsearch.painless.AndTests"}, {"methodBody": ["METHOD_START", "{", "String   declType    =     ( declareAsDef )     ?     \" def \"     :    declType ( valueType )  ;", "String   valueCtorCall    =    valueCtorCall ( valueType ,     5  )  ;", "String   decl    =     ( declType    +     \"    x    =     \"  )     +    valueCtorCall ;", "assertEquals (  5  ,    exec (  ( decl    +     \"  ;    return   x . length \"  )  ,    true )  )  ;", "assertEquals ( val ,    exec (  ( decl    +     \"  ;    x [     0  ]     =    params . val ;    return   x [     0  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( val ,    exec (  ( decl    +     \"  ;    x [     0  ]     =    params . val ;    return   x [  -  5  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( val ,    exec (  ( decl    +     \"  ;    x [  -  5  ]     =    params . val ;    return   x [  -  5  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "expOutOfBounds (  6  ,     ( decl    +     \"  ;    return   x [     6  ]  \"  )  ,    val )  ;", "expOutOfBounds (  (  -  1  )  ,     ( decl    +     \"  ;    return   x [  -  6  ]  \"  )  ,    val )  ;", "expOutOfBounds (  6  ,     ( decl    +     \"  ;    x [     6  ]     =    params . val ;    return    0  \"  )  ,    val )  ;", "expOutOfBounds (  (  -  1  )  ,     ( decl    +     \"  ;    x [  -  6  ]     =    params . val ;    return    0  \"  )  ,    val )  ;", "if    ( valPlusOne    !  =    null )     {", "assertEquals ( val ,    exec (  ( decl    +     \"  ;    x [  0  ]     =    params . val ;    x [     0  ]     =    x [     0  ]  +  +  ;    return   x [  0  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( val ,    exec (  ( decl    +     \"  ;    x [  0  ]     =    params . val ;    x [     0  ]     =    x [  -  5  ]  +  +  ;    return   x [  0  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( valPlusOne ,    exec (  ( decl    +     \"  ;    x [  0  ]     =    params . val ;    x [     0  ]     =     +  + x [     0  ]  ;    return   x [  0  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( valPlusOne ,    exec (  ( decl    +     \"  ;    x [  0  ]     =    params . val ;    x [     0  ]     =     +  + x [  -  5  ]  ;    return   x [  0  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( valPlusOne ,    exec (  ( decl    +     \"  ;    x [  0  ]     =    params . val ;    x [     0  ]  +  +                          ;    return   x [  0  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( valPlusOne ,    exec (  ( decl    +     \"  ;    x [  0  ]     =    params . val ;    x [  -  5  ]  +  +                          ;    return   x [  0  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( valPlusOne ,    exec (  ( decl    +     \"  ;    x [  0  ]     =    params . val ;    x [     0  ]     +  =     1                 ;    return   x [  0  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( valPlusOne ,    exec (  ( decl    +     \"  ;    x [  0  ]     =    params . val ;    x [  -  5  ]     +  =     1                 ;    return   x [  0  ]  ;  \"  )  ,    Collions . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "expOutOfBounds (  6  ,     ( decl    +     \"  ;    return   x [     6  ]  +  +  \"  )  ,    val )  ;", "expOutOfBounds (  (  -  1  )  ,     ( decl    +     \"  ;    return   x [  -  6  ]  +  +  \"  )  ,    val )  ;", "expOutOfBounds (  6  ,     ( decl    +     \"  ;    return    +  + x [     6  ]  \"  )  ,    val )  ;", "expOutOfBounds (  (  -  1  )  ,     ( decl    +     \"  ;    return    +  + x [  -  6  ]  \"  )  ,    val )  ;", "expOutOfBounds (  6  ,     ( decl    +     \"  ;    x [     6  ]     +  =     1  ;    return    0  \"  )  ,    val )  ;", "expOutOfBounds (  (  -  1  )  ,     ( decl    +     \"  ;    x [  -  6  ]     +  =     1  ;    return    0  \"  )  ,    val )  ;", "}", "}", "METHOD_END"], "methodName": ["arrayLoadStoreTestCase"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "IndexOutOfBoundsException   e    =    ScriptTestCase . expectScriptThrows ( IndexOutOfBoundsException . class ,     (  )     -  >    exec ( script ,    singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "try    {", "assertThat ( e . getMessage (  )  ,    outOfBoundsExceptionMessageMatcher ( index ,     5  )  )  ;", "}    catch    ( AssertionError   ae )     {", "ae . addSuppressed ( e )  ;", "throw   ae ;", "}", "}", "METHOD_END"], "methodName": ["expectOutOfBounds"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( false ,     \" byte \"  ,     (  ( byte )     (  5  )  )  ,     (  ( byte )     (  6  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testBytes"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( true ,     \" byte \"  ,     (  ( byte )     (  5  )  )  ,     (  ( byte )     (  6  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testBytesInDef"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( true ,     \" def \"  ,     5  ,    null )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( false ,     \" double \"  ,     5  .  0  ,     6  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testDoubles"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( true ,     \" double \"  ,     5  .  0  ,     6  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testDoublesInDef"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( false ,     \" float \"  ,     5  .  0 F ,     6  .  0 F )  ;", "}", "METHOD_END"], "methodName": ["testFloats"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( true ,     \" float \"  ,     5  .  0 F ,     6  .  0 F )  ;", "}", "METHOD_END"], "methodName": ["testFloatsInDef"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( false ,     \" int \"  ,     5  ,     6  )  ;", "}", "METHOD_END"], "methodName": ["testInts"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( true ,     \" int \"  ,     5  ,     6  )  ;", "}", "METHOD_END"], "methodName": ["testIntsInDef"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( false ,     \" long \"  ,     5 L ,     6 L )  ;", "}", "METHOD_END"], "methodName": ["testLongs"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( true ,     \" long \"  ,     5 L ,     6 L )  ;", "}", "METHOD_END"], "methodName": ["testLongsInDef"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( false ,     \" short \"  ,     (  ( short )     (  5  )  )  ,     (  ( short )     (  6  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testShorts"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( true ,     \" short \"  ,     (  ( short )     (  5  )  )  ,     (  ( short )     (  6  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testShortsInDef"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( false ,     \" String \"  ,     \" cat \"  ,    null )  ;", "}", "METHOD_END"], "methodName": ["testStrings"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "arrayLoadStoreTestCase ( true ,     \" String \"  ,     \" cat \"  ,    null )  ;", "}", "METHOD_END"], "methodName": ["testStringsInDef"], "fileName": "org.elasticsearch.painless.ArrayLikeObjectTestCase"}, {"methodBody": ["METHOD_START", "{", "final   MethodHandle   mh    =    Def . arrayLengthGetter ( array . getClass (  )  )  ;", "assertSame ( array . getClass (  )  ,    mh . type (  )  . parameterType (  0  )  )  ;", "assertEquals ( length ,     (  ( int )     ( mh . asType ( MethodType . methodType ( int . class ,    Object . class )  )  . invokeExact ( array )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["assertArrayLength"], "fileName": "org.elasticsearch.painless.ArrayTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( JRE _ IS _ MINIMUM _ JAVA 9  ,     (  ( Def . JAVA 9  _ ARRAY _ LENGTH _ MH _ FACTORY )     !  =    null )  )  ;", "assertLength (  2  ,    new   int [  2  ]  )  ;", "assertLength (  3  ,    new   long [  3  ]  )  ;", "assertLength (  4  ,    new   byte [  4  ]  )  ;", "assertLength (  5  ,    new   float [  5  ]  )  ;", "assertLength (  6  ,    new   double [  6  ]  )  ;", "assertLength (  7  ,    new   char [  7  ]  )  ;", "assertLength (  8  ,    new   short [  8  ]  )  ;", "assertLength (  9  ,    new   Object [  9  ]  )  ;", "assertLength (  1  0  ,    new   Integer [  1  0  ]  )  ;", "assertLength (  1  1  ,    new   String [  1  1  ]  [  2  ]  )  ;", "}", "METHOD_END"], "methodName": ["testArrayLengthHelper"], "fileName": "org.elasticsearch.painless.ArrayTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" int   x    =     1  ;    int [  ]    y    =    new   int [ x ]  ;    return   y . length \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testArrayVariable"], "fileName": "org.elasticsearch.painless.ArrayTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =     2  ;    return   x [  0  ]     /     2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDivideArray"], "fileName": "org.elasticsearch.painless.ArrayTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  9  9  9     *     1  0  0  0  )     /     2  )  ,    exec (  (  \" def   a    =    new   int [  1  0  0  0  ]  ;    for    ( int   x    =     0  ;    x    <    a . length ;    x +  +  )     {    a [ x ]     =    x ;     }     \"     +     \" int   total    =     0  ;    for    ( int   x    =     0  ;    x    <    a . length ;    x +  +  )     {    total    +  =    a [ x ]  ;     }    return   total ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testForLoop"], "fileName": "org.elasticsearch.painless.ArrayTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" int   x ;    def [  ]    y    =    new   def [  1  ]  ;    x    =    y [  0  ]     =     1  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testJacksCrazyExpression1"], "fileName": "org.elasticsearch.painless.ArrayTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" int   x ;    def   y    =    new   def [  1  ]  ;    x    =    y [  0  ]     =     1  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testJacksCrazyExpression2"], "fileName": "org.elasticsearch.painless.ArrayTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  (  \" int   foo ( Supplier   t )     {    return   t . get (  )     }  \"     +     (  \" ArrayList   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;  \"     +     \" return   foo ( l :  : getLength )  ;  \"  )  )  )  )  ;", "assertEquals (  1  ,    exec (  (  \" int   foo ( Supplier   t )     {    return   t . get (  )     }  \"     +     (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;  \"     +     \" return   foo ( l :  : getLength )  ;  \"  )  )  )  )  ;", "assertEquals (  1  ,    exec (  (  \" int   foo ( Supplier   t )     {    return   t . get (  )     }  \"     +     (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;  \"     +     \" return   foo ( l :  : getLength )  ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturingReference"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Arrays . asList (  2  ,     3  )  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    l . collect ( x    -  >    x    +     1  )  \"  )  )  ;", "assertEquals ( asSet (  2  ,     3  )  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    l . collect ( new   HashSet (  )  ,    x    -  >    x    +     1  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCollection_Collect"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    return   l . find ( x    -  >    x    =  =     2  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCollection_Find"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Arrays . asList (  2  )  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    return   l . findAll ( x    -  >    x    =  =     2  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCollection_FindAll"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" found \"  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    return   l . findResult ( x    -  >    x    >     1     ?     ' found '     :    null )  \"  )  )  ;", "assertEquals (  \" notfound \"  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    return   l . findResult (  ' notfound '  ,    x    -  >    x    >     1  0     ?     ' found '     :    null )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCollection_FindResult"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Arrays . asList ( Arrays . asList (  2  )  ,    Arrays . asList (  1  )  )  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    return   l . split ( x    -  >    x    =  =     2  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCollection_Split"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    return   l . getLength (  )  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    return   l . length ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  (  \" FeatureTest   ft    =    new   FeatureTest (  )  ;  \"     +     \"    ft . setX (  3  )  ;    ft . setY (  2  )  ;    return   ft . getTotal (  )  \"  )  )  )  ;", "assertEquals (  5  ,    exec (  (  \" def   ft    =    new   FeatureTest (  )  ;  \"     +     \"    ft . setX (  3  )  ;    ft . setY (  2  )  ;    return   ft . getTotal (  )  \"  )  )  )  ;", "assertEquals (  8  ,    exec (  (  \" FeatureTest   ft    =    new   FeatureTest (  )  ;  \"     +     \"    ft . setX (  3  )  ;    ft . setY (  2  )  ;    return   ft . addToTotal (  3  )  \"  )  )  )  ;", "assertEquals (  8  ,    exec (  (  \" def   ft    =    new   FeatureTest (  )  ;  \"     +     \"    ft . setX (  3  )  ;    ft . setY (  2  )  ;    return   ft . addToTotal (  3  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testFeatureTest"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . any ( x    -  >    x    =  =     1  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_Any"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" List   l    =    new   ArrayList (  )  ;    return   l . asCollection (  )     =  =  =    l \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_AsCollection"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" List   l    =    new   ArrayList (  )  ;    return   l . asList (  )     =  =  =    l \"  )  )  ;", "assertEquals (  5  ,    exec (  \" Set   l    =    new   HashSet (  )  ;    l . add (  5  )  ;    return   l . asList (  )  [  0  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_AsList"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    List   l 2     =    new   ArrayList (  )  ;    l . each ( l 2  :  : add )  ;    return   l 2  . size (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_Each"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  2  )  ;    Map   m    =    new   HashMap (  )  ;    l . eachWithIndex ( m :  : put )  ;    return   m . get (  2  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_EachWithIndex"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    l . every ( x    -  >    x    =  =     1  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_Every"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    l . findResults ( x    -  >    x    =  =     1     ?    x    :    null )  . size (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_FindResults"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  -  1  )  ;    l . groupBy ( x    -  >    x    <     0     ?     ' negative '     :     ' positive '  )  . size (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_GroupBy"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" test , ing \"  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  ' test '  )  ;    l . add (  ' ing '  )  ;    l . join (  '  ,  '  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_Join"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  3  .  0  ,    exec (  \" def   l    =     [  1  ,  2  ]  ;    return   l . sum (  )  \"  )  )  ;", "assertEquals (  5  .  0  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    l . sum ( x    -  >    x    +     1  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterable_Sum"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Arrays . asList (  \" one 1  \"  ,     \" two 2  \"  )  ,    exec (  \" Map   m    =    new   TreeMap (  )  ;    m . one    =     1  ;    m . two    =     2  ;    m . collect (  ( key , value )     -  >    key    +    value )  \"  )  )  ;", "assertEquals ( asSet (  \" one 1  \"  ,     \" two 2  \"  )  ,    exec (  \" Map   m    =    new   TreeMap (  )  ;    m . one    =     1  ;    m . two    =     2  ;    m . collect ( new   HashSet (  )  ,     ( key , value )     -  >    key    +    value )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMap_Collect"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" Map   m    =    new   TreeMap (  )  ;    m . one    =     1  ;    m . two    =     2  ;    m . count (  ( key , value )     -  >    value    =  =     2  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMap_Count"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" Map   m    =    new   TreeMap (  )  ;    m . one    =     1  ;    m . two    =     2  ;    Map   m 2     =    new   TreeMap (  )  ;    m . each ( m 2  :  : put )  ;    return   m 2  . size (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMap_Each"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" Map   m    =    new   TreeMap (  )  ;    m . one    =     1  ;    m . two    =     2  ;    m . every (  ( key , value )     -  >    value    =  =     2  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMap_Every"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" two \"  ,    exec (  \" Map   m    =    new   TreeMap (  )  ;    m . one    =     1  ;    m . two    =     2  ;    return   m . find (  ( key , value )     -  >    value    =  =     2  )  . key \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMap_Find"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Collections . singletonMap (  \" two \"  ,     2  )  ,    exec (  \" Map   m    =    new   TreeMap (  )  ;    m . one    =     1  ;    m . two    =     2  ;    return   m . findAll (  ( key , value )     -  >    value    =  =     2  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMap_FindAll"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" found \"  ,    exec (  \" Map   m    =    new   TreeMap (  )  ;    m . one    =     1  ;    m . two    =     2  ;    return   m . findResult (  ( key , value )     -  >    value    =  =     2     ?     ' found '     :    null )  \"  )  )  ;", "assertEquals (  \" notfound \"  ,    exec (  (  \" Map   m    =    new   TreeMap (  )  ;    m . one    =     1  ;    m . two    =     2  ;     \"     +     \" return   m . findResult (  ' notfound '  ,     ( key , value )     -  >    value    =  =     1  0     ?     ' found '     :    null )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testMap_FindResult"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Arrays . asList (  \" negative \"  ,     \" positive \"  )  ,    exec (  (  \" Map   m    =    new   TreeMap (  )  ;    m . a    =     -  1  ;    m . b    =     1  ;     \"     +     \" return   m . findResults (  ( key , value )     -  >    value    <     0     ?     ' negative '     :     ' positive '  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testMap_FindResults"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Map < String ,    Integer >  >    expected    =    new   HashMap <  >  (  )  ;", "expected . put (  \" negative \"  ,    Collecs . singletonMap (  \" a \"  ,     (  -  1  )  )  )  ;", "expected . put (  \" positive \"  ,    Collecs . singletonMap (  \" b \"  ,     1  )  )  ;", "assertEquals ( expected ,    exec (  (  \" Map   m    =    new   TreeMap (  )  ;    m . a    =     -  1  ;    m . b    =     1  ;     \"     +     \" return   m . groupBy (  ( key , value )     -  >    value    <     0     ?     ' negative '     :     ' positive '  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testMap_GroupBy"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" ArrayList   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    return   l . getLength (  )  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" ArrayList   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    return   l . length ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testStatic"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    return   l . getLength (  )  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    return   l . length ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSubclass"], "fileName": "org.elasticsearch.painless.AugmentationTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . ArrayArg . class ,    definition )  ;", "String   rando    =    randomAlphaOfLength (  5  )  ;", "assertEquals ( rando ,     (  ( BaseClassTests . ArrayArg )     ( scriptEngine . compile ( compiler ,    null ,     \" arg [  0  ]  \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( new   String [  ]  {    rando ,     \" foo \"     }  )  )  ;", "}", "METHOD_END"], "methodName": ["testArrayArg"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . DefArrayArg . class ,    definition )  ;", "Object   rando    =    randomInt (  )  ;", "assertEquals ( rando ,     (  ( BaseClassTests . DefArrayArg )     ( scriptEngine . compile ( compiler ,    null ,     \" arg [  0  ]  \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( new   Object [  ]  {    rando ,     1  0     }  )  )  ;", "rando    =    randomAlphaOfLength (  5  )  ;", "assertEquals ( rando ,     (  ( BaseClassTests . DefArrayArg )     ( scriptEngine . compile ( compiler ,    null ,     \" arg [  0  ]  \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( new   Object [  ]  {    rando ,     1  0     }  )  )  ;", "assertEquals (  5  ,     (  ( BaseClassTests . DefArrayArg )     ( scriptEngine . compile ( compiler ,    null ,     \" arg [  0  ]  . length (  )  \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( new   Object [  ]  {    rando ,     1  0     }  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefArrayArg"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . DefaultMethods . class ,    definition )  ;", "int   rando    =    randomInt (  )  ;", "assertEquals ( rando ,     (  ( BaseClassTests . DefaultMethods )     ( scriptEngine . compile ( compiler ,    null ,     \" a \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( rando ,     0  ,     0  ,     0  )  )  ;", "assertEquals ( rando ,     (  ( BaseClassTests . DefaultMethods )     ( scriptEngine . compile ( compiler ,    null ,     \" a \"  ,    Collections . emptyMap (  )  )  )  )  . executeWithASingleOne ( rando ,     0  ,     0  )  )  ;", "assertEquals (  1  0  ,     (  ( BaseClassTests . DefaultMethods )     ( scriptEngine . compile ( compiler ,    null ,     \" a    +    b    +    c    +    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  1  ,     2  ,     3  ,     4  )  )  ;", "assertEquals (  4  ,     (  ( BaseClassTests . DefaultMethods )     ( scriptEngine . compile ( compiler ,    null ,     \" a    +    b    +    c    +    d \"  ,    Collections . emptyMap (  )  )  )  )  . executeWithOne (  )  )  ;", "assertEquals (  7  ,     (  ( BaseClassTests . DefaultMethods )     ( scriptEngine . compile ( compiler ,    null ,     \" a    +    b    +    c    +    d \"  ,    Collections . emptyMap (  )  )  )  )  . executeWithASingleOne (  1  ,     2  ,     3  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaultMethods"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . Gets . class ,    definition )  ;", "Map < String ,    Object >    map    =    new   HashMap <  >  (  )  ;", "map . put (  \" s \"  ,     1  )  ;", "assertEquals (  1  ,     (  ( BaseClassTests . Gets )     ( scriptEngine . compile ( compiler ,    null ,     \" testInt \"  ,    Collections . emptyMap (  )  ,     \" s \"  ,     (  -  1  )  ,    null )  )  )  . execute (  )  )  ;", "assertEquals ( Collections . emptyMap (  )  ,     (  ( BaseClassTests . Gets )     ( scriptEngine . compile ( compiler ,    null ,     \" testMap \"  ,    Collections . emptyMap (  )  ,     \" s \"  ,     (  -  1  )  ,    null )  )  )  . execute (  )  )  ;", "assertEquals ( Collections . singletonMap (  \"  1  \"  ,     \"  1  \"  )  ,     (  ( BaseClassTests . Gets )     ( scriptEngine . compile ( compiler ,    null ,     \" testMap \"  ,    Collections . emptyMap (  )  ,     \" s \"  ,     (  -  1  )  ,    Collections . singletonMap (  \"  1  \"  ,     \"  1  \"  )  )  )  )  . execute (  )  )  ;", "assertEquals (  \" s \"  ,     (  ( BaseClassTests . Gets )     ( scriptEngine . compile ( compiler ,    null ,     \" testString \"  ,    Collections . emptyMap (  )  ,     \" s \"  ,     (  -  1  )  ,    null )  )  )  . execute (  )  )  ;", "assertEquals ( map ,     (  ( BaseClassTests . Gets )     ( scriptEngine . compile ( compiler ,    null ,     \" testMap . put ( testString ,    testInt )  ;    testMap \"  ,    Collections . emptyMap (  )  ,     \" s \"  ,     (  -  1  )  ,    null )  )  )  . execute (  )  )  ;", "}", "METHOD_END"], "methodName": ["testGets"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . ManyArgs . class ,    definition )  ;", "int   rando    =    randomInt (  )  ;", "assertEquals ( rando ,     (  ( BaseClassTests . ManyArgs )     ( scriptEngine . compile ( compiler ,    null ,     \" a \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( rando ,     0  ,     0  ,     0  )  )  ;", "assertEquals (  1  0  ,     (  ( BaseClassTests . ManyArgs )     ( scriptEngine . compile ( compiler ,    null ,     \" a    +    b    +    c    +    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  1  ,     2  ,     3  ,     4  )  )  ;", "BaseClassTests . ManyArgs   script    =     (  ( BaseClassTests . ManyArgs )     ( scriptEngine . compile ( compiler ,    null ,     \" a \"  ,    Collections . emptyMap (  )  )  )  )  ;", "assertTrue ( script . needsA (  )  )  ;", "assertFalse ( script . needsB (  )  )  ;", "assertFalse ( script . needsC (  )  )  ;", "assertFalse ( script . needsD (  )  )  ;", "script    =     (  ( BaseClassTests . ManyArgs )     ( scriptEngine . compile ( compiler ,    null ,     \" a    +    b    +    c \"  ,    Collections . emptyMap (  )  )  )  )  ;", "assertTrue ( script . needsA (  )  )  ;", "assertTrue ( script . needsB (  )  )  ;", "assertTrue ( script . needsC (  )  )  ;", "assertFalse ( script . needsD (  )  )  ;", "script    =     (  ( BaseClassTests . ManyArgs )     ( scriptEngine . compile ( compiler ,    null ,     \" a    +    b    +    c    +    d \"  ,    Collections . emptyMap (  )  )  )  )  ;", "assertTrue ( script . needsA (  )  )  ;", "assertTrue ( script . needsB (  )  )  ;", "assertTrue ( script . needsC (  )  )  ;", "assertTrue ( script . needsD (  )  )  ;", "}", "METHOD_END"], "methodName": ["testManyArgs"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . NoArgs . class ,    definition )  ;", "assertEquals (  1  ,     (  ( BaseClassTests . NoArgs )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  \" foo \"  ,     (  ( BaseClassTests . NoArgs )     ( scriptEngine . compile ( compiler ,    null ,     \"  ' foo '  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    scriptEngine . compile ( compiler ,    null ,     \" doc \"  ,    emptyMap (  )  )  )  ;", "assertEquals (  \" Variable    [ doc ]    is   not   defined .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    scriptEngine . compile ( compiler ,    null ,     \"  _ score \"  ,    emptyMap (  )  )  )  ;", "assertEquals (  \" Variable    [  _ score ]    is   not   defined .  \"  ,    e . getMessage (  )  )  ;", "String   debug    =    Debugger . toString ( BaseClassTests . NoArgs . class ,     \" int   i    =     0  \"  ,    new   CompilerSettings (  )  )  ;", "assertThat ( debug ,    containsString (  \" ACONST _ NULL \"  )  )  ;", "assertThat ( debug ,    containsString (  \" ARETURN \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoArgs"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . NoArgumentsConstant . class ,    definition )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >    scriptEngine . compile ( compiler ,    null ,     \"  1  \"  ,    emptyMap (  )  )  )  ;", "assertThat ( e . getMessage (  )  ,    startsWith (  (  (  (  \" Painless   needs   a   constant    [ String [  ]    PARAMETERS ]    on   all   interfaces   it   implements   with   the    \"     +     \" names   of   the   method   arguments   but    [  \"  )     +     ( BaseClassTests . NoArgumentsConstant . class . getName (  )  )  )     +     \"  ]    doesn ' t   have   one .  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoArgumentsConstant"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . OneArg . class ,    definition )  ;", "Object   rando    =    randomInt (  )  ;", "assertEquals ( rando ,     (  ( BaseClassTests . OneArg )     ( scriptEngine . compile ( compiler ,    null ,     \" arg \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( rando )  )  ;", "rando    =    randomAlphaOfLength (  5  )  ;", "assertEquals ( rando ,     (  ( BaseClassTests . OneArg )     ( scriptEngine . compile ( compiler ,    null ,     \" arg \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( rando )  )  ;", "Compiler   noargs    =    new   Compiler ( BaseClassTests . NoArgs . class ,    definition )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    scriptEngine . compile ( noargs ,    null ,     \" doc \"  ,    emptyMap (  )  )  )  ;", "assertEquals (  \" Variable    [ doc ]    is   not   defined .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    scriptEngine . compile ( noargs ,    null ,     \"  _ score \"  ,    emptyMap (  )  )  )  ;", "assertEquals (  \" Variable    [  _ score ]    is   not   defined .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testOneArg"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . PrimitiveArrayArg . class ,    definition )  ;", "int   rando    =    randomInt (  )  ;", "assertEquals ( rando ,     (  ( BaseClassTests . PrimitiveArrayArg )     ( scriptEngine . compile ( compiler ,    null ,     \" arg [  0  ]  \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( new   int [  ]  {    rando ,     1  0     }  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveArrayArg"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . ReturnsPrimitiveBoolean . class ,    definition )  ;", "assertEquals ( true ,     (  ( BaseClassTests . ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" true \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals ( false ,     (  ( BaseClassTests . ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" false \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals ( true ,     (  ( BaseClassTests . ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" Boolean . TRUE \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals ( false ,     (  ( BaseClassTests . ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" Boolean . FALSE \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals ( true ,     (  ( BaseClassTests . ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =    true ;    i \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals ( true ,     (  ( BaseClassTests . ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =    Boolean . TRUE ;    i \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals ( true ,     (  ( BaseClassTests . ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" true    |  |    false \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "String   debug    =    Debugger . toString ( BaseClassTests . ReturnsPrimitiveBoolean . class ,     \" false \"  ,    new   CompilerSettings (  )  )  ;", "assertThat ( debug ,    containsString (  \" ICONST _  0  \"  )  )  ;", "assertThat ( debug ,    containsString (  \" IRETURN \"  )  )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \"  1 L \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ long ]    to    [ boolean ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1 f \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ float ]    to    [ boolean ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1 d \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ double ]    to    [ boolean ]  .  \"  ,    e . getMessage (  )  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =     1 L ;    i \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =     1  .  1 f ;    i \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =     1  .  1 d ;    i \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals ( false ,     (  ( BaseClassTests . ReturnsPrimitiveBoolean )     ( scriptEngine . compile ( compiler ,    null ,     \" int   i    =     0  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnsPrimitiveBoolean"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . ReturnsPrimitiveDouble . class ,    definition )  ;", "assertEquals (  1  .  0  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  0  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \"  1 L \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  1  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1 d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  (  ( double )     (  1  .  1 F )  )  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1 f \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  1  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \" Double . valueOf (  1  .  1  )  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  (  ( double )     (  1  .  1 F )  )  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \" Float . valueOf (  1  .  1 f )  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  0  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =     1  ;    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  0  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =     1 L ;    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  1  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =     1  .  1 d ;    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  (  ( double )     (  1  .  1 F )  )  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =     1  .  1 f ;    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  1  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =    Double . valueOf (  1  .  1  )  ;    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  (  ( double )     (  1  .  1 F )  )  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =    Float . valueOf (  1  .  1 f )  ;    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  (  1  .  1     +     6  .  7  )  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1     +     6  .  7  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "String   debug    =    Debugger . toString ( BaseClassTests . ReturnsPrimitiveDouble . class ,     \"  1  \"  ,    new   CompilerSettings (  )  )  ;", "assertThat ( debug ,    containsString (  \" DCONST _  1  \"  )  )  ;", "assertThat ( debug ,    containsString (  \" DRETURN \"  )  )  ;", "assertEquals (  0  .  0  ,     (  ( BaseClassTests . ReturnsPrimitiveDouble )     ( scriptEngine . compile ( compiler ,    null ,     \" int   i    =     0  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testReturnsPrimitiveDouble"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . ReturnsPrimitiveFloat . class ,    definition )  ;", "assertEquals (  1  .  1 F ,     (  ( BaseClassTests . ReturnsPrimitiveFloat )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1 f \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  1 F ,     (  ( BaseClassTests . ReturnsPrimitiveFloat )     ( scriptEngine . compile ( compiler ,    null ,     \"  ( float )     1  .  1 d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  1 F ,     (  ( BaseClassTests . ReturnsPrimitiveFloat )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =     1  .  1 f ;    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  1  .  1 F ,     (  ( BaseClassTests . ReturnsPrimitiveFloat )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =    Float . valueOf (  1  .  1 f )  ;    d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "assertEquals (  (  1  .  1 F    +     6  .  7 F )  ,     (  ( BaseClassTests . ReturnsPrimitiveFloat )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1 f    +     6  .  7 f \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveFloat )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1 d \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ double ]    to    [ float ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveFloat )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =     1  .  1 d ;    d \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveFloat )     ( scriptEngine . compile ( compiler ,    null ,     \" def   d    =    Double . valueOf (  1  .  1  )  ;    d \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "String   debug    =    Debugger . toString ( BaseClassTests . ReturnsPrimitiveFloat . class ,     \"  1 f \"  ,    new   CompilerSettings (  )  )  ;", "assertThat ( debug ,    containsString (  \" FCONST _  1  \"  )  )  ;", "assertThat ( debug ,    containsString (  \" FRETURN \"  )  )  ;", "assertEquals (  0  .  0 F ,     (  ( BaseClassTests . ReturnsPrimitiveFloat )     ( scriptEngine . compile ( compiler ,    null ,     \" int   i    =     0  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["testReturnsPrimitiveFloat"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . ReturnsPrimitiveInt . class ,    definition )  ;", "assertEquals (  1  ,     (  ( BaseClassTests . ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  1  ,     (  ( BaseClassTests . ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \"  ( int )     1 L \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  1  ,     (  ( BaseClassTests . ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \"  ( int )     1  .  1 d \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  1  ,     (  ( BaseClassTests . ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \"  ( int )     1  .  1 f \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  1  ,     (  ( BaseClassTests . ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \" Integer . valueOf (  1  )  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  1  ,     (  ( BaseClassTests . ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =     1  ;    i \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  1  ,     (  ( BaseClassTests . ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =    Integer . valueOf (  1  )  ;    i \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  2  ,     (  ( BaseClassTests . ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \"  1     +     1  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "String   debug    =    Debugger . toString ( BaseClassTests . ReturnsPrimitiveInt . class ,     \"  1  \"  ,    new   CompilerSettings (  )  )  ;", "assertThat ( debug ,    containsString (  \" ICONST _  1  \"  )  )  ;", "assertThat ( debug ,    containsString (  \" IRETURN \"  )  )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \"  1 L \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ long ]    to    [ int ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1 f \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ float ]    to    [ int ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \"  1  .  1 d \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ double ]    to    [ int ]  .  \"  ,    e . getMessage (  )  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =     1 L ;    i \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =     1  .  1 f ;    i \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     (  ( ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \" def   i    =     1  .  1 d ;    i \"  ,    emptyMap (  )  )  )  )  . execute (  )  )  ;", "assertEquals (  0  ,     (  ( BaseClassTests . ReturnsPrimitiveInt )     ( scriptEngine . compile ( compiler ,    null ,     \" int   i    =     0  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnsPrimitiveInt"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . ReturnsVoid . class ,    definition )  ;", "Map < String ,    Object >    map    =    new   HashMap <  >  (  )  ;", "(  ( BaseClassTests . ReturnsVoid )     ( scriptEngine . compile ( compiler ,    null ,     \" map . a    =     ' foo '  \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( map )  ;", "assertEquals ( Collections . singletonMap (  \" a \"  ,     \" foo \"  )  ,    map )  ;", "(  ( BaseClassTests . ReturnsVoid )     ( scriptEngine . compile ( compiler ,    null ,     \" map . remove (  ' a '  )  \"  ,    Collections . emptyMap (  )  )  )  )  . execute ( map )  ;", "assertEquals ( Collections . emptyMap (  )  ,    map )  ;", "String   debug    =    Debugger . toString ( BaseClassTests . ReturnsVoid . class ,     \" int   i    =     0  \"  ,    new   CompilerSettings (  )  )  ;", "assertThat ( debug ,    containsString (  \"    RETURN \"  )  )  ;", "assertThat ( debug ,    not ( containsString (  \" ACONST _ NULL \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnsVoid"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . TwoExecuteMethods . class ,    definition )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >    scriptEngine . compile ( compiler ,    null ,     \" null \"  ,    emptyMap (  )  )  )  ;", "assertEquals (  (  (  \" Painless   can   only   implement   interfaces   that   have   a   single   method   named    [ execute ]    but    [  \"     +     ( BaseClassTests . TwoExecuteMethods . class . getName (  )  )  )     +     \"  ]    has   more   than   one .  \"  )  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testTwoExecuteMethods"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . UnknownArgType . class ,    definition )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >    scriptEngine . compile ( compiler ,    null ,     \"  1  \"  ,    emptyMap (  )  )  )  ;", "assertEquals (  (  (  (  \"  [ foo ]    is   of   unknown   type    [  \"     +     ( BaseClassTests . UnknownArgType . class . getName (  )  )  )     +     \"  .    Painless   interfaces   can   only   accept   arguments    \"  )     +     \" that   are   of   whitelisted   types .  \"  )  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnknownArgType"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . UnknownArgTypeInArray . class ,    definition )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >    scriptEngine . compile ( compiler ,    null ,     \"  1  \"  ,    emptyMap (  )  )  )  ;", "assertEquals (  (  (  (  \"  [ foo ]    is   of   unknown   type    [  \"     +     ( BaseClassTests . UnknownArgTypeInArray . class . getName (  )  )  )     +     \"  .    Painless   interfaces   can   only   accept    \"  )     +     \" arguments   that   are   of   whitelisted   types .  \"  )  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnknownArgTypeInArray"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . UnknownReturnType . class ,    definition )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >    scriptEngine . compile ( compiler ,    null ,     \"  1  \"  ,    emptyMap (  )  )  )  ;", "assertEquals (  (  (  (  (  \" Painless   can   only   implement   execute   methods   returning   a   whitelisted   type   but    [  \"     +     ( BaseClassTests . UnknownReturnType . class . getName (  )  )  )     +     \"  # execute ]    returns    [  \"  )     +     ( BaseClassTests . UnknownReturnType . class . getName (  )  )  )     +     \"  ]    which   isn ' t   whitelisted .  \"  )  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnknownReturnType"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . VarargTest . class ,    definition )  ;", "assertEquals (  \" foo   bar   baz \"  ,     (  ( BaseClassTests . VarargTest )     ( scriptEngine . compile ( compiler ,    null ,     \" String . join (  '     '  ,    Arrays . asList ( arg )  )  \"  ,    Collections . emptyMap (  )  )  )  )  . execute (  \" foo \"  ,     \" bar \"  ,     \" baz \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testVararg"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . WrongArgumentsConstant . class ,    definition )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >    scriptEngine . compile ( compiler ,    null ,     \"  1  \"  ,    emptyMap (  )  )  )  ;", "assertThat ( e . getMessage (  )  ,    startsWith (  (  (  (  \" Painless   needs   a   constant    [ String [  ]    PARAMETERS ]    on   all   interfaces   it   implements   with   the    \"     +     \" names   of   the   method   arguments   but    [  \"  )     +     ( BaseClassTests . WrongArgumentsConstant . class . getName (  )  )  )     +     \"  ]    doesn ' t   have   one .  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongArgumentsConstant"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "Compiler   compiler    =    new   Compiler ( BaseClassTests . WrongLengthOfArgumentConstant . class ,    definition )  ;", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >    scriptEngine . compile ( compiler ,    null ,     \"  1  \"  ,    emptyMap (  )  )  )  ;", "assertThat ( e . getMessage (  )  ,    startsWith (  (  (  (  (  \"  [  \"     +     ( BaseClassTests . WrongLengthOfArgumentConstant . class . getName (  )  )  )     +     \"  # ARGUMENTS ]    has   length    [  2  ]    but    [  \"  )     +     ( BaseClassTests . WrongLengthOfArgumentConstant . class . getName (  )  )  )     +     \"  # execute ]    takes    [  1  ]    argument .  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongLengthOfArgumentConstant"], "fileName": "org.elasticsearch.painless.BaseClassTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" int   x ;    def   y    =     2  .  0  ;    x    =     ( int ) y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefAssignments"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" Map   map    =    new   HashMap (  )  ;    return   map . getOrDefault (  5  ,  1  )  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   map    =    new   HashMap (  )  ;    return   map . getOrDefault (  5  ,  1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInterfaceDefaultMethods"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  {  }  \"  ,    exec (  \" Map   map    =    new   HashMap (  )  ;    return   map . toString (  )  ;  \"  )  )  ;", "assertEquals (  \"  {  }  \"  ,    exec (  \" def   map    =    new   HashMap (  )  ;    return   map . toString (  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInterfacesHaveObject"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =    true \"  ,     \" INVOKESTATIC   java / lang / Boolean . valueOf    ( Z ) Ljava / lang / Boolean ;  \"  )  ;", "assertBytecodeExists (  \" def   x    =     ( byte )  1  \"  ,     \" INVOKESTATIC   java / lang / Byte . valueOf    ( B ) Ljava / lang / Byte ;  \"  )  ;", "assertBytecodeExists (  \" def   x    =     ( short )  1  \"  ,     \" INVOKESTATIC   java / lang / Short . valueOf    ( S ) Ljava / lang / Short ;  \"  )  ;", "assertBytecodeExists (  \" def   x    =     ( char )  1  \"  ,     \" INVOKESTATIC   java / lang / Character . valueOf    ( C ) Ljava / lang / Character ;  \"  )  ;", "assertBytecodeExists (  \" def   x    =     1  \"  ,     \" INVOKESTATIC   java / lang / Integer . valueOf    ( I ) Ljava / lang / Integer ;  \"  )  ;", "assertBytecodeExists (  \" def   x    =     1 L \"  ,     \" INVOKESTATIC   java / lang / Long . valueOf    ( J ) Ljava / lang / Long ;  \"  )  ;", "assertBytecodeExists (  \" def   x    =     1 F \"  ,     \" INVOKESTATIC   java / lang / Float . valueOf    ( F ) Ljava / lang / Float ;  \"  )  ;", "assertBytecodeExists (  \" def   x    =     1 D \"  ,     \" INVOKESTATIC   java / lang / Double . valueOf    ( D ) Ljava / lang / Double ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testInternalBoxing"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" def   x    =    new   ArrayList (  )  ;    x . add (  5  )  ;    return   x . length \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =    new   ArrayList (  )  ;    x . add (  5  )  ;    return   x [  0  ]  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" List   x    =    new   ArrayList (  )  ;    x . add (  ' Hallo '  )  ;    return   x . length \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testListAsArray"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =    new   ArrayList (  )  ;    return   x . empty ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    return   x . empty ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testListEmpty"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" def   x    =    new   ArrayList (  )  ;    x . add (  5  )  ;    return   x . get (  0  )  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =    new   ArrayList (  )  ;    x . add (  5  )  ;    def   index    =     0  ;    return   x . get ( index )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testListGet"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  3  ,    exec (  (  \" List   x    =    new   ArrayList (  )  ;    x . add (  2  )  ;    x . add (  3  )  ;    x . add (  -  2  )  ;    Iterator   y    =    x . iterator (  )  ;     \"     +     \" int   total    =     0  ;    while    ( y . hasNext (  )  )    total    +  =    y . next (  )  ;    return   total ;  \"  )  )  )  ;", "assertEquals (  \" abc \"  ,    exec (  (  \" List   x    =    new   ArrayList (  )  ;    x . add (  \\  \" a \\  \"  )  ;    x . add (  \\  \" b \\  \"  )  ;    x . add (  \\  \" c \\  \"  )  ;     \"     +     \" Iterator   y    =    x . iterator (  )  ;    String   total    =     \\  \"  \\  \"  ;    while    ( y . hasNext (  )  )    total    +  =    y . next (  )  ;    return   total ;  \"  )  )  )  ;", "assertEquals (  3  ,    exec (  (  \" def   x    =    new   ArrayList (  )  ;    x . add (  2  )  ;    x . add (  3  )  ;    x . add (  -  2  )  ;    def   y    =    x . iterator (  )  ;     \"     +     \" def   total    =     0  ;    while    ( y . hasNext (  )  )    total    +  =    y . next (  )  ;    return   total ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testListIterator"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" def   x    =    new   ArrayList (  )  ;    x . add (  3  )  ;    x .  0     =     5  ;    return   x .  0  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =    new   ArrayList (  )  ;    x . add (  3  )  ;    x [  0  ]     =     5  ;    return   x [  0  ]  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testListLoadStore"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  3  ,    exec (  (  \" Map   x    =    new   HashMap (  )  ;    x . put (  2  ,     2  )  ;    x . put (  3  ,     3  )  ;    x . put (  -  2  ,     -  2  )  ;    Iterator   y    =    x . keySet (  )  . iterator (  )  ;     \"     +     \" int   total    =     0  ;    while    ( y . hasNext (  )  )    total    +  =     ( int ) y . next (  )  ;    return   total ;  \"  )  )  )  ;", "assertEquals (  3  ,    exec (  (  \" Map   x    =    new   HashMap (  )  ;    x . put (  2  ,     2  )  ;    x . put (  3  ,     3  )  ;    x . put (  -  2  ,     -  2  )  ;    Iterator   y    =    x . values (  )  . iterator (  )  ;     \"     +     \" int   total    =     0  ;    while    ( y . hasNext (  )  )    total    +  =     ( int ) y . next (  )  ;    return   total ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testMapIterator"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . abc    =     5  ;    return   x . abc ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =    new   HashMap (  )  ;    x [  ' abc '  ]     =     5  ;    return   x [  ' abc '  ]  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMapLoadStore"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" int   x    =     5  ;    return   x . intValue (  )  ;  \"  )  )  ;", "assertEquals (  \"  5  \"  ,    exec (  \" int   x    =     5  ;    return   x . toString (  )  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     5  ;    return   x . compareTo (  5  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitivesHaveMethods"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  (  \" FeatureTest   ft    =    new   FeatureTest (  )  ;  \"     +     \" ft . z    =     5  ;    return   ft . z ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPublicMemberAccess"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  3  ,    exec (  (  \" Set   x    =    new   HashSet (  )  ;    x . add (  2  )  ;    x . add (  3  )  ;    x . add (  -  2  )  ;    Iterator   y    =    x . iterator (  )  ;     \"     +     \" int   total    =     0  ;    while    ( y . hasNext (  )  )    total    +  =    y . next (  )  ;    return   total ;  \"  )  )  )  ;", "assertEquals (  \" abc \"  ,    exec (  (  \" Set   x    =    new   HashSet (  )  ;    x . add (  \\  \" a \\  \"  )  ;    x . add (  \\  \" b \\  \"  )  ;    x . add (  \\  \" c \\  \"  )  ;     \"     +     \" Iterator   y    =    x . iterator (  )  ;    String   total    =     \\  \"  \\  \"  ;    while    ( y . hasNext (  )  )    total    +  =    y . next (  )  ;    return   total ;  \"  )  )  )  ;", "assertEquals (  3  ,    exec (  (  \" def   x    =    new   HashSet (  )  ;    x . add (  2  )  ;    x . add (  3  )  ;    x . add (  -  2  )  ;    def   y    =    x . iterator (  )  ;     \"     +     \" def   total    =     0  ;    while    ( y . hasNext (  )  )    total    +  =     ( int ) y . next (  )  ;    return   total ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSetIterator"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    load    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >     _ source    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    ctx    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    params    =    new   HashMap <  >  (  )  ;", "load . put (  \" load 5  \"  ,     \" tvalue \"  )  ;", "_ source . put (  \" load \"  ,    load )  ;", "ctx . put (  \"  _ source \"  ,     _ source )  ;", "params . put (  \" ctx \"  ,    ctx )  ;", "assertEquals (  \" tvalue \"  ,    exec (  \" ctx .  _ source [  ' load '  ]  .  5     =    ctx .  _ source [  ' load '  ]  . remove (  ' load 5  '  )  \"  ,    params ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testUpdateMapLoadStore"], "fileName": "org.elasticsearch.painless.BasicAPITests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >    exec ( script )  )  ;", "assertEquals (  \" Result   of   null   safe   operator   must   be   nullable \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertMustBeNullable"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return   true    &  &    true ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   a    =    true ,    b    =    false ;    return   a    &  &    b ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return   true    |  |    true ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   a    =    true ,    b    =    false ;    return   a    |  |    b ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBool"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  \" return   params . get (  \\  \" x \\  \"  )  ;  \"  ,    Collections . singletonMap (  \" x \"  ,     4  )  ,    true )  )  ;", "assertEquals (  4  ,    exec (  \" int   y    =    params . get (  \\  \" x \\  \"  )  ;    return   y ;  \"  ,    Collections . singletonMap (  \" x \"  ,     4  )  ,    true )  )  ;", "assertEquals ( true ,    exec (  \" return    5     >    params . get (  \\  \" x \\  \"  )  ;  \"  ,    Collections . singletonMap (  \" x \"  ,     4  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testBoxing"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" return    ( int )  1  .  0  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  0  0  )  )  ,    exec (  \" double   x    =     1  0  0  ;    return    ( byte ) x ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  (  \" Map   x    =    new   HashMap (  )  ;  \\ n \"     +     (  (  \" Object   y    =    x ;  \\ n \"     +     \"  (  ( Map ) y )  . put (  2  ,     3  )  ;  \\ n \"  )     +     \" return   x . get (  2  )  ;  \\ n \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCast"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" aaabbb \"  ,    exec (  \" return    \\  \" aaa \\  \"     +     \\  \" bbb \\  \"  ;  \"  )  )  ;", "assertEquals (  \" aaabbb \"  ,    exec (  \" String   aaa    =     \\  \" aaa \\  \"  ,    bbb    =     \\  \" bbb \\  \"  ;    return   aaa    +    bbb ;  \"  )  )  ;", "assertEquals (  \" aaabbbbbbbbb \"  ,    exec (  (  \" String   aaa    =     \\  \" aaa \\  \"  ,    bbb    =     \\  \" bbb \\  \"  ;    int   x ;  \\ n \"     +     (  (  \" for    (  ;    x    <     3  ;     +  + x )     \\ n \"     +     \"             aaa    +  =    bbb ;  \\ n \"  )     +     \" return   aaa ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCat"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return    2     <     3  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     4  ;    char   y    =     2  ;    return   x    <    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    3     <  =     3  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     3  ;    char   y    =     3  ;    return   x    <  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    2     >     3  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     4  ;    long   y    =     2  ;    return   x    >    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    3     >  =     4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     3  ;    float   y    =     3  ;    return   x    >  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    3     =  =     4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     3  ;    float   y    =     3  ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    3     !  =     4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" double   x    =     3  ;    float   y    =     3  ;    return   x    !  =    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testComp"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" int   x    =     5  ;    return   x    >     3     ?     1     :     0  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" String   a    =    null ;    return   a    !  =    null    ?     1     :     0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testConditional"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  '  \u00cd_  '  ,    exec (  \" return    ( char )  1  0  0  0  0  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testConstantCharTruncation"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" int   i    =     5  ;    return   i ;  \"  )  )  ;", "assertEquals (  7 L ,    exec (  \" long   l    =     7  ;    return   l ;  \"  )  )  ;", "assertEquals (  7  .  0  ,    exec (  \" double   d    =     7  ;    return   d ;  \"  )  )  ;", "assertEquals (  3  2  .  0 F ,    exec (  \" float   f    =     3  2 F ;    return   f ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  2  5  5  )  )  ,    exec (  \" byte   b    =     ( byte )  2  5  5  ;    return   b ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  5  )  )  ,    exec (  \" short   s    =     ( short )  5  ;    return   s ;  \"  )  )  ;", "assertEquals (  \" string \"  ,    exec (  \" String   s    =     \\  \" string \\  \"  ;    return   s ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   v    =    true ;    return   v ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   v    =    false ;    return   v ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDeclareVariable"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "Exception   exception    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1  .  0  ;    int   y    =    x ;    return   y ;  \"  )  ;", "}  )  ;", "assertTrue ( exception . getMessage (  )  . contains (  \" cannot   be   cast \"  )  )  ;", "exception    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( short )  1  ;    byte   y    =    x ;    return   y ;  \"  )  ;", "}  )  ;", "assertTrue ( exception . getMessage (  )  . contains (  \" cannot   be   cast \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalDefCast"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertNull ( exec (  \" String   a    =    null ;       return   a ?  . toString (  )  \"  )  )  ;", "assertEquals (  \" foo \"  ,    exec (  \" String   a    =     ' foo '  ;    return   a ?  . toString (  )  \"  )  )  ;", "assertNull ( exec (  \" def            a    =    null ;       return   a ?  . toString (  )  \"  )  )  ;", "assertEquals (  \" foo \"  ,    exec (  \" def            a    =     ' foo '  ;    return   a ?  . toString (  )  \"  )  )  ;", "assertMustBeNullable (  \" String   a    =    null ;       return   a ?  . length (  )  \"  )  ;", "assertMustBeNullable (  \" String   a    =     ' foo '  ;    return   a ?  . length (  )  \"  )  ;", "assertNull ( exec (  \" def            a    =    null ;       return   a ?  . length (  )  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" def            a    =     ' foo '  ;    return   a ?  . length (  )  \"  )  )  ;", "assertMustBeNullable (  \" FeatureTest   a    =    null ;    return   a ?  . x \"  )  ;", "assertMustBeNullable (  \" FeatureTest   a    =    new   FeatureTest (  )  ;    return   a ?  . x \"  )  ;", "assertNull ( exec (  \" def            a    =    null ;       return   a ?  . x \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def            a    =    new   FeatureTest (  )  ;    return   a ?  . x \"  )  )  ;", "assertNull ( exec (  \" Map   a    =    null ;                         return   a ?  . toString (  )  \"  )  )  ;", "assertEquals (  \"  {  }  \"  ,    exec (  \" Map   a    =     [  :  ]  ;                            return   a ?  . toString (  )  \"  )  )  ;", "assertNull ( exec (  \" def   a    =    null ;                         return   a ?  . toString (  )  \"  )  )  ;", "assertEquals (  \"  {  }  \"  ,    exec (  \" def   a    =     [  :  ]  ;                            return   a ?  . toString (  )  \"  )  )  ;", "assertMustBeNullable (  \" Map   a    =     [  :  ]  ;       return   a ?  . size (  )  \"  )  ;", "assertMustBeNullable (  \" Map   a    =    null ;    return   a ?  . size (  )  \"  )  ;", "assertNull ( exec (  \" def   a    =    null ;                         return   a ?  . size (  )  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     [  :  ]  ;                            return   a ?  . size (  )  \"  )  )  ;", "assertNull ( exec (  \" Map   a    =    null ;                         return   a ?  . other \"  )  )  ;", "assertEquals (  1  ,    exec (  \" Map   a    =     [  ' other '  :  1  ]  ;    return   a ?  . other \"  )  )  ;", "assertNull ( exec (  \" def   a    =    null ;                         return   a ?  . other \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   a    =     [  ' other '  :  1  ]  ;    return   a ?  . other \"  )  )  ;", "assertMustBeNullable (  \" int [  ]    a    =    null ;                                        return   a ?  . length \"  )  ;", "assertMustBeNullable (  \" int [  ]    a    =    new   int [  ]     {  2  ,     3  }  ;    return   a ?  . length \"  )  ;", "assertNull ( exec (  \" def   a    =    null ;                                              return   a ?  . length \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   a    =    new   int [  ]     {  2  ,     3  }  ;          return   a ?  . length \"  )  )  ;", "FeatureTest   t    =    new   FeatureTest (  )  ;", "assertNull ( exec (  \" Map   a    =     [  ' thing '  :    params . t ]  ;    return   a . other ?  . getX (  )  \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertNull ( exec (  \" Map   a    =     [  ' thing '  :    params . t ]  ;    return   a . other ?  . x \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertNull ( exec (  \" def   a    =     [  ' thing '  :    params . t ]  ;    return   a . other ?  . getX (  )  \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertNull ( exec (  \" def   a    =     [  ' thing '  :    params . t ]  ;    return   a . other ?  . x \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertEquals (  0  ,    exec (  \" Map   a    =     [  ' other '  :    params . t ]  ;    return   a . other ?  . getX (  )  \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertEquals (  0  ,    exec (  \" Map   a    =     [  ' other '  :    params . t ]  ;    return   a . other ?  . x \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     [  ' other '  :    params . t ]  ;    return   a . other ?  . getX (  )  \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     [  ' other '  :    params . t ]  ;    return   a . other ?  . x \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertNull ( exec (  \" Map   a    =     [  ' thing '  :     [  ' cat '  :    params . t ]  ]  ;    return   a . other ?  . cat ?  . getX (  )  \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertNull ( exec (  \" Map   a    =     [  ' thing '  :     [  ' cat '  :    params . t ]  ]  ;    return   a . other ?  . cat ?  . x \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertNull ( exec (  \" def   a    =     [  ' thing '  :     [  ' cat '  :    params . t ]  ]  ;    return   a . other ?  . cat ?  . getX (  )  \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertNull ( exec (  \" def   a    =     [  ' thing '  :     [  ' cat '  :    params . t ]  ]  ;    return   a . other ?  . cat ?  . x \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertEquals (  0  ,    exec (  \" Map   a    =     [  ' other '  :     [  ' cat '  :    params . t ]  ]  ;    return   a . other ?  . cat ?  . getX (  )  \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertEquals (  0  ,    exec (  \" Map   a    =     [  ' other '  :     [  ' cat '  :    params . t ]  ]  ;    return   a . other ?  . cat ?  . x \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     [  ' other '  :     [  ' cat '  :    params . t ]  ]  ;    return   a . other ?  . cat ?  . getX (  )  \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     [  ' other '  :     [  ' cat '  :    params . t ]  ]  ;    return   a . other ?  . cat ?  . x \"  ,    Collections . singletonMap (  \" t \"  ,    t )  ,    true )  )  ;", "assertNull ( exec (  (  \" def   a    =     [  :  ]  ;  \\ n \"     +     (  \" a . missing _ length    =    a . missing ?  . length (  )  ;  \\ n \"     +     \" return   a . missing _ length \"  )  )  ,    true )  )  ;", "assertEquals (  3  ,    exec (  (  \" def   a    =     [  :  ]  ;  \\ n \"     +     (  (  \" a . missing    =     \\  ' foo \\  '  ;  \\ n \"     +     \" a . missing _ length    =    a . missing ?  . length (  )  ;  \\ n \"  )     +     \" return   a . missing _ length \"  )  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testNullSafeDeref"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" int   x    =     5  ;    return    ( x + x )  / x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   t    =    true ,    f    =    false ;    return   t    &  &     ( f    |  |    t )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrecedence"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" return    5  \"  )  )  ;", "assertEquals (  6 L ,    exec (  \" return    6 l \"  )  )  ;", "assertEquals (  7 L ,    exec (  \" return    7 L \"  )  )  ;", "assertEquals (  7  .  0  ,    exec (  \" return    7  .  0  \"  )  )  ;", "assertEquals (  1  8  .  0  ,    exec (  \" return    1  8 d \"  )  )  ;", "assertEquals (  1  9  .  0  ,    exec (  \" return    1  9  .  0 d \"  )  )  ;", "assertEquals (  2  0  .  0  ,    exec (  \" return    2  0 D \"  )  )  ;", "assertEquals (  2  1  .  0  ,    exec (  \" return    2  1  .  0 D \"  )  )  ;", "assertEquals (  3  2  .  0 F ,    exec (  \" return    3  2  .  0 f \"  )  )  ;", "assertEquals (  3  3  .  0 F ,    exec (  \" return    3  3 f \"  )  )  ;", "assertEquals (  3  4  .  0 F ,    exec (  \" return    3  4  .  0 F \"  )  )  ;", "assertEquals (  3  5  .  0 F ,    exec (  \" return    3  5 F \"  )  )  ;", "assertEquals (  (  ( byte )     (  2  5  5  )  )  ,    exec (  \" return    ( byte )  2  5  5  \"  )  )  ;", "assertEquals (  (  ( short )     (  5  )  )  ,    exec (  \" return    ( short )  5  \"  )  )  ;", "assertEquals (  \" string \"  ,    exec (  \" return    \\  \" string \\  \"  \"  )  )  ;", "assertEquals (  \" string \"  ,    exec (  \" return    ' string '  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return   true \"  )  )  ;", "assertEquals ( false ,    exec (  \" return   false \"  )  )  ;", "assertNull ( exec (  \" return   null \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnConstant"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  ' x '  ,    exec (  \" return    ( char )  ' x '  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnConstantChar"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  \\  \\ string \"  ,    exec (  \"  \\  \"  \\  \\  \\  \\ string \\  \"  \"  )  )  ;", "assertEquals (  \"  \\  \\ string \"  ,    exec (  \"  \\  '  \\  \\  \\  \\ string \\  '  \"  )  )  ;", "assertEquals (  \"  \\  \" string \"  ,    exec (  \"  \\  \"  \\  \\  \\  \" string \\  \"  \"  )  )  ;", "Exception   e    =    ScriptCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \"  \\  '  \\  \\  \\  \" string \\  '  \"  ,    false )  )  ;", "assertEquals (  \" unexpected   character    [  \\  '  \\  \\  \\  \"  ]  .    The   only   valid   escape   sequences   in   strings   starting   with    [  \\  '  ]    are    [  \\  \\  \\  \\  ]    and    [  \\  \\  \\  '  ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \"  \\  \"  \\  \\  \\  ' string \\  \"  \"  ,    false )  )  ;", "assertEquals (  \" unexpected   character    [  \\  \"  \\  \\  \\  '  ]  .    The   only   valid   escape   sequences   in   strings   starting   with    [  \\  \"  ]    are    [  \\  \\  \\  \\  ]    and    [  \\  \\  \\  \"  ]  .  \"  ,    e . getMessage (  )  )  ;", "assertEquals (  \"  ' string \"  ,    exec (  \"  \\  '  \\  \\  \\  ' string \\  '  \"  )  )  ;", "assertEquals (  \"  \\ nstring \"  ,    exec (  \"  \\  \"  \\ nstring \\  \"  \"  )  )  ;", "assertEquals (  \"  \\ nstring \"  ,    exec (  \"  \\  '  \\ nstring \\  '  \"  )  )  ;", "assertEquals (  \"  \\  \\ str \\  \" in \\  \\ g \"  ,    exec (  \"  \\  \"  \\  \\  \\  \\ str \\  \\  \\  \" in \\  \\  \\  \\ g \\  \"  \"  )  )  ;", "assertEquals (  \" st \\  \\ r \\  ' i \\  \\ ng \"  ,    exec (  \"  \\  ' st \\  \\  \\  \\ r \\  \\  \\  ' i \\  \\  \\  \\ ng \\  '  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testStringEscapes"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" test '  \"  ,    exec (  \"  \\  \" test \\  '  \\  \"  \"  )  )  ;", "assertEquals (  \" test \\  \"  \"  ,    exec (  \"  \\  ' test \\  \"  \\  '  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testStringTermination"], "fileName": "org.elasticsearch.painless.BasicExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  6  ,    exec (  (  \" int [  ]    a    =    new   int [  3  ]  ;    a [  0  ]     =     1  ;    a [  1  ]     =     2  ;    a [  2  ]     =     3  ;    int   total    =     0  ;  \"     +     \"    for    ( int   x    :    a )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  6  ,    exec (  (  \" int [  ]    a    =    new   int [  3  ]  ;    a [  0  ]     =     1  ;    a [  1  ]     =     2  ;    a [  2  ]     =     3  ;    int   total    =     0  ;  \"     +     \"    for    ( x   in   a )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  \"  1  2  3  \"  ,    exec (  (  \" String [  ]    a    =    new   String [  3  ]  ;    a [  0  ]     =     '  1  '  ;    a [  1  ]     =     '  2  '  ;    a [  2  ]     =     '  3  '  ;    def   total    =     '  '  ;  \"     +     \"    for    ( String   x    :    a )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  \"  1  2  3  \"  ,    exec (  (  \" String [  ]    a    =    new   String [  3  ]  ;    a [  0  ]     =     '  1  '  ;    a [  1  ]     =     '  2  '  ;    a [  2  ]     =     '  3  '  ;    def   total    =     '  '  ;  \"     +     \"    for    ( x   in   a )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  6  ,    exec (  (  \" int [  ]  [  ]    i    =    new   int [  3  ]  [  1  ]  ;    i [  0  ]  [  0  ]     =     1  ;    i [  1  ]  [  0  ]     =     2  ;    i [  2  ]  [  0  ]     =     3  ;    int   total    =     0  ;  \"     +     \"    for    ( int [  ]    j    :    i )    total    +  =    j [  0  ]  ;    return   total \"  )  )  )  ;", "assertEquals (  6  ,    exec (  (  \" int [  ]  [  ]    i    =    new   int [  3  ]  [  1  ]  ;    i [  0  ]  [  0  ]     =     1  ;    i [  1  ]  [  0  ]     =     2  ;    i [  2  ]  [  0  ]     =     3  ;    int   total    =     0  ;  \"     +     \"    for    ( j   in   i )    total    +  =    j [  0  ]  ;    return   total \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testArrayForEachStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  6  ,    exec (  (  \" def   a    =    new   int [  3  ]  ;    a [  0  ]     =     1  ;    a [  1  ]     =     2  ;    a [  2  ]     =     3  ;    int   total    =     0  ;  \"     +     \"    for    ( int   x    :    a )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  6  ,    exec (  (  \" def   a    =    new   int [  3  ]  ;    a [  0  ]     =     1  ;    a [  1  ]     =     2  ;    a [  2  ]     =     3  ;    int   total    =     0  ;  \"     +     \"    for    ( x   in   a )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  \"  1  2  3  \"  ,    exec (  (  \" def   a    =    new   String [  3  ]  ;    a [  0  ]     =     '  1  '  ;    a [  1  ]     =     '  2  '  ;    a [  2  ]     =     '  3  '  ;    def   total    =     '  '  ;  \"     +     \"    for    ( String   x    :    a )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  \"  1  2  3  \"  ,    exec (  (  \" def   a    =    new   String [  3  ]  ;    a [  0  ]     =     '  1  '  ;    a [  1  ]     =     '  2  '  ;    a [  2  ]     =     '  3  '  ;    def   total    =     '  '  ;  \"     +     \"    for    ( x   in   a )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  6  ,    exec (  (  \" def   i    =    new   int [  3  ]  [  1  ]  ;    i [  0  ]  [  0  ]     =     1  ;    i [  1  ]  [  0  ]     =     2  ;    i [  2  ]  [  0  ]     =     3  ;    int   total    =     0  ;  \"     +     \"    for    ( int [  ]    j    :    i )    total    +  =    j [  0  ]  ;    return   total \"  )  )  )  ;", "assertEquals (  6  ,    exec (  (  \" def   i    =    new   int [  3  ]  [  1  ]  ;    i [  0  ]  [  0  ]     =     1  ;    i [  1  ]  [  0  ]     =     2  ;    i [  2  ]  [  0  ]     =     3  ;    int   total    =     0  ;  \"     +     \"    for    ( j   in   i )    total    +  =    j [  0  ]  ;    return   total \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testArrayForEachStatementDef"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  6 L ,    exec (  (  \" long   sum    =     0  ;    long [  ]    array    =    new   long [  ]     {     1  ,     2  ,     3     }  ;  \"     +     \" for    ( int   i    =     0  ;    i    <    array . length ;    i +  +  )     {    sum    +  =    array [ i ]     }    return   sum \"  )  ,    Collections . emptyMap (  )  ,    Collections . singletonMap ( CompilerSettings . MAX _ LOOP _ COUNTER ,     \"  0  \"  )  ,    null ,    true )  )  ;", "assertEquals (  6 L ,    exec (  (  \" long   sum    =     0  ;    long [  ]    array    =    new   long [  ]     {     1  ,     2  ,     3     }  ;  \"     +     \" int   i    =     0  ;    while    ( i    <    array . length )     {    sum    +  =    array [ i +  +  ]     }    return   sum \"  )  ,    Collections . emptyMap (  )  ,    Collections . singletonMap ( CompilerSettings . MAX _ LOOP _ COUNTER ,     \"  0  \"  )  ,    null ,    true )  )  ;", "assertEquals (  6 L ,    exec (  (  \" long   sum    =     0  ;    long [  ]    array    =    new   long [  ]     {     1  ,     2  ,     3     }  ;  \"     +     \" int   i    =     0  ;    do    {    sum    +  =    array [ i +  +  ]     }    while    ( i    <    array . length )  ;    return   sum \"  )  ,    Collections . emptyMap (  )  ,    Collections . singletonMap ( CompilerSettings . MAX _ LOOP _ COUNTER ,     \"  0  \"  )  ,    null ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testArrayLoopWithoutCounter"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  \" int   x    =     0  ,    y    =     0  ;    while    ( x    <     1  0  )     {     +  + x ;    if    ( x    =  =     5  )    break ;     +  + y ;     }    return   y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBreakStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  9  ,    exec (  \" int   x    =     0  ,    y    =     0  ;    while    ( x    <     1  0  )     {     +  + x ;    if    ( x    =  =     1  )    continue ;     +  + y ;     }    return   y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testContinueStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  2  )  )  ,    exec (  \" byte   a    =     2  ;    return   a ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  2  )  )  ,    exec (  \" short   a    =     2  ;    return   a ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  2  )  )  ,    exec (  \" char   a    =     2  ;    return   a ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   a    =     2  ;    return   a ;  \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   a    =     2  ;    return   a ;  \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" float   a    =     2  ;    return   a ;  \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" double   a    =     2  ;    return   a ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   a    =    false ;    return   a ;  \"  )  )  ;", "assertEquals (  \" string \"  ,    exec (  \" String   a    =     \\  \" string \\  \"  ;    return   a ;  \"  )  )  ;", "assertEquals ( HashMap . cs ,    exec (  \" Map   a    =    new   HashMap (  )  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( byte [  ]  . cs ,    exec (  \" byte [  ]    a    =    new   byte [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( short [  ]  . cs ,    exec (  \" short [  ]    a    =    new   short [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( char [  ]  . cs ,    exec (  \" char [  ]    a    =    new   char [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( int [  ]  . cs ,    exec (  \" int [  ]    a    =    new   int [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( long [  ]  . cs ,    exec (  \" long [  ]    a    =    new   long [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( float [  ]  . cs ,    exec (  \" float [  ]    a    =    new   float [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( double [  ]  . cs ,    exec (  \" double [  ]    a    =    new   double [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( boolean [  ]  . cs ,    exec (  \" boolean [  ]    a    =    new   boolean [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( String [  ]  . cs ,    exec (  \" String [  ]    a    =    new   String [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( Map [  ]  . cs ,    exec (  \" Map [  ]    a    =    new   Map [  1  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( byte [  ]  [  ]  . cs ,    exec (  \" byte [  ]  [  ]    a    =    new   byte [  1  ]  [  2  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( short [  ]  [  ]  [  ]  . cs ,    exec (  \" short [  ]  [  ]  [  ]    a    =    new   short [  1  ]  [  2  ]  [  3  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( char [  ]  [  ]  [  ]  [  ]  . cs ,    exec (  \" char [  ]  [  ]  [  ]  [  ]    a    =    new   char [  1  ]  [  2  ]  [  3  ]  [  4  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( int [  ]  [  ]  [  ]  [  ]  [  ]  . cs ,    exec (  \" int [  ]  [  ]  [  ]  [  ]  [  ]    a    =    new   int [  1  ]  [  2  ]  [  3  ]  [  4  ]  [  5  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( long [  ]  [  ]  . cs ,    exec (  \" long [  ]  [  ]    a    =    new   long [  1  ]  [  2  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( float [  ]  [  ]  [  ]  . cs ,    exec (  \" float [  ]  [  ]  [  ]    a    =    new   float [  1  ]  [  2  ]  [  3  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( double [  ]  [  ]  [  ]  [  ]  . cs ,    exec (  \" double [  ]  [  ]  [  ]  [  ]    a    =    new   double [  1  ]  [  2  ]  [  3  ]  [  4  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( boolean [  ]  [  ]  [  ]  [  ]  [  ]  . cs ,    exec (  \" boolean [  ]  [  ]  [  ]  [  ]  [  ]    a    =    new   boolean [  1  ]  [  2  ]  [  3  ]  [  4  ]  [  5  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( String [  ]  [  ]  . cs ,    exec (  \" String [  ]  [  ]    a    =    new   String [  1  ]  [  2  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "assertEquals ( Map [  ]  [  ]  [  ]  . cs ,    exec (  \" Map [  ]  [  ]  [  ]    a    =    new   Map [  1  ]  [  2  ]  [  3  ]  ;    return   a ;  \"  )  . getCs (  )  )  ;", "}", "METHOD_END"], "methodName": ["testDeclarationStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" aaaaaa \"  ,    exec (  \" String   c    =     \\  \" a \\  \"  ;    int   x ;    do    {    c    +  =     \\  \" a \\  \"  ;     +  + x ;     }    while    ( x    <     5  )  ;    return   c ;  \"  )  )  ;", "Object   value    =    exec (  (  \"    int [  ]  [  ]    b    =    new   int [  5  ]  [  5  ]  ;     \\ n \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  \"    int   x    =     0  ,    y ;                                                              \\ n \"     +     \"                                                                                                        \\ n \"  )     +     \"    do    {                                                                                         \\ n \"  )     +     \"                y    =     0  ;                                                                       \\ n \"  )     +     \"                                                                                                        \\ n \"  )     +     \"                do    {                                                                             \\ n \"  )     +     \"                            b [ x ]  [ y ]     =    x * y ;                                   \\ n \"  )     +     \"                             +  + y ;                                                                 \\ n \"  )     +     \"                 }    while    ( y    <     5  )  ;                                         \\ n \"  )     +     \"                                                                                                        \\ n \"  )     +     \"                 +  + x ;                                                                             \\ n \"  )     +     \"     }    while    ( x    <     5  )  ;                                                     \\ n \"  )     +     \"                                                                                                        \\ n \"  )     +     \"    return   b ;                                                                          \\ n \"  )  )  )  ;", "int [  ]  [  ]    b    =     (  ( int [  ]  [  ]  )     ( value )  )  ;", "for    ( byte   x    =     0  ;    x    <     5  ;     +  + x )     {", "for    ( byte   y    =     0  ;    y    <     5  ;     +  + y )     {", "assertEquals (  ( x    *    y )  ,    b [ x ]  [ y ]  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testDoWhileStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  (  \" Map   settings    =     [  ' test 1  '     :     '  1  '  ]  ;  \"     +     (  (  (  (  (  (  (  (  \" int   i    =     0  ;  \"     +     \" List   keys    =     [  ' test 0  '  ,     ' test 1  '  ,     ' test 2  '  ]  ;  \"  )     +     \" for    ( String   key    :    keys )     {  \"  )     +     \"             if    ( settings . containsKey ( key )  )     {  \"  )     +     \"                         break ;  \"  )     +     \"              }  \"  )     +     \"              +  + i ;  \"  )     +     \"  }  \"  )     +     \" return   i ;  \"  )  )  )  )  ;", "List < Integer >    expected    =    new   ArrayList <  >  (  )  ;", "expected . add (  1  )  ;", "expected . add (  0  )  ;", "assertEquals ( expected ,    exec (  (  \" Map   outer    =     [  ' test 1  '     :     '  1  '  ]  ;  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" Map   inner    =     [  ' test 0  '     :     '  2  '  ]  ;  \"     +     \" int   i    =     0  ,    j    =     0  ;  \"  )     +     \" boolean   found    =    false ;  \"  )     +     \" List   keys    =     [  ' test 0  '  ,     ' test 1  '  ,     ' test 2  '  ]  ;  \"  )     +     \" for    ( String   okey    :    keys )     {  \"  )     +     \"             if    ( outer . containsKey ( okey )  )     {  \"  )     +     \"                         for    ( String   ikey    :    keys )     {  \"  )     +     \"                                     if    ( inner . containsKey ( ikey )  )     {  \"  )     +     \"                                                 found    =    true ;  \"  )     +     \"                                                 break ;  \"  )     +     \"                                      }  \"  )     +     \"                                      +  + j ;  \"  )     +     \"                          }  \"  )     +     \"                         if    ( found )     {  \"  )     +     \"                                     break ;  \"  )     +     \"                          }  \"  )     +     \"              }  \"  )     +     \"              +  + i ;  \"  )     +     \"  }  \"  )     +     \"  [ i ,    j ]  ;  \"  )  )  )  )  ;", "expected . set (  0  ,     3  )  ;", "expected . set (  1  ,     1  )  ;", "assertEquals ( expected ,    exec (  (  \" Map   outer    =     [  ' test 1  '     :     '  1  '  ]  ;  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" Map   inner    =     [  ' test 1  '     :     '  1  '  ]  ;  \"     +     \" int   i    =     0  ,    j    =     0  ;  \"  )     +     \" boolean   found    =    false ;  \"  )     +     \" List   keys    =     [  ' test 0  '  ,     ' test 1  '  ,     ' test 2  '  ]  ;  \"  )     +     \" for    ( String   okey    :    keys )     {  \"  )     +     \"             if    ( outer . containsKey ( okey )  )     {  \"  )     +     \"                         for    ( String   ikey    :    keys )     {  \"  )     +     \"                                     if    ( inner . containsKey ( ikey )  )     {  \"  )     +     \"                                                 break ;  \"  )     +     \"                                      }  \"  )     +     \"                                      +  + j ;  \"  )     +     \"                          }  \"  )     +     \"                         if    ( found )     {  \"  )     +     \"                                     break ;  \"  )     +     \"                          }  \"  )     +     \"              }  \"  )     +     \"              +  + i ;  \"  )     +     \"  }  \"  )     +     \"  [ i ,    j ]  ;  \"  )  )  )  )  ;", "expected . set (  0  ,     1  )  ;", "expected . set (  1  ,     3  )  ;", "assertEquals ( expected ,    exec (  (  \" Map   outer    =     [  ' test 1  '     :     '  1  '  ]  ;  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" Map   inner    =     [  ' test 1  '     :     '  1  '  ]  ;  \"     +     \" int   i    =     0  ,    j    =     0  ;  \"  )     +     \" boolean   found    =    false ;  \"  )     +     \" List   keys    =     [  ' test 0  '  ,     ' test 1  '  ,     ' test 2  '  ]  ;  \"  )     +     \" for    ( String   okey    :    keys )     {  \"  )     +     \"             if    ( outer . containsKey ( okey )  )     {  \"  )     +     \"                         for    ( String   ikey    :    keys )     {  \"  )     +     \"                                     if    ( found )     {  \"  )     +     \"                                                 break ;  \"  )     +     \"                                      }  \"  )     +     \"                                      +  + j ;  \"  )     +     \"                          }  \"  )     +     \"                         found    =    true ;  \"  )     +     \"                         if    ( found )     {  \"  )     +     \"                                     break ;  \"  )     +     \"                          }  \"  )     +     \"              }  \"  )     +     \"              +  + i ;  \"  )     +     \"  }  \"  )     +     \"  [ i ,    j ]  ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testForEachWithBreak"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  6  ,    exec (  \" int   x ,    y ;    for    ( x    =     0  ;    x    <     4  ;     +  + x )     { y    +  =    x ;  }    return   y ;  \"  )  )  ;", "assertEquals (  \" aaaaaa \"  ,    exec (  \" String   c    =     \\  \" a \\  \"  ;    for    ( int   x    =     0  ;    x    <     5  ;     +  + x )    c    +  =     \\  \" a \\  \"  ;    return   c ;  \"  )  )  ;", "assertEquals (  6  ,    exec (  (  \" double   t (  )     {    return    0  .  0  ;     }  \"     +     \" int   x ,    y ;    for    ( t (  )  ;    x    <     4  ;    t (  )  )     { y    +  =    x ;     +  + x ;  }    return   y ;  \"  )  )  )  ;", "Object   value    =    exec (  (  \"    int [  ]  [  ]    b    =    new   int [  5  ]  [  5  ]  ;        \\ n \"     +     (  (  (  (  (  (  \"    for    ( int   x    =     0  ;    x    <     5  ;     +  + x )     {                 \\ n \"     +     \"                for    ( int   y    =     0  ;    y    <     5  ;     +  + y )     {     \\ n \"  )     +     \"                            b [ x ]  [ y ]     =    x * y ;                                      \\ n \"  )     +     \"                 }                                                                                         \\ n \"  )     +     \"     }                                                                                                     \\ n \"  )     +     \"                                                                                                           \\ n \"  )     +     \"    return   b ;                                                                             \\ n \"  )  )  )  ;", "int [  ]  [  ]    b    =     (  ( int [  ]  [  ]  )     ( value )  )  ;", "for    ( byte   x    =     0  ;    x    <     5  ;     +  + x )     {", "for    ( byte   y    =     0  ;    y    <     5  ;     +  + y )     {", "assertEquals (  ( x    *    y )  ,    b [ x ]  [ y ]  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testForStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  (  \" Map   settings    =     [  ' test 1  '     :     '  1  '  ]  ;  \"     +     (  (  (  (  (  (  (  \" int   i    =     0  ;  \"     +     \" List   keys    =     [  ' test 0  '  ,     ' test 1  '  ,     ' test 2  '  ]  ;  \"  )     +     \" for    (  ;    i    <    keys . size (  )  ;     +  + i )     {  \"  )     +     \"             if    ( settings . containsKey ( keys [ i ]  )  )     {  \"  )     +     \"                         break ;  \"  )     +     \"              }  \"  )     +     \"  }  \"  )     +     \" return   i ;  \"  )  )  )  )  ;", "List < Integer >    expected    =    new   ArrayList <  >  (  )  ;", "expected . add (  1  )  ;", "expected . add (  0  )  ;", "assertEquals ( expected ,    exec (  (  \" Map   outer    =     [  ' test 1  '     :     '  1  '  ]  ;  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" Map   inner    =     [  ' test 0  '     :     '  2  '  ]  ;  \"     +     \" boolean   found    =    false ;  \"  )     +     \" int   i    =     0  ,    j    =     0  ;  \"  )     +     \" List   keys    =     [  ' test 0  '  ,     ' test 1  '  ,     ' test 2  '  ]  ;  \"  )     +     \" for    (  ;    i    <    keys . size (  )  ;     +  + i )     {  \"  )     +     \"             if    ( outer . containsKey ( keys [ i ]  )  )     {  \"  )     +     \"                         for    (  ;    j    <    keys . size (  )  ;     +  + j )     {  \"  )     +     \"                                     if    ( inner . containsKey ( keys [ j ]  )  )     {  \"  )     +     \"                                                 found    =    true ;  \"  )     +     \"                                                 break ;  \"  )     +     \"                                      }  \"  )     +     \"                          }  \"  )     +     \"                         if    ( found )     {  \"  )     +     \"                                     break ;  \"  )     +     \"                          }  \"  )     +     \"              }  \"  )     +     \"  }  \"  )     +     \"  [ i ,    j ]  ;  \"  )  )  )  )  ;", "expected . set (  1  ,     3  )  ;", "assertEquals ( expected ,    exec (  (  \" Map   outer    =     [  ' test 1  '     :     '  1  '  ]  ;  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" Map   inner    =     [  ' test 3  '     :     '  2  '  ]  ;  \"     +     \" int   i    =     0  ,    j    =     0  ;  \"  )     +     \" boolean   found    =    false ;  \"  )     +     \" List   keys    =     [  ' test 0  '  ,     ' test 1  '  ,     ' test 2  '  ]  ;  \"  )     +     \" for    (  ;    i    <    keys . size (  )  ;     +  + i )     {  \"  )     +     \"             if    ( outer . containsKey ( keys [ i ]  )  )     {  \"  )     +     \"                         for    (  ;    j    <    keys . size (  )  ;     +  + j )     {  \"  )     +     \"                                     if    ( found )     {  \"  )     +     \"                                                 break ;  \"  )     +     \"                                      }  \"  )     +     \"                          }  \"  )     +     \"                         found    =    true ;  \"  )     +     \"                         if    ( found )     {  \"  )     +     \"                                     break ;  \"  )     +     \"                          }  \"  )     +     \"              }  \"  )     +     \"  }  \"  )     +     \"  [ i ,    j ]  ;  \"  )  )  )  )  ;", "expected . set (  0  ,     3  )  ;", "expected . set (  1  ,     1  )  ;", "assertEquals ( expected ,    exec (  (  \" Map   outer    =     [  ' test 3  '     :     '  1  '  ]  ;  \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" Map   inner    =     [  ' test 1  '     :     '  2  '  ]  ;  \"     +     \" int   i    =     0  ,    j    =     0  ;  \"  )     +     \" boolean   found    =    false ;  \"  )     +     \" List   keys    =     [  ' test 0  '  ,     ' test 1  '  ,     ' test 2  '  ]  ;  \"  )     +     \" for    (  ;    i    <    keys . size (  )  ;     +  + i )     {  \"  )     +     \"             if    ( outer . containsKey (  ' test 3  '  )  )     {  \"  )     +     \"                         for    (  ;    j    <    keys . size (  )  ;     +  + j )     {  \"  )     +     \"                                     if    ( inner . containsKey ( keys [ j ]  )  )     {  \"  )     +     \"                                                 break ;  \"  )     +     \"                                      }  \"  )     +     \"                          }  \"  )     +     \"                         if    ( found )     {  \"  )     +     \"                                     break ;  \"  )     +     \"                          }  \"  )     +     \"              }  \"  )     +     \"  }  \"  )     +     \"  [ i ,    j ]  ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testForWithBreak"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" int   x    =     5  ;    if    ( x    =  =     5  )    return    1  ;    return    0  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     4  ;    if    ( x    =  =     5  )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     4  ;    if    ( x    =  =     5  )    return    1  ;    else   if    ( x    =  =     4  )    return    2  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" int   x    =     4  ;    if    ( x    =  =     5  )    return    1  ;    else   if    ( x    =  =     4  )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  (  \" int   x    =     5  ;  \\ n \"     +     (  (  (  (  (  (  (  (  (  \" if    ( x    =  =     5  )     {  \\ n \"     +     \"             int   y    =     2  ;  \\ n \"  )     +     \"              \\ n \"  )     +     \"             if    ( y    =  =     2  )     {  \\ n \"  )     +     \"                         x    =     3  ;  \\ n \"  )     +     \"              }  \\ n \"  )     +     \"              \\ n \"  )     +     \"  }  \\ n \"  )     +     \"  \\ n \"  )     +     \" return   x ;  \\ n \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testIfStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  6  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    l . add (  3  )  ;    int   total    =     0  ;  \"     +     \"    for    ( int   x    :    l )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  6  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    l . add (  3  )  ;    int   total    =     0  ;  \"     +     \"    for    ( x   in   l )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  \"  1  2  3  \"  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  '  1  '  )  ;    l . add (  '  2  '  )  ;    l . add (  '  3  '  )  ;    String   cat    =     '  '  ;  \"     +     \"    for    ( String   x    :    l )    cat    +  =    x ;    return   cat \"  )  )  )  ;", "assertEquals (  \"  1  2  3  \"  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  '  1  '  )  ;    l . add (  '  2  '  )  ;    l . add (  '  3  '  )  ;    String   cat    =     '  '  ;  \"     +     \"    for    ( x   in   l )    cat    +  =    x ;    return   cat \"  )  )  )  ;", "assertEquals (  \"  1  2  3  6  \"  ,    exec (  (  \" Map   m    =    new   HashMap (  )  ;    m . put (  '  1  '  ,     1  )  ;    m . put (  '  2  '  ,     2  )  ;    m . put (  '  3  '  ,     3  )  ;  \"     +     (  \"    String   cat    =     '  '  ;    int   total    =     0  ;  \"     +     \"    for    ( Map . Entry   e    :    m . rySet (  )  )     {    cat    +  =    e . getKey (  )  ;    total    +  =    e . getValue (  )  ;     }    return   cat    +    total \"  )  )  )  )  ;", "assertEquals (  \"  1  2  3  6  \"  ,    exec (  (  \" Map   m    =    new   HashMap (  )  ;    m . put (  '  1  '  ,     1  )  ;    m . put (  '  2  '  ,     2  )  ;    m . put (  '  3  '  ,     3  )  ;  \"     +     (  \"    String   cat    =     '  '  ;    int   total    =     0  ;  \"     +     \"    for    ( e   in   m . rySet (  )  )     {    cat    +  =    e . getKey (  )  ;    total    +  =    e . getValue (  )  ;     }    return   cat    +    total \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterableForEachStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  6  ,    exec (  (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    l . add (  3  )  ;    int   total    =     0  ;  \"     +     \"    for    ( int   x    :    l )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  6  ,    exec (  (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  2  )  ;    l . add (  3  )  ;    int   total    =     0  ;  \"     +     \"    for    ( x   in   l )    total    +  =    x ;    return   total \"  )  )  )  ;", "assertEquals (  \"  1  2  3  \"  ,    exec (  (  \" def   l    =    new   ArrayList (  )  ;    l . add (  '  1  '  )  ;    l . add (  '  2  '  )  ;    l . add (  '  3  '  )  ;    String   cat    =     '  '  ;  \"     +     \"    for    ( String   x    :    l )    cat    +  =    x ;    return   cat \"  )  )  )  ;", "assertEquals (  \"  1  2  3  \"  ,    exec (  (  \" def   l    =    new   ArrayList (  )  ;    l . add (  '  1  '  )  ;    l . add (  '  2  '  )  ;    l . add (  '  3  '  )  ;    String   cat    =     '  '  ;  \"     +     \"    for    ( x   in   l )    cat    +  =    x ;    return   cat \"  )  )  )  ;", "assertEquals (  \"  1  2  3  6  \"  ,    exec (  (  \" def   m    =    new   HashMap (  )  ;    m . put (  '  1  '  ,     1  )  ;    m . put (  '  2  '  ,     2  )  ;    m . put (  '  3  '  ,     3  )  ;  \"     +     (  \"    String   cat    =     '  '  ;    int   total    =     0  ;  \"     +     \"    for    ( Map . Entry   e    :    m . rySet (  )  )     {    cat    +  =    e . getKey (  )  ;    total    +  =    e . getValue (  )  ;     }    return   cat    +    total \"  )  )  )  )  ;", "assertEquals (  \"  1  2  3  6  \"  ,    exec (  (  \" def   m    =    new   HashMap (  )  ;    m . put (  '  1  '  ,     1  )  ;    m . put (  '  2  '  ,     2  )  ;    m . put (  '  3  '  ,     3  )  ;  \"     +     (  \"    String   cat    =     '  '  ;    int   total    =     0  ;  \"     +     \"    for    ( e   in   m . rySet (  )  )     {    cat    +  =    e . getKey (  )  ;    total    +  =    e . getValue (  )  ;     }    return   cat    +    total \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testIterableForEachStatementDef"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  0  ,    exec (  \" def   i    =     1  ;    if    ( i    =  =     1  )     { return    1  0  }  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \" def   i    =     1  ;    if    ( i    =  =     1  )     { return    1  0  }    else    { return    1  2  }  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \" def   i    =     1  ;    if    ( i    =  =     1  )     { i    =     2  ;    return    1  0  }  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \" def   i    =     1  ;    if    ( i    =  =     1  )     { i    =     2  ;    return    1  0  }    else    { return    1  2  }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLastInBlockDoesntNeedSemi"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  0  ,    exec (  \" return    1  0  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" int   x    =     5  ;    return   x ;  \"  )  )  ;", "assertEquals (  4  ,    exec (  \" int [  ]    x    =    new   int [  2  ]  ;    x [  1  ]     =     4  ;    return   x [  1  ]  ;  \"  )  )  ;", "assertEquals (  5  ,     (  ( short [  ]  )     ( exec (  \" short [  ]    s    =    new   short [  3  ]  ;    s [  1  ]     =     5  ;    return   s ;  \"  )  )  )  [  1  ]  )  ;", "assertEquals (  1  0  ,     (  ( Map )     ( exec (  \" Map   s    =    new   HashMap (  )  ;    s . put (  \\  \" x \\  \"  ,     1  0  )  ;    return   s ;  \"  )  )  )  . get (  \" x \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" aaaaaa \"  ,    exec (  \" String   c    =     \\  \" a \\  \"  ;    int   x ;    while    ( x    <     5  )     {    c    +  =     \\  \" a \\  \"  ;     +  + x ;     }    return   c ;  \"  )  )  ;", "Object   value    =    exec (  (  \"    byte [  ]  [  ]    b    =    new   byte [  5  ]  [  5  ]  ;                       \\ n \"     +     (  (  (  (  (  (  (  (  (  (  (  (  (  \"    byte   x    =     0  ,    y ;                                                                 \\ n \"     +     \"                                                                                                              \\ n \"  )     +     \"    while    ( x    <     5  )     {                                                              \\ n \"  )     +     \"                y    =     0  ;                                                                             \\ n \"  )     +     \"                                                                                                              \\ n \"  )     +     \"                while    ( y    <     5  )     {                                                  \\ n \"  )     +     \"                            b [ x ]  [ y ]     =     ( byte )  ( x * y )  ;                 \\ n \"  )     +     \"                             +  + y ;                                                                       \\ n \"  )     +     \"                 }                                                                                            \\ n \"  )     +     \"                                                                                                              \\ n \"  )     +     \"                 +  + x ;                                                                                   \\ n \"  )     +     \"     }                                                                                                        \\ n \"  )     +     \"                                                                                                              \\ n \"  )     +     \"    return   b ;                                                                                \\ n \"  )  )  )  ;", "byte [  ]  [  ]    b    =     (  ( byte [  ]  [  ]  )     ( value )  )  ;", "for    ( byte   x    =     0  ;    x    <     5  ;     +  + x )     {", "for    ( byte   y    =     0  ;    y    <     5  ;     +  + y )     {", "assertEquals (  ( x    *    y )  ,    b [ x ]  [ y ]  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testWhileStatement"], "fileName": "org.elasticsearch.painless.BasicStatementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" def   x    =     5 L ;    return    (  +  ( int ) x )  ;  \"  )  )  ;", "assertEquals (  6  ,    exec (  \" def   x    =     5  ;    def   y    =     1 L ;    return   x    +     ( int ) y \"  )  )  ;", "assertEquals (  ' b '  ,    exec (  \" def   x    =     ' abcdeg '  ;    def   y    =     1 L ;    x . charAt (  ( int ) y )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testArgumentsDef"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  6  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( byte )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  6  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( short )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  6  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( char )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  6  ,    exec (  \" long   x    =     5 L ;    return    ( int )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  6  .  0 F ,    exec (  \" long   x    =     5 L ;    return    ( float )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  6 L ,    exec (  \" long   x    =     5 L ;    return    ( long )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  6  .  0  ,    exec (  \" long   x    =     5 L ;    return    ( double )     ( x    +  =     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryCompoundAssignment"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  6  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( byte )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  6  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( short )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  6  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( char )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  6  ,    exec (  \" def   x    =     5 L ;    return    ( int )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  6  .  0 F ,    exec (  \" def   x    =     5 L ;    return    ( float )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  6 L ,    exec (  \" def   x    =     5 L ;    return    ( long )     ( x    +  =     1  )  ;  \"  )  )  ;", "assertEquals (  6  .  0  ,    exec (  \" def   x    =     5 L ;    return    ( double )     ( x    +  =     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryCompoundAssignmentDef"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  5  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( byte )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  5  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( short )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  5  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( char )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     5 L ;    return    ( int )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  5  .  0 F ,    exec (  \" def   x    =     5 L ;    return    ( float )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     5 L ;    return    ( long )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  5  .  0  ,    exec (  \" def   x    =     5 L ;    return    ( double )     ( x +  +  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryCompoundAssignmentPostfix"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  6  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( byte )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  6  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( short )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  6  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( char )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  6  ,    exec (  \" def   x    =     5 L ;    return    ( int )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  6  .  0 F ,    exec (  \" def   x    =     5 L ;    return    ( float )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  6 L ,    exec (  \" def   x    =     5 L ;    return    ( long )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  6  .  0  ,    exec (  \" def   x    =     5 L ;    return    ( double )     (  +  + x )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryCompoundAssignmentPrefix"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  6  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( byte )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  6  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( short )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  6  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( char )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  6  ,    exec (  \" long   x    =     5 L ;    return    ( int )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  6  .  0 F ,    exec (  \" long   x    =     5 L ;    return    ( float )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  6 L ,    exec (  \" long   x    =     5 L ;    return    ( long )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  6  .  0  ,    exec (  \" long   x    =     5 L ;    return    ( double )     ( x    +     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryOperator"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  6  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( byte )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  6  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( short )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  6  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( char )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  6  ,    exec (  \" def   x    =     5 L ;    return    ( int )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  6  .  0 F ,    exec (  \" def   x    =     5 L ;    return    ( float )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  6 L ,    exec (  \" def   x    =     5 L ;    return    ( long )     ( x    +     1  )  ;  \"  )  )  ;", "assertEquals (  6  .  0  ,    exec (  \" def   x    =     5 L ;    return    ( double )     ( x    +     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryOperatorDef"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  5  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( byte )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  5  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( short )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  5  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( char )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" long   x    =     5 L ;    return    ( int )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  5  .  0 F ,    exec (  \" long   x    =     5 L ;    return    ( float )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" long   x    =     5 L ;    return    ( long )     ( x +  +  )  ;  \"  )  )  ;", "assertEquals (  5  .  0  ,    exec (  \" long   x    =     5 L ;    return    ( double )     ( x +  +  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryPostfix"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  6  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( byte )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  6  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( short )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  6  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( char )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  6  ,    exec (  \" long   x    =     5 L ;    return    ( int )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  6  .  0 F ,    exec (  \" long   x    =     5 L ;    return    ( float )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  6 L ,    exec (  \" long   x    =     5 L ;    return    ( long )     (  +  + x )  ;  \"  )  )  ;", "assertEquals (  6  .  0  ,    exec (  \" long   x    =     5 L ;    return    ( double )     (  +  + x )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryPrefix"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  ' a '  ,    exec (  \"  ' a '  . charAt (  0  )  \"  )  )  ;", "Exception   e    =    ScripCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >    exec (  \"  ' a '  . charAt (  0 L )  \"  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ long ]    to    [ int ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScripCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >    exec (  \"  ' a '  . charAt (  0  .  0 f )  \"  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ float ]    to    [ int ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScripCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >    exec (  \"  ' a '  . charAt (  0  .  0 d )  \"  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ double ]    to    [ int ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalCastInMethodArgument"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     5 L ;    int   y    =     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     5 L ;    int   y    =     ( x    +    x )  ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    true ;    int   y    =     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    true ;    int   y    =     ( x    ^    false )  ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     5 L ;    boolean   y    =     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     5 L ;    boolean   y    =     ( x    +    x )  ;    return   y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalConversions"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     5 L ;    int   y    =     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     5 L ;    int   y    =     ( x    +    x )  ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =    true ;    int   y    =     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =    true ;    int   y    =     ( x    ^    false )  ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     5 L ;    boolean   y    =     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     5 L ;    boolean   y    =     ( x    +    x )  ;    return   y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalConversionsDef"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    true ;    int   y    =     ( int )     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    true ;    int   y    =     ( int )     ( x    ^    false )  ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     5 L ;    boolean   y    =     ( boolean )     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     5 L ;    boolean   y    =     ( boolean )     ( x    +    x )  ;    return   y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalExplicitConversions"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =    true ;    int   y    =     ( int )     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =    true ;    int   y    =     ( int )     ( x    ^    false )  ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     5 L ;    boolean   y    =     ( boolean )     + x ;    return   y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     5 L ;    boolean   y    =     ( boolean )     ( x    +    x )  ;    return   y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalExplicitConversionsDef"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" def   map    =     [  ' a '  :     1  ,  ' b '  :     2  ,  ' c '  :     3  ]  ;    map . c    =    Collections . sort ( new   ArrayList ( map . keySet (  )  )  )  ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" Map   map    =     [  ' a '  :     1  ,  ' b '  :     2  ,  ' c '  :     3  ]  ;    def   x    =    new   HashMap (  )  ;    x . put (  1  ,    map . clear (  )  )  ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalVoidCasts"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" def   x    =     5  ;    return    ( int ) x . longValue (  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMethodCallDef"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  0  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( byte )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  0  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( short )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  0  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( char )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \" long   x    =     5 L ;    return    ( int )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  .  0 F ,    exec (  \" long   x    =     5 L ;    return    ( float )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  1  0 L ,    exec (  \" long   x    =     5 L ;    return    ( long )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  .  0  ,    exec (  \" long   x    =     5 L ;    return    ( double )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testShiftCompoundAssignment"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  0  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( byte )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  0  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( short )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  0  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( char )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \" def   x    =     5 L ;    return    ( int )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  .  0 F ,    exec (  \" def   x    =     5 L ;    return    ( float )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  1  0 L ,    exec (  \" def   x    =     5 L ;    return    ( long )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  .  0  ,    exec (  \" def   x    =     5 L ;    return    ( double )     ( x    <  <  =     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testShiftCompoundAssignmentDef"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  0  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( byte )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  0  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( short )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  0  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( char )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \" long   x    =     5 L ;    return    ( int )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  .  0 F ,    exec (  \" long   x    =     5 L ;    return    ( float )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  1  0 L ,    exec (  \" long   x    =     5 L ;    return    ( long )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  .  0  ,    exec (  \" long   x    =     5 L ;    return    ( double )     ( x    <  <     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testShiftOperator"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  0  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( byte )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  0  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( short )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  0  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( char )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \" def   x    =     5 L ;    return    ( int )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  .  0 F ,    exec (  \" def   x    =     5 L ;    return    ( float )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  1  0 L ,    exec (  \" def   x    =     5 L ;    return    ( long )     ( x    <  <     1  )  ;  \"  )  )  ;", "assertEquals (  1  0  .  0  ,    exec (  \" def   x    =     5 L ;    return    ( double )     ( x    <  <     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testShiftOperatorDef"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  5  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( byte )     (  + x )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  5  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( short )     (  + x )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  5  )  )  ,    exec (  \" long   x    =     5 L ;    return    ( char )     (  + x )  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" long   x    =     5 L ;    return    ( int )     (  + x )  ;  \"  )  )  ;", "assertEquals (  5  .  0 F ,    exec (  \" long   x    =     5 L ;    return    ( float )     (  + x )  ;  \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" long   x    =     5 L ;    return    ( long )     (  + x )  ;  \"  )  )  ;", "assertEquals (  5  .  0  ,    exec (  \" long   x    =     5 L ;    return    ( double )     (  + x )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnaryOperator"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  5  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( byte )     (  + x )  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  5  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( short )     (  + x )  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  5  )  )  ,    exec (  \" def   x    =     5 L ;    return    ( char )     (  + x )  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     5 L ;    return    ( int )     (  + x )  ;  \"  )  )  ;", "assertEquals (  5  .  0 F ,    exec (  \" def   x    =     5 L ;    return    ( float )     (  + x )  ;  \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     5 L ;    return    ( long )     (  + x )  ;  \"  )  )  ;", "assertEquals (  5  .  0  ,    exec (  \" def   x    =     5 L ;    return    ( double )     (  + x )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnaryOperatorDef"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  ' a '  ,    exec (  \"  ' a '  . charAt ( Integer . valueOf (  0  )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnboxMethodParameters"], "fileName": "org.elasticsearch.painless.CastTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  7  ;    def   y    =     ( int )  7  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  6  ;    def   y    =     ( int )  6  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  5  ;    def   y    =     ( int )  5  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  7  ;    def   y    =     ( double )  7  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  6  ;    def   y    =     ( double )  6  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  5  ;    def   y    =     ( double )  5  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    def   y    =    true ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;    def   y    =    false ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;    def   y    =    null ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    null ;    def   y    =    true ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;    def   y    =    true ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    def   y    =    false ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    def   y    =    new   HashMap (  )  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    y . put (  3  ,     3  )  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    def   y    =    x ;    x . put (  3  ,     3  )  ;    y . put (  3  ,     3  )  ;    return   x    =  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefEq"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" byte   x    =     ( byte )  7  ;    def   y    =     ( int )  7  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" short   x    =     ( short )  6  ;    def   y    =     ( int )  6  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" char   x    =     ( char )  5  ;    def   y    =     ( int )  5  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" byte   x    =     ( byte )  7  ;    def   y    =     ( double )  7  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" short   x    =     ( short )  6  ;    def   y    =     ( double )  6  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" char   x    =     ( char )  5  ;    def   y    =     ( double )  5  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    def   y    =    true ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    true ;    def   y    =    false ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    true ;    def   y    =    null ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;    def   y    =    true ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    false ;    def   y    =    false ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" Map   x    =    new   HashMap (  )  ;    def   y    =    new   HashMap (  )  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" Map   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" Map   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    y . put (  3  ,     3  )  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" Map   x    =    new   HashMap (  )  ;    def   y    =    x ;    x . put (  3  ,     3  )  ;    y . put (  3  ,     3  )  ;    return   x    =  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefEqTypedLHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  7  ;    int   y    =     ( int )  7  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  6  ;    int   y    =     ( int )  6  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  5  ;    int   y    =     ( int )  5  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  4  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    int   y    =     ( int )  3  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    int   y    =     ( int )  2  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    int   y    =     ( int )  1  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  7  ;    double   y    =     ( double )  7  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  6  ;    double   y    =     ( double )  6  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  5  ;    double   y    =     ( double )  5  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    double   y    =     ( double )  4  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    double   y    =     ( double )  3  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    double   y    =     ( double )  2  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    double   y    =     ( double )  1  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    boolean   y    =    true ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;    boolean   y    =    false ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    null ;    boolean   y    =    true ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;    boolean   y    =    true ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    boolean   y    =    false ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    Map   y    =    new   HashMap (  )  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    Map   y    =    new   HashMap (  )  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    Map   y    =    new   HashMap (  )  ;    y . put (  3  ,     3  )  ;    return   x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    Map   y    =    x ;    x . put (  3  ,     3  )  ;    y . put (  3  ,     3  )  ;    return   x    =  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefEqTypedRHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  7  ;    def   y    =     ( int )  7  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  6  ;    def   y    =     ( int )  6  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  5  ;    def   y    =     ( int )  5  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    def   y    =    true ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    def   y    =    new   HashMap (  )  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    y . put (  3  ,     3  )  ;    return   x    =  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    def   y    =    x ;    x . put (  3  ,     3  )  ;    y . put (  3  ,     3  )  ;    return   x    =  =  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefEqr"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( int )  7  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( int )  6  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  3  ;    def   y    =     ( int )  5  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( double )  7  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( double )  6  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  3  ;    def   y    =     ( double )  5  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    >    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefGt"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( int )  7  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( int )  6  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" char   x    =     ( char )  3  ;    def   y    =     ( int )  5  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( double )  7  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( double )  6  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" char   x    =     ( char )  3  ;    def   y    =     ( double )  5  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    >    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefGtTypedLHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  1  ;    int   y    =     ( int )  7  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  2  ;    int   y    =     ( int )  6  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  3  ;    int   y    =     ( int )  5  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  4  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    int   y    =     ( int )  3  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    int   y    =     ( int )  2  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    int   y    =     ( int )  1  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  1  ;    double   y    =     ( double )  7  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  2  ;    double   y    =     ( double )  6  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  3  ;    double   y    =     ( double )  5  ;    return   x    >    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    double   y    =     ( double )  4  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    double   y    =     ( double )  3  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    double   y    =     ( double )  2  ;    return   x    >    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    double   y    =     ( double )  1  ;    return   x    >    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefGtTypedRHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( int )  7  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( int )  6  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  3  ;    def   y    =     ( int )  5  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( double )  7  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( double )  6  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  3  ;    def   y    =     ( double )  5  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    >  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefGte"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( int )  7  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( int )  6  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" char   x    =     ( char )  3  ;    def   y    =     ( int )  5  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( double )  7  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( double )  6  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" char   x    =     ( char )  3  ;    def   y    =     ( double )  5  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    >  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefGteTypedLHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  1  ;    int   y    =     ( int )  7  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  2  ;    int   y    =     ( int )  6  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  3  ;    int   y    =     ( int )  5  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  4  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    int   y    =     ( int )  3  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    int   y    =     ( int )  2  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    int   y    =     ( int )  1  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  1  ;    double   y    =     ( double )  7  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  2  ;    double   y    =     ( double )  6  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  3  ;    double   y    =     ( double )  5  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    double   y    =     ( double )  4  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    double   y    =     ( double )  3  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    double   y    =     ( double )  2  ;    return   x    >  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    double   y    =     ( double )  1  ;    return   x    >  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefGteTypedRHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( int )  7  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( int )  6  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  3  ;    def   y    =     ( int )  5  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( double )  7  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( double )  6  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  3  ;    def   y    =     ( double )  5  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    <    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefLt"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( int )  7  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( int )  6  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" char   x    =     ( char )  3  ;    def   y    =     ( int )  5  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( double )  7  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( double )  6  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" char   x    =     ( char )  3  ;    def   y    =     ( double )  5  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    <    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefLtTypedLHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  1  ;    int   y    =     ( int )  7  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  2  ;    int   y    =     ( int )  6  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  3  ;    int   y    =     ( int )  5  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  4  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    int   y    =     ( int )  3  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    int   y    =     ( int )  2  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    int   y    =     ( int )  1  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  1  ;    double   y    =     ( double )  7  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  2  ;    double   y    =     ( double )  6  ;    return   x    <    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  3  ;    double   y    =     ( double )  5  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    double   y    =     ( double )  4  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    double   y    =     ( double )  3  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    double   y    =     ( double )  2  ;    return   x    <    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    double   y    =     ( double )  1  ;    return   x    <    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefLtTypedRHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( int )  7  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( int )  6  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  3  ;    def   y    =     ( int )  5  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( double )  7  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( double )  6  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  3  ;    def   y    =     ( double )  5  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    <  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefLte"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( int )  7  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( int )  6  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" char   x    =     ( char )  3  ;    def   y    =     ( int )  5  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( double )  7  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( double )  6  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" char   x    =     ( char )  3  ;    def   y    =     ( double )  5  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    <  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefLteTypedLHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  1  ;    int   y    =     ( int )  7  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  2  ;    int   y    =     ( int )  6  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  3  ;    int   y    =     ( int )  5  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  4  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    int   y    =     ( int )  3  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    int   y    =     ( int )  2  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    int   y    =     ( int )  1  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  1  ;    double   y    =     ( double )  7  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  2  ;    double   y    =     ( double )  6  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  3  ;    double   y    =     ( double )  5  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( int )  4  ;    double   y    =     ( double )  4  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( long )  5  ;    double   y    =     ( double )  3  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( float )  6  ;    double   y    =     ( double )  2  ;    return   x    <  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( double )  7  ;    double   y    =     ( double )  1  ;    return   x    <  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefLteTypedRHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  7  ;    def   y    =     ( int )  7  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  6  ;    def   y    =     ( int )  6  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  5  ;    def   y    =     ( int )  5  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  7  ;    def   y    =     ( double )  7  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  6  ;    def   y    =     ( double )  6  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  5  ;    def   y    =     ( double )  5  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    def   y    =    new   HashMap (  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    y . put (  3  ,     3  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    def   y    =    x ;    x . put (  3  ,     3  )  ;    y . put (  3  ,     3  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;       def   y    =    true ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       def   y    =    false ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    def   y    =    true ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    def   y    =    false ;    return   x    !  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefNe"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" byte   x    =     ( byte )  7  ;    def   y    =     ( int )  7  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" short   x    =     ( short )  6  ;    def   y    =     ( int )  6  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" char   x    =     ( char )  5  ;    def   y    =     ( int )  5  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" byte   x    =     ( byte )  7  ;    def   y    =     ( double )  7  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" short   x    =     ( short )  6  ;    def   y    =     ( double )  6  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" char   x    =     ( char )  5  ;    def   y    =     ( double )  5  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( double )  4  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" long   x    =     ( long )  5  ;    def   y    =     ( double )  3  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" float   x    =     ( float )  6  ;    def   y    =     ( double )  2  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     ( double )  7  ;    def   y    =     ( double )  1  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" Map   x    =    new   HashMap (  )  ;    def   y    =    new   HashMap (  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" Map   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" Map   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    y . put (  3  ,     3  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" Map   x    =    new   HashMap (  )  ;    def   y    =    x ;    x . put (  3  ,     3  )  ;    y . put (  3  ,     3  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    true ;       def   y    =    true ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;       def   y    =    false ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    false ;    def   y    =    true ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    def   y    =    false ;    return   x    !  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefNeTypedLHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  7  ;    int   y    =     ( int )  7  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  6  ;    int   y    =     ( int )  6  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  5  ;    int   y    =     ( int )  5  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  4  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    int   y    =     ( int )  3  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    int   y    =     ( int )  2  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    int   y    =     ( int )  1  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( byte )  7  ;    double   y    =     ( double )  7  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( short )  6  ;    double   y    =     ( double )  6  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( char )  5  ;    double   y    =     ( double )  5  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    double   y    =     ( double )  4  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    double   y    =     ( double )  3  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    double   y    =     ( double )  2  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    double   y    =     ( double )  1  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    Map   y    =    new   HashMap (  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    Map   y    =    new   HashMap (  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    Map   y    =    new   HashMap (  )  ;    y . put (  3  ,     3  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    Map   y    =    x ;    x . put (  3  ,     3  )  ;    y . put (  3  ,     3  )  ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;       boolean   y    =    true ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       boolean   y    =    false ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    boolean   y    =    true ;    return   x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    boolean   y    =    false ;    return   x    !  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefNeTypedRHS"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =     ( byte )  7  ;    def   y    =     ( int )  7  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( short )  6  ;    def   y    =     ( int )  6  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( char )  5  ;    def   y    =     ( int )  5  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  4  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( long )  5  ;    def   y    =     ( int )  3  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( float )  6  ;    def   y    =     ( int )  2  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     ( double )  7  ;    def   y    =     ( int )  1  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    def   y    =    new   HashMap (  )  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    new   HashMap (  )  ;    x . put (  3  ,     3  )  ;    def   y    =    new   HashMap (  )  ;    y . put (  3  ,     3  )  ;    return   x    !  =  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    new   HashMap (  )  ;    def   y    =    x ;    x . put (  3  ,     3  )  ;    y . put (  3  ,     3  )  ;    return   x    !  =  =    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefNer"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" int   x    =     5  ;    return   x   instanceof   int \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     5  ;    return   x   instanceof   Number \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     5  ;    return   x   instanceof   Integer \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     5  ;    return   x   instanceof   def \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     5  ;    return   x   instanceof   Object \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     5  ;    return   x   instanceof   int \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     5  ;    return   x   instanceof   def \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     5  ;    return   x   instanceof   Object \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     5  ;    return   x   instanceof   Integer \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =     5  ;    return   x   instanceof   Number \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     5  ;    return   x   instanceof   float \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =     5  ;    return   x   instanceof   Map \"  )  )  ;", "assertEquals ( true ,    exec (  \" List   l    =    new   ArrayList (  )  ;    return   l   instanceof   List \"  )  )  ;", "assertEquals ( false ,    exec (  \" List   l    =    null ;    return   l   instanceof   List \"  )  )  ;", "assertEquals ( true ,    exec (  \" List   l    =    new   ArrayList (  )  ;    return   l   instanceof   Collection \"  )  )  ;", "assertEquals ( false ,    exec (  \" List   l    =    new   ArrayList (  )  ;    return   l   instanceof   Map \"  )  )  ;", "assertEquals ( true ,    exec (  \" int [  ]    x    =    new   int [  ]     {     5     }  ;    return   x   instanceof   int [  ]  \"  )  )  ;", "assertEquals ( false ,    exec (  \" int [  ]    x    =    new   int [  ]     {     5     }  ;    return   x   instanceof   float [  ]  \"  )  )  ;", "assertEquals ( false ,    exec (  \" int [  ]    x    =    new   int [  ]     {     5     }  ;    return   x   instanceof   int [  ]  [  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInstanceOf"], "fileName": "org.elasticsearch.painless.ComparisonTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( source . length (  )  )     >     ( Compiler . MAXIMUM _ SOURCE _ LENGTH )  )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" Scripts   may   be   no   longer   than    \"     +     ( Compiler . MAXIMUM _ SOURCE _ LENGTH )  )     +     \"    characters .       The   passed   in   script   is    \"  )     +     ( source . length (  )  )  )     +     \"    characters .       Consider   using   a \"  )     +     \"    plugin   if   a   script   longer   than   this   length   is   a   requirement .  \"  )  )  ;", "}", "ScriptClassInfo   scriptClassInfo    =    new   ScriptClassInfo ( definition ,    base )  ;", "SSource   root    =    Walker . buildPainlessTree ( scriptClassInfo ,    new   SSource . MainMethodReserved (  )  ,    name ,    source ,    settings ,    definition ,    debugStream )  ;", "root . analyze ( definition )  ;", "root . write (  )  ;", "return   root . getBytes (  )  ;", "}", "METHOD_END"], "methodName": ["compile"], "fileName": "org.elasticsearch.painless.Compiler"}, {"methodBody": ["METHOD_START", "{", "if    (  ( source . length (  )  )     >     ( Compiler . MAXIMUM _ SOURCE _ LENGTH )  )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" Scripts   may   be   no   longer   than    \"     +     ( Compiler . MAXIMUM _ SOURCE _ LENGTH )  )     +     \"    characters .       The   passed   in   script   is    \"  )     +     ( source . length (  )  )  )     +     \"    characters .       Consider   using   a \"  )     +     \"    plugin   if   a   script   longer   than   this   length   is   a   requirement .  \"  )  )  ;", "}", "ScriptClassInfo   scriptClassInfo    =    new   ScriptClassInfo ( definition ,    base )  ;", "SSource   root    =    Walker . buildPainlessTree ( scriptClassInfo ,    reserved ,    name ,    source ,    settings ,    definition ,    null )  ;", "root . analyze ( definition )  ;", "root . write (  )  ;", "try    {", "Class <  ?    extends   PainlessScript >    clazz    =    loader . defineScript ( WriterConstants . CLASS _ NAME ,    root . getBytes (  )  )  ;", "clazz . getField (  \"  $ NAME \"  )  . set ( null ,    name )  ;", "clazz . getField (  \"  $ SOURCE \"  )  . set ( null ,    source )  ;", "clazz . getField (  \"  $ STATEMENTS \"  )  . set ( null ,    root . getStatements (  )  )  ;", "clazz . getField (  \"  $ DEFINITION \"  )  . set ( null ,    definition )  ;", "return   clazz . getConstructors (  )  [  0  ]  ;", "}    catch    ( Exception   exception )     {", "throw   new   IllegalStateException (  (  (  \" An   internal   error   occurred   attempting   to   define   the   script    [  \"     +    name )     +     \"  ]  .  \"  )  ,    exception )  ;", "}", "}", "METHOD_END"], "methodName": ["compile"], "fileName": "org.elasticsearch.painless.Compiler"}, {"methodBody": ["METHOD_START", "{", "return   new   Compiler . Loader ( parent ,    definition )  ;", "}", "METHOD_END"], "methodName": ["createLoader"], "fileName": "org.elasticsearch.painless.Compiler"}, {"methodBody": ["METHOD_START", "{", "return   regexesEnabled ;", "}", "METHOD_END"], "methodName": ["areRegexesEnabled"], "fileName": "org.elasticsearch.painless.CompilerSettings"}, {"methodBody": ["METHOD_START", "{", "return   initialCallSiteDepth ;", "}", "METHOD_END"], "methodName": ["getInitialCallSiteDepth"], "fileName": "org.elasticsearch.painless.CompilerSettings"}, {"methodBody": ["METHOD_START", "{", "return   maxLoopCounter ;", "}", "METHOD_END"], "methodName": ["getMaxLoopCounter"], "fileName": "org.elasticsearch.painless.CompilerSettings"}, {"methodBody": ["METHOD_START", "{", "return   picky ;", "}", "METHOD_END"], "methodName": ["isPicky"], "fileName": "org.elasticsearch.painless.CompilerSettings"}, {"methodBody": ["METHOD_START", "{", "this . initialCallSiteDepth    =    depth ;", "}", "METHOD_END"], "methodName": ["setInitialCallSiteDepth"], "fileName": "org.elasticsearch.painless.CompilerSettings"}, {"methodBody": ["METHOD_START", "{", "this . maxLoopCounter    =    max ;", "}", "METHOD_END"], "methodName": ["setMaxLoopCounter"], "fileName": "org.elasticsearch.painless.CompilerSettings"}, {"methodBody": ["METHOD_START", "{", "this . picky    =    picky ;", "}", "METHOD_END"], "methodName": ["setPicky"], "fileName": "org.elasticsearch.painless.CompilerSettings"}, {"methodBody": ["METHOD_START", "{", "this . regexesEnabled    =    regexesEnabled ;", "}", "METHOD_END"], "methodName": ["setRegexesEnabled"], "fileName": "org.elasticsearch.painless.CompilerSettings"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  .  0  ,    exec (  \" boolean   x    =    false ;    double   z    =    x    ?     2     :     4  .  0 F ;    return   z ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  7  )  )  ,    exec (  \" boolean   x    =    false ;    int   y    =     2  ;    byte   z    =    x    ?     ( byte ) y    :     7  ;    return   z ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  7  )  )  ,    exec (  \" boolean   x    =    false ;    int   y    =     2  ;    byte   z    =     ( byte )  ( x    ?    y    :     7  )  ;    return   z ;  \"  )  )  ;", "assertEquals ( ArrayList . cs ,    exec (  \" boolean   x    =    false ;    Object   z    =    x    ?    new   HashMap (  )     :    new   ArrayList (  )  ;    return   z ;  \"  )  . getCs (  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignment"], "fileName": "org.elasticsearch.painless.ConditionalTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" boolean   x    =    true ;    return   x    ?     2     :     3  ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" boolean   x    =    false ;    return   x    ?     2     :     3  ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" boolean   x    =    false ,    y    =    true ;    return   x    &  &    y    ?     2     :     3  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" boolean   x    =    true ,    y    =    true ;    return   x    &  &    y    ?     2     :     3  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" boolean   x    =    true ,    y    =    false ;    return   x    |  |    y    ?     2     :     3  ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" boolean   x    =    false ,    y    =    false ;    return   x    |  |    y    ?     2     :     3  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasic"], "fileName": "org.elasticsearch.painless.ConditionalTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    false ;    byte   z    =    x    ?     2     :     4  .  0 F ;    return   z ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    false ;    Map   z    =    x    ?     4     :     ( byte )  7  ;    return   z ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    false ;    Map   z    =    x    ?    new   HashMap (  )     :    new   ArrayList (  )  ;    return   z ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    false ;    int   y    =     2  ;    byte   z    =    x    ?    y    :     7  ;    return   z ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIncompatibleAssignment"], "fileName": "org.elasticsearch.painless.ConditionalTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( null ,    exec (  \" boolean   b    =    false ,    c    =    true ;    Object   x ;    Map   y ;    return   b    &  &    c    ?    x    :    y ;  \"  )  )  ;", "assertEquals ( HashMap . cs ,    exec (  \" boolean   b    =    false ,    c    =    true ;    Object   x ;    Map   y    =    new   HashMap (  )  ;    return   b    &  &    c    ?    x    :    y ;  \"  )  . getCs (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullArguments"], "fileName": "org.elasticsearch.painless.ConditionalTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  \" boolean   x    =    false ,    y    =    true ;    return   x    ?     ( y    ?     2     :     3  )     :     4  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" boolean   x    =    true ,    y    =    true ;    return   x    ?     ( y    ?     2     :     3  )     :     4  ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" boolean   x    =    true ,    y    =    false ;    return   x    ?     ( y    ?     2     :     3  )     :     4  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" boolean   x    =    true ,    y    =    true ;    return   x    ?    y    ?     2     :     3     :     4  ;  \"  )  )  ;", "assertEquals (  4  ,    exec (  \" boolean   x    =    false ,    y    =    true ;    return   x    ?    y    ?     2     :     3     :     4  ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" boolean   x    =    true ,    y    =    false ;    return   x    ?    y    ?     2     :     3     :     4  ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" boolean   x    =    false ,    y    =    true ;    return   x    ?     2     :    y    ?     3     :     4  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" boolean   x    =    true ,    y    =    false ;    return   x    ?     2     :    y    ?     3     :     4  ;  \"  )  )  ;", "assertEquals (  4  ,    exec (  \" boolean   x    =    false ,    y    =    false ;    return   x    ?     2     :    y    ?     3     :     4  ;  \"  )  )  ;", "assertEquals (  4  ,    exec (  \" boolean   x    =    false ,    y    =    false ;    return    ( x    ?    true    :    y )     ?     3     :     4  ;  \"  )  )  ;", "assertEquals (  4  ,    exec (  \" boolean   x    =    true ,    y    =    false ;    return    ( x    ?    false    :    y )     ?     3     :     4  ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" boolean   x    =    false ,    y    =    true ;    return    ( x    ?    false    :    y )     ?     3     :     4  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" boolean   x    =    true ,    y    =    false ;    return    ( x    ?    false    :    y )     ?     ( x    ?     3     :     4  )     :    x    ?     2     :     1  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" boolean   x    =    true ,    y    =    false ;    return    ( x    ?    false    :    y )     ?    x    ?     3     :     4     :    x    ?     2     :     1  ;  \"  )  )  ;", "assertEquals (  4  ,    exec (  \" boolean   x    =    false ,    y    =    true ;    return   x    ?    false    :    y    ?    x    ?     3     :     4     :    x    ?     2     :     1  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrecedence"], "fileName": "org.elasticsearch.painless.ConditionalTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    boolean   y    =    true ;    return    ( x    ?     2     :     4  .  0 F )     =  =     ( y    ?     2     :     4  .  0 F )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  (  \" boolean   x    =    false ;    boolean   y    =    true ;     \"     +     \" return    ( x    ?    new   HashMap (  )     :    new   ArrayList (  )  )     =  =     ( y    ?    new   HashMap (  )     :    new   ArrayList (  )  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPromotion"], "fileName": "org.elasticsearch.painless.ConditionalTests"}, {"methodBody": ["METHOD_START", "{", "Object   dummy    =    new   Object (  )  ;", "PainlessExplainError   e    =    ScriptTestCase . expectScriptThrows ( PainlessExplainError . class ,     (  )     -  >    exec (  \" Debug . explain ( params . a )  \"  ,    singletonMap (  \" a \"  ,    dummy )  ,    true )  )  ;", "assertSame ( dummy ,    e . getObjectToExplain (  )  )  ;", "assertThat ( e . getHeaders ( definition )  ,    hasEntry (  \" es . to _ string \"  ,    Collections . singletonList ( dummy . toString (  )  )  )  )  ;", "assertThat ( e . getHeaders ( definition )  ,    hasEntry (  \" es . java _ class \"  ,    Collections . singletonList (  \" Object \"  )  )  )  ;", "assertThat ( e . getHeaders ( definition )  ,    hasEntry (  \" es _ class \"  ,    Collections . singletonList (  \" Object \"  )  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( PainlessExplainError . class ,     (  )     -  >    exec (  \" Debug . explain ( null )  \"  )  )  ;", "assertNull ( e . getObjectToExplain (  )  )  ;", "assertThat ( e . getHeaders ( definition )  ,    hasEntry (  \" es . to _ string \"  ,    Collections . singletonList (  \" null \"  )  )  )  ;", "assertThat ( e . getHeaders ( definition )  ,    not ( hasKey (  \" es . java _ class \"  )  )  )  ;", "assertThat ( e . getHeaders ( definition )  ,    not ( hasKey (  \" es _ class \"  )  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( PainlessExplainError . class ,     (  )     -  >    exec (  (  \" try    {  \\ n \"     +     (  (  (  \"       Debug . explain ( params . a )  \\ n \"     +     \"  }    catch    ( Exception   e )     {  \\ n \"  )     +     \"       return    1  \\ n \"  )     +     \"  }  \"  )  )  ,    singletonMap (  \" a \"  ,    dummy )  ,    true )  )  ;", "assertSame ( dummy ,    e . getObjectToExplain (  )  )  ;", "}", "METHOD_END"], "methodName": ["testExplain"], "fileName": "org.elasticsearch.painless.DebugTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    params    =    Collections . singletonMap (  \" a \"  ,     \" jumped   over   the   moon \"  )  ;", "ScriptException   e    =    expectThrows ( ScriptException . class ,     (  )     -  >    exec (  \" Debug . explain ( params . a )  \"  ,    params ,    true )  )  ;", "assertEquals ( Collections . singletonList (  \" jumped   over   the   moon \"  )  ,    e . getMetadata (  \" es . to _ string \"  )  )  ;", "assertEquals ( Collections . singletonList (  \" String \"  )  ,    e . getMetadata (  \" es . java _ class \"  )  )  ;", "assertEquals ( Collections . singletonList (  \" String \"  )  ,    e . getMetadata (  \" es . painless _ class \"  )  )  ;", "try    ( BytesStreamOutput   out    =    new   BytesStreamOutput (  )  )     {", "out . writeException ( e )  ;", "try    ( StreamInput   in    =    out . bytes (  )  . streamInput (  )  )     {", "EException   read    =     (  ( ScriptException )     ( in . readException (  )  )  )  ;", "assertEquals ( Collections . singletonList (  \" jumped   over   the   moon \"  )  ,    read . getMetadata (  \" es . to _ string \"  )  )  ;", "assertEquals ( Collections . singletonList (  \" String \"  )  ,    read . getMetadata (  \" es . java _ class \"  )  )  ;", "assertEquals ( Collections . singletonList (  \" String \"  )  ,    read . getMetadata (  \" es . painless _ class \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testPainlessExplainErrorSerialization"], "fileName": "org.elasticsearch.painless.DebugTests"}, {"methodBody": ["METHOD_START", "{", "StringWriter   output    =    new   StringWriter (  )  ;", "PrintWriter   outputWriter    =    new   PrintWriter ( output )  ;", "Textifier   textifier    =    new   Textifier (  )  ;", "try    {", "new   Compiler ( iface ,    new   Definition ( Whitelist . BASE _ WHITELISTS )  )  . compile (  \"  < ding >  \"  ,    source ,    settings ,    textifier )  ;", "}    catch    ( RuntimeException   e )     {", "textifier . print ( outputWriter )  ;", "e . addSuppressed ( new   Exception (  (  \" current   bytecode :     \\ n \"     +    output )  )  )  ;", "throw   e ;", "}", "textifier . print ( outputWriter )  ;", "return   output . toString (  )  ;", "}", "METHOD_END"], "methodName": ["toString"], "fileName": "org.elasticsearch.painless.Debugger"}, {"methodBody": ["METHOD_START", "{", "return   Debugger . toString ( GenericElasticsearchScript . class ,    source ,    new   CompilerSettings (  )  )  ;", "}", "METHOD_END"], "methodName": ["toString"], "fileName": "org.elasticsearch.painless.Debugger"}, {"methodBody": ["METHOD_START", "{", "return    (  ( boolean )     ( value )  )  ;", "}", "METHOD_END"], "methodName": ["DefToboolean"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Character )     {", "return    (  ( byte )     (  ( char )     ( value )  )  )  ;", "} else    {", "return    (  ( Number )     ( value )  )  . byteValue (  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTobyteExplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "return    (  ( byte )     ( value )  )  ;", "}", "METHOD_END"], "methodName": ["DefTobyteImplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Character )     {", "return    (  ( Character )     ( value )  )  ;", "} else    {", "return    (  ( char )     (  (  ( Number )     ( value )  )  . intValue (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTocharExplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Byte )     {", "return    (  ( char )     (  ( byte )     ( value )  )  )  ;", "} else    {", "return    (  ( char )     ( value )  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTocharImplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Character )     {", "return    (  ( char )     ( value )  )  ;", "} else    {", "return    (  ( Number )     ( value )  )  . doubleValue (  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTodoubleExplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Byte )     {", "return    (  ( byte )     ( value )  )  ;", "} else", "if    ( value   instanceof   Short )     {", "return    (  ( short )     ( value )  )  ;", "} else", "if    ( value   instanceof   Character )     {", "return    (  ( char )     ( value )  )  ;", "} else", "if    ( value   instanceof   Integer )     {", "return    (  ( int )     ( value )  )  ;", "} else", "if    ( value   instanceof   Long )     {", "return    (  ( long )     ( value )  )  ;", "} else", "if    ( value   instanceof   Float )     {", "return    (  ( float )     ( value )  )  ;", "} else    {", "return    (  ( double )     ( value )  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTodoubleImplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Character )     {", "return    (  ( char )     ( value )  )  ;", "} else    {", "return    (  ( Number )     ( value )  )  . floatValue (  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTofloatExplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Byte )     {", "return    (  ( byte )     ( value )  )  ;", "} else", "if    ( value   instanceof   Short )     {", "return    (  ( short )     ( value )  )  ;", "} else", "if    ( value   instanceof   Character )     {", "return    (  ( char )     ( value )  )  ;", "} else", "if    ( value   instanceof   Integer )     {", "return    (  ( int )     ( value )  )  ;", "} else", "if    ( value   instanceof   Long )     {", "return    (  ( long )     ( value )  )  ;", "} else    {", "return    (  ( float )     ( value )  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTofloatImplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Character )     {", "return    (  ( char )     ( value )  )  ;", "} else    {", "return    (  ( Number )     ( value )  )  . intValue (  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTointExplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Byte )     {", "return    (  ( byte )     ( value )  )  ;", "} else", "if    ( value   instanceof   Short )     {", "return    (  ( short )     ( value )  )  ;", "} else", "if    ( value   instanceof   Character )     {", "return    (  ( char )     ( value )  )  ;", "} else    {", "return    (  ( int )     ( value )  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTointImplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Character )     {", "return    (  ( char )     ( value )  )  ;", "} else    {", "return    (  ( Number )     ( value )  )  . longValue (  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTolongExplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Byte )     {", "return    (  ( byte )     ( value )  )  ;", "} else", "if    ( value   instanceof   Short )     {", "return    (  ( short )     ( value )  )  ;", "} else", "if    ( value   instanceof   Character )     {", "return    (  ( char )     ( value )  )  ;", "} else", "if    ( value   instanceof   Integer )     {", "return    (  ( int )     ( value )  )  ;", "} else    {", "return    (  ( long )     ( value )  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefTolongImplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Character )     {", "return    (  ( short )     (  ( char )     ( value )  )  )  ;", "} else    {", "return    (  ( Number )     ( value )  )  . shortValue (  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefToshortExplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( value   instanceof   Byte )     {", "return    (  ( byte )     ( value )  )  ;", "} else    {", "return    (  ( short )     ( value )  )  ;", "}", "}", "METHOD_END"], "methodName": ["DefToshortImplicit"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    (  ( Def . JAVA 9  _ ARRAY _ LENGTH _ MH _ FACTORY )     !  =    null )     {", "try    {", "return    (  ( MethodHandle )     ( Def . JAVA 9  _ ARRAY _ LENGTH _ MH _ FACTORY . invokeExact ( arrayType )  )  )  ;", "}    catch    ( Throwable   t )     {", "Def . rethrow ( t )  ;", "throw   new   AssertionError ( t )  ;", "}", "} else    {", "return   Def . ArrayLengthHelper . arrayLengthGetter ( arrayType )  ;", "}", "}", "METHOD_END"], "methodName": ["arrayLengthGetter"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "return    (  (  \" handle $  \"     +    name )     +     \"  $  \"  )     +    arity ;", "}", "METHOD_END"], "methodName": ["getUserFunctionHandleFieldName"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "return   index    >  =     0     ?    index    :     ( value . size (  )  )     +    index ;", "}", "METHOD_END"], "methodName": ["listIndexNormalize"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( receiverClass . isArray (  )  )     {", "return   MethodHandles . arrayElementGetter ( receiverClass )  ;", "} else", "if    ( isAssignableFrom ( receiverClass )  )     {", "return   Def . MAP _ GET ;", "} else", "if    ( isAssignableFrom ( receiverClass )  )     {", "return   Def . LIST _ GET ;", "}", "throw   new   IllegalArgumentException (  (  (  (  \" Attempting   to   address   a   non - array   type    \"     +     \"  [  \"  )     +     ( receiverClass . getCanonicalName (  )  )  )     +     \"  ]    as   an   array .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["lookupArrayLoad"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( receiverClass . isArray (  )  )     {", "return   MethodHandles . arrayElementSetter ( receiverClass )  ;", "} else", "if    ( isAssignableFrom ( receiverClass )  )     {", "return   Def . MAP _ PUT ;", "} else", "if    ( isAssignableFrom ( receiverClass )  )     {", "return   Def . LIST _ SET ;", "}", "throw   new   IllegalArgumentException (  (  (  (  \" Attempting   to   address   a   non - array   type    \"     +     \"  [  \"  )     +     ( receiverClass . getCanonicalName (  )  )  )     +     \"  ]    as   an   array .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["lookupArrayStore"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "for    ( Class <  ?  >    clazz    =    receiverClass ;    clazz    !  =    null ;    clazz    =    clazz . getSuperclass (  )  )     {", "Definition . Struct   struct    =    definition . RuntimeClassToStruct ( clazz )  ;", "if    ( struct    !  =    null )     {", "MethodHandle   handle    =    struct . getters . get ( name )  ;", "if    ( handle    !  =    null )     {", "return   handle ;", "}", "}", "for    ( final   Class <  ?  >    iface    :    clazz . getInterfaces (  )  )     {", "struct    =    definition . RuntimeClassToStruct ( iface )  ;", "if    ( struct    !  =    null )     {", "MethodHandle   handle    =    struct . getters . get ( name )  ;", "if    ( handle    !  =    null )     {", "return   handle ;", "}", "}", "}", "}", "if    (  ( receiverClass . isArray (  )  )     &  &     (  \" length \"  . equals ( name )  )  )     {", "return   Def . arrayLengthGetter ( receiverClass )  ;", "} else", "if    ( isAssignableFrom ( receiverClass )  )     {", "return   insertArguments ( Def . MAP _ GET ,     1  ,    name )  ;", "} else", "if    ( isAssignableFrom ( receiverClass )  )     {", "try    {", "int   index    =    Integer . parseInt ( name )  ;", "return   insertArguments ( Def . LIST _ GET ,     1  ,    index )  ;", "}    catch    ( NumberFormatException   exception )     {", "throw   new   IllegalArgumentException (  (  (  \" Illegal   list   shortcut   value    [  \"     +    name )     +     \"  ]  .  \"  )  )  ;", "}", "}", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" Unable   to   find   dynamic   field    [  \"     +    name )     +     \"  ]     \"  )     +     \" for   class    [  \"  )     +     ( receiverClass . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["lookupGetter"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( receiverClass . isArray (  )  )     {", "return   Def . ArrayIndexNormalizeHelper . arrayIndexNormalizer ( receiverClass )  ;", "} else", "if    ( isAssignableFrom ( receiverClass )  )     {", "return   Def . MAP _ INDEX _ NORMALIZE ;", "} else", "if    ( isAssignableFrom ( receiverClass )  )     {", "return   Def . LIST _ INDEX _ NORMALIZE ;", "}", "throw   new   IllegalArgumentException (  (  (  (  \" Attempting   to   address   a   non - array - like   type    \"     +     \"  [  \"  )     +     ( receiverClass . getCanonicalName (  )  )  )     +     \"  ]    as   an   array .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["lookupIndexNormalize"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "if    ( Iterable . class . isAssignableFrom ( receiverClass )  )     {", "return   Def . ITERATOR ;", "} else", "if    ( receiverClass . isArray (  )  )     {", "return   Def . ArrayIteratorHelper . newIterator ( receiverClass )  ;", "} else    {", "throw   new   IllegalArgumentException (  (  (  \" Cannot   iterate   over    [  \"     +     ( receiverClass . getCanonicalName (  )  )  )     +     \"  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["lookupIterator"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "String   recipeString    =     (  ( String )     ( args [  0  ]  )  )  ;", "int   numArguments    =    callSiteType . parameterCount (  )  ;", "if    ( recipeString . isEmpty (  )  )     {", "return   Def . lookupMethodInternal ( definition ,    receiverClass ,    name ,     ( numArguments    -     1  )  )  . handle ;", "}", "BitSet   lambdaArgs    =    new   BitSet ( recipeString . length (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( recipeString . length (  )  )  ;    i +  +  )     {", "lambdaArgs . set ( recipeString . charAt ( i )  )  ;", "}", "int   arity    =     ( callSiteType . parameterCount (  )  )     -     1  ;", "int   upTo    =     1  ;", "for    ( int   i    =     1  ;    i    <    numArguments ;    i +  +  )     {", "if    ( lambdaArgs . get (  ( i    -     1  )  )  )     {", "String   signature    =     (  ( String )     ( args [  ( upTo +  +  )  ]  )  )  ;", "int   numCaptures    =    Integer . parseInt ( signature . substring (  (  ( signature . indexOf (  '  ,  '  )  )     +     1  )  )  )  ;", "arity    -  =    numCaptures ;", "}", "}", "Definition . Method   method    =    Def . lookupMethodInternal ( definition ,    receiverClass ,    name ,    arity )  ;", "MethodHandle   handle    =    method . handle ;", "int   replaced    =     0  ;", "upTo    =     1  ;", "for    ( int   i    =     1  ;    i    <    numArguments ;    i +  +  )     {", "if    ( lambdaArgs . get (  ( i    -     1  )  )  )     {", "String   signature    =     (  ( String )     ( args [  ( upTo +  +  )  ]  )  )  ;", "int   separator    =    signature . IndexOf (  '  .  '  )  ;", "int   separator 2     =    signature . indexOf (  '  ,  '  )  ;", "String   type    =    signature . substring (  1  ,    separator )  ;", "String   call    =    signature . substring (  ( separator    +     1  )  ,    separator 2  )  ;", "int   numCaptures    =    Integer . parseInt ( signature . substring (  ( separator 2     +     1  )  )  )  ;", "Class <  ?  >  [  ]    captures    =    new   Class <  ?  >  [ numCaptures ]  ;", "for    ( int   capture    =     0  ;    capture    <     ( captures . length )  ;    capture +  +  )     {", "captures [ capture ]     =    callSiteType . parameterType (  (  ( i    +     1  )     +    capture )  )  ;", "}", "MethodHandle   filter ;", "Definition . Type   interfaceType    =    definition . ClassToType ( method . arguments . get (  (  ( i    -     1  )     -    replaced )  )  )  ;", "if    (  ( signature . charAt (  0  )  )     =  =     ' S '  )     {", "filter    =    Def . lookupReferenceInternal ( definition ,    lookup ,    interfaceType ,    type ,    call ,    captures )  ;", "} else", "if    (  ( signature . charAt (  0  )  )     =  =     ' D '  )     {", "MethodType   nestedType    =    MethodType . methodType ( interfaceType . clazz ,    captures )  ;", "CallSite   nested    =    DefBootstrap . bootstrap ( definition ,    lookup ,    call ,    nestedType ,     0  ,    DefBootstrap . REFERENCE ,    interfaceType . name )  ;", "filter    =    nested . dynamicInvoker (  )  ;", "} else    {", "throw   new   AssertionError (  )  ;", "}", "filter    =    MethodHandles . dropArguments ( filter ,     0  ,    String . class )  ;", "handle    =    MethodHandles . collectArguments ( handle ,    i ,    filter )  ;", "i    +  =    numCaptures ;", "replaced    +  =    numCaptures ;", "}", "}", "return   handle ;", "}", "METHOD_END"], "methodName": ["lookupMethod"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "Definition . MethodKey   key    =    new   Definition . MethodKey ( name ,    arity )  ;", "for    ( Class <  ?  >    clazz    =    receiverClass ;    clazz    !  =    null ;    clazz    =    clazz . getSuperclass (  )  )     {", "Definition . Struct   struct    =    definition . RuntimeClassToStruct ( clazz )  ;", "if    ( struct    !  =    null )     {", "Definition . Method   method    =    struct . methods . get ( key )  ;", "if    ( method    !  =    null )     {", "return   method ;", "}", "}", "for    ( Class <  ?  >    iface    :    clazz . getInterfaces (  )  )     {", "struct    =    definition . RuntimeClassToStruct ( iface )  ;", "if    ( struct    !  =    null )     {", "Definition . Method   method    =    struct . methods . get ( key )  ;", "if    ( method    !  =    null )     {", "return   method ;", "}", "}", "}", "}", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  \" Unable   to   find   dynamic   method    [  \"     +    name )     +     \"  ]    with    [  \"  )     +    arity )     +     \"  ]    arguments    \"  )     +     \" for   class    [  \"  )     +     ( receiverClass . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["lookupMethodInternal"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "Definition . Type   interfaceType    =    definition . getType ( interfaceClass )  ;", "Definition . Method   interfaceMethod    =    interfaceType . struct . functionalMethod ;", "if    ( interfaceMethod    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  \" Class    [  \"     +    interfaceClass )     +     \"  ]    is   not   a   functional   interface \"  )  )  ;", "}", "int   arity    =    interfaceMethod . arguments . size (  )  ;", "Definition . Method   implMethod    =    Def . lookupMethodInternal ( definition ,    receiverClass ,    name ,    arity )  ;", "return   Def . lookupReferenceInternal ( definition ,    lookup ,    interfaceType ,    implMethod . owner . name ,    implMethod . name ,    receiverClass )  ;", "}", "METHOD_END"], "methodName": ["lookupReference"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "final   FunctionRef   ref ;", "if    (  \" this \"  . equals ( type )  )     {", "inition . Method   interfaceMethod    =    clazz . struct . functionalMethod ;", "if    ( interfaceMethod    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  \" Cannot   convert   function   reference    [  \"     +    type )     +     \"  :  :  \"  )     +    call )     +     \"  ]     \"  )     +     \" to    [  \"  )     +     ( clazz . name )  )     +     \"  ]  ,    not   a   functional   interface \"  )  )  ;", "}", "int   arity    =     ( interfaceMethod . arguments . size (  )  )     +     ( captures . length )  ;", "final   MethodHandle   handle ;", "try    {", "MethodHandle   accessor    =    lookup . findStaticGetter ( lookup . lookupClass (  )  ,     . getUserFunctionHandleFieldName ( call ,    arity )  ,    MethodHandle . class )  ;", "handle    =     (  ( MethodHandle )     ( accessor . invokeExact (  )  )  )  ;", "}    catch    ( NoSuchFieldException    |    IllegalAccessException   e )     {", "if    ( call . contains (  \"  $  \"  )  )     {", "throw   new   IllegalArgumentException (  (  (  (  (  \" Incorrect   number   of   parameters   for    [  \"     +     ( interfaceMethod . name )  )     +     \"  ]    in    [  \"  )     +     ( clazz . clazz )  )     +     \"  ]  \"  )  )  ;", "}", "throw   new   IllegalArgumentException (  (  (  (  (  \" Unknown   call    [  \"     +    call )     +     \"  ]    with    [  \"  )     +    arity )     +     \"  ]    arguments .  \"  )  )  ;", "}", "ref    =    new   FunctionRef ( clazz . clazz ,    interfaceMethod ,    call ,    handle . type (  )  ,    captures . length )  ;", "} else    {", "ref    =    new   FunctionRef ( definition ,    clazz . clazz ,    type ,    call ,    captures . length )  ;", "}", "final   CallSite   callSite    =    LambdaBootstrap . lambdaBootstrap ( lookup ,    ref . interfaceMethodName ,    ref . factoryMethodType ,    ref . interfaceMethodType ,    ref . delegateClassName ,    ref . delegateInvokeType ,    ref . delegateMethodName ,    ref . delegateMethodType )  ;", "return   callSite . dynamicInvoker (  )  . asType ( MethodType . methodType ( clazz . clazz ,    captures )  )  ;", "}", "METHOD_END"], "methodName": ["lookupReferenceInternal"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "for    ( Class <  ?  >    clazz    =    receiverClass ;    clazz    !  =    null ;    clazz    =    clazz . getSuperclass (  )  )     {", "Definition . Struct   struct    =    definition . RuntimeClassToStruct ( clazz )  ;", "if    ( struct    !  =    null )     {", "MethodHandle   handle    =    struct . setters . get ( name )  ;", "if    ( handle    !  =    null )     {", "return   handle ;", "}", "}", "for    ( final   Class <  ?  >    iface    :    clazz . getInterfaces (  )  )     {", "struct    =    definition . RuntimeClassToStruct ( iface )  ;", "if    ( struct    !  =    null )     {", "MethodHandle   handle    =    struct . setters . get ( name )  ;", "if    ( handle    !  =    null )     {", "return   handle ;", "}", "}", "}", "}", "if    ( Map . class . isAssignableFrom ( receiverClass )  )     {", "return   MethodHandles . insertArguments ( Def . MAP _ PUT ,     1  ,    name )  ;", "} else", "if    ( isAssignableFrom ( receiverClass )  )     {", "try    {", "int   index    =    Integer . parseInt ( name )  ;", "return   MethodHandles . insertArguments ( Def . LIST _ SET ,     1  ,    index )  ;", "}    catch    ( final   NumberFormatException   exception )     {", "throw   new   IllegalArgumentException (  (  (  \" Illegal   list   shortcut   value    [  \"     +    name )     +     \"  ]  .  \"  )  )  ;", "}", "}", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" Unable   to   find   dynamic   field    [  \"     +    name )     +     \"  ]     \"  )     +     \" for   class    [  \"  )     +     ( receiverClass . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["lookupSetter"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "return   index ;", "}", "METHOD_END"], "methodName": ["mapIndexNormalize"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "throw    (  ( T )     ( t )  )  ;", "}", "METHOD_END"], "methodName": ["rethrow"], "fileName": "org.elasticsearch.painless.Def"}, {"methodBody": ["METHOD_START", "{", "switch    ( flavor )     {", "case    . METHOD _ CALL    :", "if    (  ( args . length )     =  =     0  )     {", "throw   new   BootstrapMethodError (  \" Invalid   number   of   parameters   for   method   call \"  )  ;", "}", "if    (  (  ( args [  0  ]  )    instanceof   String )     =  =    false )     {", "throw   new   BootstrapMethodError (  (  \" Illegal   parameter   for   method   call :     \"     +     ( args [  0  ]  )  )  )  ;", "}", "String   recipe    =     (  ( String )     ( args [  0  ]  )  )  ;", "int   numLambdas    =    recipe . length (  )  ;", "if    ( numLambdas    >     ( type . parameterCount (  )  )  )     {", "throw   new   BootstrapMethodError (  \" Illegal   recipe   for   method   call :    too   many   bits \"  )  ;", "}", "if    (  ( args . length )     !  =     ( numLambdas    +     1  )  )     {", "throw   new   BootstrapMethodError (  (  (  \" Illegal   number   of   parameters :    expected    \"     +    numLambdas )     +     \"    references \"  )  )  ;", "}", "return   new    . PIC ( definition ,    lookup ,    name ,    type ,    initialDepth ,    flavor ,    args )  ;", "case    . LOAD    :", "case    . STORE    :", "case    . ARRAY _ LOAD    :", "case    . ARRAY _ STORE    :", "case    . ITERATOR    :", "case    . INDEX _ NORMALIZE    :", "if    (  ( args . length )     >     0  )     {", "throw   new   BootstrapMethodError (  (  \" Illegal   static   bootstrap   parameters   for   flavor :     \"     +    flavor )  )  ;", "}", "return   new    . PIC ( definition ,    lookup ,    name ,    type ,    initialDepth ,    flavor ,    args )  ;", "case    . REFERENCE    :", "if    (  ( args . length )     !  =     1  )     {", "throw   new   BootstrapMethodError (  \" Invalid   number   of   parameters   for   reference   call \"  )  ;", "}", "if    (  (  ( args [  0  ]  )    instanceof   String )     =  =    false )     {", "throw   new   BootstrapMethodError (  (  \" Illegal   parameter   for   reference   call :     \"     +     ( args [  0  ]  )  )  )  ;", "}", "return   new    . PIC ( definition ,    lookup ,    name ,    type ,    initialDepth ,    flavor ,    args )  ;", "case    . UNARY _ OPERATOR    :", "case    . SHIFT _ OPERATOR    :", "case    . BINARY _ OPERATOR    :", "if    (  ( args . length )     !  =     1  )     {", "throw   new   BootstrapMethodError (  \" Invalid   number   of   parameters   for   operator   call \"  )  ;", "}", "if    (  (  ( args [  0  ]  )    instanceof   Integer )     =  =    false )     {", "throw   new   BootstrapMethodError (  (  \" Illegal   parameter   for   reference   call :     \"     +     ( args [  0  ]  )  )  )  ;", "}", "int   flags    =     (  ( int )     ( args [  0  ]  )  )  ;", "if    (  (  ( flags    &     (  . OPERATOR _ ALLOWS _ NULL )  )     !  =     0  )     &  &     ( flavor    !  =     (  . BINARY _ OPERATOR )  )  )     {", "throw   new   BootstrapMethodError (  \" This   parameter   is   only   supported   for   BINARY _ OPERATORs \"  )  ;", "}", "if    (  (  (  ( flags    &     (  . OPERATOR _ COMPOUND _ ASSIGNMENT )  )     !  =     0  )     &  &     ( flavor    !  =     (  . BINARY _ OPERATOR )  )  )     &  &     ( flavor    !  =     (  . SHIFT _ OPERATOR )  )  )     {", "throw   new   BootstrapMethodError (  \" This   parameter   is   only   supported   for   BINARY / SHIFT _ OPERATORs \"  )  ;", "}", "return   new    . MIC ( name ,    type ,    initialDepth ,    flavor ,    flags )  ;", "default    :", "throw   new   BootstrapMethodError (  (  \" Illegal   static   bootstrap   parameter   for   flavor :     \"     +    flavor )  )  ;", "}", "}", "METHOD_END"], "methodName": ["bootstrap"], "fileName": "org.elasticsearch.painless.DefBootstrap"}, {"methodBody": ["METHOD_START", "{", "DefBootstrap . PIC   dsite    =     (  ( DefBootstrap . PIC )     ( site )  )  ;", "assertEquals ( expected ,    dsite . depth )  ;", "}", "METHOD_END"], "methodName": ["assertDepthEquals"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "DefBootstrap . PIC   site    =     (  ( DefBootstrap . PIC )     ( DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" size \"  ,    MethodType . methodType ( int . class ,    Object . class )  ,     0  ,    DefBootstrap . METHOD _ CALL ,     \"  \"  )  )  )  ;", "site . depth    =    DefBootstrap . PIC . MAX _ DEPTH ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", "assertEquals (  2  ,     (  ( int )     ( handle . invokeExact (  (  ( Object )     ( Arrays . asList (  \"  1  \"  ,     \"  2  \"  )  )  )  )  )  )  )  ;", "assertEquals (  1  ,     (  ( int )     ( handle . invokeExact (  (  ( Object )     ( Collections . singletonMap (  \" a \"  ,     \" b \"  )  )  )  )  )  )  )  ;", "assertEquals (  3  ,     (  ( int )     ( handle . invokeExact (  (  ( Object )     ( Arrays . asList (  \" x \"  ,     \" y \"  ,     \" z \"  )  )  )  )  )  )  )  ;", "assertEquals (  2  ,     (  ( int )     ( handle . invokeExact (  (  ( Object )     ( Arrays . asList (  \" u \"  ,     \" v \"  )  )  )  )  )  )  )  ;", "final   HashMap < String ,    String >    map    =    new   HashMap <  >  (  )  ;", "map . put (  \" x \"  ,     \" y \"  )  ;", "map . put (  \" a \"  ,     \" b \"  )  ;", "assertEquals (  2  ,     (  ( int )     ( handle . invokeExact (  (  ( Object )     ( map )  )  )  )  )  )  ;", "final   IllegalArgumentException   iae    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "Integer . toString (  (  ( int )     ( handle . invokeExact ( new   Object (  )  )  )  )  )  ;", "}  )  ;", "assertEquals (  \" Unable   to   find   dynamic   method    [ size ]    with    [  0  ]    arguments   for   class    [ Object ]  .  \"  ,    iae . getMessage (  )  )  ;", "assertTrue (  \" Does   not   fail   inside   ClassValue . computeValue (  )  \"  ,    Arrays . stream ( iae . getStackTrace (  )  )  . anyMatch (  (    e )     -  >     {", "return    ( e . getMethodName (  )  . equals (  \" computeValue \"  )  )     &  &     ( e . getClassName (  )  . startsWith (  \"  $ PIC $  \"  )  )  ;", "}  )  )  ;", "}", "METHOD_END"], "methodName": ["testMegamorphic"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "DefBootstrap . MIC   site    =     (  ( DefBootstrap . MIC )     ( DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" add \"  ,    MethodType . methodType ( Object . class ,    int . class ,    Object . class )  ,     0  ,    DefBootstrap . BINARY _ OPERATOR ,     0  )  )  )  ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", "expectThrows ( NullPointerException . class ,     (  )     -  >     {", "assertNotNull (  (  ( Object )     ( handle . invokeExact (  5  ,     (  ( Object )     ( null )  )  )  )  )  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testNoNullGuardAdd"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "DefBootstrap . MIC   site    =     (  ( DefBootstrap . MIC )     ( DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" add \"  ,    MethodType . methodType ( Object . class ,    int . class ,    Object . class )  ,     0  ,    DefBootstrap . BINARY _ OPERATOR ,     0  )  )  )  ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", "assertEquals (  2  ,     (  ( Object )     ( handle . invokeExact (  1  ,     (  ( Object )     (  1  )  )  )  )  )  )  ;", "expectThrows ( NullPointerException . class ,     (  )     -  >     {", "assertNotNull (  (  ( Object )     ( handle . invokeExact (  5  ,     (  ( Object )     ( null )  )  )  )  )  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testNoNullGuardAddWhenCached"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "DefBootstrap . MIC   site    =     (  ( DefBootstrap . MIC )     ( DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" add \"  ,    MethodType . methodType ( Object . class ,    Object . class ,    Object . class )  ,     0  ,    DefBootstrap . BINARY _ OPERATOR ,    DefBootstrap . OPERATOR _ ALLOWS _ NULL )  )  )  ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", "assertEquals (  \" nulltest \"  ,     (  ( Object )     ( handle . invokeExact (  (  ( Object )     ( null )  )  ,     (  ( Object )     (  \" test \"  )  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullGuardAdd"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "DefBootstrap . MIC   site    =     (  ( DefBootstrap . MIC )     ( DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" add \"  ,    MethodType . methodType ( Object . class ,    Object . class ,    Object . class )  ,     0  ,    DefBootstrap . BINARY _ OPERATOR ,    DefBootstrap . OPERATOR _ ALLOWS _ NULL )  )  )  ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", "assertEquals (  2  ,     (  ( Object )     ( handle . invokeExact (  (  ( Object )     (  1  )  )  ,     (  ( Object )     (  1  )  )  )  )  )  )  ;", "assertEquals (  \" nulltest \"  ,     (  ( Object )     ( handle . invokeExact (  (  ( Object )     ( null )  )  ,     (  ( Object )     (  \" test \"  )  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullGuardAddWhenCached"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "DefBootstrap . MIC   site    =     (  ( DefBootstrap . MIC )     ( DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" eq \"  ,    MethodType . methodType ( boolean . class ,    Object . class ,    Object . class )  ,     0  ,    DefBootstrap . BINARY _ OPERATOR ,    DefBootstrap . OPERATOR _ ALLOWS _ NULL )  )  )  ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", "assertFalse (  (  ( boolean )     ( handle . invokeExact (  (  ( Object )     ( null )  )  ,     (  ( Object )     (  \" test \"  )  )  )  )  )  )  ;", "assertTrue (  (  ( boolean )     ( handle . invokeExact (  (  ( Object )     ( null )  )  ,     (  ( Object )     ( null )  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullGuardEq"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "DefBootstrap . MIC   site    =     (  ( DefBootstrap . MIC )     ( DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" eq \"  ,    MethodType . methodType ( boolean . class ,    Object . class ,    Object . class )  ,     0  ,    DefBootstrap . BINARY _ OPERATOR ,    DefBootstrap . OPERATOR _ ALLOWS _ NULL )  )  )  ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", "assertTrue (  (  ( boolean )     ( handle . invokeExact (  (  ( Object )     (  1  )  )  ,     (  ( Object )     (  1  )  )  )  )  )  )  ;", "assertFalse (  (  ( boolean )     ( handle . invokeExact (  (  ( Object )     ( null )  )  ,     (  ( Object )     (  \" test \"  )  )  )  )  )  )  ;", "assertTrue (  (  ( boolean )     ( handle . invokeExact (  (  ( Object )     ( null )  )  ,     (  ( Object )     ( null )  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullGuardEqWhenCached"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "CallSite   site    =    DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" toString \"  ,    MethodType . methodType ( String . class ,    Object . class )  ,     0  ,    DefBootstrap . METHOD _ CALL ,     \"  \"  )  ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", ". assertDepthEquals ( site ,     0  )  ;", "assertEquals (  \"  5  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  5  )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     1  )  ;", "assertEquals (  \"  6  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  6  )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     1  )  ;", "}", "METHOD_END"], "methodName": ["testOneType"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    DefBootstrap . PIC . MAX _ DEPTH )  ;", "CallSite   site    =    DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" toString \"  ,    MethodType . methodType ( String . class ,    Object . class )  ,     0  ,    DefBootstrap . METHOD _ CALL ,     \"  \"  )  ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", ". assertDepthEquals ( site ,     0  )  ;", "assertEquals (  \"  5  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  5  )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     1  )  ;", "assertEquals (  \"  1  .  5  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  1  .  5 F )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     2  )  ;", "assertEquals (  \"  6  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  6 L )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     3  )  ;", "assertEquals (  \"  3  .  2  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  3  .  2  )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     4  )  ;", "assertEquals (  \" foo \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  \" foo \"  )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     5  )  ;", "assertEquals (  \" c \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  ' c '  )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     5  )  ;", "}", "METHOD_END"], "methodName": ["testTooManyTypes"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "CallSite   site    =    DefBootstrap . bootstrap ( definition ,    MethodHandles . publicLookup (  )  ,     \" toString \"  ,    MethodType . methodType ( String . class ,    Object . class )  ,     0  ,    DefBootstrap . METHOD _ CALL ,     \"  \"  )  ;", "MethodHandle   handle    =    site . dynamicInvoker (  )  ;", ". assertDepthEquals ( site ,     0  )  ;", "assertEquals (  \"  5  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  5  )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     1  )  ;", "assertEquals (  \"  1  .  5  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  1  .  5 F )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     2  )  ;", "assertEquals (  \"  6  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  6  )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     2  )  ;", "assertEquals (  \"  2  .  5  \"  ,     (  ( String )     ( handle . invokeExact (  (  ( Object )     (  2  .  5 F )  )  )  )  )  )  ;", ". assertDepthEquals ( site ,     2  )  ;", "}", "METHOD_END"], "methodName": ["testTwoTypes"], "fileName": "org.elasticsearch.painless.DefBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  +  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    +    b ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    +    b ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    +    b ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   String )     {", "return    (  ( String )     ( left )  )     +    right ;", "} else", "if    ( right   instanceof   String )     {", "return   left    +     (  ( String )     ( right )  )  ;", "} else", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "if    (  ( left   instanceof   Double )     |  |     ( right   instanceof   Double )  )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     +     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Float )     |  |     ( right   instanceof   Float )  )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     +     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     +     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     +     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "if    ( left   instanceof   Double )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     +     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Long )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     +     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Float )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     +     (  ( char )     ( right )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     +     (  ( char )     ( right )  )  ;", "}", "}", "} else", "if    ( left   instanceof   Character )     {", "if    ( right   instanceof   Number )     {", "if    ( right   instanceof   Double )     {", "return    (  ( char )     ( left )  )     +     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Long )     {", "return    (  ( char )     ( left )  )     +     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Float )     {", "return    (  ( char )     ( left )  )     +     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else    {", "return    (  ( char )     ( left )  )     +     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( char )     ( left )  )     +     (  ( char )     ( right )  )  ;", "}", "}", "throw   new   CsCastException (  (  (  (  (  (  \" Cannot   apply    [  +  ]    operation   to   types    \"     +     \"  [  \"  )     +     ( left . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    and    [  \"  )     +     ( right . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    +    b ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    &    b ;", "}", "METHOD_END"], "methodName": ["and"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  &  ]    operation   to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["and"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  &  ]    operation   to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["and"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    &    b ;", "}", "METHOD_END"], "methodName": ["and"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    (  ( left   instanceof   Boolean )     &  &     ( right   instanceof   Boolean )  )     {", "return    (  ( boolean )     ( left )  )     &     (  ( boolean )     ( right )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  . longIntegralValue ( left )  )     &     (  . longIntegralValue ( right )  )  ;", "} else    {", "return    (  . intIntegralValue ( left )  )     &     (  . intIntegralValue ( right )  )  ;", "}", "}", "METHOD_END"], "methodName": ["and"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    &    b ;", "}", "METHOD_END"], "methodName": ["and"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "MethodType   newType    =    MethodType . methodType ( classA )  . unwrap (  )  ;", "MethodType   targetType    =    MethodType . methodType ( target . type (  )  . returnType (  )  )  . unwrap (  )  ;", "if    (  ( newType . returnType (  )  )     =  =     ( targetType . returnType (  )  )  )     {", "return   target ;", "}", "if    (  (  ( newType . returnType (  )  )     =  =     ( boolean . class )  )     |  |     (  ( targetType . returnType (  )  )     =  =     ( boolean . class )  )  )     {", "throw   new   ClassCastException (  (  (  (  \" Cannot   cast    \"     +     ( targetType . returnType (  )  )  )     +     \"    to    \"  )     +     ( newType . returnType (  )  )  )  )  ;", "}", "return   MethodHandles . explicitCastArguments ( target ,    target . type (  )  . changeReturnType ( newType . returnType (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["cast"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  /  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["div"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    /    b ;", "}", "METHOD_END"], "methodName": ["div"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    /    b ;", "}", "METHOD_END"], "methodName": ["div"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    /    b ;", "}", "METHOD_END"], "methodName": ["div"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "if    (  ( left   instanceof   Double )     |  |     ( right   instanceof   Double )  )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     /     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Float )     |  |     ( right   instanceof   Float )  )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     /     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     /     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     /     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "if    ( left   instanceof   Double )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     /     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Long )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     /     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Float )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     /     (  ( char )     ( right )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     /     (  ( char )     ( right )  )  ;", "}", "}", "} else", "if    ( left   instanceof   Character )     {", "if    ( right   instanceof   Number )     {", "if    ( right   instanceof   Double )     {", "return    (  ( char )     ( left )  )     /     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Long )     {", "return    (  ( char )     ( left )  )     /     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Float )     {", "return    (  ( char )     ( left )  )     /     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else    {", "return    (  ( char )     ( left )  )     /     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( char )     ( left )  )     /     (  ( char )     ( right )  )  ;", "}", "}", "throw   new   CsCastException (  (  (  (  (  (  \" Cannot   apply    [  /  ]    operation   to   types    \"     +     \"  [  \"  )     +     ( left . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    and    [  \"  )     +     ( right . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["div"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    /    b ;", "}", "METHOD_END"], "methodName": ["div"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( value    !  =    null )     {", "if    ( clazz    =  =     ( value . getClass (  )  )  )     {", "return   value ;", "}", "if    ( clazz    =  =     ( Integer . class )  )     {", "return    . getNumber ( value )  . intValue (  )  ;", "} else", "if    ( clazz    =  =     ( Long . class )  )     {", "return    . getNumber ( value )  . longValue (  )  ;", "} else", "if    ( clazz    =  =     ( Double . class )  )     {", "return    . getNumber ( value )  . doubleValue (  )  ;", "} else", "if    ( clazz    =  =     ( Float . class )  )     {", "return    . getNumber ( value )  . floatValue (  )  ;", "} else", "if    ( clazz    =  =     ( Short . class )  )     {", "return    . getNumber ( value )  . shortValue (  )  ;", "} else", "if    ( clazz    =  =     ( Byte . class )  )     {", "return    . getNumber ( value )  . byteValue (  )  ;", "} else", "if    ( clazz    =  =     ( Character . class )  )     {", "return    (  ( char )     (  . getNumber ( value )  . intValue (  )  )  )  ;", "}", "return   clazz . cast ( value )  ;", "} else    {", "return   value ;", "}", "}", "METHOD_END"], "methodName": ["dynamicCast"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "MethodHandle   cast    =    DefMath . DYNAMIC _ RECEIVER _ CAST . asType ( MethodType . methodType ( target . type (  )  . returnType (  )  ,    target . type (  )  . returnType (  )  ,    target . type (  )  . parameterType (  0  )  )  )  ;", "cast    =    MethodHandles . dropArguments ( cast ,     2  ,    target . type (  )  . parameterType (  1  )  )  ;", "return   MethodHandles . foldArguments ( cast ,    target )  ;", "}", "METHOD_END"], "methodName": ["dynamicCast"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "desired    =    MethodType . methodType ( desired )  . wrap (  )  . returnType (  )  ;", "MethodHandle   cast    =     . DYNAMIC _ CAST . bindTo ( desired )  ;", "return   MethodHandles . filterReturnValue ( target ,    cast )  ;", "}", "METHOD_END"], "methodName": ["dynamicCast"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( lhs    !  =    null )     {", "return    . dynamicCast ( lhs . getClass (  )  ,    returnValue )  ;", "} else    {", "return   returnValue ;", "}", "}", "METHOD_END"], "methodName": ["dynamicReceiverCast"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    =  =    b ;", "}", "METHOD_END"], "methodName": ["eq"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    =  =    b ;", "}", "METHOD_END"], "methodName": ["eq"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    =  =    b ;", "}", "METHOD_END"], "methodName": ["eq"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    =  =    b ;", "}", "METHOD_END"], "methodName": ["eq"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    (  ( left    !  =    null )     &  &     ( right    !  =    null )  )     {", "if    ( left   instanceof   Double )     {", "if    ( right   instanceof   Number )     {", "return    (  ( double )     ( left )  )     =  =     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( double )     ( left )  )     =  =     (  ( char )     ( right )  )  ;", "}", "} else", "if    ( right   instanceof   Double )     {", "if    ( left   instanceof   Number )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     =  =     (  ( double )     ( right )  )  ;", "} else", "if    ( left   instanceof   Character )     {", "return    (  ( char )     ( left )  )     =  =     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "}", "} else", "if    ( left   instanceof   Float )     {", "if    ( right   instanceof   Number )     {", "return    (  ( float )     ( left )  )     =  =     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( float )     ( left )  )     =  =     (  ( char )     ( right )  )  ;", "}", "} else", "if    ( right   instanceof   Float )     {", "if    ( left   instanceof   Number )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     =  =     (  ( float )     ( right )  )  ;", "} else", "if    ( left   instanceof   Character )     {", "return    (  ( char )     ( left )  )     =  =     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "}", "} else", "if    ( left   instanceof   Long )     {", "if    ( right   instanceof   Number )     {", "return    (  ( long )     ( left )  )     =  =     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( long )     ( left )  )     =  =     (  ( char )     ( right )  )  ;", "}", "} else", "if    ( right   instanceof   Long )     {", "if    ( left   instanceof   Number )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     =  =     (  ( long )     ( right )  )  ;", "} else", "if    ( left   instanceof   Character )     {", "return    (  ( char )     ( left )  )     =  =     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "}", "} else", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     =  =     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "} else", "if    ( right   instanceof   Character )     {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     =  =     (  ( char )     ( right )  )  ;", "}", "} else", "if    (  ( right   instanceof   Number )     &  &     ( left   instanceof   Character )  )     {", "return    (  ( char )     ( left )  )     =  =     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Character )     &  &     ( right   instanceof   Character )  )     {", "return    (  ( char )     ( left )  )     =  =     (  ( char )     ( right )  )  ;", "}", "return   left . equals ( right )  ;", "}", "return    ( left    =  =    null )     &  &     ( right    =  =    null )  ;", "}", "METHOD_END"], "methodName": ["eq"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    =  =    b ;", "}", "METHOD_END"], "methodName": ["eq"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( o   instanceof   Number )     {", "return    (  ( Number )     ( o )  )  ;", "} else", "if    ( o   instanceof   Character )     {", "return   Integer . valueOf (  (  ( char )     ( o )  )  )  ;", "} else    {", "throw   new   CsCastException (  (  (  \" Cannot   convert    [  \"     +     ( o . getCs (  )  )  )     +     \"  ]    to   a   Number \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getNumber"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  >  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["gt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >    b ;", "}", "METHOD_END"], "methodName": ["gt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >    b ;", "}", "METHOD_END"], "methodName": ["gt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >    b ;", "}", "METHOD_END"], "methodName": ["gt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "if    (  ( left   instanceof   Double )     |  |     ( right   instanceof   Double )  )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     >     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Float )     |  |     ( right   instanceof   Float )  )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     >     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     >     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     >     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "if    ( left   instanceof   Double )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     >     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Long )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     >     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Float )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     >     (  ( char )     ( right )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     >     (  ( char )     ( right )  )  ;", "}", "}", "} else", "if    ( left   instanceof   Character )     {", "if    ( right   instanceof   Number )     {", "if    ( right   instanceof   Double )     {", "return    (  ( char )     ( left )  )     >     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Long )     {", "return    (  ( char )     ( left )  )     >     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Float )     {", "return    (  ( char )     ( left )  )     >     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else    {", "return    (  ( char )     ( left )  )     >     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( char )     ( left )  )     >     (  ( char )     ( right )  )  ;", "}", "}", "throw   new   CsCastException (  (  (  (  (  (  \" Cannot   apply    [  >  ]    operation   to   types    \"     +     \"  [  \"  )     +     ( left . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    and    [  \"  )     +     ( right . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["gt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >    b ;", "}", "METHOD_END"], "methodName": ["gt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  >  =  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["gte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >  =    b ;", "}", "METHOD_END"], "methodName": ["gte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >  =    b ;", "}", "METHOD_END"], "methodName": ["gte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >  =    b ;", "}", "METHOD_END"], "methodName": ["gte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "if    (  ( left   instanceof   Double )     |  |     ( right   instanceof   Double )  )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     >  =     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Float )     |  |     ( right   instanceof   Float )  )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     >  =     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     >  =     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     >  =     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "if    ( left   instanceof   Double )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     >  =     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Long )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     >  =     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Float )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     >  =     (  ( char )     ( right )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     >  =     (  ( char )     ( right )  )  ;", "}", "}", "} else", "if    ( left   instanceof   Character )     {", "if    ( right   instanceof   Number )     {", "if    ( right   instanceof   Double )     {", "return    (  ( char )     ( left )  )     >  =     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Long )     {", "return    (  ( char )     ( left )  )     >  =     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Float )     {", "return    (  ( char )     ( left )  )     >  =     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else    {", "return    (  ( char )     ( left )  )     >  =     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( char )     ( left )  )     >  =     (  ( char )     ( right )  )  ;", "}", "}", "throw   new   CsCastException (  (  (  (  (  (  \" Cannot   apply    [  >  ]    operation   to   types    \"     +     \"  [  \"  )     +     ( left . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    and    [  \"  )     +     ( right . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["gte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >  =    b ;", "}", "METHOD_END"], "methodName": ["gte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( o   instanceof   Integer )     |  |     ( o   instanceof   Short )  )     |  |     ( o   instanceof   Byte )  )     {", "return    (  ( Number )     ( o )  )  . intValue (  )  ;", "} else", "if    ( o   instanceof   Character )     {", "return    (  ( char )     ( o )  )  ;", "} else    {", "throw   new   CsCastException (  (  (  \" Cannot   convert    [  \"     +     ( o . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    to   an   integral   value .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["intIntegralValue"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( o   instanceof   Long )     {", "return    (  ( long )     ( o )  )  ;", "} else", "if    (  (  ( o   instanceof   Integer )     |  |     ( o   instanceof   Short )  )     |  |     ( o   instanceof   Byte )  )     {", "return    (  ( Number )     ( o )  )  . longValue (  )  ;", "} else", "if    ( o   instanceof   Character )     {", "return    (  ( char )     ( o )  )  ;", "} else    {", "throw   new   CsCastException (  (  (  \" Cannot   convert    [  \"     +     ( o . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    to   an   integral   value .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["longIntegralValue"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "MethodHandle   handle    =    DefMath . TYPE _ OP _ MAPPING . get ( DefMath . promote ( DefMath . promote ( DefMath . unbox ( classA )  )  ,    DefMath . promote ( DefMath . unbox ( classB )  )  )  )  . get ( name )  ;", "if    ( handle    =  =    null )     {", "throw   new   ClassCastException (  (  (  (  (  (  (  \" Cannot   apply   operator    [  \"     +    name )     +     \"  ]    to   types    [  \"  )     +    classA )     +     \"  ]    and    [  \"  )     +    classB )     +     \"  ]  \"  )  )  ;", "}", "return   handle ;", "}", "METHOD_END"], "methodName": ["lookupBinary"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   DefMath . TYPE _ OP _ MAPPING . get ( Object . class )  . get ( name )  ;", "}", "METHOD_END"], "methodName": ["lookupGeneric"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "MethodHandle   handle    =    DefMath . TYPE _ OP _ MAPPING . get ( DefMath . promote ( DefMath . unbox ( receiverClass )  )  )  . get ( name )  ;", "if    ( handle    =  =    null )     {", "throw   new   ClassCastException (  (  (  (  (  \" Cannot   apply   operator    [  \"     +    name )     +     \"  ]    to   type    [  \"  )     +    receiverClass )     +     \"  ]  \"  )  )  ;", "}", "return   handle ;", "}", "METHOD_END"], "methodName": ["lookupUnary"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  <  <  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["lsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  <  <  ]    operation   to   type    [ double ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["lsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  <  <  ]    operation   to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["lsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <  <    b ;", "}", "METHOD_END"], "methodName": ["lsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Long )     {", "return    (  ( long )     ( left )  )     <  <    right ;", "} else    {", "return    (  . intIntegralValue ( left )  )     <  <    right ;", "}", "}", "METHOD_END"], "methodName": ["lsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <  <    b ;", "}", "METHOD_END"], "methodName": ["lsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  <  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["lt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <    b ;", "}", "METHOD_END"], "methodName": ["lt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <    b ;", "}", "METHOD_END"], "methodName": ["lt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <    b ;", "}", "METHOD_END"], "methodName": ["lt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "if    (  ( left   instanceof   Double )     |  |     ( right   instanceof   Double )  )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     <     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Float )     |  |     ( right   instanceof   Float )  )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     <     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     <     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     <     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "if    ( left   instanceof   Double )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     <     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Long )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     <     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Float )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     <     (  ( char )     ( right )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     <     (  ( char )     ( right )  )  ;", "}", "}", "} else", "if    ( left   instanceof   Character )     {", "if    ( right   instanceof   Number )     {", "if    ( right   instanceof   Double )     {", "return    (  ( char )     ( left )  )     <     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Long )     {", "return    (  ( char )     ( left )  )     <     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Float )     {", "return    (  ( char )     ( left )  )     <     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else    {", "return    (  ( char )     ( left )  )     <     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( char )     ( left )  )     <     (  ( char )     ( right )  )  ;", "}", "}", "throw   new   CsCastException (  (  (  (  (  (  \" Cannot   apply    [  <  ]    operation   to   types    \"     +     \"  [  \"  )     +     ( left . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    and    [  \"  )     +     ( right . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["lt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <    b ;", "}", "METHOD_END"], "methodName": ["lt"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  <  =  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["lte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <  =    b ;", "}", "METHOD_END"], "methodName": ["lte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <  =    b ;", "}", "METHOD_END"], "methodName": ["lte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <  =    b ;", "}", "METHOD_END"], "methodName": ["lte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "if    (  ( left   instanceof   Double )     |  |     ( right   instanceof   Double )  )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     <  =     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Float )     |  |     ( right   instanceof   Float )  )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     <  =     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     <  =     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     <  =     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "if    ( left   instanceof   Double )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     <  =     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Long )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     <  =     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Float )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     <  =     (  ( char )     ( right )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     <  =     (  ( char )     ( right )  )  ;", "}", "}", "} else", "if    ( left   instanceof   Character )     {", "if    ( right   instanceof   Number )     {", "if    ( right   instanceof   Double )     {", "return    (  ( char )     ( left )  )     <  =     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Long )     {", "return    (  ( char )     ( left )  )     <  =     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Float )     {", "return    (  ( char )     ( left )  )     <  =     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else    {", "return    (  ( char )     ( left )  )     <  =     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( char )     ( left )  )     <  =     (  ( char )     ( right )  )  ;", "}", "}", "throw   new   CsCastException (  (  (  (  (  (  \" Cannot   apply    [  <  =  ]    operation   to   types    \"     +     \"  [  \"  )     +     ( left . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    and    [  \"  )     +     ( right . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["lte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    <  =    b ;", "}", "METHOD_END"], "methodName": ["lte"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  *  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["mul"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    *    b ;", "}", "METHOD_END"], "methodName": ["mul"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    *    b ;", "}", "METHOD_END"], "methodName": ["mul"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    *    b ;", "}", "METHOD_END"], "methodName": ["mul"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "if    (  ( left   instanceof   Double )     |  |     ( right   instanceof   Double )  )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     *     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Float )     |  |     ( right   instanceof   Float )  )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     *     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     *     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     *     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "if    ( left   instanceof   Double )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     *     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Long )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     *     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Float )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     *     (  ( char )     ( right )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     *     (  ( char )     ( right )  )  ;", "}", "}", "} else", "if    ( left   instanceof   Character )     {", "if    ( right   instanceof   Number )     {", "if    ( right   instanceof   Double )     {", "return    (  ( char )     ( left )  )     *     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Long )     {", "return    (  ( char )     ( left )  )     *     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Float )     {", "return    (  ( char )     ( left )  )     *     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else    {", "return    (  ( char )     ( left )  )     *     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( char )     ( left )  )     *     (  ( char )     ( right )  )  ;", "}", "}", "throw   new   CsCastException (  (  (  (  (  (  \" Cannot   apply    [  *  ]    operation   to   types    \"     +     \"  [  \"  )     +     ( left . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    and    [  \"  )     +     ( right . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["mul"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    *    b ;", "}", "METHOD_END"], "methodName": ["mul"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  -  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["neg"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    - v ;", "}", "METHOD_END"], "methodName": ["neg"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    - v ;", "}", "METHOD_END"], "methodName": ["neg"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    - v ;", "}", "METHOD_END"], "methodName": ["neg"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( unary   instanceof   Double )     {", "return    -  (  ( double )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Long )     {", "return    -  (  ( long )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Integer )     {", "return    -  (  ( int )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Float )     {", "return    -  (  ( float )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Short )     {", "return    -  (  ( short )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Character )     {", "return    -  (  ( char )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Byte )     {", "return    -  (  ( byte )     ( unary )  )  ;", "}", "throw   new   CsCastException (  (  (  (  \" Cannot   apply    [  -  ]    operation   to   type    \"     +     \"  [  \"  )     +     ( unary . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["neg"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    - v ;", "}", "METHOD_END"], "methodName": ["neg"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply   not    [  ~  ]    to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["not"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply   not    [  ~  ]    to   type    [ double ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["not"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply   not    [  ~  ]    to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["not"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    ~ v ;", "}", "METHOD_END"], "methodName": ["not"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( unary   instanceof   Long )     {", "return    ~  (  ( Long )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Integer )     {", "return    ~  (  ( Integer )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Short )     {", "return    ~  (  ( Short )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Character )     {", "return    ~  (  ( Character )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Byte )     {", "return    ~  (  ( Byte )     ( unary )  )  ;", "}", "throw   new   CsCastException (  (  (  (  \" Cannot   apply    [  ~  ]    operation   to   type    \"     +     \"  [  \"  )     +     ( unary . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["not"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    ~ v ;", "}", "METHOD_END"], "methodName": ["not"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    |    b ;", "}", "METHOD_END"], "methodName": ["or"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  |  ]    operation   to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["or"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  |  ]    operation   to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["or"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    |    b ;", "}", "METHOD_END"], "methodName": ["or"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    (  ( left   instanceof   Boolean )     &  &     ( right   instanceof   Boolean )  )     {", "return    (  ( boolean )     ( left )  )     |     (  ( boolean )     ( right )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  . longIntegralValue ( left )  )     |     (  . longIntegralValue ( right )  )  ;", "} else    {", "return    (  . intIntegralValue ( left )  )     |     (  . intIntegralValue ( right )  )  ;", "}", "}", "METHOD_END"], "methodName": ["or"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    |    b ;", "}", "METHOD_END"], "methodName": ["or"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  +  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["plus"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    + v ;", "}", "METHOD_END"], "methodName": ["plus"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    + v ;", "}", "METHOD_END"], "methodName": ["plus"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    + v ;", "}", "METHOD_END"], "methodName": ["plus"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( unary   instanceof   Double )     {", "return    +  (  ( double )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Long )     {", "return    +  (  ( long )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Integer )     {", "return    +  (  ( int )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Float )     {", "return    +  (  ( float )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Short )     {", "return    +  (  ( short )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Character )     {", "return    +  (  ( char )     ( unary )  )  ;", "} else", "if    ( unary   instanceof   Byte )     {", "return    +  (  ( byte )     ( unary )  )  ;", "}", "throw   new   CsCastException (  (  (  (  \" Cannot   apply    [  +  ]    operation   to   type    \"     +     \"  [  \"  )     +     ( unary . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["plus"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return    + v ;", "}", "METHOD_END"], "methodName": ["plus"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    (  ( clazz . isPrimitive (  )  )     =  =    false )     {", "return   Object . cs ;", "}", "if    (  (  (  ( clazz    =  =     ( byte . cs )  )     |  |     ( clazz    =  =     ( short . cs )  )  )     |  |     ( clazz    =  =     ( char . cs )  )  )     |  |     ( clazz    =  =     ( int . cs )  )  )     {", "return   int . cs ;", "} else    {", "return   clazz ;", "}", "}", "METHOD_END"], "methodName": ["promote"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( a . isPrimitive (  )  )     =  =    false )     |  |     (  ( b . isPrimitive (  )  )     =  =    false )  )     {", "return   Object . cs ;", "}", "if    (  ( a    =  =     ( boolean . cs )  )     &  &     ( b    =  =     ( boolean . cs )  )  )     {", "return   boolean . cs ;", "}", "if    (  ( a    =  =     ( double . cs )  )     |  |     ( b    =  =     ( double . cs )  )  )     {", "return   double . cs ;", "} else", "if    (  ( a    =  =     ( float . cs )  )     |  |     ( b    =  =     ( float . cs )  )  )     {", "return   float . cs ;", "} else", "if    (  ( a    =  =     ( long . cs )  )     |  |     ( b    =  =     ( long . cs )  )  )     {", "return   long . cs ;", "} else    {", "return   int . cs ;", "}", "}", "METHOD_END"], "methodName": ["promote"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  %  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["rem"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    %    b ;", "}", "METHOD_END"], "methodName": ["rem"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    %    b ;", "}", "METHOD_END"], "methodName": ["rem"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    %    b ;", "}", "METHOD_END"], "methodName": ["rem"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "if    (  ( left   instanceof   Double )     |  |     ( right   instanceof   Double )  )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     %     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Float )     |  |     ( right   instanceof   Float )  )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     %     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     %     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     %     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "if    ( left   instanceof   Double )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     %     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Long )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     %     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Float )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     %     (  ( char )     ( right )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     %     (  ( char )     ( right )  )  ;", "}", "}", "} else", "if    ( left   instanceof   Character )     {", "if    ( right   instanceof   Number )     {", "if    ( right   instanceof   Double )     {", "return    (  ( char )     ( left )  )     %     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Long )     {", "return    (  ( char )     ( left )  )     %     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Float )     {", "return    (  ( char )     ( left )  )     %     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else    {", "return    (  ( char )     ( left )  )     %     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( char )     ( left )  )     %     (  ( char )     ( right )  )  ;", "}", "}", "throw   new   CsCastException (  (  (  (  (  (  \" Cannot   apply    [  %  ]    operation   to   types    \"     +     \"  [  \"  )     +     ( left . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    and    [  \"  )     +     ( right . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["rem"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    %    b ;", "}", "METHOD_END"], "methodName": ["rem"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  >  >  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["rsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  >  >  ]    operation   to   type    [ double ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["rsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  >  >  ]    operation   to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["rsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >  >    b ;", "}", "METHOD_END"], "methodName": ["rsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Long )     {", "return    (  ( long )     ( left )  )     >  >    right ;", "} else    {", "return    (  . intIntegralValue ( left )  )     >  >    right ;", "}", "}", "METHOD_END"], "methodName": ["rsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >  >    b ;", "}", "METHOD_END"], "methodName": ["rsh"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  -  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["sub"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    -    b ;", "}", "METHOD_END"], "methodName": ["sub"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    -    b ;", "}", "METHOD_END"], "methodName": ["sub"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    -    b ;", "}", "METHOD_END"], "methodName": ["sub"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Number )     {", "if    ( right   instanceof   Number )     {", "if    (  ( left   instanceof   Double )     |  |     ( right   instanceof   Double )  )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     -     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Float )     |  |     ( right   instanceof   Float )  )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     -     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     -     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     -     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "if    ( left   instanceof   Double )     {", "return    (  (  ( Number )     ( left )  )  . doubleValue (  )  )     -     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Long )     {", "return    (  (  ( Number )     ( left )  )  . longValue (  )  )     -     (  ( char )     ( right )  )  ;", "} else", "if    ( left   instanceof   Float )     {", "return    (  (  ( Number )     ( left )  )  . floatValue (  )  )     -     (  ( char )     ( right )  )  ;", "} else    {", "return    (  (  ( Number )     ( left )  )  . intValue (  )  )     -     (  ( char )     ( right )  )  ;", "}", "}", "} else", "if    ( left   instanceof   Character )     {", "if    ( right   instanceof   Number )     {", "if    ( right   instanceof   Double )     {", "return    (  ( char )     ( left )  )     -     (  (  ( Number )     ( right )  )  . doubleValue (  )  )  ;", "} else", "if    ( right   instanceof   Long )     {", "return    (  ( char )     ( left )  )     -     (  (  ( Number )     ( right )  )  . longValue (  )  )  ;", "} else", "if    ( right   instanceof   Float )     {", "return    (  ( char )     ( left )  )     -     (  (  ( Number )     ( right )  )  . floatValue (  )  )  ;", "} else    {", "return    (  ( char )     ( left )  )     -     (  (  ( Number )     ( right )  )  . intValue (  )  )  ;", "}", "} else", "if    ( right   instanceof   Character )     {", "return    (  ( char )     ( left )  )     -     (  ( char )     ( right )  )  ;", "}", "}", "throw   new   CsCastException (  (  (  (  (  (  \" Cannot   apply    [  -  ]    operation   to   types    \"     +     \"  [  \"  )     +     ( left . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]    and    [  \"  )     +     ( right . getCs (  )  . getCanonicalName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["sub"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    -    b ;", "}", "METHOD_END"], "methodName": ["sub"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   MethodType . methodType ( clazz )  . unwrap (  )  . returnType (  )  ;", "}", "METHOD_END"], "methodName": ["unbox"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  >  >  >  ]    operation   to   type    [ boolean ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["ush"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  >  >  >  ]    operation   to   type    [ double ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["ush"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  >  >  >  ]    operation   to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["ush"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >  >  >    b ;", "}", "METHOD_END"], "methodName": ["ush"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    ( left   instanceof   Long )     {", "return    (  ( long )     ( left )  )     >  >  >    right ;", "} else    {", "return    (  . intIntegralValue ( left )  )     >  >  >    right ;", "}", "}", "METHOD_END"], "methodName": ["ush"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    >  >  >    b ;", "}", "METHOD_END"], "methodName": ["ush"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    ^    b ;", "}", "METHOD_END"], "methodName": ["xor"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  ^  ]    operation   to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["xor"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "throw   new   ClassCastException (  \" Cannot   apply    [  ^  ]    operation   to   type    [ float ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["xor"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    ^    b ;", "}", "METHOD_END"], "methodName": ["xor"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "if    (  ( left   instanceof   Boolean )     &  &     ( right   instanceof   Boolean )  )     {", "return    (  ( boolean )     ( left )  )     ^     (  ( boolean )     ( right )  )  ;", "} else", "if    (  ( left   instanceof   Long )     |  |     ( right   instanceof   Long )  )     {", "return    (  . longIntegralValue ( left )  )     ^     (  . longIntegralValue ( right )  )  ;", "} else    {", "return    (  . intIntegralValue ( left )  )     ^     (  . intIntegralValue ( right )  )  ;", "}", "}", "METHOD_END"], "methodName": ["xor"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "return   a    ^    b ;", "}", "METHOD_END"], "methodName": ["xor"], "fileName": "org.elasticsearch.painless.DefMath"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    +    y \"  ,     \" INVOKEDYNAMIC   add ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testAddOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeHasPattern (  \" def   x    =     1  ;    def   y    =     2  ;    return   x    +    y \"  ,     (  (  (  (  (  \"  (  ? s )  .  * INVOKEDYNAMIC   add .  * arguments :  \\  \\ s +  \"     +     (  \"  \\  \\ d +  \"     +     \"  ,  \\  \\ s +  \"  )  )     +     ( DefBootstrap . BINARY _ OPERATOR )  )     +     \"  ,  \\  \\ s +  \"  )     +     ( DefBootstrap . OPERATOR _ ALLOWS _ NULL )  )     +     \"  .  *  \"  )  )  ;", "assertBytecodeHasPattern (  \" def   x    =     1  ;    def   y    =     2  ;    double   z    =    x    +    y \"  ,     (  (  (  (  (  \"  (  ? s )  .  * INVOKEDYNAMIC   add .  * arguments :  \\  \\ s +  \"     +     (  \"  \\  \\ d +  \"     +     \"  ,  \\  \\ s +  \"  )  )     +     ( DefBootstrap . BINARY _ OPERATOR )  )     +     \"  ,  \\  \\ s +  \"  )     +     ( DefBootstrap . OPERATOR _ ALLOWS _ NULL )  )     +     \"  .  *  \"  )  )  ;", "assertBytecodeHasPattern (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    +    y \"  ,     (  (  (  (  (  \"  (  ? s )  .  * INVOKEDYNAMIC   add .  * arguments :  \\  \\ s +  \"     +     (  \"  \\  \\ d +  \"     +     \"  ,  \\  \\ s +  \"  )  )     +     ( DefBootstrap . BINARY _ OPERATOR )  )     +     \"  ,  \\  \\ s +  \"  )     +     0  )     +     \"  .  *  \"  )  )  ;", "assertBytecodeHasPattern (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    +    y \"  ,     (  (  (  (  (  \"  (  ? s )  .  * INVOKEDYNAMIC   add .  * arguments :  \\  \\ s +  \"     +     (  \"  \\  \\ d +  \"     +     \"  ,  \\  \\ s +  \"  )  )     +     ( DefBootstrap . BINARY _ OPERATOR )  )     +     \"  ,  \\  \\ s +  \"  )     +     0  )     +     \"  .  *  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAddOptNullGuards"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    +    y \"  ,     \" INVOKEDYNAMIC   add ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testAddOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    +    y \"  ,     \" INVOKEDYNAMIC   add ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testAddOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    &    y \"  ,     \" INVOKEDYNAMIC   and ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testAndOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    &    y \"  ,     \" INVOKEDYNAMIC   and ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testAndOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    &    y \"  ,     \" INVOKEDYNAMIC   and ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testAndOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" boolean   x    =    true ;    def   y    =    true ;    return   x    ^    y \"  ,     \" INVOKEDYNAMIC   xor ( ZLjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testBooleanXorOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =    true ;    boolean   y    =    true ;    return   x    ^    y \"  ,     \" INVOKEDYNAMIC   xor ( Ljava / lang / Object ; Z ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testBooleanXorOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =    true ;    def   y    =    true ;    boolean   v    =    x    ^    y \"  ,     \" INVOKEDYNAMIC   xor ( Ljava / lang / Object ; Ljava / lang / Object ;  ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testBooleanXorOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    /    y \"  ,     \" INVOKEDYNAMIC   div ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testDivOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    /    y \"  ,     \" INVOKEDYNAMIC   div ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testDivOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    /    y \"  ,     \" INVOKEDYNAMIC   div ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testDivOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     0  ;    def   y    =    new   double [  1  ]  ;    y [  0  ]     =     5  .  0  ;    x    =    y [  0  ]  ;    return   x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayLoad ( Ljava / lang / Object ; I ) D \"  )  ;", "assertEquals (  5  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleBraceArrayOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     1  ;    def   y    =    new   double [  1  ]  ;    y [  0  ]     =    x ;    return   y [  0  ]  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayStore ( Ljava / lang / Object ; ID )  \"  )  ;", "assertEquals (  1  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleBraceArrayOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     0  .  0  ;    def   y    =    new   ArrayList (  )  ;    y . add (  5  .  0  )  ;    x    =    y [  0  ]  ;    return   x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayLoad ( Ljava / lang / Object ; I ) D \"  )  ;", "assertEquals (  5  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleBraceListOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     1  .  0  ;    def   y    =    new   ArrayList (  )  ;    y . add (  0  .  0  )  ;    y [  0  ]     =    x ;    return   y [  0  ]  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayStore ( Ljava / lang / Object ; ID )  \"  )  ;", "assertEquals (  1  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleBraceListOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     0  .  0  ;    def   y    =    new   HashMap (  )  ;    y . put (  0  ,     5  .  0  )  ;    x    =    y [  0  ]  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayLoad ( Ljava / lang / Object ; I ) D \"  )  ;", "assertEquals (  5  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleBraceMapOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     1  .  0  ;    def   y    =    new   HashMap (  )  ;    y . put (  0  ,     2  .  0  )  ;    y [  0  ]     =    x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayStore ( Ljava / lang / Object ; ID )  \"  )  ;", "assertEquals (  1  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleBraceMapOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x ;    def   y    =    new   HashMap (  )  ;    y [  ' double '  ]     =     1  .  0  ;    x    =    y . get (  ' double '  )  ;    return   x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   get ( Ljava / lang / Object ; Ljava / lang / String ;  ) D \"  )  ;", "assertEquals (  1  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleCall0Opti"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x ;    def   y    =    new   HashMap (  )  ;    y [  ' double '  ]     =     1  .  0  ;    x    =    y . get (  ' double '  )  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   get ( Ljava / lang / Object ; Ljava / lang / String ;  ) D \"  )  ;", "assertEquals (  1  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleCall1Opti"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     0  ;    def   y    =    new   ArrayList (  )  ;    y . add (  5  .  0  )  ;    x    =    y .  0  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC    0  ( Ljava / lang / Object ;  ) D \"  )  ;", "assertEquals (  5  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleFieldListOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     1  .  0  ;    def   y    =    new   ArrayList (  )  ;    y . add (  0  )  ;    y .  0     =    x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC    0  ( Ljava / lang / Object ; D )  \"  )  ;", "assertEquals (  1  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleFieldListOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     0  ;    def   y    =    new   HashMap (  )  ;    y . put (  '  0  '  ,     5  .  0  )  ;    x    =    y .  0  ;    return   x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC    0  ( Ljava / lang / Object ;  ) D \"  )  ;", "assertEquals (  5  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleFieldMapOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" double   x    =     1  .  0  ;    def   y    =    new   HashMap (  )  ;    y . put (  '  0  '  ,     1  .  0  )  ;    y .  0     =    x ;    return   y .  0  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC    0  ( Ljava / lang / Object ; D )  \"  )  ;", "assertEquals (  1  .  0  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleFieldMapOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    =  =    y \"  ,     \" INVOKEDYNAMIC   eq ( ILjava / lang / Object ;  ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testEqOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    =  =    y \"  ,     \" INVOKEDYNAMIC   eq ( Ljava / lang / Object ; I ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testEqOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    >    y \"  ,     \" INVOKEDYNAMIC   gt ( ILjava / lang / Object ;  ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testGtOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    >    y \"  ,     \" INVOKEDYNAMIC   gt ( Ljava / lang / Object ; I ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testGtOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    >  =    y \"  ,     \" INVOKEDYNAMIC   gte ( ILjava / lang / Object ;  ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testGteOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    >  =    y \"  ,     \" INVOKEDYNAMIC   gte ( Ljava / lang / Object ; I ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testGteOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x ;  \\ ndef   y    =    new   HashMap (  )  ;  \\ ny [  \\  ' double \\  '  ]     =     1  .  0  ;  \\ nx    =    y . get (  \\  ' double \\  '  )  ;  \\ n \"  ;", "assertBytecodeExists ( script ,     \" INVOKEDYNAMIC   get ( Ljava / lang / Object ; Ljava / lang / String ;  ) I \"  )  ;", "final   Excep   excep    =    ScriptTestCase . expectScriptThrows ( ClassCastExcep . class ,     (  )     -  >     {", "exec ( script )  ;", "}  )  ;", "assertTrue ( excep . getMessage (  )  . contains (  \" Cannot   cast   Integer \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalCast"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     0  ;    def   y    =    new   int [  1  ]  ;    y [  0  ]     =     5  ;    x    =    y [  0  ]  ;    return   x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayLoad ( Ljava / lang / Object ; I ) I \"  )  ;", "assertEquals (  5  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntBraceArrayOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     1  ;    def   y    =    new   int [  1  ]  ;    y [  0  ]     =    x ;    return   y [  0  ]  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayStore ( Ljava / lang / Object ; II )  \"  )  ;", "assertEquals (  1  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntBraceArrayOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     0  ;    def   y    =    new   ArrayList (  )  ;    y . add (  5  )  ;    x    =    y [  0  ]  ;    return   x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayLoad ( Ljava / lang / Object ; I ) I \"  )  ;", "assertEquals (  5  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntBraceListOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     1  ;    def   y    =    new   ArrayList (  )  ;    y . add (  0  )  ;    y [  0  ]     =    x ;    return   y [  0  ]  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayStore ( Ljava / lang / Object ; II )  \"  )  ;", "assertEquals (  1  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntBraceListOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     0  ;    def   y    =    new   HashMap (  )  ;    y . put (  0  ,     5  )  ;    x    =    y [  0  ]  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayLoad ( Ljava / lang / Object ; I ) I \"  )  ;", "assertEquals (  5  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntBraceMapOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     1  ;    def   y    =    new   HashMap (  )  ;    y . put (  0  ,     1  )  ;    y [  0  ]     =    x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   arrayStore ( Ljava / lang / Object ; II )  \"  )  ;", "assertEquals (  1  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntBraceMapOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x ;    def   y    =    new   HashMap (  )  ;    y [  ' int '  ]     =     1  ;    x    =    y . get (  ' int '  )  ;    return   x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   get ( Ljava / lang / Object ; Ljava / lang / String ;  ) I \"  )  ;", "assertEquals (  1  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntCall0Opti"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x ;    def   y    =    new   HashMap (  )  ;    y [  ' int '  ]     =     1  ;    x    =    y . get (  ' int '  )  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC   get ( Ljava / lang / Object ; Ljava / lang / String ;  ) I \"  )  ;", "assertEquals (  1  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntCall1Opti"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     0  ;    def   y    =    new   ArrayList (  )  ;    y . add (  5  )  ;    x    =    y .  0  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC    0  ( Ljava / lang / Object ;  ) I \"  )  ;", "assertEquals (  5  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntFieldListOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     1  ;    def   y    =    new   ArrayList (  )  ;    y . add (  0  )  ;    y .  0     =    x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC    0  ( Ljava / lang / Object ; I )  \"  )  ;", "assertEquals (  1  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntFieldListOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     0  ;    def   y    =    new   HashMap (  )  ;    y . put (  '  0  '  ,     5  )  ;    x    =    y .  0  ;    return   x ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC    0  ( Ljava / lang / Object ;  ) I \"  )  ;", "assertEquals (  5  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntFieldMapOptiLoad"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "final   String   script    =     \" int   x    =     1  ;    def   y    =    new   HashMap (  )  ;    y . put (  '  0  '  ,     1  )  ;    y .  0     =    x ;    return   y .  0  ;  \"  ;", "assertBytecodeExi ( script ,     \" INVOKEDYNAMIC    0  ( Ljava / lang / Object ; I )  \"  )  ;", "assertEquals (  1  ,    exec ( script )  )  ;", "}", "METHOD_END"], "methodName": ["testIntFieldMapOptiStore"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" List   l    =    new   ArrayList (  )  ;    l . stream (  )  . mapToDouble ( Double :  : valueOf )  . map ( x    -  >    x    +     1  )  \"  ,     \" synthetic   lambda $  0  ( D ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testLambdaArguments"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" List   l    =    new   ArrayList (  )  ;    l . removeIf ( x    -  >    x    <     1  0  )  \"  ,     \" synthetic   lambda $  0  ( Ljava / lang / Object ;  ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testLambdaReturnType"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    <  <    y \"  ,     \" INVOKEDYNAMIC   lsh ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testLshOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    <  <    y \"  ,     \" INVOKEDYNAMIC   lsh ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testLshOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    <  <    y \"  ,     \" INVOKEDYNAMIC   lsh ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testLshOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    <    y \"  ,     \" INVOKEDYNAMIC   lt ( ILjava / lang / Object ;  ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testLtOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    <    y \"  ,     \" INVOKEDYNAMIC   lt ( Ljava / lang / Object ; I ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testLtOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    <  =    y \"  ,     \" INVOKEDYNAMIC   lte ( ILjava / lang / Object ;  ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testLteOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    <  =    y \"  ,     \" INVOKEDYNAMIC   lte ( Ljava / lang / Object ; I ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testLteOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    *    y \"  ,     \" INVOKEDYNAMIC   mul ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testMulOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    *    y \"  ,     \" INVOKEDYNAMIC   mul ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testMulOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    *    y \"  ,     \" INVOKEDYNAMIC   mul ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testMulOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    !  =    y \"  ,     \" INVOKEDYNAMIC   eq ( ILjava / lang / Object ;  ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testNeqOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    !  =    y \"  ,     \" INVOKEDYNAMIC   eq ( Ljava / lang / Object ; I ) Z \"  )  ;", "}", "METHOD_END"], "methodName": ["testNeqOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    |    y \"  ,     \" INVOKEDYNAMIC   or ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testOrOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    |    y \"  ,     \" INVOKEDYNAMIC   or ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testOrOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    |    y \"  ,     \" INVOKEDYNAMIC   or ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testOrOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    %    y \"  ,     \" INVOKEDYNAMIC   rem ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testRemOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    %    y \"  ,     \" INVOKEDYNAMIC   rem ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testRemOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    %    y \"  ,     \" INVOKEDYNAMIC   rem ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testRemOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    >  >    y \"  ,     \" INVOKEDYNAMIC   rsh ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testRshOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    >  >    y \"  ,     \" INVOKEDYNAMIC   rsh ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testRshOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    >  >    y \"  ,     \" INVOKEDYNAMIC   rsh ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testRshOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    -    y \"  ,     \" INVOKEDYNAMIC   sub ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testSubOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    -    y \"  ,     \" INVOKEDYNAMIC   sub ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testSubOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    -    y \"  ,     \" INVOKEDYNAMIC   sub ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testSubOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    double   y    =     - x ;    return   y \"  ,     \" INVOKEDYNAMIC   neg ( Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testUnaryMinusOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    double   y    =     ~ x ;    return   y \"  ,     \" INVOKEDYNAMIC   not ( Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testUnaryNotOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    double   y    =     + x ;    return   y \"  ,     \" INVOKEDYNAMIC   plus ( Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testUnaryPlusOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    >  >  >    y \"  ,     \" INVOKEDYNAMIC   ush ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testUshOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    >  >  >    y \"  ,     \" INVOKEDYNAMIC   ush ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testUshOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    >  >  >    y \"  ,     \" INVOKEDYNAMIC   ush ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testUshOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" int   x    =     1  ;    def   y    =     2  ;    return   x    ^    y \"  ,     \" INVOKEDYNAMIC   xor ( ILjava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testXorOptLHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    int   y    =     2  ;    return   x    ^    y \"  ,     \" INVOKEDYNAMIC   xor ( Ljava / lang / Object ; I ) Ljava / lang / Object ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testXorOptRHS"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "assertBytecodeExists (  \" def   x    =     1  ;    def   y    =     2  ;    double   d    =    x    ^    y \"  ,     \" INVOKEDYNAMIC   xor ( Ljava / lang / Object ; Ljava / lang / Object ;  ) D \"  )  ;", "}", "METHOD_END"], "methodName": ["testXorOptRet"], "fileName": "org.elasticsearch.painless.DefOptimizationTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( clazz . isLocalClass (  )  )     |  |     ( clazz . isAnonymousClass (  )  )  )     {", "return   null ;", "} else", "if    ( clazz . isArray (  )  )     {", "Class <  ?  >    component    =    clazz . getComponentType (  )  ;", "int   dimensions    =     1  ;", "while    ( component . isArray (  )  )     {", "component    =    component . getComponentType (  )  ;", "+  + dimensions ;", "}", "if    ( component    =  =     (  . def . class )  )     {", "StringBuilder   builder    =    new   StringBuilder (  . def . class . getSimpleName (  )  )  ;", "for    ( int   dimension    =     0  ;    dimension    <    dimensions ;    dimension +  +  )     {", "builder . append (  \"  [  ]  \"  )  ;", "}", "return   builder . toString (  )  ;", "}", "} else", "if    ( clazz    =  =     (  . def . class )  )     {", "return    . def . class . getSimpleName (  )  ;", "}", "return   clazz . getCanonicalName (  )  . replace (  '  $  '  ,     '  .  '  )  ;", "}", "METHOD_END"], "methodName": ["ClassToName"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "if    ( clazz    =  =    null )     {", "return   null ;", "} else", "if    ( clazz . isArray (  )  )     {", "Class <  ?  >    component    =    clazz . getComponentType (  )  ;", "int   dimensions    =     1  ;", "while    ( component . isArray (  )  )     {", "component    =    component . getComponentType (  )  ;", "+  + dimensions ;", "}", "if    ( component    =  =     (  . def . class )  )     {", "return   getType ( structsMap . get (  . def . class . getSimpleName (  )  )  ,    dimensions )  ;", "} else    {", "return   getType ( structsMap . get (  . ClassToName ( component )  )  ,    dimensions )  ;", "}", "} else", "if    ( clazz    =  =     (  . def . class )  )     {", "return   getType ( structsMap . get (  . def . class . getSimpleName (  )  )  ,     0  )  ;", "}", "return   getType ( structsMap . get (  . ClassToName ( clazz )  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["ClassToType"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "if    ( clazz . isArray (  )  )     {", "Class <  ?  >    component    =    clazz . getComponentType (  )  ;", "int   dimensions    =     1  ;", "while    ( component . isArray (  )  )     {", "component    =    component . getComponentType (  )  ;", "+  + dimensions ;", "}", "if    ( component    =  =     ( Object . class )  )     {", "char [  ]    braces    =    new   char [ dimensions ]  ;", "Arrays . fill ( braces ,     '  [  '  )  ;", "String   descriptor    =     ( new   String ( braces )  )     +     ( getType (  . def . class )  . getDescriptor (  )  )  ;", "Type   type    =    getType ( descriptor )  ;", "try    {", "return   Class . forName ( type . getInternalName (  )  . replace (  '  /  '  ,     '  .  '  )  )  ;", "}    catch    ( ClassNotFoundException   exception )     {", "throw   new   IllegalStateException (  \" internal   error \"  ,    exception )  ;", "}", "}", "} else", "if    ( clazz    =  =     ( Object . class )  )     {", "return    . def . class ;", "}", "return   clazz ;", "}", "METHOD_END"], "methodName": ["ObjectClassTodefClass"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "return   structsMap . get ( Definition . ClassToName ( clazz )  )  ;", "}", "METHOD_END"], "methodName": ["RuntimeClassToStruct"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "if    ( Definition . def . class . getSimpleName (  )  . equals ( type . struct . name )  )     {", "return   Definition . ObjectClassTodefClass ( type . clazz )  ;", "}", "return   type . clazz ;", "}", "METHOD_END"], "methodName": ["TypeToClass"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "Definition . Struct   ownerStruct    =    structsMap . get ( ownerStructName )  ;", "if    ( ownerStruct    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  (  (  \" owner   struct    [  \"     +    ownerStructName )     +     \"  ]    not   defined   for   constructor   with    \"  )     +     \" parameters    \"  )     +     ( whitelistConstructor . painlessParameterTypeNames )  )  )  ;", "}", "List < Class <  ?  >  >    painlessParametersTypes    =    new   ArrayList <  >  ( whitelistConstructor . painlessParameterTypeNames . size (  )  )  ;", "Class <  ?  >  [  ]    javaClassParameters    =    new   Class <  ?  >  [ whitelistConstructor . painlessParameterTypeNames . size (  )  ]  ;", "for    ( int   parameterCount    =     0  ;    parameterCount    <     ( whitelistConstructor . painlessParameterTypeNames . size (  )  )  ;     +  + parameterCount )     {", "String   painlessParameterTypeName    =    whitelistConstructor . painlessParameterTypeNames . get ( parameterCount )  ;", "try    {", "Class <  ?  >    painlessParameterClass    =    Definition . TypeToClass ( getTypeInternal ( painlessParameterTypeName )  )  ;", "painlessParametersTypes . add ( painlessParameterClass )  ;", "javaClassParameters [ parameterCount ]     =    Definition . defClassToObjectClass ( painlessParameterClass )  ;", "}    catch    ( IllegalArgumentException   iae )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  \" struct   not   defined   for   constructor   parameter    [  \"     +    painlessParameterTypeName )     +     \"  ]     \"  )     +     \" with   owner   struct    [  \"  )     +    ownerStructName )     +     \"  ]    and   constructor   parameters    \"  )     +     ( whitelistConstructor . painlessParameterTypeNames )  )  ,    iae )  ;", "}", "}", "Constructor <  ?  >    javaConstructor ;", "try    {", "javaConstructor    =    ownerStruct . clazz . getConstructor ( javaClassParameters )  ;", "}    catch    ( NoSuchMethodException   exception )     {", "throw   new   IllegalArgumentException (  (  (  (  (  \" constructor   not   defined   for   owner   struct    [  \"     +    ownerStructName )     +     \"  ]     \"  )     +     \"    with   constructor   parameters    \"  )     +     ( whitelistConstructor . painlessParameterTypeNames )  )  ,    exception )  ;", "}", "Definition . MethodKey   painlessMethodKey    =    new   Definition . MethodKey (  \"  < init >  \"  ,    whitelistConstructor . painlessParameterTypeNames . size (  )  )  ;", "Definition . Method   painlessConstructor    =    ownerStruct . constructors . get ( painlessMethodKey )  ;", "if    ( painlessConstructor    =  =    null )     {", "Method   asmConstructor    =    getMethod ( javaConstructor )  ;", "MethodHandle   javaHandle ;", "try    {", "javaHandle    =    MethodHandles . publicLookup (  )  . in ( ownerStruct . clazz )  . unreflectConstructor ( javaConstructor )  ;", "}    catch    ( IllegalAccessException   exception )     {", "throw   new   IllegalArgumentException (  (  (  (  (  \" constructor   not   defined   for   owner   struct    [  \"     +    ownerStructName )     +     \"  ]     \"  )     +     \"    with   constructor   parameters    \"  )     +     ( whitelistConstructor . painlessParameterTypeNames )  )  )  ;", "}", "painlessConstructor    =    Definition . methodCache . computeIfAbsent ( Definition . buildMethodCacheKey ( ownerStruct . name ,     \"  < init >  \"  ,    painlessParametersTypes )  ,     (    key )     -  >    new   Definition . Method (  \"  < init >  \"  ,    ownerStruct ,    null ,    void . class ,    painlessParametersTypes ,    asmConstructor ,    getModifiers (  )  ,    javaHandle )  )  ;", "ownerStruct . constructors . put ( painlessMethodKey ,    painlessConstructor )  ;", "} else", "if    (  ( painlessConstructor . arguments . equals ( painlessParametersTypes )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  (  \" illegal   duplicate   constructors    [  \"     +    painlessMethodKey )     +     \"  ]    found   within   the   struct    [  \"  )     +     ( ownerStruct . name )  )     +     \"  ]     \"  )     +     \" with   parameters    \"  )     +    painlessParametersTypes )     +     \"    and    \"  )     +     ( painlessConstructor . arguments )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["addConstructor"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "Definition . Struct   ownerStruct    =    structsMap . get ( ownerStructName )  ;", "if    ( ownerStruct    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  \" owner   struct    [  \"     +    ownerStructName )     +     \"  ]    not   defined   for   method   with    \"  )     +     \" name    [  \"  )     +     ( whitelistField . javaFieldName )  )     +     \"  ]    and   type    \"  )     +     ( whitelistField . painlessFieldTypeName )  )  )  ;", "}", "if    (  ( Definition . TYPE _ NAME _ PATTERN . matcher ( whitelistField . javaFieldName )  . matches (  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" invalid   field   name    \"     +     \"  [  \"  )     +     ( whitelistField . painlessFieldTypeName )  )     +     \"  ]    for   owner   struct    [  \"  )     +    ownerStructName )     +     \"  ]  .  \"  )  )  ;", "}", "Field   javaField ;", "try    {", "javaField    =    ownerStruct . clazz . getField ( whitelistField . javaFieldName )  ;", "}    catch    ( NoSuchFieldException   exception )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" field    [  \"     +     ( whitelistField . javaFieldName )  )     +     \"  ]     \"  )     +     \" not   found   for   class    [  \"  )     +     ( ownerStruct . clazz . getName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "Class <  ?  >    painlessFieldClass ;", "try    {", "painlessFieldClass    =    Definition . TypeToClass ( getTypeInternal ( whitelistField . painlessFieldTypeName )  )  ;", "}    catch    ( IllegalArgumentException   iae )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  \" struct   not   defined   for   return   type    [  \"     +     ( whitelistField . painlessFieldTypeName )  )     +     \"  ]     \"  )     +     \" with   owner   struct    [  \"  )     +    ownerStructName )     +     \"  ]    and   field   with   name    [  \"  )     +     ( whitelistField . javaFieldName )  )     +     \"  ]  \"  )  ,    iae )  ;", "}", "if    ( Modifier . isStatic ( getModifiers (  )  )  )     {", "if    (  ( Modifier . isFinal ( getModifiers (  )  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" static    [  \"     +     ( whitelistField . javaFieldName )  )     +     \"  ]     \"  )     +     \" with   owner   struct    [  \"  )     +     ( ownerStruct . name )  )     +     \"  ]    is   not   final \"  )  )  ;", "}", "Definition . Field   painlessField    =    ownerStruct . staticMembers . get ( whitelistField . javaFieldName )  ;", "if    ( painlessField    =  =    null )     {", "painlessField    =    Definition . fieldCache . computeIfAbsent ( Definition . buildFieldCacheKey ( ownerStruct . name ,    whitelistField . javaFieldName ,    painlessFieldClass . getName (  )  )  ,     (    key )     -  >    new   Definition . Field ( whitelistField . javaFieldName ,    getName (  )  ,    ownerStruct ,    painlessFieldClass ,    getModifiers (  )  ,    null ,    null )  )  ;", "ownerStruct . staticMembers . put ( whitelistField . javaFieldName ,    painlessField )  ;", "} else", "if    (  ( painlessField . clazz )     !  =    painlessFieldClass )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  \" illegal   duplicate   static   fields    [  \"     +     ( whitelistField . javaFieldName )  )     +     \"  ]     \"  )     +     \" found   within   the   struct    [  \"  )     +     ( ownerStruct . name )  )     +     \"  ]    with   type    [  \"  )     +     ( whitelistField . painlessFieldTypeName )  )     +     \"  ]  \"  )  )  ;", "}", "} else    {", "MethodHandle   javaMethodHandleGetter ;", "MethodHandle   javaMethodHandleSetter ;", "try    {", "if    (  ( Modifier . isStatic ( getModifiers (  )  )  )     =  =    false )     {", "javaMethodHandleGetter    =    MethodHandles . publicLookup (  )  . unreflectGetter ( javaField )  ;", "javaMethodHandleSetter    =    MethodHandles . publicLookup (  )  . unreflectSetter ( javaField )  ;", "} else    {", "javaMethodHandleGetter    =    null ;", "javaMethodHandleSetter    =    null ;", "}", "}    catch    ( IllegalAccessException   exception )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" getter / setter    [  \"     +     ( whitelistField . javaFieldName )  )     +     \"  ]  \"  )     +     \"    not   found   for   class    [  \"  )     +     ( ownerStruct . clazz . getName (  )  )  )     +     \"  ]  .  \"  )  )  ;", "}", "Definition . Field   painlessField    =    ownerStruct . members . get ( whitelistField . javaFieldName )  ;", "if    ( painlessField    =  =    null )     {", "painlessField    =    Definition . fieldCache . computeIfAbsent ( Definition . buildFieldCacheKey ( ownerStruct . name ,    whitelistField . javaFieldName ,    painlessFieldClass . getName (  )  )  ,     (    key )     -  >    new   Definition . Field ( whitelistField . javaFieldName ,    getName (  )  ,    ownerStruct ,    painlessFieldClass ,    getModifiers (  )  ,    javaMethodHandleGetter ,    javaMethodHandleSetter )  )  ;", "ownerStruct . members . put ( whitelistField . javaFieldName ,    painlessField )  ;", "} else", "if    (  ( painlessField . clazz )     !  =    painlessFieldClass )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  \" illegal   duplicate   member   fields    [  \"     +     ( whitelistField . javaFieldName )  )     +     \"  ]     \"  )     +     \" found   within   the   struct    [  \"  )     +     ( ownerStruct . name )  )     +     \"  ]    with   type    [  \"  )     +     ( whitelistField . painlessFieldTypeName )  )     +     \"  ]  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["addField"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "Definition . Struct   ownerStruct    =    structsMap . get ( ownerStructName )  ;", "if    ( ownerStruct    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  \" owner   struct    [  \"     +    ownerStructName )     +     \"  ]    not   defined   for   method   with    \"  )     +     \" name    [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]    and   parameters    \"  )     +     ( whitelistMethod . painlessParameterTypeNames )  )  )  ;", "}", "if    (  ( Definition . TYPE _ NAME _ PATTERN . matcher ( whitelistMethod . javaMethodName )  . matches (  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" invalid   method   name \"     +     \"     [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]    for   owner   struct    [  \"  )     +    ownerStructName )     +     \"  ]  .  \"  )  )  ;", "}", "Class <  ?  >    javaAugmentedClass ;", "if    (  ( whitelistMethod . javaAugmentedClassName )     !  =    null )     {", "try    {", "javaAugmentedClass    =    Class . forName ( whitelistMethod . javaAugmentedClassName ,    true ,    whitelistClassLoader )  ;", "}    catch    ( ClassNotFoundException   cnfe )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  \" augmented   class    [  \"     +     ( whitelistMethod . javaAugmentedClassName )  )     +     \"  ]     \"  )     +     \" not   found   for   method   with   name    [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]     \"  )     +     \" and   parameters    \"  )     +     ( whitelistMethod . painlessParameterTypeNames )  )  ,    cnfe )  ;", "}", "} else    {", "javaAugmentedClass    =    null ;", "}", "int   augmentedOffset    =     ( javaAugmentedClass    =  =    null )     ?     0     :     1  ;", "List < Class <  ?  >  >    painlessParametersTypes    =    new   ArrayList <  >  ( whitelistMethod . painlessParameterTypeNames . size (  )  )  ;", "Class <  ?  >  [  ]    javaClassParameters    =    new   Class <  ?  >  [  ( whitelistMethod . painlessParameterTypeNames . size (  )  )     +    augmentedOffset ]  ;", "if    ( javaAugmentedClass    !  =    null )     {", "javaClassParameters [  0  ]     =    ownerStruct . clazz ;", "}", "for    ( int   parameterCount    =     0  ;    parameterCount    <     ( whitelistMethod . painlessParameterTypeNames . size (  )  )  ;     +  + parameterCount )     {", "String   painlessParameterTypeName    =    whitelistMethod . painlessParameterTypeNames . get ( parameterCount )  ;", "try    {", "Class <  ?  >    painlessParameterClass    =    Definition . TypeToClass ( getTypeInternal ( painlessParameterTypeName )  )  ;", "painlessParametersTypes . add ( painlessParameterClass )  ;", "javaClassParameters [  ( parameterCount    +    augmentedOffset )  ]     =    Definition . defClassToObjectClass ( painlessParameterClass )  ;", "}    catch    ( IllegalArgumentException   iae )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  (  (  \" struct   not   defined   for   method   parameter    [  \"     +    painlessParameterTypeName )     +     \"  ]     \"  )     +     \" with   owner   struct    [  \"  )     +    ownerStructName )     +     \"  ]    and   method   with   name    [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]     \"  )     +     \" and   parameters    \"  )     +     ( whitelistMethod . painlessParameterTypeNames )  )  ,    iae )  ;", "}", "}", "Class <  ?  >    javaImplClass    =     ( javaAugmentedClass    =  =    null )     ?    ownerStruct . clazz    :    javaAugmentedClass ;", "Method   javaMethod ;", "try    {", "javaMethod    =    getMethod ( whitelistMethod . javaMethodName ,    javaClassParameters )  ;", "}    catch    ( NoSuchMethodException   nsme )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  \" method   with   name    [  \"     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]     \"  )     +     \" and   parameters    \"  )     +     ( whitelistMethod . painlessParameterTypeNames )  )     +     \"    not   found   for   class    [  \"  )     +     ( getName (  )  )  )     +     \"  ]  \"  )  ,    nsme )  ;", "}", "Class <  ?  >    painlessReturnClass ;", "try    {", "painlessReturnClass    =    Definition . TypeToClass ( getTypeInternal ( whitelistMethod . painlessReturnTypeName )  )  ;", "}    catch    ( IllegalArgumentException   iae )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  (  (  \" struct   not   defined   for   return   type    [  \"     +     ( whitelistMethod . painlessReturnTypeName )  )     +     \"  ]     \"  )     +     \" with   owner   struct    [  \"  )     +    ownerStructName )     +     \"  ]    and   method   with   name    [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]     \"  )     +     \" and   parameters    \"  )     +     ( whitelistMethod . painlessParameterTypeNames )  )  ,    iae )  ;", "}", "if    (  ( getReturnType (  )  )     !  =     ( Definition . defClassToObjectClass ( painlessReturnClass )  )  )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  (  (  (  \" specified   return   type   class    [  \"     +    painlessReturnClass )     +     \"  ]     \"  )     +     \" does   not   match   the   return   type   class    [  \"  )     +     ( getReturnType (  )  )  )     +     \"  ]    for   the    \"  )     +     \" method   with   name    [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]     \"  )     +     \" and   parameters    \"  )     +     ( whitelistMethod . painlessParameterTypeNames )  )  )  ;", "}", "Definition . MethodKey   painlessMethodKey    =    new   Definition . MethodKey ( whitelistMethod . javaMethodName ,    whitelistMethod . painlessParameterTypeNames . size (  )  )  ;", "if    (  ( javaAugmentedClass    =  =    null )     &  &     ( Modifier . isStatic ( getModifiers (  )  )  )  )     {", "Definition . Method   painlessMethod    =    ownerStruct . staticMethods . get ( painlessMethodKey )  ;", "if    ( painlessMethod    =  =    null )     {", "Method   asmMethod    =    getMethod ( javaMethod )  ;", "MethodHandle   javaMethodHandle ;", "try    {", "javaMethodHandle    =    MethodHandles . publicLookup (  )  . in ( javaImplClass )  . unreflect ( javaMethod )  ;", "}    catch    ( IllegalAccessException   exception )     {", "throw   new   IllegalArgumentException (  (  (  (  (  \" method   handle   not   found   for   method   with   name    \"     +     \"  [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]    and   parameters    \"  )     +     ( whitelistMethod . painlessParameterTypeNames )  )  )  ;", "}", "painlessMethod    =    Definition . methodCache . computeIfAbsent ( Definition . buildMethodCacheKey ( ownerStruct . name ,    whitelistMethod . javaMethodName ,    painlessParametersTypes )  ,     (    key )     -  >    new   Definition . Method ( whitelistMethod . javaMethodName ,    ownerStruct ,    null ,    painlessReturnClass ,    painlessParametersTypes ,    asmMethod ,    getModifiers (  )  ,    javaMethodHandle )  )  ;", "ownerStruct . staticMethods . put ( painlessMethodKey ,    painlessMethod )  ;", "} else", "if    (  (  (  ( painlessMethod . name . equals ( whitelistMethod . javaMethodName )  )     &  &     (  ( painlessMethod . rtn )     =  =    painlessReturnClass )  )     &  &     ( painlessMethod . arguments . equals ( painlessParametersTypes )  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" illegal   duplicate   static   methods    [  \"     +    painlessMethodKey )     +     \"  ]     \"  )     +     \" found   within   the   struct    [  \"  )     +     ( ownerStruct . name )  )     +     \"  ]    with   name    [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]  ,     \"  )     +     \" return   types    [  \"  )     +    painlessReturnClass )     +     \"  ]    and    [  \"  )     +     ( painlessMethod . rtn )  )     +     \"  ]  ,     \"  )     +     \" and   parameters    \"  )     +    painlessParametersTypes )     +     \"    and    \"  )     +     ( painlessMethod . arguments )  )  )  ;", "}", "} else    {", "Definition . Method   painlessMethod    =    ownerStruct . methods . get ( painlessMethodKey )  ;", "if    ( painlessMethod    =  =    null )     {", "Method   asmMethod    =    getMethod ( javaMethod )  ;", "MethodHandle   javaMethodHandle ;", "try    {", "javaMethodHandle    =    MethodHandles . publicLookup (  )  . in ( javaImplClass )  . unreflect ( javaMethod )  ;", "}    catch    ( IllegalAccessException   exception )     {", "throw   new   IllegalArgumentException (  (  (  (  (  \" method   handle   not   found   for   method   with   name    \"     +     \"  [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]    and   parameters    \"  )     +     ( whitelistMethod . painlessParameterTypeNames )  )  )  ;", "}", "painlessMethod    =    Definition . methodCache . computeIfAbsent ( Definition . buildMethodCacheKey ( ownerStruct . name ,    whitelistMethod . javaMethodName ,    painlessParametersTypes )  ,     (    key )     -  >    new   Definition . Method ( whitelistMethod . javaMethodName ,    ownerStruct ,    javaAugmentedClass ,    painlessReturnClass ,    painlessParametersTypes ,    asmMethod ,    getModifiers (  )  ,    javaMethodHandle )  )  ;", "ownerStruct . methods . put ( painlessMethodKey ,    painlessMethod )  ;", "} else", "if    (  (  (  ( painlessMethod . name . equals ( whitelistMethod . javaMethodName )  )     &  &     ( painlessMethod . rtn . equals ( painlessReturnClass )  )  )     &  &     ( painlessMethod . arguments . equals ( painlessParametersTypes )  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  \" illegal   duplicate   member   methods    [  \"     +    painlessMethodKey )     +     \"  ]     \"  )     +     \" found   within   the   struct    [  \"  )     +     ( ownerStruct . name )  )     +     \"  ]    with   name    [  \"  )     +     ( whitelistMethod . javaMethodName )  )     +     \"  ]  ,     \"  )     +     \" return   types    [  \"  )     +    painlessReturnClass )     +     \"  ]    and    [  \"  )     +     ( painlessMethod . rtn )  )     +     \"  ]  ,     \"  )     +     \" and   parameters    \"  )     +    painlessParametersTypes )     +     \"    and    \"  )     +     ( painlessMethod . arguments )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["addMethod"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "for    ( Map . Entry < Definition . MethodKey ,    Definition . Method >    method    :    struct . methods . entrySet (  )  )     {", "String   name    =    method . getKey (  )  . name ;", "Definition . Method   m    =    method . getValue (  )  ;", "if    (  (  (  (  ( m . arguments . size (  )  )     =  =     0  )     &  &     ( name . startsWith (  \" get \"  )  )  )     &  &     (  ( name . length (  )  )     >     3  )  )     &  &     ( Character . isUpperCase ( name . charAt (  3  )  )  )  )     {", "StringBuilder   newName    =    new   StringBuilder (  )  ;", "newName . append ( Character . toLowerCase ( name . charAt (  3  )  )  )  ;", "newName . append ( name . substring (  4  )  )  ;", "struct . getters . putIfAbsent ( newName . toString (  )  ,    m . handle )  ;", "} else", "if    (  (  (  (  ( m . arguments . size (  )  )     =  =     0  )     &  &     ( name . startsWith (  \" is \"  )  )  )     &  &     (  ( name . length (  )  )     >     2  )  )     &  &     ( Character . isUpperCase ( name . charAt (  2  )  )  )  )     {", "StringBuilder   newName    =    new   StringBuilder (  )  ;", "newName . append ( Character . toLowerCase ( name . charAt (  2  )  )  )  ;", "newName . append ( name . substring (  3  )  )  ;", "struct . getters . putIfAbsent ( newName . toString (  )  ,    m . handle )  ;", "}", "if    (  (  (  (  ( m . arguments . size (  )  )     =  =     1  )     &  &     ( name . startsWith (  \" set \"  )  )  )     &  &     (  ( name . length (  )  )     >     3  )  )     &  &     ( Character . isUpperCase ( name . charAt (  3  )  )  )  )     {", "StringBuilder   newName    =    new   StringBuilder (  )  ;", "newName . append ( Character . toLowerCase ( name . charAt (  3  )  )  )  ;", "newName . append ( name . substring (  4  )  )  ;", "struct . setters . putIfAbsent ( newName . toString (  )  ,    m . handle )  ;", "}", "}", "for    ( Map . Entry < String ,    Definition . Field >    member    :    struct . members . entrySet (  )  )     {", "struct . getters . put ( member . getKey (  )  ,    member . getValue (  )  . getter )  ;", "struct . setters . put ( member . getKey (  )  ,    member . getValue (  )  . setter )  ;", "}", "}", "METHOD_END"], "methodName": ["addRuntimeClass"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "String   painlessTypeName    =    whitelistStruct . replace (  '  $  '  ,     '  .  '  )  ;", "String   importedPainlessTypeName    =    painlessTypeName ;", "if    (  (  . TYPE _ NAME _ PATTERN . matcher ( painlessTypeName )  . matches (  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  \" invalid   struct   type   name    [  \"     +    painlessTypeName )     +     \"  ]  \"  )  )  ;", "}", "int   index    =    whitelistStruct . lastIndexOf (  '  .  '  )  ;", "if    ( index    !  =     (  -  1  )  )     {", "importedPainlessTypeName    =    whitelistStruct . substring (  ( index    +     1  )  )  . replace (  '  $  '  ,     '  .  '  )  ;", "}", "Class <  ?  >    javaClass ;", "if    (  \" void \"  . equals ( whitelistStruct . javaClassName )  )", "javaClass    =    void . class ;", "else", "if    (  \" boolean \"  . equals ( whitelistStruct . javaClassName )  )", "javaClass    =    boolean . class ;", "else", "if    (  \" byte \"  . equals ( whitelistStruct . javaClassName )  )", "javaClass    =    byte . class ;", "else", "if    (  \" short \"  . equals ( whitelistStruct . javaClassName )  )", "javaClass    =    short . class ;", "else", "if    (  \" char \"  . equals ( whitelistStruct . javaClassName )  )", "javaClass    =    char . class ;", "else", "if    (  \" int \"  . equals ( whitelistStruct . javaClassName )  )", "javaClass    =    int . class ;", "else", "if    (  \" long \"  . equals ( whitelistStruct . javaClassName )  )", "javaClass    =    long . class ;", "else", "if    (  \" float \"  . equals ( whitelistStruct . javaClassName )  )", "javaClass    =    float . class ;", "else", "if    (  \" double \"  . equals ( whitelistStruct . javaClassName )  )", "javaClass    =    double . class ;", "else    {", "try    {", "javaClass    =    Class . forName ( whitelistStruct . javaClassName ,    true ,    whitelistClassLoader )  ;", "}    catch    ( ClassNotFoundException   cnfe )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" invalid   java   class   name    [  \"     +     ( whitelistStruct . javaClassName )  )     +     \"  ]  \"  )     +     \"    for   struct    [  \"  )     +    painlessTypeName )     +     \"  ]  \"  )  )  ;", "}", "}", ". Struct   existingStruct    =    structsMap . get ( painlessTypeName )  ;", "if    ( existingStruct    =  =    null )     {", ". Struct   struct    =    new    . Struct ( painlessTypeName ,    javaClass ,    getType ( javaClass )  )  ;", "structsMap . put ( painlessTypeName ,    struct )  ;", "if    ( whitelistStruct . onlyFQNJavaClassName )     {", "simpleTypesMap . put ( painlessTypeName ,    getType ( painlessTypeName )  )  ;", "} else", "if    (  ( simpleTypesMap . containsKey ( importedPainlessTypeName )  )     =  =    false )     {", "simpleTypesMap . put ( importedPainlessTypeName ,    getType ( painlessTypeName )  )  ;", "structsMap . put ( importedPainlessTypeName ,    struct )  ;", "} else    {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" duplicate   short   name    [  \"     +    importedPainlessTypeName )     +     \"  ]     \"  )     +     \" found   for   struct    [  \"  )     +    painlessTypeName )     +     \"  ]  \"  )  )  ;", "}", "} else", "if    (  ( existingStruct . clazz . equals ( javaClass )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  (  \" struct    [  \"     +    painlessTypeName )     +     \"  ]    is   used   to    \"  )     +     \" illegally   represent   multiple   java   classes    [  \"  )     +     ( whitelistStruct . javaClassName )  )     +     \"  ]    and    \"  )     +     \"  [  \"  )     +     ( existingStruct . clazz . getName (  )  )  )     +     \"  ]  \"  )  )  ;", "} else", "if    (  (  (  ( whitelistStruct . onlyFQNJavaClassName )     &  &     ( simpleTypesMap . containsKey ( importedPainlessTypeName )  )  )     &  &     (  ( simpleTypesMap . get ( importedPainlessTypeName )  . clazz )     =  =    javaClass )  )     |  |     (  (  ( whitelistStruct . onlyFQNJavaClassName )     =  =    false )     &  &     (  (  ( simpleTypesMap . containsKey ( importedPainlessTypeName )  )     =  =    false )     |  |     (  ( simpleTypesMap . get ( importedPainlessTypeName )  . clazz )     !  =    javaClass )  )  )  )     {", "throw   new   IllegalArgumentException (  (  (  \" inconsistent   only _ fqn   parameters   found   for   type    [  \"     +    painlessTypeName )     +     \"  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["addStruct"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "return   simpleTypesMap . values (  )  ;", "}", "METHOD_END"], "methodName": ["allSimpleTypes"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "return    ( structName    +    fieldName )     +    typeName ;", "}", "METHOD_END"], "methodName": ["buildFieldCacheKey"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   key    =    new   StringBuilder (  )  ;", "key . append ( structName )  ;", "key . append ( methodName )  ;", "for    ( Cs <  ?  >    argument    :    arguments )     {", "key . append ( argument . getName (  )  )  ;", "}", "return   key . toString (  )  ;", "}", "METHOD_END"], "methodName": ["buildMethodCacheKey"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( clazz . clazz . isInterface (  )  )  )     {", "return   null ;", "}", "boolean   hasAnnotation    =    clazz . clazz . isAnnotationPresent ( FunctionalInterface . class )  ;", "List < Method >    methods    =    new   ArrayList <  >  (  )  ;", "for    ( Method   m    :    clazz . clazz . getMethods (  )  )     {", "if    ( m . isDefault (  )  )     {", "continue ;", "}", "if    ( Modifier . isStatic ( m . getModifiers (  )  )  )     {", "continue ;", "}", "try    {", "Object . class . getMethod ( m . getName (  )  ,    m . getParameterTypes (  )  )  ;", "continue ;", "}    catch    ( ReflectiveOperationException   e )     {", "}", "methods . add ( m )  ;", "}", "if    (  ( methods . size (  )  )     !  =     1  )     {", "if    ( hasAnnotation )     {", "throw   new   IllegalArgumentException (  (  (  (  \" Class :     \"     +     ( clazz . name )  )     +     \"    is   marked   with   FunctionalInterface   but   doesn ' t   fit   the   bill :     \"  )     +    methods )  )  ;", "}", "return   null ;", "}", "Method   oneMethod    =    methods . get (  0  )  ;", ". Method   painless    =    clazz . methods . get ( new    . MethodKey ( oneMethod . getName (  )  ,    oneMethod . getParameterCount (  )  )  )  ;", "if    (  ( painless    =  =    null )     |  |     (  ( painless . method . equals ( getMethod ( oneMethod )  )  )     =  =    false )  )     {", "throw   new   IllegalArgumentException (  (  (  (  \" Class :     \"     +     ( clazz . name )  )     +     \"    is   functional   but   the   functional    \"  )     +     \" method   is   not   whitelisted !  \"  )  )  ;", "}", "return   painless ;", "}", "METHOD_END"], "methodName": ["computeFunctionalInterfaceMethod"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "final   Definition . Struct   owner    =    structsMap . get ( struct )  ;", "if    ( owner    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  \" Owner   struct    [  \"     +    struct )     +     \"  ]    not   defined   for   copy .  \"  )  )  ;", "}", "for    ( int   count    =     0  ;    count    <     ( children . size (  )  )  ;     +  + count )     {", "final   Definition . Struct   child    =    structsMap . get ( children . get ( count )  )  ;", "if    ( child    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" Child   struct    [  \"     +     ( children . get ( count )  )  )     +     \"  ]  \"  )     +     \"    not   defined   for   copy   to   owner   struct    [  \"  )     +     ( owner . name )  )     +     \"  ]  .  \"  )  )  ;", "}", "if    (  !  ( child . clazz . isAssignableFrom ( owner . clazz )  )  )     {", "throw   new   ClassCastException (  (  (  (  (  (  \" Child   struct    [  \"     +     ( child . name )  )     +     \"  ]  \"  )     +     \"    is   not   a   super   type   of   owner   struct    [  \"  )     +     ( owner . name )  )     +     \"  ]    in   copy .  \"  )  )  ;", "}", "for    ( Map . Entry < Definition . MethodKey ,    Definition . Method >    kvPair    :    child . methods . entrySet (  )  )     {", "Definition . MethodKey   methodKey    =    kvPair . getKey (  )  ;", "Definition . Method   method    =    kvPair . getValue (  )  ;", "if    (  ( owner . methods . get ( methodKey )  )     =  =    null )     {", "owner . methods . put ( methodKey ,    method )  ;", "}", "}", "for    ( Definition . Field   field    :    child . members . values (  )  )     {", "if    (  ( owner . members . get ( field . name )  )     =  =    null )     {", "owner . members . put ( field . name ,    new   Definition . Field ( field . name ,    field . javaName ,    owner ,    field . clazz ,    field . modifiers ,    field . getter ,    field . setter )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["copyStruct"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "if    ( clazz . isArray (  )  )     {", "Class <  ?  >    component    =    clazz . getComponentType (  )  ;", "int   dimensions    =     1  ;", "while    ( component . isArray (  )  )     {", "component    =    component . getComponentType (  )  ;", "+  + dimensions ;", "}", "if    ( component    =  =     (  . def . class )  )     {", "char [  ]    braces    =    new   char [ dimensions ]  ;", "Arrays . fill ( braces ,     '  [  '  )  ;", "String   descriptor    =     ( new   String ( braces )  )     +     ( getType ( Object . class )  . getDescriptor (  )  )  ;", "Type   type    =    getType ( descriptor )  ;", "try    {", "return   Class . forName ( type . getInternalName (  )  . replace (  '  /  '  ,     '  .  '  )  )  ;", "}    catch    ( ClassNotFoundException   exception )     {", "throw   new   IllegalStateException (  \" internal   error \"  ,    exception )  ;", "}", "}", "} else", "if    ( clazz    =  =     (  . def . class )  )     {", "return   Object . class ;", "}", "return   clazz ;", "}", "METHOD_END"], "methodName": ["defClassToObjectClass"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "if    ( clazz    =  =     ( boolean . class )  )     {", "return   Boolean . class ;", "} else", "if    ( clazz    =  =     ( byte . class )  )     {", "return   Byte . class ;", "} else", "if    ( clazz    =  =     ( short . class )  )     {", "return   Short . class ;", "} else", "if    ( clazz    =  =     ( char . class )  )     {", "return   Character . class ;", "} else", "if    ( clazz    =  =     ( int . class )  )     {", "return   Integer . class ;", "} else", "if    ( clazz    =  =     ( long . class )  )     {", "return   Long . class ;", "} else", "if    ( clazz    =  =     ( float . class )  )     {", "return   Float . class ;", "} else", "if    ( clazz    =  =     ( double . class )  )     {", "return   Double . class ;", "}", "return   clazz ;", "}", "METHOD_END"], "methodName": ["getBoxedType"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "Definition . Struct   struct    =    structsMap . get ( name . replace (  '  $  '  ,     '  .  '  )  )  ;", "return   struct    =  =    null    ?    null    :    struct . clazz ;", "}", "METHOD_END"], "methodName": ["getClassFromBinaryName"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "int   dimensions    =     0  ;", "int   index    =    name . indexOf (  '  [  '  )  ;", "if    ( index    !  =     (  -  1  )  )     {", "int   length    =    name . length (  )  ;", "while    ( index    <    length )     {", "if    (  (  (  ( name . charAt ( index )  )     =  =     '  [  '  )     &  &     (  (  +  + index )     <    length )  )     &  &     (  ( name . charAt (  ( index +  +  )  )  )     =  =     '  ]  '  )  )     {", "+  + dimensions ;", "} else    {", "throw   new   IllegalArgumentExcep (  (  (  \" Invalid   array   braces   in   canonical   name    [  \"     +    name )     +     \"  ]  .  \"  )  )  ;", "}", "}", "}", "return   dimensions ;", "}", "METHOD_END"], "methodName": ["getDimensions"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "return   getTypeInternal ( name )  ;", "}", "METHOD_END"], "methodName": ["getType"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "return   getTypeInternal ( struct ,    dimensions )  ;", "}", "METHOD_END"], "methodName": ["getType"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "Definition . Type   simple    =    simpleTypesMap . get ( name )  ;", "if    ( simple    !  =    null )     {", "return   simple ;", "}", "int   dimensions    =    getDimensions ( name )  ;", "String   structstr    =     ( dimensions    =  =     0  )     ?    name    :    name . substring (  0  ,    name . indexOf (  '  [  '  )  )  ;", "Definition . Struct   struct    =    structsMap . get ( structstr )  ;", "if    ( struct    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  \" The   struct   with   name    [  \"     +    name )     +     \"  ]    has   not   been   defined .  \"  )  )  ;", "}", "return   getTypeInternal ( struct ,    dimensions )  ;", "}", "METHOD_END"], "methodName": ["getTypeInternal"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "String   name    =    struct . name ;", "Type   type    =    struct . type ;", "Class <  ?  >    clazz    =    struct . clazz ;", "if    ( dimensions    >     0  )     {", "StringBuilder   builder    =    new   StringBuilder ( name )  ;", "char [  ]    brackets    =    new   char [ dimensions ]  ;", "for    ( int   count    =     0  ;    count    <    dimensions ;     +  + count )     {", "builder . append (  \"  [  ]  \"  )  ;", "brackets [ count ]     =     '  [  '  ;", "}", "String   descriptor    =     ( new   String ( brackets )  )     +     ( struct . type . getDescriptor (  )  )  ;", "name    =    builder . toString (  )  ;", "type    =    getType ( descriptor )  ;", "try    {", "clazz    =    Class . forName ( type . getInternalName (  )  . replace (  '  /  '  ,     '  .  '  )  )  ;", "}    catch    ( ClassNotFoundException   exception )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" The   class    [  \"     +     ( type . getInternalName (  )  )  )     +     \"  ]  \"  )     +     \"    could   not   be   found   to   create   type    [  \"  )     +    name )     +     \"  ]  .  \"  )  )  ;", "}", "}", "return   new    . Type ( name ,    dimensions ,     . def . class . getSimpleName (  )  . equals ( name )  ,    struct ,    clazz ,    type )  ;", "}", "METHOD_END"], "methodName": ["getTypeInternal"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "if    ( clazz    =  =     ( Boolean . class )  )     {", "return   boolean . class ;", "} else", "if    ( clazz    =  =     ( Byte . class )  )     {", "return   byte . class ;", "} else", "if    ( clazz    =  =     ( Short . class )  )     {", "return   short . class ;", "} else", "if    ( clazz    =  =     ( Character . class )  )     {", "return   char . class ;", "} else", "if    ( clazz    =  =     ( Integer . class )  )     {", "return   int . class ;", "} else", "if    ( clazz    =  =     ( Long . class )  )     {", "return   long . class ;", "} else", "if    ( clazz    =  =     ( Float . class )  )     {", "return   float . class ;", "} else", "if    ( clazz    =  =     ( Double . class )  )     {", "return   double . class ;", "}", "return   clazz ;", "}", "METHOD_END"], "methodName": ["getUnboxedype"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "return    (  (  (  (  (  (  (  ( clazz    =  =     ( boolean . class )  )     |  |     ( clazz    =  =     ( byte . class )  )  )     |  |     ( clazz    =  =     ( short . class )  )  )     |  |     ( clazz    =  =     ( char . class )  )  )     |  |     ( clazz    =  =     ( int . class )  )  )     |  |     ( clazz    =  =     ( long . class )  )  )     |  |     ( clazz    =  =     ( float . class )  )  )     |  |     ( clazz    =  =     ( double . class )  )  )     |  |     ( clazz    =  =     ( String . class )  )  ;", "}", "METHOD_END"], "methodName": ["isConstantType"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "return   structsMap . containsKey ( name )  ;", "}", "METHOD_END"], "methodName": ["isSimpleType"], "fileName": "org.elasticsearch.painless.Definition"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  2  .  2  5 F    /     1  .  5 F )  ,    exec (  \" return    2  .  2  5 F    /     1  .  5 F ;  \"  )  )  ;", "assertEquals (  0  .  5  ,    exec (  \" double   x    =     1  ;    float   y    =     2  ;    return   x    /    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" byte   x    =     4  5  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  5  )  )  ,    exec (  \" byte   x    =     5  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" short   x    =     4  5  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  5  )  )  ,    exec (  \" short   x    =     5  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" char   x    =     4  5  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" int   x    =     4  5  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  )  ,    exec (  \" int   x    =     5  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" long   x    =     4  5  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5 L )  ,    exec (  \" long   x    =     5  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0 F ,    exec (  \" float   x    =     4  5 f ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0 F )  ,    exec (  \" float   x    =     5 f ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0  ,    exec (  \" double   x    =     4  5  .  0  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0  )  ,    exec (  \" double   x    =     5  .  0  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignment"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" byte   x    =     1  ;    x    /  =     0  ;    return   x ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" short   x    =     1  ;    x    /  =     0  ;    return   x ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" char   x    =     1  ;    x    /  =     0  ;    return   x ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1  ;    x    /  =     0  ;    return   x ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" long   x    =     1  ;    x    /  =     0  ;    return   x ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1  ;    x    /  =     0  ;    return   x ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignmentByZero"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" def   x    =     ( byte )  4  5  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  5  )  )  ,    exec (  \" def   x    =     ( byte )  5  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" def   x    =     ( short )  4  5  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  5  )  )  ,    exec (  \" def   x    =     ( short )  5  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" def   x    =     ( char )  4  5  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" def   x    =     4  5  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  )  ,    exec (  \" def   x    =     5  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" def   x    =     4  5 L ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5 L )  ,    exec (  \" def   x    =     5 L ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0 F ,    exec (  \" def   x    =     4  5 f ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0 F )  ,    exec (  \" def   x    =     5 f ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0  ,    exec (  \" def   x    =     4  5  .  0  ;    x    /  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0  )  ,    exec (  \" def   x    =     5  .  0  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefCompoundAssignment"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedLHS"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    byte   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    byte   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    byte   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    byte   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    byte   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    byte   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    byte   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    short   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    short   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    short   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    short   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    short   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    short   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    short   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    char   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    char   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    char   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    char   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    char   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    char   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    char   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    int   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    int   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    int   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    int   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    int   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    int   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    int   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( byte )  2  ;    long   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( short )  2  ;    long   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( char )  2  ;    long   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( int )  2  ;    long   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    long   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    long   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    long   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( byte )  2  ;    float   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( short )  2  ;    float   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( char )  2  ;    float   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( int )  2  ;    float   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( long )  2  ;    float   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    float   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    float   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( byte )  2  ;    double   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( short )  2  ;    double   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( char )  2  ;    double   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( int )  2  ;    double   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( long )  2  ;    double   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( float )  2  ;    double   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    double   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( byte )  2  ;    byte   y    =     ( byte )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( short )  2  ;    short   y    =     ( short )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( char )  2  ;    char   y    =     ( char )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     ( int )  2  ;    int   y    =     ( int )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     ( long )  2  ;    long   y    =     ( long )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    float   y    =     ( float )  2  ;    return   x    /    y \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    double   y    =     ( double )  2  ;    return   x    /    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedRHS"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1  ;    int   y    =     0  ;    return   x    /    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" long   x    =     1 L ;    long   y    =     0 L ;    return   x    /    y ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDivideByZero"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" return    1  /  0  ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" return    1 L /  0 L ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDivideByZeroConst"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     /     1  .  0  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  2  .  0     /     3  .  0  )  ,    exec (  \" double   x    =     2  ;    double   y    =     3  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  5  .  0     /     1  0  .  0  )  ,    exec (  \" double   x    =     5  ;    double   y    =     1  0  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0     /     1  .  0  )     /     2  .  0  )  ,    exec (  \" double   x    =     1  0  ;    double   y    =     1  ;    double   z    =     2  ;    return   x / y / z ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0     /     1  .  0  )     /     2  .  0  )  ,    exec (  \" double   x    =     1  0  ;    double   y    =     1  ;    double   z    =     2  ;    return    ( x / y )  / z ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     /     (  4  .  0     /     2  .  0  )  )  ,    exec (  \" double   x    =     1  0  ;    double   y    =     4  ;    double   z    =     2  ;    return   x /  ( y / z )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     /     1  .  0  )  ,    exec (  \" double   x    =     1  0  ;    double   y    =     1  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  0  .  0     /     1  .  0  )  ,    exec (  \" double   x    =     0  ;    double   y    =     1  ;    return   x / y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDouble"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     /     1  .  0  )  ,    exec (  \" return    1  .  0  /  1  .  0  ;  \"  )  )  ;", "assertEquals (  (  2  .  0     /     3  .  0  )  ,    exec (  \" return    2  .  0  /  3  .  0  ;  \"  )  )  ;", "assertEquals (  (  5  .  0     /     1  0  .  0  )  ,    exec (  \" return    5  .  0  /  1  0  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0     /     1  .  0  )     /     2  .  0  )  ,    exec (  \" return    1  0  .  0  /  1  .  0  /  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0     /     1  .  0  )     /     2  .  0  )  ,    exec (  \" return    (  1  0  .  0  /  1  .  0  )  /  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     /     (  4  .  0     /     2  .  0  )  )  ,    exec (  \" return    1  0  .  0  /  (  4  .  0  /  2  .  0  )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     /     1  .  0  )  ,    exec (  \" return    1  0  .  0  /  1  .  0  ;  \"  )  )  ;", "assertEquals (  (  0  .  0     /     1  .  0  )  ,    exec (  \" return    0  .  0  /  1  .  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleConst"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    /     1  .  0 F )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  2  .  0 F    /     3  .  0 F )  ,    exec (  \" float   x    =     2  ;    float   y    =     3  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    /     1  0  .  0 F )  ,    exec (  \" float   x    =     5  ;    float   y    =     1  0  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0 F    /     1  .  0 F )     /     2  .  0 F )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     1  ;    float   z    =     2  ;    return   x / y / z ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0 F    /     1  .  0 F )     /     2  .  0 F )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     1  ;    float   z    =     2  ;    return    ( x / y )  / z ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    /     (  4  .  0 F    /     2  .  0 F )  )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     4  ;    float   z    =     2  ;    return   x /  ( y / z )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    /     1  .  0 F )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     1  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    /     1  .  0 F )  ,    exec (  \" float   x    =     0  ;    float   y    =     1  ;    return   x / y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloat"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    /     1  .  0 F )  ,    exec (  \" return    1 F /  1 F ;  \"  )  )  ;", "assertEquals (  (  2  .  0 F    /     3  .  0 F )  ,    exec (  \" return    2 F /  3 F ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    /     1  0  .  0 F )  ,    exec (  \" return    5 F /  1  0 F ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0 F    /     1  .  0 F )     /     2  .  0 F )  ,    exec (  \" return    1  0 F /  1 F /  2 F ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0 F    /     1  .  0 F )     /     2  .  0 F )  ,    exec (  \" return    (  1  0 F /  1 F )  /  2 F ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    /     (  4  .  0 F    /     2  .  0 F )  )  ,    exec (  \" return    1  0 F /  (  4 F /  2 F )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    /     1  .  0 F )  ,    exec (  \" return    1  0 F /  1 F ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    /     1  .  0 F )  ,    exec (  \" return    0 F /  1 F ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloatConst"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     /     1  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  2     /     3  )  ,    exec (  \" int   x    =     2  ;    int   y    =     3  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  5     /     1  0  )  ,    exec (  \" int   x    =     5  ;    int   y    =     1  0  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  (  1  0     /     1  )     /     2  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     1  ;    int   z    =     2  ;    return   x / y / z ;  \"  )  )  ;", "assertEquals (  (  (  1  0     /     1  )     /     2  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     1  ;    int   z    =     2  ;    return    ( x / y )  / z ;  \"  )  )  ;", "assertEquals (  (  1  0     /     (  4     /     2  )  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     4  ;    int   z    =     2  ;    return   x /  ( y / z )  ;  \"  )  )  ;", "assertEquals (  (  1  0     /     1  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     1  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  0     /     1  )  ,    exec (  \" int   x    =     0  ;    int   y    =     1  ;    return   x / y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInt"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     /     1  )  ,    exec (  \" return    1  /  1  ;  \"  )  )  ;", "assertEquals (  (  2     /     3  )  ,    exec (  \" return    2  /  3  ;  \"  )  )  ;", "assertEquals (  (  5     /     1  0  )  ,    exec (  \" return    5  /  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  0     /     1  )     /     2  )  ,    exec (  \" return    1  0  /  1  /  2  ;  \"  )  )  ;", "assertEquals (  (  (  1  0     /     1  )     /     2  )  ,    exec (  \" return    (  1  0  /  1  )  /  2  ;  \"  )  )  ;", "assertEquals (  (  1  0     /     (  4     /     2  )  )  ,    exec (  \" return    1  0  /  (  4  /  2  )  ;  \"  )  )  ;", "assertEquals (  (  1  0     /     1  )  ,    exec (  \" return    1  0  /  1  ;  \"  )  )  ;", "assertEquals (  (  0     /     1  )  ,    exec (  \" return    0  /  1  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIntConst"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    /     1 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  2 L    /     3 L )  ,    exec (  \" long   x    =     2  ;    long   y    =     3  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  5 L    /     1  0 L )  ,    exec (  \" long   x    =     5  ;    long   y    =     1  0  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  (  1  0 L    /     1 L )     /     2 L )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     1  ;    long   z    =     2  ;    return   x / y / z ;  \"  )  )  ;", "assertEquals (  (  (  1  0 L    /     1 L )     /     2 L )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     1  ;    long   z    =     2  ;    return    ( x / y )  / z ;  \"  )  )  ;", "assertEquals (  (  1  0 L    /     (  4 L    /     2 L )  )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     4  ;    long   z    =     2  ;    return   x /  ( y / z )  ;  \"  )  )  ;", "assertEquals (  (  1  0 L    /     1 L )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     1  ;    return   x / y ;  \"  )  )  ;", "assertEquals (  (  0 L    /     1 L )  ,    exec (  \" long   x    =     0  ;    long   y    =     1  ;    return   x / y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLong"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    /     1 L )  ,    exec (  \" return    1 L /  1 L ;  \"  )  )  ;", "assertEquals (  (  2 L    /     3 L )  ,    exec (  \" return    2 L /  3 L ;  \"  )  )  ;", "assertEquals (  (  5 L    /     1  0 L )  ,    exec (  \" return    5 L /  1  0 L ;  \"  )  )  ;", "assertEquals (  (  (  1  0 L    /     1 L )     /     2 L )  ,    exec (  \" return    1  0 L /  1 L /  2 L ;  \"  )  )  ;", "assertEquals (  (  (  1  0 L    /     1 L )     /     2 L )  ,    exec (  \" return    (  1  0 L /  1 L )  /  2 L ;  \"  )  )  ;", "assertEquals (  (  1  0 L    /     (  4 L    /     2 L )  )  ,    exec (  \" return    1  0 L /  (  4 L /  2 L )  ;  \"  )  )  ;", "assertEquals (  (  1  0 L    /     1 L )  ,    exec (  \" return    1  0 L /  1 L ;  \"  )  )  ;", "assertEquals (  (  0 L    /     1 L )  ,    exec (  \" return    0 L /  1 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongConst"], "fileName": "org.elasticsearch.painless.DivisionTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec ( script )  )  ;", "assertEquals (  \"    operator   cannot   return   primitives \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertCannotReturnPrimitive"], "fileName": "org.elasticsearch.painless.ElvisTests"}, {"methodBody": ["METHOD_START", "{", "String   disassembled    =    Debugger . toString ( code )  ;", "int   firstLookup    =    disassembled . indexOf (  \" INVOKEINTERFACE   java / util / Map . get    ( Ljava / lang / Object ;  ) Ljava / lang / Object ;  \"  )  ;", "assertThat ( disassembled ,    firstLookup ,    greaterThan (  (  -  1  )  )  )  ;", "int   firstDestinationLabelIndex    =    disassembled . indexOf (  \" IFNONNULL   L \"  ,    firstLookup )  ;", "assertThat ( disassembled ,    firstDestinationLabelIndex ,    greaterThan (  (  -  1  )  )  )  ;", "String   firstDestinationLabel    =    disassembled . substring (  ( firstDestinationLabelIndex    +     (  \" IFNONNULL    \"  . length (  )  )  )  ,    disassembled . indexOf (  '  \\ n '  ,    firstDestinationLabelIndex )  )  ;", "int   firstDestionation    =    disassembled . indexOf (  (  \"           \"     +    firstDestinationLabel )  )  ;", "assertThat ( disassembled ,    firstDestionation ,    greaterThan (  (  -  1  )  )  )  ;", "int   ifAfterFirstDestination    =    disassembled . indexOf (  \" IF \"  ,    firstDestionation )  ;", "if    ( expectOneBranch )     {", "assertThat ( disassembled ,    ifAfterFirstDestination ,    lessThan (  0  )  )  ;", "} else    {", "assertThat ( disassembled ,    ifAfterFirstDestination ,    greaterThan (  (  -  1  )  )  )  ;", "}", "int   returnAfterFirstDestination    =    disassembled . indexOf (  \" RETURN \"  ,    firstDestionation )  ;", "assertThat ( disassembled ,    returnAfterFirstDestination ,    greaterThan (  (  -  1  )  )  )  ;", "}", "METHOD_END"], "methodName": ["checkOneBranch"], "fileName": "org.elasticsearch.painless.ElvisTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" str \"  ,    exec (  \" return   params . a    ?  :     ' str '  \"  )  )  ;", "assertEquals (  \" str \"  ,    exec (  \" return   params . a    ?  :     ' str 2  '  \"  ,    Collections . singletonMap (  \" a \"  ,     \" str \"  )  ,    true )  )  ;", "assertEquals (  \" str \"  ,    exec (  \" return   params . a    ?  :     ' asdf '  \"  ,    Collections . singletonMap (  \" a \"  ,     \" str \"  )  ,    true )  )  ;", "assertCannotReturnPrimitive (  \" int   i    =    params . a    ?  :     1  ;    return   i \"  )  ;", "assertCannotReturnPrimitive (  \" Integer   a    =    Integer . valueOf (  1  )  ;    int   b    =    a    ?  :     2  ;    return   b \"  )  ;", "assertCannotReturnPrimitive (  \" Integer   a    =    Integer . valueOf (  1  )  ;    int   b    =    a    ?  :    Integer . valueOf (  2  )  ;    return   b \"  )  ;", "assertEquals (  2  ,    exec (  \" int   i    =     ( params . a    ?  :    Integer . valueOf (  2  )  )  . intValue (  )  ;    return   i \"  )  )  ;", "assertEquals (  1  ,    exec (  \" int   i    =     ( params . a    ?  :    Integer . valueOf (  2  )  )  . intValue (  )  ;    return   i \"  ,    Collections . singletonMap (  \" a \"  ,     1  )  ,    true )  )  ;", "assertEquals (  1  ,    exec (  \" Integer   a    =    Integer . valueOf (  1  )  ;    int   b    =     ( a    ?  :    Integer . valueOf (  2  )  )  . intValue (  )  ;    return   b \"  )  )  ;", "assertEquals (  2  ,    exec (  \" Integer   a    =    null ;    int   b    =     ( a    ?  :    Integer . valueOf (  2  )  )  . intValue (  )  ;    return   b \"  )  )  ;", "assertEquals (  1  ,    exec (  \" Integer   i    =    params . a    ?  :    Integer . valueOf (  1  )  ;    return   i \"  )  )  ;", "assertEquals (  1  ,    exec (  \" Integer   i    =    params . a    ?  :    Integer . valueOf (  2  )  ;    return   i \"  ,    Collections . singletonMap (  \" a \"  ,     1  )  ,    true )  )  ;", "assertEquals (  1  ,    exec (  \" Integer   a    =    Integer . valueOf (  1  )  ;    Integer   b    =    a    ?  :    Integer . valueOf (  2  )  ;    return   b \"  )  )  ;", "assertEquals (  2  ,    exec (  \" Integer   a    =    null ;    Integer   b    =    a    ?  :    Integer . valueOf (  2  )  ;    return   b \"  )  )  ;", "assertEquals (  1  ,    exec (  \" return    ( Integer )  ( params . a    ?  :    Integer . valueOf (  1  )  )  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" return    ( Integer )  ( params . a    ?  :    Integer . valueOf (  2  )  )  \"  ,    Collections . singletonMap (  \" a \"  ,     1  )  ,    true )  )  ;", "assertCannotReturnPrimitive (  \" return    ( int )  ( params . a    ?  :     1  )  \"  )  ;", "assertEquals (  1  ,    exec (  \" return   params . a    ?  :    params . a    ?  :     1  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" return   params . a    ?  :    params . b    ?  :     ' j '  \"  ,    Collections . singletonMap (  \" b \"  ,     1  )  ,    true )  )  ;", "assertEquals (  1  ,    exec (  \" return   params . a    ?  :    params . b    ?  :     ' j '  \"  ,    Collections . singletonMap (  \" a \"  ,     1  )  ,    true )  )  ;", "assertEquals (  1  ,    exec (  \" return   params . a    ?  :     2     +     2  \"  ,    Collections . singletonMap (  \" a \"  ,     1  )  ,    true )  )  ;", "assertEquals (  4  ,    exec (  \" return   params . a    ?  :     2     +     2  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" return   params . a    +     1     ?  :     2     +     2  \"  ,    Collections . singletonMap (  \" a \"  ,     1  )  ,    true )  )  ;", "assertEquals (  1  ,    exec (  \" int   i    =    params . i ;                String   s    =    params . s ;    return   s    ?  :    i \"  ,    Collections . singletonMap (  \" i \"  ,     1  )  ,    true )  )  ;", "assertEquals (  \" str \"  ,    exec (  \" Integer   i    =    params . i ;    String   s    =    params . s ;    return   s    ?  :    i \"  ,    Collections . singletonMap (  \" s \"  ,     \" str \"  )  ,    true )  )  ;", "assertEquals (  2  ,    exec (  \" return    ( params . a    ?  :     0  )     +     1  \"  ,    Collections . singletonMap (  \" a \"  ,     1  )  ,    true )  )  ;", "assertEquals (  1  ,    exec (  \" return    ( params . a    ?  :     0  )     +     1  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" return    ( params . a    ?  :     [  ' b '  :     1  0  ]  )  . b    +     1  \"  ,    Collections . singletonMap (  \" a \"  ,    Collections . singletonMap (  \" b \"  ,     1  )  )  ,    true )  )  ;", "assertEquals (  1  1  ,    exec (  \" return    ( params . a    ?  :     [  ' b '  :     1  0  ]  )  . b    +     1  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.ElvisTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" int   i    =    params . a ;    return   i    ?  :     1  \"  )  )  ;", "assertEquals (  \" Extraneous   elvis   operator .    LHS   is   a   primitive .  \"  ,    e . getMessage (  )  )  ;", "ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" int   i    =    params . a ;    return   i    +     1  0     ?  :     ' ignored '  \"  )  )  ;", "assertEquals (  \" Extraneous   elvis   operator .    LHS   is   a   primitive .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return    ' cat '     ?  :     1  \"  )  )  ;", "assertEquals (  \" Extraneous   elvis   operator .    LHS   is   a   constant .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return   null    ?  :     ' j '  \"  )  )  ;", "assertEquals (  \" Extraneous   elvis   operator .    LHS   is   null .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return   params . a    ?  :    null    ?  :     ' j '  \"  )  )  ;", "assertEquals (  \" Extraneous   elvis   operator .    LHS   is   null .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return   params . a    ?  :    null \"  )  )  ;", "assertEquals (  \" Extraneous   elvis   operator .    RHS   is   null .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtraneous"], "fileName": "org.elasticsearch.painless.ElvisTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" def   fail (  )     { throw   new   RuntimeException (  ' test '  )  }    return   params . a    ?  :    fail (  )  \"  ,    Collections . singletonMap (  \" a \"  ,     1  )  ,    true )  )  ;", "Exception   e    =    ScriptCase . expectScriptThrows ( RuntimeException . class ,     (  )     -  >    exec (  \" def   fail (  )     { throw   new   RuntimeException (  ' test '  )  }    return   params . a    ?  :    fail (  )  \"  )  )  ;", "assertEquals ( e . getMessage (  )  ,     \" test \"  )  ;", "}", "METHOD_END"], "methodName": ["testLazy"], "fileName": "org.elasticsearch.painless.ElvisTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return   params . a    ?     :     1  \"  ,    false )  )  ;", "assertEquals (  \" invalid   sequence   of   tokens   near    [  '  :  '  ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testQuestionSpaceColonIsNotElvis"], "fileName": "org.elasticsearch.painless.ElvisTests"}, {"methodBody": ["METHOD_START", "{", "checkOneBranch (  \" params . a    ?  :     ( params . b    ?  :    params . c )  \"  ,    true )  ;", "checkOneBranch (  \"  ( params . a    ?  :    params . b )     ?  :    params . c \"  ,    false )  ;", "checkOneBranch (  \" params . a    ?  :    params . b    ?  :    params . c \"  ,    true )  ;", "}", "METHOD_END"], "methodName": ["testRightAssociative"], "fileName": "org.elasticsearch.painless.ElvisTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" return   params . a ?  . b    ?  :     1  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" return   params . a ?  . b    ?  :     2  \"  ,    Collections . singletonMap (  \" a \"  ,    Collections . singletonMap (  \" b \"  ,     1  )  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testWithNullSafeDereferences"], "fileName": "org.elasticsearch.painless.ElvisTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    exec (  \" def   a    =     ( char )  ' a '  ;    def   b    =     ( char )  ' b '  ;    if    ( a    =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   a    =     ( char )  ' a '  ;    def   b    =     ( char )  ' a '  ;    if    ( a    =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   a    =     1  ;    def   b    =     1  ;    if    ( a    =  =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   a    =     ( char )  ' a '  ;    def   b    =     ( char )  ' a '  ;    if    ( a    =  =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   a    =     ( char )  ' a '  ;    Object   b    =    a ;    if    ( a    =  =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   a    =     1  ;    Number   b    =    a ;    Number   c    =    a ;    if    ( c    =  =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     1  ;    Object   b    =    new   HashMap (  )  ;    if    ( a    =  =  =     ( Object ) b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBranchEquals"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" def   a    =     ( char )  ' a '  ;    def   b    =     ( char )  ' b '  ;    if    ( a    !  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     ( char )  ' a '  ;    def   b    =     ( char )  ' a '  ;    if    ( a    !  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     1  ;    def   b    =     1  ;    if    ( a    !  =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     ( char )  ' a '  ;    def   b    =     ( char )  ' a '  ;    if    ( a    !  =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     ( char )  ' a '  ;    Object   b    =    a ;    if    ( a    !  =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   a    =     1  ;    Number   b    =    a ;    Number   c    =    a ;    if    ( c    !  =  =    b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   a    =     1  ;    Object   b    =    new   HashMap (  )  ;    if    ( a    !  =  =     ( Object ) b )    return    1  ;    else   return    0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBranchNotEquals"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return    3     =  =     3  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     4  ;    int   y    =     5  ;    x    =  =    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" int [  ]    x    =    new   int [  1  ]  ;    Object   y    =    x ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" int [  ]    x    =    new   int [  1  ]  ;    Object   y    =    x ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" int [  ]    x    =    new   int [  1  ]  ;    Object   y    =    new   int [  1  ]  ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" int [  ]    x    =    new   int [  1  ]  ;    Object   y    =    new   int [  1  ]  ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" Map   x    =    new   HashMap (  )  ;    List   y    =    new   ArrayList (  )  ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" Map   x    =    new   HashMap (  )  ;    List   y    =    new   ArrayList (  )  ;    return   x    =  =  =    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEquals"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "int   uncachedAutoboxedInt    =    randomValueOtherThanMany (  (    i )     -  >     ( Integer . valueOf ( i )  )     =  =     ( Integer . valueOf ( i )  )  ,    ESTestCase :  : randomInt )  ;", "assert ( true ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   x    =  =    y ;  \"  ,    Collections . singletonMap (  \" i \"  ,    uncachedAutoboxedInt )  ,    true )  )  ;", "assert ( false ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   x    =  =  =    y ;  \"  ,    Collections . singletonMap (  \" i \"  ,    uncachedAutoboxedInt )  ,    true )  )  ;", "assert ( true ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   y    =  =    x ;  \"  ,    Collections . singletonMap (  \" i \"  ,    uncachedAutoboxedInt )  ,    true )  )  ;", "assert ( false ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   y    =  =  =    x ;  \"  ,    Collections . singletonMap (  \" i \"  ,    uncachedAutoboxedInt )  ,    true )  )  ;", "int   cachedAutoboxedInt    =     0  ;", "assertSame ( Integer . valueOf ( cachedAutoboxedInt )  ,    Integer . valueOf ( cachedAutoboxedInt )  )  ;", "assert ( true ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   x    =  =    y ;  \"  ,    Collections . singletonMap (  \" i \"  ,    cachedAutoboxedInt )  ,    true )  )  ;", "assert ( true ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   x    =  =  =    y ;  \"  ,    Collections . singletonMap (  \" i \"  ,    cachedAutoboxedInt )  ,    true )  )  ;", "assert ( true ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   y    =  =    x ;  \"  ,    Collections . singletonMap (  \" i \"  ,    cachedAutoboxedInt )  ,    true )  )  ;", "assert ( true ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   y    =  =  =    x ;  \"  ,    Collections . singletonMap (  \" i \"  ,    cachedAutoboxedInt )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testEqualsDefAndPrimitive"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" HashMap   a    =    new   HashMap (  )  ;    return   null    =  =    a ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" HashMap   a    =    new   HashMap (  )  ;    return   null    =  =  =    a ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" HashMap   a    =    new   HashMap (  )  ;    return   null    !  =    a ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" HashMap   a    =    new   HashMap (  )  ;    return   null    !  =  =    a ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLeftHandNull"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" return    3     !  =     3  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     4  ;    int   y    =     5  ;    x    !  =    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" int [  ]    x    =    new   int [  1  ]  ;    Object   y    =    x ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" int [  ]    x    =    new   int [  1  ]  ;    Object   y    =    x ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" int [  ]    x    =    new   int [  1  ]  ;    Object   y    =    new   int [  1  ]  ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" int [  ]    x    =    new   int [  1  ]  ;    Object   y    =    new   int [  1  ]  ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" Map   x    =    new   HashMap (  )  ;    List   y    =    new   ArrayList (  )  ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" Map   x    =    new   HashMap (  )  ;    List   y    =    new   ArrayList (  )  ;    return   x    !  =  =    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNotEquals"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "int   uncachedAutoboxedInt    =    randomValueOtherThanMany (  (    i )     -  >     ( Integer . valueOf ( i )  )     =  =     ( Integer . valueOf ( i )  )  ,    ESTestCase :  : randomInt )  ;", "assert ( false ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   x    !  =    y ;  \"  ,    Collections . singletonMap (  \" i \"  ,    uncachedAutoboxedInt )  ,    true )  )  ;", "assert ( true ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   x    !  =  =    y ;  \"  ,    Collections . singletonMap (  \" i \"  ,    uncachedAutoboxedInt )  ,    true )  )  ;", "assert ( false ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   y    !  =    x ;  \"  ,    Collections . singletonMap (  \" i \"  ,    uncachedAutoboxedInt )  ,    true )  )  ;", "assert ( true ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   y    !  =  =    x ;  \"  ,    Collections . singletonMap (  \" i \"  ,    uncachedAutoboxedInt )  ,    true )  )  ;", "int   cachedAutoboxedInt    =     0  ;", "assertSame ( Integer . valueOf ( cachedAutoboxedInt )  ,    Integer . valueOf ( cachedAutoboxedInt )  )  ;", "assert ( false ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   x    !  =    y ;  \"  ,    Collections . singletonMap (  \" i \"  ,    cachedAutoboxedInt )  ,    true )  )  ;", "assert ( false ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   x    !  =  =    y ;  \"  ,    Collections . singletonMap (  \" i \"  ,    cachedAutoboxedInt )  ,    true )  )  ;", "assert ( false ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   y    !  =    x ;  \"  ,    Collections . singletonMap (  \" i \"  ,    cachedAutoboxedInt )  ,    true )  )  ;", "assert ( false ,    exec (  \" def   x    =    params . i ;    int   y    =    params . i ;    return   y    !  =  =    x ;  \"  ,    Collections . singletonMap (  \" i \"  ,    cachedAutoboxedInt )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testNotEqualsDefAndPrimitive"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" HashMap   a    =    new   HashMap (  )  ;    return   a    =  =    null ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" HashMap   a    =    new   HashMap (  )  ;    return   a    =  =  =    null ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" HashMap   a    =    new   HashMap (  )  ;    return   a    !  =    null ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" HashMap   a    =    new   HashMap (  )  ;    return   a    !  =  =    null ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRightHandNull"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return   false    =  =  =    false ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    boolean   y    =    true ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    false ;    boolean   y    =    false ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( byte )  3     =  =  =     ( byte )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" byte   x    =     3  ;    byte   y    =     3  ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( char )  3     =  =  =     ( char )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" char   x    =     3  ;    char   y    =     3  ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( short )  3     =  =  =     ( short )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" short   x    =     3  ;    short   y    =     3  ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( int )  3     =  =  =     ( int )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     3  ;    int   y    =     3  ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( long )  3     =  =  =     ( long )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" long   x    =     3  ;    long   y    =     3  ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( float )  3     =  =  =     ( float )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" float   x    =     3  ;    float   y    =     3  ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( double )  3     =  =  =     ( double )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     3  ;    double   y    =     3  ;    return   x    =  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return   false    =  =    false ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    boolean   y    =    true ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    false ;    boolean   y    =    false ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( byte )  3     =  =     ( byte )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" byte   x    =     3  ;    byte   y    =     3  ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( char )  3     =  =     ( char )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" char   x    =     3  ;    char   y    =     3  ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( short )  3     =  =     ( short )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" short   x    =     3  ;    short   y    =     3  ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( int )  3     =  =     ( int )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" int   x    =     3  ;    int   y    =     3  ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( long )  3     =  =     ( long )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" long   x    =     3  ;    long   y    =     3  ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( float )  3     =  =     ( float )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" float   x    =     3  ;    float   y    =     3  ;    return   x    =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( double )  3     =  =     ( double )  4  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" double   x    =     3  ;    double   y    =     3  ;    return   x    =  =    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testTypesEquals"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" return   true    !  =  =    true ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;    boolean   y    =    false ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    boolean   y    =    false ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( byte )  3     !  =  =     ( byte )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" byte   x    =     3  ;    byte   y    =     3  ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( char )  3     !  =  =     ( char )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" char   x    =     3  ;    char   y    =     3  ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( short )  3     !  =  =     ( short )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" short   x    =     3  ;    short   y    =     3  ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( int )  3     !  =  =     ( int )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     3  ;    int   y    =     3  ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( long )  3     !  =  =     ( long )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" long   x    =     3  ;    long   y    =     3  ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( float )  3     !  =  =     ( float )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" float   x    =     3  ;    float   y    =     3  ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( double )  3     !  =  =     ( double )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" double   x    =     3  ;    double   y    =     3  ;    return   x    !  =  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return   true    !  =    true ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;    boolean   y    =    false ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    boolean   y    =    false ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( byte )  3     !  =     ( byte )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" byte   x    =     3  ;    byte   y    =     3  ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( char )  3     !  =     ( char )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" char   x    =     3  ;    char   y    =     3  ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( short )  3     !  =     ( short )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" short   x    =     3  ;    short   y    =     3  ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( int )  3     !  =     ( int )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" int   x    =     3  ;    int   y    =     3  ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( long )  3     !  =     ( long )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" long   x    =     3  ;    long   y    =     3  ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( float )  3     !  =     ( float )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" float   x    =     3  ;    float   y    =     3  ;    return   x    !  =    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( double )  3     !  =     ( double )  4  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" double   x    =     3  ;    double   y    =     3  ;    return   x    !  =    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testTypesNotEquals"], "fileName": "org.elasticsearch.painless.EqualsTests"}, {"methodBody": ["METHOD_START", "{", "FactoryTests . EmptyTestScript . Factory   factory    =    scriptEngine . compile (  \" empty _ test \"  ,     \"  1  \"  ,    FactoryTests . EmptyTestScript . CONTEXT ,    Collections . emptyMap (  )  )  ;", "FactoryTests . EmptyTestScript   script    =    factory . newInstance (  )  ;", "assertEquals (  1  ,    script . execute (  )  )  ;", "assertEquals (  1  ,    script . execute (  )  )  ;", "script    =    factory . newInstance (  )  ;", "assertEquals (  1  ,    script . execute (  )  )  ;", "assertEquals (  1  ,    script . execute (  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmpty"], "fileName": "org.elasticsearch.painless.FactoryTests"}, {"methodBody": ["METHOD_START", "{", "FactoryTests . FactoryTestScript . Factory   factory    =    scriptEngine . compile (  \" factory _ test \"  ,     \" test    +    params . get (  ' test '  )  \"  ,    FactoryTests . FactoryTestScript . CONTEXT ,    Collections . emptyMap (  )  )  ;", "FactoryTests . FactoryTestScript   script    =    factory . newInstance ( Collections . singletonMap (  \" test \"  ,     2  )  )  ;", "assertEquals (  4  ,    script . execute (  2  )  )  ;", "assertEquals (  5  ,    script . execute (  3  )  )  ;", "script    =    factory . newInstance ( Collections . singletonMap (  \" test \"  ,     3  )  )  ;", "assertEquals (  5  ,    script . execute (  2  )  )  ;", "assertEquals (  2  ,    script . execute (  (  -  1  )  )  )  ;", "assertEquals ( true ,    factory . needsTest (  )  )  ;", "assertEquals ( false ,    factory . needsNothing (  )  )  ;", "}", "METHOD_END"], "methodName": ["testFactory"], "fileName": "org.elasticsearch.painless.FactoryTests"}, {"methodBody": ["METHOD_START", "{", "FactoryTests . FactoryTestScript . Factory   factory    =    scriptEngine . compile (  \" template _ test \"  ,     \" IntSupplier   createLambda ( IntSupplier   s )     {    return   s ;     }    createLambda (  (  )     -  >    params [  ' x '  ]     +    test )  . getAsInt (  )  \"  ,    FactoryTests . FactoryTestScript . CONTEXT ,    Collections . emptyMap (  )  )  ;", "FactoryTests . FactoryTestScript   script    =    factory . newInstance ( Collections . singletonMap (  \" x \"  ,     1  )  )  ;", "assertEquals (  2  ,    script . execute (  1  )  )  ;", "}", "METHOD_END"], "methodName": ["testGetterInLambda"], "fileName": "org.elasticsearch.painless.FactoryTests"}, {"methodBody": ["METHOD_START", "{", "FactoryTests . StatefulFactoryTestScript . Factory   factory    =    scriptEngine . compile (  \" stateful _ factory _ test \"  ,     \" test    +    x    +    y    +    d \"  ,    FactoryTests . StatefulFactoryTestScript . CONTEXT ,    Collections . emptyMap (  )  )  ;", "FactoryTests . StatefulFactoryTestScript . StatefulFactory   statefulFactory    =    factory . newFactory (  1  ,     2  )  ;", "FactoryTests . StatefulFactoryTestScript   script    =    statefulFactory . newInstance (  3  ,     4  )  ;", "assertEquals (  2  4  ,    script . execute (  3  )  )  ;", "statefulFactory . newInstance (  5  ,     6  )  ;", "assertEquals (  2  8  ,    script . execute (  7  )  )  ;", "assertEquals ( true ,    script . needsTest (  )  )  ;", "assertEquals ( false ,    script . needsNothing (  )  )  ;", "assertEquals ( true ,    script . needsX (  )  )  ;", "assertEquals ( false ,    script . needsC (  )  )  ;", "assertEquals ( true ,    script . needsD (  )  )  ;", "assertEquals ( true ,    statefulFactory . needsTest (  )  )  ;", "assertEquals ( false ,    statefulFactory . needsNothing (  )  )  ;", "assertEquals ( true ,    statefulFactory . needsX (  )  )  ;", "assertEquals ( false ,    statefulFactory . needsC (  )  )  ;", "assertEquals ( true ,    statefulFactory . needsD (  )  )  ;", "assertEquals ( true ,    factory . needsTest (  )  )  ;", "assertEquals ( false ,    factory . needsNothing (  )  )  ;", "assertEquals ( true ,    factory . needsX (  )  )  ;", "assertEquals ( false ,    factory . needsC (  )  )  ;", "assertEquals ( true ,    factory . needsD (  )  )  ;", "}", "METHOD_END"], "methodName": ["testStatefulFactory"], "fileName": "org.elasticsearch.painless.FactoryTests"}, {"methodBody": ["METHOD_START", "{", "TemplateScript . Factory   factory    =    scriptEngine . compile (  \" template _ test \"  ,     \" params [  ' test '  ]  \"  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "TemplateScript   script    =    factory . newInstance ( Collections . singletonMap (  \" test \"  ,     \" abc \"  )  )  ;", "assertEquals (  \" abc \"  ,    script . execute (  )  )  ;", "assertEquals (  \" abc \"  ,    script . execute (  )  )  ;", "script    =    factory . newInstance ( Collections . singletonMap (  \" test \"  ,     \" def \"  )  )  ;", "assertEquals (  \" def \"  ,    script . execute (  )  )  ;", "assertEquals (  \" def \"  ,    script . execute (  )  )  ;", "}", "METHOD_END"], "methodName": ["testTemplate"], "fileName": "org.elasticsearch.painless.FactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   x ;", "}", "METHOD_END"], "methodName": ["getX"], "fileName": "org.elasticsearch.painless.FeatureTest"}, {"methodBody": ["METHOD_START", "{", "return   y ;", "}", "METHOD_END"], "methodName": ["getY"], "fileName": "org.elasticsearch.painless.FeatureTest"}, {"methodBody": ["METHOD_START", "{", "return   true ;", "}", "METHOD_END"], "methodName": ["overloadedStatic"], "fileName": "org.elasticsearch.painless.FeatureTest"}, {"methodBody": ["METHOD_START", "{", "return   whatToReturn ;", "}", "METHOD_END"], "methodName": ["overloadedStatic"], "fileName": "org.elasticsearch.painless.FeatureTest"}, {"methodBody": ["METHOD_START", "{", "this . x    =    x ;", "}", "METHOD_END"], "methodName": ["setX"], "fileName": "org.elasticsearch.painless.FeatureTest"}, {"methodBody": ["METHOD_START", "{", "this . y    =    y ;", "}", "METHOD_END"], "methodName": ["setY"], "fileName": "org.elasticsearch.painless.FeatureTest"}, {"methodBody": ["METHOD_START", "{", "return   f . apply ( g . apply ( x )  )  ;", "}", "METHOD_END"], "methodName": ["twoFunctionsOfX"], "fileName": "org.elasticsearch.painless.FeatureTest"}, {"methodBody": ["METHOD_START", "{", "return    ( FeatureTestAugmentation . getTotal ( ft )  )     +    add ;", "}", "METHOD_END"], "methodName": ["addToTotal"], "fileName": "org.elasticsearch.painless.FeatureTestAugmentation"}, {"methodBody": ["METHOD_START", "{", "return    ( ft . getX (  )  )     +     ( ft . getY (  )  )  ;", "}", "METHOD_END"], "methodName": ["getTotal"], "fileName": "org.elasticsearch.painless.FeatureTestAugmentation"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" float   x    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    float   y    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    return   x    +    y ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" double   x    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    double   y    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    return   x    +    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAddition"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" return    3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f    +     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" return    1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8     +     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAdditionConst"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" float   x    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    x    +  =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    return   x ;  \"  )  )  ;", "assertEquals ( Float . NEGATIVE _ INFINITY ,    exec (  \" float   x    =     -  3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    x    +  =     -  3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    return   x ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" double   x    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    x    +  =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    return   x ;  \"  )  )  ;", "assertEquals ( Double . NEGATIVE _ INFINITY ,    exec (  \" double   x    =     -  1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    x    +  =     -  1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignmentAdditionOverflow"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" float   x    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    x    /  =     1  .  4  0  1  2  9  8  4  6  4  3  2  4  8  1  7 E -  4  5 f ;    return   x ;  \"  )  )  ;", "assertEquals ( Float . NEGATIVE _ INFINITY ,    exec (  \" float   x    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    x    /  =     -  1  .  4  0  1  2  9  8  4  6  4  3  2  4  8  1  7 E -  4  5 f ;    return   x ;  \"  )  )  ;", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" float   x    =     1  .  0 f ;    x    /  =     0  .  0 f ;    return   x ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" double   x    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    x    /  =     4  .  9 E -  3  2  4  ;    return   x ;  \"  )  )  ;", "assertEquals ( Double . NEGATIVE _ INFINITY ,    exec (  \" double   x    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    x    /  =     -  4  .  9 E -  3  2  4  ;    return   x ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" double   x    =     1  .  0 f ;    x    /  =     0  .  0  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignmentDivisionOverflow"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" float   x    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    x    *  =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    return   x ;  \"  )  )  ;", "assertEquals ( Float . NEGATIVE _ INFINITY ,    exec (  \" float   x    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    x    *  =     -  3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    return   x ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" double   x    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    x    *  =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    return   x ;  \"  )  )  ;", "assertEquals ( Double . NEGATIVE _ INFINITY ,    exec (  \" double   x    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    x    *  =     -  1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignmentMultiplicationOverflow"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" float   x    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    x    -  =     -  3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    return   x ;  \"  )  )  ;", "assertEquals ( Float . NEGATIVE _ INFINITY ,    exec (  \" float   x    =     -  3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    x    -  =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    return   x ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" double   x    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    x    -  =     -  1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    return   x ;  \"  )  )  ;", "assertEquals ( Double . NEGATIVE _ INFINITY ,    exec (  \" double   x    =     -  1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    x    -  =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignmentSubtractionOverflow"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" float   x    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    float   y    =     1  .  4  0  1  2  9  8  4  6  4  3  2  4  8  1  7 E -  4  5 f ;    return   x    /    y ;  \"  )  )  ;", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" float   x    =     1  .  0 f ;    float   y    =     0  .  0 f ;    return   x    /    y ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" double   x    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    double   y    =     4  .  9 E -  3  2  4  ;    return   x    /    y ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" double   x    =     1  .  0  ;    double   y    =     0  .  0  ;    return   x    /    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDivision"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" return    3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f    /     1  .  4  0  1  2  9  8  4  6  4  3  2  4  8  1  7 E -  4  5 f ;  \"  )  )  ;", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" return    1  .  0 f    /     0  .  0 f ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" return    1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8     /     4  .  9 E -  3  2  4  ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" return    1  .  0     /     0  .  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDivisionConst"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertTrue ( Float . isNaN (  (  ( Float )     ( exec (  \" float   x    =     0 f ;    float   y    =     0 f ;    return   x    /    y ;  \"  )  )  )  )  )  ;", "assertTrue ( Float . isNaN (  (  ( Float )     ( exec (  \" return    0 f    /     0 f ;  \"  )  )  )  )  )  ;", "assertTrue ( Float . isNaN (  (  ( Float )     ( exec (  \" float   x    =     0 f ;    x    /  =     0 f ;    return   x ;  \"  )  )  )  )  )  ;", "assertTrue ( Double . isNaN (  (  ( Double )     ( exec (  \" double   x    =     0  .  0  ;    double   y    =     0  .  0  ;    return   x    /    y ;  \"  )  )  )  )  )  ;", "assertTrue ( Double . isNaN (  (  ( Double )     ( exec (  \" return    0  .  0     /     0  .  0  ;  \"  )  )  )  )  )  ;", "assertTrue ( Double . isNaN (  (  ( Double )     ( exec (  \" double   x    =     0  .  0  ;    x    /  =     0  .  0  ;    return   x ;  \"  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testDivisionNaN"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" float   x    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    float   y    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    return   x    *    y ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" double   x    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    double   y    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    return   x    *    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiplication"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . POSITIVE _ INFINITY ,    exec (  \" return    3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f    *     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;  \"  )  )  ;", "assertEquals ( Double . POSITIVE _ INFINITY ,    exec (  \" return    1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8     *     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiplicationConst"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertTrue ( Float . isNaN (  (  ( Float )     ( exec (  \" float   x    =     1 f ;    float   y    =     0 f ;    return   x    %    y ;  \"  )  )  )  )  )  ;", "assertTrue ( Float . isNaN (  (  ( Float )     ( exec (  \" return    1 f    %     0 f ;  \"  )  )  )  )  )  ;", "assertTrue ( Float . isNaN (  (  ( Float )     ( exec (  \" float   x    =     1 f ;    x    %  =     0 f ;    return   x ;  \"  )  )  )  )  )  ;", "assertTrue ( Double . isNaN (  (  ( Double )     ( exec (  \" double   x    =     1  .  0  ;    double   y    =     0  .  0  ;    return   x    %    y ;  \"  )  )  )  )  )  ;", "assertTrue ( Double . isNaN (  (  ( Double )     ( exec (  \" return    1  .  0     %     0  .  0  ;  \"  )  )  )  )  )  ;", "assertTrue ( Double . isNaN (  (  ( Double )     ( exec (  \" double   x    =     1  .  0  ;    x    %  =     0  .  0  ;    return   x ;  \"  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testRemainderNaN"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . NEGATIVE _ INFINITY ,    exec (  \" float   x    =     -  3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    float   y    =     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;    return   x    -    y ;  \"  )  )  ;", "assertEquals ( Double . NEGATIVE _ INFINITY ,    exec (  \" double   x    =     -  1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    double   y    =     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;    return   x    -    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSubtraction"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Float . NEGATIVE _ INFINITY ,    exec (  \" return    -  3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f    -     3  .  4  0  2  8  2  3  4  6  6  3  8  5  2  8  8  6 E 3  8 f ;  \"  )  )  ;", "assertEquals ( Double . NEGATIVE _ INFINITY ,    exec (  \" return    -  1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8     -     1  .  7  9  7  6  9  3  1  3  4  8  6  2  3  1  5  7 E 3  0  8  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSubtractionConst"], "fileName": "org.elasticsearch.painless.FloatOverflowTests"}, {"methodBody": ["METHOD_START", "{", "Definition . Method   method    =    definition . ClassToType ( expected )  . struct . functionalMethod ;", "if    ( method    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  \" Cannot   convert   function   reference    [  \"     +    type )     +     \"  :  :  \"  )     +    call )     +     \"  ]     \"  )     +     \" to    [  \"  )     +     ( Definition . ClassToName ( expected )  )  )     +     \"  ]  ,    not   a   functional   interface \"  )  )  ;", "}", "Definition . Struct   struct    =    definition . getType ( type )  . struct ;", "final   Definition . Method   impl ;", "if    (  \" new \"  . equals ( call )  )     {", "impl    =    struct . constructors . get ( new   Definition . MethodKey (  \"  < init >  \"  ,    method . arguments . size (  )  )  )  ;", "} else    {", "Definition . Method   staticImpl    =    struct . staticMethods . get ( new   Definition . MethodKey ( call ,    method . arguments . size (  )  )  )  ;", "if    ( staticImpl    =  =    null )     {", "final   int   arity ;", "if    ( receiverCaptured )     {", "arity    =    method . arguments . size (  )  ;", "} else    {", "arity    =     ( method . arguments . size (  )  )     -     1  ;", "}", "impl    =    struct . methods . get ( new   Definition . MethodKey ( call ,    arity )  )  ;", "} else    {", "impl    =    staticImpl ;", "}", "}", "if    ( impl    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  (  (  (  (  (  \" Unknown   reference    [  \"     +    type )     +     \"  :  :  \"  )     +    call )     +     \"  ]    matching    \"  )     +     \"  [  \"  )     +    expected )     +     \"  ]  \"  )  )  ;", "}", "return   impl ;", "}", "METHOD_END"], "methodName": ["lookup"], "fileName": "org.elasticsearch.painless.FunctionRef"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  .  0  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  .  0  )  ;    l . add (  2  .  0  )  ;     \"     +     (  \" def [  ]    array    =    l . stream (  )  . toArray ( Double [  ]  :  : new )  ;  \"     +     \" return   array [  0  ]  ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testArrayCtorMethodRef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  .  0  ,    exec (  (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  .  0  )  ;    l . add (  2  .  0  )  ;     \"     +     (  \" def [  ]    array    =    l . stream (  )  . toArray ( Double [  ]  :  : new )  ;  \"     +     \" return   array [  0  ]  ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testArrayCtorMethodRefDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  5  \"  ,    exec (  \" Integer   x    =    Integer . valueOf (  5  )  ;    return   Optional . empty (  )  . orElseGet ( x :  : toString )  ;  \"  )  )  ;", "assertEquals (  \"  [  ]  \"  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    return   Optional . empty (  )  . orElseGet ( l :  : toString )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturingMethodReference"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  5  \"  ,    exec (  \" def   x    =    Integer . valueOf (  5  )  ;    def   opt    =    Optional . empty (  )  ;    return   opt . orElseGet ( x :  : toString )  ;  \"  )  )  ;", "assertEquals (  \"  [  ]  \"  ,    exec (  \" def   l    =    new   ArrayList (  )  ;    def   opt    =    Optional . empty (  )  ;    return   opt . orElseGet ( l :  : toString )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturingMethodReferenceDefEverywhere"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  5  \"  ,    exec (  \" def   x    =    Integer . valueOf (  5  )  ;    return   Optional . empty (  )  . orElseGet ( x :  : toString )  ;  \"  )  )  ;", "assertEquals (  \"  [  ]  \"  ,    exec (  \" def   l    =    new   ArrayList (  )  ;    return   Optional . empty (  )  . orElseGet ( l :  : toString )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturingMethodReferenceDefImpl"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  5  \"  ,    exec (  \" Integer   x    =    Integer . valueOf (  5  )  ;    def   opt    =    Optional . empty (  )  ;    return   opt . orElseGet ( x :  : toString )  ;  \"  )  )  ;", "assertEquals (  \"  [  ]  \"  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    def   opt    =    Optional . empty (  )  ;    return   opt . orElseGet ( l :  : toString )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturingMethodReferenceDefInterface"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" testingcdefg \"  ,    exec (  (  \" String   x    =     ' testing '  ;  \"     +     (  (  \" String   y    =     ' abcdefg '  ;  \"     +     \" FeatureTest   test    =    new   FeatureTest (  2  ,  3  )  ;  \"  )     +     \" return   test . twoFunctionsOfX ( x :  : concat ,    y :  : substring )  ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturingMethodReferenceMultipleLambdas"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" testingcdefg \"  ,    exec (  (  \" def   x    =     ' testing '  ;  \"     +     (  (  \" def   y    =     ' abcdefg '  ;  \"     +     \" def   test    =    new   FeatureTest (  2  ,  3  )  ;  \"  )     +     \" return   test . twoFunctionsOfX ( x :  : concat ,    y :  : substring )  ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturingMethodReferenceMultipleLambdasDefEverywhere"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" testingcdefg \"  ,    exec (  (  \" def   x    =     ' testing '  ;  \"     +     (  (  \" def   y    =     ' abcdefg '  ;  \"     +     \" FeatureTest   test    =    new   FeatureTest (  2  ,  3  )  ;  \"  )     +     \" return   test . twoFunctionsOfX ( x :  : concat ,    y :  : substring )  ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturingMethodReferenceMultipleLambdasDefImpls"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" testingcdefg \"  ,    exec (  (  \" String   x    =     ' testing '  ;  \"     +     (  (  \" String   y    =     ' abcdefg '  ;  \"     +     \" def   test    =    new   FeatureTest (  2  ,  3  )  ;  \"  )     +     \" return   test . twoFunctionsOfX ( x :  : concat ,    y :  : substring )  ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturingMethodReferenceMultipleLambdasDefInterface"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" List   l    =     [  2  ,     1  ]  ;    l . sort ( Bogus :  : bogus )  ;    return   l . get (  0  )  ;  \"  ,    false )  ;", "}  )  ;", "assertThat ( e . getMessage (  )  ,    endsWith (  \" Variable    [ Bogus ]    is   not   defined .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testClassMissing"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  3  .  0  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  .  0  )  ;    l . add (  2  .  0  )  ;     \"     +     (  (  (  (  \" DoubleStream   doubleStream    =    l . stream (  )  . mapToDouble ( Double :  : doubleValue )  ;  \"     +     \" DoubleSummaryStatistics   stats    =    doubleStream . collect ( DoubleSummaryStatistics :  : new ,     \"  )     +     \" DoubleSummaryStatistics :  : accept ,     \"  )     +     \" DoubleSummaryStatistics :  : combine )  ;     \"  )     +     \" return   stats . getSum (  )  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCtorMethodReference"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  3  .  0  ,    exec (  (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  .  0  )  ;    l . add (  2  .  0  )  ;     \"     +     (  (  (  (  \" def   doubleStream    =    l . stream (  )  . mapToDouble ( Double :  : doubleValue )  ;  \"     +     \" def   stats    =    doubleStream . collect ( DoubleSummaryStatistics :  : new ,     \"  )     +     \" DoubleSummaryStatistics :  : accept ,     \"  )     +     \" DoubleSummaryStatistics :  : combine )  ;     \"  )     +     \" return   stats . getSum (  )  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCtorMethodReferenceDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertArrayEquals ( new   Object [  ]  {     \" foo \"  ,     \" bar \"     }  ,     (  ( Object [  ]  )     ( exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  ' foo '  )  ;    l . add (  ' bar '  )  ;     \"     +     (  \" Stream   stream    =    l . stream (  )  . map ( StringBuilder :  : new )  ;  \"     +     \" return   stream . map ( Object :  : toString )  . toArray (  )  \"  )  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCtorWithParams"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( BootstrapMethodError . class ,     (  )     -  >     {", "exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  2  )  ;    l . add (  1  )  ;    l . sort ( String :  : startsWith )  ;    return   l . get (  0  )  ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIncompatible"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" bar \"  ,    exec (  (  \" String   f ( BiFunction   function )     {    function . apply (  ' foo '  ,     ' bar '  )     }  \"     +     \" Map   map    =    new   HashMap (  )  ;    f ( map :  : getOrDefault )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testInterfaceDefaultMethod"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" bar \"  ,    exec (  (  \" String   f ( BiFunction   function )     {    function . apply (  ' foo '  ,     ' bar '  )     }  \"     +     \" def   map    =    new   HashMap (  )  ;    f ( map :  : getOrDefault )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testInterfaceDefaultMethodDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" List   l    =     [  2  ,     1  ]  ;    l . sort ( Integer :  : bogus )  ;    return   l . get (  0  )  ;  \"  )  ;", "}  )  ;", "assertThat ( e . getMessage (  )  ,    startsWith (  \" Unknown   reference \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMethodMissing"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  2  )  ;    l . add (  1  )  ;    l . add ( Integer :  : bogus )  ;    return   l . get (  0  )  ;  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" Cannot   convert   f   reference \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNotFunctionalInterface"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  (  \" int   mycompare ( int   i ,    int   j )     {    j    -    i    }     \"     +     \" List   l    =    new   ArrayList (  )  ;    l . add (  2  )  ;    l . add (  1  )  ;    l . sort ( this :  : mycompare )  ;    return   l . get (  0  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testOwnStaticMethodReference"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  (  \" int   mycompare ( int   i ,    int   j )     {    j    -    i    }     \"     +     \" def   l    =    new   ArrayList (  )  ;    l . add (  2  )  ;    l . add (  1  )  ;    l . sort ( this :  : mycompare )  ;    return   l . get (  0  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testOwnStaticMethodReferenceDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" List   l    =     [  2  ,     1  ]  ;    l . sort ( BogusDateTime :  : bogus )  ;    return   l . get (  0  )  ;  \"  ,    false )  ;", "}  )  ;", "assertEquals (  \" invalid   sequence   of   tokens   near    [  '  :  :  '  ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testQualifiedClassMissing"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" List   l    =     [  2  ,     1  ]  ;    l . sort ( ReadableDateTime :  : bogus )  ;    return   l . get (  0  )  ;  \"  ,    false )  ;", "}  )  ;", "assertThat ( e . getMessage (  )  ,    startsWith (  \" Unknown   reference \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testQualifiedMethodMissing"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" List   l    =     [ true ]  ;    l . stream (  )  . map ( FeatureTest :  : overloadedStatic )  . findFirst (  )  . get (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testQualifiedStaticMethodReference"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   l    =     [ true ]  ;    l . stream (  )  . map ( FeatureTest :  : overloadedStatic )  . findFirst (  )  . get (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testQualifiedStaticMethodReferenceDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "long   instant    =    randomLong (  )  ;", "assertEquals ( instant ,    exec (  \" List   l    =     [ params . d ]  ;    return   l . stream (  )  . mapToLong ( ReadableDateTime :  : getMillis )  . sum (  )  \"  ,    Colles . singletonMap (  \" d \"  ,    new   DateTime ( instant ,    DateTimeZone . UTC )  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testQualifiedVirtualMethodReference"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "long   instant    =    randomLong (  )  ;", "assertEquals ( instant ,    exec (  \" def   l    =     [ params . d ]  ;    return   l . stream (  )  . mapToLong ( ReadableDateTime :  : getMillis )  . sum (  )  \"  ,    Colles . singletonMap (  \" d \"  ,    new   DateTime ( instant ,    DateTimeZone . UTC )  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testQualifiedVirtualMethodReferenceDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "Throwable   expected    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" StringBuilder   b    =    new   StringBuilder (  )  ;    List   l    =     [  1  ,     2  ]  ;    l . stream (  )  . mapToLong ( b :  : setLength )  . sum (  )  ;  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" Cannot   cast   from    [ void ]    to    [ long ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnVoid"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "Exception   expected    =    ScriptTestCase . expectScriptThrows ( LambdaConversionException . class ,     (  )     -  >     {", "exec (  \" StringBuilder   b    =    new   StringBuilder (  )  ;    def   l    =     [  1  ,     2  ]  ;    l . stream (  )  . mapToLong ( b :  : setLength )  ;  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" lambda   expects   return   type    [ long ]  ,    but   found   return   type    [ void ]  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( LambdaConversionException . class ,     (  )     -  >     {", "exec (  \" def   b    =    new   StringBuilder (  )  ;    def   l    =     [  1  ,     2  ]  ;    l . stream (  )  . mapToLong ( b :  : setLength )  ;  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" lambda   expects   return   type    [ long ]  ,    but   found   return   type    [ void ]  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( LambdaConversionException . class ,     (  )     -  >     {", "exec (  \" def   b    =    new   StringBuilder (  )  ;    List   l    =     [  1  ,     2  ]  ;    l . stream (  )  . mapToLong ( b :  : setLength )  ;  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" lambda   expects   return   type    [ long ]  ,    but   found   return   type    [ void ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnVoidDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  2  )  ;    l . add (  1  )  ;    l . sort ( Integer :  : compare )  ;    return   l . get (  0  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testStaticMethodReference"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" def   l    =    new   ArrayList (  )  ;    l . add (  2  )  ;    l . add (  1  )  ;    l . sort ( Integer :  : compare )  ;    return   l . get (  0  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testStaticMethodReferenceDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;    return   l . stream (  )  . mapToInt ( Integer :  : intValue )  . sum (  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testVirtualMethodReference"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;    return   l . stream (  )  . mapToInt ( Integer :  : intValue )  . sum (  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testVirtualMethodReferenceDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" Optional . empty (  )  . orElseGet ( String :  : startsWith )  ;  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" Unknown   reference \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongArity"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" def   y    =    Optional . empty (  )  ;    return   y . orElseGet ( String :  : startsWith )  ;  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" Unknown   reference \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongArityDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" List   l    =    new   ArrayList (  )  ;    l . add (  2  )  ;    l . add (  1  )  ;    l . sort ( String :  : isEmpty )  ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Unknown   reference \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongArityNotEnough"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" def   l    =    new   ArrayList (  )  ;    l . add (  2  )  ;    l . add (  1  )  ;    l . sort ( String :  : isEmpty )  ;  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" Unknown   reference \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongArityNotEnoughDef"], "fileName": "org.elasticsearch.painless.FunctionRefTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >    exec (  \" int   get (  )     {  5 L }    get (  )  \"  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ long ]    to    [ int ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >    exec (  \" int   get (  )     {  5  .  1 f }    get (  )  \"  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ float ]    to    [ int ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >    exec (  \" int   get (  )     {  5  .  1 d }    get (  )  \"  )  )  ;", "assertEquals (  \" Cannot   cast   from    [ double ]    to    [ int ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBadCastFromMethod"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" int   get (  )     {  5  ;  }    get (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasic"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" xyxy \"  ,    exec (  \" String   catcat ( String   single )     { single    +    single ;  }    catcat (  ' xy '  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testConcat"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "Exception   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" void   test ( int   x )     { x    =     2  ;  }    void   test ( def   y )     { y    =     3  ;  }    test (  )  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" Duplicate   fs \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDuplicates"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "Exception   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" void   test ( int   x )     {  }    test (  )  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" Cannot   generate   an   empty   f \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmpty"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "Error   expected    =    ScriptTestCase . expectScriptThrows ( PainlessError . class ,     (  )     -  >     {", "exec (  \" void   test (  )     { boolean   x    =    true ;    while    ( x )     {  }  }    test (  )  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInfiniteLoop"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" int   add ( int   x ,    int   y )     { return   x    +    y ;  }    int   x    =     1  ,    y    =     2  ;    add ( add ( x ,    x )  ,    add ( x ,    y )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiArgs"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" int   add ( int   x ,    int   y )     { return   x    +    y ;  }    int   sub ( int   x ,    int   y )     { return   x    -    y ;  }    add (  2  ,    sub (  3  ,     4  )  )  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" int   sub 2  ( int   x ,    int   y )     { sub ( x ,    y )     -    y ;  }    int   sub ( int   x ,    int   y )     { return   x    -    y ;  }    sub 2  (  5  ,     1  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiFuncs"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  5  ,    exec (  \" int   fib ( int   n )     { if    ( n    <  =     1  )    return   n ;    else   return   fib ( n -  1  )     +    fib ( n -  2  )  ;  }    fib (  1  0  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRecursion"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" void   get ( int [  ]    x )     { x [  0  ]     =     5  ;  }    int [  ]    y    =    new   int [  1  ]  ;    y [  0  ]     =     1  ;    get ( y )  ;    y [  0  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReference"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( null ,    exec (  \" void   test ( StringBuilder   b ,    int   i )     { b . setLength ( i )  }    test ( new   StringBuilder (  )  ,     1  )  \"  )  )  ;", "Excep   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentExcep . class ,     (  )     -  >     {", "exec (  \" int   test ( StringBuilder   b ,    int   i )     { b . setLength ( i )  }    test ( new   StringBuilder (  )  ,     1  )  \"  )  ;", "}  )  ;", "assertEquals (  \" Not   all   paths   provide   a   return   value   for   method    [ test ]  .  \"  ,    expected . getMessage (  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( ClassCastExcep . class ,     (  )     -  >     {", "exec (  \" int   test ( StringBuilder   b ,    int   i )     { return   b . setLength ( i )  }    test ( new   StringBuilder (  )  ,     1  )  \"  )  ;", "}  )  ;", "assertEquals (  \" Cannot   cast   from    [ void ]    to    [ int ]  .  \"  ,    expected . getMessage (  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( ClassCastExcep . class ,     (  )     -  >     {", "exec (  \" def   test ( StringBuilder   b ,    int   i )     { return   b . setLength ( i )  }    test ( new   StringBuilder (  )  ,     1  )  \"  )  ;", "}  )  ;", "assertEquals (  \" Cannot   cast   from    [ void ]    to    [ def ]  .  \"  ,    expected . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnVoid"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  5  )  )  ,    exec (  \" byte   get (  )     { Byte . valueOf (  5  )  }    get (  )  \"  )  )  ;", "assertEquals (  (  ( short )     (  5  )  )  ,    exec (  \" short   get (  )     { Byte . valueOf (  5  )  }    get (  )  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" int   get (  )     { Byte . valueOf (  5  )  }    get (  )  \"  )  )  ;", "assertEquals (  (  ( short )     (  5  )  )  ,    exec (  \" short   get (  )     { Short . valueOf (  5  )  }    get (  )  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" int   get (  )     { Integer . valueOf (  5  )  }    get (  )  \"  )  )  ;", "assertEquals (  5  .  0 F ,    exec (  \" float   get (  )     { Float . valueOf (  5  )  }    get (  )  \"  )  )  ;", "assertEquals (  5  .  0  ,    exec (  \" double   get (  )     { Float . valueOf (  5  )  }    get (  )  \"  )  )  ;", "assertEquals (  5  .  0  ,    exec (  \" double   get (  )     { Double . valueOf (  5  )  }    get (  )  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   get (  )     { Boolean . TRUE }    get (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnsAreUnboxedIfNeeded"], "fileName": "org.elasticsearch.painless.FunctionTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( constantInitializers . put ( constant . name ,    constant )  )     !  =    null )     {", "throw   new   IllegalStateException (  (  (  \" constant   initializer :     \"     +     ( constant . name )  )     +     \"    already   exists \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["addConstantInitializer"], "fileName": "org.elasticsearch.painless.Globals"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( function . synthetic )  )     {", "throw   new   IllegalStateException (  (  (  \" method :     \"     +     ( function . name )  )     +     \"    is   not   synthetic \"  )  )  ;", "}", "if    (  ( syntheticMethods . put ( function . name ,    function )  )     !  =    null )     {", "throw   new   IllegalStateException (  (  (  \" synthetic   method :     \"     +     ( function . name )  )     +     \"    already   exists \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["addSyntheticMethod"], "fileName": "org.elasticsearch.painless.Globals"}, {"methodBody": ["METHOD_START", "{", "return   constantInitializers ;", "}", "METHOD_END"], "methodName": ["getConstantInitializers"], "fileName": "org.elasticsearch.painless.Globals"}, {"methodBody": ["METHOD_START", "{", "return   statements ;", "}", "METHOD_END"], "methodName": ["getStatements"], "fileName": "org.elasticsearch.painless.Globals"}, {"methodBody": ["METHOD_START", "{", "return   syntheticMethods ;", "}", "METHOD_END"], "methodName": ["getSyntheticMethods"], "fileName": "org.elasticsearch.painless.Globals"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  0  )  )  ,    exec (  \" byte   x    =     ( byte )  0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  0  )  )  ,    exec (  \" byte   x    =     ( byte )  0  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  )  )  ,    exec (  \" byte   x    =     ( byte )  0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  1  )  )  ,    exec (  \" byte   x    =     ( byte )  0  ;    return    -  - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncrementByte"], "fileName": "org.elasticsearch.painless.IncrementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( char )     (  0  )  )  ,    exec (  \" char   x    =     ( char )  0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  )  )  ,    exec (  \" char   x    =     ( char )  1  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  )  )  ,    exec (  \" char   x    =     ( char )  0  ;    return    +  + x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncrementChar"], "fileName": "org.elasticsearch.painless.IncrementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  0  )  )  ,    exec (  \" def   x    =     ( byte )  0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  0  )  )  ,    exec (  \" def   x    =     ( byte )  0  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  )  )  ,    exec (  \" def   x    =     ( byte )  0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  1  )  )  ,    exec (  \" def   x    =     ( byte )  0  ;    return    -  - x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  0  )  )  ,    exec (  \" def   x    =     ( char )  0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  )  )  ,    exec (  \" def   x    =     ( char )  1  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  )  )  ,    exec (  \" def   x    =     ( char )  0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  0  )  )  ,    exec (  \" def   x    =     ( short )  0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  0  )  )  ,    exec (  \" def   x    =     ( short )  0  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  )  )  ,    exec (  \" def   x    =     ( short )  0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  1  )  )  ,    exec (  \" def   x    =     ( short )  0  ;    return    -  - x ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     0  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   x    =     0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     0  ;    return    -  - x ;  \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     0 L ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     0 L ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" def   x    =     0 L ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  -  1 L )  ,    exec (  \" def   x    =     0 L ;    return    -  - x ;  \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     0 F ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     0 F ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" def   x    =     0 F ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  -  1  .  0 F )  ,    exec (  \" def   x    =     0 F ;    return    -  - x ;  \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     0  .  0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     0  .  0  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" def   x    =     0  .  0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  -  1  .  0  )  ,    exec (  \" def   x    =     0  .  0  ;    return    -  - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncrementDef"], "fileName": "org.elasticsearch.painless.IncrementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     0  .  0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     0  .  0  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     0  .  0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  -  1  .  0  )  ,    exec (  \" double   x    =     0  .  0  ;    return    -  - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncrementDouble"], "fileName": "org.elasticsearch.painless.IncrementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     0 F ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     0 F ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  1  .  0 F ,    exec (  \" float   x    =     0 F ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  -  1  .  0 F )  ,    exec (  \" float   x    =     0 F ;    return    -  - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncrementFloat"], "fileName": "org.elasticsearch.painless.IncrementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    exec (  \" int   x    =     0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     0  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" int   x    =     0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" int   x    =     0  ;    return    -  - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncrementInt"], "fileName": "org.elasticsearch.painless.IncrementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0 L ,    exec (  \" long   x    =     0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     0  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  1 L ,    exec (  \" long   x    =     0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  -  1 L )  ,    exec (  \" long   x    =     0  ;    return    -  - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncrementLong"], "fileName": "org.elasticsearch.painless.IncrementTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( short )     (  0  )  )  ,    exec (  \" short   x    =     ( short )  0  ;    return   x +  +  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  0  )  )  ,    exec (  \" short   x    =     ( short )  0  ;    return   x -  -  ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  )  )  ,    exec (  \" short   x    =     ( short )  0  ;    return    +  + x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  1  )  )  ,    exec (  \" short   x    =     ( short )  0  ;    return    -  - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncrementShort"], "fileName": "org.elasticsearch.painless.IncrementTests"}, {"methodBody": ["METHOD_START", "{", "int [  ]    ints    =     (  ( int [  ]  )     ( exec (  \" new   int [  ]     {  }  \"  )  )  )  ;", "assertEquals (  0  ,    ints . length )  ;", "ints    =     (  ( int [  ]  )     ( exec (  \" new   int [  ]     {  5  ,     7  ,     -  1  ,     1  4  }  \"  )  )  )  ;", "assertEquals (  4  ,    ints . length )  ;", "assertEquals (  5  ,    ints [  0  ]  )  ;", "assertEquals (  7  ,    ints [  1  ]  )  ;", "assertEquals (  (  -  1  )  ,    ints [  2  ]  )  ;", "assertEquals (  1  4  ,    ints [  3  ]  )  ;", "ints    =     (  ( int [  ]  )     ( exec (  \" int   y    =     2  ;    int   z    =     3  ;    int [  ]    x    =    new   int [  ]     { y * z ,    y    +    z ,    y    -    z ,    y ,    z }  ;    return   x ;  \"  )  )  )  ;", "assertEquals (  5  ,    ints . length )  ;", "assertEquals (  6  ,    ints [  0  ]  )  ;", "assertEquals (  5  ,    ints [  1  ]  )  ;", "assertEquals (  (  -  1  )  ,    ints [  2  ]  )  ;", "assertEquals (  2  ,    ints [  3  ]  )  ;", "assertEquals (  3  ,    ints [  4  ]  )  ;", "Object [  ]    objects    =     (  ( Object [  ]  )     ( exec (  (  \" int   y    =     2  ;    List   z    =    new   ArrayList (  )  ;    String   s    =     ' aaa '  ;  \"     +     \" Object [  ]    x    =    new   Object [  ]     { y ,    z ,     1     +    s ,    s    +     ' aaa '  }  ;    return   x ;  \"  )  )  )  )  ;", "assertEquals (  4  ,    objects . length )  ;", "assertEquals ( new   Integer (  2  )  ,    objects [  0  ]  )  ;", "assertEquals ( new   ArrayList (  )  ,    objects [  1  ]  )  ;", "assertEquals (  \"  1 aaa \"  ,    objects [  2  ]  )  ;", "assertEquals (  \" aaaaaa \"  ,    objects [  3  ]  )  ;", "}", "METHOD_END"], "methodName": ["testArrayInitializers"], "fileName": "org.elasticsearch.painless.InitializerTests"}, {"methodBody": ["METHOD_START", "{", "Map   map    =     (  ( Map )     ( exec (  \" int   y    =     2  ;    int   z    =     3  ;    Map   x    =     [ y * z    :    y    +    z ,     ' s '     :     [ y ,     [ y    :     [  [ z ]  ,     [  ]  ,     [  :  ]  ]  ]  ]  ,    z    :     [ z ,     9  ]  ]  ;    return   x ;  \"  )  )  )  ;", "List   list 0     =    new   ArrayList (  )  ;", "list 0  . add (  3  )  ;", "List   list 1     =    new   ArrayList (  )  ;", "list 1  . add ( list 0  )  ;", "list 1  . add ( new   ArrayList (  )  )  ;", "list 1  . add ( new   HashMap (  )  )  ;", "Map   map 0     =    new   HashMap (  )  ;", "map 0  . put (  2  ,    list 1  )  ;", "List   list 2     =    new   ArrayList (  )  ;", "list 2  . add (  2  )  ;", "list 2  . add ( map 0  )  ;", "List   list 3     =    new   ArrayList (  )  ;", "list 3  . add (  3  )  ;", "list 3  . add (  9  )  ;", "assertEquals (  3  ,    map . s (  )  )  ;", "assertEquals ( new   Integer (  5  )  ,    map . get (  6  )  )  ;", "assertEquals ( list 2  ,    map . get (  \" s \"  )  )  ;", "assertEquals ( list 3  ,    map . get (  3  )  )  ;", "}", "METHOD_END"], "methodName": ["testCrazyInitializer"], "fileName": "org.elasticsearch.painless.InitializerTests"}, {"methodBody": ["METHOD_START", "{", "List   list    =     (  ( List )     ( exec (  \"  [  ]  \"  )  )  )  ;", "assertEquals (  0  ,    list . s (  )  )  ;", "list    =     (  ( List )     ( exec (  \"  [  5  ,     7  ,     -  1  ,     1  4  ]  \"  )  )  )  ;", "assertEquals (  4  ,    list . s (  )  )  ;", "assertEquals (  5  ,    list . get (  0  )  )  ;", "assertEquals (  7  ,    list . get (  1  )  )  ;", "assertEquals (  (  -  1  )  ,    list . get (  2  )  )  ;", "assertEquals (  1  4  ,    list . get (  3  )  )  ;", "list    =     (  ( List )     ( exec (  \" int   y    =     2  ;    int   z    =     3  ;    def   x    =     [ y * z ,    y    +    z ,    y    -    z ,    y ,    z ]  ;    return   x ;  \"  )  )  )  ;", "assertEquals (  5  ,    list . s (  )  )  ;", "assertEquals (  6  ,    list . get (  0  )  )  ;", "assertEquals (  5  ,    list . get (  1  )  )  ;", "assertEquals (  (  -  1  )  ,    list . get (  2  )  )  ;", "assertEquals (  2  ,    list . get (  3  )  )  ;", "assertEquals (  3  ,    list . get (  4  )  )  ;", "list    =     (  ( List )     ( exec (  \" int   y    =     2  ;    List   z    =    new   ArrayList (  )  ;    String   s    =     ' aaa '  ;    List   x    =     [ y ,    z ,     1     +    s ,    s    +     ' aaa '  ]  ;    return   x ;  \"  )  )  )  ;", "assertEquals (  4  ,    list . s (  )  )  ;", "assertEquals ( new   Integer (  2  )  ,    list . get (  0  )  )  ;", "assertEquals ( new   ArrayList (  )  ,    list . get (  1  )  )  ;", "assertEquals (  \"  1 aaa \"  ,    list . get (  2  )  )  ;", "assertEquals (  \" aaaaaa \"  ,    list . get (  3  )  )  ;", "}", "METHOD_END"], "methodName": ["testListInitializers"], "fileName": "org.elasticsearch.painless.InitializerTests"}, {"methodBody": ["METHOD_START", "{", "Map   map    =     (  ( Map )     ( exec (  \"  [  :  ]  \"  )  )  )  ;", "assertEquals (  0  ,    map . s (  )  )  ;", "map    =     (  ( Map )     ( exec (  \"  [  5     :     7  ,     -  1     :     1  4  ]  \"  )  )  )  ;", "assertEquals (  2  ,    map . s (  )  )  ;", "assertEquals ( new   Integer (  7  )  ,    map . get (  5  )  )  ;", "assertEquals ( new   Integer (  1  4  )  ,    map . get (  (  -  1  )  )  )  ;", "map    =     (  ( Map )     ( exec (  \" int   y    =     2  ;    int   z    =     3  ;    Map   x    =     [ y * z    :    y    +    z ,    y    -    z    :    y ,    z    :    z ]  ;    return   x ;  \"  )  )  )  ;", "assertEquals (  3  ,    map . s (  )  )  ;", "assertEquals ( new   Integer (  5  )  ,    map . get (  6  )  )  ;", "assertEquals ( new   Integer (  2  )  ,    map . get (  (  -  1  )  )  )  ;", "assertEquals ( new   Integer (  3  )  ,    map . get (  3  )  )  ;", "map    =     (  ( Map )     ( exec (  (  \" int   y    =     2  ;    List   z    =    new   ArrayList (  )  ;    String   s    =     ' aaa '  ;  \"     +     \" def   x    =     [ y    :    z ,     1     +    s    :    s    +     ' aaa '  ]  ;    return   x ;  \"  )  )  )  )  ;", "assertEquals (  2  ,    map . s (  )  )  ;", "assertEquals ( new   ArrayList (  )  ,    map . get (  2  )  )  ;", "assertEquals (  \" aaaaaa \"  ,    map . get (  \"  1 aaa \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMapInitializers"], "fileName": "org.elasticsearch.painless.InitializerTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  2  1  4  7  4  8  3  6  4  7     +     2  1  4  7  4  8  3  6  4  7  )  ,    exec (  \" int   x    =     2  1  4  7  4  8  3  6  4  7  ;    int   y    =     2  1  4  7  4  8  3  6  4  7  ;    return   x    +    y ;  \"  )  )  ;", "assertEquals (  (  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    +     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  ,    exec (  \" long   x    =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    long   y    =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    return   x    +    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAddition"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  2  1  4  7  4  8  3  6  4  7     +     2  1  4  7  4  8  3  6  4  7  )  ,    exec (  \" return    2  1  4  7  4  8  3  6  4  7     +     2  1  4  7  4  8  3  6  4  7  ;  \"  )  )  ;", "assertEquals (  (  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    +     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  ,    exec (  \" return    9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    +     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAdditionConst"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  0     +     1  2  8  )  )  ,    exec (  \" byte   x    =     0  ;    x    +  =     1  2  8  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  0     +     (  -  1  2  9  )  )  )  ,    exec (  \" byte   x    =     0  ;    x    +  =     -  1  2  9  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  0     +     3  2  7  6  8  )  )  ,    exec (  \" short   x    =     0  ;    x    +  =     3  2  7  6  8  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  0     +     (  -  3  2  7  6  9  )  )  )  ,    exec (  \" short   x    =     0  ;    x    +  =     -  3  2  7  6  9  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  0     +     6  5  5  3  6  )  )  ,    exec (  \" char   x    =     0  ;    x    +  =     6  5  5  3  6  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  0     +     (  -  6  5  5  3  6  )  )  )  ,    exec (  \" char   x    =     0  ;    x    +  =     -  6  5  5  3  6  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1     +     2  1  4  7  4  8  3  6  4  7  )  ,    exec (  \" int   x    =     1  ;    x    +  =     2  1  4  7  4  8  3  6  4  7  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  -  2  )     +     (  -  2  1  4  7  4  8  3  6  4  7  )  )  ,    exec (  \" int   x    =     -  2  ;    x    +  =     -  2  1  4  7  4  8  3  6  4  7  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1 L    +     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  ,    exec (  \" long   x    =     1  ;    x    +  =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  -  2 L )     +     (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  )  ,    exec (  \" long   x    =     -  2  ;    x    +  =     -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignmentAdditionOverflow"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  (  -  1  2  8  )     /     (  -  1  )  )  )  ,    exec (  \" byte   x    =     ( byte )     -  1  2  8  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  (  -  3  2  7  6  8  )     /     (  -  1  )  )  )  ,    exec (  \" short   x    =     ( short )     -  3  2  7  6  8  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  (  -  2  1  4  7  4  8  3  6  4  7  )     -     1  )     /     (  -  1  )  )  ,    exec (  \" int   x    =     -  2  1  4  7  4  8  3  6  4  7     -     1  ;    x    /  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )     -     1 L )     /     (  -  1 L )  )  ,    exec (  \" long   x    =     -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    -     1 L ;    x    /  =  -  1 L ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignmentDivisionOverflow"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  2     *     1  2  8  )  )  ,    exec (  \" byte   x    =     2  ;    x    *  =     1  2  8  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  2     *     (  -  1  2  8  )  )  )  ,    exec (  \" byte   x    =     2  ;    x    *  =     -  1  2  8  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  2     *     6  5  5  3  6  )  )  ,    exec (  \" char   x    =     2  ;    x    *  =     6  5  5  3  6  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  2     *     (  -  6  5  5  3  6  )  )  )  ,    exec (  \" char   x    =     2  ;    x    *  =     -  6  5  5  3  6  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  2     *     2  1  4  7  4  8  3  6  4  7  )  ,    exec (  \" int   x    =     2  ;    x    *  =     2  1  4  7  4  8  3  6  4  7  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  2     *     (  -  2  1  4  7  4  8  3  6  4  7  )  )  ,    exec (  \" int   x    =     2  ;    x    *  =     -  2  1  4  7  4  8  3  6  4  7  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  2 L    *     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  ,    exec (  \" long   x    =     2  ;    x    *  =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    return   x ;  \"  )  )  ;", "assertEquals (  (  2 L    *     (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  )  ,    exec (  \" long   x    =     2  ;    x    *  =     -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignmentMultiplicationOverflow"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  0     -     (  -  1  2  8  )  )  )  ,    exec (  \" byte   x    =     0  ;    x    -  =     -  1  2  8  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  0     -     1  2  9  )  )  ,    exec (  \" byte   x    =     0  ;    x    -  =     1  2  9  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  0     -     (  -  3  2  7  6  8  )  )  )  ,    exec (  \" short   x    =     0  ;    x    -  =     -  3  2  7  6  8  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  0     -     3  2  7  6  9  )  )  ,    exec (  \" short   x    =     0  ;    x    -  =     3  2  7  6  9  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  0     -     (  -  6  5  5  3  6  )  )  )  ,    exec (  \" char   x    =     0  ;    x    -  =     -  6  5  5  3  6  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  0     -     6  5  5  3  6  )  )  ,    exec (  \" char   x    =     0  ;    x    -  =     6  5  5  3  6  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1     -     (  -  2  1  4  7  4  8  3  6  4  7  )  )  ,    exec (  \" int   x    =     1  ;    x    -  =     -  2  1  4  7  4  8  3  6  4  7  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  -  2  )     -     2  1  4  7  4  8  3  6  4  7  )  ,    exec (  \" int   x    =     -  2  ;    x    -  =     2  1  4  7  4  8  3  6  4  7  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1 L    -     (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  )  ,    exec (  \" long   x    =     1  ;    x    -  =     -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  -  2 L )     -     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  ,    exec (  \" long   x    =     -  2  ;    x    -  =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignmentSubtractionOverflow"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  (  -  2  1  4  7  4  8  3  6  4  7  )     -     1  )     /     (  -  1  )  )  ,    exec (  \" int   x    =     -  2  1  4  7  4  8  3  6  4  8  ;    int   y    =     -  1  ;    return   x    /    y ;  \"  )  )  ;", "assertEquals (  (  (  (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )     -     1 L )     /     (  -  1 L )  )  ,    exec (  \" long   x    =     -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8 L ;    long   y    =     -  1 L ;    return   x    /    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDivision"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  (  -  2  1  4  7  4  8  3  6  4  7  )     -     1  )     /     (  -  1  )  )  ,    exec (  \" return    (  -  2  1  4  7  4  8  3  6  4  8  )     /     -  1  ;  \"  )  )  ;", "assertEquals (  (  (  (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )     -     1 L )     /     (  -  1 L )  )  ,    exec (  \" return    (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8 L )     /     -  1 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDivisionConst"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  2  8  )  )  ,    exec (  \" byte   x    =     1  2  7  ;     +  + x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  2  8  )  )  ,    exec (  \" byte   x    =     1  2  7  ;    x +  +  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  1  2  9  )  )  ,    exec (  \" byte   x    =     ( byte )     -  1  2  8  ;     -  - x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  1  2  9  )  )  ,    exec (  \" byte   x    =     ( byte )     -  1  2  8  ;    x -  -  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  3  2  7  6  8  )  )  ,    exec (  \" short   x    =     3  2  7  6  7  ;     +  + x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  3  2  7  6  8  )  )  ,    exec (  \" short   x    =     3  2  7  6  7  ;    x +  +  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  3  2  7  6  9  )  )  ,    exec (  \" short   x    =     ( short )     -  3  2  7  6  8  ;     -  - x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  3  2  7  6  9  )  )  ,    exec (  \" short   x    =     ( short )     -  3  2  7  6  8  ;    x -  -  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  6  5  5  3  6  )  )  ,    exec (  \" char   x    =     6  5  5  3  5  ;     +  + x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  6  5  5  3  6  )  )  ,    exec (  \" char   x    =     6  5  5  3  5  ;    x +  +  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  -  1  )  )  ,    exec (  \" char   x    =     ( char )     0  ;     -  - x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  -  1  )  )  ,    exec (  \" char   x    =     ( char )     0  ;    x -  -  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  2  1  4  7  4  8  3  6  4  7     +     1  )  ,    exec (  \" int   x    =     2  1  4  7  4  8  3  6  4  7  ;     +  + x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  2  1  4  7  4  8  3  6  4  7     +     1  )  ,    exec (  \" int   x    =     2  1  4  7  4  8  3  6  4  7  ;    x +  +  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  2  1  4  7  4  8  3  6  4  8     -     1  )  ,    exec (  \" int   x    =     ( int )     -  2  1  4  7  4  8  3  6  4  8 L ;     -  - x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  2  1  4  7  4  8  3  6  4  8     -     1  )  ,    exec (  \" int   x    =     ( int )     -  2  1  4  7  4  8  3  6  4  8 L ;    x -  -  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    +     1 L )  ,    exec (  \" long   x    =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;     +  + x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    +     1 L )  ,    exec (  \" long   x    =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    x +  +  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )     -     1 L )     -     1 L )  ,    exec (  \" long   x    =     -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    -     1 L ;     -  - x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )     -     1 L )     -     1 L )  ,    exec (  \" long   x    =     -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    -     1 L ;    x -  -  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIncrementOverFlow"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  2  1  4  7  4  8  3  6  4  7     *     2  1  4  7  4  8  3  6  4  7  )  ,    exec (  \" int   x    =     2  1  4  7  4  8  3  6  4  7  ;    int   y    =     2  1  4  7  4  8  3  6  4  7  ;    return   x    *    y ;  \"  )  )  ;", "assertEquals (  (  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    *     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  ,    exec (  \" long   x    =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    long   y    =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    return   x    *    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiplication"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  2  1  4  7  4  8  3  6  4  7     *     2  1  4  7  4  8  3  6  4  7  )  ,    exec (  \" return    2  1  4  7  4  8  3  6  4  7     *     2  1  4  7  4  8  3  6  4  7  ;  \"  )  )  ;", "assertEquals (  (  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    *     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  ,    exec (  \" return    9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L    *     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiplicationConst"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  -  (  (  -  2  1  4  7  4  8  3  6  4  7  )     -     1  )  )  ,    exec (  \" int   x    =     -  2  1  4  7  4  8  3  6  4  8  ;    x    =     - x ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  (  (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )     -     1 L )  )  ,    exec (  \" long   x    =     -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8 L ;    x    =     - x ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNegationOverflow"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  -  (  (  -  2  1  4  7  4  8  3  6  4  7  )     -     1  )  )  ,    exec (  \" int   x    =     -  (  -  2  1  4  7  4  8  3  6  4  8  )  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  (  (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )     -     1 L )  )  ,    exec (  \" long   x    =     -  (  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  8 L )  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNegationOverflowConst"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  -  1  0  )     -     2  1  4  7  4  8  3  6  4  7  )  ,    exec (  \" int   x    =     -  1  0  ;    int   y    =     2  1  4  7  4  8  3  6  4  7  ;    return   x    -    y ;  \"  )  )  ;", "assertEquals (  (  (  -  1  0 L )     -     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  ,    exec (  \" long   x    =     -  1  0 L ;    long   y    =     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;    return   x    -    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSubtraction"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  -  1  0  )     -     2  1  4  7  4  8  3  6  4  7  )  ,    exec (  \" return    -  1  0     -     2  1  4  7  4  8  3  6  4  7  ;  \"  )  )  ;", "assertEquals (  (  (  -  1  0 L )     -     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L )  ,    exec (  \" return    -  1  0 L    -     9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSubtractionConst"], "fileName": "org.elasticsearch.painless.IntegerOverflowTests"}, {"methodBody": ["METHOD_START", "{", "String   baseClass    =    Type . getInternalName ( Object . class )  ;", "int   modifiers    =     (  (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ SUPER )  )     |     ( Opcodes . ACC _ FINAL )  )     |     ( Opcodes . ACC _ SYNTHETIC )  ;", "ClassWriter   cw    =    new   ClassWriter ( ClassWriter . COMPUTE _ MAXS )  ;", "cw . visit ( WriterConstants . CLASS _ VERSION ,    modifiers ,    lClassName ,    null ,    baseClass ,    new   String [  ]  {    Type . getInternalName ( lInterface )     }  )  ;", "return   cw ;", "}", "METHOD_END"], "methodName": ["beginLambdaClass"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   new   ConstantCallSite ( lookup . findStatic ( lambdaClass ,     . LAMBDA _ FACTORY _ METHOD _ NAME ,    factoryMethodType )  )  ;", "}    catch    ( ReflectiveOperationException   exception )     {", "throw   new   IllegalStateException (  \" unable   to   create   lambda   class \"  ,    exception )  ;", "}", "}", "METHOD_END"], "methodName": ["createCaptureCallSite"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "byte [  ]    classBytes    =    cw . toByteArray (  )  ;", "return   AccessController . doPrivileged (  (  ( PrivilegedAction < Class <  ?  >  >  )     (  (  )     -  >    loader . define ( lambdaClassType . getClassName (  )  ,    classBytes )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["createLambdaClass"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   new   ConstantCallSite ( MethodHandles . constant ( factoryMethodType . returnType (  )  ,    lClass . getConstructor (  )  . newInstance (  )  )  )  ;", "}    catch    ( ReflectiveOperationException   exception )     {", "throw   new   IllegalStateException (  \" unable   to   instantiate   l   class \"  ,    exception )  ;", "}", "}", "METHOD_END"], "methodName": ["createNoCaptureCallSite"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "return   new   ConstantCallSite ( delegateMethodHandle . asType ( interfaceMethodType )  )  ;", "}", "METHOD_END"], "methodName": ["delegateBootstrap"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "cw . visitEnd (  )  ;", "}", "METHOD_END"], "methodName": ["endLambdaClass"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "int   captureTotal    =    factoryMethodType . parameterCount (  )  ;", ". Capture [  ]    captures    =    new    . Capture [ captureTotal ]  ;", "for    ( int   captureCount    =     0  ;    captureCount    <    captureTotal ;     +  + captureCount )     {", "captures [ captureCount ]     =    new    . Capture ( captureCount ,    factoryMethodType . parameterType ( captureCount )  )  ;", "int   modifiers    =     ( Opcodes . ACC _ PRIVATE )     |     ( Opcodes . ACC _ FINAL )  ;", "FieldVisitor   fv    =    cw . visitField ( modifiers ,    captures [ captureCount ]  . name ,    captures [ captureCount ]  . desc ,    null ,    null )  ;", "fv . visitEnd (  )  ;", "}", "return   captures ;", "}", "METHOD_END"], "methodName": ["generateCaptureFields"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "String   lamDesc    =    interfaceMethodType . toMethodDescriptorString (  )  ;", "Method   lamMeth    =    new   Method ( lambdaClassType . getInternalName (  )  ,    lamDesc )  ;", "int   modifiers    =    Opcodes . ACC _ PUBLIC ;", "GeneratorAdapter   iface    =    new   GeneratorAdapter ( modifiers ,    lamMeth ,    cw . visitMethod ( modifiers ,    interfaceMethodName ,    lamDesc ,    null ,    null )  )  ;", "iface . visitCode (  )  ;", "for    ( int   captureCount    =     0  ;    captureCount    <     ( captures . length )  ;     +  + captureCount )     {", "iface . loadThis (  )  ;", "iface . getField ( lambdaClassType ,    captures [ captureCount ]  . name ,    captures [ captureCount ]  . type )  ;", "}", "iface . loadArgs (  )  ;", "if    ( delegateInvokeType    =  =     ( Opcodes . H _ INVOKESTATIC )  )     {", "interfaceMethodType    =    interfaceMethodType . insertParameterTypes (  0  ,    factoryMethodType . parameterArray (  )  )  ;", "delegateMethodType    =    delegateMethodType . insertParameterTypes (  0  ,    factoryMethodType . parameterArray (  )  )  ;", "} else", "if    (  ( delegateInvokeType    =  =     ( Opcodes . H _ INVOKEVIRTUAL )  )     |  |     ( delegateInvokeType    =  =     ( Opcodes . H _ INVOKEINTERFACE )  )  )     {", "if    (  ( captures . length )     =  =     0  )     {", "Class <  ?  >    clazz    =    delegateMethodType . parameterType (  0  )  ;", "delegateClassType    =    Type . getType ( clazz )  ;", "delegateMethodType    =    delegateMethodType . dropParameterTypes (  0  ,     1  )  ;", "} else", "if    (  ( captures . length )     =  =     1  )     {", "Class <  ?  >    clazz    =    factoryMethodType . parameterType (  0  )  ;", "delegateClassType    =    Type . getType ( clazz )  ;", "interfaceMethodType    =    interfaceMethodType . insertParameterTypes (  0  ,    clazz )  ;", "} else    {", "throw   new   invokeConversionException (  (  (  \" unexpected   number   of   captures    [     \"     +     ( captures . length )  )     +     \"  ]  \"  )  )  ;", "}", "} else    {", "throw   new   IllegalStateException (  (  (  \" unexpected   invocation   type    [  \"     +    delegateInvokeType )     +     \"  ]  \"  )  )  ;", "}", "Handle   delegateHandle    =    new   Handle ( delegateInvokeType ,    delegateClassType . getInternalName (  )  ,    delegateMethodName ,    delegateMethodType . toMethodDescriptorString (  )  ,     ( delegateInvokeType    =  =     ( Opcodes . H _ INVOKEINTERFACE )  )  )  ;", "iface . invokeDynamic ( delegateMethodName ,    Type . getMethodType ( interfaceMethodType . toMethodDescriptorString (  )  )  . getDescriptor (  )  ,    WriterConstants . DELEGATE _ BOOTSTRAP _ HANDLE ,    delegateHandle )  ;", "iface . returnValue (  )  ;", "iface . endMethod (  )  ;", "}", "METHOD_END"], "methodName": ["generateInterfaceMethod"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "String   conDesc    =    factoryMethodType . changeReturnType ( void . class )  . toMethodDescriptorString (  )  ;", "Method   conMeth    =    new   Method ( WriterConstants . CTOR _ METHOD _ NAME ,    conDesc )  ;", "Type   baseConType    =    Type . getType ( Object . class )  ;", "Method   baseConMeth    =    new   Method ( WriterConstants . CTOR _ METHOD _ NAME ,    MethodType . methodType ( void . class )  . toMethodDescriptorString (  )  )  ;", "int   modifiers    =     (  ( captures . length )     >     0  )     ?    Opcodes . ACC _ PRIVATE    :    Opcodes . ACC _ PUBLIC ;", "GeneratorAdapter   constructor    =    new   GeneratorAdapter ( modifiers ,    conMeth ,    cw . visitMethod ( modifiers ,    WriterConstants . CTOR _ METHOD _ NAME ,    conDesc ,    null ,    null )  )  ;", "constructor . visitCode (  )  ;", "constructor . loadThis (  )  ;", "constructor . invokeConstructor ( baseConType ,    baseConMeth )  ;", "for    ( int   captureCount    =     0  ;    captureCount    <     ( captures . length )  ;     +  + captureCount )     {", "constructor . loadThis (  )  ;", "constructor . loadArg ( captureCount )  ;", "constructor . putField ( lambdaClassType ,    captures [ captureCount ]  . name ,    captures [ captureCount ]  . type )  ;", "}", "constructor . returnValue (  )  ;", "constructor . endMethod (  )  ;", "if    (  ( captures . length )     >     0  )     {", ". generateStaticCtorDelegator ( cw ,    Opcodes . ACC _ PUBLIC ,     . LAMBDA _ FACTORY _ METHOD _ NAME ,    lambdaClassType ,    factoryMethodType )  ;", "}", "}", "METHOD_END"], "methodName": ["generateLambdaConstructor"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "Method   wrapperMethod    =    new   Method ( delegatorMethodName ,    delegateMethodType . toMethodDescriptorString (  )  )  ;", "Method   constructorMethod    =    new   Method ( WriterConstants . CTOR _ METHOD _ NAME ,    delegateMethodType . changeReturnType ( void . class )  . toMethodDescriptorString (  )  )  ;", "int   modifiers    =    access    |     ( Opcodes . ACC _ STATIC )  ;", "GeneratorAdapter   factory    =    new   GeneratorAdapter ( modifiers ,    wrapperMethod ,    cw . visitMethod ( modifiers ,    delegatorMethodName ,    delegateMethodType . toMethodDescriptorString (  )  ,    null ,    null )  )  ;", "factory . visitCode (  )  ;", "factory . newInstance ( delegateClassType )  ;", "factory . dup (  )  ;", "factory . loadArgs (  )  ;", "factory . invokeConstructor ( delegateClassType ,    constructorMethod )  ;", "factory . returnValue (  )  ;", "factory . endMethod (  )  ;", "}", "METHOD_END"], "methodName": ["generateStaticCtorDelegator"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "Compiler . Loader   loader    =     (  ( Compiler . Loader )     ( lookup . lookupClass (  )  . getClassLoader (  )  )  )  ;", "String   lambdaClassName    =     (  ( Type . getInternalName ( lookup . lookupClass (  )  )  )     +     \"  $  $ Lambda \"  )     +     ( loader . newLambdaIdentifier (  )  )  ;", "Type   lambdaClassType    =    Type . getObjectType ( lambdaClassName )  ;", "Type   delegateClassType    =    Type . getObjectType ( delegateClassName . replace (  '  .  '  ,     '  /  '  )  )  ;", ". validateTypes ( interfaceMethodType ,    delegateMethodType )  ;", "ClassWriter   cw    =     . beginLambdaClass ( lambdaClassName ,    factoryMethodType . returnType (  )  )  ;", ". Capture [  ]    captures    =     . generateCaptureFields ( cw ,    factoryMethodType )  ;", ". generateLambdaConstructor ( cw ,    lambdaClassType ,    factoryMethodType ,    captures )  ;", "if    ( delegateInvokeType    =  =     ( Opcodes . H _ NEWINVOKESPECIAL )  )     {", "assert   WriterConstants . CTOR _ METHOD _ NAME . equals ( delegateMethodName )  ;", ". generateStaticCtorDelegator ( cw ,    Opcodes . ACC _ PRIVATE ,     . DELEGATED _ CTOR _ WRAPPER _ NAME ,    delegateClassType ,    delegateMethodType )  ;", "delegateMethodName    =     . DELEGATED _ CTOR _ WRAPPER _ NAME ;", "delegateClassType    =    lambdaClassType ;", "delegateInvokeType    =    Opcodes . H _ INVOKESTATIC ;", "}", ". generateInterfaceMethod ( cw ,    factoryMethodType ,    lambdaClassType ,    interfaceMethodName ,    interfaceMethodType ,    delegateClassType ,    delegateInvokeType ,    delegateMethodName ,    delegateMethodType ,    captures )  ;", ". endLambdaClass ( cw )  ;", "Class <  ?  >    lambdaClass    =     . createLambdaClass ( loader ,    cw ,    lambdaClassType )  ;", "if    (  ( captures . length )     >     0  )     {", "return    . createCaptureCallSite ( lookup ,    factoryMethodType ,    lambdaClass )  ;", "} else    {", "return    . createNoCaptureCallSite ( factoryMethodType ,    lambdaClass )  ;", "}", "}", "METHOD_END"], "methodName": ["lambdaBootstrap"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( interfaceMethodType . returnType (  )  )     !  =     ( void . class )  )     &  &     (  ( delegateMethodType . returnType (  )  )     =  =     ( void . class )  )  )     {", "throw   new   ConversionException (  (  (  \" lambda   expects   return   type    [  \"     +     ( interfaceMethodType . returnType (  )  )  )     +     \"  ]  ,    but   found   return   type    [ void ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["validateTypes"], "fileName": "org.elasticsearch.painless.LambdaBootstrap"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" int   x    =     5  ;    return   Optional . empty (  )  . orElseGet (  (  )     -  >    x )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapture"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" int   x    =     5  ;    def   y    =    Optional . empty (  )  ;    y . orElseGet (  (  )     -  >    x )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCaptureDef"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt ( x    -  >     {    l    =    null ;    return   x    +     1     }  )  . sum (  )  ;  \"  )  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" is   read - only \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCapturesAreReadOnly"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" def   foo ( int   x )     {    Optional . empty (  )  . orElseGet (  (  )     -  >    x )     }    return   foo (  5  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLambdaCaptureFunctionParam"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" def   foo (  )     {    Optional . empty (  )  . orElseGet (  (  )     -  >     5  )     }    return   foo (  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLambdaInFunction"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  0  0  ,    exec (  (  \" int   sum    =     0  ;     \"     +     (  (  (  \" for    ( int   i    =     0  ;    i    <     1  0  0  ;    i +  +  )     {  \"     +     \"       sum    +  =    Optional . empty (  )  . orElseGet (  (  )     -  >     1  )  ;  \"  )     +     \"  }  \"  )     +     \" return   sum ;  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testLambdaInLoop"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" short \"  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  ' looooong '  )  ;    l . add (  ' short '  )  ;     \"     +     \" l . sort (  ( a ,    b )     -  >    a . length (  )     -    b . length (  )  )  ;    return   l . get (  0  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testLambdaWithArgs"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" short \"  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  ' looooong '  )  ;    l . add (  ' short '  )  ;     \"     +     \" l . sort (  ( String   a ,    String   b )     -  >    a . length (  )     -    b . length (  )  )  ;    return   l . get (  0  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testLambdaWithTypedArgs"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" int   applyOne ( IntFunction   arg )     {    arg . apply (  1  )     }    applyOne ( x    -  >     {    def   y    =    x    +     1  ;    return   y    }  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultipleStatements"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  (  \" boolean   x    =    false ;    int   y    =     1  ;  \"     +     \" return   Optional . empty (  )  . orElseGet (  (  )     -  >    x    ?     5     :    Optional . empty (  )  . orElseGet (  (  )     -  >    y )  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNestedCapture"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  (  \" int   foo ( Function   f )     {    return   f . apply (  1  )     }  \"     +     \" return   foo ( x    -  >    foo ( y    -  >    x    +     1  )  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNestedCaptureParams"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" Optional . empty (  )  . orElseGet (  (  )     -  >    Optional . empty (  )  . orElseGet (  (  )     -  >     1  )  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNestedLambdas"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" Optional . empty (  )  . orElseGet (  (  )     -  >     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoArgLambda"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  \" def   x    =    Optional . empty (  )  ;    x . orElseGet (  (  )     -  >     1  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoArgLambdaDef"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  (  \" int   x    =     0  ;    List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt ( x    -  >     {    x    +  =     1  ;    return   x    }  )  . sum (  )  ;  \"  )  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" already   defined \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoParamMasking"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt ( x    -  >     {    x    +  =     1  ;    return   x    }  )  . sum (  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testOnlyCapturesAreReadOnly"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" int   applyOne ( IntFunction   arg )     {    arg . apply (  1  )     }    applyOne ( x    -  >    x    +     1  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveArgs"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" int   applyOne ( IntFunction   arg )     {    arg . apply (  1  )     }    applyOne ( int   x    -  >    x    +     1  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveArgsTyped"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2 L ,    exec (  \" long   applyOne ( IntFunction   arg )     {    arg . apply (  1  )     }    applyOne ( long   x    -  >    x    +     1  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveArgsTypedOddly"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt ( x    -  >    x    +     1  )  . sum (  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveLambdas"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  ( short )  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt ( long   x    -  >     ( int )  1  )  . sum (  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveLambdasConvertible"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt ( x    -  >    x    +     1  )  . sum (  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveLambdasDef"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt ( int   x    -  >    x    +     1  )  . sum (  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveLambdasWithTypedArgs"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt ( int   x    -  >    x    +     1  )  . sum (  )  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveLambdasWithTypedArgsDef"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "String   compare    =     \" boolean   compare ( Supplier   s ,    def   v )     { s . get (  )     =  =    v }  \"  ;", "assertEquals ( true ,    exec (  ( compare    +     \" compare (  (  )     -  >    new   ArrayList (  )  ,    new   ArrayList (  )  )  \"  )  )  )  ;", "assertEquals ( true ,    exec (  ( compare    +     \" compare (  (  )     -  >     {    new   ArrayList (  )     }  ,    new   ArrayList (  )  )  \"  )  )  )  ;", "Map < String ,    Object >    params    =    new   HashMap <  >  (  )  ;", "params . put (  \" key \"  ,     \" value \"  )  ;", "params . put (  \" number \"  ,     2  )  ;", "assertEquals ( true ,    exec (  ( compare    +     \" compare (  (  )     -  >     {    return   params [  ' key '  ]     }  ,     ' value '  )  \"  )  ,    params ,    true )  )  ;", "assertEquals ( false ,    exec (  ( compare    +     \" compare (  (  )     -  >     {    return   params [  ' nokey '  ]     }  ,     ' value '  )  \"  )  ,    params ,    true )  )  ;", "assertEquals ( true ,    exec (  ( compare    +     \" compare (  (  )     -  >     {    return   params [  ' nokey '  ]     }  ,    null )  \"  )  ,    params ,    true )  )  ;", "assertEquals ( true ,    exec (  ( compare    +     \" compare (  (  )     -  >     {    return   params [  ' number '  ]     }  ,     2  )  \"  )  ,    params ,    true )  )  ;", "assertEquals ( false ,    exec (  ( compare    +     \" compare (  (  )     -  >     {    return   params [  ' number '  ]     }  ,     ' value '  )  \"  )  ,    params ,    true )  )  ;", "assertEquals ( false ,    exec (  (  ( compare    +     \" compare (  (  )     -  >     {    if    ( params [  ' number '  ]     =  =     2  )     {    return   params [  ' number '  ]     }  \"  )     +     \" else    {    return   params [  ' key '  ]     }     }  ,     ' value '  )  \"  )  ,    params ,    true )  )  ;", "assertEquals ( true ,    exec (  (  ( compare    +     \" compare (  (  )     -  >     {    if    ( params [  ' number '  ]     =  =     2  )     {    return   params [  ' number '  ]     }  \"  )     +     \" else    {    return   params [  ' key '  ]     }     }  ,     2  )  \"  )  ,    params ,    true )  )  ;", "assertEquals ( true ,    exec (  (  ( compare    +     \" compare (  (  )     -  >     {    if    ( params [  ' number '  ]     =  =     1  )     {    return   params [  ' number '  ]     }  \"  )     +     \" else    {    return   params [  ' key '  ]     }     }  ,     ' value '  )  \"  )  ,    params ,    true )  )  ;", "assertEquals ( false ,    exec (  (  ( compare    +     \" compare (  (  )     -  >     {    if    ( params [  ' number '  ]     =  =     1  )     {    return   params [  ' number '  ]     }  \"  )     +     \" else    {    return   params [  ' key '  ]     }     }  ,     2  )  \"  )  ,    params ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testReservedCapture"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "Throwable   expected    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" StringBuilder   b    =    new   StringBuilder (  )  ;    List   l    =     [  1  ,     2  ]  ;    l . stream (  )  . mapToLong ( i    -  >    b . setLength ( i )  )  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" Cannot   cast   from    [ void ]    to    [ long ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnVoid"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "Exception   expected    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" StringBuilder   b    =    new   StringBuilder (  )  ;    def   l    =     [  1  ,     2  ]  ;    l . stream (  )  . mapToLong ( i    -  >    b . setLength ( i )  )  \"  )  ;", "}  )  ;", "assertThat ( expected . getMessage (  )  ,    containsString (  \" Cannot   cast   from    [ void ]    to    [ def ]  .  \"  )  )  ;", "assertEquals ( Arrays . asList ( null ,    null )  ,    exec (  \" def   b    =    new   StringBuilder (  )  ;    def   l    =     [  1  ,     2  ]  ;    l . stream (  )  . map ( i    -  >    b . setLength ( i )  )  . collect ( Collectors . toList (  )  )  \"  )  )  ;", "assertEquals ( Arrays . asList ( null ,    null )  ,    exec (  \" def   b    =    new   StringBuilder (  )  ;    List   l    =     [  1  ,     2  ]  ;    l . stream (  )  . map ( i    -  >    b . setLength ( i )  )  . collect ( Collectors . toList (  )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnVoidDef"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  1 test \"  ,    exec (  \" int   x    =     1  ;    String   y    =     ' test '  ;    return   Optional . empty (  )  . orElseGet (  (  )     -  >    x    +    y )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testTwoCaptures"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" testingcdefg \"  ,    exec (  (  \" FeatureTest   test    =    new   FeatureTest (  2  ,  3  )  ;  \"     +     \" return   test . twoFunctionsOfX ( x    -  >     ' testing '  . concat ( x )  ,    y    -  >     ' abcdefg '  . substring ( y )  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testTwoLambdas"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" int   applyOne ( IntFunction   arg )     {    arg . apply (  1  )     }    applyOne ( x    -  >     {    x    +     1     }  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnneededCurlyStatements"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  (  \" List   list    =    new   ArrayList (  )  ;     \"     +     (  (  (  \" list . add (  2  )  ;     \"     +     \" List   list 2     =    new   ArrayList (  )  ;     \"  )     +     \" list . forEach ( x    -  >    list 2  . add ( x )  )  ;  \"  )     +     \" return   list [  0  ]  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testVoidReturn"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  (  \" def   list    =    new   ArrayList (  )  ;     \"     +     (  (  (  \" list . add (  2  )  ;     \"     +     \" List   list 2     =    new   ArrayList (  )  ;     \"  )     +     \" list . forEach ( x    -  >    list 2  . add ( x )  )  ;  \"  )     +     \" return   list [  0  ]  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testVoidReturnDef"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >     {", "exec (  \" Optional . empty (  )  . orElseGet ( x    -  >    x )  ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Incorrect   number   of   parameters \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongArity"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" def   y    =    Optional . empty (  )  ;    return   y . orElseGet ( x    -  >    x )  ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  ,    expected . getMessage (  )  . contains (  \" Incorrect   number   of   parameters \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongArityDef"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >     {", "exec (  (  \" List   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt (  (  )     -  >     5  )  . sum (  )  ;  \"  )  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Incorrect   number   of   parameters \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongArityNotEnough"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  (  \" def   l    =    new   ArrayList (  )  ;    l . add (  1  )  ;    l . add (  1  )  ;     \"     +     \" return   l . stream (  )  . mapToInt (  (  )     -  >     5  )  . sum (  )  ;  \"  )  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Incorrect   number   of   parameters \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testWrongArityNotEnoughDef"], "fileName": "org.elasticsearch.painless.LambdaTests"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.painless.LangPainlessClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "switch    ( valueType )     {", "case    \" int \"     :", "return    \"  0  \"  ;", "case    \" long \"     :", "return    \"  0 L \"  ;", "case    \" short \"     :", "return    \"  ( short )     0  \"  ;", "case    \" byte \"     :", "return    \"  ( byte )     0  \"  ;", "case    \" float \"     :", "return    \"  0  .  0 f \"  ;", "case    \" double \"     :", "return    \"  0  .  0  \"  ;", "default    :", "return   null ;", "}", "}", "METHOD_END"], "methodName": ["fillValue"], "fileName": "org.elasticsearch.painless.ListTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( methods )     =  =    null )     {", "methods    =    new   HhMap <  >  (  )  ;", "}", "methods . put ( new   Definition . MethodKey ( method . name ,    method . arguments . size (  )  )  ,    method )  ;", "}", "METHOD_END"], "methodName": ["addMethod"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "if    ( hasVariable ( name )  )     {", "throw   ltion . createError ( new   IllegalArgumentException (  (  (  \" Variable    [  \"     +    name )     +     \"  ]    is   already   defined .  \"  )  )  )  ;", "}", "if    ( keywords . contains ( name )  )     {", "throw   ltion . createError ( new   IllegalArgumentException (  (  (  \" Variable    [  \"     +    name )     +     \"  ]    is   reserved .  \"  )  )  )  ;", "}", "return   defineVariable ( ltion ,    clazz ,    name ,    readonly )  ;", "}", "METHOD_END"], "methodName": ["addVariable"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "if    (  ( variables )     =  =    null )     {", "variables    =    new   HashMap <  >  (  )  ;", "}", ". Variable   variable    =    new    . Variable ( location ,    name ,    type ,    getNextSlot (  )  ,    readonly )  ;", "variables . put ( name ,    variable )  ;", "nextSlotNumber    +  =    MethodWriter . getType ( type )  . getSize (  )  ;", "return   variable ;", "}", "METHOD_END"], "methodName": ["defineVariable"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "return   definition ;", "}", "METHOD_END"], "methodName": ["getDefinition"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "Definition . Method   method    =    lookupMethod ( key )  ;", "if    ( method    !  =    null )     {", "return   method ;", "}", "if    (  ( parent )     !  =    null )     {", "return   parent . getMethod ( key )  ;", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["getMethod"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "return   nextSlotNumber ;", "}", "METHOD_END"], "methodName": ["getNextSlot"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "return   parent ;", "}", "METHOD_END"], "methodName": ["getParent"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "Locals   locals    =    this ;", "while    (  ( locals . getParent (  )  )     !  =    null )     {", "locals    =    locals . getParent (  )  ;", "}", "return   locals ;", "}", "METHOD_END"], "methodName": ["getProgramScope"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "return   returnType ;", "}", "METHOD_END"], "methodName": ["getReturnType"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "Locals . Variable   variable    =    lookupVariable ( location ,    name )  ;", "if    ( variable    !  =    null )     {", "return   variable ;", "}", "if    (  ( parent )     !  =    null )     {", "return   parent . getVariable ( location ,    name )  ;", "}", "throw   location . createError ( new   IllegalArgumentException (  (  (  \" Variable    [  \"     +    name )     +     \"  ]    is   not   defined .  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["getVariable"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "Locals . Variable   variable    =    lookupVariable ( null ,    name )  ;", "if    ( variable    !  =    null )     {", "return   true ;", "}", "if    (  ( parent )     !  =    null )     {", "return   parent . hasVariable ( name )  ;", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["hasVariable"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "if    (  ( method    =  =    null )     {", "return   null ;", "}", "return   methodget ( key )  ;", "}", "METHOD_END"], "methodName": ["lookupMethod"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "if    (  ( variables )     =  =    null )     {", "return   null ;", "}", "return   variables . get ( name )  ;", "}", "METHOD_END"], "methodName": ["lookupVariable"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "Locals   locals    =    new   Locals ( programScope ,    programScope . definition ,    returnType ,    Locals . KEYWORDS )  ;", "for    ( Locals . Parameter   parameter    :    parameters )     {", "locals . addVariable ( parameter . location ,    parameter . clazz ,    parameter . name ,    false )  ;", "}", "if    ( maxLoopCounter    >     0  )     {", "locals . defineVariable ( null ,    int . class ,    Locals . LOOP ,    true )  ;", "}", "return   locals ;", "}", "METHOD_END"], "methodName": ["newFunctionScope"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "Locals   locals    =    new   Locals ( programScope ,    programScope . definition ,    returnType ,    Locals . KEYWORDS )  ;", "for    ( int   i    =     0  ;    i    <     ( parameters . size (  )  )  ;    i +  +  )     {", "Locals . Parameter   parameter    =    parameters . get ( i )  ;", "boolean   isCapture    =    true ;", "locals . addVariable ( parameter . location ,    parameter . clazz ,    parameter . name ,    isCapture )  ;", "}", "if    ( maxLoopCounter    >     0  )     {", "locals . defineVariable ( null ,    int . class ,    Locals . LOOP ,    true )  ;", "}", "return   locals ;", "}", "METHOD_END"], "methodName": ["newLambdaScope"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "return   new   Locals ( currentScope )  ;", "}", "METHOD_END"], "methodName": ["newLocalScope"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "Locals   locals    =    new   Locals ( programScope ,    programScope . definition ,    scriptClassInfo . getExecuteMethodReturnType (  )  ,    Locals . KEYWORDS )  ;", "locals . defineVariable ( null ,    Object . class ,    Locals . THIS ,    true )  ;", "for    ( ScriptClassInfo . MethodArgument   arg    :    scriptClassInfo . getExecuteArguments (  )  )     {", "locals . defineVariable ( null ,    arg . getClazz (  )  ,    arg . getName (  )  ,    true )  ;", "}", "if    ( maxLoopCounter    >     0  )     {", "locals . defineVariable ( null ,    int . class ,    Locals . LOOP ,    true )  ;", "}", "return   locals ;", "}", "METHOD_END"], "methodName": ["newMainMethodScope"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "Locals   locals    =    new   Locals ( null ,    definition ,    null ,    null )  ;", "for    ( Definition . Method   method    :    methods )     {", "locals . addMethod ( method )  ;", "}", "return   locals ;", "}", "METHOD_END"], "methodName": ["newProgramScope"], "fileName": "org.elasticsearch.painless.Locals"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   fileName    =    new   StringBuilder (  )  ;", "int   limit    =    scriptName . indexOf (  '  \\ n '  )  ;", "if    ( limit    >  =     0  )     {", "int   limit 2     =    scriptName . indexOf (  '  \\ r '  )  ;", "if    ( limit 2     >  =     0  )     {", "limit    =    Math . min ( limit ,    limit 2  )  ;", "}", "} else    {", "limit    =    scriptName . length (  )  ;", "}", "limit    =    Math . min ( limit ,     . MAX _ NAME _ LENGTH )  ;", "fileName . append ( scriptName ,     0  ,    limit )  ;", "if    ( limit    !  =     ( scriptName . length (  )  )  )     {", "fileName . append (  \"     .  .  .  \"  )  ;", "}", "return   fileName . toString (  )  ;", "}", "METHOD_END"], "methodName": ["computeSourceName"], "fileName": "org.elasticsearch.painless.Location"}, {"methodBody": ["METHOD_START", "{", "StackTraceElement   element    =    new   StackTraceElement ( WriterConstants . CLASS _ NAME ,     \" compile \"  ,    sourceName ,     (  ( offset )     +     1  )  )  ;", "StackTraceElement [  ]    oldStack    =    excep . getStackTrace (  )  ;", "StackTraceElement [  ]    newStack    =    new   StackTraceElement [  ( oldStack . length )     +     1  ]  ;", "System . arraycopy ( oldStack ,     0  ,    newStack ,     1  ,    oldStack . length )  ;", "newStack [  0  ]     =    element ;", "excep . setStackTrace ( newStack )  ;", "assert    ( excep . getStackTrace (  )  . length )     =  =     ( newStack . length )     :     \" non - writeable   stacktrace   for   excep :     \"     +     ( excep . getClass (  )  )  ;", "return   excep ;", "}", "METHOD_END"], "methodName": ["createError"], "fileName": "org.elasticsearch.painless.Location"}, {"methodBody": ["METHOD_START", "{", "return   offset ;", "}", "METHOD_END"], "methodName": ["getOffset"], "fileName": "org.elasticsearch.painless.Location"}, {"methodBody": ["METHOD_START", "{", "return   sourceName ;", "}", "METHOD_END"], "methodName": ["getSourceName"], "fileName": "org.elasticsearch.painless.Location"}, {"methodBody": ["METHOD_START", "{", "Object   val    =    randomFrom (  \" test \"  ,     1  ,     1  .  3  ,    new   Object (  )  )  ;", "String   decl    =    listType    +     \"    x    =     [  ' a '  :     1  ,     ' b '  :     2  ,     0  :     2  ,     -  5  :     ' slot '  ,     1  2  3  .  1  :     1  2  ]  \"  ;", "assertEquals (  5  ,    exec (  ( decl    +     \"  ;    return   x . size (  )  \"  )  )  )  ;", "assertEquals (  2  ,    exec (  ( decl    +     \"  ;    return   x [  0  ]  ;  \"  )  ,    true )  )  ;", "assertEquals (  1  ,    exec (  ( decl    +     \"  ;    return   x [  ' a '  ]  ;  \"  )  ,    true )  )  ;", "assertEquals (  1  2  ,    exec (  ( decl    +     \"  ;    return   x [  1  2  3  .  1  ]  ;  \"  )  ,    true )  )  ;", "assertEquals ( val ,    exec (  ( decl    +     \"  ;    x [     0  ]     =    params . val ;    return   x [     0  ]  ;  \"  )  ,    Collections . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals (  \" slot \"  ,    exec (  ( decl    +     \"  ;    x [     0  ]     =    params . val ;    return   x [  -  5  ]  ;  \"  )  ,    Collections . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "assertEquals ( val ,    exec (  ( decl    +     \"  ;    x [  -  5  ]     =    params . val ;    return   x [  -  5  ]  ;  \"  )  ,    Collections . singletonMap (  \" val \"  ,    val )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["mapAccessesTestCase"], "fileName": "org.elasticsearch.painless.MapTests"}, {"methodBody": ["METHOD_START", "{", "mapAccessesTestCase (  \" Map \"  )  ;", "}", "METHOD_END"], "methodName": ["testMapAccesses"], "fileName": "org.elasticsearch.painless.MapTests"}, {"methodBody": ["METHOD_START", "{", "mapAccessesTestCase (  \" def \"  )  ;", "}", "METHOD_END"], "methodName": ["testMapInDefAccesses"], "fileName": "org.elasticsearch.painless.MapTests"}, {"methodBody": ["METHOD_START", "{", "if    ( clazz . isArray (  )  )     {", "Cs <  ?  >    component    =    clazz . getComponentType (  )  ;", "int   dimensions    =     1  ;", "while    ( component . isArray (  )  )     {", "component    =    component . getComponentType (  )  ;", "+  + dimensions ;", "}", "if    ( component    =  =     ( Definition . def . cs )  )     {", "char [  ]    braces    =    new   char [ dimensions ]  ;", "Arrays . fill ( braces ,     '  [  '  )  ;", "return   Type . getType (  (  ( new   String ( braces )  )     +     ( Type . getType ( Object . cs )  . getDescriptor (  )  )  )  )  ;", "}", "} else", "if    ( clazz    =  =     ( Definition . def . cs )  )     {", "return   Type . getType ( Object . cs )  ;", "}", "return   Type . getType ( clazz )  ;", "}", "METHOD_END"], "methodName": ["getType"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "Object [  ]    args    =    new   Object [  ( params . length )     +     2  ]  ;", "args [  0  ]     =    settings . getInitialCallSiteDepth (  )  ;", "args [  1  ]     =    flavor ;", "System . arraycopy ( params ,     0  ,    args ,     2  ,    params . length )  ;", "invokeDynamic ( name ,    methodType . getDescriptor (  )  ,    Constants . DEF _ BOOTSTRAP _ HANDLE ,    args )  ;", "}", "METHOD_END"], "methodName": ["invokeDefCall"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "if    (  ( WriterConstants . INDY _ STRING _ CONCAT _ BOOTSTRAP _ HANDLE )     !  =    null )     {", "stringConcatArgs . peek (  )  . add (  . getType ( clazz )  )  ;", "if    (  ( stringConcatArgs . peek (  )  . size (  )  )     >  =     ( WriterConstants . MAX _ INDY _ STRING _ CONCAT _ ARGS )  )     {", "writeToStrings (  )  ;", "writeNewStrings (  )  ;", "stringConcatArgs . peek (  )  . add ( WriterConstants . STRING _ TYPE )  ;", "}", "} else    {", "if    ( clazz    =  =     ( boolean . class )  )", "invokeVirtual ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ APPEND _ BOOLEAN )  ;", "else", "if    ( clazz    =  =     ( char . class )  )", "invokeVirtual ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ APPEND _ CHAR )  ;", "else", "if    (  (  ( clazz    =  =     ( byte . class )  )     |  |     ( clazz    =  =     ( short . class )  )  )     |  |     ( clazz    =  =     ( int . class )  )  )", "invokeVirtual ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ APPEND _ INT )  ;", "else", "if    ( clazz    =  =     ( long . class )  )", "invokeVirtual ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ APPEND _ LONG )  ;", "else", "if    ( clazz    =  =     ( float . class )  )", "invokeVirtual ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ APPEND _ FLOAT )  ;", "else", "if    ( clazz    =  =     ( double . class )  )", "invokeVirtual ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ APPEND _ DOUBLE )  ;", "else", "if    ( clazz    =  =     ( String . class )  )", "invokeVirtual ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ APPEND _ STRING )  ;", "else", "invokeVirtual ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ APPEND _ OBJECT )  ;", "}", "}", "METHOD_END"], "methodName": ["writeAppendStrings"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( clazz    =  =     ( float . class )  )     |  |     ( clazz    =  =     ( double . class )  )  )     &  &     (  (  (  (  (  ( operation    =  =     ( Operation . LSH )  )     |  |     ( operation    =  =     ( Operation . USH )  )  )     |  |     ( operation    =  =     ( Operation . RSH )  )  )     |  |     ( operation    =  =     ( Operation . BWAND )  )  )     |  |     ( operation    =  =     ( Operation . XOR )  )  )     |  |     ( operation    =  =     ( Operation . BWOR )  )  )  )     {", "throw   location . createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "switch    ( operation )     {", "case   MUL    :", "math ( MUL ,     . getType ( clazz )  )  ;", "break ;", "case   DIV    :", "math ( DIV ,     . getType ( clazz )  )  ;", "break ;", "case   REM    :", "math ( REM ,     . getType ( clazz )  )  ;", "break ;", "case   ADD    :", "math ( ADD ,     . getType ( clazz )  )  ;", "break ;", "case   SUB    :", "math ( SUB ,     . getType ( clazz )  )  ;", "break ;", "case   LSH    :", "math ( SHL ,     . getType ( clazz )  )  ;", "break ;", "case   USH    :", "math ( USHR ,     . getType ( clazz )  )  ;", "break ;", "case   RSH    :", "math ( SHR ,     . getType ( clazz )  )  ;", "break ;", "case   BWAND    :", "math ( AND ,     . getType ( clazz )  )  ;", "break ;", "case   XOR    :", "math ( XOR ,     . getType ( clazz )  )  ;", "break ;", "case   BWOR    :", "math ( OR ,     . getType ( clazz )  )  ;", "break ;", "default    :", "throw   location . createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["writeBinaryInstruction"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "if    ( tru    !  =    null )     {", "visJumpInsn ( IFNE ,    tru )  ;", "} else", "if    ( fals    !  =    null )     {", "visJumpInsn ( Opcodes . IFEQ ,    fals )  ;", "}", "}", "METHOD_END"], "methodName": ["writeBranch"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "if    ( from . equals ( to )  )     {", "return ;", "}", "if    (  (  (  ( from    !  =     ( boolean . class )  )     &  &     ( from . isPrimitive (  )  )  )     &  &     ( to    !  =     ( boolean . class )  )  )     &  &     ( to . isPrimitive (  )  )  )     {", "cast (  . getType ( from )  ,     . getType ( to )  )  ;", "} else    {", "if    (  !  ( to . isAssignableFrom ( from )  )  )     {", "checkCast (  . getType ( to )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["writeCast"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "if    ( cast    !  =    null )     {", "if    (  (  ( cast . from )     =  =     ( char . class )  )     &  &     (  ( cast . to )     =  =     ( String . class )  )  )     {", "invokeStatic ( WriterConstants . UTILITY _ TYPE ,    WriterConstants . CHAR _ TO _ STRING )  ;", "} else", "if    (  (  ( cast . from )     =  =     ( String . class )  )     &  &     (  ( cast . to )     =  =     ( char . class )  )  )     {", "invokeStatic ( WriterConstants . UTILITY _ TYPE ,    WriterConstants . STRING _ TO _ CHAR )  ;", "} else", "if    (  ( cast . unboxFrom )     !  =    null )     {", "unbox (  . getType ( cast . unboxFrom )  )  ;", "writeCast ( cast . from ,    cast . to )  ;", "} else", "if    (  ( cast . unboxTo )     !  =    null )     {", "if    (  ( cast . from )     =  =     ( Definition . def . class )  )     {", "if    ( cast . explicit )     {", "if    (  ( cast . to )     =  =     ( Boolean . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ BOOLEAN )  ;", "else", "if    (  ( cast . to )     =  =     ( Byte . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ BYTE _ EXPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Short . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ SHORT _ EXPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Character . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ CHAR _ EXPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Integer . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ INT _ EXPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Long . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ LONG _ EXPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Float . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ FLOAT _ EXPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Double . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ DOUBLE _ EXPLICIT )  ;", "else    {", "throw   new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  ;", "}", "} else    {", "if    (  ( cast . to )     =  =     ( Boolean . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ BOOLEAN )  ;", "else", "if    (  ( cast . to )     =  =     ( Byte . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ BYTE _ IMPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Short . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ SHORT _ IMPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Character . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ CHAR _ IMPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Integer . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ INT _ IMPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Long . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ LONG _ IMPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Float . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ FLOAT _ IMPLICIT )  ;", "else", "if    (  ( cast . to )     =  =     ( Double . class )  )", "invokeStatic ( WriterConstants . DEF _ UTIL _ TYPE ,    WriterConstants . DEF _ TO _ DOUBLE _ IMPLICIT )  ;", "else    {", "throw   new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  ;", "}", "}", "} else    {", "writeCast ( cast . from ,    cast . to )  ;", "unbox (  . getType ( cast . unboxTo )  )  ;", "}", "} else", "if    (  ( cast . boxFrom )     !  =    null )     {", "box (  . getType ( cast . boxFrom )  )  ;", "writeCast ( cast . from ,    cast . to )  ;", "} else", "if    (  ( cast . boxTo )     !  =    null )     {", "writeCast ( cast . from ,    cast . to )  ;", "box (  . getType ( cast . boxTo )  )  ;", "} else    {", "writeCast ( cast . from ,    cast . to )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["writeCast"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "Label   label    =    new   Label (  )  ;", "visitLabel ( label )  ;", "visitLineNumber (  (  ( location . getOffset (  )  )     +     1  )  ,    label )  ;", "}", "METHOD_END"], "methodName": ["writeDebugInfo"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "if    ( size    =  =     1  )     {", "if    ( xsize    =  =     2  )     {", "dupX 2  (  )  ;", "} se", "if    ( xsize    =  =     1  )     {", "dupX 1  (  )  ;", "} se    {", "dup (  )  ;", "}", "} se", "if    ( size    =  =     2  )     {", "if    ( xsize    =  =     2  )     {", "dup 2 X 2  (  )  ;", "} se", "if    ( xsize    =  =     1  )     {", "dup 2 X 1  (  )  ;", "} se    {", "dup 2  (  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["writeDup"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "Type   methodType    =    Type . getMethodType ( MethodWriter . getType ( returnType )  ,    MethodWriter . getType ( lhs )  ,    MethodWriter . getType ( rhs )  )  ;", "switch    ( operation )     {", "case   MUL    :", "invokeDefCall (  \" mul \"  ,    methodType ,    DefBootstrap . BINARY _ OPERATOR ,    flags )  ;", "break ;", "case   DIV    :", "invokeDefCall (  \" div \"  ,    methodType ,    DefBootstrap . BINARY _ OPERATOR ,    flags )  ;", "break ;", "case   REM    :", "invokeDefCall (  \" rem \"  ,    methodType ,    DefBootstrap . BINARY _ OPERATOR ,    flags )  ;", "break ;", "case   ADD    :", "boolean   hasPrimitiveArg    =     ( lhs . isPrimitive (  )  )     |  |     ( rhs . isPrimitive (  )  )  ;", "if    (  ! hasPrimitiveArg )     {", "flags    |  =    DefBootstrap . OPERATOR _ ALLOWS _ NULL ;", "}", "invokeDefCall (  \" add \"  ,    methodType ,    DefBootstrap . BINARY _ OPERATOR ,    flags )  ;", "break ;", "case   SUB    :", "invokeDefCall (  \" sub \"  ,    methodType ,    DefBootstrap . BINARY _ OPERATOR ,    flags )  ;", "break ;", "case   LSH    :", "invokeDefCall (  \" lsh \"  ,    methodType ,    DefBootstrap . SHIFT _ OPERATOR ,    flags )  ;", "break ;", "case   USH    :", "invokeDefCall (  \" ush \"  ,    methodType ,    DefBootstrap . SHIFT _ OPERATOR ,    flags )  ;", "break ;", "case   RSH    :", "invokeDefCall (  \" rsh \"  ,    methodType ,    DefBootstrap . SHIFT _ OPERATOR ,    flags )  ;", "break ;", "case   BWAND    :", "invokeDefCall (  \" and \"  ,    methodType ,    DefBootstrap . BINARY _ OPERATOR ,    flags )  ;", "break ;", "case   XOR    :", "invokeDefCall (  \" xor \"  ,    methodType ,    DefBootstrap . BINARY _ OPERATOR ,    flags )  ;", "break ;", "case   BWOR    :", "invokeDefCall (  \" or \"  ,    methodType ,    DefBootstrap . BINARY _ OPERATOR ,    flags )  ;", "break ;", "default    :", "throw   location . createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["writeDynamicBinaryInstruction"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "assert   slot    !  =     (  -  1  )  ;", "writeDebugInfo ( location )  ;", "final   Label   end    =    new   Label (  )  ;", "iinc ( slot ,     (  - count )  )  ;", "visitVarInsn ( ILOAD ,    slot )  ;", "push (  0  )  ;", "ifICmp ( GT ,    end )  ;", "throwException ( Constants . PAINLESS _ ERROR _ TYPE ,     \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  ;", "mark ( end )  ;", "}", "METHOD_END"], "methodName": ["writeLoopCounter"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "if    (  ( WriterConstants . INDY _ STRING _ CONCAT _ BOOTSTRAP _ HANDLE )     !  =    null )     {", "stringConcatArgs . push ( new   ArrayList (  )  )  ;", "return    0  ;", "} else    {", "newInstance ( WriterConstants . STRINGBUILDER _ TYPE )  ;", "dup (  )  ;", "invokeConstructor ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ CONSTRUCTOR )  ;", "return    1  ;", "}", "}", "METHOD_END"], "methodName": ["writeNewStrings"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "if    ( size    =  =     1  )     {", "pop (  )  ;", "} se", "if    ( size    =  =     2  )     {", "pop 2  (  )  ;", "}", "}", "METHOD_END"], "methodName": ["writePop"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "int   offset    =    location . getOffset (  )  ;", "assert    ( statements . get ( offset )  )     =  =    false ;", "statements . set ( offset )  ;", "}", "METHOD_END"], "methodName": ["writeStatementOffset"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "if    (  ( WriterConstants . INDY _ STRING _ CONCAT _ BOOTSTRAP _ HANDLE )     !  =    null )     {", "final   String   desc    =    Type . getMethodDescriptor ( WriterConstants . STRING _ TYPE ,    stringConcatArgs . pop (  )  . stream (  )  . toArray ( Type [  ]  :  : new )  )  ;", "invokeDynamic (  \" concat \"  ,    desc ,    WriterConstants . INDY _ STRING _ CONCAT _ BOOTSTRAP _ HANDLE )  ;", "} else    {", "invokeVirtual ( WriterConstants . STRINGBUILDER _ TYPE ,    WriterConstants . STRINGBUILDER _ TOSTRING )  ;", "}", "}", "METHOD_END"], "methodName": ["writeToStrings"], "fileName": "org.elasticsearch.painless.MethodWriter"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  8  ,    exec (  \" int   x    =     4  ;    char   y    =     2  ;    return   x * y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( byte )     (  1  )  )     *     (  ( byte )     (  1  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  2  )  )     *     (  ( byte )     (  3  )  )  )  ,    exec (  \" byte   x    =     2  ;    byte   y    =     3  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  5  )  )     *     (  ( byte )     (  1  0  )  )  )  ,    exec (  \" byte   x    =     5  ;    byte   y    =     1  0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     *     (  ( byte )     (  1  )  )  )     *     (  ( byte )     (  2  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    byte   z    =     2  ;    return   x * y * z ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     *     (  ( byte )     (  1  )  )  )     *     (  ( byte )     (  2  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    byte   z    =     2  ;    return    ( x * y )  * z ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     *     (  (  ( byte )     (  1  )  )     *     (  ( byte )     (  2  )  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    byte   z    =     2  ;    return   x *  ( y * z )  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  0  )  )     *     (  ( byte )     (  0  )  )  )  ,    exec (  \" byte   x    =     1  0  ;    byte   y    =     0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  0  )  )     *     (  ( byte )     (  0  )  )  )  ,    exec (  \" byte   x    =     0  ;    byte   y    =     0  ;    return   x * x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testByte"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" byte   x    =     5  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  5  )  )  ,    exec (  \" byte   x    =     5  ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" short   x    =     5  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  5  )  )  ,    exec (  \" short   x    =     5  ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" char   x    =     5  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" int   x    =     5  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  )  ,    exec (  \" int   x    =     5  ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" long   x    =     5  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5 L )  ,    exec (  \" long   x    =     5  ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0 F ,    exec (  \" float   x    =     5 f ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0 F )  ,    exec (  \" float   x    =     5 f ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0  ,    exec (  \" double   x    =     5  .  0  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0  )  ,    exec (  \" double   x    =     5  .  0  ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignment"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" def   x    =     ( byte )  5  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  5  )  )  ,    exec (  \" def   x    =     ( byte )  5  ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" def   x    =     ( short )  5  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  5  )  )  ,    exec (  \" def   x    =     ( short )  5  ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" def   x    =     ( char )  5  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" def   x    =     5  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  )  ,    exec (  \" def   x    =     5  ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" def   x    =     5 L ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5 L )  ,    exec (  \" def   x    =     5 L ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0 F ,    exec (  \" def   x    =     5 f ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0 F )  ,    exec (  \" def   x    =     5 f ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0  ,    exec (  \" def   x    =     5  .  0  ;    x    *  =     3  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0  )  ,    exec (  \" def   x    =     5  .  0  ;    x    *  =     -  1  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefCompoundAssignment"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedLHS"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    byte   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    byte   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    byte   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    byte   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    byte   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    byte   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    byte   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    short   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    short   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    short   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    short   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    short   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    short   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    short   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    char   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    char   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    char   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    char   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    char   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    char   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    char   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    int   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    int   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    int   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    int   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    int   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    int   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    int   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( byte )  2  ;    long   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( short )  2  ;    long   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( char )  2  ;    long   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( int )  2  ;    long   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    long   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    long   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    long   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( byte )  2  ;    float   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( short )  2  ;    float   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( char )  2  ;    float   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( int )  2  ;    float   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( long )  2  ;    float   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    float   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    float   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( byte )  2  ;    double   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( short )  2  ;    double   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( char )  2  ;    double   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( int )  2  ;    double   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( long )  2  ;    double   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( float )  2  ;    double   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    double   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( byte )  2  ;    byte   y    =     ( byte )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( short )  2  ;    short   y    =     ( short )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( char )  2  ;    char   y    =     ( char )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  ,    exec (  \" def   x    =     ( int )  2  ;    int   y    =     ( int )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4 L ,    exec (  \" def   x    =     ( long )  2  ;    long   y    =     ( long )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    float   y    =     ( float )  2  ;    return   x    *    y \"  )  )  ;", "assertEquals (  4  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    double   y    =     ( double )  2  ;    return   x    *    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedRHS"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     *     1  .  0  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  2  .  0     *     3  .  0  )  ,    exec (  \" double   x    =     2  ;    double   y    =     3  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  5  .  0     *     1  0  .  0  )  ,    exec (  \" double   x    =     5  ;    double   y    =     1  0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     *     1  .  0  )     *     2  .  0  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    double   z    =     2  ;    return   x * y * z ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     *     1  .  0  )     *     2  .  0  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    double   z    =     2  ;    return    ( x * y )  * z ;  \"  )  )  ;", "assertEquals (  (  1  .  0     *     (  1  .  0     *     2  .  0  )  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    double   z    =     2  ;    return   x *  ( y * z )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     *     0  .  0  )  ,    exec (  \" double   x    =     1  0  ;    float   y    =     0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  0  .  0     *     0  .  0  )  ,    exec (  \" double   x    =     0  ;    float   y    =     0  ;    return   x * x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDouble"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     *     1  .  0  )  ,    exec (  \" return    1  .  0  *  1  .  0  ;  \"  )  )  ;", "assertEquals (  (  2  .  0     *     3  .  0  )  ,    exec (  \" return    2  .  0  *  3  .  0  ;  \"  )  )  ;", "assertEquals (  (  5  .  0     *     1  0  .  0  )  ,    exec (  \" return    5  .  0  *  1  0  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     *     1  .  0  )     *     2  .  0  )  ,    exec (  \" return    1  .  0  *  1  .  0  *  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     *     1  .  0  )     *     2  .  0  )  ,    exec (  \" return    (  1  .  0  *  1  .  0  )  *  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     *     (  1  .  0     *     2  .  0  )  )  ,    exec (  \" return    1  .  0  *  (  1  .  0  *  2  .  0  )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     *     0  .  0  )  ,    exec (  \" return    1  0  .  0  *  0  .  0  ;  \"  )  )  ;", "assertEquals (  (  0  .  0     *     0  .  0  )  ,    exec (  \" return    0  .  0  *  0  .  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleConst"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    *     1  .  0 F )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  2  .  0 F    *     3  .  0 F )  ,    exec (  \" float   x    =     2  ;    float   y    =     3  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    *     1  0  .  0 F )  ,    exec (  \" float   x    =     5  ;    float   y    =     1  0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    *     1  .  0 F )     *     2  .  0 F )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    float   z    =     2  ;    return   x * y * z ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    *     1  .  0 F )     *     2  .  0 F )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    float   z    =     2  ;    return    ( x * y )  * z ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    *     (  1  .  0 F    *     2  .  0 F )  )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    float   z    =     2  ;    return   x *  ( y * z )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    *     0  .  0 F )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    *     0  .  0 F )  ,    exec (  \" float   x    =     0  ;    float   y    =     0  ;    return   x * x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloat"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    *     1  .  0 F )  ,    exec (  \" return    1 F *  1 F ;  \"  )  )  ;", "assertEquals (  (  2  .  0 F    *     3  .  0 F )  ,    exec (  \" return    2 F *  3 F ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    *     1  0  .  0 F )  ,    exec (  \" return    5 F *  1  0 F ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    *     1  .  0 F )     *     2  .  0 F )  ,    exec (  \" return    1 F *  1 F *  2 F ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    *     1  .  0 F )     *     2  .  0 F )  ,    exec (  \" return    (  1 F *  1 F )  *  2 F ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    *     (  1  .  0 F    *     2  .  0 F )  )  ,    exec (  \" return    1 F *  (  1 F *  2 F )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    *     0  .  0 F )  ,    exec (  \" return    1  0 F *  0 F ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    *     0  .  0 F )  ,    exec (  \" return    0 F *  0 F ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloatConst"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     *     1  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  2     *     3  )  ,    exec (  \" int   x    =     2  ;    int   y    =     3  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  5     *     1  0  )  ,    exec (  \" int   x    =     5  ;    int   y    =     1  0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  (  1     *     1  )     *     2  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    int   z    =     2  ;    return   x * y * z ;  \"  )  )  ;", "assertEquals (  (  (  1     *     1  )     *     2  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    int   z    =     2  ;    return    ( x * y )  * z ;  \"  )  )  ;", "assertEquals (  (  1     *     (  1     *     2  )  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    int   z    =     2  ;    return   x *  ( y * z )  ;  \"  )  )  ;", "assertEquals (  (  1  0     *     0  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  0     *     0  )  ,    exec (  \" int   x    =     0  ;    int   y    =     0  ;    return   x * x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInt"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     *     1  )  ,    exec (  \" return    1  *  1  ;  \"  )  )  ;", "assertEquals (  (  2     *     3  )  ,    exec (  \" return    2  *  3  ;  \"  )  )  ;", "assertEquals (  (  5     *     1  0  )  ,    exec (  \" return    5  *  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  1     *     1  )     *     2  )  ,    exec (  \" return    1  *  1  *  2  ;  \"  )  )  ;", "assertEquals (  (  (  1     *     1  )     *     2  )  ,    exec (  \" return    (  1  *  1  )  *  2  ;  \"  )  )  ;", "assertEquals (  (  1     *     (  1     *     2  )  )  ,    exec (  \" return    1  *  (  1  *  2  )  ;  \"  )  )  ;", "assertEquals (  (  1  0     *     0  )  ,    exec (  \" return    1  0  *  0  ;  \"  )  )  ;", "assertEquals (  (  0     *     0  )  ,    exec (  \" return    0  *  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIntConst"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    *     1 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  2 L    *     3 L )  ,    exec (  \" long   x    =     2  ;    long   y    =     3  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  5 L    *     1  0 L )  ,    exec (  \" long   x    =     5  ;    long   y    =     1  0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  (  1 L    *     1 L )     *     2 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    int   z    =     2  ;    return   x * y * z ;  \"  )  )  ;", "assertEquals (  (  (  1 L    *     1 L )     *     2 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    int   z    =     2  ;    return    ( x * y )  * z ;  \"  )  )  ;", "assertEquals (  (  1 L    *     (  1 L    *     2 L )  )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    int   z    =     2  ;    return   x *  ( y * z )  ;  \"  )  )  ;", "assertEquals (  (  1  0 L    *     0 L )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     0  ;    return   x * y ;  \"  )  )  ;", "assertEquals (  (  0 L    *     0 L )  ,    exec (  \" long   x    =     0  ;    long   y    =     0  ;    return   x * x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLong"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    *     1 L )  ,    exec (  \" return    1 L *  1 L ;  \"  )  )  ;", "assertEquals (  (  2 L    *     3 L )  ,    exec (  \" return    2 L *  3 L ;  \"  )  )  ;", "assertEquals (  (  5 L    *     1  0 L )  ,    exec (  \" return    5 L *  1  0 L ;  \"  )  )  ;", "assertEquals (  (  (  1 L    *     1 L )     *     2 L )  ,    exec (  \" return    1 L *  1 L *  2 L ;  \"  )  )  ;", "assertEquals (  (  (  1 L    *     1 L )     *     2 L )  ,    exec (  \" return    (  1 L *  1 L )  *  2 L ;  \"  )  )  ;", "assertEquals (  (  1 L    *     (  1 L    *     2 L )  )  ,    exec (  \" return    1 L *  (  1 L *  2 L )  ;  \"  )  )  ;", "assertEquals (  (  1  0 L    *     0 L )  ,    exec (  \" return    1  0 L *  0 L ;  \"  )  )  ;", "assertEquals (  (  0 L    *     0 L )  ,    exec (  \" return    0 L *  0 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongConst"], "fileName": "org.elasticsearch.painless.MultiplicationTests"}, {"methodBody": ["METHOD_START", "{", "IndexService   index    =    createIndex (  \" test \"  ,    EMPTY ,     \" type \"  ,     \" d \"  ,     \" type = double \"  )  ;", "Map < ScriptContext <  ?  >  ,    List < Whitelist >  >    contexts    =    new   HashMap <  >  (  )  ;", "contexts . put ( CONTEXT ,    Whitelist . BASE _ WHITELISTS )  ;", "contexts . put ( ExecutableScript . CONTEXT ,    Whitelist . BASE _ WHITELISTS )  ;", "PScriptEngine   service    =    new   PScriptEngine ( Settings . EMPTY ,    contexts )  ;", "QueryShardContext   shardContext    =    index . newQueryShardContext (  0  ,    null ,     (  )     -  >     0  ,    null )  ;", "SearchLookup   lookup    =    new   SearchLookup ( index . mapperService (  )  ,    shardContext :  : getForField ,    null )  ;", "SearchScript . Factory   factory    =    service . compile ( null ,     \"  1  .  2  \"  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "SearchScript . LeafFactory   ss    =    factory . newFactory ( Collections . emptyMap (  )  ,    lookup )  ;", "assertFalse ( ss . needs _ score (  )  )  ;", "factory    =    service . compile ( null ,     \" doc [  ' d '  ]  . value \"  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "ss    =    factory . newFactory ( Collections . emptyMap (  )  ,    lookup )  ;", "assertFalse ( ss . needs _ score (  )  )  ;", "factory    =    service . compile ( null ,     \"  1  /  _ score \"  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "ss    =    factory . newFactory ( Collections . emptyMap (  )  ,    lookup )  ;", "assertTrue ( ss . needs _ score (  )  )  ;", "factory    =    service . compile ( null ,     \" doc [  ' d '  ]  . value    *     _ score \"  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "ss    =    factory . newFactory ( Collections . emptyMap (  )  ,    lookup )  ;", "assertTrue ( ss . needs _ score (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNeedsScores"], "fileName": "org.elasticsearch.painless.NeedsScoreTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  2  )  )  ,    exec (  \" byte   a    =     2  ;    return   a \"  )  )  ;", "assertEquals (  (  ( short )     (  2  )  )  ,    exec (  \" short   a    =     2  ;    return   a \"  )  )  ;", "assertEquals (  (  ( char )     (  2  )  )  ,    exec (  \" char   a    =     2  ;    return   a \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   a    =     2  ;    return   a \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" g   a    =     2  ;    return   a \"  )  )  ;", "assertEquals (  2  .  0 F ,    exec (  \" float   a    =     2  ;    return   a \"  )  )  ;", "assertEquals (  2  .  0  ,    exec (  \" double   a    =     2  ;    return   a \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   a    =    false ;    return   a \"  )  )  ;", "assertEquals (  \" string \"  ,    exec (  \" String   a    =     \\  \" string \\  \"  ;    return   a \"  )  )  ;", "assertEquals ( HashMap . class ,    exec (  \" Map   a    =    new   HashMap (  )  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( byte [  ]  . class ,    exec (  \" byte [  ]    a    =    new   byte [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( short [  ]  . class ,    exec (  \" short [  ]    a    =    new   short [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( char [  ]  . class ,    exec (  \" char [  ]    a    =    new   char [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( int [  ]  . class ,    exec (  \" int [  ]    a    =    new   int [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( g [  ]  . class ,    exec (  \" g [  ]    a    =    new   g [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( float [  ]  . class ,    exec (  \" float [  ]    a    =    new   float [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( double [  ]  . class ,    exec (  \" double [  ]    a    =    new   double [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( boolean [  ]  . class ,    exec (  \" boolean [  ]    a    =    new   boolean [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( String [  ]  . class ,    exec (  \" String [  ]    a    =    new   String [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( Map [  ]  . class ,    exec (  \" Map [  ]    a    =    new   Map [  1  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( byte [  ]  [  ]  . class ,    exec (  \" byte [  ]  [  ]    a    =    new   byte [  1  ]  [  2  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( short [  ]  [  ]  [  ]  . class ,    exec (  \" short [  ]  [  ]  [  ]    a    =    new   short [  1  ]  [  2  ]  [  3  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( char [  ]  [  ]  [  ]  [  ]  . class ,    exec (  \" char [  ]  [  ]  [  ]  [  ]    a    =    new   char [  1  ]  [  2  ]  [  3  ]  [  4  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( int [  ]  [  ]  [  ]  [  ]  [  ]  . class ,    exec (  \" int [  ]  [  ]  [  ]  [  ]  [  ]    a    =    new   int [  1  ]  [  2  ]  [  3  ]  [  4  ]  [  5  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( g [  ]  [  ]  . class ,    exec (  \" g [  ]  [  ]    a    =    new   g [  1  ]  [  2  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( float [  ]  [  ]  [  ]  . class ,    exec (  \" float [  ]  [  ]  [  ]    a    =    new   float [  1  ]  [  2  ]  [  3  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( double [  ]  [  ]  [  ]  [  ]  . class ,    exec (  \" double [  ]  [  ]  [  ]  [  ]    a    =    new   double [  1  ]  [  2  ]  [  3  ]  [  4  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( boolean [  ]  [  ]  [  ]  [  ]  [  ]  . class ,    exec (  \" boolean [  ]  [  ]  [  ]  [  ]  [  ]    a    =    new   boolean [  1  ]  [  2  ]  [  3  ]  [  4  ]  [  5  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( String [  ]  [  ]  . class ,    exec (  \" String [  ]  [  ]    a    =    new   String [  1  ]  [  2  ]  ;    return   a \"  )  . getClass (  )  )  ;", "assertEquals ( Map [  ]  [  ]  [  ]  . class ,    exec (  \" Map [  ]  [  ]  [  ]    a    =    new   Map [  1  ]  [  2  ]  [  3  ]  ;    return   a \"  )  . getClass (  )  )  ;", "}", "METHOD_END"], "methodName": ["testDeclarationStatement"], "fileName": "org.elasticsearch.painless.NoSemiColonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  0  ,    exec (  \"  1  0  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \"  5     +     5  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \"  5     +     5  \"  )  )  ;", "assertEquals (  1  0  ,    exec ( ramsram    =  =     ' yes '     ?     1  0     :     5  \"  ,    Collections . singletonMap ( ram \"  ,     \" yes \"  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testExpression"], "fileName": "org.elasticsearch.painless.NoSemiColonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  0  ,    exec (  \" return    1  0  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" int   x    =     5  ;    return   x \"  )  )  ;", "assertEquals (  4  ,    exec (  \" int [  ]    x    =    new   int [  2  ]  ;    x [  1  ]     =     4  ;    return   x [  1  ]  \"  )  )  ;", "assertEquals (  5  ,     (  ( short [  ]  )     ( exec (  \" short [  ]    s    =    new   short [  3  ]  ;    s [  1  ]     =     5  ;    return   s \"  )  )  )  [  1  ]  )  ;", "assertEquals (  1  0  ,     (  ( Map )     ( exec (  \" Map   s    =    new   HashMap (  )  ;    s . put (  \\  \" x \\  \"  ,     1  0  )  ;    return   s \"  )  )  )  . get (  \" x \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnStatement"], "fileName": "org.elasticsearch.painless.NoSemiColonTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5     |     3  )  ,    exec (  \" return    5     |     3  ;  \"  )  )  ;", "assertEquals (  (  5 L    |     3  )  ,    exec (  \" return    5 L    |     3  ;  \"  )  )  ;", "assertEquals (  (  5     |     3 L )  ,    exec (  \" return    5     |     3 L ;  \"  )  )  ;", "assertEquals (  7  ,    exec (  \" short   x    =     5  ;    byte   y    =     3  ;    return   x    |    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     4  ;    int   y    =     1  ;    x    |  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     4  ;    int   y    =     1  ;    x    |  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    float   y    =     1  ;    x    |  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    double   y    =     1  ;    x    |  =    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusCompoundAssignment"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;    x    |  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;    x    |  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    false ;    x    |  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    x    |  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     |  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     |  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     |  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     |  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  3     |     1  4  )  )  ,    exec (  \" byte   x    =     1  3  ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  3     |     1  4  )  )  ,    exec (  \" short   x    =     1  3  ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  3     |     1  4  )  )  ,    exec (  \" char   x    =     1  3  ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1  3     |     1  4  )  ,    exec (  \" int   x    =     1  3  ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( long )     (  1  3     |     1  4  )  )  ,    exec (  \" long   x    =     1  3 L ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignment"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( float )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( double )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  ;", "}  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       def   y    =    true ;    return   x    |    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       def   y    =    false ;    return   x    |    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    def   y    =    true ;    return   x    |    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    def   y    =    false ;    return   x    |    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     4 F ;    int   y    =     1  ;    x    |  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     4 D ;    int   y    =     1  ;    x    |  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     4  ;    float   y    =     1  ;    x    |  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     4  ;    double   y    =     1  ;    x    |  =    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDefBogusCompoundAssignment"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x    =    true ;    x    |  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;    x    |  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    x    |  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    x    |  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     |  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     |  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     |  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     |  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  3     |     1  4  )  )  ,    exec (  \" def   x    =     ( byte )  1  3  ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  3     |     1  4  )  )  ,    exec (  \" def   x    =     ( short )  1  3  ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  3     |     1  4  )  )  ,    exec (  \" def   x    =     ( char )  1  3  ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1  3     |     1  4  )  ,    exec (  \" def   x    =     1  3  ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( long )     (  1  3     |     1  4  )  )  ,    exec (  \" def   x    =     1  3 L ;    x    |  =     1  4  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefCompoundAssignment"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     ( float )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     ( double )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  ;", "}  )  ;", "assertEquals (  5  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;       def   y    =    true ;    return   x    |    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;       def   y    =    false ;    return   x    |    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    false ;    def   y    =    true ;    return   x    |    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    def   y    =    false ;    return   x    |    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedLHS"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( float )  4  ;    byte   y    =     ( byte )  1  ;    return   x    |    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( double )  4  ;    byte   y    =     ( byte )  1  ;    return   x    |    y \"  )  ;", "}  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    byte   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    byte   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    byte   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    byte   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    short   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    short   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    short   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    short   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    char   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    char   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    char   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    char   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    int   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    int   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    int   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    int   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( byte )  4  ;    long   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( short )  4  ;    long   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( char )  4  ;    long   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( int )  4  ;    long   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    |    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       boolean   y    =    true ;    return   x    |    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       boolean   y    =    false ;    return   x    |    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    boolean   y    =    true ;    return   x    |    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    boolean   y    =    false ;    return   x    |    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedRHS"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     ( float )  4  ;    int   y    =     1  ;    return   x    |    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     ( double )  4  ;    int   y    =     1  ;    return   x    |    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIllegal"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5     |     1  2  )  ,    exec (  \" int   x    =     5  ;    int   y    =     1  2  ;    return   x    |    y ;  \"  )  )  ;", "assertEquals (  (  5     |     (  -  1  2  )  )  ,    exec (  \" int   x    =     5  ;    int   y    =     -  1  2  ;    return   x    |    y ;  \"  )  )  ;", "assertEquals (  (  (  7     |     1  5  )     |     3  )  ,    exec (  \" int   x    =     7  ;    int   y    =     1  5  ;    int   z    =     3  ;    return   x    |    y    |    z ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInt"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5     |     1  2  )  ,    exec (  \" return    5     |     1  2  ;  \"  )  )  ;", "assertEquals (  (  5     |     (  -  1  2  )  )  ,    exec (  \" return    5     |     -  1  2  ;  \"  )  )  ;", "assertEquals (  (  (  7     |     1  5  )     |     3  )  ,    exec (  \" return    7     |     1  5     |     3  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIntConst"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5 L    |     1  2 L )  ,    exec (  \" long   x    =     5  ;    long   y    =     1  2  ;    return   x    |    y ;  \"  )  )  ;", "assertEquals (  (  5 L    |     (  -  1  2 L )  )  ,    exec (  \" long   x    =     5  ;    long   y    =     -  1  2  ;    return   x    |    y ;  \"  )  )  ;", "assertEquals (  (  (  7 L    |     1  5 L )     |     3 L )  ,    exec (  \" long   x    =     7  ;    long   y    =     1  5  ;    long   z    =     3  ;    return   x    |    y    |    z ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLong"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5 L    |     1  2 L )  ,    exec (  \" return    5 L    |     1  2 L ;  \"  )  )  ;", "assertEquals (  (  5 L    |     (  -  1  2 L )  )  ,    exec (  \" return    5 L    |     -  1  2 L ;  \"  )  )  ;", "assertEquals (  (  (  7 L    |     1  5 L )     |     3 L )  ,    exec (  \" return    7 L    |     1  5 L    |     3 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongConst"], "fileName": "org.elasticsearch.painless.OrTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  (  \" FeatureTest   f    =    new   FeatureTest (  )  ;  \"     +     \" return   f . x    =  =     0     &  &    f . y    =  =     0  ;  \"  )  )  )  ;", "assertEquals ( true ,    exec (  (  \" FeatureTest   f    =    new   FeatureTest (  1  ,     2  )  ;  \"     +     \" return   f . x    =  =     1     &  &    f . y    =  =     2  ;  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testConstructor"], "fileName": "org.elasticsearch.painless.OverloadTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" return    ' abc 1  2  3 abc '  . indexOf (  ' c '  )  ;  \"  )  )  ;", "assertEquals (  8  ,    exec (  \" return    ' abc 1  2  3 abc '  . indexOf (  ' c '  ,     3  )  ;  \"  )  )  ;", "IllegalArgumentException   expected    =    ScriptCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" return    ' abc 1  2  3 abc '  . indexOf (  ' c '  ,     3  ,     ' bogus '  )  ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \"  [ indexOf ]    with    [  3  ]    arguments \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMethod"], "fileName": "org.elasticsearch.painless.OverloadTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   x    =     ' abc 1  2  3 abc '  ;    return   x . indexOf (  ' c '  )  ;  \"  )  )  ;", "assertEquals (  8  ,    exec (  \" def   x    =     ' abc 1  2  3 abc '  ;    return   x . indexOf (  ' c '  ,     3  )  ;  \"  )  )  ;", "IllegalArgumentException   expected    =    ScriptCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ' abc 1  2  3 abc '  ;    return   x . indexOf (  ' c '  ,     3  ,     ' bogus '  )  ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" dynamic   method    [ indexOf ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMethodDynamic"], "fileName": "org.elasticsearch.painless.OverloadTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return   overloadedStatic (  )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return   overloadedStatic ( false )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testStatic"], "fileName": "org.elasticsearch.painless.OverloadTests"}, {"methodBody": ["METHOD_START", "{", "return   clazz . getName (  )  . replace (  '  .  '  ,     '  /  '  )  . replace (  '  $  '  ,     '  .  '  )  ;", "}", "METHOD_END"], "methodName": ["classUrlPath"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "stream . print (  \"  *  *     [  [  \"  )  ;", ". emitAnchor ( stream ,    field )  ;", "stream . print (  \"  ]  ]  \"  )  ;", "if    ( Modifier . isStatic ( field . modifiers )  )     {", "stream . print (  \" static    \"  )  ;", "}", ". emitType ( stream ,     . definition . ClassToType ( field . clazz )  )  ;", "stream . print (  '     '  )  ;", "String   javadocRoot    =     . javadocRoot ( field )  ;", ". emitJavadocLink ( stream ,    javadocRoot ,    field )  ;", "stream . print (  '  [  '  )  ;", "stream . print ( field . name )  ;", "stream . print (  '  ]  '  )  ;", "if    ( equals (  \" java 8  \"  )  )     {", "stream . print (  \"     (  \"  )  ;", ". emitJavadocLink ( stream ,     \" java 9  \"  ,    field )  ;", "stream . print (  \"  [ java    9  ]  )  \"  )  ;", "}", "stream . println (  )  ;", "}", "METHOD_END"], "methodName": ["documentField"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "stream . print (  \"  *     +  +  [  [  \"  )  ;", ". emitAnchor ( stream ,    method )  ;", "stream . print (  \"  ]  ]  \"  )  ;", "if    (  ( null    =  =     ( method . augmentation )  )     &  &     ( Modifier . isStatic ( method . modifiers )  )  )     {", "stream . print (  \" static    \"  )  ;", "}", "if    ( false    =  =     ( method . name . equals (  \"  < init >  \"  )  )  )     {", ". emitType ( stream ,     . definition . ClassToType ( method . rtn )  )  ;", "stream . print (  '     '  )  ;", "}", "String   javadocRoot    =     . javadocRoot ( method )  ;", ". emitJavadocLink ( stream ,    javadocRoot ,    method )  ;", "stream . print (  '  [  '  )  ;", "stream . print (  . methodName ( method )  )  ;", "stream . print (  \"  ]  (  \"  )  ;", "boolean   first    =    true ;", "for    ( Class <  ?  >    arg    :    method . arguments )     {", "if    ( first )     {", "first    =    false ;", "} else    {", "stream . print (  \"  ,     \"  )  ;", "}", ". emitType ( stream ,     . definition . ClassToType ( arg )  )  ;", "}", "stream . print (  \"  )  +  +  \"  )  ;", "if    ( equals (  \" java 8  \"  )  )     {", "stream . print (  \"     (  \"  )  ;", ". emitJavadocLink ( stream ,     \" java 9  \"  ,    method )  ;", "stream . print (  \"  [ java    9  ]  )  \"  )  ;", "}", "stream . println (  )  ;", "}", "METHOD_END"], "methodName": ["documentMethod"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "PainlessDocGenerator . emitAnchor ( stream ,    field . owner )  ;", "stream . print (  '  -  '  )  ;", "stream . print ( field . name )  ;", "}", "METHOD_END"], "methodName": ["emitAnchor"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "PainlessDocGenerator . emitAnchor ( stream ,    method . owner )  ;", "stream . print (  '  -  '  )  ;", "stream . print ( PainlessDocGenerator . methodName ( method )  )  ;", "stream . print (  '  -  '  )  ;", "stream . print ( method . arguments . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["emitAnchor"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "stream . print (  \" painless - api - reference -  \"  )  ;", "stream . print ( struct . name . replace (  '  .  '  ,     '  -  '  )  )  ;", "}", "METHOD_END"], "methodName": ["emitAnchor"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "stream . println (  \"  /  /  /  /  \"  )  ;", "stream . println (  \" Automatically   generated   by    .    Do   not   edit .  \"  )  ;", "stream . println (  \" Rebuild   by   running    ` gradle   generatePainlessApi `  .  \"  )  ;", "stream . println (  \"  /  /  /  /  \"  )  ;", "stream . println (  )  ;", "}", "METHOD_END"], "methodName": ["emitGeneratedWarning"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "stream . print (  \" link :  {  \"  )  ;", "stream . print ( root )  ;", "stream . print (  \"  - javadoc }  /  \"  )  ;", "stream . print (  . classUrlPath ( field . owner . clazz )  )  ;", "stream . print (  \"  . html #  \"  )  ;", "stream . print ( field . javaName )  ;", "}", "METHOD_END"], "methodName": ["emitJavadocLink"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "stream . print (  \" link :  {  \"  )  ;", "stream . print ( root )  ;", "stream . print (  \"  - javadoc }  /  \"  )  ;", "stream . print (  . classUrlPath (  (  ( method . augmentation )     !  =    null    ?    method . augmentation    :    method . owner . clazz )  )  )  ;", "stream . print (  \"  . html #  \"  )  ;", "stream . print (  . methodName ( method )  )  ;", "stream . print (  \"  %  2 D \"  )  ;", "boolean   first    =    true ;", "if    (  ( method . augmentation )     !  =    null )     {", "first    =    false ;", "stream . print ( method . owner . clazz . getName (  )  )  ;", "}", "for    ( Class <  ?  >    clazz    :    method . arguments )     {", "Definition . Type   arg    =     . definition . ClassToType ( clazz )  ;", "if    ( first )     {", "first    =    false ;", "} else    {", "stream . print (  \"  %  2 D \"  )  ;", "}", "stream . print ( arg . struct . clazz . getName (  )  )  ;", "if    (  ( arg . dimensions )     >     0  )     {", "stream . print (  \"  : A \"  )  ;", "}", "}", "stream . print (  \"  %  2 D \"  )  ;", "}", "METHOD_END"], "methodName": ["emitJavadocLink"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "if    (  ( false    =  =     ( struct . clazz . isPrimitive (  )  )  )     &  &     ( false    =  =     ( struct . name . equals (  \" def \"  )  )  )  )     {", "stream . print (  \"  <  <  \"  )  ;", ". emitAnchor ( stream ,    struct )  ;", "stream . print (  '  ,  '  )  ;", "stream . print ( struct . name )  ;", "stream . print (  \"  >  >  \"  )  ;", "} else    {", "stream . print ( struct . name )  ;", "}", "}", "METHOD_END"], "methodName": ["emitStruct"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "PainlessDocGenerator . emitStruct ( stream ,    type . struct )  ;", "for    ( int   i    =     0  ;    i    <     ( type . dimensions )  ;    i +  +  )     {", "stream . print (  \"  [  ]  \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["emitType"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "return   PainlessDocGenerator . javadocRoot ( field . owner )  ;", "}", "METHOD_END"], "methodName": ["javadocRoot"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "if    (  ( method . augmentation )     !  =    null )     {", "return    \" painless \"  ;", "}", "return    . javadocRoot ( method . owner )  ;", "}", "METHOD_END"], "methodName": ["javadocRoot"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "String   classPackage    =    struct . clazz . getPackage (  )  . getName (  )  ;", "if    ( classPackage . startsWith (  \" java \"  )  )     {", "return    \" java 8  \"  ;", "}", "if    ( classPackage . startsWith (  \"  \"  )  )     {", "return    \" painless \"  ;", "}", "if    ( classPackage . startsWith (  \" elasticsearch \"  )  )     {", "return    \" elasticsearch \"  ;", "}", "if    ( classPackage . startsWith (  \" time \"  )  )     {", "return    \" joda - time \"  ;", "}", "if    ( classPackage . startsWith (  \" lucene \"  )  )     {", "return    \" lucene - core \"  ;", "}", "throw   new   IllegalArgumentException (  (  \" Unrecognized   packge :     \"     +    classPackage )  )  ;", "}", "METHOD_END"], "methodName": ["javadocRoot"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "Path   apiRootPath    =    PathUtils . get ( args [  0  ]  )  ;", "IOUtils . rm ( apiRootPath )  ;", "Files . createDirectories ( apiRootPath )  ;", "Path   indexPath    =    apiRootPath . resolve (  \" index . asciidoc \"  )  ;", ". logger . info (  \" Starting   to   write    [ index . asciidoc ]  \"  )  ;", "try    ( PrintStream   indexStream    =    new   PrintStream ( Files . newOutputStream ( indexPath ,    StandardOpenOption . CREATE _ NEW ,    StandardOpenOption . WRITE )  ,    false ,    StandardCharsets . UTF _  8  . name (  )  )  )     {", ". emitGeneratedWarning ( indexStream )  ;", "List < Definition . Type >    types    =     . definition . allSimpleTypes (  )  . stream (  )  . sorted ( Comparator . comparing (  (    t )     -  >    t . name )  )  . collect ( Collectors . toList (  )  )  ;", "for    ( Definition . Type   type    :    types )     {", "if    ( type . clazz . isPrimitive (  )  )     {", "continue ;", "}", "if    (  \" def \"  . equals ( type . name )  )     {", "continue ;", "}", "indexStream . print (  \" include :  :  \"  )  ;", "indexStream . print ( type . struct . name )  ;", "indexStream . println (  \"  . asciidoc [  ]  \"  )  ;", "Path   typePath    =    apiRootPath . resolve (  (  ( type . struct . name )     +     \"  . asciidoc \"  )  )  ;", ". logger . info (  \" Writing    [  {  }  . asciidoc ]  \"  ,    type . name )  ;", "try    ( PrintStream   typeStream    =    new   PrintStream ( Files . newOutputStream ( typePath ,    StandardOpenOption . CREATE _ NEW ,    StandardOpenOption . WRITE )  ,    false ,    StandardCharsets . UTF _  8  . name (  )  )  )     {", ". emitGeneratedWarning ( typeStream )  ;", "typeStream . print (  \"  [  [  \"  )  ;", ". emitAnchor ( typeStream ,    type . struct )  ;", "typeStream . print (  \"  ]  ]  +  +  \"  )  ;", "typeStream . print ( type . name )  ;", "typeStream . println (  \"  +  +  :  :  \"  )  ;", "Consumer < Definition . Field >    documentField    =     (    field )     -  >     . documentField ( typeStream ,    field )  ;", "Consumer < Definition . Method >    documentMethod    =     (    method )     -  >     . documentMethod ( typeStream ,    method )  ;", "type . struct . staticMembers . values (  )  . stream (  )  . sorted (  . FIELD _ NAME )  . forEach ( documentField )  ;", "type . struct . members . values (  )  . stream (  )  . sorted (  . FIELD _ NAME )  . forEach ( documentField )  ;", "type . struct . staticMethods . values (  )  . stream (  )  . sorted (  . METHOD _ NAME . thenComparing (  . NUMBER _ OF _ ARGS )  )  . forEach ( documentMethod )  ;", "type . struct . constructors . values (  )  . stream (  )  . sorted (  . NUMBER _ OF _ ARGS )  . forEach ( documentMethod )  ;", "Map < String ,    Definition . Struct >    inherited    =    new   TreeMap <  >  (  )  ;", "type . struct . methods . values (  )  . stream (  )  . sorted (  . METHOD _ NAME . thenComparing (  . NUMBER _ OF _ ARGS )  )  . forEach (  (    method )     -  >     {", "if    (  ( method . owner )     =  =     ( type . struct )  )     {", ". documentMethod ( typeStream ,    method )  ;", "} else    {", "inherited . put ( method . owner . name ,    method . owner )  ;", "}", "}  )  ;", "if    ( false    =  =     ( inherited . isEmpty (  )  )  )     {", "typeStream . print (  \"  *    Inherits   methods   from    \"  )  ;", "boolean   first    =    true ;", "for    ( Definition . Struct   inheritsFrom    :    inherited . values (  )  )     {", "if    ( first )     {", "first    =    false ;", "} else    {", "typeStream . print (  \"  ,     \"  )  ;", "}", "typeStream . print (  \"  +  +  \"  )  ;", ". emitStruct ( typeStream ,    inheritsFrom )  ;", "typeStream . print (  \"  +  +  \"  )  ;", "}", "typeStream . println (  )  ;", "}", "}", "}", "}", ". logger . info (  \" Done   writing    [ index . asciidoc ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["main"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "return   method . name . equals (  \"  < init >  \"  )     ?    method . owner . name    :    method . name ;", "}", "METHOD_END"], "methodName": ["methodName"], "fileName": "org.elasticsearch.painless.PainlessDocGenerator"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    List < String >  >    headers    =    new   TreeMap <  >  (  )  ;", "String   toString    =     \" null \"  ;", "String   javaClassName    =    null ;", "StringClassName    =    null ;", "if    (  ( objectToExplain )     !  =    null )     {", "toString    =    objectToExplain . toString (  )  ;", "javaClassName    =    objectToExplain . getClass (  )  . getName (  )  ;", "Definition . Struct   struct    =    definition . ClassToType ( objectToExplain . getClass (  )  )  . struct ;", "if    ( struct    !  =    null )     {", "ClassName    =    struct . name ;", "}", "}", "headers . put (  \" es . to _ string \"  ,    Collections . singletonList ( toString )  )  ;", "if   ClassName    !  =    null )     {", "headers . put (  \" es _ class \"  ,    Collections . singletonListClassName )  )  ;", "}", "if    ( javaClassName    !  =    null )     {", "headers . put (  \" es . java _ class \"  ,    Collections . singletonList ( javaClassName )  )  ;", "}", "return   headers ;", "}", "METHOD_END"], "methodName": ["getHeaders"], "fileName": "org.elasticsearch.painless.PainlessExplainError"}, {"methodBody": ["METHOD_START", "{", "return   objectToExplain ;", "}", "METHOD_END"], "methodName": ["getObjectToExplain"], "fileName": "org.elasticsearch.painless.PainlessExplainError"}, {"methodBody": ["METHOD_START", "{", "List < String >    scriptStack    =    new   ArrayList <  >  (  )  ;", "for    ( StackTraceElement   element    :    t . getStackTrace (  )  )     {", "if    ( WriterConstants . CLASS _ NAME . equals ( element . getClassName (  )  )  )     {", "int   offset    =    element . getLineNumber (  )  ;", "if    ( offset    =  =     (  -  1  )  )     {", "scriptStack . add (  \"  <  <  <    unknown   portion   of   script    >  >  >  \"  )  ;", "} else    {", "offset -  -  ;", "int   startOffset    =    getPreviousStatement ( offset )  ;", "if    ( startOffset    =  =     (  -  1  )  )     {", "assert   false ;", "startOffset    =     0  ;", "}", "int   endOffset    =    getNextStatement ( startOffset )  ;", "if    ( endOffset    =  =     (  -  1  )  )     {", "endOffset    =    getSource (  )  . length (  )  ;", "}", "String   snippet    =    getSource (  )  . substring ( startOffset ,    endOffset )  ;", "scriptStack . add ( snippet )  ;", "StringBuilder   pointer    =    new   StringBuilder (  )  ;", "for    ( int   i    =    startOffset ;    i    <    offset ;    i +  +  )     {", "pointer . append (  '     '  )  ;", "}", "pointer . append (  \"  ^  -  -  -  -    HERE \"  )  ;", "scriptStack . add ( pointer . toString (  )  )  ;", "}", "break ;", "} else", "if    (  !  ( shouldFilter ( element )  )  )     {", "scriptStack . add ( element . toString (  )  )  ;", "}", "}", "ScriptException   scriptException    =    new   ScriptException (  \" runtime   error \"  ,    t ,    scriptStack ,    getName (  )  ,    Engine . NAME )  ;", "for    ( Map . Entry < String ,    List < String >  >    entry    :    extraMetadata . entrySet (  )  )     {", "scriptException . addMetadata ( entry . getKey (  )  ,    entry . getValue (  )  )  ;", "}", "return   scriptException ;", "}", "METHOD_END"], "methodName": ["convertToScriptException"], "fileName": "org.elasticsearch.painless.PainlessScript"}, {"methodBody": ["METHOD_START", "{", "return   getStatements (  )  . nextSetBit (  ( offset    +     1  )  )  ;", "}", "METHOD_END"], "methodName": ["getNextStatement"], "fileName": "org.elasticsearch.painless.PainlessScript"}, {"methodBody": ["METHOD_START", "{", "return   getStatements (  )  . previousSetBit ( offset )  ;", "}", "METHOD_END"], "methodName": ["getPreviousStatement"], "fileName": "org.elasticsearch.painless.PainlessScript"}, {"methodBody": ["METHOD_START", "{", "return    (  ( element . getClassName (  )  . startsWith (  \" \"  )  )     |  |     ( element . getClassName (  )  . startsWith (  \" \"  )  )  )     |  |     ( element . getClassName (  )  . startsWith (  \" sun . invoke .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["shouldFilter"], "fileName": "org.elasticsearch.painless.PainlessScript"}, {"methodBody": ["METHOD_START", "{", "final   CompilerSettings   compilerSettings ;", "if    ( params . isEmpty (  )  )     {", "compilerSettings    =    defaultCompilerSettings ;", "} else    {", "compilerSettings    =    new   CompilerSettings (  )  ;", "compilerSettings . setRegexesEnabled ( defaultCompilerSettings . areRegexesEnabled (  )  )  ;", "Map < String ,    String >    copy    =    new   HashMap <  >  ( params )  ;", "String   value    =    copy . remove ( CompilerSettings . MAX _ LOOP _ COUNTER )  ;", "if    ( value    !  =    null )     {", "compilerSettings . setMaxLoopCounter ( Integer . parseInt ( value )  )  ;", "}", "value    =    copy . remove ( CompilerSettings . PICKY )  ;", "if    ( value    !  =    null )     {", "compilerSettings . setPicky ( Boolean . parseBoolean ( value )  )  ;", "}", "value    =    copy . remove ( CompilerSettings . INITIAL _ CALL _ SITE _ DEPTH )  ;", "if    ( value    !  =    null )     {", "compilerSettings . setInitialCallSiteDepth ( Integer . parseInt ( value )  )  ;", "}", "value    =    copy . remove ( CompilerSettings . REGEX _ ENABLED . getKey (  )  )  ;", "if    ( value    !  =    null )     {", "throw   new   IllegalArgumentException (  \"  [ painless . regex . enabled ]    can   only   be   set   on   node   startup .  \"  )  ;", "}", "if    (  !  ( copy . isEmpty (  )  )  )     {", "throw   new   IllegalArgumentException (  (  \" Unrecognized   compile - time   parameter ( s )  :     \"     +    copy )  )  ;", "}", "}", "SpecialPermission . check (  )  ;", "final   Compiler . Loader   loader    =    AccessController . doPrivileged ( new   PrivilegedAction < Compiler . Loader >  (  )     {", "@ Override", "public   Compiler . Loader   run (  )     {", "return   compiler . createLoader ( getClass (  )  . getClassLoader (  )  )  ;", "}", "}  )  ;", "try    {", "return   AccessController . doPrivileged ( new   PrivilegedAction < Object >  (  )     {", "@ Override", "public   Object   run (  )     {", "String   name    =     ( scriptName    =  =    null )     ?    source    :    scriptName ;", "Constructor <  ?  >    constructor    =    compiler . compile ( loader ,    new   SSource . MainMethodReserved (  )  ,    name ,    source ,    compilerSettings )  ;", "try    {", "return   constructor . newInstance ( args )  ;", "}    catch    ( Exception   exception )     {", "throw   new   IllegalStateException (  (  (  \" An   internal   error   occurred   attempting   to   define   the   script    [  \"     +    name )     +     \"  ]  .  \"  )  ,    exception )  ;", "}", "}", "}  ,     . COMPILATION _ CONTEXT )  ;", "}    catch    ( OutOfMemoryError    |    StackOverflowError    |    VerifyError    |    Exception   e )     {", "throw   convertToScriptException (  ( scriptName    =  =    null    ?    source    :    scriptName )  ,    source ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["compile"], "fileName": "org.elasticsearch.painless.PainlessScriptEngine"}, {"methodBody": ["METHOD_START", "{", "final   CompilerSettings   compilerSettings ;", "if    ( params . isEmpty (  )  )     {", "compilerSettings    =    defaultCompilerSettings ;", "} else    {", "compilerSettings    =    new   CompilerSettings (  )  ;", "compilerSettings . setRegexesEnabled ( defaultCompilerSettings . areRegexesEnabled (  )  )  ;", "Map < String ,    String >    copy    =    new   HashMap <  >  ( params )  ;", "String   value    =    copy . remove ( CompilerSettings . MAX _ LOOP _ COUNTER )  ;", "if    ( value    !  =    null )     {", "compilerSettings . setMaxLoopCounter ( Integer . parseInt ( value )  )  ;", "}", "value    =    copy . remove ( CompilerSettings . PICKY )  ;", "if    ( value    !  =    null )     {", "compilerSettings . setPicky ( Boolean . parseBoolean ( value )  )  ;", "}", "value    =    copy . remove ( CompilerSettings . INITIAL _ CALL _ SITE _ DEPTH )  ;", "if    ( value    !  =    null )     {", "compilerSettings . setInitialCallSiteDepth ( Integer . parseInt ( value )  )  ;", "}", "value    =    copy . remove ( CompilerSettings . REGEX _ ENABLED . getKey (  )  )  ;", "if    ( value    !  =    null )     {", "throw   new   IllegalArgumentException (  \"  [ painless . regex . enabled ]    can   only   be   set   on   node   startup .  \"  )  ;", "}", "if    (  !  ( copy . isEmpty (  )  )  )     {", "throw   new   IllegalArgumentException (  (  \" Unrecognized   compile - time   parameter ( s )  :     \"     +    copy )  )  ;", "}", "}", "try    {", "AccessController . doPrivileged ( new   PrivilegedAction < Void >  (  )     {", "@ Override", "public   Void   run (  )     {", "String   name    =     ( scriptName    =  =    null )     ?    source    :    scriptName ;", "compiler . compile ( loader ,    reserved ,    name ,    source ,    compilerSettings )  ;", "return   null ;", "}", "}  ,     . COMPILATION _ CONTEXT )  ;", "}    catch    ( OutOfMemoryError    |    StackOverflowError    |    VerifyError    |    Exception   e )     {", "throw   convertToScriptException (  ( scriptName    =  =    null    ?    source    :    scriptName )  ,    source ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["compile"], "fileName": "org.elasticsearch.painless.PainlessScriptEngine"}, {"methodBody": ["METHOD_START", "{", "List < String >    scriptStack    =    new   ArrayList <  >  (  )  ;", "for    ( StackTraceElement   element    :    t . getStackTrace (  )  )     {", "if    ( WriterConstants . CLASS _ NAME . equals ( element . getClassName (  )  )  )     {", "int   offset    =    element . getLineNumber (  )  ;", "if    ( offset    =  =     (  -  1  )  )     {", "scriptStack . add (  \"  <  <  <    unknown   portion   of   script    >  >  >  \"  )  ;", "} else    {", "offset -  -  ;", "int   startOffset    =    getPreviousStatement ( scriptSource ,    offset )  ;", "int   endOffset    =    getNextStatement ( scriptSource ,    offset )  ;", "StringBuilder   snippet    =    new   StringBuilder (  )  ;", "if    ( startOffset    >     0  )     {", "snippet . append (  \"  .  .  .     \"  )  ;", "}", "snippet . append ( scriptSource . substring ( startOffset ,    endOffset )  )  ;", "if    ( endOffset    <     ( scriptSource . length (  )  )  )     {", "snippet . append (  \"     .  .  .  \"  )  ;", "}", "scriptStack . add ( snippet . toString (  )  )  ;", "StringBuilder   pointer    =    new   StringBuilder (  )  ;", "if    ( startOffset    >     0  )     {", "pointer . append (  \"              \"  )  ;", "}", "for    ( int   i    =    startOffset ;    i    <    offset ;    i +  +  )     {", "pointer . append (  '     '  )  ;", "}", "pointer . append (  \"  ^  -  -  -  -    HERE \"  )  ;", "scriptStack . add ( pointer . toString (  )  )  ;", "}", "break ;", "}", "}", "throw   new   ScriptException (  \" compile   error \"  ,    t ,    scriptStack ,    scriptSource ,     . NAME )  ;", "}", "METHOD_END"], "methodName": ["convertToScriptException"], "fileName": "org.elasticsearch.painless.PainlessScriptEngine"}, {"methodBody": ["METHOD_START", "{", "int   classFrames    =     ( ClassWriter . COMPUTE _ FRAMES )     |     ( ClassWriter . COMPUTE _ MAXS )  ;", "int   classAccess    =     (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ SUPER )  )     |     ( Opcodes . ACC _ FINAL )  ;", "String   interfaceBase    =    Type . getType ( context . factoryClazz )  . getInternalName (  )  ;", "String   className    =    interfaceBase    +     \"  $ Factory \"  ;", "String [  ]    classInterfaces    =    new   String [  ]  {    interfaceBase    }  ;", "ClassWriter   writer    =    new   ClassWriter ( classFrames )  ;", "writer . visit ( WriterConstants . CLASS _ VERSION ,    classAccess ,    className ,    null ,    WriterConstants . OBJECT _ TYPE . getInternalName (  )  ,    classInterfaces )  ;", "Method   init    =    new   Method (  \"  < init >  \"  ,    MethodType . methodType ( void . class )  . toMethodDesorString (  )  )  ;", "GeneratorAdapter   constructor    =    new   GeneratorAdapter ( Opcodes . ASM 5  ,    init ,    writer . visitMethod ( ACC _ PUBLIC ,    init . getName (  )  ,    init . getDesor (  )  ,    null ,    null )  )  ;", "constructor . visitCode (  )  ;", "constructor . loadThis (  )  ;", "constructor . invokeConstructor ( WriterConstants . OBJECT _ TYPE ,    init )  ;", "constructor . returnValue (  )  ;", "constructor . endMethod (  )  ;", "Method   reflect    =    null ;", "for    ( Method   method    :    context . factoryClazz . getMethods (  )  )     {", "if    (  \" newInstance \"  . equals ( method . getName (  )  )  )     {", "reflect    =    method ;", "break ;", "} else", "if    (  \" newFactory \"  . equals ( method . getName (  )  )  )     {", "reflect    =    method ;", "break ;", "}", "}", "Method   instance    =    new   Method ( reflect . getName (  )  ,    MethodType . methodType ( reflect . getReturnType (  )  ,    reflect . getParameterTypes (  )  )  . toMethodDesorString (  )  )  ;", "Method   constru    =    new   Method (  \"  < init >  \"  ,    MethodType . methodType ( void . class ,    reflect . getParameterTypes (  )  )  . toMethodDesorString (  )  )  ;", "GeneratorAdapter   adapter    =    new   GeneratorAdapter ( Opcodes . ASM 5  ,    instance ,    writer . visitMethod (  (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ FINAL )  )  ,    instance . getName (  )  ,    instance . getDesor (  )  ,    null ,    null )  )  ;", "adapter . visitCode (  )  ;", "adapter . newInstance ( classType )  ;", "adapter . dup (  )  ;", "adapter . loadArgs (  )  ;", "adapter . invokeConstructor ( classType ,    constru )  ;", "adapter . returnValue (  )  ;", "adapter . endMethod (  )  ;", "writeNeedsMethods ( context . factoryClazz ,    writer ,    reserved )  ;", "writer . visitEnd (  )  ;", "Class <  ?  >    factory    =    loader . defineFactory ( className . replace (  '  /  '  ,     '  .  '  )  ,    writer . toByteArray (  )  )  ;", "try    {", "return   context . factoryClazz . cast ( factory . getConstructor (  )  . newInstance (  )  )  ;", "}    catch    ( Exception   exception )     {", "throw   new   IllegalStateException (  (  (  \" An   internal   error   occurred   attempting   to   define   the   factory   class    [  \"     +    className )     +     \"  ]  .  \"  )  ,    exception )  ;", "}", "}", "METHOD_END"], "methodName": ["generateFactory"], "fileName": "org.elasticsearch.painless.PainlessScriptEngine"}, {"methodBody": ["METHOD_START", "{", "int   classFrames    =     ( ClassWriter . COMPUTE _ FRAMES )     |     ( ClassWriter . COMPUTE _ MAXS )  ;", "int   classAccess    =     (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ SUPER )  )     |     ( Opcodes . ACC _ FINAL )  ;", "String   interfaceBase    =    Type . getType ( context . statefulFactoryClazz )  . getInternalName (  )  ;", "String   className    =    interfaceBase    +     \"  $ StatefulFactory \"  ;", "String [  ]    classInterfaces    =    new   String [  ]  {    interfaceBase    }  ;", "ClassWriter   writer    =    new   ClassWriter ( classFrames )  ;", "writer . visit ( WriterConstants . CLASS _ VERSION ,    classAccess ,    className ,    null ,    WriterConstants . OBJECT _ TYPE . getInternalName (  )  ,    classInterfaces )  ;", "Method   newFactory    =    null ;", "for    ( Method   method    :    context . factoryClazz . getMethods (  )  )     {", "if    (  \" newFactory \"  . equals ( method . getName (  )  )  )     {", "newFactory    =    method ;", "break ;", "}", "}", "for    ( int   count    =     0  ;    count    <     ( newFactory . getParameterTypes (  )  . length )  ;     +  + count )     {", "writer . visitField (  (  ( Opcodes . ACC _ PRIVATE )     |     ( Opcodes . ACC _ FINAL )  )  ,     (  \"  $ arg \"     +    count )  ,    Type . getType ( newFactory . getParameterTypes (  )  [ count ]  )  . getDesor (  )  ,    null ,    null )  . visitEnd (  )  ;", "}", "Method   base    =    new   Method (  \"  < init >  \"  ,    MethodType . methodType ( void . class )  . toMethodDesorString (  )  )  ;", "Method   init    =    new   Method (  \"  < init >  \"  ,    MethodType . methodType ( void . class ,    newFactory . getParameterTypes (  )  )  . toMethodDesorString (  )  )  ;", "GeneratorAdapter   constructor    =    new   GeneratorAdapter ( Opcodes . ASM 5  ,    init ,    writer . visitMethod ( ACC _ PUBLIC ,    init . getName (  )  ,    init . getDesor (  )  ,    null ,    null )  )  ;", "constructor . visitCode (  )  ;", "constructor . loadThis (  )  ;", "constructor . invokeConstructor ( WriterConstants . OBJECT _ TYPE ,    base )  ;", "for    ( int   count    =     0  ;    count    <     ( newFactory . getParameterTypes (  )  . length )  ;     +  + count )     {", "constructor . loadThis (  )  ;", "constructor . loadArg ( count )  ;", "constructor . putField ( Type . getType ( className )  ,     (  \"  $ arg \"     +    count )  ,    Type . getType ( newFactory . getParameterTypes (  )  [ count ]  )  )  ;", "}", "constructor . returnValue (  )  ;", "constructor . endMethod (  )  ;", "Method   newInstance    =    null ;", "for    ( Method   method    :    context . statefulFactoryClazz . getMethods (  )  )     {", "if    (  \" newInstance \"  . equals ( method . getName (  )  )  )     {", "newInstance    =    method ;", "break ;", "}", "}", "Method   instance    =    new   Method ( newInstance . getName (  )  ,    MethodType . methodType ( newInstance . getReturnType (  )  ,    newInstance . getParameterTypes (  )  )  . toMethodDesorString (  )  )  ;", "List < Class <  ?  >  >    parameters    =    new   ArrayList <  >  ( Arrays . asList ( newFactory . getParameterTypes (  )  )  )  ;", "parameters . addAll ( Arrays . asList ( newInstance . getParameterTypes (  )  )  )  ;", "Method   constru    =    new   Method (  \"  < init >  \"  ,    MethodType . methodType ( void . class ,    parameters . toArray ( new   Class <  ?  >  [  ]  {        }  )  )  . toMethodDesorString (  )  )  ;", "GeneratorAdapter   adapter    =    new   GeneratorAdapter ( Opcodes . ASM 5  ,    instance ,    writer . visitMethod (  (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ FINAL )  )  ,    instance . getName (  )  ,    instance . getDesor (  )  ,    null ,    null )  )  ;", "adapter . visitCode (  )  ;", "adapter . newInstance ( WriterConstants . CLASS _ TYPE )  ;", "adapter . dup (  )  ;", "for    ( int   count    =     0  ;    count    <     ( newFactory . getParameterTypes (  )  . length )  ;     +  + count )     {", "adapter . loadThis (  )  ;", "adapter . getField ( Type . getType ( className )  ,     (  \"  $ arg \"     +    count )  ,    Type . getType ( newFactory . getParameterTypes (  )  [ count ]  )  )  ;", "}", "adapter . loadArgs (  )  ;", "adapter . invokeConstructor ( WriterConstants . CLASS _ TYPE ,    constru )  ;", "adapter . returnValue (  )  ;", "adapter . endMethod (  )  ;", "writeNeedsMethods ( context . statefulFactoryClazz ,    writer ,    reserved )  ;", "writer . visitEnd (  )  ;", "loader . defineFactory ( className . replace (  '  /  '  ,     '  .  '  )  ,    writer . toByteArray (  )  )  ;", "return   Type . getType ( className )  ;", "}", "METHOD_END"], "methodName": ["generateStatefulFactory"], "fileName": "org.elasticsearch.painless.PainlessScriptEngine"}, {"methodBody": ["METHOD_START", "{", "return   Math . min ( scriptSource . length (  )  ,     ( offset    +     2  5  )  )  ;", "}", "METHOD_END"], "methodName": ["getNextStatement"], "fileName": "org.elasticsearch.painless.PainlessScriptEngine"}, {"methodBody": ["METHOD_START", "{", "return   Math . max (  0  ,     ( offset    -     2  5  )  )  ;", "}", "METHOD_END"], "methodName": ["getPreviousStatement"], "fileName": "org.elasticsearch.painless.PainlessScriptEngine"}, {"methodBody": ["METHOD_START", "{", "for    ( Method   method    :    clazz . getMethods (  )  )     {", "if    (  (  ( method . getName (  )  . startsWith (  \" needs \"  )  )     &  &     ( method . getReturnType (  )  . equals ( boolean . class )  )  )     &  &     (  ( method . getParameterTypes (  )  . length )     =  =     0  )  )     {", "String   name    =    method . getName (  )  ;", "name    =    name . substring (  5  )  ;", "name    =     ( Character . toLowerCase ( name . charAt (  0  )  )  )     +     ( name . substring (  1  )  )  ;", "Method   needs    =    new   Method ( method . getName (  )  ,    MethodType . methodType ( boolean . class )  . toMethodDesorString (  )  )  ;", "GeneratorAdapter   adapter    =    new   GeneratorAdapter ( Opcodes . ASM 5  ,    needs ,    writer . visitMethod ( ACC _ PUBLIC ,    needs . getName (  )  ,    needs . getDesor (  )  ,    null ,    null )  )  ;", "adapter . visitCode (  )  ;", "adapter . push ( reserved . getUsedVariables (  )  . contains ( name )  )  ;", "adapter . returnValue (  )  ;", "adapter . endMethod (  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["writeNeedsMethods"], "fileName": "org.elasticsearch.painless.PainlessScriptEngine"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" int   x ;     '  3  '     =  =     ( x    =     3  )  . toString (  )  \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" int   x ;     ( x    =     3  )  . compareTo (  4  )  \"  )  )  ;", "assertEquals (  3 L ,    exec (  \" long [  ]    x ;     ( x    =    new   long [  1  ]  )  [  0  ]     =     3  ;    return   x [  0  ]  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x ;     (  ( x )  )     =     2  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAssignmentPostfixes"], "fileName": "org.elasticsearch.painless.PostfixTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  5  \"  ,    exec (  \" boolean   b    =    false ;     ( b    ?     4     :     5  )  . toString (  )  \"  )  )  ;", "assertEquals (  3  ,    exec (  (  \" Map   x    =    new   HashMap (  )  ;    x [  ' t '  ]     =     3  ;  \"     +     (  (  \" Map   y    =    new   HashMap (  )  ;    y [  ' t '  ]     =     4  ;  \"     +     \" boolean   b    =    true ;  \"  )     +     \" return    ( int )  ( b    ?    x    :    y )  . get (  ' t '  )  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testConditionalPostfixes"], "fileName": "org.elasticsearch.painless.PostfixTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  2  \"  ,    exec (  \"  2  . toString (  )  \"  )  )  ;", "assertEquals (  4  ,    exec (  \"  [  1  ,     2  ,     3  ,     4  ,     5  ]  [  3  ]  \"  )  )  ;", "assertEquals (  \"  4  \"  ,    exec (  \"  [  1  ,     2  ,     3  ,     4  ,     5  ]  [  3  ]  . toString (  )  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" new   int [  ]     {  1  ,     2  ,     3  ,     4  ,     5  }  [  2  ]  \"  )  )  ;", "assertEquals (  \"  4  \"  ,    exec (  \"  (  2     +     2  )  . toString (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testConstantPostfixes"], "fileName": "org.elasticsearch.painless.PostfixTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   x ;     '  3  '     =  =     ( x    =     3  )  . toString (  )  \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" def   x ;     ( x    =     3  )  . compareTo (  4  )  \"  )  )  ;", "assertEquals (  3 L ,    exec (  \" def   x ;     ( x    =    new   long [  1  ]  )  [  0  ]     =     3  ;    return   x [  0  ]  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x ;     (  ( x )  )     =     2  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefAssignmentPostfixes"], "fileName": "org.elasticsearch.painless.PostfixTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  5  \"  ,    exec (  \" def   b    =    false ;     ( b    ?     4     :     5  )  . toString (  )  \"  )  )  ;", "assertEquals (  3  ,    exec (  (  \" def   x    =    new   HashMap (  )  ;    x [  ' t '  ]     =     3  ;  \"     +     (  (  \" def   y    =    new   HashMap (  )  ;    y [  ' t '  ]     =     4  ;  \"     +     \" boolean   b    =    true ;  \"  )     +     \" return    ( b    ?    x    :    y )  . get (  ' t '  )  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefConditionalPostfixes"], "fileName": "org.elasticsearch.painless.PostfixTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" byte   x    =     1  ;    char   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" byte   x    =     1  ;    short   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     1  )  ,    exec (  \" byte   x    =     1  ;    int   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     1 L )  ,    exec (  \" byte   x    =     1  ;    long   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     1  .  0 F )  ,    exec (  \" byte   x    =     1  ;    float   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     1  .  0  )  ,    exec (  \" byte   x    =     1  ;    double   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" char   x    =     1  ;    byte   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" char   x    =     1  ;    short   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     1  )  ,    exec (  \" char   x    =     1  ;    int   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     1 L )  ,    exec (  \" char   x    =     1  ;    long   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     1  .  0 F )  ,    exec (  \" char   x    =     1  ;    float   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     1  .  0  )  ,    exec (  \" char   x    =     1  ;    double   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" short   x    =     1  ;    byte   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" short   x    =     1  ;    char   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     1  )  ,    exec (  \" short   x    =     1  ;    int   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     1 L )  ,    exec (  \" short   x    =     1  ;    long   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     1  .  0 F )  ,    exec (  \" short   x    =     1  ;    float   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     1  .  0  )  ,    exec (  \" short   x    =     1  ;    double   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" int   x    =     1  ;    byte   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1     +     (  ( char )     (  1  )  )  )  ,    exec (  \" int   x    =     1  ;    char   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1     +     (  ( short )     (  1  )  )  )  ,    exec (  \" int   x    =     1  ;    short   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1     +     1  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1     +     1 L )  ,    exec (  \" int   x    =     1  ;    long   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1     +     1  .  0 F )  ,    exec (  \" int   x    =     1  ;    float   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1     +     1  .  0  )  ,    exec (  \" int   x    =     1  ;    double   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1 L    +     (  ( byte )     (  1  )  )  )  ,    exec (  \" long   x    =     1  ;    byte   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1 L    +     (  ( char )     (  1  )  )  )  ,    exec (  \" long   x    =     1  ;    char   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1 L    +     (  ( short )     (  1  )  )  )  ,    exec (  \" long   x    =     1  ;    short   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1 L    +     1  )  ,    exec (  \" long   x    =     1  ;    int   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1 L    +     1 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1 L    +     1  .  0 F )  ,    exec (  \" long   x    =     1  ;    float   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1 L    +     1  .  0  )  ,    exec (  \" long   x    =     1  ;    double   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     (  ( byte )     (  1  )  )  )  ,    exec (  \" float   x    =     1  ;    byte   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     (  ( char )     (  1  )  )  )  ,    exec (  \" float   x    =     1  ;    char   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     (  ( short )     (  1  )  )  )  ,    exec (  \" float   x    =     1  ;    short   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     1  )  ,    exec (  \" float   x    =     1  ;    int   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     1 L )  ,    exec (  \" float   x    =     1  ;    long   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     1  .  0 F )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     1  .  0  )  ,    exec (  \" float   x    =     1  ;    double   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" double   x    =     1  ;    byte   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     (  ( char )     (  1  )  )  )  ,    exec (  \" double   x    =     1  ;    char   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     (  ( short )     (  1  )  )  )  ,    exec (  \" double   x    =     1  ;    short   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     1  )  ,    exec (  \" double   x    =     1  ;    int   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     1 L )  ,    exec (  \" double   x    =     1  ;    long   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     1  .  0 F )  ,    exec (  \" double   x    =     1  ;    float   y    =     1  ;    return   x + y ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     1  .  0  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    return   x + y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryPromotion"], "fileName": "org.elasticsearch.painless.PromotionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    ( byte )  1     +     ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" return    ( byte )  1     +     ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" return    ( byte )  1     +     ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     1  )  ,    exec (  \" return    ( byte )  1     +     1  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     1 L )  ,    exec (  \" return    ( byte )  1     +     1 L ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     1  .  0 F )  ,    exec (  \" return    ( byte )  1     +     1 F ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     +     1  .  0  )  ,    exec (  \" return    ( byte )  1     +     1  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    ( char )  1     +     ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" return    ( char )  1     +     ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" return    ( char )  1     +     ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     1  )  ,    exec (  \" return    ( char )  1     +     1  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     1 L )  ,    exec (  \" return    ( char )  1     +     1 L ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     1  .  0 F )  ,    exec (  \" return    ( char )  1     +     1 F ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     +     1  .  0  )  ,    exec (  \" return    ( char )  1     +     1  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    ( short )  1     +     ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( char )     (  1  )  )  )  ,    exec (  \" return    ( short )  1     +     ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     (  ( short )     (  1  )  )  )  ,    exec (  \" return    ( short )  1     +     ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     1  )  ,    exec (  \" return    ( short )  1     +     1  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     1 L )  ,    exec (  \" return    ( short )  1     +     1 L ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     1  .  0 F )  ,    exec (  \" return    ( short )  1     +     1 F ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     +     1  .  0  )  ,    exec (  \" return    ( short )  1     +     1  .  0  ;  \"  )  )  ;", "assertEquals (  (  1     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    1     +     ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  1     +     (  ( char )     (  1  )  )  )  ,    exec (  \" return    1     +     ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  1     +     (  ( short )     (  1  )  )  )  ,    exec (  \" return    1     +     ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  1     +     1  )  ,    exec (  \" return    1     +     1  ;  \"  )  )  ;", "assertEquals (  (  1     +     1 L )  ,    exec (  \" return    1     +     1 L ;  \"  )  )  ;", "assertEquals (  (  1     +     1  .  0 F )  ,    exec (  \" return    1     +     1 F ;  \"  )  )  ;", "assertEquals (  (  1     +     1  .  0  )  ,    exec (  \" return    1     +     1  .  0  ;  \"  )  )  ;", "assertEquals (  (  1 L    +     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    1 L    +     ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  1 L    +     (  ( char )     (  1  )  )  )  ,    exec (  \" return    1 L    +     ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  1 L    +     (  ( short )     (  1  )  )  )  ,    exec (  \" return    1 L    +     ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  1 L    +     1  )  ,    exec (  \" return    1 L    +     1  ;  \"  )  )  ;", "assertEquals (  (  1 L    +     1 L )  ,    exec (  \" return    1 L    +     1 L ;  \"  )  )  ;", "assertEquals (  (  1 L    +     1  .  0 F )  ,    exec (  \" return    1 L    +     1 F ;  \"  )  )  ;", "assertEquals (  (  1 L    +     1  .  0  )  ,    exec (  \" return    1 L    +     1  .  0  ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    1 F    +     ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     (  ( char )     (  1  )  )  )  ,    exec (  \" return    1 F    +     ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     (  ( short )     (  1  )  )  )  ,    exec (  \" return    1 F    +     ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     1  )  ,    exec (  \" return    1 F    +     1  ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     1 L )  ,    exec (  \" return    1 F    +     1 L ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     1  .  0 F )  ,    exec (  \" return    1 F    +     1 F ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    +     1  .  0  )  ,    exec (  \" return    1 F    +     1  .  0  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    1  .  0     +     ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     (  ( char )     (  1  )  )  )  ,    exec (  \" return    1  .  0     +     ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     (  ( short )     (  1  )  )  )  ,    exec (  \" return    1  .  0     +     ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     1  )  ,    exec (  \" return    1  .  0     +     1  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     1 L )  ,    exec (  \" return    1  .  0     +     1 L ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     1  .  0 F )  ,    exec (  \" return    1  .  0     +     1 F ;  \"  )  )  ;", "assertEquals (  (  1  .  0     +     1  .  0  )  ,    exec (  \" return    1  .  0     +     1  .  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBinaryPromotionConst"], "fileName": "org.elasticsearch.painless.PromotionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \"  \\  '  \\  \\  \\  \\  \\  '     =  =  ~     /  \\  \\  \\  \\  /  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBackslashEscapeBackslash"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \"  \\  '  /  /  \\  '     =  =  ~     /  \\  \\  /  \\  \\  /  /  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBackslashEscapesForwardSlash"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "ScriptException   e    =    expectThrows ( ScriptException . class ,     (  )     -  >     {", "exec (  \"  /  \\  \\ ujjjj /  \"  )  ;", "}  )  ;", "assertEquals (  \" Error   compiling   r :    Illegal   Unicode   escape   sequence \"  ,    e . getCause (  )  . getMessage (  )  )  ;", "ScriptTestCase . assertScriptStack ( e ,     \"  /  \\  \\ ujjjj /  \"  ,     \"           ^  -  -  -  -    HERE \"  )  ;", "}", "METHOD_END"], "methodName": ["testBadRegexPattern"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \"  / asdf / b \"  ,    false )  ;", "}  )  ;", "assertEquals (  \" unexpected   token    [  ' b '  ]    was   expecting   one   of    [  {  < EOF >  ,     '  ;  '  }  ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBogusRegexFlag"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return    / foo /  . matcher (  ' foo '  )  . matches (  )  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    / foo /  . matcher (  ' bar '  )  . matches (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCallMatcherDirectly"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Pattern . CANON _ EQ ,    exec (  \"  /  .  / c . flags (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCanonicalEquivalenceFlag"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" Pattern . compile (  ' aa '  )  \"  )  ;", "}  )  ;", "assertEquals (  \" Unknown   call    [ compile ]    with    [  1  ]    arguments   on   type    [ Pattern ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCantUsePatternCompile"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Pattern . COMMENTS ,    exec (  \"  /  .  / x . flags (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtendedFlag"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return    ( boolean )  (  ' fooasdfbasdf '     =  ~     / foo /  )  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ( boolean )  (  '  1  1  1 fooasdfbasdf '     =  ~     / foo /  )  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ( boolean )  (  ' fo 1  1 oasdfbasdf '     =  ~     / foo /  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFindCastToBoolean"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" if    (  ' fooasdfbasdf '     =  ~     / foo /  )     { return   true }    else    { return   false }  \"  )  )  ;", "assertEquals ( true ,    exec (  \" if    (  '  1 fooasdfbasdf '     =  ~     / foo /  )     { return   true }    else    { return   false }  \"  )  )  ;", "assertEquals ( false ,    exec (  \" if    (  '  1 f 1  1 ooasdfbasdf '     =  ~     / foo /  )     { return   true }    else    { return   false }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFindInIf"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   s    =     ' foo '  ;    return   s    =  ~     / foo /  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFindOfDef"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return   params . s    =  ~     / foo /  \"  ,    Collections . singletonMap (  \" s \"  ,     \" fooasdfdf \"  )  ,    true )  )  ;", "assertEquals ( false ,    exec (  \" return   params . s    =  ~     / foo /  \"  ,    Collections . singletonMap (  \" s \"  ,     \"  1  1 f 2 ooasdfdf \"  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testFindOnInput"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return    ' f '     +     ' o '     +     ' o '     =  ~     / foo /  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFindOrStringConcat"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" foo \"  ,    exec (  \" Matcher   m    =     / foo /  . matcher (  ' foo '  )  ;    m . find (  )  ;    return   m . group (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testGroup"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return    / foo /  . matcher (  ' foo '  )  . matches (  )     ?    true    :    false \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   i    =     0  ;    i    +  =     / foo /  . matcher (  ' foo '  )  . matches (  )     ?     1     :     1  ;    return   i \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ' foo '     =  =  ~     / foo /     ?    true    :    false \"  )  )  ;", "assertEquals (  1  ,    exec (  \" def   i    =     0  ;    i    +  =     ' foo '     =  =  ~     / foo /     ?     1     :     1  ;    return   i \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInTernaryCondition"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   i    =    false ;    return   i    ?    false    :     ' foo '     =  =  ~     / foo /  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInTernaryFalseArm"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   i    =    true ;    return   i    ?     / foo /  . matcher (  ' foo '  )  . matches (  )     :    false \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   i    =    true ;    return   i    ?     ' foo '     =  =  ~     / foo /     :    false \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInTernaryTrueArm"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Pattern . CASE _ INSENSITIVE ,    exec (  \"  /  .  / i . flags (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInsensitiveFlag"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Pattern . LITERAL ,    exec (  \"  /  .  / l . flags (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLiteralFlag"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  (  ( Pattern . CANON _ EQ )     |     ( Pattern . CASE _ INSENSITIVE )  )     |     ( Pattern . UNICODE _ CASE )  )     |     ( Pattern . COMMENTS )  )  ,    exec (  \"  /  .  / ciux . flags (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testManyFlags"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Pattern . MULTILINE ,    exec (  \"  /  .  / m . flags (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultilineFlag"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" o \"  ,    exec (  \" Matcher   m    =     /  (  ?  < first > f )  (  ?  < second > o ) o /  . matcher (  ' foo '  )  ;    m . find (  )  ;    return   m . namedGroup (  ' second '  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNamedGroup"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" o \"  ,    exec (  \" Matcher   m    =     /  ( f )  ( o ) o /  . matcher (  ' foo '  )  ;    m . find (  )  ;    return   m . group (  2  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNumberedGroup"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   a    =     / foo /  ;    return    ' foo '     =  =  ~    a \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPatternAfterAssignment"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return   false    |  |     / foo /  . matcher (  ' foo '  )  . matches (  )  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return   true    &  &     / foo /  . matcher (  ' foo '  )  . matches (  )  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return   false    |  |     ' foo '     =  =  ~     / foo /  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return   true    &  &     ' foo '     =  =  ~     / foo /  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPatternAfterInfixBoolean"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" return    ' foo '     =  =  ~     / foo /  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ' bar '     =  =  ~     / foo /  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPatternAfterReturn"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" return    !  / foo /  . matcher (  ' foo '  )  . matches (  )  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    !  / foo /  . matcher (  ' bar '  )  . matches (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPatternAfterUnaryNotBoolean"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" if    (  / foo /  . matcher (  ' foo '  )  . matches (  )  )     {    return   true    }    else    {    return   false    }  \"  )  )  ;", "assertEquals ( true ,    exec (  \" if    (  ' foo '     =  =  ~     / foo /  )     {    return   true    }    else    {    return   false    }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPatternInIfStement"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "ClassCastException   e    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \"  1  2     =  =  ~     / cat /  \"  )  ;", "}  )  ;", "assertEquals (  \" Cannot   cast   from    [ int ]    to    [ String ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRegexAgainstNumber"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" boolean   m ( String   s )     {  / foo /  . matcher ( s )  . matches (  )  }    m (  ' foo '  )  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   m ( String   s )     { s    =  =  ~     / foo /  }    m (  ' foo '  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRegexInFunction"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" def   s    =     /  \\  \\  \\  \\  /  . split (  \\  '  .  \\  \\  \\  \\  .  \\  '  )  ;    return   s [  1  ]     =  =  ~     /  \\  \\  .  /  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRegexIsNonGreedy"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "CharSequence   charSequence    =    CharBuffer . wrap (  \" the   quick   brown   fox \"  )  ;", "assertEquals (  \" thE   qUIck   brOwn   fOx \"  ,    exec (  \" params . a . replaceAll (  /  [ aeiou ]  /  ,    m    -  >    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  ,    Collections . singletonMap (  \" a \"  ,    charSequence )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceAllMatchesCharSequence"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" thE   qUIck   brOwn   fOx \"  ,    exec (  \"  ' the   quick   brown   fox '  . replaceAll (  /  [ aeiou ]  /  ,    m    -  >    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceAllMatchesString"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "CharSequence   charSequence    =    CharBuffer . wrap (  \" i   am   cat \"  )  ;", "assertEquals (  \" i   am   cat \"  ,    exec (  \" params . a . replaceAll (  / dolphin /  ,    m    -  >    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  ,    Collections . singletonMap (  \" a \"  ,    charSequence )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceAllNoMatchCharSequence"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" i   am   cat \"  ,    exec (  \"  ' i   am   cat '  . replaceAll (  / dolphin /  ,    m    -  >    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceAllNoMatchString"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" th / E   q / U / Ick   br / Own   f / Ox \"  ,    exec (  \"  ' the   quick   brown   fox '  . replaceAll (  /  [ aeiou ]  /  ,    m    -  >     '  /  '     +    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  )  )  ;", "assertEquals (  \" th $ E   q $ U $ Ick   br $ Own   f $ Ox \"  ,    exec (  \"  ' the   quick   brown   fox '  . replaceAll (  /  [ aeiou ]  /  ,    m    -  >     '  $  '     +    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceAllQuoteReplacement"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "CharSequence   charSequence    =    CharBuffer . wrap (  \" the   quick   brown   fox \"  )  ;", "assertEquals (  \" thE   quick   brown   fox \"  ,    exec (  \" params . a . replaceFirst (  /  [ aeiou ]  /  ,    m    -  >    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  ,    Collections . singletonMap (  \" a \"  ,    charSequence )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceFirstMatchesCharSequence"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" thE   quick   brown   fox \"  ,    exec (  \"  ' the   quick   brown   fox '  . replaceFirst (  /  [ aeiou ]  /  ,    m    -  >    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceFirstMatchesString"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "CharSequence   charSequence    =    CharBuffer . wrap (  \" i   am   cat \"  )  ;", "assertEquals (  \" i   am   cat \"  ,    exec (  \" params . a . replaceFirst (  / dolphin /  ,    m    -  >    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  ,    Collections . singletonMap (  \" a \"  ,    charSequence )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceFirstNoMatchCharSequence"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" i   am   cat \"  ,    exec (  \"  ' i   am   cat '  . replaceFirst (  / dolphin /  ,    m    -  >    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceFirstNoMatchString"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" th / E   quick   brown   fox \"  ,    exec (  \"  ' the   quick   brown   fox '  . replaceFirst (  /  [ aeiou ]  /  ,    m    -  >     '  /  '     +    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  )  )  ;", "assertEquals (  \" th $ E   quick   brown   fox \"  ,    exec (  \"  ' the   quick   brown   fox '  . replaceFirst (  /  [ aeiou ]  /  ,    m    -  >     '  $  '     +    m . group (  )  . toUpperCase ( Locale . ROOT )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReplaceFirstQuoteReplacement"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( true ,    exec (  \" Pattern   m ( boolean   a )     { a    ?     / foo /     :     / bar /  }    m ( true )  . matcher (  ' foo '  )  . matches (  )  \"  )  )  ;", "assertEquals ( true ,    exec (  \" Pattern   m ( boolean   a )     { a    ?     / foo /     :     / bar /  }     ' foo '     =  =  ~    m ( true )  \"  )  )  ;", "assertEquals ( false ,    exec (  \" Pattern   m ( boolean   a )     { a    ?     / foo /     :     / bar /  }    m ( false )  . matcher (  ' foo '  )  . matches (  )  \"  )  )  ;", "assertEquals ( false ,    exec (  \" Pattern   m ( boolean   a )     { a    ?     / foo /     :     / bar /  }     ' foo '     =  =  ~    m ( false )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testReturnRegexFromFunction"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Pattern . DOTALL ,    exec (  \"  /  .  / s . flags (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSinglelineFlag"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertArrayEquals ( new   String [  ]  {     \" cat \"  ,     \" dog \"     }  ,     (  ( String [  ]  )     ( exec (  \"  /  ,  /  . split (  ' cat , dog '  )  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSplit"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( new   HashSet < String >  ( Arrays . asList (  \" cat \"  ,     \" dog \"  )  )  ,    exec (  \"  /  ,  /  . splitAsStream (  ' cat , dog '  )  . collect ( Collectors . toSet (  )  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSplitAsStream"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Pattern . UNICODE _ CASE ,    exec (  \"  /  .  / u . flags (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnicodeCaseFlag"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( Pattern . UNICODE _ CASE )     |     ( Pattern . UNICODE _ CHARACTER _ CLASS )  )  ,    exec (  \"  /  .  / U . flags (  )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnicodeCharacterClassFlag"], "fileName": "org.elasticsearch.painless.RegexTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  2  .  2  5 F    %     1  .  5 F )  ,    exec (  \" return    2  .  2  5 F    %     1  .  5 F ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" int   x    =     3  ;    int   y    =     2  ;    return   x    %    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  3  )  )  ,    exec (  \" byte   x    =     1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  3  )  )  ,    exec (  \" byte   x    =     ( byte )     -  1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  3  )  )  ,    exec (  \" short   x    =     1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  3  )  )  ,    exec (  \" short   x    =     ( short )     -  1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  3  )  )  ,    exec (  \" char   x    =     ( char )     1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" int   x    =     1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  3  )  ,    exec (  \" int   x    =     -  1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  3 L ,    exec (  \" long   x    =     1  5 L ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  3 L )  ,    exec (  \" long   x    =     -  1  5 L ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  3  .  0 F ,    exec (  \" float   x    =     1  5 F ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  3  .  0 F )  ,    exec (  \" float   x    =     -  1  5 F ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  3  .  0  ,    exec (  \" double   x    =     1  5  .  0  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  3  .  0  )  ,    exec (  \" double   x    =     -  1  5  .  0  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignment"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  3  )  )  ,    exec (  \" def   x    =     ( byte )  1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  3  )  )  ,    exec (  \" def   x    =     ( byte )     -  1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  3  )  )  ,    exec (  \" def   x    =     ( short )  1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  3  )  )  ,    exec (  \" def   x    =     ( short )     -  1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  3  )  )  ,    exec (  \" def   x    =     ( char )     1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" def   x    =     1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  3  )  ,    exec (  \" def   x    =     -  1  5  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  3 L ,    exec (  \" def   x    =     1  5 L ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  3 L )  ,    exec (  \" def   x    =     -  1  5 L ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  3  .  0 F ,    exec (  \" def   x    =     1  5 F ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  3  .  0 F )  ,    exec (  \" def   x    =     -  1  5 F ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  3  .  0  ,    exec (  \" def   x    =     1  5  .  0  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  3  .  0  )  ,    exec (  \" def   x    =     -  1  5  .  0  ;    x    %  =     4  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefCompoundAssignment"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  2  ;    def   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  2  ;    def   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  2  ;    def   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  2  ;    def   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  2  ;    def   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  2  ;    def   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  2  ;    def   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedLHS"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    byte   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    byte   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    byte   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    byte   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    byte   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    byte   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    byte   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    short   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    short   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    short   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    short   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    short   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    short   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    short   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    char   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    char   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    char   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    char   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    char   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    char   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    char   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    int   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    int   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    int   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    int   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    int   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    int   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    int   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( byte )  2  ;    long   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( short )  2  ;    long   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( char )  2  ;    long   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( int )  2  ;    long   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    long   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    long   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    long   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( byte )  2  ;    float   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( short )  2  ;    float   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( char )  2  ;    float   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( int )  2  ;    float   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( long )  2  ;    float   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    float   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    float   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( byte )  2  ;    double   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( short )  2  ;    double   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( char )  2  ;    double   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( int )  2  ;    double   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( long )  2  ;    double   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( float )  2  ;    double   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    double   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  2  ;    byte   y    =     ( byte )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  2  ;    short   y    =     ( short )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  2  ;    char   y    =     ( char )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  2  ;    int   y    =     ( int )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  2  ;    long   y    =     ( long )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  2  ;    float   y    =     ( float )  2  ;    return   x    %    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  2  ;    double   y    =     ( double )  2  ;    return   x    %    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedRHS"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1  ;    int   y    =     0  ;    return   x    %    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" long   x    =     1 L ;    long   y    =     0 L ;    return   x    %    y ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDivideByZero"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" return    1  %  0  ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ArithmeticException . class ,     (  )     -  >     {", "exec (  \" return    1 L %  0 L ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDivideByZeroConst"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     %     1  .  0  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  2  .  0     %     3  .  0  )  ,    exec (  \" double   x    =     2  ;    double   y    =     3  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  5  .  0     %     1  0  .  0  )  ,    exec (  \" double   x    =     5  ;    double   y    =     1  0  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0     %     1  .  0  )     %     2  .  0  )  ,    exec (  \" double   x    =     1  0  ;    double   y    =     1  ;    double   z    =     2  ;    return   x % y % z ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0     %     1  .  0  )     %     2  .  0  )  ,    exec (  \" double   x    =     1  0  ;    double   y    =     1  ;    double   z    =     2  ;    return    ( x % y )  % z ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     %     (  4  .  0     %     3  .  0  )  )  ,    exec (  \" double   x    =     1  0  ;    double   y    =     4  ;    double   z    =     3  ;    return   x %  ( y % z )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     %     1  .  0  )  ,    exec (  \" double   x    =     1  0  ;    double   y    =     1  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  0  .  0     %     1  .  0  )  ,    exec (  \" double   x    =     0  ;    double   y    =     1  ;    return   x % y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDouble"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     %     1  .  0  )  ,    exec (  \" return    1  .  0  %  1  .  0  ;  \"  )  )  ;", "assertEquals (  (  2  .  0     %     3  .  0  )  ,    exec (  \" return    2  .  0  %  3  .  0  ;  \"  )  )  ;", "assertEquals (  (  5  .  0     %     1  0  .  0  )  ,    exec (  \" return    5  .  0  %  1  0  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0     %     1  .  0  )     %     2  .  0  )  ,    exec (  \" return    1  0  .  0  %  1  .  0  %  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0     %     1  .  0  )     %     2  .  0  )  ,    exec (  \" return    (  1  0  .  0  %  1  .  0  )  %  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     %     (  4  .  0     %     3  .  0  )  )  ,    exec (  \" return    1  0  .  0  %  (  4  .  0  %  3  .  0  )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     %     1  .  0  )  ,    exec (  \" return    1  0  .  0  %  1  .  0  ;  \"  )  )  ;", "assertEquals (  (  0  .  0     %     1  .  0  )  ,    exec (  \" return    0  .  0  %  1  .  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDoubleConst"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    %     1  .  0 F )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  2  .  0 F    %     3  .  0 F )  ,    exec (  \" float   x    =     2  ;    float   y    =     3  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    %     1  0  .  0 F )  ,    exec (  \" float   x    =     5  ;    float   y    =     1  0  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0 F    %     1  .  0 F )     %     2  .  0 F )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     1  ;    float   z    =     2  ;    return   x % y % z ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0 F    %     1  .  0 F )     %     2  .  0 F )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     1  ;    float   z    =     2  ;    return    ( x % y )  % z ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    %     (  4  .  0 F    %     3  .  0 F )  )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     4  ;    float   z    =     3  ;    return   x %  ( y % z )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    %     1  .  0 F )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     1  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    %     1  .  0 F )  ,    exec (  \" float   x    =     0  ;    float   y    =     1  ;    return   x % y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloat"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    %     1  .  0 F )  ,    exec (  \" return    1 F %  1 F ;  \"  )  )  ;", "assertEquals (  (  2  .  0 F    %     3  .  0 F )  ,    exec (  \" return    2 F %  3 F ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    %     1  0  .  0 F )  ,    exec (  \" return    5 F %  1  0 F ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0 F    %     1  .  0 F )     %     2  .  0 F )  ,    exec (  \" return    1  0 F %  1 F %  2 F ;  \"  )  )  ;", "assertEquals (  (  (  1  0  .  0 F    %     1  .  0 F )     %     2  .  0 F )  ,    exec (  \" return    (  1  0 F %  1 F )  %  2 F ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    %     (  4  .  0 F    %     3  .  0 F )  )  ,    exec (  \" return    1  0 F %  (  4 F %  3 F )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    %     1  .  0 F )  ,    exec (  \" return    1  0 F %  1 F ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    %     1  .  0 F )  ,    exec (  \" return    0 F %  1 F ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloatConst"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     %     1  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  2     %     3  )  ,    exec (  \" int   x    =     2  ;    int   y    =     3  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  5     %     1  0  )  ,    exec (  \" int   x    =     5  ;    int   y    =     1  0  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  (  1  0     %     1  )     %     2  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     1  ;    int   z    =     2  ;    return   x % y % z ;  \"  )  )  ;", "assertEquals (  (  (  1  0     %     1  )     %     2  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     1  ;    int   z    =     2  ;    return    ( x % y )  % z ;  \"  )  )  ;", "assertEquals (  (  1  0     %     (  4     %     3  )  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     4  ;    int   z    =     3  ;    return   x %  ( y % z )  ;  \"  )  )  ;", "assertEquals (  (  1  0     %     1  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     1  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  0     %     1  )  ,    exec (  \" int   x    =     0  ;    int   y    =     1  ;    return   x % y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInt"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     %     1  )  ,    exec (  \" return    1  %  1  ;  \"  )  )  ;", "assertEquals (  (  2     %     3  )  ,    exec (  \" return    2  %  3  ;  \"  )  )  ;", "assertEquals (  (  5     %     1  0  )  ,    exec (  \" return    5  %  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  0     %     1  )     %     2  )  ,    exec (  \" return    1  0  %  1  %  2  ;  \"  )  )  ;", "assertEquals (  (  (  1  0     %     1  )     %     2  )  ,    exec (  \" return    (  1  0  %  1  )  %  2  ;  \"  )  )  ;", "assertEquals (  (  1  0     %     (  4     %     3  )  )  ,    exec (  \" return    1  0  %  (  4  %  3  )  ;  \"  )  )  ;", "assertEquals (  (  1  0     %     1  )  ,    exec (  \" return    1  0  %  1  ;  \"  )  )  ;", "assertEquals (  (  0     %     1  )  ,    exec (  \" return    0  %  1  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIntConst"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    %     1 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  2 L    %     3 L )  ,    exec (  \" long   x    =     2  ;    long   y    =     3  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  5 L    %     1  0 L )  ,    exec (  \" long   x    =     5  ;    long   y    =     1  0  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  (  1  0 L    %     1 L )     %     2 L )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     1  ;    long   z    =     2  ;    return   x % y % z ;  \"  )  )  ;", "assertEquals (  (  (  1  0 L    %     1 L )     %     2 L )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     1  ;    long   z    =     2  ;    return    ( x % y )  % z ;  \"  )  )  ;", "assertEquals (  (  1  0 L    %     (  4 L    %     3 L )  )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     4  ;    long   z    =     3  ;    return   x %  ( y % z )  ;  \"  )  )  ;", "assertEquals (  (  1  0 L    %     1 L )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     1  ;    return   x % y ;  \"  )  )  ;", "assertEquals (  (  0 L    %     1 L )  ,    exec (  \" long   x    =     0  ;    long   y    =     1  ;    return   x % y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLong"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    %     1 L )  ,    exec (  \" return    1 L %  1 L ;  \"  )  )  ;", "assertEquals (  (  2 L    %     3 L )  ,    exec (  \" return    2 L %  3 L ;  \"  )  )  ;", "assertEquals (  (  5 L    %     1  0 L )  ,    exec (  \" return    5 L %  1  0 L ;  \"  )  )  ;", "assertEquals (  (  (  1  0 L    %     1 L )     %     2 L )  ,    exec (  \" return    1  0 L %  1 L %  2 L ;  \"  )  )  ;", "assertEquals (  (  (  1  0 L    %     1 L )     %     2 L )  ,    exec (  \" return    (  1  0 L %  1 L )  %  2 L ;  \"  )  )  ;", "assertEquals (  (  1  0 L    %     (  4 L    %     3 L )  )  ,    exec (  \" return    1  0 L %  (  4 L %  3 L )  ;  \"  )  )  ;", "assertEquals (  (  1  0 L    %     1 L )  ,    exec (  \" return    1  0 L %  1 L ;  \"  )  )  ;", "assertEquals (  (  0 L    %     1 L )  ,    exec (  \" return    0 L %  1 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongConst"], "fileName": "org.elasticsearch.painless.RemainderTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \"  _ value    =     5  ;    return    _ value ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Variable    [  _ value ]    is   read - only \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAggregationValueStore"], "fileName": "org.elasticsearch.painless.ReservedWordTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" int    _ value    =     5  ;    return    _ value ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Variable    [  _ value ]    is   already   defined \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAggregationValueVar"], "fileName": "org.elasticsearch.painless.ReservedWordTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" ctx    =     5  ;    return   ctx ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Variable    [ ctx ]    is   read - only \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCtxStore"], "fileName": "org.elasticsearch.painless.ReservedWordTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  5  ,    exec (  \" ctx . foo    =     5  ;    return   ctx . foo ;  \"  ,    Collections . singletonMap (  \" ctx \"  ,    new   HashMap < String ,    Object >  (  )  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testCtxStoreMap"], "fileName": "org.elasticsearch.painless.ReservedWordTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" int   ctx    =     5  ;    return   ctx ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Variable    [ ctx ]    is   already   defined \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCtxVar"], "fileName": "org.elasticsearch.painless.ReservedWordTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" doc    =     5  ;    return   doc ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Variable    [ doc ]    is   read - only \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDocStore"], "fileName": "org.elasticsearch.painless.ReservedWordTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" int   doc    =     5  ;    return   doc ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Variable    [ doc ]    is   already   defined \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDocVar"], "fileName": "org.elasticsearch.painless.ReservedWordTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \"  _ score    =     5  ;    return    _ score ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Variable    [  _ score ]    is   read - only \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testScoreStore"], "fileName": "org.elasticsearch.painless.ReservedWordTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" int    _ score    =     5  ;    return    _ score ;  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Variable    [  _ score ]    is   already   defined \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testScoreVar"], "fileName": "org.elasticsearch.painless.ReservedWordTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  9  .  0  ,    exec (  \"  _ score    +     _ score \"  ,    Collections . emptyMap (  )  ,    Collections . emptyMap (  )  ,    new   ScoreTests . MockScorer (  )     {", "private   boolean   used    =    false ;", "@ Override", "public   float   score (  )    throws   IOException    {", "if    (  ( used )     =  =    false )     {", "return    4  .  5 F ;", "}", "throw   new   AssertionError (  \" score (  )    should   not   be   called   twice \"  )  ;", "}", "}  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testScoreCached"], "fileName": "org.elasticsearch.painless.ScoreTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  3  .  5  ,    exec (  \"  3  .  5  \"  ,    Collections . emptyMap (  )  ,    Collections . emptyMap (  )  ,    new   ScoreTests . MockScorer (  )     {", "@ Override", "public   float   score (  )    throws   IOException    {", "throw   new   AssertionError (  \" score (  )    should   not   be   called \"  )  ;", "}", "}  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testScoreNotUsed"], "fileName": "org.elasticsearch.painless.ScoreTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  .  5  ,    exec (  \"  _ score \"  ,    Collections . emptyMap (  )  ,    Collections . emptyMap (  )  ,    new   ScoreTests . MockScorer (  )     {", "@ Override", "public   float   score (  )    throws   IOException    {", "return    2  .  5 F ;", "}", "}  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testScoreWorks"], "fileName": "org.elasticsearch.painless.ScoreTests"}, {"methodBody": ["METHOD_START", "{", "int   dimensions    =     0  ;", "<  ?  >    componentType    =    type ;", "while    ( componentType . isArray (  )  )     {", "dimensions +  +  ;", "componentType    =    componentType . getComponentType (  )  ;", "}", "Definition . Struct   struct ;", "if    ( componentType    =  =     ( Object . class )  )     {", "struct    =    definition . getType (  \" def \"  )  . struct ;", "} else    {", "if    (  ( definition . RuntimeToStruct ( componentType )  )     =  =    null )     {", "throw   new   IllegalArgumentException ( unknownErrorMessageSource . apply ( componentType )  )  ;", "}", "struct    =    definition . RuntimeToStruct ( componentType )  ;", "}", "return   Definition . TypeTo ( definition . getType ( struct ,    dimensions )  )  ;", "}", "METHOD_END"], "methodName": ["definitionTypeForClass"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "return   baseClass ;", "}", "METHOD_END"], "methodName": ["getBaseClass"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "return   executeArguments ;", "}", "METHOD_END"], "methodName": ["getExecuteArguments"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "return   executeMethod ;", "}", "METHOD_END"], "methodName": ["getExecuteMethod"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "return   executeMethodReturnType ;", "}", "METHOD_END"], "methodName": ["getExecuteMethodReturnType"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "return   getMethods ;", "}", "METHOD_END"], "methodName": ["getGetMethods"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "return   getReturns ;", "}", "METHOD_END"], "methodName": ["getGetReturns"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "return   needsMethods ;", "}", "METHOD_END"], "methodName": ["getNeedsMethods"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "Class <  ?  >    defClass    =    ScriptClassInfo . definitionTypeForClass ( definition ,    clazz ,     (    componentType )     -  >     (  (  (  \"  [  \"     +    argName )     +     \"  ]    is   of   unknown   type    [  \"  )     +     ( componentType . getName (  )  )  )     +     \"  .    Painless   interfaces   can   only   accept   arguments   that   are   of   whitelisted   types .  \"  )  ;", "return   new   ScriptClassInfo . MethodArgument ( defClass ,    argName )  ;", "}", "METHOD_END"], "methodName": ["methodArgument"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "Field   argumentNamesField ;", "try    {", "argumentNamesField    =    iface . getField (  \" PARAMETERS \"  )  ;", "}    catch    ( NoSuchFieldException   e )     {", "throw   new   IllegalArgumentException (  (  (  (  \" P   needs   a   constant    [ String [  ]    PARAMETERS ]    on   all   interfaces   it   implements   with   the    \"     +     \" names   of   the   method   arguments   but    [  \"  )     +     ( iface . getName (  )  )  )     +     \"  ]    doesn ' t   have   one .  \"  )  ,    e )  ;", "}", "if    ( false    =  =     ( argumentNamesField . getType (  )  . equals ( String [  ]  . class )  )  )     {", "throw   new   IllegalArgumentException (  (  (  (  \" P   needs   a   constant    [ String [  ]    PARAMETERS ]    on   all   interfaces   it   implements   with   the    \"     +     \" names   of   the   method   arguments   but    [  \"  )     +     ( iface . getName (  )  )  )     +     \"  ]    doesn ' t   have   one .  \"  )  )  ;", "}", "try    {", "return    (  ( String [  ]  )     ( argumentNamesField . get ( null )  )  )  ;", "}    catch    ( IllegalArgumentException    |    IllegalAccessException   e )     {", "throw   new   IllegalArgumentException (  (  (  \" Error   trying   to   read    [  \"     +     ( iface . getName (  )  )  )     +     \"  # ARGUMENTS ]  \"  )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["readArgumentNamesConstant"], "fileName": "org.elasticsearch.painless.ScriptClassInfo"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    obj 2     =    new   HashMap <  >  (  )  ;", "obj 2  . put (  \" prop 2  \"  ,     \" value 2  \"  )  ;", "Map < String ,    Object >    obj 1     =    new   HashMap <  >  (  )  ;", "obj 1  . put (  \" prop 1  \"  ,     \" value 1  \"  )  ;", "obj 1  . put (  \" obj 2  \"  ,    obj 2  )  ;", "vars . put (  \" l \"  ,    Arrays . asList (  \"  1  \"  ,     \"  2  \"  ,     \"  3  \"  ,    obj 1  )  )  ;", "assertEquals (  4  ,    exec (  \" return   params . l . size (  )  ;  \"  ,    vars ,    true )  )  ;", "assertEquals (  \"  1  \"  ,    exec (  \" return   params . l .  0  ;  \"  ,    vars ,    true )  )  ;", "Object   value    =    exec (  \" return   params . l .  3  ;  \"  ,    vars ,    true )  ;", "obj 1     =     (  ( Map < String ,    Object >  )     ( value )  )  ;", "assertEquals (  \" value 1  \"  ,    obj 1  . get (  \" prop 1  \"  )  )  ;", "assertEquals (  \" value 2  \"  ,     (  ( Map < String ,    Object >  )     ( obj 1  . get (  \" obj 2  \"  )  )  )  . get (  \" prop 2  \"  )  )  ;", "assertEquals (  \" value 1  \"  ,    exec (  \" return   params . l .  3  . prop 1  ;  \"  ,    vars ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testAccessListInScript"], "fileName": "org.elasticsearch.painless.ScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    ctx    =    new   HashMap <  >  (  )  ;", "vars . put (  \" ctx \"  ,    ctx )  ;", "ExecutableScript . Factory   factory    =    s . compile ( null ,     \" return   ctx . value ;  \"  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "ExecutableScript   script    =    factory . newInstance ( vars )  ;", "ctx . put (  \" value \"  ,     1  )  ;", "Object   o    =    script . run (  )  ;", "assertEquals (  1  ,     (  ( Number )     ( o )  )  . intValue (  )  )  ;", "ctx . put (  \" value \"  ,     2  )  ;", "o    =    script . run (  )  ;", "assertEquals (  2  ,     (  ( Number )     ( o )  )  . intValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testChangingVarsCrossExecution1"], "fileName": "org.elasticsearch.painless.ScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "ExecutableScript . Factory   factory    =    s . compile ( null ,     \" return   params [  ' value '  ]  ;  \"  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "ExecutableScript   script    =    factory . newInstance ( vars )  ;", "script . setNextVar (  \" value \"  ,     1  )  ;", "Object   value    =    script . run (  )  ;", "assertEquals (  1  ,     (  ( Number )     ( value )  )  . intValue (  )  )  ;", "script . setNextVar (  \" value \"  ,     2  )  ;", "value    =    script . run (  )  ;", "assertEquals (  2  ,     (  ( Number )     ( value )  )  . intValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testChangingVarsCrossExecution2"], "fileName": "org.elasticsearch.painless.ScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    obj 2     =    new   HashMap <  >  (  )  ;", "obj 2  . put (  \" prop 2  \"  ,     \" value 2  \"  )  ;", "Map < String ,    Object >    obj 1     =    new   HashMap <  >  (  )  ;", "obj 1  . put (  \" prop 1  \"  ,     \" value 1  \"  )  ;", "obj 1  . put (  \" obj 2  \"  ,    obj 2  )  ;", "obj 1  . put (  \" l \"  ,    Arrays . asList (  \"  2  \"  ,     \"  1  \"  )  )  ;", "vars . put (  \" obj 1  \"  ,    obj 1  )  ;", "Object   value    =    exec (  \" return   params [  ' obj 1  '  ]  ;  \"  ,    vars ,    true )  ;", "obj 1     =     (  ( Map < String ,    Object >  )     ( value )  )  ;", "assertEquals (  \" value 1  \"  ,    obj 1  . get (  \" prop 1  \"  )  )  ;", "assertEquals (  \" value 2  \"  ,     (  ( Map < String ,    Object >  )     ( obj 1  . get (  \" obj 2  \"  )  )  )  . get (  \" prop 2  \"  )  )  ;", "value    =    exec (  \" return   params . obj 1  . l .  0  ;  \"  ,    vars ,    true )  ;", "assertEquals (  \"  2  \"  ,    value )  ;", "}", "METHOD_END"], "methodName": ["testMapAccess"], "fileName": "org.elasticsearch.painless.ScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "final   Object   value    =    exec (  \" return    1     +     2  ;  \"  )  ;", "assertEquals (  3  ,     (  ( Number )     ( value )  )  . intValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimpleEquation"], "fileName": "org.elasticsearch.painless.ScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "final   String   asm    =    Debugger . toString ( script )  ;", "assertTrue (  (  \" bytecode   not   found ,    got :     \\ n \"     +    asm )  ,    asm . contains ( bytecode )  )  ;", "}", "METHOD_END"], "methodName": ["assertBytecodeExists"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "final   String   asm    =    Debugger . toString ( script )  ;", "assertTrue (  (  \" bytecode   not   found ,    got :     \\ n \"     +    asm )  ,    asm . matches ( pattern )  )  ;", "}", "METHOD_END"], "methodName": ["assertBytecodeHasPattern"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "try    {", "assertThat ( e . getStack (  )  ,    hasSize ( stack . length )  )  ;", "for    ( int   i    =     0  ;    i    <     ( stack . length )  ;    i +  +  )     {", "assertEquals ( stack [ i ]  ,    e . getStack (  )  . get ( i )  )  ;", "}", "}    catch    ( AssertionError   assertion )     {", "assertion . initCause ( e )  ;", "throw   assertion ;", "}", "}", "METHOD_END"], "methodName": ["assertScriptStack"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "return   exec ( script ,    null ,    true )  ;", "}", "METHOD_END"], "methodName": ["exec"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "return   exec ( script ,    null ,    picky )  ;", "}", "METHOD_END"], "methodName": ["exec"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    compilerSettings    =    new   HashMap <  >  (  )  ;", "compilerSettings . put ( CompilerSettings . INITIAL _ CALL _ SITE _ DEPTH ,     ( random (  )  . nextBoolean (  )     ?     \"  0  \"     :     \"  1  0  \"  )  )  ;", "return   exec ( s ,    vars ,    compilerSettings ,    null ,    picky )  ;", "}", "METHOD_END"], "methodName": ["exec"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "if    ( picky )     {", "Definition   definition    =    new   Definition ( Whitelist . BASE _ WHITELISTS )  ;", "ScriptClassInfo   scriptClassInfo    =    new   ScriptClassInfo ( definition ,    GenericEScript . class )  ;", "CompilerSettings   pickySettings    =    new   CompilerSettings (  )  ;", "pickySettings . setPicky ( true )  ;", "pickySettings . setRegexesEnabled ( CompilerSettings . REGEX _ ENABLED . get ( scriptEngineSettings (  )  )  )  ;", "Walker . buildPainlessTree ( scriptClassInfo ,    new   SSource . MainMethodReserved (  )  ,    getTestName (  )  ,    script ,    pickySettings ,    definition ,    null )  ;", "}", "ExecutableScript . Factory   factory    =    scriptEngine . compile ( null ,    script ,    CONTEXT ,    compileParams )  ;", "ExecutableScript   executableScript    =    factory . newInstance ( vars )  ;", "if    ( scorer    !  =    null )     {", "(  ( ScorerAware )     ( executableScript )  )  . setScorer ( scorer )  ;", "}", "return   executableScript . run (  )  ;", "}", "METHOD_END"], "methodName": ["exec"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "try    {", "runnable . run (  )  ;", "}    catch    ( Throwable   e )     {", "if    ( e   instanceof   Exception )     {", "boolean   hasEmptyStack    =     (  ( Exception )     ( e )  )  . getStack (  )  . isEmpty (  )  ;", "if    ( shouldHaveStack    &  &    hasEmptyStack )     {", "AssertionFailedError   assertion    =    new   AssertionFailedError (  \" Exception   should   have   a   scriptStack \"  )  ;", "assertion . initCause ( e )  ;", "throw   assertion ;", "} else", "if    (  ( false    =  =    shouldHaveStack )     &  &     ( false    =  =    hasEmptyStack )  )     {", "AssertionFailedError   assertion    =    new   AssertionFailedError (  \" Exception   shouldn ' t   have   a   scriptStack \"  )  ;", "assertion . initCause ( e )  ;", "throw   assertion ;", "}", "e    =    e . getCause (  )  ;", "if    ( expectedType . isInstance ( e )  )     {", "return   expectedType . cast ( e )  ;", "}", "} else    {", "AssertionFailedError   assertion    =    new   AssertionFailedError (  \" Expected   boxed   Exception \"  )  ;", "assertion . initCause ( e )  ;", "throw   assertion ;", "}", "AssertionFailedError   assertion    =    new   AssertionFailedError (  (  \" Unexpected   exception   type ,    expected    \"     +     ( expectedType . getSimpleName (  )  )  )  )  ;", "assertion . initCause ( e )  ;", "throw   assertion ;", "}", "throw   new   AssertionFailedError (  (  \" Expected   exception    \"     +     ( expectedType . getSimpleName (  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["expectScriptThrows"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "return   ScriptTestCase . expectScriptThrows ( expectedType ,    true ,    runnable )  ;", "}", "METHOD_END"], "methodName": ["expectScriptThrows"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "Map < ScriptContext <  ?  >  ,    List < Whitelist >  >    contexts    =    new   HashMap <  >  (  )  ;", "contexts . put ( CONTEXT ,    Whitelist . BASE _ WHITELISTS )  ;", "contexts . put ( ExecutableScript . CONTEXT ,    Whitelist . BASE _ WHITELISTS )  ;", "return   contexts ;", "}", "METHOD_END"], "methodName": ["scriptContexts"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "return   Settings . EMPTY ;", "}", "METHOD_END"], "methodName": ["scriptEngineSettings"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "scriptEngine    =    new   PainlessScriptEngine ( scriptEngineSettings (  )  ,    scriptContexts (  )  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.painless.ScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     <  <     2  )  ,    exec (  \" return    1     <  <     2  ;  \"  )  )  ;", "assertEquals (  (  4     >  >     2  )  ,    exec (  \" return    4     >  >     2  ;  \"  )  )  ;", "assertEquals (  (  (  -  1  )     >  >  >     2  9  )  ,    exec (  \" return    -  1     >  >  >     2  9  ;  \"  )  )  ;", "assertEquals (  4  ,    exec (  \" int   x    =     1  ;    char   y    =     2  ;    return   x    <  <    y ;  \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" int   x    =     -  1  ;    char   y    =     2  9  ;    return   x    >  >    y ;  \"  )  )  ;", "assertEquals (  3  ,    exec (  \" int   x    =     -  1  ;    char   y    =     3  0  ;    return   x    >  >  >    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     1 L ;    float   y    =     2  ;    x    <  <  =    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1  ;    double   y    =     2 L ;    x    <  <  =    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     1 F ;    int   y    =     2  ;    x    <  <  =    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     1 D ;    int   y    =     2 L ;    x    <  <  =    y ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusCompoundAssignment"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1 L ;    x    <  <  =     2 F ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1 L ;    x    <  <  =     2  .  0  ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     1 F ;    x    <  <  =     2  ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     1 D ;    x    <  <  =     2 L ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusCompoundAssignmentConst"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 L ;    float   y    =     2  ;    x    <  <  =    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1  ;    double   y    =     2 L ;    x    <  <  =    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     1 F ;    def   y    =     2  ;    x    <  <  =    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     1 D ;    def   y    =     2 L ;    x    <  <  =    y ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusCompoundAssignmentDef"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 L ;    def   y    =     2 F ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1  ;    def   y    =     2 D ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 F ;    def   y    =     2  ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 D ;    def   y    =     2 L ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 L ;    def   y    =     2 F ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1  ;    def   y    =     2 D ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 F ;    def   y    =     2  ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 D ;    def   y    =     2 L ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 L ;    def   y    =     2 F ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1  ;    def   y    =     2 D ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 F ;    def   y    =     2  ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 D ;    def   y    =     2 L ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusDefShifts"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     1 L ;    def   y    =     2 F ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1  ;    def   y    =     2 D ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     1 F ;    def   y    =     2  ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     1 D ;    def   y    =     2 L ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     1 L ;    def   y    =     2 F ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1  ;    def   y    =     2 D ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     1 F ;    def   y    =     2  ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     1 D ;    def   y    =     2 L ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     1 L ;    def   y    =     2 F ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1  ;    def   y    =     2 D ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     1 F ;    def   y    =     2  ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     1 D ;    def   y    =     2 L ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusDefShiftsTypedLHS"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 L ;    float   y    =     2 F ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1  ;    double   y    =     2 D ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 F ;    int   y    =     2  ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 D ;    long   y    =     2 L ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 L ;    float   y    =     2 F ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1  ;    double   y    =     2 D ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 F ;    int   y    =     2  ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 D ;    long   y    =     2 L ;    return   x    >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 L ;    float   y    =     2 F ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1  ;    double   y    =     2 D ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 F ;    int   y    =     2  ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     1 D ;    long   y    =     2 L ;    return   x    >  >  >    y ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusDefShiftsTypedRHS"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" long   x    =     1 L ;    float   y    =     2  ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     1  ;    double   y    =     2 L ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     1 F ;    int   y    =     2  ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     1 D ;    int   y    =     2 L ;    return   x    <  <    y ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusShifts"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" return    1 L    <  <     2 F ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" return    1 L    <  <     2  .  0  ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" return    1 F    <  <     2  ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" return    1 D    <  <     2 L \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusShiftsConst"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    <  <     2  )  ,    exec (  \" long   x    =     1 L ;    int   y    =     2  ;    return   x    <  <    y ;  \"  )  )  ;", "assertEquals (  (  1     <  <     2 L )  ,    exec (  \" int   x    =     1  ;    long   y    =     2 L ;    return   x    <  <    y ;  \"  )  )  ;", "assertEquals (  (  4     >  >     2 L )  ,    exec (  \" int   x    =     4  ;    long   y    =     2 L ;    return   x    >  >    y ;  \"  )  )  ;", "assertEquals (  (  4 L    >  >     2  )  ,    exec (  \" long   x    =     4 L ;    int   y    =     2  ;    return   x    >  >    y ;  \"  )  )  ;", "assertEquals (  (  (  -  1 L )     >  >  >     2  9  )  ,    exec (  \" long   x    =     -  1 L ;    int   y    =     2  9  ;    return   x    >  >  >    y ;  \"  )  )  ;", "assertEquals (  (  (  -  1  )     >  >  >     2  9 L )  ,    exec (  \" int   x    =     -  1  ;    long   y    =     2  9 L ;    return   x    >  >  >    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongShifts"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    <  <     2  )  ,    exec (  \" return    1 L    <  <     2  ;  \"  )  )  ;", "assertEquals (  (  1     <  <     2 L )  ,    exec (  \" return    1     <  <     2 L ;  \"  )  )  ;", "assertEquals (  (  4     >  >     2 L )  ,    exec (  \" return    4     >  >     2 L ;  \"  )  )  ;", "assertEquals (  (  4 L    >  >     2  )  ,    exec (  \" return    4 L    >  >     2  ;  \"  )  )  ;", "assertEquals (  (  (  -  1 L )     >  >  >     2  9  )  ,    exec (  \" return    -  1 L    >  >  >     2  9  ;  \"  )  )  ;", "assertEquals (  (  (  -  1  )     >  >  >     2  9 L )  ,    exec (  \" return    -  1     >  >  >     2  9 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongShiftsConst"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  6  0  )  )  ,    exec (  \" byte   x    =     1  5  ;    x    <  <  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  6  0  )  )  ,    exec (  \" byte   x    =     ( byte )     -  1  5  ;    x    <  <  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  6  0  )  )  ,    exec (  \" short   x    =     1  5  ;    x    <  <  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  6  0  )  )  ,    exec (  \" short   x    =     ( short )     -  1  5  ;    x    <  <  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  6  0  )  )  ,    exec (  \" char   x    =     ( char )     1  5  ;    x    <  <  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  6  0  ,    exec (  \" int   x    =     1  5  ;    x    <  <  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  6  0  )  ,    exec (  \" int   x    =     -  1  5  ;    x    <  <  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  6  0 L ,    exec (  \" long   x    =     1  5 L ;    x    <  <  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  6  0 L )  ,    exec (  \" long   x    =     -  1  5 L ;    x    <  <  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  6  0  ,    exec (  \" int   x    =     1  5  ;    x    <  <  =     2 L ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  6  0  )  ,    exec (  \" int   x    =     -  1  5  ;    x    <  <  =     2 L ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLshCompoundAssignment"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLshDef"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLshDefTypedLHS"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    byte   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    byte   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    byte   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    byte   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    byte   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    short   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    short   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    short   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    short   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    short   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    char   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    char   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    char   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    char   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    char   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    int   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    int   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    int   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    int   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    int   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    long   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    long   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    long   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    long   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    long   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  1  ;    byte   y    =     ( byte )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  1  ;    short   y    =     ( short )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  1  ;    char   y    =     ( char )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  1  ;    int   y    =     ( int )  1  ;    return   x    <  <    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  1  ;    long   y    =     ( long )  1  ;    return   x    <  <    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLshDefTypedRHS"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" byte   x    =     6  0  ;    x    >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  1  5  )  )  ,    exec (  \" byte   x    =     ( byte )     -  6  0  ;    x    >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" short   x    =     6  0  ;    x    >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  1  5  )  )  ,    exec (  \" short   x    =     ( short )     -  6  0  ;    x    >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" char   x    =     ( char )     6  0  ;    x    >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" int   x    =     6  0  ;    x    >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  1  5  )  ,    exec (  \" int   x    =     -  6  0  ;    x    >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" long   x    =     6  0 L ;    x    >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  1  5 L )  ,    exec (  \" long   x    =     -  6  0 L ;    x    >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" int   x    =     6  0  ;    x    >  >  =     2 L ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  1  5  )  ,    exec (  \" int   x    =     -  6  0  ;    x    >  >  =     2 L ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRshCompoundAssignment"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRshDef"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRshDefTypeLHS"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRshDefTypedLHS"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" byte   x    =     6  0  ;    x    >  >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  1  5  )  )  ,    exec (  \" byte   x    =     ( byte )     -  6  0  ;    x    >  >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" short   x    =     6  0  ;    x    >  >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  1  5  )  )  ,    exec (  \" short   x    =     ( short )     -  6  0  ;    x    >  >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" char   x    =     ( char )     6  0  ;    x    >  >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" int   x    =     6  0  ;    x    >  >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  -  6  0  )     >  >  >     2  )  ,    exec (  \" int   x    =     -  6  0  ;    x    >  >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" long   x    =     6  0 L ;    x    >  >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  -  6  0 L )     >  >  >     2  )  ,    exec (  \" long   x    =     -  6  0 L ;    x    >  >  >  =     2  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" int   x    =     6  0  ;    x    >  >  >  =     2 L ;    return   x ;  \"  )  )  ;", "assertEquals (  (  (  -  6  0  )     >  >  >     2  )  ,    exec (  \" int   x    =     -  6  0  ;    x    >  >  >  =     2 L ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUshCompoundAssignment"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUshDef"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" byte   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" short   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" char   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" int   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" long   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUshDefTypedLHS"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    >  >  >    y \"  )  )  ;", "assertEquals (  2 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    >  >  >    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUshDefTypedRHS"], "fileName": "org.elasticsearch.painless.ShiftTests"}, {"methodBody": ["METHOD_START", "{", "SimilarityScript . Factory   factory    =    scriptEngine . compile (  \" foobar \"  ,     \" return   query . boost    *    doc . freq    /    doc . length \"  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "ScriptedSimilarity   sim    =    new   ScriptedSimilarity (  \" foobar \"  ,    null ,     \" foobaz \"  ,    factory :  : newInstance ,    true )  ;", "Directory   dir    =    new   RAMDirectory (  )  ;", "IndexWriter   w    =    new   IndexWriter ( dir ,    newIndexWriterConfig (  )  . setSimilarity ( sim )  )  ;", "Document   doc    =    new   Document (  )  ;", "doc . add ( new   TextField (  \" f \"  ,     \" foo   bar \"  ,    Store . NO )  )  ;", "doc . add ( new   StringField (  \" match \"  ,     \" no \"  ,    Store . NO )  )  ;", "w . addDocument ( doc )  ;", "doc    =    new   Document (  )  ;", "doc . add ( new   TextField (  \" f \"  ,     \" foo   foo   bar \"  ,    Store . NO )  )  ;", "doc . add ( new   StringField (  \" match \"  ,     \" yes \"  ,    Store . NO )  )  ;", "w . addDocument ( doc )  ;", "doc    =    new   Document (  )  ;", "doc . add ( new   TextField (  \" f \"  ,     \" bar \"  ,    Store . NO )  )  ;", "doc . add ( new   StringField (  \" match \"  ,     \" no \"  ,    Store . NO )  )  ;", "w . addDocument ( doc )  ;", "IndexReader   r    =    DirectoryReader . open ( w )  ;", "w . close (  )  ;", "IndexSearcher   searcher    =    new   IndexSearcher ( r )  ;", "searcher . setSimilarity ( sim )  ;", "Query   query    =    new   BoostQuery ( new   BooleanQuery . Builder (  )  . add ( new   TermQuery ( new   Term (  \" f \"  ,     \" foo \"  )  )  ,    SHOULD )  . add ( new   TermQuery ( new   Term (  \" match \"  ,     \" yes \"  )  )  ,    FILTER )  . build (  )  ,     3  .  2 F )  ;", "TopDocs   topDocs    =    searcher . search ( query ,     1  )  ;", "assertEquals (  1  ,    topDocs . totalHits )  ;", "assertEquals (  (  ( float )     (  (  3  .  2     *     2  )     /     3  )  )  ,    topDocs . scoreDocs [  0  ]  . score ,     0  )  ;", "w . close (  )  ;", "dir . close (  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.SimilarityScriptTests"}, {"methodBody": ["METHOD_START", "{", "SimilarityWeightScript . Factory   weightFactory    =    scriptEngine . compile (  \" foobar \"  ,     \" return   query . boost \"  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", ". Factory   factory    =    scriptEngine . compile (  \" foobar \"  ,     \" return   weight    *    doc . freq    /    doc . length \"  ,     . CONTEXT ,    Collections . emptyMap (  )  )  ;", "ScriptedSimilarity   sim    =    new   ScriptedSimilarity (  \" foobar \"  ,    weightFactory :  : newInstance ,     \" foobaz \"  ,    factory :  : newInstance ,    true )  ;", "Directory   dir    =    new   RAMDirectory (  )  ;", "IndexWriter   w    =    new   IndexWriter ( dir ,    newIndexWriterConfig (  )  . setSimilarity ( sim )  )  ;", "Document   doc    =    new   Document (  )  ;", "doc . add ( new   TextField (  \" f \"  ,     \" foo   bar \"  ,    Store . NO )  )  ;", "doc . add ( new   StringField (  \" match \"  ,     \" no \"  ,    Store . NO )  )  ;", "w . addDocument ( doc )  ;", "doc    =    new   Document (  )  ;", "doc . add ( new   TextField (  \" f \"  ,     \" foo   foo   bar \"  ,    Store . NO )  )  ;", "doc . add ( new   StringField (  \" match \"  ,     \" yes \"  ,    Store . NO )  )  ;", "w . addDocument ( doc )  ;", "doc    =    new   Document (  )  ;", "doc . add ( new   TextField (  \" f \"  ,     \" bar \"  ,    Store . NO )  )  ;", "doc . add ( new   StringField (  \" match \"  ,     \" no \"  ,    Store . NO )  )  ;", "w . addDocument ( doc )  ;", "IndexReader   r    =    DirectoryReader . open ( w )  ;", "w . close (  )  ;", "IndexSearcher   searcher    =    new   IndexSearcher ( r )  ;", "searcher . setSimilarity ( sim )  ;", "Query   query    =    new   BoostQuery ( new   BooleanQuery . Builder (  )  . add ( new   TermQuery ( new   Term (  \" f \"  ,     \" foo \"  )  )  ,    SHOULD )  . add ( new   TermQuery ( new   Term (  \" match \"  ,     \" yes \"  )  )  ,    FILTER )  . build (  )  ,     3  .  2 F )  ;", "TopDocs   topDocs    =    searcher . search ( query ,     1  )  ;", "assertEquals (  1  ,    topDocs . totalHits )  ;", "assertEquals (  (  ( float )     (  (  3  .  2     *     2  )     /     3  )  )  ,    topDocs . scoreDocs [  0  ]  . score ,     0  )  ;", "w . close (  )  ;", "dir . close (  )  ;", "}", "METHOD_END"], "methodName": ["testWeightScript"], "fileName": "org.elasticsearch.painless.SimilarityScriptTests"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   script    =    new   StringBuilder (  \" String   s    =     \\  \" cat \\  \"  ;    return   s \"  )  ;", "StringBuilder   result    =    new   StringBuilder (  \" cat \"  )  ;", "for    ( int   i    =     1  ;    i    <    count ;    i +  +  )     {", "final   String   s    =    String . format ( Locale . ROOT ,     \"  %  0  3 d \"  ,    i )  ;", "script . append (  \"     +     '  \"  )  . append ( s )  . append (  \"  '  . toString (  )  \"  )  ;", "result . append ( s )  ;", "}", "final   String   s    =    script . toString (  )  ;", "assertTrue (  \" every   string   part   should   be   separatly   pushed   to   stack .  \"  ,    Debugger . toString ( s )  . contains ( String . format ( Locale . ROOT ,     \" LDC    \\  \"  %  0  3 d \\  \"  \"  ,     ( count    /     2  )  )  )  )  ;", "assertEquals ( result . toString (  )  ,    exec ( s )  )  ;", "}", "METHOD_END"], "methodName": ["doTestAppendMany"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  \" cat \"     +    true )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +    true ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     (  ( byte )     (  3  )  )  )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +     ( byte )  3  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     (  ( short )     (  3  )  )  )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +     ( short )  3  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     ' t '  )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +     \\  ' t \\  '  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     (  ( char )     (  4  0  )  )  )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +     ( char )  4  0  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     2  )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +     2  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     2 L )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +     2 L ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     2  .  0 F )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +     2 F ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     2  .  0  )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +     2  .  0  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     \" cat \"  )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +    s ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +    true )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +    true ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     (  ( byte )     (  3  )  )  )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +     ( byte )  3  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     (  ( short )     (  3  )  )  )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +     ( short )  3  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     ' t '  )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +     ' t '  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     (  ( char )     (  4  0  )  )  )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +     ( char )  4  0  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     2  )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +     2  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     2 L )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +     2 L ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     2  .  0 F )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +     2 F ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     2  .  0  )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +     2  .  0  ;  \"  )  )  ;", "assertEquals (  (  \" cat \"     +     \" cat \"  )  ,    exec (  \" String   s    =     ' cat '  ;    return   s    +    s ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAppend"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "for    ( int   i    =     ( WriterConstants . MAX _ INDY _ STRING _ CONCAT _ ARGS )     -     5  ;    i    <     (  ( WriterConstants . MAX _ INDY _ STRING _ CONCAT _ ARGS )     +     5  )  ;    i +  +  )     {", "doAppendMany ( i )  ;", "}", "}", "METHOD_END"], "methodName": ["testAppendMany"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  (  \" cat \"     +    true )     +     \" abc \"  )     +    null )  ,    exec (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +    true    +     \\  ' abc \\  '     +    null ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAppendMultiple"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" nullcat \"  ,    exec (  \" def   a    =    new   HashMap (  )  ;    a . cat    +  =     ' cat '  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAppendStringIntoMap"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" Y 2 F 0  \"  ,    exec (  \"  ' cat '  . encodeBase 6  4  (  )  \"  )  )  ;", "assertEquals (  \" cat \"  ,    exec (  \"  ' Y 2 F 0  '  . decodeBase 6  4  (  )  \"  )  )  ;", "assertEquals (  \"  6 KiA 6 Kqe \"  ,    exec (  \"  \\  '  \\ u 8 a 0  0  \\ u 8 a 9 e \\  '  . encodeBase 6  4  (  )  \"  )  )  ;", "assertEquals (  \"  \\ u 8 a 0  0  \\ u 8 a 9 e \"  ,    exec (  \"  '  6 KiA 6 Kqe '  . decodeBase 6  4  (  )  \"  )  )  ;", "rando    =    randomRealisticUnicodeOfLength ( between (  5  ,     1  0  0  0  )  )  ;", "assertEquals ( rando ,    exec (  \" params . rando . encodeBase 6  4  (  )  . decodeBase 6  4  (  )  \"  ,    Collections . singletonMap (  \" rando \"  ,    rando )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testBase64Augmentations"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    params    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    ctx    =    new   HashMap <  >  (  )  ;", "ctx . put (  \"  _ id \"  ,     \" somerandomid \"  )  ;", "params . put (  \" ctx \"  ,    ctx )  ;", "assertEquals (  \" somerandomid . somerandomid \"  ,    exec (  \" ctx .  _ id    +  =     '  .  '     +    ctx .  _ id \"  ,    params ,    false )  )  ;", "assertEquals (  \" somerandomid . somerandomid \"  ,    exec (  \" String   x    =     ' somerandomid '  ;    x    +  =     '  .  '     +    x \"  )  )  ;", "assertEquals (  \" somerandomid . somerandomid \"  ,    exec (  \" def   x    =     ' somerandomid '  ;    x    +  =     '  .  '     +    x \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testComplexCompoundAssignment"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  \" a \"     +     (  ( byte )     (  2  )  )  )  ,    exec (  \" def   x    =     ' a '  ;    x    +  =     ( byte )  2  ;    return   x \"  )  )  ;", "assertEquals (  (  \" a \"     +     (  ( short )     (  2  )  )  )  ,    exec (  \" def   x    =     ' a '  ;    x       +  =     ( short )  2  ;    return   x \"  )  )  ;", "assertEquals (  (  \" a \"     +     (  ( char )     (  2  )  )  )  ,    exec (  \" def   x    =     ' a '  ;    x    +  =     ( char )  2  ;    return   x \"  )  )  ;", "assertEquals (  (  \" a \"     +     2  )  ,    exec (  \" def   x    =     ' a '  ;    x    +  =     ( int )  2  ;    return   x \"  )  )  ;", "assertEquals (  (  \" a \"     +     2 L )  ,    exec (  \" def   x    =     ' a '  ;    x    +  =     ( long )  2  ;    return   x \"  )  )  ;", "assertEquals (  (  \" a \"     +     2  .  0 F )  ,    exec (  \" def   x    =     ' a '  ;    x    +  =     ( float )  2  ;    return   x \"  )  )  ;", "assertEquals (  (  \" a \"     +     2  .  0  )  ,    exec (  \" def   x    =     ' a '  ;    x    +  =     ( double )  2  ;    return   x \"  )  )  ;", "assertEquals (  \" ab \"  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ' b '  ;    x    +  =    y ;    return   x \"  )  )  ;", "assertEquals (  \" anull \"  ,    exec (  \" def   x    =     ' a '  ;    x    +  =    null ;    return   x \"  )  )  ;", "assertEquals (  \" nullb \"  ,    exec (  \" def   x    =    null ;    x    +  =     ' b '  ;    return   x \"  )  )  ;", "ScriptCase . expectScriptThrows ( NullPointerException . class ,     (  )     -  >     {", "exec (  \" def   x    =    null ;    def   y    =    null ;    x    +  =    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDefCompoundAssignment"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  \" a \"     +     (  ( byte )     (  2  )  )  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( byte )  2  ;    return   x    +    y \"  )  )  ;", "assertEquals (  (  \" a \"     +     (  ( short )     (  2  )  )  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( short )  2  ;    return   x    +    y \"  )  )  ;", "assertEquals (  (  \" a \"     +     (  ( char )     (  2  )  )  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( char )  2  ;    return   x    +    y \"  )  )  ;", "assertEquals (  (  \" a \"     +     2  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( int )  2  ;    return   x    +    y \"  )  )  ;", "assertEquals (  (  \" a \"     +     2 L )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( long )  2  ;    return   x    +    y \"  )  )  ;", "assertEquals (  (  \" a \"     +     2  .  0 F )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( float )  2  ;    return   x    +    y \"  )  )  ;", "assertEquals (  (  \" a \"     +     2  .  0  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( double )  2  ;    return   x    +    y \"  )  )  ;", "assertEquals (  \" ab \"  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ' b '  ;    return   x    +    y \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  2  )  )     +     \" a \"  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( byte )  2  ;    return   y    +    x \"  )  )  ;", "assertEquals (  (  (  ( short )     (  2  )  )     +     \" a \"  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( short )  2  ;    return   y    +    x \"  )  )  ;", "assertEquals (  (  (  ( char )     (  2  )  )     +     \" a \"  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( char )  2  ;    return   y    +    x \"  )  )  ;", "assertEquals (  (  2     +     \" a \"  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( int )  2  ;    return   y    +    x \"  )  )  ;", "assertEquals (  (  2 L    +     \" a \"  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( long )  2  ;    return   y    +    x \"  )  )  ;", "assertEquals (  (  2  .  0 F    +     \" a \"  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( float )  2  ;    return   y    +    x \"  )  )  ;", "assertEquals (  (  2  .  0     +     \" a \"  )  ,    exec (  \" def   x    =     ' a '  ;    def   y    =     ( double )  2  ;    return   y    +    x \"  )  )  ;", "assertEquals (  \" anull \"  ,    exec (  \" def   x    =     ' a '  ;    def   y    =    null ;    return   x    +    y \"  )  )  ;", "assertEquals (  \" nullb \"  ,    exec (  \" def   x    =    null ;    def   y    =     ' b '  ;    return   x    +    y \"  )  )  ;", "ScriptCase . expectScriptThrows ( NullPointerException . class ,     (  )     -  >     {", "exec (  \" def   x    =    null ;    def   y    =    null ;    return   x    +    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDefConcat"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" Needs   Java    9    to   test   indified   String   concat \"  ,    JRE _ IS _ MINIMUM _ JAVA 9  )  ;", "assertNotNull ( WriterConstants . INDY _ STRING _ CONCAT _ BOOTSTRAP _ HANDLE )  ;", "assertBytecodeExists (  \" String   s    =     \\  \" cat \\  \"  ;    return   s    +    true    +     \\  ' abc \\  '     +    null ;  \"  ,     \" INVOKEDYNAMIC   concat ( Ljava / lang / String ; ZLjava / lang / String ; Ljava / lang / Object ;  ) Ljava / lang / String ;  \"  )  ;", "}", "METHOD_END"], "methodName": ["testJava9StringConcatBytecode"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" foo 1  0  1  0 foo \"  ,    exec (  \" String   s    =     ' foo '  ;    String   x    =     '  1  0  '  ;    return   s    +    Integer . parseInt ( x    +    x )     +    s ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNestedConcats"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  \"  ,    exec (  \" return   new   String (  )  ;  \"  )  )  ;", "assertEquals (  ' x '  ,    exec (  \" String   s    =     \\  \" x \\  \"  ;    return   s . charAt (  0  )  ;  \"  )  )  ;", "assertEquals (  1  2  0  ,    exec (  \" String   s    =     \\  \" x \\  \"  ;    return   s . codePointAt (  0  )  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" String   s    =     \\  \" x \\  \"  ;    return   s . compareTo (  \\  \" x \\  \"  )  ;  \"  )  )  ;", "assertEquals (  \" xx \"  ,    exec (  \" String   s    =     \\  \" x \\  \"  ;    return   s . concat (  \\  \" x \\  \"  )  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" String   s    =     \\  \" xy \\  \"  ;    return   s . endsWith (  \\  \" y \\  \"  )  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" String   t    =     \\  \" abcde \\  \"  ;    return   t . indexOf (  \\  \" cd \\  \"  ,     1  )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" String   t    =     \\  \" abcde \\  \"  ;    return   t . isEmpty (  )  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" String   t    =     \\  \" abcde \\  \"  ;    return   t . length (  )  ;  \"  )  )  ;", "assertEquals (  \" cdcde \"  ,    exec (  \" String   t    =     \\  \" abcde \\  \"  ;    return   t . replace (  \\  \" ab \\  \"  ,     \\  \" cd \\  \"  )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" String   s    =     \\  \" xy \\  \"  ;    return   s . startsWith (  \\  \" y \\  \"  )  ;  \"  )  )  ;", "assertEquals (  \" e \"  ,    exec (  \" String   t    =     \\  \" abcde \\  \"  ;    return   t . substring (  4  ,     5  )  ;  \"  )  )  ;", "assertEquals (  9  7  ,     (  ( char [  ]  )     ( exec (  \" String   s    =     \\  \" a \\  \"  ;    return   s . toCharArray (  )  ;  \"  )  )  )  [  0  ]  )  ;", "assertEquals (  \" a \"  ,    exec (  \" String   s    =     \\  \"    a    \\  \"  ;    return   s . trim (  )  ;  \"  )  )  ;", "assertEquals (  ' x '  ,    exec (  \" return    \\  \" x \\  \"  . charAt (  0  )  ;  \"  )  )  ;", "assertEquals (  1  2  0  ,    exec (  \" return    \\  \" x \\  \"  . codePointAt (  0  )  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" return    \\  \" x \\  \"  . compareTo (  \\  \" x \\  \"  )  ;  \"  )  )  ;", "assertEquals (  \" xx \"  ,    exec (  \" return    \\  \" x \\  \"  . concat (  \\  \" x \\  \"  )  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    \\  \" xy \\  \"  . endsWith (  \\  \" y \\  \"  )  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" return    \\  \" abcde \\  \"  . indexOf (  \\  \" cd \\  \"  ,     1  )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    \\  \" abcde \\  \"  . isEmpty (  )  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" return    \\  \" abcde \\  \"  . length (  )  ;  \"  )  )  ;", "assertEquals (  \" cdcde \"  ,    exec (  \" return    \\  \" abcde \\  \"  . replace (  \\  \" ab \\  \"  ,     \\  \" cd \\  \"  )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    \\  \" xy \\  \"  . startsWith (  \\  \" y \\  \"  )  ;  \"  )  )  ;", "assertEquals (  \" e \"  ,    exec (  \" return    \\  \" abcde \\  \"  . substring (  4  ,     5  )  ;  \"  )  )  ;", "assertEquals (  9  7  ,     (  ( char [  ]  )     ( exec (  \" return    \\  \" a \\  \"  . toCharArray (  )  ;  \"  )  )  )  [  0  ]  )  ;", "assertEquals (  \" a \"  ,    exec (  \" return    \\  \"    a    \\  \"  . trim (  )  ;  \"  )  )  ;", "assertEquals (  \"  \"  ,    exec (  \" return   new   String (  )  ;  \"  )  )  ;", "assertEquals (  ' x '  ,    exec (  \" String   s    =     ' x '  ;    return   s . charAt (  0  )  ;  \"  )  )  ;", "assertEquals (  1  2  0  ,    exec (  \" String   s    =     ' x '  ;    return   s . codePointAt (  0  )  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" String   s    =     ' x '  ;    return   s . compareTo (  ' x '  )  ;  \"  )  )  ;", "assertEquals (  \" xx \"  ,    exec (  \" String   s    =     ' x '  ;    return   s . concat (  ' x '  )  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" String   s    =     ' xy '  ;    return   s . endsWith (  ' y '  )  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" String   t    =     ' abcde '  ;    return   t . indexOf (  ' cd '  ,     1  )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" String   t    =     ' abcde '  ;    return   t . isEmpty (  )  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" String   t    =     ' abcde '  ;    return   t . length (  )  ;  \"  )  )  ;", "assertEquals (  \" cdcde \"  ,    exec (  \" String   t    =     ' abcde '  ;    return   t . replace (  ' ab '  ,     ' cd '  )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" String   s    =     ' xy '  ;    return   s . startsWith (  ' y '  )  ;  \"  )  )  ;", "assertEquals (  \" e \"  ,    exec (  \" String   t    =     ' abcde '  ;    return   t . substring (  4  ,     5  )  ;  \"  )  )  ;", "assertEquals (  9  7  ,     (  ( char [  ]  )     ( exec (  \" String   s    =     ' a '  ;    return   s . toCharArray (  )  ;  \"  )  )  )  [  0  ]  )  ;", "assertEquals (  \" a \"  ,    exec (  \" String   s    =     '    a    '  ;    return   s . trim (  )  ;  \"  )  )  ;", "assertEquals (  ' x '  ,    exec (  \" return    ' x '  . charAt (  0  )  ;  \"  )  )  ;", "assertEquals (  1  2  0  ,    exec (  \" return    ' x '  . codePointAt (  0  )  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" return    ' x '  . compareTo (  ' x '  )  ;  \"  )  )  ;", "assertEquals (  \" xx \"  ,    exec (  \" return    ' x '  . concat (  ' x '  )  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return    ' xy '  . endsWith (  ' y '  )  ;  \"  )  )  ;", "assertEquals (  2  ,    exec (  \" return    ' abcde '  . indexOf (  ' cd '  ,     1  )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ' abcde '  . isEmpty (  )  ;  \"  )  )  ;", "assertEquals (  5  ,    exec (  \" return    ' abcde '  . length (  )  ;  \"  )  )  ;", "assertEquals (  \" cdcde \"  ,    exec (  \" return    ' abcde '  . replace (  ' ab '  ,     ' cd '  )  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return    ' xy '  . startsWith (  ' y '  )  ;  \"  )  )  ;", "assertEquals (  \" e \"  ,    exec (  \" return    ' abcde '  . substring (  4  ,     5  )  ;  \"  )  )  ;", "assertEquals (  9  7  ,     (  ( char [  ]  )     ( exec (  \" return    ' a '  . toCharArray (  )  ;  \"  )  )  )  [  0  ]  )  ;", "assertEquals (  \" a \"  ,    exec (  \" return    '    a    '  . trim (  )  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testStringAPI"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  ' c '  ,    exec (  \" return    ( char )  \\  \" c \\  \"  \"  )  )  ;", "assertEquals (  ' c '  ,    exec (  \" return    ( char )  ' c '  \"  )  )  ;", "assertEquals (  \" c \"  ,    exec (  \" return    (  )  ( char )  \\  \" c \\  \"  \"  )  )  ;", "assertEquals (  \" c \"  ,    exec (  \" return    (  )  ( char )  ' c '  \"  )  )  ;", "assertEquals (  ' c '  ,    exec (  \"    s    =     \\  \" c \\  \"  ;     ( char ) s \"  )  )  ;", "assertEquals (  ' c '  ,    exec (  \"    s    =     ' c '  ;     ( char ) s \"  )  )  ;", "ClassCastException   expected    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,    false ,     (  )     -  >     {", "assertEquals (  \" cc \"  ,    exec (  \" return    (  )  ( char )  \\  \" cc \\  \"  \"  )  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Cannot   cast    [  ]    with   length   greater   than   one   to    [ char ]  .  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,    false ,     (  )     -  >     {", "assertEquals (  \" cc \"  ,    exec (  \" return    (  )  ( char )  ' cc '  \"  )  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Cannot   cast    [  ]    with   length   greater   than   one   to    [ char ]  .  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "assertEquals (  ' c '  ,    exec (  \"    s    =     \\  \" cc \\  \"  ;     ( char ) s \"  )  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Cannot   cast    [  ]    with   length   greater   than   one   to    [ char ]  .  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "assertEquals (  ' c '  ,    exec (  \"    s    =     ' cc '  ;     ( char ) s \"  )  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Cannot   cast    [  ]    with   length   greater   than   one   to    [ char ]  .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testStringAndCharacter"], "fileName": "org.elasticsearch.painless.StringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  2     -     1  )  ,    exec (  \" return    2     -     1  ;  \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" int   x    =     1  ;    char   y    =     2  ;    return   x    -    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( byte )     (  1  )  )     -     (  ( byte )     (  1  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  2  )  )     -     (  ( byte )     (  3  )  )  )  ,    exec (  \" byte   x    =     2  ;    byte   y    =     3  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  5  )  )     -     (  ( byte )     (  1  0  )  )  )  ,    exec (  \" byte   x    =     5  ;    byte   y    =     1  0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     -     (  ( byte )     (  1  )  )  )     -     (  ( byte )     (  2  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    byte   z    =     2  ;    return   x - y - z ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     -     (  ( byte )     (  1  )  )  )     -     (  ( byte )     (  2  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    byte   z    =     2  ;    return    ( x - y )  - z ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     -     (  (  ( byte )     (  1  )  )     -     (  ( byte )     (  2  )  )  )  )  ,    exec (  \" byte   x    =     1  ;    byte   y    =     1  ;    byte   z    =     2  ;    return   x -  ( y - z )  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  0  )  )     -     (  ( byte )     (  1  )  )  )  ,    exec (  \" byte   x    =     1  0  ;    byte   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  0  )  )     -     (  ( byte )     (  0  )  )  )  ,    exec (  \" byte   x    =     0  ;    byte   y    =     0  ;    return   x - y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testByte"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( byte )     (  1  )  )     -     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    ( byte )  1  -  ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  2  )  )     -     (  ( byte )     (  3  )  )  )  ,    exec (  \" return    ( byte )  2  -  ( byte )  3  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  5  )  )     -     (  ( byte )     (  1  0  )  )  )  ,    exec (  \" return    ( byte )  5  -  ( byte )  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     -     (  ( byte )     (  1  )  )  )     -     (  ( byte )     (  2  )  )  )  ,    exec (  \" return    ( byte )  1  -  ( byte )  1  -  ( byte )  2  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( byte )     (  1  )  )     -     (  ( byte )     (  1  )  )  )     -     (  ( byte )     (  2  )  )  )  ,    exec (  \" return    (  ( byte )  1  -  ( byte )  1  )  -  ( byte )  2  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  )  )     -     (  (  ( byte )     (  1  )  )     -     (  ( byte )     (  2  )  )  )  )  ,    exec (  \" return    ( byte )  1  -  (  ( byte )  1  -  ( byte )  2  )  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  1  0  )  )     -     (  ( byte )     (  1  )  )  )  ,    exec (  \" return    ( byte )  1  0  -  ( byte )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( byte )     (  0  )  )     -     (  ( byte )     (  0  )  )  )  ,    exec (  \" return    ( byte )  0  -  ( byte )  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testByteConst"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( char )     (  1  )  )     -     (  ( char )     (  1  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  2  )  )     -     (  ( char )     (  3  )  )  )  ,    exec (  \" char   x    =     2  ;    char   y    =     3  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  5  )  )     -     (  ( char )     (  1  0  )  )  )  ,    exec (  \" char   x    =     5  ;    char   y    =     1  0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  (  ( char )     (  1  )  )     -     (  ( char )     (  1  )  )  )     -     (  ( char )     (  2  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     1  ;    char   z    =     2  ;    return   x - y - z ;  \"  )  )  ;", "assertEquals (  (  (  (  ( char )     (  1  )  )     -     (  ( char )     (  1  )  )  )     -     (  ( char )     (  2  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     1  ;    char   z    =     2  ;    return    ( x - y )  - z ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     -     (  (  ( char )     (  1  )  )     -     (  ( char )     (  2  )  )  )  )  ,    exec (  \" char   x    =     1  ;    char   y    =     1  ;    char   z    =     2  ;    return   x -  ( y - z )  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  0  )  )     -     (  ( char )     (  1  )  )  )  ,    exec (  \" char   x    =     1  0  ;    char   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  0  )  )     -     (  ( char )     (  0  )  )  )  ,    exec (  \" char   x    =     0  ;    char   y    =     0  ;    return   x - y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testChar"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( char )     (  1  )  )     -     (  ( char )     (  1  )  )  )  ,    exec (  \" return    ( char )  1  -  ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  2  )  )     -     (  ( char )     (  3  )  )  )  ,    exec (  \" return    ( char )  2  -  ( char )  3  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  5  )  )     -     (  ( char )     (  1  0  )  )  )  ,    exec (  \" return    ( char )  5  -  ( char )  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( char )     (  1  )  )     -     (  ( char )     (  1  )  )  )     -     (  ( char )     (  2  )  )  )  ,    exec (  \" return    ( char )  1  -  ( char )  1  -  ( char )  2  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( char )     (  1  )  )     -     (  ( char )     (  1  )  )  )     -     (  ( char )     (  2  )  )  )  ,    exec (  \" return    (  ( char )  1  -  ( char )  1  )  -  ( char )  2  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  )  )     -     (  (  ( char )     (  1  )  )     -     (  ( char )     (  2  )  )  )  )  ,    exec (  \" return    ( char )  1  -  (  ( char )  1  -  ( char )  2  )  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  1  0  )  )     -     (  ( char )     (  1  )  )  )  ,    exec (  \" return    ( char )  1  0  -  ( char )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( char )     (  0  )  )     -     (  ( char )     (  0  )  )  )  ,    exec (  \" return    ( char )  0  -  ( char )  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCharConst"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" byte   x    =     5  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  5  )  )  ,    exec (  \" byte   x    =     5  ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" short   x    =     5  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  5  )  )  ,    exec (  \" short   x    =     5  ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" char   x    =     5  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  5  )  )  ,    exec (  \" char   x    =     1  0  ;    x    -  =     5  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" int   x    =     5  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  )  ,    exec (  \" int   x    =     5  ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" long   x    =     5  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5 L )  ,    exec (  \" long   x    =     5  ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0 F ,    exec (  \" float   x    =     5 f ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0 F )  ,    exec (  \" float   x    =     5 f ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0  ,    exec (  \" double   x    =     5  .  0  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0  )  ,    exec (  \" double   x    =     5  .  0  ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignment"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( byte )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( short )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( char )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( int )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( long )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( float )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( byte )     (  1  5  )  )  ,    exec (  \" def   x    =     ( byte )  5  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  -  5  )  )  ,    exec (  \" def   x    =     ( byte )  5  ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  5  )  )  ,    exec (  \" def   x    =     ( short )  5  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  -  5  )  )  ,    exec (  \" def   x    =     ( short )  5  ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  5  )  )  ,    exec (  \" def   x    =     ( char )  5  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  5  )  )  ,    exec (  \" def   x    =     ( char )  1  0  ;    x    -  =     5  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  ,    exec (  \" def   x    =     5  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  )  ,    exec (  \" def   x    =     5  ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5 L ,    exec (  \" def   x    =     5 L ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5 L )  ,    exec (  \" def   x    =     5 L ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0 F ,    exec (  \" def   x    =     5 f ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0 F )  ,    exec (  \" def   x    =     5 f ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  1  5  .  0  ,    exec (  \" def   x    =     5  .  0  ;    x    -  =     -  1  0  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  -  5  .  0  )  ,    exec (  \" def   x    =     5  .  0  ;    x    -  =     1  0  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefCompoundAssignment"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" byte   x    =     ( byte )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" short   x    =     ( short )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" char   x    =     ( char )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" int   x    =     ( int )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" long   x    =     ( long )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" float   x    =     ( float )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" double   x    =     ( double )  1  ;    def   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedLHS"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  1  ;    byte   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  1  ;    byte   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  1  ;    byte   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  1  ;    byte   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    byte   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    byte   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    byte   y    =     ( byte )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  1  ;    short   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  1  ;    short   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  1  ;    short   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  1  ;    short   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    short   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    short   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    short   y    =     ( short )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  1  ;    char   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  1  ;    char   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  1  ;    char   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  1  ;    char   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    char   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    char   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    char   y    =     ( char )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( byte )  1  ;    int   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( short )  1  ;    int   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( char )  1  ;    int   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  ,    exec (  \" def   x    =     ( int )  1  ;    int   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    int   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    int   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    int   y    =     ( int )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( byte )  1  ;    long   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( short )  1  ;    long   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( char )  1  ;    long   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( int )  1  ;    long   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0 L ,    exec (  \" def   x    =     ( long )  1  ;    long   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    long   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    long   y    =     ( long )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( byte )  1  ;    float   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( short )  1  ;    float   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( char )  1  ;    float   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( int )  1  ;    float   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( long )  1  ;    float   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0 F ,    exec (  \" def   x    =     ( float )  1  ;    float   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    float   y    =     ( float )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( byte )  1  ;    double   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( short )  1  ;    double   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( char )  1  ;    double   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( int )  1  ;    double   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( long )  1  ;    double   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( float )  1  ;    double   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "assertEquals (  0  .  0  ,    exec (  \" def   x    =     ( double )  1  ;    double   y    =     ( double )  1  ;    return   x    -    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedRHS"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     -     1  .  0  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  2  .  0     -     3  .  0  )  ,    exec (  \" double   x    =     2  ;    double   y    =     3  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  5  .  0     -     1  0  .  0  )  ,    exec (  \" double   x    =     5  ;    double   y    =     1  0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     -     1  .  0  )     -     2  .  0  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    double   z    =     2  ;    return   x - y - z ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     -     1  .  0  )     -     2  .  0  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    double   z    =     2  ;    return    ( x - y )  - z ;  \"  )  )  ;", "assertEquals (  (  1  .  0     -     (  1  .  0     -     2  .  0  )  )  ,    exec (  \" double   x    =     1  ;    double   y    =     1  ;    double   z    =     2  ;    return   x -  ( y - z )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     -     0  .  0  )  ,    exec (  \" double   x    =     1  0  ;    float   y    =     0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  0  .  0     -     0  .  0  )  ,    exec (  \" double   x    =     0  ;    float   y    =     0  ;    return   x - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDouble"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    -     1  .  0 F )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  2  .  0 F    -     3  .  0 F )  ,    exec (  \" float   x    =     2  ;    float   y    =     3  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    -     1  0  .  0 F )  ,    exec (  \" float   x    =     5  ;    float   y    =     1  0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    -     1  .  0 F )     -     2  .  0 F )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    float   z    =     2  ;    return   x - y - z ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    -     1  .  0 F )     -     2  .  0 F )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    float   z    =     2  ;    return    ( x - y )  - z ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    -     (  1  .  0 F    -     2  .  0 F )  )  ,    exec (  \" float   x    =     1  ;    float   y    =     1  ;    float   z    =     2  ;    return   x -  ( y - z )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    -     0  .  0 F )  ,    exec (  \" float   x    =     1  0  ;    float   y    =     0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    -     0  .  0 F )  ,    exec (  \" float   x    =     0  ;    float   y    =     0  ;    return   x - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloat"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0 F    -     1  .  0 F )  ,    exec (  \" return    1 F -  1 F ;  \"  )  )  ;", "assertEquals (  (  2  .  0 F    -     3  .  0 F )  ,    exec (  \" return    2 F -  3 F ;  \"  )  )  ;", "assertEquals (  (  5  .  0 F    -     1  0  .  0 F )  ,    exec (  \" return    5 F -  1  0 F ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    -     1  .  0 F )     -     2  .  0 F )  ,    exec (  \" return    1 F -  1 F -  2 F ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0 F    -     1  .  0 F )     -     2  .  0 F )  ,    exec (  \" return    (  1 F -  1 F )  -  2 F ;  \"  )  )  ;", "assertEquals (  (  1  .  0 F    -     (  1  .  0 F    -     2  .  0 F )  )  ,    exec (  \" return    1 F -  (  1 F -  2 F )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0 F    -     0  .  0 F )  ,    exec (  \" return    1  0 F -  0 F ;  \"  )  )  ;", "assertEquals (  (  0  .  0 F    -     0  .  0 F )  ,    exec (  \" return    0 F -  0 F ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFloatConst"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     -     1  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  2     -     3  )  ,    exec (  \" int   x    =     2  ;    int   y    =     3  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  5     -     1  0  )  ,    exec (  \" int   x    =     5  ;    int   y    =     1  0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  1     -     1  )     -     2  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    int   z    =     2  ;    return   x - y - z ;  \"  )  )  ;", "assertEquals (  (  (  1     -     1  )     -     2  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    int   z    =     2  ;    return    ( x - y )  - z ;  \"  )  )  ;", "assertEquals (  (  1     -     (  1     -     2  )  )  ,    exec (  \" int   x    =     1  ;    int   y    =     1  ;    int   z    =     2  ;    return   x -  ( y - z )  ;  \"  )  )  ;", "assertEquals (  (  1  0     -     0  )  ,    exec (  \" int   x    =     1  0  ;    int   y    =     0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  0     -     0  )  ,    exec (  \" int   x    =     0  ;    int   y    =     0  ;    return   x - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInt"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1     -     1  )  ,    exec (  \" return    1  -  1  ;  \"  )  )  ;", "assertEquals (  (  2     -     3  )  ,    exec (  \" return    2  -  3  ;  \"  )  )  ;", "assertEquals (  (  5     -     1  0  )  ,    exec (  \" return    5  -  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  1     -     1  )     -     2  )  ,    exec (  \" return    1  -  1  -  2  ;  \"  )  )  ;", "assertEquals (  (  (  1     -     1  )     -     2  )  ,    exec (  \" return    (  1  -  1  )  -  2  ;  \"  )  )  ;", "assertEquals (  (  1     -     (  1     -     2  )  )  ,    exec (  \" return    1  -  (  1  -  2  )  ;  \"  )  )  ;", "assertEquals (  (  1  0     -     0  )  ,    exec (  \" return    1  0  -  0  ;  \"  )  )  ;", "assertEquals (  (  0     -     0  )  ,    exec (  \" return    0  -  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIntConst"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    -     1 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  2 L    -     3 L )  ,    exec (  \" long   x    =     2  ;    long   y    =     3  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  5 L    -     1  0 L )  ,    exec (  \" long   x    =     5  ;    long   y    =     1  0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  1 L    -     1 L )     -     2 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    int   z    =     2  ;    return   x - y - z ;  \"  )  )  ;", "assertEquals (  (  (  1 L    -     1 L )     -     2 L )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    int   z    =     2  ;    return    ( x - y )  - z ;  \"  )  )  ;", "assertEquals (  (  1 L    -     (  1 L    -     2 L )  )  ,    exec (  \" long   x    =     1  ;    long   y    =     1  ;    int   z    =     2  ;    return   x -  ( y - z )  ;  \"  )  )  ;", "assertEquals (  (  1  0 L    -     0 L )  ,    exec (  \" long   x    =     1  0  ;    long   y    =     0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  0 L    -     0 L )  ,    exec (  \" long   x    =     0  ;    long   y    =     0  ;    return   x - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLong"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1 L    -     1 L )  ,    exec (  \" return    1 L -  1 L ;  \"  )  )  ;", "assertEquals (  (  2 L    -     3 L )  ,    exec (  \" return    2 L -  3 L ;  \"  )  )  ;", "assertEquals (  (  5 L    -     1  0 L )  ,    exec (  \" return    5 L -  1  0 L ;  \"  )  )  ;", "assertEquals (  (  (  1 L    -     1 L )     -     2 L )  ,    exec (  \" return    1 L -  1 L -  2 L ;  \"  )  )  ;", "assertEquals (  (  (  1 L    -     1 L )     -     2 L )  ,    exec (  \" return    (  1 L -  1 L )  -  2 L ;  \"  )  )  ;", "assertEquals (  (  1 L    -     (  1 L    -     2 L )  )  ,    exec (  \" return    1 L -  (  1 L -  2 L )  ;  \"  )  )  ;", "assertEquals (  (  1  0 L    -     0 L )  ,    exec (  \" return    1  0 L -  0 L ;  \"  )  )  ;", "assertEquals (  (  0 L    -     0 L )  ,    exec (  \" return    0 L -  0 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongConst"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( short )     (  1  )  )     -     (  ( short )     (  1  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  2  )  )     -     (  ( short )     (  3  )  )  )  ,    exec (  \" short   x    =     2  ;    short   y    =     3  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  5  )  )     -     (  ( short )     (  1  0  )  )  )  ,    exec (  \" short   x    =     5  ;    short   y    =     1  0  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  (  ( short )     (  1  )  )     -     (  ( short )     (  1  )  )  )     -     (  ( short )     (  2  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     1  ;    short   z    =     2  ;    return   x - y - z ;  \"  )  )  ;", "assertEquals (  (  (  (  ( short )     (  1  )  )     -     (  ( short )     (  1  )  )  )     -     (  ( short )     (  2  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     1  ;    short   z    =     2  ;    return    ( x - y )  - z ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     -     (  (  ( short )     (  1  )  )     -     (  ( short )     (  2  )  )  )  )  ,    exec (  \" short   x    =     1  ;    short   y    =     1  ;    short   z    =     2  ;    return   x -  ( y - z )  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  0  )  )     -     (  ( short )     (  1  )  )  )  ,    exec (  \" short   x    =     1  0  ;    short   y    =     1  ;    return   x - y ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  0  )  )     -     (  ( short )     (  0  )  )  )  ,    exec (  \" short   x    =     0  ;    short   y    =     0  ;    return   x - y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testShort"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  (  ( short )     (  1  )  )     -     (  ( short )     (  1  )  )  )  ,    exec (  \" return    ( short )  1  -  ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  2  )  )     -     (  ( short )     (  3  )  )  )  ,    exec (  \" return    ( short )  2  -  ( short )  3  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  5  )  )     -     (  ( short )     (  1  0  )  )  )  ,    exec (  \" return    ( short )  5  -  ( short )  1  0  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( short )     (  1  )  )     -     (  ( short )     (  1  )  )  )     -     (  ( short )     (  2  )  )  )  ,    exec (  \" return    ( short )  1  -  ( short )  1  -  ( short )  2  ;  \"  )  )  ;", "assertEquals (  (  (  (  ( short )     (  1  )  )     -     (  ( short )     (  1  )  )  )     -     (  ( short )     (  2  )  )  )  ,    exec (  \" return    (  ( short )  1  -  ( short )  1  )  -  ( short )  2  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  )  )     -     (  (  ( short )     (  1  )  )     -     (  ( short )     (  2  )  )  )  )  ,    exec (  \" return    ( short )  1  -  (  ( short )  1  -  ( short )  2  )  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  1  0  )  )     -     (  ( short )     (  1  )  )  )  ,    exec (  \" return    ( short )  1  0  -  ( short )  1  ;  \"  )  )  ;", "assertEquals (  (  (  ( short )     (  0  )  )     -     (  ( short )     (  0  )  )  )  ,    exec (  \" return    ( short )  0  -  ( short )  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testShortConst"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  1  .  0     -     1  .  0  )  ,    exec (  \" return    1  .  0  -  1  .  0  ;  \"  )  )  ;", "assertEquals (  (  2  .  0     -     3  .  0  )  ,    exec (  \" return    2  .  0  -  3  .  0  ;  \"  )  )  ;", "assertEquals (  (  5  .  0     -     1  0  .  0  )  ,    exec (  \" return    5  .  0  -  1  0  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     -     1  .  0  )     -     2  .  0  )  ,    exec (  \" return    1  .  0  -  1  .  0  -  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  (  1  .  0     -     1  .  0  )     -     2  .  0  )  ,    exec (  \" return    (  1  .  0  -  1  .  0  )  -  2  .  0  ;  \"  )  )  ;", "assertEquals (  (  1  .  0     -     (  1  .  0     -     2  .  0  )  )  ,    exec (  \" return    1  .  0  -  (  1  .  0  -  2  .  0  )  ;  \"  )  )  ;", "assertEquals (  (  1  0  .  0     -     0  .  0  )  ,    exec (  \" return    1  0  .  0  -  0  .  0  ;  \"  )  )  ;", "assertEquals (  (  0  .  0     -     0  .  0  )  ,    exec (  \" return    0  .  0  -  0  .  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testyDoubleConst"], "fileName": "org.elasticsearch.painless.SubtractionTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  (  \" try    {    if    ( params . param    =  =     ' true '  )    throw   new   RuntimeException (  ' test '  )  ;     }     \"     +     \" catch    ( RuntimeException   e )     {    return    1  ;     }    return    2  ;  \"  )  ,    Collections . singletonMap (  \" param \"  ,     \" true \"  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testCatch"], "fileName": "org.elasticsearch.painless.TryCatchTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  1  ,    exec (  (  \" try    {    if    ( params . param    =  =     ' true '  )    throw   new   RuntimeException (  ' test '  )  ;     }     \"     +     \" catch    ( Exception   e )     {    return    1  ;     }    return    2  ;  \"  )  ,    Collections . singletonMap (  \" param \"  ,     \" true \"  )  ,    true )  )  ;", "}", "METHOD_END"], "methodName": ["testCatchSuperclass"], "fileName": "org.elasticsearch.painless.TryCatchTests"}, {"methodBody": ["METHOD_START", "{", "RuntimeException   exception    =    ScriptTestCase . expectScriptThrows ( RuntimeException . class ,     (  )     -  >     {", "exec (  (  \" try    {    if    ( params . param    =  =     ' true '  )    throw   new   RuntimeException (  ' test '  )  ;     }     \"     +     \" catch    ( ArithmeticException   e )     {    return    1  ;     }    return    2  ;  \"  )  ,    Collections . singletonMap (  \" param \"  ,     \" true \"  )  ,    true )  ;", "}  )  ;", "assertEquals (  \" test \"  ,    exception . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNoCatch"], "fileName": "org.elasticsearch.painless.TryCatchTests"}, {"methodBody": ["METHOD_START", "{", "RuntimeException   exception    =    ScriptTestCase . expectScriptThrows ( RuntimeException . class ,     (  )     -  >     {", "exec (  \" throw   new   RuntimeException (  ' test '  )  \"  )  ;", "}  )  ;", "assertEquals (  \" test \"  ,    exception . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThrow"], "fileName": "org.elasticsearch.painless.TryCatchTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" return    ! true ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    false ;    return    ! x ;  \"  )  )  ;", "assertEquals (  (  -  2  )  ,    exec (  \" return    ~  1  ;  \"  )  )  ;", "assertEquals (  (  -  2  )  ,    exec (  \" byte   x    =     1  ;    return    ~ x ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" return    +  1  ;  \"  )  )  ;", "assertEquals (  1  .  0  ,    exec (  \" double   x    =     1  ;    return    + x ;  \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" return    -  1  ;  \"  )  )  ;", "assertEquals (  (  -  2  )  ,    exec (  \" short   x    =     2  ;    return    - x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.UnaryTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     ( byte )  1  ;    return    - x \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     ( short )  1  ;    return    - x \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     ( char )  1  ;    return    - x \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     1  ;    return    - x \"  )  )  ;", "assertEquals (  (  -  1 L )  ,    exec (  \" def   x    =     1 L ;    return    - x \"  )  )  ;", "assertEquals (  (  -  1  .  0 F )  ,    exec (  \" def   x    =     1 F ;    return    - x \"  )  )  ;", "assertEquals (  (  -  1  .  0  )  ,    exec (  \" def   x    =     1  .  0  ;    return    - x \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefNeg"], "fileName": "org.elasticsearch.painless.UnaryTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( double )     (  -  1  )  )  ,    exec (  \" def   x    =     ( byte )  1  ;    double   y    =     - x ;    return   y ;  \"  )  )  ;", "assertEquals (  (  ( float )     (  -  1  )  )  ,    exec (  \" def   x    =     ( short )  1  ;    float   y    =     - x ;    return   y ;  \"  )  )  ;", "assertEquals (  (  ( long )     (  -  1  )  )  ,    exec (  \" def   x    =     ( char )  1  ;    long   y    =     - x ;    return   y ;  \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     1  ;    int   y    =     - x ;    return   y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefNegTypedRet"], "fileName": "org.elasticsearch.painless.UnaryTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ~  1  )  ,    exec (  \" def   x    =     ( byte )  1  ;    return    ~ x \"  )  )  ;", "assertEquals (  (  ~  1  )  ,    exec (  \" def   x    =     ( short )  1  ;    return    ~ x \"  )  )  ;", "assertEquals (  (  ~  1  )  ,    exec (  \" def   x    =     ( char )  1  ;    return    ~ x \"  )  )  ;", "assertEquals (  (  ~  1  )  ,    exec (  \" def   x    =     1  ;    return    ~ x \"  )  )  ;", "assertEquals (  (  ~  1 L )  ,    exec (  \" def   x    =     1 L ;    return    ~ x \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefNot"], "fileName": "org.elasticsearch.painless.UnaryTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( double )     (  ~  1  )  )  ,    exec (  \" def   x    =     ( byte )  1  ;    double   y    =     ~ x ;    return   y ;  \"  )  )  ;", "assertEquals (  (  ( float )     (  ~  1  )  )  ,    exec (  \" def   x    =     ( short )  1  ;    float   y    =     ~ x ;    return   y ;  \"  )  )  ;", "assertEquals (  (  ( long )     (  ~  1  )  )  ,    exec (  \" def   x    =     ( char )  1  ;    long   y    =     ~ x ;    return   y ;  \"  )  )  ;", "assertEquals (  (  ~  1  )  ,    exec (  \" def   x    =     1  ;    int   y    =     ~ x ;    return   y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefNotTypedRet"], "fileName": "org.elasticsearch.painless.UnaryTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     ( byte )  -  1  ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     ( short )  -  1  ;    return    + x \"  )  )  ;", "assertEquals (  6  5  5  3  5  ,    exec (  \" def   x    =     ( char )  -  1  ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     -  1  ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1 L )  ,    exec (  \" def   x    =     -  1 L ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1  .  0 F )  ,    exec (  \" def   x    =     -  1 F ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1  .  0  )  ,    exec (  \" def   x    =     -  1  .  0  ;    return    + x \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefPlus"], "fileName": "org.elasticsearch.painless.UnaryTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  ( double )     (  -  1  )  )  ,    exec (  \" def   x    =     ( byte )  -  1  ;    double   y    =     + x ;    return   y ;  \"  )  )  ;", "assertEquals (  (  ( float )     (  -  1  )  )  ,    exec (  \" def   x    =     ( short )  -  1  ;    float   y    =     + x ;    return   y ;  \"  )  )  ;", "assertEquals (  (  ( long )     (  6  5  5  3  5  )  )  ,    exec (  \" def   x    =     ( char )  -  1  ;    long   y    =     + x ;    return   y ;  \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" def   x    =     -  1  ;    int   y    =     + x ;    return   y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefPlusTypedRet"], "fileName": "org.elasticsearch.painless.UnaryTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  -  1  )  ,    exec (  \" return    -  1  ;  \"  )  )  ;", "assertEquals (  1  ,    exec (  \" return    -  (  -  1  )  ;  \"  )  )  ;", "assertEquals (  0  ,    exec (  \" return    -  0  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNegationInt"], "fileName": "org.elasticsearch.painless.UnaryTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  -  1  )  ,    exec (  \" byte   x    =     ( byte )  -  1  ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" short   x    =     ( short )  -  1  ;    return    + x \"  )  )  ;", "assertEquals (  6  5  5  3  5  ,    exec (  \" char   x    =     ( char )  -  1  ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1  )  ,    exec (  \" int   x    =     -  1  ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1 L )  ,    exec (  \" long   x    =     -  1 L ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1  .  0 F )  ,    exec (  \" float   x    =     -  1 F ;    return    + x \"  )  )  ;", "assertEquals (  (  -  1  .  0  )  ,    exec (  \" double   x    =     -  1  .  0  ;    return    + x \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPlus"], "fileName": "org.elasticsearch.painless.UnaryTests"}, {"methodBody": ["METHOD_START", "{", "if    (  ( value . length (  )  )     !  =     1  )     {", "throw   new   CsCastException (  \" Cannot   cast    [ String ]    with   length   greater   than   one   to    [ char ]  .  \"  )  ;", "}", "return   value . charAt (  0  )  ;", "}", "METHOD_END"], "methodName": ["StringTochar"], "fileName": "org.elasticsearch.painless.Utility"}, {"methodBody": ["METHOD_START", "{", "return   String . valueOf ( value )  ;", "}", "METHOD_END"], "methodName": ["charToString"], "fileName": "org.elasticsearch.painless.Utility"}, {"methodBody": ["METHOD_START", "{", "StackTraceElement [  ]    stackTrace    =    exception . getCause (  )  . getStackTrace (  )  ;", "for    ( int   i    =     0  ;    i    <     ( stackTrace . length )  ;    i +  +  )     {", "if    ( WriterConstants . CLASS _ NAME . equals ( stackTrace [ i ]  . getCsName (  )  )  )     {", "if    (  ( expectedColumn    +     1  )     !  =     ( stackTrace [ i ]  . getLineNumber (  )  )  )     {", "AssertionFailedError   assertion    =    new   AssertionFailedError (  (  (  (  (  \" Expected   column   to   be    [  \"     +    expectedColumn )     +     \"  ]    but   was    [  \"  )     +     ( stackTrace [ i ]  . getLineNumber (  )  )  )     +     \"  ]  \"  )  )  ;", "assertion . initCause ( exception )  ;", "throw   assertion ;", "}", "return ;", "}", "}", "fail (  \" didn ' t   find   script   stack   element \"  )  ;", "}", "METHOD_END"], "methodName": ["assertScriptElementColumn"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" BitSet   bs    =    new   BitSet (  )  ;    bs . and (  2  )  ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBadBoxingCast"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \"  \\  '  \\  \\ a \\  '  \"  ,    false )  )  ;", "assertEquals (  \" unexpected   character    [  \\  '  \\  \\ a ]  .    The   only   valid   escape   sequences   in   strings   starting   with    [  \\  '  ]    are    [  \\  \\  \\  \\  ]    and    [  \\  \\  \\  '  ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \"  \\  \"  \\  \\ a \\  \"  \"  ,    false )  )  ;", "assertEquals (  \" unexpected   character    [  \\  \"  \\  \\ a ]  .    The   only   valid   escape   sequences   in   strings   starting   with    [  \\  \"  ]    are    [  \\  \\  \\  \\  ]    and    [  \\  \\  \\  \"  ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBadStringEscape"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" return    5  ;  \"  ,    null ,    Collections . singletonMap (  \" bogusParameterKey \"  ,     \" bogusParameterValue \"  )  ,    null ,    true )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Unrecognized   compile - time   parameter \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBogusParameter"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \"  \"  ,    null ,    singletonMap ( CompilerSettings . REGEX _ ENABLED . getKey (  )  ,     \" true \"  )  ,    null ,    false )  )  ;", "assertEquals (  \"  [ regex . enabled ]    can   only   be   set   on   node   startup .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCanNotOverrideRegexEnabled"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( WrongMethodTypeException . class ,     (  )     -  >     {", "exec (  \" def   x    =    new   long [  1  ]  ;    x [  0  ]  =  1  ;    return   x [  ' bogus '  ]  ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDynamicArrayWrongIndex"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( WrongMethodTypeException . class ,     (  )     -  >     {", "exec (  \" def   x    =    new   ArrayList (  )  ;    x . add (  ' foo '  )  ;    return   x [  ' bogus '  ]  ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDynamicListWrongIndex"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( NullPointerException . class ,     (  )     -  >     {", "exec (  \" def   x    =    null ;    return   x . toString (  )  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDynamicNPE"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( WrongMethodTypeException . class ,     (  )     -  >     {", "exec (  \" def   x    =    new   ArrayList (  )  ;    return   x . get (  ' bogus '  )  ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDynamicWrongArgs"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   expected    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ' test '  ;    return   x . getClass (  )  . toString (  )  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Unable   to   find   dynamic   method \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIllegalDynamicMethod"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "PainlessError   expected    =    ScriptTestCase . expectScriptThrows ( PainlessError . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    true ;    while    ( x )     {  }  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( PainlessError . class ,     (  )     -  >     {", "exec (  \" while    ( true )     { int   y    =     5  ;  }  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( PainlessError . class ,     (  )     -  >     {", "exec (  \" while    ( true )     {    boolean   x    =    true ;    while    ( x )     {  }     }  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( PainlessError . class ,     (  )     -  >     {", "exec (  \" while    ( true )     {    boolean   x    =    false ;    while    ( x )     {  }     }  \"  )  ;", "fail (  \" should   have   hit   PainlessError \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( PainlessError . class ,     (  )     -  >     {", "exec (  \" boolean   x    =    true ;    for    (  ; x ;  )     {  }  \"  )  ;", "fail (  \" should   have   hit   PainlessError \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( PainlessError . class ,     (  )     -  >     {", "exec (  \" for    (  ;  ;  )     { int   x    =     5  ;  }  \"  )  ;", "fail (  \" should   have   hit   PainlessError \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  )  ;", "expected    =    ScriptTestCase . expectScriptThrows ( PainlessError . class ,     (  )     -  >     {", "exec (  \" def   x    =    true ;    do    { int   y    =     5  ;  }    while    ( x )  \"  )  ;", "fail (  \" should   have   hit   PainlessError \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  )  ;", "RuntimeException   parseException    =    ScriptTestCase . expectScriptThrows ( RuntimeException . class ,     (  )     -  >     {", "exec (  \" try    {    int   x ;     }    catch    ( PainlessError   error )     {  }  \"  ,    false )  ;", "fail (  \" should   have   hit   ParseException \"  )  ;", "}  )  ;", "assertTrue ( parseException . getMessage (  )  . contains (  \" unexpected   token    [  ' PainlessError '  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInfiniteLoops"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return    8  6  4  0  0  0  0  0  0  0  0  0  \"  )  )  ;", "assertEquals (  \" Invalid   int   constant    [  8  6  4  0  0  0  0  0  0  0  0  0  ]  .    If   you   want   a   long   constant   then   change   it   to    [  8  6  4  0  0  0  0  0  0  0  0  0 L ]  .  \"  ,    e . getMessage (  )  )  ;", "assertEquals (  8  6  4  0  0  0  0  0  0  0  0  0 L ,    exec (  \" return    8  6  4  0  0  0  0  0  0  0  0  0 L \"  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return    -  8  6  4  0  0  0  0  0  0  0  0  0  \"  )  )  ;", "assertEquals (  \" Invalid   int   constant    [  -  8  6  4  0  0  0  0  0  0  0  0  0  ]  .    If   you   want   a   long   constant   then   change   it   to    [  -  8  6  4  0  0  0  0  0  0  0  0  0 L ]  .  \"  ,    e . getMessage (  )  )  ;", "assertEquals (  (  -  8  6  4  0  0  0  0  0  0  0  0  0 L )  ,    exec (  \" return    -  8  6  4  0  0  0  0  0  0  0  0  0 L \"  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return    9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  0  \"  )  )  ;", "assertEquals (  \" Invalid   int   constant    [  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  0  ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return    -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  0  \"  )  )  ;", "assertEquals (  \" Invalid   int   constant    [  -  9  2  2  3  3  7  2  0  3  6  8  5  4  7  7  5  8  0  7  0  ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidIntConstantSuggestsLong"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     1  5 F ;    x    <  <  =     2  ;    return   x ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     1  5 F ;    x    <  <  =     2  ;    return   x ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidShift"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "exec (  \" for    ( int   x    =     0  ;    x    <     9  9  9  9  9  9  ;     +  + x )     {  }  \"  )  ;", "PError   expected    =    ScriptTestCase . expectScriptThrows ( PError . class ,     (  )     -  >     {", "exec (  \" for    ( int   x    =     0  ;    x    <     1  0  0  0  0  0  0  ;     +  + x )     {  }  \"  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" The   maximum   number   of   statements   that   can   be   executed   in   a   loop   has   been   reached .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLoopLimits"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( NullPointerException . class ,     (  )     -  >     {", "exec (  \" int   x    =    params [  ' missing '  ]  ;    return   x ;  \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( NullPointerException . class ,     (  )     -  >     {", "exec (  \" Double . parseDouble ( params [  ' missing '  ]  )  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testNullPointer"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   only   happens   to   work   for   sure   on   oracle   jre \"  ,    JAVA _ VENDOR . startsWith (  \" Oracle \"  )  )  ;", "ScriptCase . expectScriptThrows ( OutOfMemoryError . class ,     (  )     -  >     {", "exec (  \" int [  ]    x    =    new   int [ Integer . MAX _ VALUE    -     1  ]  ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testOutOfMemoryError"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \" return   params . a ?     . b \"  ,    false )  )  ;", "assertEquals (  \" invalid   sequence   of   tokens   near    [  '  .  '  ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testQuestionSpaceDotIsNotNullSafeDereference"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "exec (  \" def   i    =     1  }    return    1  \"  ,    emptyMap (  )  ,    emptyMap (  )  ,    null ,    false )  ;", "}  )  ;", "assertEquals (  \" unexpected   token    [  '  }  '  ]    was   expecting   one   of    [  < EOF >  ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRCurlyNotDelim"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "IllegalStateException   e    =    expectThrows ( IllegalStateException . class ,     (  )     -  >    exec (  \" return    ' foo '     =  =  ~     / foo /  \"  )  )  ;", "assertEquals (  (  \" Regexes   are   disabled .    Set    [ script . painless . regex . enabled ]    to    [ true ]    in   yaml   to   allow   them .     \"     +     \" Be   careful   though ,    regexes   break   out   of   Painless ' s   protection   against   deep   recursion   and   long   loops .  \"  )  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRegexDisabledByDefault"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "Exception   e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \"  '  \"  ,    false )  )  ;", "assertEquals (  \" unexpected   character    [  '  ]  .  \"  ,    e . getMessage (  )  )  ;", "e    =    ScriptTestCase . expectScriptThrows ( IllegalArgumentException . class ,     (  )     -  >    exec (  \"  ' cat \"  ,    false )  )  ;", "assertEquals (  \" unexpected   character    [  ' cat ]  .  \"  ,    e . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testRegularUnexpectedCharacter"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "for    ( String   type    :    new   String [  ]  {     \" String \"  ,     \" def          \"     }  )     {", "ScriptException   exception    =    expectThrows ( ScriptException . class ,     (  )     -  >     {", "exec (  (  ( type    +     \"    x    =    null ;    boolean   y    =    x . isEmpty (  )  ;  \\ n \"  )     +     \" return   y ;  \"  )  )  ;", "}  )  ;", "assertScriptElementColumn (  3  0  ,    exception )  ;", "ScriptCase . assertScriptStack ( exception ,     \" y    =    x . isEmpty (  )  ;  \\ n \"  ,     \"                 ^  -  -  -  -    HERE \"  )  ;", "assertThat ( exception . getCause (  )  ,    instanceOf ( NullPointerException . class )  )  ;", "exception    =    expectThrows ( ScriptException . class ,     (  )     -  >     {", "exec (  (  ( type    +     \"    x    =    null ;  \\ n \"  )     +     \" return   x . isEmpty (  )  ;  \"  )  )  ;", "}  )  ;", "assertScriptElementColumn (  2  5  ,    exception )  ;", "ScriptCase . assertScriptStack ( exception ,     \" return   x . isEmpty (  )  ;  \"  ,     \"                          ^  -  -  -  -    HERE \"  )  ;", "assertThat ( exception . getCause (  )  ,    instanceOf ( NullPointerException . class )  )  ;", "exception    =    expectThrows ( ScriptException . class ,     (  )     -  >     {", "exec (  (  (  (  ( type    +     \"    x    =    null ;  \\ n \"  )     +    type )     +     \"    y    =    x ;  \\ n \"  )     +     \" return   y . isEmpty (  )  ;  \"  )  )  ;", "}  )  ;", "assertScriptElementColumn (  3  9  ,    exception )  ;", "ScriptCase . assertScriptStack ( exception ,     \" return   y . isEmpty (  )  ;  \"  ,     \"                          ^  -  -  -  -    HERE \"  )  ;", "assertThat ( exception . getCause (  )  ,    instanceOf ( NullPointerException . class )  )  ;", "exception    =    expectThrows ( ScriptException . class ,     (  )     -  >     {", "exec (  (  (  (  (  (  ( type    +     \"    x    =    null ;  \\ n \"  )     +     \" boolean   y    =    false ;  \\ n \"  )     +     \" if    (  ! y )     {  \\ n \"  )     +     \"       y    =    x . isEmpty (  )  ;  \\ n \"  )     +     \"  }  \\ n \"  )     +     \" return   y ;  \"  )  )  ;", "}  )  ;", "assertScriptElementColumn (  5  3  ,    exception )  ;", "ScriptCase . assertScriptStack ( exception ,     \" y    =    x . isEmpty (  )  ;  \\ n }  \\ n \"  ,     \"                 ^  -  -  -  -    HERE \"  )  ;", "assertThat ( exception . getCause (  )  ,    instanceOf ( NullPointerException . class )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testScriptStack"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "final   char [  ]    tooManyChars    =    new   char [  ( Compiler . MAXIMUM _ SOURCE _ LENGTH )     +     1  ]  ;", "Arrays . fill ( tooManyChars ,     '  0  '  )  ;", "IllegalArgumentException   expected    =    ScriptCase . expectScriptThrows ( IllegalArgumentException . class ,    false ,     (  )     -  >     {", "exec ( new   String ( tooManyChars )  )  ;", "}  )  ;", "assertTrue ( expected . getMessage (  )  . contains (  \" Scripts   may   be   no   longer   than \"  )  )  ;", "final   char [  ]    exactlyAtLimit    =    new   char [ Compiler . MAXIMUM _ SOURCE _ LENGTH ]  ;", "Arrays . fill ( exactlyAtLimit ,     '  0  '  )  ;", "assertEquals (  0  ,    exec ( new   String ( exactlyAtLimit )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSourceLimits"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( StackOverflowError . class ,     (  )     -  >     {", "exec (  \" void   recurse ( int   x ,    int   y )     { recurse ( x ,    y )  }    recurse (  1  ,     2  )  ;  \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testStackOverflowError"], "fileName": "org.elasticsearch.painless.WhenThingsGoWrongTests"}, {"methodBody": ["METHOD_START", "{", "return   new   Method ( name ,    MethodType . methodType ( rtype ,    ptypes )  . toMethodDescriptorString (  )  )  ;", "}", "METHOD_END"], "methodName": ["getAsmMethod"], "fileName": "org.elasticsearch.painless.WriterConstants"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  9     ^     3  )  ,    exec (  \" return    9     ^     3  ;  \"  )  )  ;", "assertEquals (  (  9 L    ^     3  )  ,    exec (  \" return    9 L    ^     3  ;  \"  )  )  ;", "assertEquals (  (  9     ^     3 L )  ,    exec (  \" return    9     ^     3 L ;  \"  )  )  ;", "assertEquals (  1  0  ,    exec (  \" short   x    =     9  ;    char   y    =     3  ;    return   x    ^    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     4  ;    int   y    =     1  ;    x    ^  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     4  ;    int   y    =     1  ;    x    ^  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    float   y    =     1  ;    x    ^  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    double   y    =     1  ;    x    ^  =    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testBogusCompoundAssignment"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" boolean   x    =    true ;    boolean   y    =    true ;    return   x    ^    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;    boolean   y    =    false ;    return   x    ^    y ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    false ;    boolean   y    =    true ;    return   x    ^    y ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    boolean   y    =    false ;    return   x    ^    y ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBool"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" return   true    ^    true ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return   true    ^    false ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" return   false    ^    true ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" return   false    ^    false ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBoolConst"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" boolean   x    =    true ;    x    ^  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    true ;    x    ^  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean   x    =    false ;    x    ^  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean   x    =    false ;    x    ^  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     ^  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     ^  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     ^  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" boolean [  ]    x    =    new   boolean [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     ^  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  3     ^     1  4  )  )  ,    exec (  \" byte   x    =     1  3  ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  3     ^     1  4  )  )  ,    exec (  \" short   x    =     1  3  ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  3     ^     1  4  )  )  ,    exec (  \" char   x    =     1  3  ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1  3     ^     1  4  )  ,    exec (  \" int   x    =     1  3  ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( long )     (  1  3     ^     1  4  )  )  ,    exec (  \" long   x    =     1  3 L ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignment"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( false ,    exec (  \" def   x    =    true ;    x    ^  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;    x    ^  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    x    ^  =    true ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    x    ^  =    false ;    return   x ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     ^  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    true ;    x [  0  ]     ^  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( true ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     ^  =    true ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals ( false ,    exec (  \" def [  ]    x    =    new   def [  1  ]  ;    x [  0  ]     =    false ;    x [  0  ]     ^  =    false ;    return   x [  0  ]  ;  \"  )  )  ;", "assertEquals (  (  ( byte )     (  1  3     ^     1  4  )  )  ,    exec (  \" def   x    =     ( byte )  1  3  ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( short )     (  1  3     ^     1  4  )  )  ,    exec (  \" def   x    =     ( short )  1  3  ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( char )     (  1  3     ^     1  4  )  )  ,    exec (  \" def   x    =     ( char )  1  3  ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  1  3     ^     1  4  )  ,    exec (  \" def   x    =     1  3  ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "assertEquals (  (  ( long )     (  1  3     ^     1  4  )  )  ,    exec (  \" def   x    =     1  3 L ;    x    ^  =     1  4  ;    return   x ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testCompoundAssignmentDef"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( float )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( double )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  ;", "}  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;       def   y    =    true ;    return   x    ^    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       def   y    =    false ;    return   x    ^    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    def   y    =    true ;    return   x    ^    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    def   y    =    false ;    return   x    ^    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDef"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     4 F ;    int   y    =     1  ;    x    ^  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     4 D ;    int   y    =     1  ;    x    ^  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    def   y    =     ( float )  1  ;    x    ^  =    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" int   x    =     4  ;    def   y    =     ( double )  1  ;    x    ^  =    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testDefBogusCompoundAssignment"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     ( float )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     ( double )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  ;", "}  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    def   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    def   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    def   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    def   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    def   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;       def   y    =    true ;    return   x    ^    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       def   y    =    false ;    return   x    ^    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    def   y    =    true ;    return   x    ^    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    def   y    =    false ;    return   x    ^    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedLHS"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( float )  4  ;    byte   y    =     ( byte )  1  ;    return   x    ^    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" def   x    =     ( double )  4  ;    byte   y    =     ( byte )  1  ;    return   x    ^    y \"  )  ;", "}  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    byte   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    byte   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    byte   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    byte   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    short   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    short   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    short   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    short   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    char   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    char   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    char   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    char   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    int   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    int   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    int   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    int   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( byte )  4  ;    long   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( short )  4  ;    long   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( char )  4  ;    long   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( int )  4  ;    long   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( byte )  4  ;    byte   y    =     ( byte )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( short )  4  ;    short   y    =     ( short )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( char )  4  ;    char   y    =     ( char )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5  ,    exec (  \" def   x    =     ( int )  4  ;    int   y    =     ( int )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals (  5 L ,    exec (  \" def   x    =     ( long )  4  ;    long   y    =     ( long )  1  ;    return   x    ^    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    true ;       boolean   y    =    true ;    return   x    ^    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    true ;       boolean   y    =    false ;    return   x    ^    y \"  )  )  ;", "assertEquals ( true ,    exec (  \" def   x    =    false ;    boolean   y    =    true ;    return   x    ^    y \"  )  )  ;", "assertEquals ( false ,    exec (  \" def   x    =    false ;    boolean   y    =    false ;    return   x    ^    y \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefTypedRHS"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" float   x    =     ( float )  4  ;    int   y    =     1  ;    return   x    ^    y \"  )  ;", "}  )  ;", "ScriptTestCase . expectScriptThrows ( ClassCastException . class ,     (  )     -  >     {", "exec (  \" double   x    =     ( double )  4  ;    int   y    =     1  ;    return   x    ^    y \"  )  ;", "}  )  ;", "}", "METHOD_END"], "methodName": ["testIllegal"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5     ^     1  2  )  ,    exec (  \" int   x    =     5  ;    int   y    =     1  2  ;    return   x    ^    y ;  \"  )  )  ;", "assertEquals (  (  5     ^     (  -  1  2  )  )  ,    exec (  \" int   x    =     5  ;    int   y    =     -  1  2  ;    return   x    ^    y ;  \"  )  )  ;", "assertEquals (  (  (  7     ^     1  5  )     ^     3  )  ,    exec (  \" int   x    =     7  ;    int   y    =     1  5  ;    int   z    =     3  ;    return   x    ^    y    ^    z ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInt"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5     ^     1  2  )  ,    exec (  \" return    5     ^     1  2  ;  \"  )  )  ;", "assertEquals (  (  5     ^     (  -  1  2  )  )  ,    exec (  \" return    5     ^     -  1  2  ;  \"  )  )  ;", "assertEquals (  (  (  7     ^     1  5  )     ^     3  )  ,    exec (  \" return    7     ^     1  5     ^     3  ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testIntConst"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5 L    ^     1  2 L )  ,    exec (  \" long   x    =     5  ;    long   y    =     1  2  ;    return   x    ^    y ;  \"  )  )  ;", "assertEquals (  (  5 L    ^     (  -  1  2 L )  )  ,    exec (  \" long   x    =     5  ;    long   y    =     -  1  2  ;    return   x    ^    y ;  \"  )  )  ;", "assertEquals (  (  (  7 L    ^     1  5 L )     ^     3 L )  ,    exec (  \" long   x    =     7  ;    long   y    =     1  5  ;    long   z    =     3  ;    return   x    ^    y    ^    z ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLong"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  (  5 L    ^     1  2 L )  ,    exec (  \" return    5 L    ^     1  2 L ;  \"  )  )  ;", "assertEquals (  (  5 L    ^     (  -  1  2 L )  )  ,    exec (  \" return    5 L    ^     -  1  2 L ;  \"  )  )  ;", "assertEquals (  (  (  7 L    ^     1  5 L )     ^     3 L )  ,    exec (  \" return    7 L    ^     1  5 L    ^     3 L ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testLongConst"], "fileName": "org.elasticsearch.painless.XorTests"}, {"methodBody": ["METHOD_START", "{", "return   previous ;", "}", "METHOD_END"], "methodName": ["getPreviousToken"], "fileName": "org.elasticsearch.painless.antlr.EnhancedPainlessLexer"}, {"methodBody": ["METHOD_START", "{", "if    (  ( previous    =  =    null )     |  |     (  ( next . getType (  )  )     !  =     ( PainlessLexer . RBRACK )  )  )     {", "return   false ;", "}", "switch    ( previous . getType (  )  )     {", "case   PainlessLexer . RBRACK    :", "case   PainlessLexer . SEMICOLON    :", "case   PainlessLexer . LBRACK    :", "return   false ;", "default    :", "return   true ;", "}", "}", "METHOD_END"], "methodName": ["insertSemicolon"], "fileName": "org.elasticsearch.painless.antlr.EnhancedPainlessLexer"}, {"methodBody": ["METHOD_START", "{", "switch    ( predIndex )     {", "case    0     :", "return   false    =  =     ( shIsRegex (  )  )  ;", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["DIV_sempred"], "fileName": "org.elasticsearch.painless.antlr.PainlessLexer"}, {"methodBody": ["METHOD_START", "{", "switch    ( predIndex )     {", "case    1     :", "return   shIsRegex (  )  ;", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["REGEX_sempred"], "fileName": "org.elasticsearch.painless.antlr.PainlessLexer"}, {"methodBody": ["METHOD_START", "{", "switch    ( predIndex )     {", "case    2     :", "return   isSimpleType ( getText (  )  )  ;", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["TYPE_sempred"], "fileName": "org.elasticsearch.painless.antlr.PainlessLexer"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . AfterthoughtContext    _ localctx    =    new   PainlessParser . AfterthoughtContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     1  6  ,    PainlessParser . RULE _ afterthought )  ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  2  0  6  )  ;", "expression (  0  )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["afterthought"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . ArgumentContext    _ localctx    =    new   PainlessParser . ArgumentContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     5  6  ,    PainlessParser . RULE _ argument )  ;", "try    {", "setState (  4  6  5  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     4  1  ,     _ ctx )  )     {", "case    1     :", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  4  6  2  )  ;", "expression (  0  )  ;", "}", "break ;", "case    2     :", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  4  6  3  )  ;", "lambda (  )  ;", "}", "break ;", "case    3     :", "enterOuterAlt (  _ localctx ,     3  )  ;", "{", "setState (  4  6  4  )  ;", "funcref (  )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["argument"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . ArgumentsContext    _ localctx    =    new   PainlessParser . ArgumentsContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     5  4  ,    PainlessParser . RULE _ arguments )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "{", "setState (  4  4  9  )  ;", "match ( PainlessParser . LP )  ;", "setState (  4  5  8  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  (  (  (  (  (  (  1 L    <  <     ( PainlessParser . LBRACE )  )     |     (  1 L    <  <     ( PainlessParser . LP )  )  )     |     (  1 L    <  <     ( PainlessParser . NEW )  )  )     |     (  1 L    <  <     ( PainlessParser . THIS )  )  )     |     (  1 L    <  <     ( PainlessParser . BOOLNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . BWNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . ADD )  )  )     |     (  1 L    <  <     ( PainlessParser . SUB )  )  )     |     (  1 L    <  <     ( PainlessParser . INCR )  )  )     |     (  1 L    <  <     ( PainlessParser . DECR )  )  )  )     !  =     0  )  )     |  |     (  (  (  (  _ la    -     7  2  )     &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     (  _ la    -     7  2  )  )     &     (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     (  ( PainlessParser . OCTAL )     -     7  2  )  )     |     (  1 L    <  <     (  ( PainlessParser . HEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . INTEGER )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . DECIMAL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . STRING )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . REGEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TRUE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . FALSE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . NULL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TYPE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . ID )     -     7  2  )  )  )  )     !  =     0  )  )  )     {", "{", "setState (  4  5  0  )  ;", "argument (  )  ;", "setState (  4  5  5  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "while    (  _ la    =  =     ( PainlessParser . COMMA )  )     {", "{", "{", "setState (  4  5  1  )  ;", "match ( PainlessParser . COMMA )  ;", "setState (  4  5  2  )  ;", "argument (  )  ;", "}", "}", "setState (  4  5  7  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "}", "}", "}", "setState (  4  6  0  )  ;", "match ( PainlessParser . RP )  ;", "}", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["arguments"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . ArrayinitializerContext    _ localctx    =    new   PainlessParser . ArrayinitializerContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     4  6  ,    PainlessParser . RULE _ arrayinitializer )  ;", "int    _ la ;", "try    {", "int    _ alt ;", "setState (  4  1  2  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     3  4  ,     _ ctx )  )     {", "case    1     :", "_ localctx    =    new   PainlessParser . NewstandardarrayContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  3  6  8  )  ;", "match ( PainlessParser . NEW )  ;", "setState (  3  6  9  )  ;", "match ( PainlessParser . TYPE )  ;", "setState (  3  7  4  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =     1  ;", "do    {", "switch    (  _ alt )     {", "case    1     :", "{", "{", "setState (  3  7  0  )  ;", "match ( PainlessParser . LBRACE )  ;", "setState (  3  7  1  )  ;", "expression (  0  )  ;", "setState (  3  7  2  )  ;", "match ( PainlessParser . RBRACE )  ;", "}", "}", "break ;", "default    :", "throw   new   NoViableAltException ( this )  ;", "}", "setState (  3  7  6  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     2  7  ,     _ ctx )  ;", "}    while    (  (  _ alt    !  =     2  )     &  &     (  _ alt    !  =     ( ATN . INVALID _ ALT _ NUMBER )  )     )  ;", "setState (  3  8  5  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     2  9  ,     _ ctx )  )     {", "case    1     :", "{", "setState (  3  7  8  )  ;", "postdot (  )  ;", "setState (  3  8  2  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     2  8  ,     _ ctx )  ;", "while    (  (  _ alt    !  =     2  )     &  &     (  _ alt    !  =     ( ATN . INVALID _ ALT _ NUMBER )  )  )     {", "if    (  _ alt    =  =     1  )     {", "{", "{", "setState (  3  7  9  )  ;", "postfix (  )  ;", "}", "}", "}", "setState (  3  8  4  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     2  8  ,     _ ctx )  ;", "}", "}", "break ;", "}", "}", "break ;", "case    2     :", "_ localctx    =    new   PainlessParser . NewinitializedarrayContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  3  8  7  )  ;", "match ( PainlessParser . NEW )  ;", "setState (  3  8  8  )  ;", "match ( PainlessParser . TYPE )  ;", "setState (  3  8  9  )  ;", "match ( PainlessParser . LBRACE )  ;", "setState (  3  9  0  )  ;", "match ( PainlessParser . RBRACE )  ;", "setState (  3  9  1  )  ;", "match ( PainlessParser . LBRACK )  ;", "setState (  4  0  0  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  (  (  (  (  (  1 L    <  <     ( PainlessParser . LBRACE )  )     |     (  1 L    <  <     ( PainlessParser . LP )  )  )     |     (  1 L    <  <     ( PainlessParser . NEW )  )  )     |     (  1 L    <  <     ( PainlessParser . BOOLNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . BWNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . ADD )  )  )     |     (  1 L    <  <     ( PainlessParser . SUB )  )  )     |     (  1 L    <  <     ( PainlessParser . INCR )  )  )     |     (  1 L    <  <     ( PainlessParser . DECR )  )  )  )     !  =     0  )  )     |  |     (  (  (  (  _ la    -     7  2  )     &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     (  _ la    -     7  2  )  )     &     (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     (  ( PainlessParser . OCTAL )     -     7  2  )  )     |     (  1 L    <  <     (  ( PainlessParser . HEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . INTEGER )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . DECIMAL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . STRING )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . REGEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TRUE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . FALSE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . NULL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TYPE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . ID )     -     7  2  )  )  )  )     !  =     0  )  )  )     {", "{", "setState (  3  9  2  )  ;", "expression (  0  )  ;", "setState (  3  9  7  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "while    (  _ la    =  =     ( PainlessParser . COMMA )  )     {", "{", "{", "setState (  3  9  3  )  ;", "match ( PainlessParser . COMMA )  ;", "setState (  3  9  4  )  ;", "expression (  0  )  ;", "}", "}", "setState (  3  9  9  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "}", "}", "}", "setState (  4  0  3  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  _ la    =  =     ( PainlessParser . SEMICOLON )  )     {", "{", "setState (  4  0  2  )  ;", "match ( PainlessParser . SEMICOLON )  ;", "}", "}", "setState (  4  0  5  )  ;", "match ( PainlessParser . RBRACK )  ;", "setState (  4  0  9  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     3  3  ,     _ ctx )  ;", "while    (  (  _ alt    !  =     2  )     &  &     (  _ alt    !  =     ( ATN . INVALID _ ALT _ NUMBER )  )  )     {", "if    (  _ alt    =  =     1  )     {", "{", "{", "setState (  4  0  6  )  ;", "postfix (  )  ;", "}", "}", "}", "setState (  4  1  1  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     3  3  ,     _ ctx )  ;", "}", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["arrayinitializer"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . BlockContext    _ localctx    =    new   PainlessParser . BlockContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     1  0  ,    PainlessParser . RULE _ block )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  1  9  1  )  ;", "match ( PainlessParser . LBRACK )  ;", "setState (  1  9  5  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "while    (  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     ( PainlessParser . LBRACE )  )     |     (  1 L    <  <     ( PainlessParser . LP )  )  )     |     (  1 L    <  <     ( PainlessParser . IF )  )  )     |     (  1 L    <  <     ( PainlessParser . WHILE )  )  )     |     (  1 L    <  <     ( PainlessParser . DO )  )  )     |     (  1 L    <  <     ( PainlessParser . FOR )  )  )     |     (  1 L    <  <     ( PainlessParser . CONTINUE )  )  )     |     (  1 L    <  <     ( PainlessParser . BREAK )  )  )     |     (  1 L    <  <     ( PainlessParser . RETURN )  )  )     |     (  1 L    <  <     ( PainlessParser . NEW )  )  )     |     (  1 L    <  <     ( PainlessParser . TRY )  )  )     |     (  1 L    <  <     ( PainlessParser . THROW )  )  )     |     (  1 L    <  <     ( PainlessParser . BOOLNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . BWNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . ADD )  )  )     |     (  1 L    <  <     ( PainlessParser . SUB )  )  )     |     (  1 L    <  <     ( PainlessParser . INCR )  )  )     |     (  1 L    <  <     ( PainlessParser . DECR )  )  )  )     !  =     0  )  )     |  |     (  (  (  (  _ la    -     7  2  )     &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     (  _ la    -     7  2  )  )     &     (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     (  ( PainlessParser . OCTAL )     -     7  2  )  )     |     (  1 L    <  <     (  ( PainlessParser . HEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . INTEGER )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . DECIMAL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . STRING )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . REGEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TRUE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . FALSE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . NULL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TYPE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . ID )     -     7  2  )  )  )  )     !  =     0  )  )  )     {", "{", "{", "setState (  1  9  2  )  ;", "statement (  )  ;", "}", "}", "setState (  1  9  7  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "}", "setState (  1  9  8  )  ;", "match ( PainlessParser . RBRACK )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["block"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . BraceaccessContext    _ localctx    =    new   PainlessParser . BraceaccessContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     4  4  ,    PainlessParser . RULE _ braceaccess )  ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  3  6  4  )  ;", "match ( PainlessParser . LBRACE )  ;", "setState (  3  6  5  )  ;", "expression (  0  )  ;", "setState (  3  6  6  )  ;", "match ( PainlessParser . RBRACE )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["braceaccess"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . CallinvokeContext    _ localctx    =    new   PainlessParser . CallinvokeContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     4  0  ,    PainlessParser . RULE _ callinvoke )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  3  5  7  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  _ la    =  =     ( PainlessParser . DOT )  )     |  |     (  _ la    =  =     ( PainlessParser . NSDOT )  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  3  5  8  )  ;", "match ( PainlessParser . DOTID )  ;", "setState (  3  5  9  )  ;", "arguments (  )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["callinvoke"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . ChainContext    _ localctx    =    new   PainlessParser . ChainContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     3  2  ,    PainlessParser . RULE _ chain )  ;", "try    {", "int    _ alt ;", "setState (  3  2  6  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     2  3  ,     _ ctx )  )     {", "case    1     :", "_ localctx    =    new   PainlessParser . DynamicContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  3  1  0  )  ;", "primary (  )  ;", "setState (  3  1  4  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     2  1  ,     _ ctx )  ;", "while    (  (  _ alt    !  =     2  )     &  &     (  _ alt    !  =     ( ATN . INVALID _ ALT _ NUMBER )  )  )     {", "if    (  _ alt    =  =     1  )     {", "{", "{", "setState (  3  1  1  )  ;", "postfix (  )  ;", "}", "}", "}", "setState (  3  1  6  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     2  1  ,     _ ctx )  ;", "}", "}", "break ;", "case    2     :", "_ localctx    =    new   PainlessParser . StaticContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  3  1  7  )  ;", "decltype (  )  ;", "setState (  3  1  8  )  ;", "postdot (  )  ;", "setState (  3  2  2  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     2  2  ,     _ ctx )  ;", "while    (  (  _ alt    !  =     2  )     &  &     (  _ alt    !  =     ( ATN . INVALID _ ALT _ NUMBER )  )  )     {", "if    (  _ alt    =  =     1  )     {", "{", "{", "setState (  3  1  9  )  ;", "postfix (  )  ;", "}", "}", "}", "setState (  3  2  4  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     2  2  ,     _ ctx )  ;", "}", "}", "break ;", "case    3     :", "_ localctx    =    new   PainlessParser . NewarrayContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     3  )  ;", "{", "setState (  3  2  5  )  ;", "arrayinitializer (  )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["chain"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . DeclarationContext    _ localctx    =    new   PainlessParser . DeclarationContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     1  8  ,    PainlessParser . RULE _ declaration )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  2  0  8  )  ;", "decltype (  )  ;", "setState (  2  0  9  )  ;", "declvar (  )  ;", "setState (  2  1  4  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "while    (  _ la    =  =     ( PainlessParser . COMMA )  )     {", "{", "{", "setState (  2  1  0  )  ;", "match ( PainlessParser . COMMA )  ;", "setState (  2  1  1  )  ;", "declvar (  )  ;", "}", "}", "setState (  2  1  6  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "}", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["declaration"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . DecltypeContext    _ localctx    =    new   PainlessParser . DecltypeContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     2  0  ,    PainlessParser . RULE _ decltype )  ;", "try    {", "int    _ alt ;", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  2  1  7  )  ;", "match ( PainlessParser . TYPE )  ;", "setState (  2  2  2  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     1  6  ,     _ ctx )  ;", "while    (  (  _ alt    !  =     2  )     &  &     (  _ alt    !  =     ( ATN . INVALID _ ALT _ NUMBER )  )  )     {", "if    (  _ alt    =  =     1  )     {", "{", "{", "setState (  2  1  8  )  ;", "match ( PainlessParser . LBRACE )  ;", "setState (  2  1  9  )  ;", "match ( PainlessParser . RBRACE )  ;", "}", "}", "}", "setState (  2  2  4  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     1  6  ,     _ ctx )  ;", "}", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["decltype"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . DeclvarContext    _ localctx    =    new   PainlessParser . DeclvarContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     2  2  ,    PainlessParser . RULE _ declvar )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  2  2  5  )  ;", "match ( PainlessParser . ID )  ;", "setState (  2  2  8  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  _ la    =  =     ( PainlessParser . ASSIGN )  )     {", "{", "setState (  2  2  6  )  ;", "match ( PainlessParser . ASSIGN )  ;", "setState (  2  2  7  )  ;", "expression (  0  )  ;", "}", "}", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["declvar"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . DelimiterContext    _ localctx    =    new   PainlessParser . DelimiterContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     2  6  ,    PainlessParser . RULE _ delimiter )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  2  3  7  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  _ la    =  =     ( EOF )  )     |  |     (  _ la    =  =     ( PainlessParser . SEMICOLON )  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["delimiter"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . EmptyContext    _ localctx    =    new   PainlessParser . EmptyContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     1  2  ,    PainlessParser . RULE _ empty )  ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  2  0  0  )  ;", "match ( PainlessParser . SEMICOLON )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["empty"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "return   expression (  0  )  ;", "}", "METHOD_END"], "methodName": ["expression"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "ParserRuleContext    _ parentctx    =     _ ctx ;", "int    _ parentState    =    getState (  )  ;", ". ExpressionContext    _ localctx    =    new    . ExpressionContext (  _ ctx ,     _ parentState )  ;", ". ExpressionContext    _ prevctx    =     _ localctx ;", "int    _ startState    =     2  8  ;", "enterRecursionRule (  _ localctx ,     2  8  ,     . RULE _ expression ,     _ p )  ;", "int    _ la ;", "try    {", "int    _ alt ;", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "{", "_ localctx    =    new    . SingleContext (  _ localctx )  ;", "_ ctx    =     _ localctx ;", "_ prevctx    =     _ localctx ;", "setState (  2  4  0  )  ;", "unary (  )  ;", "}", "_ ctx . stop    =     _ input . LT (  (  -  1  )  )  ;", "setState (  2  9  2  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     1  9  ,     _ ctx )  ;", "while    (  (  _ alt    !  =     2  )     &  &     (  _ alt    !  =     ( ATN . INVALID _ ALT _ NUMBER )  )  )     {", "if    (  _ alt    =  =     1  )     {", "if    (  (  _ parseListeners )     !  =    null )", "triggerExitRuleEvent (  )  ;", "_ prevctx    =     _ localctx ;", "{", "setState (  2  9  0  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     1  8  ,     _ ctx )  )     {", "case    1     :", "{", "_ localctx    =    new    . BinaryContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  4  2  )  ;", "if    (  !  ( precpred (  _ ctx ,     1  5  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     1  5  )  \"  )  ;", "setState (  2  4  3  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  1 L    <  <     (  . MUL )  )     |     (  1 L    <  <     (  . DIV )  )  )     |     (  1 L    <  <     (  . REM )  )  )  )     !  =     0  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  2  4  4  )  ;", "expression (  1  6  )  ;", "}", "break ;", "case    2     :", "{", "_ localctx    =    new    . BinaryContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  4  5  )  ;", "if    (  !  ( precpred (  _ ctx ,     1  4  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     1  4  )  \"  )  ;", "setState (  2  4  6  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  _ la    =  =     (  . ADD )  )     |  |     (  _ la    =  =     (  . SUB )  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  2  4  7  )  ;", "expression (  1  5  )  ;", "}", "break ;", "case    3     :", "{", "_ localctx    =    new    . BinaryContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  4  8  )  ;", "if    (  !  ( precpred (  _ ctx ,     1  3  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     1  3  )  \"  )  ;", "setState (  2  4  9  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  _ la    =  =     (  . FIND )  )     |  |     (  _ la    =  =     (  . MATCH )  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  2  5  0  )  ;", "expression (  1  4  )  ;", "}", "break ;", "case    4     :", "{", "_ localctx    =    new    . BinaryContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  5  1  )  ;", "if    (  !  ( precpred (  _ ctx ,     1  2  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     1  2  )  \"  )  ;", "setState (  2  5  2  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  1 L    <  <     (  . LSH )  )     |     (  1 L    <  <     (  . RSH )  )  )     |     (  1 L    <  <     (  . USH )  )  )  )     !  =     0  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  2  5  3  )  ;", "expression (  1  3  )  ;", "}", "break ;", "case    5     :", "{", "_ localctx    =    new    . CompContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  5  4  )  ;", "if    (  !  ( precpred (  _ ctx ,     1  1  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     1  1  )  \"  )  ;", "setState (  2  5  5  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  1 L    <  <     (  . LT )  )     |     (  1 L    <  <     (  . LTE )  )  )     |     (  1 L    <  <     (  . GT )  )  )     |     (  1 L    <  <     (  . GTE )  )  )  )     !  =     0  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  2  5  6  )  ;", "expression (  1  2  )  ;", "}", "break ;", "case    6     :", "{", "_ localctx    =    new    . CompContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  5  7  )  ;", "if    (  !  ( precpred (  _ ctx ,     9  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     9  )  \"  )  ;", "setState (  2  5  8  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  1 L    <  <     (  . EQ )  )     |     (  1 L    <  <     (  . EQR )  )  )     |     (  1 L    <  <     (  . NE )  )  )     |     (  1 L    <  <     (  . NER )  )  )  )     !  =     0  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  2  5  9  )  ;", "expression (  1  0  )  ;", "}", "break ;", "case    7     :", "{", "_ localctx    =    new    . BinaryContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  6  0  )  ;", "if    (  !  ( precpred (  _ ctx ,     8  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     8  )  \"  )  ;", "setState (  2  6  1  )  ;", "match (  . BWAND )  ;", "setState (  2  6  2  )  ;", "expression (  9  )  ;", "}", "break ;", "case    8     :", "{", "_ localctx    =    new    . BinaryContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  6  3  )  ;", "if    (  !  ( precpred (  _ ctx ,     7  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     7  )  \"  )  ;", "setState (  2  6  4  )  ;", "match (  . XOR )  ;", "setState (  2  6  5  )  ;", "expression (  8  )  ;", "}", "break ;", "case    9     :", "{", "_ localctx    =    new    . BinaryContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  6  6  )  ;", "if    (  !  ( precpred (  _ ctx ,     6  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     6  )  \"  )  ;", "setState (  2  6  7  )  ;", "match (  . BWOR )  ;", "setState (  2  6  8  )  ;", "expression (  7  )  ;", "}", "break ;", "case    1  0     :", "{", "_ localctx    =    new    . BoolContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  6  9  )  ;", "if    (  !  ( precpred (  _ ctx ,     5  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     5  )  \"  )  ;", "setState (  2  7  0  )  ;", "match (  . BOOLAND )  ;", "setState (  2  7  1  )  ;", "expression (  6  )  ;", "}", "break ;", "case    1  1     :", "{", "_ localctx    =    new    . BoolContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  7  2  )  ;", "if    (  !  ( precpred (  _ ctx ,     4  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     4  )  \"  )  ;", "setState (  2  7  3  )  ;", "match (  . BOOLOR )  ;", "setState (  2  7  4  )  ;", "expression (  5  )  ;", "}", "break ;", "case    1  2     :", "{", "_ localctx    =    new    . ConditionalContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  7  5  )  ;", "if    (  !  ( precpred (  _ ctx ,     3  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     3  )  \"  )  ;", "setState (  2  7  6  )  ;", "match (  . COND )  ;", "setState (  2  7  7  )  ;", "expression (  0  )  ;", "setState (  2  7  8  )  ;", "match (  . COLON )  ;", "setState (  2  7  9  )  ;", "expression (  3  )  ;", "}", "break ;", "case    1  3     :", "{", "_ localctx    =    new    . ElvisContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  8  1  )  ;", "if    (  !  ( precpred (  _ ctx ,     2  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     2  )  \"  )  ;", "setState (  2  8  2  )  ;", "match (  . ELVIS )  ;", "setState (  2  8  3  )  ;", "expression (  2  )  ;", "}", "break ;", "case    1  4     :", "{", "_ localctx    =    new    . AssignmentContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  8  4  )  ;", "if    (  !  ( precpred (  _ ctx ,     1  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     1  )  \"  )  ;", "setState (  2  8  5  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  (  (  _ la    -     6  0  )     &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     (  _ la    -     6  0  )  )     &     (  (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     (  (  . ASSIGN )     -     6  0  )  )     |     (  1 L    <  <     (  (  . AADD )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . ASUB )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . AMUL )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . ADIV )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . AREM )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . AAND )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . AXOR )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . AOR )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . ALSH )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . ARSH )     -     6  0  )  )  )     |     (  1 L    <  <     (  (  . AUSH )     -     6  0  )  )  )  )     !  =     0  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  2  8  6  )  ;", "expression (  1  )  ;", "}", "break ;", "case    1  5     :", "{", "_ localctx    =    new    . InstanceofContext ( new    . ExpressionContext (  _ parentctx ,     _ parentState )  )  ;", "pushNewRecursionContext (  _ localctx ,     _ startState ,     . RULE _ expression )  ;", "setState (  2  8  7  )  ;", "if    (  !  ( precpred (  _ ctx ,     1  0  )  )  )", "throw   new   FailedPredicateException ( this ,     \" precpred (  _ ctx ,     1  0  )  \"  )  ;", "setState (  2  8  8  )  ;", "match (  . INSTANCEOF )  ;", "setState (  2  8  9  )  ;", "decltype (  )  ;", "}", "break ;", "}", "}", "}", "setState (  2  9  4  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     1  9  ,     _ ctx )  ;", "}", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "unrollRecursionContexts (  _ parentctx )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["expression"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "switch    ( predIndex )     {", "case    1     :", "return   precpred (  _ ctx ,     1  5  )  ;", "case    2     :", "return   precpred (  _ ctx ,     1  4  )  ;", "case    3     :", "return   precpred (  _ ctx ,     1  3  )  ;", "case    4     :", "return   precpred (  _ ctx ,     1  2  )  ;", "case    5     :", "return   precpred (  _ ctx ,     1  1  )  ;", "case    6     :", "return   precpred (  _ ctx ,     9  )  ;", "case    7     :", "return   precpred (  _ ctx ,     8  )  ;", "case    8     :", "return   precpred (  _ ctx ,     7  )  ;", "case    9     :", "return   precpred (  _ ctx ,     6  )  ;", "case    1  0     :", "return   precpred (  _ ctx ,     5  )  ;", "case    1  1     :", "return   precpred (  _ ctx ,     4  )  ;", "case    1  2     :", "return   precpred (  _ ctx ,     3  )  ;", "case    1  3     :", "return   precpred (  _ ctx ,     2  )  ;", "case    1  4     :", "return   precpred (  _ ctx ,     1  )  ;", "case    1  5     :", "return   precpred (  _ ctx ,     1  0  )  ;", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["expression_sempred"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . FieldaccessContext    _ localctx    =    new   PainlessParser . FieldaccessContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     4  2  ,    PainlessParser . RULE _ fieldaccess )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  3  6  1  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  _ la    =  =     ( PainlessParser . DOT )  )     |  |     (  _ la    =  =     ( PainlessParser . NSDOT )  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  3  6  2  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  _ la    =  =     ( PainlessParser . DOTINTEGER )  )     |  |     (  _ la    =  =     ( PainlessParser . DOTID )  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["fieldaccess"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . FuncrefContext    _ localctx    =    new   PainlessParser . FuncrefContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     6  2  ,    PainlessParser . RULE _ funcref )  ;", "try    {", "setState (  5  0  5  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     4  7  ,     _ ctx )  )     {", "case    1     :", "_ localctx    =    new   PainlessParser . ClassfuncrefContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  4  9  2  )  ;", "match ( PainlessParser . TYPE )  ;", "setState (  4  9  3  )  ;", "match ( PainlessParser . REF )  ;", "setState (  4  9  4  )  ;", "match ( PainlessParser . ID )  ;", "}", "break ;", "case    2     :", "_ localctx    =    new   PainlessParser . ConstructorfuncrefContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  4  9  5  )  ;", "decltype (  )  ;", "setState (  4  9  6  )  ;", "match ( PainlessParser . REF )  ;", "setState (  4  9  7  )  ;", "match ( PainlessParser . NEW )  ;", "}", "break ;", "case    3     :", "_ localctx    =    new   PainlessParser . CapturingfuncrefContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     3  )  ;", "{", "setState (  4  9  9  )  ;", "match ( PainlessParser . ID )  ;", "setState (  5  0  0  )  ;", "match ( PainlessParser . REF )  ;", "setState (  5  0  1  )  ;", "match ( PainlessParser . ID )  ;", "}", "break ;", "case    4     :", "_ localctx    =    new   PainlessParser . LocalfuncrefContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     4  )  ;", "{", "setState (  5  0  2  )  ;", "match ( PainlessParser . THIS )  ;", "setState (  5  0  3  )  ;", "match ( PainlessParser . REF )  ;", "setState (  5  0  4  )  ;", "match ( PainlessParser . ID )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["funcref"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . FunctionContext    _ localctx    =    new   PainlessParser . FunctionContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     2  ,    PainlessParser . RULE _ function )  ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  7  8  )  ;", "decltype (  )  ;", "setState (  7  9  )  ;", "match ( PainlessParser . ID )  ;", "setState (  8  0  )  ;", "parameters (  )  ;", "setState (  8  1  )  ;", "block (  )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["function"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . InitializerContext    _ localctx    =    new   PainlessParser . InitializerContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     1  4  ,    PainlessParser . RULE _ initializer )  ;", "try    {", "setState (  2  0  4  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     1  4  ,     _ ctx )  )     {", "case    1     :", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  2  0  2  )  ;", "declaration (  )  ;", "}", "break ;", "case    2     :", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  2  0  3  )  ;", "expression (  0  )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["initializer"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . LambdaContext    _ localctx    =    new   PainlessParser . LambdaContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     5  8  ,    PainlessParser . RULE _ lambda )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  4  8  0  )  ;", "switch    (  _ input . LA (  1  )  )     {", "case   PainlessParser . TYPE    :", "case   PainlessParser . ID    :", "{", "setState (  4  6  7  )  ;", "lamtype (  )  ;", "}", "break ;", "case   PainlessParser . LP    :", "{", "setState (  4  6  8  )  ;", "match ( PainlessParser . LP )  ;", "setState (  4  7  7  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  (  _ la    =  =     ( PainlessParser . TYPE )  )     |  |     (  _ la    =  =     ( PainlessParser . ID )  )  )     {", "{", "setState (  4  6  9  )  ;", "lamtype (  )  ;", "setState (  4  7  4  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "while    (  _ la    =  =     ( PainlessParser . COMMA )  )     {", "{", "{", "setState (  4  7  0  )  ;", "match ( PainlessParser . COMMA )  ;", "setState (  4  7  1  )  ;", "lamtype (  )  ;", "}", "}", "setState (  4  7  6  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "}", "}", "}", "setState (  4  7  9  )  ;", "match ( PainlessParser . RP )  ;", "}", "break ;", "default    :", "throw   new   NoViableAltException ( this )  ;", "}", "setState (  4  8  2  )  ;", "match ( PainlessParser . ARROW )  ;", "setState (  4  8  5  )  ;", "switch    (  _ input . LA (  1  )  )     {", "case   PainlessParser . LBRACK    :", "{", "setState (  4  8  3  )  ;", "block (  )  ;", "}", "break ;", "case   PainlessParser . LBRACE    :", "case   PainlessParser . LP    :", "case   PainlessParser . NEW    :", "case   PainlessParser . BOOLNOT    :", "case   PainlessParser . BWNOT    :", "case   PainlessParser . ADD    :", "case   PainlessParser . SUB    :", "case   PainlessParser . INCR    :", "case   PainlessParser . DECR    :", "case   PainlessParser . OCTAL    :", "case   PainlessParser . HEX    :", "case   PainlessParser . INTEGER    :", "case   PainlessParser . DECIMAL    :", "case   PainlessParser . STRING    :", "case   PainlessParser . REGEX    :", "case   PainlessParser . TRUE    :", "case   PainlessParser . FALSE    :", "case   PainlessParser . NULL    :", "case   PainlessParser . TYPE    :", "case   PainlessParser . ID    :", "{", "setState (  4  8  4  )  ;", "expression (  0  )  ;", "}", "break ;", "default    :", "throw   new   NoViableAltException ( this )  ;", "}", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["lambda"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . LamtypeContext    _ localctx    =    new   PainlessParser . LamtypeContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     6  0  ,    PainlessParser . RULE _ lamtype )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  4  8  8  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  _ la    =  =     ( PainlessParser . TYPE )  )     {", "{", "setState (  4  8  7  )  ;", "decltype (  )  ;", "}", "}", "setState (  4  9  0  )  ;", "match ( PainlessParser . ID )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["lamtype"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . ListinitializerContext    _ localctx    =    new   PainlessParser . ListinitializerContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     4  8  ,    PainlessParser . RULE _ listinitializer )  ;", "int    _ la ;", "try    {", "setState (  4  2  7  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     3  6  ,     _ ctx )  )     {", "case    1     :", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  4  1  4  )  ;", "match ( PainlessParser . LBRACE )  ;", "setState (  4  1  5  )  ;", "expression (  0  )  ;", "setState (  4  2  0  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "while    (  _ la    =  =     ( PainlessParser . COMMA )  )     {", "{", "{", "setState (  4  1  6  )  ;", "match ( PainlessParser . COMMA )  ;", "setState (  4  1  7  )  ;", "expression (  0  )  ;", "}", "}", "setState (  4  2  2  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "}", "setState (  4  2  3  )  ;", "match ( PainlessParser . RBRACE )  ;", "}", "break ;", "case    2     :", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  4  2  5  )  ;", "match ( PainlessParser . LBRACE )  ;", "setState (  4  2  6  )  ;", "match ( PainlessParser . RBRACE )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["listinitializer"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . MapinitializerContext    _ localctx    =    new   PainlessParser . MapinitializerContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     5  0  ,    PainlessParser . RULE _ mapinitializer )  ;", "int    _ la ;", "try    {", "setState (  4  4  3  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     3  8  ,     _ ctx )  )     {", "case    1     :", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  4  2  9  )  ;", "match ( PainlessParser . LBRACE )  ;", "setState (  4  3  0  )  ;", "maptoken (  )  ;", "setState (  4  3  5  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "while    (  _ la    =  =     ( PainlessParser . COMMA )  )     {", "{", "{", "setState (  4  3  1  )  ;", "match ( PainlessParser . COMMA )  ;", "setState (  4  3  2  )  ;", "maptoken (  )  ;", "}", "}", "setState (  4  3  7  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "}", "setState (  4  3  8  )  ;", "match ( PainlessParser . RBRACE )  ;", "}", "break ;", "case    2     :", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  4  4  0  )  ;", "match ( PainlessParser . LBRACE )  ;", "setState (  4  4  1  )  ;", "match ( PainlessParser . COLON )  ;", "setState (  4  4  2  )  ;", "match ( PainlessParser . RBRACE )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["mapinitializer"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . MaptokenContext    _ localctx    =    new   PainlessParser . MaptokenContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     5  2  ,    PainlessParser . RULE _ maptoken )  ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  4  4  5  )  ;", "expression (  0  )  ;", "setState (  4  4  6  )  ;", "match ( PainlessParser . COLON )  ;", "setState (  4  4  7  )  ;", "expression (  0  )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["maptoken"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . ParametersContext    _ localctx    =    new   PainlessParser . ParametersContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     4  ,    PainlessParser . RULE _ parameters )  ;", "int    _ la ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  8  3  )  ;", "match ( PainlessParser . LP )  ;", "setState (  9  5  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  _ la    =  =     ( PainlessParser . TYPE )  )     {", "{", "setState (  8  4  )  ;", "decltype (  )  ;", "setState (  8  5  )  ;", "match ( PainlessParser . ID )  ;", "setState (  9  2  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "while    (  _ la    =  =     ( PainlessParser . COMMA )  )     {", "{", "{", "setState (  8  6  )  ;", "match ( PainlessParser . COMMA )  ;", "setState (  8  7  )  ;", "decltype (  )  ;", "setState (  8  8  )  ;", "match ( PainlessParser . ID )  ;", "}", "}", "setState (  9  4  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "}", "}", "}", "setState (  9  7  )  ;", "match ( PainlessParser . RP )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . PostdotContext    _ localctx    =    new   PainlessParser . PostdotContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     3  8  ,    PainlessParser . RULE _ postdot )  ;", "try    {", "setState (  3  5  5  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     2  6  ,     _ ctx )  )     {", "case    1     :", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  3  5  3  )  ;", "callinvoke (  )  ;", "}", "break ;", "case    2     :", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  3  5  4  )  ;", "fieldaccess (  )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["postdot"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . PostfixContext    _ localctx    =    new   PainlessParser . PostfixContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     3  6  ,    PainlessParser . RULE _ postfix )  ;", "try    {", "setState (  3  5  1  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     2  5  ,     _ ctx )  )     {", "case    1     :", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  3  4  8  )  ;", "callinvoke (  )  ;", "}", "break ;", "case    2     :", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  3  4  9  )  ;", "fieldaccess (  )  ;", "}", "break ;", "case    3     :", "enterOuterAlt (  _ localctx ,     3  )  ;", "{", "setState (  3  5  0  )  ;", "braceaccess (  )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["postfix"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . PrimaryContext    _ localctx    =    new   PainlessParser . PrimaryContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     3  4  ,    PainlessParser . RULE _ primary )  ;", "int    _ la ;", "try    {", "setState (  3  4  6  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     2  4  ,     _ ctx )  )     {", "case    1     :", "_ localctx    =    new   PainlessParser . PrecedenceContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  3  2  8  )  ;", "match ( PainlessParser . LP )  ;", "setState (  3  2  9  )  ;", "expression (  0  )  ;", "setState (  3  3  0  )  ;", "match ( PainlessParser . RP )  ;", "}", "break ;", "case    2     :", "_ localctx    =    new   PainlessParser . NumericContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  3  3  2  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  (  (  _ la    -     7  2  )     &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     (  _ la    -     7  2  )  )     &     (  (  (  (  1 L    <  <     (  ( PainlessParser . OCTAL )     -     7  2  )  )     |     (  1 L    <  <     (  ( PainlessParser . HEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . INTEGER )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . DECIMAL )     -     7  2  )  )  )  )     !  =     0  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "}", "break ;", "case    3     :", "_ localctx    =    new   PainlessParser . TrueContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     3  )  ;", "{", "setState (  3  3  3  )  ;", "match ( PainlessParser . TRUE )  ;", "}", "break ;", "case    4     :", "_ localctx    =    new   PainlessParser . FalseContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     4  )  ;", "{", "setState (  3  3  4  )  ;", "match ( PainlessParser . FALSE )  ;", "}", "break ;", "case    5     :", "_ localctx    =    new   PainlessParser . NullContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     5  )  ;", "{", "setState (  3  3  5  )  ;", "match ( PainlessParser . NULL )  ;", "}", "break ;", "case    6     :", "_ localctx    =    new   PainlessParser . StringContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     6  )  ;", "{", "setState (  3  3  6  )  ;", "match ( PainlessParser . STRING )  ;", "}", "break ;", "case    7     :", "_ localctx    =    new   PainlessParser . RegexContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     7  )  ;", "{", "setState (  3  3  7  )  ;", "match ( PainlessParser . REGEX )  ;", "}", "break ;", "case    8     :", "_ localctx    =    new   PainlessParser . ListinitContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     8  )  ;", "{", "setState (  3  3  8  )  ;", "listinitializer (  )  ;", "}", "break ;", "case    9     :", "_ localctx    =    new   PainlessParser . MapinitContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     9  )  ;", "{", "setState (  3  3  9  )  ;", "mapinitializer (  )  ;", "}", "break ;", "case    1  0     :", "_ localctx    =    new   PainlessParser . VariableContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  0  )  ;", "{", "setState (  3  4  0  )  ;", "match ( PainlessParser . ID )  ;", "}", "break ;", "case    1  1     :", "_ localctx    =    new   PainlessParser . CalllocalContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  1  )  ;", "{", "setState (  3  4  1  )  ;", "match ( PainlessParser . ID )  ;", "setState (  3  4  2  )  ;", "arguments (  )  ;", "}", "break ;", "case    1  2     :", "_ localctx    =    new   PainlessParser . NewobjectContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  2  )  ;", "{", "setState (  3  4  3  )  ;", "match ( PainlessParser . NEW )  ;", "setState (  3  4  4  )  ;", "match ( PainlessParser . TYPE )  ;", "setState (  3  4  5  )  ;", "arguments (  )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["primary"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "switch    ( ruleIndex )     {", "case    3     :", "return   statement _ sempred (  (  (  . StatementContext )     (  _ localctx )  )  ,    predIndex )  ;", "case    1  4     :", "return   expression _ sempred (  (  (  . ExpressionContext )     (  _ localctx )  )  ,    predIndex )  ;", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["sempred"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . SourceContext    _ localctx    =    new   PainlessParser . SourceContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     0  ,    PainlessParser . RULE _ source )  ;", "int    _ la ;", "try    {", "int    _ alt ;", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  6  7  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     0  ,     _ ctx )  ;", "while    (  (  _ alt    !  =     2  )     &  &     (  _ alt    !  =     ( ATN . INVALID _ ALT _ NUMBER )  )  )     {", "if    (  _ alt    =  =     1  )     {", "{", "{", "setState (  6  4  )  ;", "function (  )  ;", "}", "}", "}", "setState (  6  9  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     0  ,     _ ctx )  ;", "}", "setState (  7  3  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "while    (  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     ( PainlessParser . LBRACE )  )     |     (  1 L    <  <     ( PainlessParser . LP )  )  )     |     (  1 L    <  <     ( PainlessParser . IF )  )  )     |     (  1 L    <  <     ( PainlessParser . WHILE )  )  )     |     (  1 L    <  <     ( PainlessParser . DO )  )  )     |     (  1 L    <  <     ( PainlessParser . FOR )  )  )     |     (  1 L    <  <     ( PainlessParser . CONTINUE )  )  )     |     (  1 L    <  <     ( PainlessParser . BREAK )  )  )     |     (  1 L    <  <     ( PainlessParser . RETURN )  )  )     |     (  1 L    <  <     ( PainlessParser . NEW )  )  )     |     (  1 L    <  <     ( PainlessParser . TRY )  )  )     |     (  1 L    <  <     ( PainlessParser . THROW )  )  )     |     (  1 L    <  <     ( PainlessParser . BOOLNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . BWNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . ADD )  )  )     |     (  1 L    <  <     ( PainlessParser . SUB )  )  )     |     (  1 L    <  <     ( PainlessParser . INCR )  )  )     |     (  1 L    <  <     ( PainlessParser . DECR )  )  )  )     !  =     0  )  )     |  |     (  (  (  (  _ la    -     7  2  )     &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     (  _ la    -     7  2  )  )     &     (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     (  ( PainlessParser . OCTAL )     -     7  2  )  )     |     (  1 L    <  <     (  ( PainlessParser . HEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . INTEGER )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . DECIMAL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . STRING )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . REGEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TRUE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . FALSE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . NULL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TYPE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . ID )     -     7  2  )  )  )  )     !  =     0  )  )  )     {", "{", "{", "setState (  7  0  )  ;", "statement (  )  ;", "}", "}", "setState (  7  5  )  ;", "_ errHandler . sync ( this )  ;", "_ la    =     _ input . LA (  1  )  ;", "}", "setState (  7  6  )  ;", "match ( EOF )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["source"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . StatementContext    _ localctx    =    new   PainlessParser . StatementContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     6  ,    PainlessParser . RULE _ statement )  ;", "int    _ la ;", "try    {", "int    _ alt ;", "setState (  1  8  5  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     1  1  ,     _ ctx )  )     {", "case    1     :", "_ localctx    =    new   PainlessParser . IfContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  9  9  )  ;", "match ( PainlessParser . IF )  ;", "setState (  1  0  0  )  ;", "match ( PainlessParser . LP )  ;", "setState (  1  0  1  )  ;", "expression (  0  )  ;", "setState (  1  0  2  )  ;", "match ( PainlessParser . RP )  ;", "setState (  1  0  3  )  ;", "trailer (  )  ;", "setState (  1  0  7  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     4  ,     _ ctx )  )     {", "case    1     :", "{", "setState (  1  0  4  )  ;", "match ( PainlessParser . ELSE )  ;", "setState (  1  0  5  )  ;", "trailer (  )  ;", "}", "break ;", "case    2     :", "{", "setState (  1  0  6  )  ;", "if    (  !  (  (  _ input . LA (  1  )  )     !  =     ( PainlessParser . ELSE )  )  )", "throw   new   FailedPredicateException ( this ,     \"     _ input . LA (  1  )     !  =    ELSE    \"  )  ;", "}", "break ;", "}", "}", "break ;", "case    2     :", "_ localctx    =    new   PainlessParser . WhileContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  1  0  9  )  ;", "match ( PainlessParser . WHILE )  ;", "setState (  1  1  0  )  ;", "match ( PainlessParser . LP )  ;", "setState (  1  1  1  )  ;", "expression (  0  )  ;", "setState (  1  1  2  )  ;", "match ( PainlessParser . RP )  ;", "setState (  1  1  5  )  ;", "switch    (  _ input . LA (  1  )  )     {", "case   PainlessParser . LBRACK    :", "case   PainlessParser . LBRACE    :", "case   PainlessParser . LP    :", "case   PainlessParser . IF    :", "case   PainlessParser . WHILE    :", "case   PainlessParser . DO    :", "case   PainlessParser . FOR    :", "case   PainlessParser . CONTINUE    :", "case   PainlessParser . BREAK    :", "case   PainlessParser . RETURN    :", "case   PainlessParser . NEW    :", "case   PainlessParser . TRY    :", "case   PainlessParser . THROW    :", "case   PainlessParser . BOOLNOT    :", "case   PainlessParser . BWNOT    :", "case   PainlessParser . ADD    :", "case   PainlessParser . SUB    :", "case   PainlessParser . INCR    :", "case   PainlessParser . DECR    :", "case   PainlessParser . OCTAL    :", "case   PainlessParser . HEX    :", "case   PainlessParser . INTEGER    :", "case   PainlessParser . DECIMAL    :", "case   PainlessParser . STRING    :", "case   PainlessParser . REGEX    :", "case   PainlessParser . TRUE    :", "case   PainlessParser . FALSE    :", "case   PainlessParser . NULL    :", "case   PainlessParser . TYPE    :", "case   PainlessParser . ID    :", "{", "setState (  1  1  3  )  ;", "trailer (  )  ;", "}", "break ;", "case   PainlessParser . SEMICOLON    :", "{", "setState (  1  1  4  )  ;", "empty (  )  ;", "}", "break ;", "default    :", "throw   new   NoViableAltException ( this )  ;", "}", "}", "break ;", "case    3     :", "_ localctx    =    new   PainlessParser . DoContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     3  )  ;", "{", "setState (  1  1  7  )  ;", "match ( PainlessParser . DO )  ;", "setState (  1  1  8  )  ;", "block (  )  ;", "setState (  1  1  9  )  ;", "match ( PainlessParser . WHILE )  ;", "setState (  1  2  0  )  ;", "match ( PainlessParser . LP )  ;", "setState (  1  2  1  )  ;", "expression (  0  )  ;", "setState (  1  2  2  )  ;", "match ( PainlessParser . RP )  ;", "setState (  1  2  3  )  ;", "delimiter (  )  ;", "}", "break ;", "case    4     :", "_ localctx    =    new   PainlessParser . ForContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     4  )  ;", "{", "setState (  1  2  5  )  ;", "match ( PainlessParser . FOR )  ;", "setState (  1  2  6  )  ;", "match ( PainlessParser . LP )  ;", "setState (  1  2  8  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  (  (  (  (  (  1 L    <  <     ( PainlessParser . LBRACE )  )     |     (  1 L    <  <     ( PainlessParser . LP )  )  )     |     (  1 L    <  <     ( PainlessParser . NEW )  )  )     |     (  1 L    <  <     ( PainlessParser . BOOLNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . BWNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . ADD )  )  )     |     (  1 L    <  <     ( PainlessParser . SUB )  )  )     |     (  1 L    <  <     ( PainlessParser . INCR )  )  )     |     (  1 L    <  <     ( PainlessParser . DECR )  )  )  )     !  =     0  )  )     |  |     (  (  (  (  _ la    -     7  2  )     &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     (  _ la    -     7  2  )  )     &     (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     (  ( PainlessParser . OCTAL )     -     7  2  )  )     |     (  1 L    <  <     (  ( PainlessParser . HEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . INTEGER )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . DECIMAL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . STRING )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . REGEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TRUE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . FALSE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . NULL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TYPE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . ID )     -     7  2  )  )  )  )     !  =     0  )  )  )     {", "{", "setState (  1  2  7  )  ;", "initializer (  )  ;", "}", "}", "setState (  1  3  0  )  ;", "match ( PainlessParser . SEMICOLON )  ;", "setState (  1  3  2  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  (  (  (  (  (  1 L    <  <     ( PainlessParser . LBRACE )  )     |     (  1 L    <  <     ( PainlessParser . LP )  )  )     |     (  1 L    <  <     ( PainlessParser . NEW )  )  )     |     (  1 L    <  <     ( PainlessParser . BOOLNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . BWNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . ADD )  )  )     |     (  1 L    <  <     ( PainlessParser . SUB )  )  )     |     (  1 L    <  <     ( PainlessParser . INCR )  )  )     |     (  1 L    <  <     ( PainlessParser . DECR )  )  )  )     !  =     0  )  )     |  |     (  (  (  (  _ la    -     7  2  )     &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     (  _ la    -     7  2  )  )     &     (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     (  ( PainlessParser . OCTAL )     -     7  2  )  )     |     (  1 L    <  <     (  ( PainlessParser . HEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . INTEGER )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . DECIMAL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . STRING )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . REGEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TRUE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . FALSE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . NULL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TYPE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . ID )     -     7  2  )  )  )  )     !  =     0  )  )  )     {", "{", "setState (  1  3  1  )  ;", "expression (  0  )  ;", "}", "}", "setState (  1  3  4  )  ;", "match ( PainlessParser . SEMICOLON )  ;", "setState (  1  3  6  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  (  (  (  (  (  1 L    <  <     ( PainlessParser . LBRACE )  )     |     (  1 L    <  <     ( PainlessParser . LP )  )  )     |     (  1 L    <  <     ( PainlessParser . NEW )  )  )     |     (  1 L    <  <     ( PainlessParser . BOOLNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . BWNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . ADD )  )  )     |     (  1 L    <  <     ( PainlessParser . SUB )  )  )     |     (  1 L    <  <     ( PainlessParser . INCR )  )  )     |     (  1 L    <  <     ( PainlessParser . DECR )  )  )  )     !  =     0  )  )     |  |     (  (  (  (  _ la    -     7  2  )     &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     (  _ la    -     7  2  )  )     &     (  (  (  (  (  (  (  (  (  (  (  1 L    <  <     (  ( PainlessParser . OCTAL )     -     7  2  )  )     |     (  1 L    <  <     (  ( PainlessParser . HEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . INTEGER )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . DECIMAL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . STRING )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . REGEX )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TRUE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . FALSE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . NULL )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . TYPE )     -     7  2  )  )  )     |     (  1 L    <  <     (  ( PainlessParser . ID )     -     7  2  )  )  )  )     !  =     0  )  )  )     {", "{", "setState (  1  3  5  )  ;", "afterthought (  )  ;", "}", "}", "setState (  1  3  8  )  ;", "match ( PainlessParser . RP )  ;", "setState (  1  4  1  )  ;", "switch    (  _ input . LA (  1  )  )     {", "case   PainlessParser . LBRACK    :", "case   PainlessParser . LBRACE    :", "case   PainlessParser . LP    :", "case   PainlessParser . IF    :", "case   PainlessParser . WHILE    :", "case   PainlessParser . DO    :", "case   PainlessParser . FOR    :", "case   PainlessParser . CONTINUE    :", "case   PainlessParser . BREAK    :", "case   PainlessParser . RETURN    :", "case   PainlessParser . NEW    :", "case   PainlessParser . TRY    :", "case   PainlessParser . THROW    :", "case   PainlessParser . BOOLNOT    :", "case   PainlessParser . BWNOT    :", "case   PainlessParser . ADD    :", "case   PainlessParser . SUB    :", "case   PainlessParser . INCR    :", "case   PainlessParser . DECR    :", "case   PainlessParser . OCTAL    :", "case   PainlessParser . HEX    :", "case   PainlessParser . INTEGER    :", "case   PainlessParser . DECIMAL    :", "case   PainlessParser . STRING    :", "case   PainlessParser . REGEX    :", "case   PainlessParser . TRUE    :", "case   PainlessParser . FALSE    :", "case   PainlessParser . NULL    :", "case   PainlessParser . TYPE    :", "case   PainlessParser . ID    :", "{", "setState (  1  3  9  )  ;", "trailer (  )  ;", "}", "break ;", "case   PainlessParser . SEMICOLON    :", "{", "setState (  1  4  0  )  ;", "empty (  )  ;", "}", "break ;", "default    :", "throw   new   NoViableAltException ( this )  ;", "}", "}", "break ;", "case    5     :", "_ localctx    =    new   PainlessParser . EachContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     5  )  ;", "{", "setState (  1  4  3  )  ;", "match ( PainlessParser . FOR )  ;", "setState (  1  4  4  )  ;", "match ( PainlessParser . LP )  ;", "setState (  1  4  5  )  ;", "decltype (  )  ;", "setState (  1  4  6  )  ;", "match ( PainlessParser . ID )  ;", "setState (  1  4  7  )  ;", "match ( PainlessParser . COLON )  ;", "setState (  1  4  8  )  ;", "expression (  0  )  ;", "setState (  1  4  9  )  ;", "match ( PainlessParser . RP )  ;", "setState (  1  5  0  )  ;", "trailer (  )  ;", "}", "break ;", "case    6     :", "_ localctx    =    new   PainlessParser . IneachContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     6  )  ;", "{", "setState (  1  5  2  )  ;", "match ( PainlessParser . FOR )  ;", "setState (  1  5  3  )  ;", "match ( PainlessParser . LP )  ;", "setState (  1  5  4  )  ;", "match ( PainlessParser . ID )  ;", "setState (  1  5  5  )  ;", "match ( PainlessParser . IN )  ;", "setState (  1  5  6  )  ;", "expression (  0  )  ;", "setState (  1  5  7  )  ;", "match ( PainlessParser . RP )  ;", "setState (  1  5  8  )  ;", "trailer (  )  ;", "}", "break ;", "case    7     :", "_ localctx    =    new   PainlessParser . DeclContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     7  )  ;", "{", "setState (  1  6  0  )  ;", "declaration (  )  ;", "setState (  1  6  1  )  ;", "delimiter (  )  ;", "}", "break ;", "case    8     :", "_ localctx    =    new   PainlessParser . ContinueContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     8  )  ;", "{", "setState (  1  6  3  )  ;", "match ( PainlessParser . CONTINUE )  ;", "setState (  1  6  4  )  ;", "delimiter (  )  ;", "}", "break ;", "case    9     :", "_ localctx    =    new   PainlessParser . BreakContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     9  )  ;", "{", "setState (  1  6  5  )  ;", "match ( PainlessParser . BREAK )  ;", "setState (  1  6  6  )  ;", "delimiter (  )  ;", "}", "break ;", "case    1  0     :", "_ localctx    =    new   PainlessParser . ReturnContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  0  )  ;", "{", "setState (  1  6  7  )  ;", "match ( PainlessParser . RETURN )  ;", "setState (  1  6  8  )  ;", "expression (  0  )  ;", "setState (  1  6  9  )  ;", "delimiter (  )  ;", "}", "break ;", "case    1  1     :", "_ localctx    =    new   PainlessParser . TryContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  1  )  ;", "{", "setState (  1  7  1  )  ;", "match ( PainlessParser . TRY )  ;", "setState (  1  7  2  )  ;", "block (  )  ;", "setState (  1  7  4  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =     1  ;", "do    {", "switch    (  _ alt )     {", "case    1     :", "{", "{", "setState (  1  7  3  )  ;", "trap (  )  ;", "}", "}", "break ;", "default    :", "throw   new   NoViableAltException ( this )  ;", "}", "setState (  1  7  6  )  ;", "_ errHandler . sync ( this )  ;", "_ alt    =    getInterpreter (  )  . adaptivePredict (  _ input ,     1  0  ,     _ ctx )  ;", "}    while    (  (  _ alt    !  =     2  )     &  &     (  _ alt    !  =     ( ATN . INVALID _ ALT _ NUMBER )  )     )  ;", "}", "break ;", "case    1  2     :", "_ localctx    =    new   PainlessParser . ThrowContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  2  )  ;", "{", "setState (  1  7  8  )  ;", "match ( PainlessParser . THROW )  ;", "setState (  1  7  9  )  ;", "expression (  0  )  ;", "setState (  1  8  0  )  ;", "delimiter (  )  ;", "}", "break ;", "case    1  3     :", "_ localctx    =    new   PainlessParser . ExprContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  3  )  ;", "{", "setState (  1  8  2  )  ;", "expression (  0  )  ;", "setState (  1  8  3  )  ;", "delimiter (  )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["statement"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "switch    ( predIndex )     {", "case    0     :", "return    (  _ input . LA (  1  )  )     !  =     (  . ELSE )  ;", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["statement_sempred"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . TrailerContext    _ localctx    =    new   PainlessParser . TrailerContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     8  ,    PainlessParser . RULE _ trailer )  ;", "try    {", "setState (  1  8  9  )  ;", "switch    (  _ input . LA (  1  )  )     {", "case   PainlessParser . LBRACK    :", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  1  8  7  )  ;", "block (  )  ;", "}", "break ;", "case   PainlessParser . LBRACE    :", "case   PainlessParser . LP    :", "case   PainlessParser . IF    :", "case   PainlessParser . WHILE    :", "case   PainlessParser . DO    :", "case   PainlessParser . FOR    :", "case   PainlessParser . CONTINUE    :", "case   PainlessParser . BREAK    :", "case   PainlessParser . RETURN    :", "case   PainlessParser . NEW    :", "case   PainlessParser . TRY    :", "case   PainlessParser . THROW    :", "case   PainlessParser . BOOLNOT    :", "case   PainlessParser . BWNOT    :", "case   PainlessParser . ADD    :", "case   PainlessParser . SUB    :", "case   PainlessParser . INCR    :", "case   PainlessParser . DECR    :", "case   PainlessParser . OCTAL    :", "case   PainlessParser . HEX    :", "case   PainlessParser . INTEGER    :", "case   PainlessParser . DECIMAL    :", "case   PainlessParser . STRING    :", "case   PainlessParser . REGEX    :", "case   PainlessParser . TRUE    :", "case   PainlessParser . FALSE    :", "case   PainlessParser . NULL    :", "case   PainlessParser . TYPE    :", "case   PainlessParser . ID    :", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  1  8  8  )  ;", "statement (  )  ;", "}", "break ;", "default    :", "throw   new   NoViableAltException ( this )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["trailer"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . TrapContext    _ localctx    =    new   PainlessParser . TrapContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     2  4  ,    PainlessParser . RULE _ trap )  ;", "try    {", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  2  3  0  )  ;", "match ( PainlessParser . CATCH )  ;", "setState (  2  3  1  )  ;", "match ( PainlessParser . LP )  ;", "setState (  2  3  2  )  ;", "match ( PainlessParser . TYPE )  ;", "setState (  2  3  3  )  ;", "match ( PainlessParser . ID )  ;", "setState (  2  3  4  )  ;", "match ( PainlessParser . RP )  ;", "setState (  2  3  5  )  ;", "block (  )  ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["trap"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "PainlessParser . UnaryContext    _ localctx    =    new   PainlessParser . UnaryContext (  _ ctx ,    getState (  )  )  ;", "enterRule (  _ localctx ,     3  0  ,    PainlessParser . RULE _ unary )  ;", "int    _ la ;", "try    {", "setState (  3  0  8  )  ;", "_ errHandler . sync ( this )  ;", "switch    ( getInterpreter (  )  . adaptivePredict (  _ input ,     2  0  ,     _ ctx )  )     {", "case    1     :", "_ localctx    =    new   PainlessParser . PreContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     1  )  ;", "{", "setState (  2  9  5  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  _ la    =  =     ( PainlessParser . INCR )  )     |  |     (  _ la    =  =     ( PainlessParser . DECR )  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  2  9  6  )  ;", "chain (  )  ;", "}", "break ;", "case    2     :", "_ localctx    =    new   PainlessParser . PostContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     2  )  ;", "{", "setState (  2  9  7  )  ;", "chain (  )  ;", "setState (  2  9  8  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  _ la    =  =     ( PainlessParser . INCR )  )     |  |     (  _ la    =  =     ( PainlessParser . DECR )  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "}", "break ;", "case    3     :", "_ localctx    =    new   PainlessParser . ReadContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     3  )  ;", "{", "setState (  3  0  0  )  ;", "chain (  )  ;", "}", "break ;", "case    4     :", "_ localctx    =    new   PainlessParser . OperatorContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     4  )  ;", "{", "setState (  3  0  1  )  ;", "_ la    =     _ input . LA (  1  )  ;", "if    (  !  (  (  (  _ la    &     (  ~  6  3  )  )     =  =     0  )     &  &     (  (  (  1 L    <  <     _ la )     &     (  (  (  (  1 L    <  <     ( PainlessParser . BOOLNOT )  )     |     (  1 L    <  <     ( PainlessParser . BWNOT )  )  )     |     (  1 L    <  <     ( PainlessParser . ADD )  )  )     |     (  1 L    <  <     ( PainlessParser . SUB )  )  )  )     !  =     0  )  )  )     {", "_ errHandler . recoverInline ( this )  ;", "} else    {", "consume (  )  ;", "}", "setState (  3  0  2  )  ;", "unary (  )  ;", "}", "break ;", "case    5     :", "_ localctx    =    new   PainlessParser . CastContext (  _ localctx )  ;", "enterOuterAlt (  _ localctx ,     5  )  ;", "{", "setState (  3  0  3  )  ;", "match ( PainlessParser . LP )  ;", "setState (  3  0  4  )  ;", "decltype (  )  ;", "setState (  3  0  5  )  ;", "match ( PainlessParser . RP )  ;", "setState (  3  0  6  )  ;", "unary (  )  ;", "}", "break ;", "}", "}    catch    ( RecognitionException   re )     {", "_ localctx . exception    =    re ;", "_ errHandler . reportError ( this ,    re )  ;", "_ errHandler . recover ( this ,    re )  ;", "}    finally    {", "exitRule (  )  ;", "}", "return    _ localctx ;", "}", "METHOD_END"], "methodName": ["unary"], "fileName": "org.elasticsearch.painless.antlr.PainlessParser"}, {"methodBody": ["METHOD_START", "{", "return   lastToken ;", "}", "METHOD_END"], "methodName": ["getLastToken"], "fileName": "org.elasticsearch.painless.antlr.StashingTokenFactory"}, {"methodBody": ["METHOD_START", "{", "if    (  ( token . getChannel (  )  )     =  =     ( Lexer . DEFAULT _ TOKEN _ CHANNEL )  )     {", "last    =    token ;", "}", "return   token ;", "}", "METHOD_END"], "methodName": ["maybeStash"], "fileName": "org.elasticsearch.painless.antlr.StashingTokenFactory"}, {"methodBody": ["METHOD_START", "{", "ANTLRInputStream   stream    =    new   ANTLRInputStream ( source )  ;", "PLexer   lexer    =    new   EnhancedPLexer ( stream ,    sourceName ,    definition )  ;", "PParser   parser    =    new   PParser ( new   CommonTokenStream ( lexer )  )  ;", "ParserErrorStrategy   strategy    =    new   ParserErrorStrategy ( sourceName )  ;", "lexer . removeErrorListeners (  )  ;", "parser . removeErrorListeners (  )  ;", "if    ( settings . isPicky (  )  )     {", "setupPicky ( parser )  ;", "}", "parser . setErrorHandler ( strategy )  ;", "return   parser . source (  )  ;", "}", "METHOD_END"], "methodName": ["buildAntlrTree"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "return   new   Walker ( mainMethod ,    reserved ,    sourceName ,    sourceText ,    settings ,    definition ,    debugStream )  . source ;", "}", "METHOD_END"], "methodName": ["buildPainlessTree"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "AExpression   prefix    =    primary ;", "if    ( postdot    !  =    null )     {", "prefix    =    visitPostdot ( postdot ,    prefix )  ;", "}", "for    ( PParser . PostfixContext   postfix    :    postfixes )     {", "prefix    =    visitPostfix ( postfix ,    prefix )  ;", "}", "return   prefix ;", "}", "METHOD_END"], "methodName": ["buildPostfixChain"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "List < AExpression >    arguments    =    new   ArrayList <  >  (  )  ;", "for    ( PParser . ArgumentContext   argument    :    ctx . argument (  )  )     {", "arguments . add (  (  ( AExpression )     ( visit ( argument )  )  )  )  ;", "}", "return   arguments ;", "}", "METHOD_END"], "methodName": ["collectArguments"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "return   new   Location ( sourceName ,    ctx . getStart (  )  . getStartIndex (  )  )  ;", "}", "METHOD_END"], "methodName": ["location"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "return    \" lambda $  \"     +     (  ( syntheticCounter )  +  +  )  ;", "}", "METHOD_END"], "methodName": ["nextLambda"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "parser . addErrorListener ( new   DiagnosticErrorListener ( true )  )  ;", "parser . addErrorListener ( new   BaseErrorListener (  )     {", "@ Override", "public   void   syntaxError ( final   Recognizer <  ?  ,     ?  >    recognizer ,    final   Object   offendingSymbol ,    final   int   line ,    final   int   charPositionInLine ,    final   String   msg ,    final   RecognitionException   e )     {", "throw   new   AssertionError (  (  (  (  (  (  (  (  \" line :     \"     +    line )     +     \"  ,    offset :     \"  )     +    charPositionInLine )     +     \"  ,    symbol :  \"  )     +    offendingSymbol )     +     \"     \"  )     +    msg )  )  ;", "}", "}  )  ;", "parser . getInterpreter (  )  . setPredictionMode ( LL _ EXACT _ AMBIG _ DETECTION )  ;", "}", "METHOD_END"], "methodName": ["setupPicky"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "AExpression   expression    =     (  ( AExpression )     ( visit ( ctx . expression (  )  )  )  )  ;", "return   new   PBrace ( location ( ctx )  ,    prefix ,    expression )  ;", "}", "METHOD_END"], "methodName": ["visitBraceaccess"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "String   name    =    ctx . DOTID (  )  . getText (  )  ;", "List < AExprion >    arguments    =    collectArguments ( ctx . arguments (  )  )  ;", "return   new   PCallInvoke ( location ( ctx )  ,    prefix ,    name ,     (  ( ctx . NSDOT (  )  )     !  =    null )  ,    arguments )  ;", "}", "METHOD_END"], "methodName": ["visitCallinvoke"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "final   String   value ;", "if    (  ( ctx . DOTID (  )  )     !  =    null )     {", "value    =    ctx . DOTID (  )  . getText (  )  ;", "} else", "if    (  ( ctx . DOTINTEGER (  )  )     !  =    null )     {", "value    =    ctx . DOTINTEGER (  )  . getText (  )  ;", "} else    {", "throw   location ( ctx )  . createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "return   new   PField ( location ( ctx )  ,    prefix ,     (  ( ctx . NSDOT (  )  )     !  =    null )  ,    value )  ;", "}", "METHOD_END"], "methodName": ["visitFieldaccess"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "if    (  ( ctx . callinvoke (  )  )     !  =    null )     {", "return   visitCallinvoke ( ctx . callinvoke (  )  ,    prefix )  ;", "} else", "if    (  ( ctx . fieldacc (  )  )     !  =    null )     {", "return   visitFieldacc ( ctx . fieldacc (  )  ,    prefix )  ;", "} else    {", "throw   location ( ctx )  . createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["visitPostdot"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "if    (  ( ctx . callinvoke (  )  )     !  =    null )     {", "return   visitCallinvoke ( ctx . callinvoke (  )  ,    prefix )  ;", "} else", "if    (  ( ctx . fieldacc (  )  )     !  =    null )     {", "return   visitFieldacc ( ctx . fieldacc (  )  ,    prefix )  ;", "} else", "if    (  ( ctx . braceacc (  )  )     !  =    null )     {", "return   visitBraceacc ( ctx . braceacc (  )  ,    prefix )  ;", "} else    {", "throw   location ( ctx )  . createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["visitPostfix"], "fileName": "org.elasticsearch.painless.antlr.Walker"}, {"methodBody": ["METHOD_START", "{", "for    ( T   t    :    receiver )     {", "if    ( predicate . test ( t )  )     {", "return   true ;", "}", "}", "return   false ;", "}", "METHOD_END"], "methodName": ["any"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "if    ( receiver   instanceof   Collection )     {", "return    (  ( Collection < T >  )     ( receiver )  )  ;", "}", "List < T >    list    =    new   ArrayList <  >  (  )  ;", "for    ( T   t    :    receiver )     {", "list . add ( t )  ;", "}", "return   list ;", "}", "METHOD_END"], "methodName": ["asCollection"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "if    ( receiver   instanceof   List )     {", "return    (  ( List < T >  )     ( receiver )  )  ;", "}", "List < T >    list    =    new   ArrayList <  >  (  )  ;", "for    ( T   t    :    receiver )     {", "list . add ( t )  ;", "}", "return   list ;", "}", "METHOD_END"], "methodName": ["asList"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "for    ( T   t    :    receiver )     {", "collec . add ( func . apply ( t )  )  ;", "}", "return   collec ;", "}", "METHOD_END"], "methodName": ["collect"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "List < U >    list    =    new   ArrayList <  >  (  )  ;", "for    ( T   t    :    receiver )     {", "list . add ( func . apply ( t )  )  ;", "}", "return   list ;", "}", "METHOD_END"], "methodName": ["collect"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "for    ( Map . Entry < K ,    V >    kvPair    :    receiver . entrySet (  )  )     {", "collec . add ( func . apply ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  )  ;", "}", "return   collec ;", "}", "METHOD_END"], "methodName": ["collect"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "List < T >    list    =    new   ArrayList <  >  (  )  ;", "for    ( Map . Entry < K ,    V >    kvPair    :    receiver . entrySet (  )  )     {", "list . add ( func . apply ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  )  ;", "}", "return   list ;", "}", "METHOD_END"], "methodName": ["collect"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "int   count    =     0  ;", "for    ( T   t    :    receiver )     {", "if    ( predicate . test ( t )  )     {", "count +  +  ;", "}", "}", "return   count ;", "}", "METHOD_END"], "methodName": ["count"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "int   count    =     0  ;", "for    ( Map . Entry < K ,    V >    kvPair    :    receiver . rySet (  )  )     {", "if    ( predicate . test ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  )     {", "count +  +  ;", "}", "}", "return   count ;", "}", "METHOD_END"], "methodName": ["count"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "return   new   String ( Base 6  4  . getDecoder (  )  . decode ( receiver . getBytes ( StandardCharsets . UTF _  8  )  )  ,    StandardCharsets . UTF _  8  )  ;", "}", "METHOD_END"], "methodName": ["decodeBase64"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "receiver . forEach ( consumer )  ;", "return   receiver ;", "}", "METHOD_END"], "methodName": ["each"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "receiver . forEach ( consumer )  ;", "return   receiver ;", "}", "METHOD_END"], "methodName": ["each"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "int   count    =     0  ;", "for    ( T   t    :    receiver )     {", "consumer . accept ( t ,     ( count +  +  )  )  ;", "}", "return   receiver ;", "}", "METHOD_END"], "methodName": ["eachWithIndex"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "return   Base 6  4  . getEncoder (  )  . encodeToString ( receiver . getBytes ( StandardCharsets . UTF _  8  )  )  ;", "}", "METHOD_END"], "methodName": ["encodeBase64"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "for    ( T   t    :    receiver )     {", "if    (  ( predicate . test ( t )  )     =  =    false )     {", "return   false ;", "}", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["every"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "for    ( Map . Entry < K ,    V >    kvPair    :    receiver . entrySet (  )  )     {", "if    (  ( predicate . test ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  )     =  =    false )     {", "return   false ;", "}", "}", "return   true ;", "}", "METHOD_END"], "methodName": ["every"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "for    ( T   t    :    receiver )     {", "if    ( predicate . test ( t )  )     {", "return   t ;", "}", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["find"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "for    ( Map . Entry < K ,    V >    kvPair    :    receiver . entrySet (  )  )     {", "if    ( predicate . test ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  )     {", "return   kvPair ;", "}", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["find"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "List < T >    list    =    new   ArrayList <  >  (  )  ;", "for    ( T   t    :    receiver )     {", "if    ( predicate . test ( t )  )     {", "list . add ( t )  ;", "}", "}", "return   list ;", "}", "METHOD_END"], "methodName": ["findAll"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "final   Map < K ,    V >    map ;", "if    ( receiver   instanceof   TreeMap )     {", "map    =    new   TreeMap <  >  (  )  ;", "} else    {", "map    =    new   LinkedHashMap <  >  (  )  ;", "}", "for    ( Map . Entry < K ,    V >    kvPair    :    receiver . rySet (  )  )     {", "if    ( predicate . test ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  )     {", "map . put ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  ;", "}", "}", "return   map ;", "}", "METHOD_END"], "methodName": ["findAll"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "for    ( T   t    :    receiver )     {", "U   value    =    func . apply ( t )  ;", "if    ( value    !  =    null )     {", "return   value ;", "}", "}", "return   defaultResult ;", "}", "METHOD_END"], "methodName": ["findResult"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "return   Augmentation . findResult ( receiver ,    null ,    function )  ;", "}", "METHOD_END"], "methodName": ["findResult"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "for    ( Map . Entry < K ,    V >    kvPair    :    receiver . entrySet (  )  )     {", "T   value    =    func . apply ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  ;", "if    ( value    !  =    null )     {", "return   value ;", "}", "}", "return   defaultResult ;", "}", "METHOD_END"], "methodName": ["findResult"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "return   Augmentation . findResult ( receiver ,    null ,    function )  ;", "}", "METHOD_END"], "methodName": ["findResult"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "List < U >    list    =    new   ArrayList <  >  (  )  ;", "for    ( T   t    :    receiver )     {", "U   result    =    filterply ( t )  ;", "if    ( result    !  =    null )     {", "list . add ( result )  ;", "}", "}", "return   list ;", "}", "METHOD_END"], "methodName": ["findResults"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "List < T >    list    =    new   ArrayList <  >  (  )  ;", "for    ( Map . Entry < K ,    V >    kvPair    :    receiver . rySet (  )  )     {", "T   result    =    filter . apply ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  ;", "if    ( result    !  =    null )     {", "list . add ( result )  ;", "}", "}", "return   list ;", "}", "METHOD_END"], "methodName": ["findResults"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "return   receiver . size (  )  ;", "}", "METHOD_END"], "methodName": ["getLength"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "< U ,    List < T >  >        =    new   LinkedHash <  >  (  )  ;", "for    ( T   t    :    receiver )     {", "U   ped    =    perply ( t )  ;", "List < T >    results    =     . get ( ped )  ;", "if    ( results    =  =    null )     {", "results    =    new   ArrayList <  >  (  )  ;", ". put ( ped ,    results )  ;", "}", "results . add ( t )  ;", "}", "return    ;", "}", "METHOD_END"], "methodName": ["groupBy"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "Map < T ,    Map < K ,    V >  >    map    =    new   LinkedHashMap <  >  (  )  ;", "for    ( Map . Entry < K ,    V >    kvPair    :    receiver . rySet (  )  )     {", "T   mapped    =    mapper . apply ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  ;", "Map < K ,    V >    results    =    map . get ( mapped )  ;", "if    ( results    =  =    null )     {", "if    ( receiver   instanceof   TreeMap )     {", "results    =    new   TreeMap <  >  (  )  ;", "} else    {", "results    =    new   LinkedHashMap <  >  (  )  ;", "}", "map . put ( mapped ,    results )  ;", "}", "results . put ( kvPair . getKey (  )  ,    kvPair . getValue (  )  )  ;", "}", "return   map ;", "}", "METHOD_END"], "methodName": ["groupBy"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "return    ( seq . length (  )  )     +     1  6  ;", "}", "METHOD_END"], "methodName": ["initialBufferForReplaceWith"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   sb    =    new   StringBuilder (  )  ;", "for    ( T   t    :    receiver )     {", "if    (  ( sb . length (  )  )     >     0  )     {", "sbpend ( separator )  ;", "}", "sbpend ( t )  ;", "}", "return   sb . toString (  )  ;", "}", "METHOD_END"], "methodName": ["join"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "return   receiver . group ( name )  ;", "}", "METHOD_END"], "methodName": ["namedGroup"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "Matcher   m    =    pattern . matcher ( receiver )  ;", "if    ( false    =  =     ( m . find (  )  )  )     {", "return   receiver . toString (  )  ;", "}", "StringBuffer   result    =    new   StringBuffer (  . initialBufferForReplaceWith ( receiver )  )  ;", "do    {", "m . appendReplacement ( result ,    Matcher . quoteReplacement ( replacementBuilder . apply ( m )  )  )  ;", "}    while    ( m . find (  )     )  ;", "m . appendTail ( result )  ;", "return   result . toString (  )  ;", "}", "METHOD_END"], "methodName": ["replaceAll"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "Matcher   m    =    pattern . matcher ( receiver )  ;", "if    ( false    =  =     ( m . find (  )  )  )     {", "return   receiver . toString (  )  ;", "}", "StringBuffer   result    =    new   StringBuffer (  . initialBufferForReplaceWith ( receiver )  )  ;", "m . appendReplacement ( result ,    Matcher . quoteReplacement ( replacementBuilder . apply ( m )  )  )  ;", "m . appendTail ( result )  ;", "return   result . toString (  )  ;", "}", "METHOD_END"], "methodName": ["replaceFirst"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "List < T >    matched    =    new   ArrayList <  >  (  )  ;", "List < T >    unmatched    =    new   ArrayList <  >  (  )  ;", "List < List < T >  >    result    =    new   ArrayList <  >  (  2  )  ;", "result . add ( matched )  ;", "result . add ( unmatched )  ;", "for    ( T   t    :    receiver )     {", "if    ( predicate . test ( t )  )     {", "matched . add ( t )  ;", "} else    {", "unmatched . add ( t )  ;", "}", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["split"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "double   sum    =     0  ;", "for    ( T   t    :    receiver )     {", "sum    +  =    t . doubleValue (  )  ;", "}", "return   sum ;", "}", "METHOD_END"], "methodName": ["sum"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "double   sum    =     0  ;", "for    ( T   t    :    receiver )     {", "sum    +  =    func . applyAsDouble ( t )  ;", "}", "return   sum ;", "}", "METHOD_END"], "methodName": ["sum"], "fileName": "org.elasticsearch.painless.api.Augmentation"}, {"methodBody": ["METHOD_START", "{", "throw   new   PainlessExplainError ( objectToExplain )  ;", "}", "METHOD_END"], "methodName": ["explain"], "fileName": "org.elasticsearch.painless.api.Debug"}, {"methodBody": ["METHOD_START", "{", "Definition . Cast   cast    =    AnalyzerCaster . getLegalCast ( location ,    actual ,    expected ,    explicit ,    internal )  ;", "if    ( cast    =  =    null )     {", "if    (  (  ( constant )     =  =    null )     |  |     (  ( this )    instanceof   EConstant )  )     {", "return   this ;", "} else    {", "EConstant   econstant    =    new   EConstant ( location ,    constant )  ;", "econstant . analyze ( locals )  ;", "if    (  !  ( expected . equals ( econstant . actual )  )  )     {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "return   econstant ;", "}", "} else    {", "if    (  ( constant )     =  =    null )     {", "ECast   ecast    =    new   ECast ( location ,    this ,    cast )  ;", "ecast . statement    =    statement ;", "ecast . actual    =    expected ;", "ecast . isNull    =    isNull ;", "return   ecast ;", "} else    {", "if    ( Definition . isConstantType ( expected )  )     {", "constant    =    AnalyzerCaster . constCast ( location ,    constant ,    cast )  ;", "EConstant   econstant    =    new   EConstant ( location ,    constant )  ;", "econstant . analyze ( locals )  ;", "if    (  !  ( expected . equals ( econstant . actual )  )  )     {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "return   econstant ;", "} else", "if    (  ( this )    instanceof   EConstant )     {", "ECast   ecast    =    new   ECast ( location ,    this ,    cast )  ;", "ecast . actual    =    expected ;", "return   ecast ;", "} else    {", "EConstant   econstant    =    new   EConstant ( location ,    constant )  ;", "econstant . analyze ( locals )  ;", "if    (  !  ( actual . equals ( econstant . actual )  )  )     {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "ECast   ecast    =    new   ECast ( location ,    econstant ,    cast )  ;", "ecast . actual    =    expected ;", "return   ecast ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["cast"], "fileName": "org.elasticsearch.painless.node.AExpression"}, {"methodBody": ["METHOD_START", "{", "return   location . createError ( exception )  ;", "}", "METHOD_END"], "methodName": ["createError"], "fileName": "org.elasticsearch.painless.node.ANode"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   b    =    new   StringBuilder (  )  ;", "b . append (  '  (  '  )  . append ( name )  ;", "for    ( Object   sub    :    sameLine )     {", "b . append (  '     '  )  . append ( sub )  ;", "}", "if    (  (  ( ownLine . size (  )  )     =  =     1  )     &  &     ( sameLine . isEmpty (  )  )  )     {", "b . append (  '     '  )  . append ( ownLine . iterator (  )  . next (  )  )  ;", "} else    {", "for    ( Object   sub    :    ownLine )     {", "b . append (  \"  \\ n       \"  )  . append ( Objects . toString ( sub )  . replace (  \"  \\ n \"  ,     \"  \\ n       \"  )  )  ;", "}", "}", "return   b . append (  '  )  '  )  . toString (  )  ;", "}", "METHOD_END"], "methodName": ["joinWithName"], "fileName": "org.elasticsearch.painless.node.ANode"}, {"methodBody": ["METHOD_START", "{", "return   joinWithName ( getClass (  )  . getSimpleName (  )  ,    sameLine ,    ownLine )  ;", "}", "METHOD_END"], "methodName": ["multilineToString"], "fileName": "org.elasticsearch.painless.node.ANode"}, {"methodBody": ["METHOD_START", "{", "List < String >    pairs    =    new   ArrayList <  >  ( Math . max ( lefts . size (  )  ,    rights . size (  )  )  )  ;", "Iterator <  ?    extends   Object >    left    =    lefts . iterator (  )  ;", "Iterator <  ?    extends   Object >    right    =    rights . iterator (  )  ;", "while    (  ( left . hasNext (  )  )     |  |     ( right . hasNext (  )  )  )     {", "pairs . add ( joinWithName (  \" Pair \"  ,    Arrays . asList (  ( left . hasNext (  )     ?    left . next (  )     :     \"  < uneven >  \"  )  ,     ( right . hasNext (  )     ?    right . next (  )     :     \"  < uneven >  \"  )  )  ,    Collections . emptyList (  )  )  )  ;", "}", "return   pairs ;", "}", "METHOD_END"], "methodName": ["pairwiseToString"], "fileName": "org.elasticsearch.painless.node.ANode"}, {"methodBody": ["METHOD_START", "{", "return   singleLineToString ( Arrays . asList ( subs )  )  ;", "}", "METHOD_END"], "methodName": ["singleLineToString"], "fileName": "org.elasticsearch.painless.node.ANode"}, {"methodBody": ["METHOD_START", "{", "return   joinWithName ( getClass (  )  . getSimpleName (  )  ,    subs ,    Collections . emptyList (  )  )  ;", "}", "METHOD_END"], "methodName": ["singleLineToString"], "fileName": "org.elasticsearch.painless.node.ANode"}, {"methodBody": ["METHOD_START", "{", "List < Object >    subs    =    new   ArrayList <  >  (  )  ;", "Collections . addAll ( subs ,    restOfSubs )  ;", "if    ( false    =  =     ( arguments . isEmpty (  )  )  )     {", "subs . add ( joinWithName (  \" Args \"  ,    arguments ,    Collections . emptyList (  )  )  )  ;", "}", "return   singleLineToString ( subs )  ;", "}", "METHOD_END"], "methodName": ["singleLineToStringWithOptionalArgs"], "fileName": "org.elasticsearch.painless.node.ANode"}, {"methodBody": ["METHOD_START", "{", "Label   noFlip    =    new   Label (  )  ;", "writer . dup (  )  ;", "writer . ifZCmp ( IFGE ,    noFlip )  ;", "writer . swap (  )  ;", "writer . dupX 1  (  )  ;", "writeGetLength . accept ( writer )  ;", "writer . visitInsn ( IADD )  ;", "writer . mark ( noFlip )  ;", "}", "METHOD_END"], "methodName": ["writeIndexFlip"], "fileName": "org.elasticsearch.painless.node.AStoreable"}, {"methodBody": ["METHOD_START", "{", "rhs . analyze ( locals )  ;", "boolean   shift    =    false ;", "if    (  ( operation )     =  =     ( Operation . MUL )  )     {", "promote    =    AnalyzerCaster . promoteNumeric ( lhs . actual ,    rhs . actual ,    true )  ;", "} else", "if    (  ( operation )     =  =     ( Operation . DIV )  )     {", "promote    =    AnalyzerCaster . promoteNumeric ( lhs . actual ,    rhs . actual ,    true )  ;", "} else", "if    (  ( operation )     =  =     ( Operation . REM )  )     {", "promote    =    AnalyzerCaster . promoteNumeric ( lhs . actual ,    rhs . actual ,    true )  ;", "} else", "if    (  ( operation )     =  =     ( Operation . ADD )  )     {", "promote    =    AnalyzerCaster . promoteAdd ( lhs . actual ,    rhs . actual )  ;", "} else", "if    (  ( operation )     =  =     ( Operation . SUB )  )     {", "promote    =    AnalyzerCaster . promoteNumeric ( lhs . actual ,    rhs . actual ,    true )  ;", "} else", "if    (  ( operation )     =  =     ( Operation . LSH )  )     {", "promote    =    AnalyzerCaster . promoteNumeric ( lhs . actual ,    false )  ;", "shiftDistance    =    AnalyzerCaster . promoteNumeric ( rhs . actual ,    false )  ;", "shift    =    true ;", "} else", "if    (  ( operation )     =  =     ( Operation . RSH )  )     {", "promote    =    AnalyzerCaster . promoteNumeric ( lhs . actual ,    false )  ;", "shiftDistance    =    AnalyzerCaster . promoteNumeric ( rhs . actual ,    false )  ;", "shift    =    true ;", "} else", "if    (  ( operation )     =  =     ( Operation . USH )  )     {", "promote    =    AnalyzerCaster . promoteNumeric ( lhs . actual ,    false )  ;", "shiftDistance    =    AnalyzerCaster . promoteNumeric ( rhs . actual ,    false )  ;", "shift    =    true ;", "} else", "if    (  ( operation )     =  =     ( Operation . BWAND )  )     {", "promote    =    AnalyzerCaster . promoteXor ( lhs . actual ,    rhs . actual )  ;", "} else", "if    (  ( operation )     =  =     ( Operation . XOR )  )     {", "promote    =    AnalyzerCaster . promoteXor ( lhs . actual ,    rhs . actual )  ;", "} else", "if    (  ( operation )     =  =     ( Operation . BWOR )  )     {", "promote    =    AnalyzerCaster . promoteXor ( lhs . actual ,    rhs . actual )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "if    (  (  ( promote )     =  =    null )     |  |     ( shift    &  &     (  ( shiftDistance )     =  =    null )  )  )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  (  (  \" Cannot   apply   compound   a    \"     +     \"  [  \"  )     +     ( operation . symbol )  )     +     \"  =  ]    to   types    [  \"  )     +     ( lhs . actual )  )     +     \"  ]    and    [  \"  )     +     ( rhs . actual )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "cat    =     (  ( operation )     =  =     ( Operation . ADD )  )     &  &     (  ( promote )     =  =     ( String . class )  )  ;", "if    ( cat )     {", "if    (  (  (  ( rhs )    instanceof   EBinary )     &  &     (  (  (  ( EBinary )     ( rhs )  )  . operation )     =  =     ( Operation . ADD )  )  )     &  &     (  ( rhs . actual )     =  =     ( String . class )  )  )     {", "(  ( EBinary )     ( rhs )  )  . cat    =    true ;", "}", "rhs . expected    =    rhs . actual ;", "} else", "if    ( shift )     {", "if    (  ( promote )     =  =     ( Definition . def . class )  )     {", "rhs . expected    =    promote ;", "} else", "if    (  ( shiftDistance )     =  =     ( long . class )  )     {", "rhs . expected    =    int . class ;", "rhs . explicit    =    true ;", "} else    {", "rhs . expected    =    shiftDistance ;", "}", "} else    {", "rhs . expected    =    promote ;", "}", "rhs    =    rhs . cast ( locals )  ;", "there    =    AnalyzerCaster . getLegalCast ( location ,    lhs . actual ,    promote ,    false ,    false )  ;", "back    =    AnalyzerCaster . getLegalCast ( location ,    promote ,    lhs . actual ,    true ,    false )  ;", "this . statement    =    true ;", "this . actual    =     ( read )     ?    lhs . actual    :    void . class ;", "}", "METHOD_END"], "methodName": ["analyzeCompound"], "fileName": "org.elasticsearch.painless.node.EAssignment"}, {"methodBody": ["METHOD_START", "{", "if    (  ( pre )     &  &     ( post )  )     {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "} else", "if    (  ( pre )     |  |     ( post )  )     {", "if    (  ( rhs )     !  =    null )     {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "if    (  ( operation )     =  =     ( Operation . INCR )  )     {", "if    (  ( lhs . actual )     =  =     ( double . class )  )     {", "rhs    =    new   EConstant ( location ,     1  .  0  )  ;", "} else", "if    (  ( lhs . actual )     =  =     ( float . class )  )     {", "rhs    =    new   EConstant ( location ,     1  .  0 F )  ;", "} else", "if    (  ( lhs . actual )     =  =     ( long . class )  )     {", "rhs    =    new   EConstant ( location ,     1 L )  ;", "} else    {", "rhs    =    new   EConstant ( location ,     1  )  ;", "}", "operation    =    Operation . ADD ;", "} else", "if    (  ( operation )     =  =     ( Operation . DECR )  )     {", "if    (  ( lhs . actual )     =  =     ( double . class )  )     {", "rhs    =    new   EConstant ( location ,     1  .  0  )  ;", "} else", "if    (  ( lhs . actual )     =  =     ( float . class )  )     {", "rhs    =    new   EConstant ( location ,     1  .  0 F )  ;", "} else", "if    (  ( lhs . actual )     =  =     ( long . class )  )     {", "rhs    =    new   EConstant ( location ,     1 L )  ;", "} else    {", "rhs    =    new   EConstant ( location ,     1  )  ;", "}", "operation    =    Operation . SUB ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeIncrDecr"], "fileName": "org.elasticsearch.painless.node.EAssignment"}, {"methodBody": ["METHOD_START", "{", "if    (  ( lhs )    instanceof   AStoreable )     {", "AStoreable   lhs    =     (  ( AStoreable )     ( this . lhs )  )  ;", "lhs . read    =    read ;", "lhs . write    =    true ;", "lhs . analyze ( locals )  ;", "} else    {", "throw   new   IllegalArgumentException (  \" Left - hand   side   cannot   be   aed   a   value .  \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["analyzeLHS"], "fileName": "org.elasticsearch.painless.node.EAssignment"}, {"methodBody": ["METHOD_START", "{", "AStoreable   lhs    =     (  ( AStoreable )     ( this . lhs )  )  ;", "if    ( lhs . isDefOptimized (  )  )     {", "rhs . analyze ( locals )  ;", "if    (  ( rhs . actual )     =  =     ( void . class )  )     {", "throw   createError ( new   IllegalArgumentException (  \" Right - hand   side   cannot   be   a    [ void ]    type   for   a .  \"  )  )  ;", "}", "rhs . expected    =    rhs . actual ;", "lhs . updateActual ( rhs . actual )  ;", "} else    {", "rhs . expected    =    lhs . actual ;", "rhs . analyze ( locals )  ;", "}", "rhs    =    rhs . cast ( locals )  ;", "this . statement    =    true ;", "this . actual    =     ( read )     ?    lhs . actual    :    void . class ;", "}", "METHOD_END"], "methodName": ["analyzeSimple"], "fileName": "org.elasticsearch.painless.node.EAssignment"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteAdd ( left . actual ,    right . actual )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   add    [  +  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote ;", "if    (  ( promote )     =  =     ( String . class )  )     {", "left . expected    =    left . actual ;", "if    (  (  (  ( left )    instanceof    )     &  &     (  (  (  (  )     ( left )  )  . operation )     =  =     ( Operation . ADD )  )  )     &  &     (  ( left . actual )     =  =     ( String . class )  )  )     {", "(  (  )     ( left )  )  . cat    =    true ;", "}", "right . expected    =    right . actual ;", "if    (  (  (  ( right )    instanceof    )     &  &     (  (  (  (  )     ( right )  )  . operation )     =  =     ( Operation . ADD )  )  )     &  &     (  ( right . actual )     =  =     ( String . class )  )  )     {", "(  (  )     ( right )  )  . cat    =    true ;", "}", "} else", "if    (  ( promote )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    promote ;", "right . expected    =    promote ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     +     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     +     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     +     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     +     (  ( double )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( String . class )  )     {", "constant    =     ( left . constant . toString (  )  )     +     ( right . constant . toString (  )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeAdd"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    false )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   and    [  &  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote ;", "if    (  ( promote )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    promote ;", "right . expected    =    promote ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     &     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     &     (  ( long )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeBWAnd"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    false )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   or    [  |  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote ;", "if    (  ( promote )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    promote ;", "right . expected    =    promote ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     |     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     |     (  ( long )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeBWOr"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    true )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   divide    [  /  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote ;", "if    (  ( promote )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    promote ;", "right . expected    =    promote ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "try    {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     /     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     /     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     /     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     /     (  ( double )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}    catch    ( ArithmeticException   exception )     {", "throw   createError ( exception )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeDiv"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "Class <  ?  >    lhspromote    =    AnalyzerCaster . promoteNumeric ( left . actual ,    false )  ;", "Class <  ?  >    rhspromote    =    AnalyzerCaster . promoteNumeric ( right . actual ,    false )  ;", "if    (  ( lhspromote    =  =    null )     |  |     ( rhspromote    =  =    null )  )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   left   shift    [  <  <  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote    =    lhspromote ;", "shiftDistance    =    rhspromote ;", "if    (  ( lhspromote    =  =     ( Definition . def . class )  )     |  |     ( rhspromote    =  =     ( Definition . def . class )  )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    lhspromote ;", "if    ( rhspromote    =  =     ( long . class )  )     {", "right . expected    =    int . class ;", "right . explicit    =    true ;", "} else    {", "right . expected    =    rhspromote ;", "}", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     <  <     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     <  <     (  ( int )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeLSH"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    true )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   multiply    [  *  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote ;", "if    (  ( promote )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    promote ;", "right . expected    =    promote ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     *     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     *     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     *     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     *     (  ( double )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeMul"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "Class <  ?  >    lhspromote    =    AnalyzerCaster . promoteNumeric ( left . actual ,    false )  ;", "Class <  ?  >    rhspromote    =    AnalyzerCaster . promoteNumeric ( right . actual ,    false )  ;", "if    (  ( lhspromote    =  =    null )     |  |     ( rhspromote    =  =    null )  )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   right   shift    [  >  >  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote    =    lhspromote ;", "shiftDistance    =    rhspromote ;", "if    (  ( lhspromote    =  =     ( Definition . def . class )  )     |  |     ( rhspromote    =  =     ( Definition . def . class )  )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    lhspromote ;", "if    ( rhspromote    =  =     ( long . class )  )     {", "right . expected    =    int . class ;", "right . explicit    =    true ;", "} else    {", "right . expected    =    rhspromote ;", "}", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     >  >     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     >  >     (  ( int )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeRSH"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "left . expected    =    String . class ;", "right . expected    =    Pattern . class ;", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "promote    =    boolean . class ;", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeRegexOp"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    true )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   remainder    [  %  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote ;", "if    (  ( promote )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    promote ;", "right . expected    =    promote ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "try    {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     %     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     %     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     %     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     %     (  ( double )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}    catch    ( ArithmeticException   exception )     {", "throw   createError ( exception )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeRem"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    true )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   subtract    [  -  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote ;", "if    (  ( promote )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    promote ;", "right . expected    =    promote ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     -     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     -     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     -     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     -     (  ( double )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeSub"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "Class <  ?  >    lhspromote    =    AnalyzerCaster . promoteNumeric ( left . actual ,    false )  ;", "Class <  ?  >    rhspromote    =    AnalyzerCaster . promoteNumeric ( right . actual ,    false )  ;", "actual    =    promote    =    lhspromote ;", "shiftDistance    =    rhspromote ;", "if    (  ( lhspromote    =  =    null )     |  |     ( rhspromote    =  =    null )  )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   unsigned   shift    [  >  >  >  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "if    (  ( lhspromote    =  =     ( Definition . def . class )  )     |  |     ( rhspromote    =  =     ( Definition . def . class )  )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    lhspromote ;", "if    ( rhspromote    =  =     ( long . class )  )     {", "right . expected    =    int . class ;", "right . explicit    =    true ;", "} else    {", "right . expected    =    rhspromote ;", "}", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     >  >  >     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     >  >  >     (  ( int )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeUSH"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteXor ( left . actual ,    right . actual )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   xor    [  ^  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "actual    =    promote ;", "if    (  ( promote )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "if    (  ( expected )     !  =    null )     {", "actual    =    expected ;", "}", "} else    {", "left . expected    =    promote ;", "right . expected    =    promote ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promote )     =  =     ( boolean . class )  )     {", "constant    =     (  ( boolean )     ( left . constant )  )     ^     (  ( boolean )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     ^     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     ^     (  ( long )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["analyzeXor"], "fileName": "org.elasticsearch.painless.node.EBinary"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promotedType    =    AnalyzerCaster . promoteEquality ( left . actual ,    right . actual )  ;", "if    (  ( promotedType )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   equals    [  =  =  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "if    (  ( promotedType )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "} else    {", "left . expected    =    promotedType ;", "right . expected    =    promotedType ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  ( left . isNull )     &  &     ( right . isNull )  )     {", "throw   createError ( new   IllegalArgumentException (  \" Extraneous   comparison   of   null   constants .  \"  )  )  ;", "}", "if    (  (  (  ( left . constant )     !  =    null )     |  |     ( left . isNull )  )     &  &     (  (  ( right . constant )     !  =    null )     |  |     ( right . isNull )  )  )     {", "if    (  ( promotedType )     =  =     ( boolean . class )  )     {", "constant    =     (  ( boolean )     ( left . constant )  )     =  =     (  ( boolean )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     =  =     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     =  =     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     =  =     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     =  =     (  ( double )     ( right . constant )  )  ;", "} else", "if    (  !  ( left . isNull )  )     {", "constant    =    left . constant . equals ( right . constant )  ;", "} else", "if    (  !  ( right . isNull )  )     {", "constant    =    right . constant . equals ( null )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeEq"], "fileName": "org.elasticsearch.painless.node.EComp"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promotedType    =    AnalyzerCaster . promoteEquality ( left . actual ,    right . actual )  ;", "if    (  ( promotedType )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   reference   equals    [  =  =  =  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "left . expected    =    promotedType ;", "right . expected    =    promotedType ;", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  ( left . isNull )     &  &     ( right . isNull )  )     {", "throw   createError ( new   IllegalArgumentException (  \" Extraneous   comparison   of   null   constants .  \"  )  )  ;", "}", "if    (  (  (  ( left . constant )     !  =    null )     |  |     ( left . isNull )  )     &  &     (  (  ( right . constant )     !  =    null )     |  |     ( right . isNull )  )  )     {", "if    (  ( promotedType )     =  =     ( boolean . class )  )     {", "constant    =     (  ( boolean )     ( left . constant )  )     =  =     (  ( boolean )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     =  =     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     =  =     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     =  =     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     =  =     (  ( double )     ( right . constant )  )  ;", "} else    {", "constant    =     ( left . constant )     =  =     ( right . constant )  ;", "}", "}", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeEqR"], "fileName": "org.elasticsearch.painless.node.EComp"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promotedType    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    true )  ;", "if    (  ( promotedType )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   greater   than    [  >  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "if    (  ( promotedType )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "} else    {", "left . expected    =    promotedType ;", "right . expected    =    promotedType ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promotedType )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     >     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     >     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     >     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     >     (  ( double )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeGT"], "fileName": "org.elasticsearch.painless.node.EComp"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promotedType    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    true )  ;", "if    (  ( promotedType )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   greater   than   or   equals    [  >  =  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "if    (  ( promotedType )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "} else    {", "left . expected    =    promotedType ;", "right . expected    =    promotedType ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promotedType )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     >  =     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     >  =     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     >  =     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     >  =     (  ( double )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeGTE"], "fileName": "org.elasticsearch.painless.node.EComp"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promotedType    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    true )  ;", "if    (  ( promotedType )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply      than    [  >  =  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "if    (  ( promotedType )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "} else    {", "left . expected    =    promotedType ;", "right . expected    =    promotedType ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promotedType )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     <     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     <     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     <     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     <     (  ( double )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeLT"], "fileName": "org.elasticsearch.painless.node.EComp"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promotedType    =    AnalyzerCaster . promoteNumeric ( left . actual ,    right . actual ,    true )  ;", "if    (  ( promotedType )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply      than   or   equals    [  <  =  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "if    (  ( promotedType )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "} else    {", "left . expected    =    promotedType ;", "right . expected    =    promotedType ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  (  ( left . constant )     !  =    null )     &  &     (  ( right . constant )     !  =    null )  )     {", "if    (  ( promotedType )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     <  =     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     <  =     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     <  =     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     <  =     (  ( double )     ( right . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeLTE"], "fileName": "org.elasticsearch.painless.node.EComp"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promotedType    =    AnalyzerCaster . promoteEquality ( left . actual ,    right . actual )  ;", "if    (  ( promotedType )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   not   equals    [  !  =  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "if    (  ( promotedType )     =  =     ( Definition . def . class )  )     {", "left . expected    =    left . actual ;", "right . expected    =    right . actual ;", "} else    {", "left . expected    =    promotedType ;", "right . expected    =    promotedType ;", "}", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  ( left . isNull )     &  &     ( right . isNull )  )     {", "throw   createError ( new   IllegalArgumentException (  \" Extraneous   comparison   of   null   constants .  \"  )  )  ;", "}", "if    (  (  (  ( left . constant )     !  =    null )     |  |     ( left . isNull )  )     &  &     (  (  ( right . constant )     !  =    null )     |  |     ( right . isNull )  )  )     {", "if    (  ( promotedType )     =  =     ( boolean . class )  )     {", "constant    =     (  ( boolean )     ( left . constant )  )     !  =     (  ( boolean )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     !  =     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     !  =     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     !  =     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     !  =     (  ( double )     ( right . constant )  )  ;", "} else", "if    (  !  ( left . isNull )  )     {", "constant    =     !  ( left . constant . equals ( right . constant )  )  ;", "} else", "if    (  !  ( right . isNull )  )     {", "constant    =     !  ( right . constant . equals ( null )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeNE"], "fileName": "org.elasticsearch.painless.node.EComp"}, {"methodBody": ["METHOD_START", "{", "left . analyze ( variables )  ;", "right . analyze ( variables )  ;", "promotedType    =    AnalyzerCaster . promoteEquality ( left . actual ,    right . actual )  ;", "if    (  ( promotedType )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  (  (  (  \" Cannot   apply   reference   not   equals    [  !  =  =  ]    to   types    \"     +     \"  [  \"  )     +     ( Definition . ClassToName ( left . actual )  )  )     +     \"  ]    and    [  \"  )     +     ( Definition . ClassToName ( right . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "left . expected    =    promotedType ;", "right . expected    =    promotedType ;", "left    =    left . cast ( variables )  ;", "right    =    right . cast ( variables )  ;", "if    (  ( left . isNull )     &  &     ( right . isNull )  )     {", "throw   createError ( new   IllegalArgumentException (  \" Extraneous   comparison   of   null   constants .  \"  )  )  ;", "}", "if    (  (  (  ( left . constant )     !  =    null )     |  |     ( left . isNull )  )     &  &     (  (  ( right . constant )     !  =    null )     |  |     ( right . isNull )  )  )     {", "if    (  ( promotedType )     =  =     ( boolean . class )  )     {", "constant    =     (  ( boolean )     ( left . constant )  )     !  =     (  ( boolean )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( int . class )  )     {", "constant    =     (  ( int )     ( left . constant )  )     !  =     (  ( int )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( long . class )  )     {", "constant    =     (  ( long )     ( left . constant )  )     !  =     (  ( long )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( float . class )  )     {", "constant    =     (  ( float )     ( left . constant )  )     !  =     (  ( float )     ( right . constant )  )  ;", "} else", "if    (  ( promotedType )     =  =     ( double . class )  )     {", "constant    =     (  ( double )     ( left . constant )  )     !  =     (  ( double )     ( right . constant )  )  ;", "} else    {", "constant    =     ( left . constant )     !  =     ( right . constant )  ;", "}", "}", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeNER"], "fileName": "org.elasticsearch.painless.node.EComp"}, {"methodBody": ["METHOD_START", "{", "child . expected    =    expected ;", "child . e    =    e ;", "child . internal    =    internal ;", "return   child . cast ( locals )  ;", "}", "METHOD_END"], "methodName": ["cast"], "fileName": "org.elasticsearch.painless.node.EExplicit"}, {"methodBody": ["METHOD_START", "{", "switch    ( c )     {", "case    ' c '     :", "return   Pattern . CANON _ EQ ;", "case    ' i '     :", "return   Pattern . CASE _ INSENSITIVE ;", "case    ' l '     :", "return   Pattern . LITERAL ;", "case    ' m '     :", "return   Pattern . MULTILINE ;", "case    ' s '     :", "return   Pattern . DOTALL ;", "case    ' U '     :", "return   Pattern . UNICODE _ CHARACTER _ CLASS ;", "case    ' u '     :", "return   Pattern . UNICODE _ CASE ;", "case    ' x '     :", "return   Pattern . COMMENTS ;", "default    :", "throw   new   IllegalArgumentException (  (  (  \" Unknown   flag    [  \"     +    c )     +     \"  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["flagForChar"], "fileName": "org.elasticsearch.painless.node.ERegex"}, {"methodBody": ["METHOD_START", "{", "writer . push ( pattern )  ;", "writer . push ( flags )  ;", "writer . invokeStatic ( objectweb . asm . Type . getType ( Pattern . class )  ,    WriterConstants . PATTERN _ COMPILE )  ;", "}", "METHOD_END"], "methodName": ["initializeConstant"], "fileName": "org.elasticsearch.painless.node.ERegex"}, {"methodBody": ["METHOD_START", "{", "child . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteNumeric ( child . actual ,    false )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  \" Cannot   apply   not    [  ~  ]    to   type    [  \"     +     ( Definition . ClassToName ( child . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "child . expected    =    promote ;", "child    =    child . cast ( variables )  ;", "if    (  ( child . constant )     !  =    null )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     ~  (  ( int )     ( child . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     ~  (  ( long )     ( child . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "if    (  (  ( promote )     =  =     ( Definition . def . class )  )     &  &     (  ( expected )     !  =    null )  )     {", "actual    =    expected ;", "} else    {", "actual    =    promote ;", "}", "}", "METHOD_END"], "methodName": ["analyzeBWNot"], "fileName": "org.elasticsearch.painless.node.EUnary"}, {"methodBody": ["METHOD_START", "{", "child . expected    =    boolean . class ;", "child . analyze ( variables )  ;", "child    =    child . cast ( variables )  ;", "if    (  ( child . constant )     !  =    null )     {", "constant    =     !  (  ( boolean )     ( child . constant )  )  ;", "}", "actual    =    boolean . class ;", "}", "METHOD_END"], "methodName": ["analyzeNot"], "fileName": "org.elasticsearch.painless.node.EUnary"}, {"methodBody": ["METHOD_START", "{", "child . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteNumeric ( child . actual ,    true )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  \" Cannot   apply   positive    [  +  ]    to   type    [  \"     +     ( Definition . ClassToName ( child . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "child . expected    =    promote ;", "child    =    child . cast ( variables )  ;", "if    (  ( child . constant )     !  =    null )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     +  (  ( int )     ( child . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     +  (  ( long )     ( child . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( float . class )  )     {", "constant    =     +  (  ( float )     ( child . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( double . class )  )     {", "constant    =     +  (  ( double )     ( child . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "if    (  (  ( promote )     =  =     ( Definition . def . class )  )     &  &     (  ( expected )     !  =    null )  )     {", "actual    =    expected ;", "} else    {", "actual    =    promote ;", "}", "}", "METHOD_END"], "methodName": ["analyzerAdd"], "fileName": "org.elasticsearch.painless.node.EUnary"}, {"methodBody": ["METHOD_START", "{", "child . analyze ( variables )  ;", "promote    =    AnalyzerCaster . promoteNumeric ( child . actual ,    true )  ;", "if    (  ( promote )     =  =    null )     {", "throw   createError ( new   ClassCastException (  (  (  \" Cannot   apply   negative    [  -  ]    to   type    [  \"     +     ( Definition . ClassToName ( child . actual )  )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "child . expected    =    promote ;", "child    =    child . cast ( variables )  ;", "if    (  ( child . constant )     !  =    null )     {", "if    (  ( promote )     =  =     ( int . class )  )     {", "constant    =     -  (  ( int )     ( child . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( long . class )  )     {", "constant    =     -  (  ( long )     ( child . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( float . class )  )     {", "constant    =     -  (  ( float )     ( child . constant )  )  ;", "} else", "if    (  ( promote )     =  =     ( double . class )  )     {", "constant    =     -  (  ( double )     ( child . constant )  )  ;", "} else    {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "}", "if    (  (  ( promote )     =  =     ( Definition . def . class )  )     &  &     (  ( expected )     !  =    null )  )     {", "actual    =    expected ;", "} else    {", "actual    =    promote ;", "}", "}", "METHOD_END"], "methodName": ["analyzerSub"], "fileName": "org.elasticsearch.painless.node.EUnary"}, {"methodBody": ["METHOD_START", "{", "return   getCaptures (  )  . length ;", "}", "METHOD_END"], "methodName": ["getCaptureCount"], "fileName": "org.elasticsearch.painless.node.ILambda"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( expected ,    walk ( code )  . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertToString"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  \"        ( SDeclBlock    ( SDeclaration   def   i )  )  \\ n \"     +     \"        ( SExpression    ( EAssignment    ( EVariable   i )     =     ( ENumeric    2  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   i )  )  )  \"  )  )  ,     (  \" def   i ;  \\ n \"     +     (  \" i    =     2  ;  \\ n \"     +     \" return   i \"  )  )  )  ;", "for    ( String   operator    :    new   String [  ]  {     \"  +  \"  ,     \"  -  \"  ,     \"  *  \"  ,     \"  /  \"  ,     \"  %  \"  ,     \"  &  \"  ,     \"  ^  \"  ,     \"  |  \"  ,     \"  <  <  \"  ,     \"  >  >  \"  ,     \"  >  >  >  \"     }  )     {", "assertToString (  (  (  (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   def   i    ( ENumeric    1  )  )  )  \\ n \"     +     \"        ( SExpression    ( EAssignment    ( EVariable   i )     \"  )  )     +    operator )     +     \"  =     ( ENumeric    2  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   i )  )  )  \"  )  ,     (  (  (  (  \" def   i    =     1  ;  \\ n \"     +     \" i    \"  )     +    operator )     +     \"  =     2  ;  \\ n \"  )     +     \" return   i \"  )  )  ;", "}", "assertToString (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   def   i )  )  \\ n \"     +     \"        ( SReturn    ( EAssignment    ( EVariable   i )     =     ( ENumeric    2  )  )  )  )  \"  )  )  ,     (  \" def   i ;  \\ n \"     +     \" return   i    =     2  \"  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   def   i )  )  \\ n \"     +     \"        ( SReturn    ( EAssignment    ( EVariable   i )     +  +    post )  )  )  \"  )  )  ,     (  \" def   i ;  \\ n \"     +     \" return   i +  +  \"  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   def   i )  )  \\ n \"     +     \"        ( SReturn    ( EAssignment    ( EVariable   i )     +  +    pre )  )  )  \"  )  )  ,     (  \" def   i ;  \\ n \"     +     \" return    +  + i \"  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   def   i )  )  \\ n \"     +     \"        ( SReturn    ( EAssignment    ( EVariable   i )     -  -    post )  )  )  \"  )  )  ,     (  \" def   i ;  \\ n \"     +     \" return   i -  -  \"  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   def   i )  )  \\ n \"     +     \"        ( SReturn    ( EAssignment    ( EVariable   i )     -  -    pre )  )  )  \"  )  )  ,     (  \" def   i ;  \\ n \"     +     \" return    -  - i \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEAssignment"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     *     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     *     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     /     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     /     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     %     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     %     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     +     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     +     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     -     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     -     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( EString    ' asb '  )     =  ~     ( ERegex    / cat /  )  )  )  )  \"  ,     \" return    ' asb '     =  ~     / cat /  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( EString    ' asb '  )     =  =  ~     ( ERegex    / cat /  )  )  )  )  \"  ,     \" return    ' asb '     =  =  ~     / cat /  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     <  <     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     <  <     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     >  >     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     >  >     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     >  >  >     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     >  >  >     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     &     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     &     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     ^     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     ^     1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBinary    ( ENumeric    1  )     |     ( ENumeric    1  )  )  )  )  \"  ,     \" return    1     |     1  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEBinary"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EBool    ( EBoolean   true )     &  &     ( EBoolean   false )  )  )  )  \"  ,     \" return   true    &  &    false \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBool    ( EBoolean   true )     |  |     ( EBoolean   false )  )  )  )  \"  ,     \" return   true    |  |    false \"  )  ;", "}", "METHOD_END"], "methodName": ["testEBool"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EBoolean   true )  )  )  \"  ,     \" return   true \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EBoolean   false )  )  )  \"  ,     \" return   false \"  )  ;", "}", "METHOD_END"], "methodName": ["testEBoolean"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  \"        ( SFunction   def   a \\ n \"     +     \"              ( SReturn    ( EBoolean   true )  )  )  \\ n \"  )     +     \"        ( SReturn    ( ECallLocal   a )  )  )  \"  )  )  ,     (  \" def   a (  )     {  \\ n \"     +     (  (  \"       return   true \\ n \"     +     \"  }  \\ n \"  )     +     \" return   a (  )  \"  )  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  \"        ( SFunction   def   a    ( Args    ( Pair   int   i )     ( Pair   int   j )  )  \\ n \"     +     \"              ( SReturn    ( EBoolean   true )  )  )  \\ n \"  )     +     \"        ( SReturn    ( ECallLocal   a    ( Args    ( ENumeric    1  )     ( ENumeric    2  )  )  )  )  )  \"  )  )  ,     (  \" def   a ( int   i ,    int   j )     {  \\ n \"     +     (  (  \"       return   true \\ n \"     +     \"  }  \\ n \"  )     +     \" return   a (  1  ,     2  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testECallLocal"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   Integer   x    ( PCallInvoke    ( EStatic   Integer )    valueOf    ( Args    ( ENumeric    5  )  )  )  )  )  \\ n \"     +     \"        ( SReturn    ( PCallInvoke    ( PCallInvoke    ( EStatic   Optional )    empty )    orElseGet    ( Args    ( ECapturingFunctionRef   x   toString )  )  )  )  )  \"  )  )  ,     (  \" Integer   x    =    Integer . valueOf (  5  )  ;  \\ n \"     +     \" return   Optional . empty (  )  . orElseGet ( x :  : toString )  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testECapturingFunctionRef"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "AExpression   child    =    new   EConstant ( l ,     \" test \"  )  ;", "Definition . Cast   cast    =    Definition . Cast . standard ( String . class ,    Integer . class ,    true )  ;", "assertEquals (  \"  ( ECast   Integer    ( EConstant   String    ' test '  )  )  \"  ,    new   ECast ( l ,    child ,    cast )  . t (  )  )  ;", "l    =    new   Location ( getTestName (  )  ,     1  )  ;", "child    =    new   EBinary ( l ,    Operation . ADD ,    new   EConstant ( l ,     \" test \"  )  ,    new   EConstant ( l ,     1  2  )  )  ;", "cast    =    Definition . Cast . standard ( Integer . class ,    Boolean . class ,    true )  ;", "assertEquals (  \"  ( ECast   Boolean    ( EBinary    ( EConstant   String    ' test '  )     +     ( EConstant   Integer    1  2  )  )  )  \"  ,    new   ECast ( l ,    child ,    cast )  . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testECast"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EComp    ( PField    ( EVariable   params )    a )     <     ( ENumeric    1  0  )  )  )  )  \"  ,     \" return   params . a    <     1  0  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EComp    ( PField    ( EVariable   params )    a )     <  =     ( ENumeric    1  0  )  )  )  )  \"  ,     \" return   params . a    <  =     1  0  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EComp    ( PField    ( EVariable   params )    a )     >     ( ENumeric    1  0  )  )  )  )  \"  ,     \" return   params . a    >     1  0  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EComp    ( PField    ( EVariable   params )    a )     >  =     ( ENumeric    1  0  )  )  )  )  \"  ,     \" return   params . a    >  =     1  0  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EComp    ( PField    ( EVariable   params )    a )     =  =     ( ENumeric    1  0  )  )  )  )  \"  ,     \" return   params . a    =  =     1  0  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EComp    ( PField    ( EVariable   params )    a )     =  =  =     ( ENumeric    1  0  )  )  )  )  \"  ,     \" return   params . a    =  =  =     1  0  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EComp    ( PField    ( EVariable   params )    a )     !  =     ( ENumeric    1  0  )  )  )  )  \"  ,     \" return   params . a    !  =     1  0  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EComp    ( PField    ( EVariable   params )    a )     !  =  =     ( ENumeric    1  0  )  )  )  )  \"  ,     \" return   params . a    !  =  =     1  0  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEComp"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EConditional    ( PField    ( EVariable   params )    a )     ( ENumeric    1  )     ( ENumeric    6  )  )  )  )  \"  ,     \" return   params . a    ?     1     :     6  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEConditional"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \"  ( EConstant   String    '  1  2  1  '  )  \"  ,    new   EConstant ( new   Location ( getTestName (  )  ,     0  )  ,     \"  1  2  1  \"  )  . toString (  )  )  ;", "assertEquals (  \"  ( EConstant   String    '  9  2     '  )  \"  ,    new   EConstant ( new   Location ( getTestName (  )  ,     0  )  ,     \"  9  2     \"  )  . toString (  )  )  ;", "assertEquals (  \"  ( EConstant   Integer    1  2  3  7  )  \"  ,    new   EConstant ( new   Location ( getTestName (  )  ,     1  )  ,     1  2  3  7  )  . toString (  )  )  ;", "assertEquals (  \"  ( EConstant   Boolean   true )  \"  ,    new   EConstant ( new   Location ( getTestName (  )  ,     2  )  ,    true )  . toString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testEConstant"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EDecimal    1  .  0  )  )  )  \"  ,     \" return    1  .  0  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EDecimal    1  4  .  1  2  1 d )  )  )  \"  ,     \" return    1  4  .  1  2  1 d \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EDecimal    2  2  3  4  .  1 f )  )  )  \"  ,     \" return    2  2  3  4  .  1 f \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EDecimal    1  4  .  1  2  1 D )  )  )  \"  ,     \" return    1  4  .  1  2  1 D \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EDecimal    1  2  3  4  .  1 F )  )  )  \"  ,     \" return    1  2  3  4  .  1 F \"  )  ;", "}", "METHOD_END"], "methodName": ["testEDecimal"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EElvis    ( PField    ( EVariable   params )    a )     ( ENumeric    1  )  )  )  )  \"  ,     \" return   params . a    ?  :     1  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEElvis"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EExplicit   byte    ( PField    ( EVariable   params )    a )  )  )  )  \"  ,     \" return    ( byte )  ( params . a )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEExplicit"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource    ( SReturn    \"     +     \"  ( PCallInvoke    ( PCallInvoke    ( EStatic   Optional )    empty )    orElseGet    ( Args    ( EFunctionRef   Optional   empty )  )  )  )  )  \"  )  ,     \" return   Optional . empty (  )  . orElseGet ( Optional :  : empty )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEFunctionRef"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EInstanceof    ( ENewObj   Object )    Object )  )  )  \"  ,     \" return   new   Object (  )    instanceof   Object \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EInstanceof    ( ENumeric    1  2  )    double )  )  )  \"  ,     \" return    1  2    instanceof   double \"  )  ;", "}", "METHOD_END"], "methodName": ["testEInstanceOf"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( PCallInvoke    ( EStatic   Optional )    empty )    orElseGet    ( Args    \"     +     \"  ( ELambda    ( SReturn    ( ENumeric    1  )  )  )  )  )  )  )  \"  )  ,     (  \" return   Optional . empty (  )  . orElseGet (  (  )     -  >     {  \\ n \"     +     (  \"       return    1  \\ n \"     +     \"  }  )  \"  )  )  )  ;", "assertToString (  (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( PCallInvoke    ( EStatic   Optional )    empty )    orElseGet    ( Args    \"     +     \"  ( ELambda    ( SReturn    ( ENumeric    1  )  )  )  )  )  )  )  \"  )  ,     \" return   Optional . empty (  )  . orElseGet (  (  )     -  >     1  )  \"  )  ;", "assertToString (  (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( PCallInvoke    ( PCallInvoke    ( EListInit    ( ENumeric    1  )     ( ENumeric    2  )     ( ENumeric    3  )  )    stream )     \"     +     (  \" mapToInt    ( Args    ( ELambda    ( Pair   def   x )  \\ n \"     +     \"        ( SReturn    ( EBinary    ( EVariable   x )     +     ( ENumeric    1  )  )  )  )  )  )    sum )  )  )  \"  )  )  ,     (  \" return    [  1  ,     2  ,     3  ]  . stream (  )  . mapToInt (  ( def   x )     -  >     {  \\ n \"     +     (  \"       return   x    +     1  \\ n \"     +     \"  }  )  . sum (  )  \"  )  )  )  ;", "assertToString (  (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( PCallInvoke    ( PCallInvoke    ( EListInit    ( ENumeric    1  )     ( ENumeric    2  )     ( ENumeric    3  )  )    stream )     \"     +     (  \" mapToInt    ( Args    ( ELambda    ( Pair   null   x )  \\ n \"     +     \"        ( SReturn    ( EBinary    ( EVariable   x )     +     ( ENumeric    1  )  )  )  )  )  )    sum )  )  )  \"  )  )  ,     \" return    [  1  ,     2  ,     3  ]  . stream (  )  . mapToInt ( x    -  >    x    +     1  )  . sum (  )  \"  )  ;", "assertToString (  (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( EListInit    ( EString    \\  ' a \\  '  )     ( EString    \\  ' b \\  '  )  )    sort    ( Args    ( ELambda    ( Pair   def   a )     ( Pair   def   b )  \\ n \"     +     \"        ( SReturn    ( EBinary    ( PCallInvoke    ( EVariable   a )    length )     -     ( PCallInvoke    ( EVariable   b )    length )  )  )  )  )  )  )  )  \"  )  ,     (  \" return    [  \\  ' a \\  '  ,     \\  ' b \\  '  ]  . sort (  ( def   a ,    def   b )     -  >     {  \\ n \"     +     (  \"       return   a . length (  )     -    b . length (  )  \\ n \"     +     \"  }  )  \"  )  )  )  ;", "assertToString (  (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( EListInit    ( EString    \\  ' a \\  '  )     ( EString    \\  ' b \\  '  )  )    sort    ( Args    ( ELambda    ( Pair   null   a )     ( Pair   null   b )  \\ n \"     +     \"        ( SReturn    ( EBinary    ( PCallInvoke    ( EVariable   a )    length )     -     ( PCallInvoke    ( EVariable   b )    length )  )  )  )  )  )  )  )  \"  )  ,     \" return    [  ' a '  ,     ' b '  ]  . sort (  ( a ,    b )     -  >    a . length (  )     -    b . length (  )  )  \"  )  ;", "assertToString (  (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( EListInit    ( EString    \\  ' a \\  '  )     ( EString    \\  ' b \\  '  )  )    sort    ( Args    ( ELambda    ( Pair   def   a )     ( Pair   def   b )  \\ n \"     +     (  (  \"        ( SIf    ( EComp    ( EVariable   a )     <     ( EVariable   b )  )     ( SBlock    \"     +     \"  ( SReturn    ( EBinary    ( PCallInvoke    ( EVariable   a )    length )     -     ( PCallInvoke    ( EVariable   b )    length )  )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( ENumeric    1  )  )  )  )  )  )  )  \"  )  )  ,     (  \" return    [  \\  ' a \\  '  ,     \\  ' b \\  '  ]  . sort (  ( def   a ,    def   b )     -  >     {  \\ n \"     +     (  (  (  (  \"       if    ( a    <    b )     {  \\ n \"     +     \"             return   a . length (  )     -    b . length (  )  \\ n \"  )     +     \"        }  \\ n \"  )     +     \"       return    1  \\ n \"  )     +     \"  }  )  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testELambda"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EListInit    ( ENumeric    1  )     ( ENumeric    2  )     ( EString    ' cat '  )     ( EString    ' dog '  )     ( ENewObj   Object )  )  )  )  \"  ,     \" return    [  1  ,     2  ,     ' cat '  ,     ' dog '  ,    new   Object (  )  ]  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EListInit )  )  )  \"  ,     \" return    [  ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEListInit"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource    ( SReturn    ( EMapInit    \"     +     (  (  \"  ( Pair    ( EString    ' a '  )     ( ENumeric    1  )  )     \"     +     \"  ( Pair    ( EString    ' b '  )     ( ENumeric    3  )  )     \"  )     +     \"  ( Pair    ( ENumeric    1  2  )     ( ENewObj   Object )  )  )  )  )  \"  )  )  ,     \" return    [  ' a '  :     1  ,     ' b '  :     3  ,     1  2  :    new   Object (  )  ]  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EMapInit )  )  )  \"  ,     \" return    [  :  ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEMapInit"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( ENewArray   int   dims    ( Args    ( ENumeric    1  0  )  )  )  )  )  \"  ,     \" return   new   int [  1  0  ]  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENewArray   int   dims    ( Args    ( ENumeric    1  0  )     ( ENumeric    4  )     ( ENumeric    5  )  )  )  )  )  \"  ,     \" return   new   int [  1  0  ]  [  4  ]  [  5  ]  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENewArray   int   init    ( Args    ( ENumeric    1  )     ( ENumeric    2  )     ( ENumeric    3  )  )  )  )  )  \"  ,     \" return   new   int [  ]     {  1  ,     2  ,     3  }  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENewArray   def   init    ( Args    ( ENumeric    1  )     ( ENumeric    2  )     ( EString    ' bird '  )  )  )  )  )  \"  ,     \" return   new   def [  ]     {  1  ,     2  ,     ' bird '  }  \"  )  ;", "}", "METHOD_END"], "methodName": ["testENewArray"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( ENewObj   Object )  )  )  \"  ,     \" return   new   Object (  )  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENewObj   DateTimeException    ( Args    ( EString    ' test '  )  )  )  )  )  \"  ,     \" return   new   DateTimeException (  ' test '  )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testENewObj"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( ENull )  )  )  \"  ,     \" return   null \"  )  ;", "}", "METHOD_END"], "methodName": ["testENull"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    1  )  )  )  \"  ,     \" return    1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    1  1  4  1  2  1 d )  )  )  \"  ,     \" return    1  1  4  1  2  1 d \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    1  1  4  1  3  4 f )  )  )  \"  ,     \" return    1  1  4  1  3  4 f \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    1  1  4  1  2  1 D )  )  )  \"  ,     \" return    1  1  4  1  2  1 D \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    1  1  1  2  3  4 F )  )  )  \"  ,     \" return    1  1  1  2  3  4 F \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    7  7  4  1  2  1 l )  )  )  \"  ,     \" return    7  7  4  1  2  1 l \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    8  8  1  2  3  4 L )  )  )  \"  ,     \" return    8  8  1  2  3  4 L \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    1     1  6  )  )  )  \"  ,     \" return    0 x 1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    7  7  4  1  2  1 l    1  6  )  )  )  \"  ,     \" return    0 x 7  7  4  1  2  1 l \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    8  8  1  2  3  4 L    1  6  )  )  )  \"  ,     \" return    0 x 8  8  1  2  3  4 L \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    1     8  )  )  )  \"  ,     \" return    0  1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    7  7  4  1  2  1 l    8  )  )  )  \"  ,     \" return    0  7  7  4  1  2  1 l \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ENumeric    4  4  1  2  3  4 L    8  )  )  )  \"  ,     \" return    0  4  4  1  2  3  4 L \"  )  ;", "}", "METHOD_END"], "methodName": ["testENumeric"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( ERegex    / foo /  )  )  )  \"  ,     \" return    / foo /  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ERegex    / foo /    cix )  )  )  \"  ,     \" return    / foo / cix \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( ERegex    / foo /    cix )  )  )  \"  ,     \" return    / foo / xci \"  )  ;", "}", "METHOD_END"], "methodName": ["testERegex"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( EStatic   Optional )    empty )  )  )  \"  ,     \" return   Optional . empty (  )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEStatic"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EString    ' foo '  )  )  )  \"  ,     \" return    ' foo '  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EString    '    oo '  )  )  )  \"  ,     \" return    '    oo '  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EString    ' fo    '  )  )  )  \"  ,     \" return    ' fo    '  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EString    '    o    '  )  )  )  \"  ,     \" return    '    o    '  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEString"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EUnary    !     ( EBoolean   true )  )  )  )  \"  ,     \" return    ! true \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EUnary    ~     ( ENumeric    1  )  )  )  )  \"  ,     \" return    ~  1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EUnary    +     ( ENumeric    1  )  )  )  )  \"  ,     \" return    +  1  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( EUnary    -     ( ENumeric    1  )  )  )  )  \"  ,     \" return    -  (  1  )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEUnary"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( EVariable   params )  )  )  \"  ,     \" return   params \"  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   def   a    ( ENumeric    1  )  )  )  \\ n \"     +     \"        ( SReturn    ( EVariable   a )  )  )  \"  )  )  ,     (  \" def   a    =     1  ;  \\ n \"     +     \" return   a \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEVariable"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( PBrace    ( PField    ( EVariable   params )    a )     ( ENumeric    1  0  )  )  )  )  \"  ,     \" return   params . a [  1  0  ]  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( PBrace    ( EVariable   params )     ( EString    ' a '  )  )  )  )  \"  ,     \" return   params [  ' a '  ]  \"  )  ;", "}", "METHOD_END"], "methodName": ["testPBrace"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( EStatic   Optional )    empty )  )  )  \"  ,     \" return   Optional . empty (  )  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( EStatic   Optional )    of    ( Args    ( ENumeric    1  )  )  )  )  )  \"  ,     \" return   Optional . of (  1  )  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( EStatic   Objects )    equals    ( Args    ( ENumeric    1  )     ( ENumeric    2  )  )  )  )  )  \"  ,     \" return   Objects . equals (  1  ,     2  )  \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( PCallInvoke    ( EVariable   params )    equals    ( Args    ( ENumeric    1  )  )  )  )  )  \"  ,     \" return   params . equals (  1  )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testPCallInvoke"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SReturn    ( PField    ( EVariable   params )    a )  )  )  \"  ,     \" return   params . a \"  )  ;", "assertToString (  \"  ( SSource    ( SReturn    ( PField   nullSafe    ( EVariable   params )    a )  )  )  \"  ,     \" return   params ?  . a \"  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   int [  ]    a    ( ENewArray   int   dims    ( Args    ( ENumeric    1  0  )  )  )  )  )  \\ n \"     +     \"        ( SReturn    ( PField    ( EVariable   a )    length )  )  )  \"  )  )  ,     (  \" int [  ]    a    =    new   int [  1  0  ]  ;  \\ n \"     +     \" return   a . length \"  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  \"        ( SDeclBlock    ( SDeclaration   FeatureTest   a    ( ENewObj   FeatureTest )  )  )  \\ n \"     +     \"        ( SExpression    ( EAssignment    ( PField    ( EVariable   a )    x )     =     ( ENumeric    1  0  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( PField    ( EVariable   a )    x )  )  )  \"  )  )  ,     (  \" FeatureTest   a    =    new   FeatureTest (  )  ;  \\ n \"     +     (  \" a . x    =     1  0  ;  \\ n \"     +     \" return   a . x \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPField"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "PSubArrayLength   node    =    new   PSubArrayLength ( l ,     \" int \"  ,     \" a \"  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubArrayLength    ( EVariable   a )  )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeField    ( PSubArrayLength    ( EVariable   a )  )  )  \"  ,    new   PSubNullSafeField ( l ,    node )  . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubArrayLength"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "PSubBrace   node    =    new   PSubBrace ( l ,    int . class ,    new   ENumeric ( l ,     \"  1  \"  ,     1  0  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubBrace    ( EVariable   a )     ( ENumeric    1  )  )  \"  ,    node . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubBrace"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "Definition . Struct   c    =    definition . ClassToType ( Integer . class )  . struct ;", "Definition . Method   m    =    c . methods . get ( new   Definition . MethodKey (  \" t \"  ,     0  )  )  ;", "PSubCallInvoke   node    =    new   PSubCallInvoke ( l ,    m ,    null ,    Collections . emptyList (  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubCallInvoke    ( EVariable   a )    t )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubCallInvoke    ( EVariable   a )    t )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "l    =    new   Location ( getTestName (  )  ,     1  )  ;", "m    =    c . methods . get ( new   Definition . MethodKey (  \" equals \"  ,     1  )  )  ;", "node    =    new   PSubCallInvoke ( l ,    m ,    null ,    Collections . singletonList ( new   EVariable ( l ,     \" b \"  )  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubCallInvoke    ( EVariable   a )    equals    ( Args    ( EVariable   b )  )  )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubCallInvoke    ( EVariable   a )    equals    ( Args    ( EVariable   b )  )  )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubCallInvoke"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "PSubDefArray   node    =    new   PSubDefArray ( l ,    new   EConstant ( l ,     1  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubDefArray    ( EVariable   a )     ( EConstant   Integer    1  )  )  \"  ,    node . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubDefArray"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "PSubDefCall   node    =    new   PSubDefCall ( l ,     \" t \"  ,    Collections . emptyList (  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubDefCall    ( EVariable   a )    t )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubDefCall    ( EVariable   a )    t )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "l    =    new   Location ( getTestName (  )  ,     0  )  ;", "node    =    new   PSubDefCall ( l ,     \" equals \"  ,    Collections . singletonList ( new   EVariable ( l ,     \" b \"  )  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubDefCall    ( EVariable   a )    equals    ( Args    ( EVariable   b )  )  )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubDefCall    ( EVariable   a )    equals    ( Args    ( EVariable   b )  )  )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "l    =    new   Location ( getTestName (  )  ,     0  )  ;", "node    =    new   PSubDefCall ( l ,     \" superWeird \"  ,    Arrays . asList ( new   EVariable ( l ,     \" b \"  )  ,    new   EVariable ( l ,     \" c \"  )  ,    new   EVariable ( l ,     \" d \"  )  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubDefCall    ( EVariable   a )    superWeird    ( Args    ( EVariable   b )     ( EVariable   c )     ( EVariable   d )  )  )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubDefCall    ( EVariable   a )    superWeird    ( Args    ( EVariable   b )     ( EVariable   c )     ( EVariable   d )  )  )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubDefCall"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "PSubDefField   node    =    new   PSubDefField ( l ,     \" ok \"  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubDefField    ( EVariable   a )    ok )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubDefField    ( EVariable   a )    ok )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubDefField"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "Definition . Struct   s    =    definition . getType ( Boolean . class . getSimpleName (  )  )  . struct ;", "Definition . Field   f    =    s . staticMembers . get (  \" TRUE \"  )  ;", "PSubField   node    =    new   PSubField ( l ,    f )  ;", "node . prefix    =    new   EStatic ( l ,     \" Boolean \"  )  ;", "assertEquals (  \"  ( PSubField    ( EStatic   Boolean )    TRUE )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubField    ( EStatic   Boolean )    TRUE )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubField"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "Definition . Struct   s    =    definition . getType ( List . class . getSimpleName (  )  )  . struct ;", "PSubListShortcut   node    =    new   PSubListShortcut ( l ,    s ,    new   EConstant ( l ,     1  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubListShortcut    ( EVariable   a )     ( EConstant   Integer    1  )  )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubListShortcut    ( EVariable   a )     ( EConstant   Integer    1  )  )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "l    =    new   Location ( getTestName (  )  ,     0  )  ;", "s    =    definition . getType ( List . class . getSimpleName (  )  )  . struct ;", "node    =    new   PSubListShortcut ( l ,    s ,    new   EBinary ( l ,    Operation . ADD ,    new   EConstant ( l ,     1  )  ,    new   EConstant ( l ,     4  )  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubListShortcut    ( EVariable   a )     ( EBinary    ( EConstant   Integer    1  )     +     ( EConstant   Integer    4  )  )  )  \"  ,    node . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubListShortcut"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "Definition . Struct   s    =    definition . getType ( Map . class . getSimpleName (  )  )  . struct ;", "PSubMapShortcut   node    =    new   PSubMapShortcut ( l ,    s ,    new   EConstant ( l ,     \" cat \"  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubMapShortcut    ( EVariable   a )     ( EConstant   String    ' cat '  )  )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubMapShortcut    ( EVariable   a )     ( EConstant   String    ' cat '  )  )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "l    =    new   Location ( getTestName (  )  ,     1  )  ;", "s    =    definition . getType ( Map . class . getSimpleName (  )  )  . struct ;", "node    =    new   PSubMapShortcut ( l ,    s ,    new   EBinary ( l ,    Operation . ADD ,    new   EConstant ( l ,     1  )  ,    new   EConstant ( l ,     4  )  )  )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubMapShortcut    ( EVariable   a )     ( EBinary    ( EConstant   Integer    1  )     +     ( EConstant   Integer    4  )  )  )  \"  ,    node . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubMapShortcut"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "Definition . Struct   s    =    definition . getType ( FeatureTest . class . getName (  )  )  . struct ;", "Definition . Method   getter    =    s . methods . get ( new   Definition . MethodKey (  \" getX \"  ,     0  )  )  ;", "Definition . Method   setter    =    s . methods . get ( new   Definition . MethodKey (  \" setX \"  ,     1  )  )  ;", "PSubShortcut   node    =    new   PSubShortcut ( l ,     \" x \"  ,    FeatureTest . class . getName (  )  ,    getter ,    setter )  ;", "node . prefix    =    new   EVariable ( l ,     \" a \"  )  ;", "assertEquals (  \"  ( PSubShortcut    ( EVariable   a )    x )  \"  ,    node . t (  )  )  ;", "assertEquals (  \"  ( PSubNullSafeCallInvoke    ( PSubShortcut    ( EVariable   a )    x )  )  \"  ,    new   PSubNullSafeCallInvoke ( l ,    node )  . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testPSubShortcut"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  (  (  (  (  (  \"        ( SDeclBlock    ( SDeclaration   int   itr    ( ENumeric    2  )  )  )  \\ n \"     +     \"        ( SDeclBlock    ( SDeclaration   int   a    ( ENumeric    1  )  )  )  \\ n \"  )     +     \"        ( SDeclBlock    ( SDeclaration   int   b    ( ENumeric    1  )  )  )  \\ n \"  )     +     \"        ( SDo    ( EComp    ( EVariable   b )     <     ( ENumeric    1  0  0  0  )  )     ( SBlock \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   itr )     +  +    post )  )  \\ n \"  )     +     \"              ( SIf    ( EComp    ( EVariable   itr )     >     ( ENumeric    1  0  0  0  0  )  )     ( SBlock    ( SBreak )  )  )  \\ n \"  )     +     \"              ( SDeclBlock    ( SDeclaration   int   tmp    ( EVariable   a )  )  )  \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   a )     =     ( EVariable   b )  )  )  \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   b )     =     ( EBinary    ( EVariable   tmp )     +     ( EVariable   b )  )  )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   b )  )  )  \"  )  )  ,     (  \" int   itr    =     2  ;  \\ n \"     +     (  (  (  (  (  (  (  (  (  (  (  \" int   a    =     1  ;  \\ n \"     +     \" int   b    =     1  ;  \\ n \"  )     +     \" do    {  \\ n \"  )     +     \"       itr +  +  ;  \\ n \"  )     +     \"       if    ( itr    >     1  0  0  0  0  )     {  \\ n \"  )     +     \"             break \\ n \"  )     +     \"        }  \\ n \"  )     +     \"       int   tmp    =    a ;  \\ n \"  )     +     \"       a    =    b ;  \\ n \"  )     +     \"       b    =    tmp    +    b \\ n \"  )     +     \"  }    while    ( b    <     1  0  0  0  )  ;  \\ n \"  )     +     \" return   b \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSBreak"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  (  (  (  (  (  \"        ( SDeclBlock    ( SDeclaration   int   itr    ( ENumeric    2  )  )  )  \\ n \"     +     \"        ( SDeclBlock    ( SDeclaration   int   a    ( ENumeric    1  )  )  )  \\ n \"  )     +     \"        ( SDeclBlock    ( SDeclaration   int   b    ( ENumeric    1  )  )  )  \\ n \"  )     +     \"        ( SDo    ( EComp    ( EVariable   b )     <     ( ENumeric    1  0  0  0  )  )     ( SBlock \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   itr )     +  +    post )  )  \\ n \"  )     +     \"              ( SIf    ( EComp    ( EVariable   itr )     <     ( ENumeric    1  0  0  0  0  )  )     ( SBlock    ( SContinue )  )  )  \\ n \"  )     +     \"              ( SDeclBlock    ( SDeclaration   int   tmp    ( EVariable   a )  )  )  \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   a )     =     ( EVariable   b )  )  )  \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   b )     =     ( EBinary    ( EVariable   tmp )     +     ( EVariable   b )  )  )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   b )  )  )  \"  )  )  ,     (  \" int   itr    =     2  ;  \\ n \"     +     (  (  (  (  (  (  (  (  (  (  (  \" int   a    =     1  ;  \\ n \"     +     \" int   b    =     1  ;  \\ n \"  )     +     \" do    {  \\ n \"  )     +     \"       itr +  +  ;  \\ n \"  )     +     \"       if    ( itr    <     1  0  0  0  0  )     {  \\ n \"  )     +     \"             continue \\ n \"  )     +     \"        }  \\ n \"  )     +     \"       int   tmp    =    a ;  \\ n \"  )     +     \"       a    =    b ;  \\ n \"  )     +     \"       b    =    tmp    +    b \\ n \"  )     +     \"  }    while    ( b    <     1  0  0  0  )  ;  \\ n \"  )     +     \" return   b \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSContinue"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  \"        ( SDeclBlock    ( SDeclaration   def   a )  )  \\ n \"     +     \"        ( SExpression    ( EAssignment    ( EVariable   a )     =     ( ENumeric    1  0  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   a )  )  )  \"  )  )  ,     (  \" def   a ;  \\ n \"     +     (  \" a    =     1  0  ;  \\ n \"     +     \" return   a \"  )  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  \"        ( SDeclBlock    ( SDeclaration   def   a    ( ENumeric    1  0  )  )  )  \\ n \"     +     \"        ( SReturn    ( EVariable   a )  )  )  \"  )  )  ,     (  \" def   a    =     1  0  ;  \\ n \"     +     \" return   a \"  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  \"        ( SDeclBlock \\ n \"     +     \"              ( SDeclaration   def   a )  \\ n \"  )     +     \"              ( SDeclaration   def   b )  \\ n \"  )     +     \"              ( SDeclaration   def   c )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   a )  )  )  \"  )  )  ,     (  \" def   a ,    b ,    c ;  \\ n \"     +     \" return   a \"  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  \"        ( SDeclBlock \\ n \"     +     \"              ( SDeclaration   def   a    ( ENumeric    1  0  )  )  \\ n \"  )     +     \"              ( SDeclaration   def   b    ( ENumeric    2  0  )  )  \\ n \"  )     +     \"              ( SDeclaration   def   c    ( ENumeric    1  0  0  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   a )  )  )  \"  )  )  ,     (  \" def   a    =     1  0  ,    b    =     2  0  ,    c    =     1  0  0  ;  \\ n \"     +     \" return   a \"  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  \"        ( SDeclBlock \\ n \"     +     \"              ( SDeclaration   def   a    ( ENumeric    1  0  )  )  \\ n \"  )     +     \"              ( SDeclaration   def   b )  \\ n \"  )     +     \"              ( SDeclaration   def   c    ( ENumeric    1  0  0  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   a )  )  )  \"  )  )  ,     (  \" def   a    =     1  0  ,    b ,    c    =     1  0  0  ;  \\ n \"     +     \" return   a \"  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  (  (  \"        ( SIf    ( PField    ( EVariable   params )    a )     ( SBlock \\ n \"     +     \"              ( SDeclBlock \\ n \"  )     +     \"                    ( SDeclaration   def   a    ( ENumeric    1  0  )  )  \\ n \"  )     +     \"                    ( SDeclaration   def   b )  \\ n \"  )     +     \"                    ( SDeclaration   def   c    ( ENumeric    1  0  0  )  )  )  \\ n \"  )     +     \"              ( SReturn    ( EVariable   a )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EBoolean   false )  )  )  \"  )  )  ,     (  \" if    ( params . a )     {  \"     +     (  (  (  \"       def   a    =     1  0  ,    b ,    c    =     1  0  0  ;  \\ n \"     +     \"       return   a \\ n \"  )     +     \"  }  \\ n \"  )     +     \" return   false \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSDeclBlock"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  (  (  (  (  \"        ( SDeclBlock    ( SDeclaration   int   itr    ( ENumeric    2  )  )  )  \\ n \"     +     \"        ( SDeclBlock    ( SDeclaration   int   a    ( ENumeric    1  )  )  )  \\ n \"  )     +     \"        ( SDeclBlock    ( SDeclaration   int   b    ( ENumeric    1  )  )  )  \\ n \"  )     +     \"        ( SDo    ( EComp    ( EVariable   b )     <     ( ENumeric    1  0  0  0  )  )     ( SBlock \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   itr )     +  +    post )  )  \\ n \"  )     +     \"              ( SDeclBlock    ( SDeclaration   int   tmp    ( EVariable   a )  )  )  \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   a )     =     ( EVariable   b )  )  )  \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   b )     =     ( EBinary    ( EVariable   tmp )     +     ( EVariable   b )  )  )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   b )  )  )  \"  )  )  ,     (  \" int   itr    =     2  ;  \\ n \"     +     (  (  (  (  (  (  (  (  \" int   a    =     1  ;  \\ n \"     +     \" int   b    =     1  ;  \\ n \"  )     +     \" do    {  \\ n \"  )     +     \"       itr +  +  ;  \\ n \"  )     +     \"       int   tmp    =    a ;  \\ n \"  )     +     \"       a    =    b ;  \\ n \"  )     +     \"       b    =    tmp    +    b \\ n \"  )     +     \"  }    while    ( b    <     1  0  0  0  )  ;  \\ n \"  )     +     \" return   b \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSDo"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  \"        ( SDeclBlock    ( SDeclaration   int   l    ( ENumeric    0  )  )  )  \\ n \"     +     \"        ( SEach   String   s    ( EListInit    ( EString    ' cat '  )     ( EString    ' dog '  )     ( EString    ' chicken '  )  )     ( SBlock    \"  )     +     \"  ( SExpression    ( EAssignment    ( EVariable   l )     +  =     ( PCallInvoke    ( EVariable   s )    length )  )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   l )  )  )  \"  )  )  ,     (  \" int   l    =     0  ;  \\ n \"     +     (  (  (  \" for    ( String   s    :     [  \\  ' cat \\  '  ,     \\  ' dog \\  '  ,     \\  ' chicken \\  '  ]  )     {  \\ n \"     +     \"       l    +  =    s . length (  )  \\ n \"  )     +     \"  }  \\ n \"  )     +     \" return   l \"  )  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  \"        ( SDeclBlock    ( SDeclaration   int   l    ( ENumeric    0  )  )  )  \\ n \"     +     \"        ( SEach   String   s    ( EListInit    ( EString    \\  ' cat \\  '  )     ( EString    \\  ' dog \\  '  )     ( EString    \\  ' chicken \\  '  )  )     ( SBlock \\ n \"  )     +     \"              ( SDeclBlock    ( SDeclaration   String   s 2     ( EBinary    ( EString    \\  ' dire    \\  '  )     +     ( EVariable   s )  )  )  )  \\ n \"  )     +     \"              ( SExpression    ( EAssignment    ( EVariable   l )     +  =     ( PCallInvoke    ( EVariable   s 2  )    length )  )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   l )  )  )  \"  )  )  ,     (  \" int   l    =     0  ;  \\ n \"     +     (  (  (  (  \" for    ( String   s    :     [  \\  ' cat \\  '  ,     \\  ' dog \\  '  ,     \\  ' chicken \\  '  ]  )     {  \\ n \"     +     \"       String   s 2     =     \\  ' dire    \\  '     +    s ;  \\ n \"  )     +     \"       l    +  =    s 2  . length (  )  \\ n \"  )     +     \"  }  \\ n \"  )     +     \" return   l \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSEach"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  (  (  \"        ( SDeclBlock    ( SDeclaration   int   sum    ( ENumeric    0  )  )  )  \\ n \"     +     \"        ( SFor \\ n \"  )     +     \"              ( SDeclBlock    ( SDeclaration   int   i    ( ENumeric    0  )  )  )  \\ n \"  )     +     \"              ( EComp    ( EVariable   i )     <     ( ENumeric    1  0  0  0  )  )  \\ n \"  )     +     \"              ( EAssignment    ( EVariable   i )     +  +    post )  \\ n \"  )     +     \"              ( SBlock    ( SExpression    ( EAssignment    ( EVariable   sum )     +  =     ( EVariable   i )  )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   sum )  )  )  \"  )  )  ,     (  \" int   sum    =     0  ;  \\ n \"     +     (  (  (  \" for    ( int   i    =     0  ;    i    <     1  0  0  0  ;    i +  +  )     {  \\ n \"     +     \"       sum    +  =    i \\ n \"  )     +     \"  }  \\ n \"  )     +     \" return   sum \"  )  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  (  (  (  (  (  (  \"        ( SDeclBlock    ( SDeclaration   int   sum    ( ENumeric    0  )  )  )  \\ n \"     +     \"        ( SFor \\ n \"  )     +     \"              ( SDeclBlock    ( SDeclaration   int   i    ( ENumeric    0  )  )  )  \\ n \"  )     +     \"              ( EComp    ( EVariable   i )     <     ( ENumeric    1  0  0  0  )  )  \\ n \"  )     +     \"              ( EAssignment    ( EVariable   i )     +  +    post )  \\ n \"  )     +     \"              ( SBlock    ( SFor \\ n \"  )     +     \"                    ( SDeclBlock    ( SDeclaration   int   j    ( ENumeric    0  )  )  )  \\ n \"  )     +     \"                    ( EComp    ( EVariable   j )     <     ( ENumeric    1  0  0  0  )  )  \\ n \"  )     +     \"                    ( EAssignment    ( EVariable   j )     +  +    post )  \\ n \"  )     +     \"                    ( SBlock    ( SExpression    ( EAssignment    ( EVariable   sum )     +  =     ( EBinary    ( EVariable   i )     *     ( EVariable   j )  )  )  )  )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   sum )  )  )  \"  )  )  ,     (  \" int   sum    =     0  ;  \\ n \"     +     (  (  (  (  (  \" for    ( int   i    =     0  ;    i    <     1  0  0  0  ;    i +  +  )     {  \\ n \"     +     \"       for    ( int   j    =     0  ;    j    <     1  0  0  0  ;    j +  +  )     {  \\ n \"  )     +     \"             sum    +  =    i    *    j \\ n \"  )     +     \"        }  \\ n \"  )     +     \"  }  \\ n \"  )     +     \" return   sum \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSFor"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  \"        ( SFunction   def   a \\ n \"     +     \"              ( SReturn    ( EBoolean   true )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EBoolean   true )  )  )  \"  )  )  ,     (  \" def   a (  )     {  \\ n \"     +     (  (  \"       return   true \\ n \"     +     \"  }  \\ n \"  )     +     \" return   true \"  )  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  \"        ( SFunction   def   a    ( Args    ( Pair   int   i )     ( Pair   int   j )  )  \\ n \"     +     \"              ( SReturn    ( EBoolean   true )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EBoolean   true )  )  )  \"  )  )  ,     (  \" def   a ( int   i ,    int   j )     {  \\ n \"     +     (  (  \"       return   true \\ n \"     +     \"  }  \\ n \"  )     +     \" return   true \"  )  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  \"        ( SFunction   def   a    ( Args    ( Pair   int   i )     ( Pair   int   j )  )  \\ n \"     +     \"              ( SIf    ( EComp    ( EVariable   i )     <     ( EVariable   j )  )     ( SBlock    ( SReturn    ( EBoolean   true )  )  )  )  \\ n \"  )     +     \"              ( SDeclBlock    ( SDeclaration   int   k    ( EBinary    ( EVariable   i )     +     ( EVariable   j )  )  )  )  \\ n \"  )     +     \"              ( SReturn    ( EVariable   k )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EBoolean   true )  )  )  \"  )  )  ,     (  \" def   a ( int   i ,    int   j )     {  \\ n \"     +     (  (  (  (  (  (  \"       if    ( i    <    j )     {  \\ n \"     +     \"             return   true \\ n \"  )     +     \"        }  \\ n \"  )     +     \"       int   k    =    i    +    j ;  \\ n \"  )     +     \"       return   k \\ n \"  )     +     \"  }  \\ n \"  )     +     \" return   true \"  )  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  \"        ( SFunction   def   a \\ n \"     +     \"              ( SReturn    ( EBoolean   true )  )  )  \\ n \"  )     +     \"        ( SFunction   def   b \\ n \"  )     +     \"              ( SReturn    ( EBoolean   false )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EBoolean   true )  )  )  \"  )  )  ,     (  \" def   a (  )     {  \\ n \"     +     (  (  (  (  (  \"       return   true \\ n \"     +     \"  }  \\ n \"  )     +     \" def   b (  )     {  \\ n \"  )     +     \"       return   false \\ n \"  )     +     \"  }  \\ n \"  )     +     \" return   true \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSFunction"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SIf    ( PField    ( EVariable   param )    a )     ( SBlock    ( SReturn    ( EBoolean   true )  )  )  )  )  \"  ,     (  \" if    ( param . a )     {  \\ n \"     +     (  \"       return   true \\ n \"     +     \"  }  \"  )  )  )  ;", "assertToString (  (  \"  ( SSource    ( SIf    ( PField    ( EVariable   param )    a )     ( SBlock \\ n \"     +     (  \"        ( SIf    ( PField    ( EVariable   param )    b )     ( SBlock    ( SReturn    ( EBoolean   true )  )  )  )  \\ n \"     +     \"        ( SReturn    ( EBoolean   false )  )  )  )  )  \"  )  )  ,     (  \" if    ( param . a )     {  \\ n \"     +     (  (  (  (  \"       if    ( param . b )     {  \\ n \"     +     \"             return   true \\ n \"  )     +     \"        }  \\ n \"  )     +     \"       return   false \\ n \"  )     +     \"  }  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSIf"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource    ( SIfElse    ( PField    ( EVariable   param )    a )  \\ n \"     +     (  \"        ( SBlock    ( SReturn    ( EBoolean   true )  )  )  \\ n \"     +     \"        ( SBlock    ( SReturn    ( EBoolean   false )  )  )  )  )  \"  )  )  ,     (  \" if    ( param . a )     {  \\ n \"     +     (  (  (  \"       return   true \\ n \"     +     \"  }    else    {  \\ n \"  )     +     \"       return   false \\ n \"  )     +     \"  }  \"  )  )  )  ;", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  (  (  (  \"        ( SDeclBlock    ( SDeclaration   int   i    ( ENumeric    0  )  )  )  \\ n \"     +     \"        ( SIfElse    ( PField    ( EVariable   param )    a )  \\ n \"  )     +     \"              ( SBlock    ( SIfElse    ( PField    ( EVariable   param )    b )  \\ n \"  )     +     \"                    ( SBlock    ( SReturn    ( EBoolean   true )  )  )  \\ n \"  )     +     \"                    ( SBlock    ( SReturn    ( EString    \\  ' cat \\  '  )  )  )  )  )  \\ n \"  )     +     \"              ( SBlock    ( SReturn    ( EBoolean   false )  )  )  )  )  \"  )  )  ,     (  \" int   i    =     0  ;  \\ n \"     +     (  (  (  (  (  (  (  (  \" if    ( param . a )     {  \\ n \"     +     \"       if    ( param . b )     {  \\ n \"  )     +     \"             return   true \\ n \"  )     +     \"        }    else    {  \\ n \"  )     +     \"             return    \\  ' cat \\  '  \\ n \"  )     +     \"        }  \\ n \"  )     +     \"  }    else    {  \"  )     +     \"       return   false \\ n \"  )     +     \"  }  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSIfElse"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "Locals . Variable   v    =    new   Locals . Variable ( l ,     \" test \"  ,    int . class ,     5  ,    false )  ;", "AExpression   e    =    new   ENewArray ( l ,     \" int \"  ,    Arrays . asList ( new   EConstant ( l ,     1  )  ,    new   EConstant ( l ,     2  )  ,    new   EConstant ( l ,     3  )  )  ,    true )  ;", "SBlock   b    =    new   SBlock ( l ,    Collections . singletonList ( new   SReturn ( l ,    new   EConstant ( l ,     5  )  )  )  )  ;", "SSubEachArray   node    =    new   SSubEachArray ( l ,    v ,    e ,    b )  ;", "assertEquals (  (  \"  ( SSubEachArray   int   test    ( ENewArray   int   init    ( Args    ( EConstant   Integer    1  )     ( EConstant   Integer    2  )     ( EConstant   Integer    3  )  )  )     \"     +     \"  ( SBlock    ( SReturn    ( EConstant   Integer    5  )  )  )  )  \"  )  ,    node . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testSSubEachArray"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "Location   l    =    new   Location ( getTestName (  )  ,     0  )  ;", "Locals . Variable   v    =    new   Locals . Variable ( l ,     \" test \"  ,    int . class ,     5  ,    false )  ;", "AExpression   e    =    new   EListInit ( l ,    Arrays . asList ( new   EConstant ( l ,     1  )  ,    new   EConstant ( l ,     2  )  ,    new   EConstant ( l ,     3  )  )  )  ;", "SBlock   b    =    new   SBlock ( l ,    Collections . singletonList ( new   SReturn ( l ,    new   EConstant ( l ,     5  )  )  )  )  ;", "SSubEachIterable   node    =    new   SSubEachIterable ( l ,    v ,    e ,    b )  ;", "assertEquals (  (  \"  ( SSubEachIterable   int   test    ( EListInit    ( EConstant   Integer    1  )     ( EConstant   Integer    2  )     ( EConstant   Integer    3  )  )     ( SBlock    \"     +     \"  ( SReturn    ( EConstant   Integer    5  )  )  )  )  \"  )  ,    node . t (  )  )  ;", "}", "METHOD_END"], "methodName": ["testSSubEachIterable"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  \"  ( SSource    ( SThrow    ( ENewObj   RuntimeException )  )  )  \"  ,     \" throw   new   RuntimeException (  )  \"  )  ;", "}", "METHOD_END"], "methodName": ["testSThrow"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource    ( STry    ( SBlock    ( SReturn    ( ENumeric    1  )  )  )  \\ n \"     +     \"        ( SCatch   Exception   e    ( SBlock    ( SReturn    ( ENumeric    2  )  )  )  )  )  )  \"  )  ,     (  \" try    {  \\ n \"     +     (  (  (  \"       return    1  \\ n \"     +     \"  }    catch    ( Exception   e )     {  \\ n \"  )     +     \"       return    2  \\ n \"  )     +     \"  }  \"  )  )  )  ;", "assertToString (  (  \"  ( SSource    ( STry    ( SBlock \\ n \"     +     (  (  \"        ( SDeclBlock    ( SDeclaration   int   i    ( ENumeric    1  )  )  )  \\ n \"     +     \"        ( SReturn    ( ENumeric    1  )  )  )  \\ n \"  )     +     \"        ( SCatch   Exception   e    ( SBlock    ( SReturn    ( ENumeric    2  )  )  )  )  )  )  \"  )  )  ,     (  \" try    {  \\ n \"     +     (  (  (  (  \"       int   i    =     1  ;  \"     +     \"       return    1  \\ n \"  )     +     \"  }    catch    ( Exception   e )     {  \\ n \"  )     +     \"       return    2  \\ n \"  )     +     \"  }  \"  )  )  )  ;", "assertToString (  (  \"  ( SSource    ( STry    ( SBlock    ( SReturn    ( ENumeric    1  )  )  )  \\ n \"     +     (  (  \"        ( SCatch   Exception   e    ( SBlock \\ n \"     +     \"              ( SDeclBlock    ( SDeclaration   int   i    ( ENumeric    1  )  )  )  \\ n \"  )     +     \"              ( SReturn    ( ENumeric    2  )  )  )  )  )  )  \"  )  )  ,     (  \" try    {  \\ n \"     +     (  (  (  (  \"       return    1  \\ n \"     +     \"  }    catch    ( Exception   e )     {  \"  )     +     \"       int   i    =     1  ;  \\ n \"  )     +     \"       return    2  \\ n \"  )     +     \"  }  \"  )  )  )  ;", "assertToString (  (  \"  ( SSource    ( STry    ( SBlock    ( SReturn    ( ENumeric    1  )  )  )  \\ n \"     +     (  \"        ( SCatch   NullPointerException   e    ( SBlock    ( SReturn    ( ENumeric    2  )  )  )  )  \\ n \"     +     \"        ( SCatch   Exception   e    ( SBlock    ( SReturn    ( ENumeric    3  )  )  )  )  )  )  \"  )  )  ,     (  \" try    {  \\ n \"     +     (  (  (  (  (  \"       return    1  \\ n \"     +     \"  }    catch    ( NullPointerException   e )     {  \\ n \"  )     +     \"       return    2  \\ n \"  )     +     \"  }    catch    ( Exception   e )     {  \\ n \"  )     +     \"       return    3  \\ n \"  )     +     \"  }  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSTryAndSCatch"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "assertToString (  (  \"  ( SSource \\ n \"     +     (  (  \"        ( SDeclBlock    ( SDeclaration   int   i    ( ENumeric    0  )  )  )  \\ n \"     +     \"        ( SWhile    ( EComp    ( EVariable   i )     <     ( ENumeric    1  0  )  )     ( SBlock    ( SExpression    ( EAssignment    ( EVariable   i )     +  +    post )  )  )  )  \\ n \"  )     +     \"        ( SReturn    ( EVariable   i )  )  )  \"  )  )  ,     (  \" int   i    =     0  ;  \\ n \"     +     (  (  (  \" while    ( i    <     1  0  )     {  \\ n \"     +     \"       i +  +  \\ n \"  )     +     \"  }  \\ n \"  )     +     \" return   i \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testSWhile"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "ScriptClassInfo   scriptClassInfo    =    new   ScriptClassInfo ( definition ,    GenericElasticsearchScript . class )  ;", "CompilerSettings   compilerSettings    =    new   CompilerSettings (  )  ;", "compilerSettings . setRegexesEnabled ( true )  ;", "try    {", "return   Walker . buildPainlessTree ( scriptClassInfo ,    new   SSource . MainMethodReserved (  )  ,    getTestName (  )  ,    code ,    compilerSettings ,    definition ,    null )  ;", "}    catch    ( Exception   e )     {", "throw   new   AssertionError (  (  \" Failed   to   compile :     \"     +    code )  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["walk"], "fileName": "org.elasticsearch.painless.node.NodeToStringTests"}, {"methodBody": ["METHOD_START", "{", "try    {", "rtnType    =    Definition . TypeToClass ( definition . getType ( rtnTypeStr )  )  ;", "}    catch    ( IllegalArgumentException   exception )     {", "throw   createError ( new   IllegalArgumentException (  (  (  (  (  \" Illegal   return   type    [  \"     +     ( rtnTypeStr )  )     +     \"  ]    for   f    [  \"  )     +     ( name )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "if    (  ( paramTypeStrs . size (  )  )     !  =     ( paramNameStrs . size (  )  )  )     {", "throw   createError ( new   IllegalStateException (  \" Illegal   tree   structure .  \"  )  )  ;", "}", "Class <  ?  >  [  ]    paramClasses    =    new   Class <  ?  >  [ this . paramTypeStrs . size (  )  ]  ;", "List < Class <  ?  >  >    paramTypes    =    new   ArrayList <  >  (  )  ;", "for    ( int   param    =     0  ;    param    <     ( this . paramTypeStrs . size (  )  )  ;     +  + param )     {", "try    {", "Class <  ?  >    paramType    =    Definition . TypeToClass ( definition . getType ( this . paramTypeStrs . get ( param )  )  )  ;", "paramClasses [ param ]     =    Definition . defClassToObjectClass ( paramType )  ;", "paramTypes . add ( paramType )  ;", "parameters . add ( new   Locals . Parameter ( location ,    paramNameStrs . get ( param )  ,    paramType )  )  ;", "}    catch    ( IllegalArgumentException   exception )     {", "throw   createError ( new   IllegalArgumentException (  (  (  (  (  \" Illegal   parameter   type    [  \"     +     ( this . paramTypeStrs . get ( param )  )  )     +     \"  ]    for   f    [  \"  )     +     ( name )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "}", "Method   method    =    new   Method ( name ,    MethodType . methodType ( Definition . defClassToObjectClass ( rtnType )  ,    paramClasses )  . toMethodDescriptorString (  )  )  ;", "this . method    =    new   Definition . Method ( name ,    null ,    null ,    rtnType ,    paramTypes ,    method ,     (  ( Modifier . STATIC )     |     ( Modifier . PRIVATE )  )  ,    null )  ;", "}", "METHOD_END"], "methodName": ["generateSignature"], "fileName": "org.elasticsearch.painless.node.SFunction"}, {"methodBody": ["METHOD_START", "{", "final   Handle   handle    =    new   Handle ( Opcodes . H _ INVOKESTATIC ,    WriterConstants . CLASS _ TYPE . getInternalName (  )  ,    name ,    method . method . getDescriptor (  )  ,    false )  ;", "writer . push ( handle )  ;", "}", "METHOD_END"], "methodName": ["initializeConstant"], "fileName": "org.elasticsearch.painless.node.SFunction"}, {"methodBody": ["METHOD_START", "{", "int   access    =     ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ STATIC )  ;", "if    ( synthetic )     {", "access    |  =    Opcodes . ACC _ SYNTHETIC ;", "}", "final   MethodWriter   f    =    new   MethodWriter ( access ,    method . method ,    writer ,    globals . getStatements (  )  ,    settings )  ;", "f . visitCode (  )  ;", "write ( f ,    globals )  ;", "f . endMethod (  )  ;", "}", "METHOD_END"], "methodName": ["write"], "fileName": "org.elasticsearch.painless.node.SFunction"}, {"methodBody": ["METHOD_START", "{", "Map < Definition . MethodKey ,    Definition . Method >    methods    =    new   HashMap <  >  (  )  ;", "for    ( SFunction   function    :    functions )     {", "function . generateSignature ( definition )  ;", "Definition . MethodKey   key    =    new   Definition . MethodKey ( function . name ,    functionrameters . size (  )  )  ;", "if    (  ( methods . put ( key ,    function . method )  )     !  =    null )     {", "throw   createError ( new   IllegalArgumentException (  (  (  \" Duplicate   functions   with   name    [  \"     +     ( function . name )  )     +     \"  ]  .  \"  )  )  )  ;", "}", "}", "analyze ( Locals . newProgramScope ( definition ,    methods . values (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["analyze"], "fileName": "org.elasticsearch.painless.node.SSource"}, {"methodBody": ["METHOD_START", "{", "return   bytes ;", "}", "METHOD_END"], "methodName": ["getBytes"], "fileName": "org.elasticsearch.painless.node.SSource"}, {"methodBody": ["METHOD_START", "{", "return   globals . getStatements (  )  ;", "}", "METHOD_END"], "methodName": ["getStatements"], "fileName": "org.elasticsearch.painless.node.SSource"}, {"methodBody": ["METHOD_START", "{", "int   classFrames    =     ( ClassWriter . COMPUTE _ FRAMES )     |     ( ClassWriter . COMPUTE _ MAXS )  ;", "int   classAccess    =     (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ SUPER )  )     |     ( Opcodes . ACC _ FINAL )  ;", "String   interfaceBase    =    WriterConstants . BASE _ INTERFACE _ TYPE . getInternalName (  )  ;", "String   className    =    WriterConstants . CLASS _ TYPE . getInternalName (  )  ;", "String [  ]    classInterfaces    =    new   String [  ]  {    interfaceBase    }  ;", "ClassWriter   writer    =    new   ClassWriter ( classFrames )  ;", "ClassVisitor   visitor    =    writer ;", "if    ( settings . isPicky (  )  )     {", "visitor    =    new   SimpleChecksAdapter ( visitor )  ;", "}", "if    (  ( debugStream )     !  =    null )     {", "visitor    =    new   TraceClassVisitor ( visitor ,    debugStream ,    null )  ;", "}", "visitor . visit ( WriterConstants . CLASS _ VERSION ,    classAccess ,    className ,    null ,    Type . getType ( scriptClassInfo . getBaseClass (  )  )  . getInternalName (  )  ,    classInterfaces )  ;", "visitor . visit ( Location . computeName ( name )  ,    null )  ;", "MethodWriter   bootstrapDef    =    new   MethodWriter (  (  ( Opcodes . ACC _ STATIC )     |     ( Opcodes . ACC _ VARARGS )  )  ,    WriterConstants . DEF _ BOOTSTRAP _ METHOD ,    visitor ,    globals . getStatements (  )  ,    settings )  ;", "bootstrapDef . visitCode (  )  ;", "bootstrapDef . getStatic ( WriterConstants . CLASS _ TYPE ,     \"  $ DEFINITION \"  ,    WriterConstants . DEFINITION _ TYPE )  ;", "bootstrapDef . loadArgs (  )  ;", "bootstrapDef . invokeStatic ( WriterConstants . DEF _ BOOTSTRAP _ DELEGATE _ TYPE ,    WriterConstants . DEF _ BOOTSTRAP _ DELEGATE _ METHOD )  ;", "bootstrapDef . returnValue (  )  ;", "bootstrapDef . endMethod (  )  ;", "visitor . visitField (  (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ STATIC )  )  ,     \"  $ NAME \"  ,    WriterConstants . STRING _ TYPE . getDescriptor (  )  ,    null ,    null )  . visitEnd (  )  ;", "visitor . visitField (  (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ STATIC )  )  ,     \"  $ SOURCE \"  ,    WriterConstants . STRING _ TYPE . getDescriptor (  )  ,    null ,    null )  . visitEnd (  )  ;", "visitor . visitField (  (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ STATIC )  )  ,     \"  $ STATEMENTS \"  ,    WriterConstants . BITSET _ TYPE . getDescriptor (  )  ,    null ,    null )  . visitEnd (  )  ;", "visitor . visitField (  (  ( Opcodes . ACC _ PUBLIC )     |     ( Opcodes . ACC _ STATIC )  )  ,     \"  $ DEFINITION \"  ,    WriterConstants . DEFINITION _ TYPE . getDescriptor (  )  ,    null ,    null )  . visitEnd (  )  ;", "Method   init ;", "if    (  ( scriptClassInfo . getBaseClass (  )  . getConstructors (  )  . length )     =  =     0  )     {", "init    =    new   Method (  \"  < init >  \"  ,    MethodType . methodType ( void . class )  . toMethodDescriptorString (  )  )  ;", "} else    {", "init    =    new   Method (  \"  < init >  \"  ,    MethodType . methodType ( void . class ,    scriptClassInfo . getBaseClass (  )  . getConstructors (  )  [  0  ]  . getParameterTypes (  )  )  . toMethodDescriptorString (  )  )  ;", "}", "MethodWriter   constructor    =    new   MethodWriter ( Opcodes . ACC _ PUBLIC ,    init ,    visitor ,    globals . getStatements (  )  ,    settings )  ;", "constructor . visitCode (  )  ;", "constructor . loadThis (  )  ;", "constructor . loadArgs (  )  ;", "constructor . invokeConstructor ( Type . getType ( scriptClassInfo . getBaseClass (  )  )  ,    init )  ;", "constructor . returnValue (  )  ;", "constructor . endMethod (  )  ;", "MethodWriter   nameMethod    =    new   MethodWriter ( Opcodes . ACC _ PUBLIC ,    WriterConstants . GET _ NAME _ METHOD ,    visitor ,    globals . getStatements (  )  ,    settings )  ;", "nameMethod . visitCode (  )  ;", "nameMethod . getStatic ( WriterConstants . CLASS _ TYPE ,     \"  $ NAME \"  ,    WriterConstants . STRING _ TYPE )  ;", "nameMethod . returnValue (  )  ;", "nameMethod . endMethod (  )  ;", "MethodWriter   sourceMethod    =    new   MethodWriter ( Opcodes . ACC _ PUBLIC ,    WriterConstants . GET _ SOURCE _ METHOD ,    visitor ,    globals . getStatements (  )  ,    settings )  ;", "sourceMethod . visitCode (  )  ;", "sourceMethod . getStatic ( WriterConstants . CLASS _ TYPE ,     \"  $ SOURCE \"  ,    WriterConstants . STRING _ TYPE )  ;", "sourceMethod . returnValue (  )  ;", "sourceMethod . endMethod (  )  ;", "MethodWriter   statementsMethod    =    new   MethodWriter ( Opcodes . ACC _ PUBLIC ,    WriterConstants . GET _ STATEMENTS _ METHOD ,    visitor ,    globals . getStatements (  )  ,    settings )  ;", "statementsMethod . visitCode (  )  ;", "statementsMethod . getStatic ( WriterConstants . CLASS _ TYPE ,     \"  $ STATEMENTS \"  ,    WriterConstants . BITSET _ TYPE )  ;", "statementsMethod . returnValue (  )  ;", "statementsMethod . endMethod (  )  ;", "MethodWriter   executeMethod    =    new   MethodWriter ( Opcodes . ACC _ PUBLIC ,    scriptClassInfo . getExecuteMethod (  )  ,    visitor ,    globals . getStatements (  )  ,    settings )  ;", "executeMethod . visitCode (  )  ;", "write ( executeMethod ,    globals )  ;", "executeMethod . endMethod (  )  ;", "for    ( SFunction   function    :    functions )     {", "function . write ( visitor ,    settings ,    globals )  ;", "}", "while    (  !  ( globals . getSyntheticMethods (  )  . isEmpty (  )  )  )     {", "List < SFunction >    current    =    new   ArrayList <  >  ( globals . getSyntheticMethods (  )  . values (  )  )  ;", "globals . getSyntheticMethods (  )  . clear (  )  ;", "for    ( SFunction   function    :    current )     {", "function . write ( visitor ,    settings ,    globals )  ;", "}", "}", "if    ( false    =  =     ( globals . getConstantInitializers (  )  . isEmpty (  )  )  )     {", "Collection < Constant >    inits    =    globals . getConstantInitializers (  )  . values (  )  ;", "for    ( Constant   constant    :    inits )     {", "visitor . visitField (  (  (  ( Opcodes . ACC _ FINAL )     |     ( Opcodes . ACC _ PRIVATE )  )     |     ( Opcodes . ACC _ STATIC )  )  ,    constant . name ,    constant . type . getDescriptor (  )  ,    null ,    null )  . visitEnd (  )  ;", "}", "final   MethodWriter   clinit    =    new   MethodWriter ( Opcodes . ACC _ STATIC ,    WriterConstants . CLINIT ,    visitor ,    globals . getStatements (  )  ,    settings )  ;", "clinit . visitCode (  )  ;", "for    ( Constant   constant    :    inits )     {", "constant . initializer . accept ( clinit )  ;", "clinit . putStatic ( WriterConstants . CLASS _ TYPE ,    constant . name ,    constant . type )  ;", "}", "clinit . returnValue (  )  ;", "clinit . endMethod (  )  ;", "}", "for    ( Method   needsMethod    :    scriptClassInfo . getNeedsMethods (  )  )     {", "String   name    =    needsMethod . getName (  )  ;", "name    =    name . substring (  5  )  ;", "name    =     ( Character . toLowerCase ( name . charAt (  0  )  )  )     +     ( name . substring (  1  )  )  ;", "MethodWriter   ifaceMethod    =    new   MethodWriter ( Opcodes . ACC _ PUBLIC ,    needsMethod ,    visitor ,    globals . getStatements (  )  ,    settings )  ;", "ifaceMethod . visitCode (  )  ;", "ifaceMethod . push ( reserved . getUsedVariables (  )  . contains ( name )  )  ;", "ifaceMethod . returnValue (  )  ;", "ifaceMethod . endMethod (  )  ;", "}", "visitor . visitEnd (  )  ;", "bytes    =    writer . toByteArray (  )  ;", "}", "METHOD_END"], "methodName": ["write"], "fileName": "org.elasticsearch.painless.node.SSource"}, {"methodBody": ["METHOD_START", "{", "List < Whitelist . Struct >    whitelistStructs    =    new   ArrayList <  >  (  )  ;", "for    ( String   filepath    :    filepaths )     {", "String   line ;", "int   number    =     -  1  ;", "try    ( LineNumberReader   reader    =    new   LineNumberReader ( new   InputStreamReader ( resource . getResourceAsStream ( filepath )  ,    StandardCharsets . UTF _  8  )  )  )     {", "String   whitelistStructOrigin    =    null ;", "String   javaClassName    =    null ;", "boolean   onlyFQNJavaClassName    =    false ;", "List < Whitelist . Constructor >    whitelistConstructors    =    null ;", "List < Whitelist . Method >    whitelistMethods    =    null ;", "List < Whitelist . Field >    whitelistFields    =    null ;", "while    (  ( line    =    reader . readLine (  )  )     !  =    null )     {", "number    =    reader . getLineNumber (  )  ;", "line    =    line . trim (  )  ;", "if    (  (  ( line . length (  )  )     =  =     0  )     |  |     (  ( line . charAt (  0  )  )     =  =     '  #  '  )  )     {", "continue ;", "}", "if    ( line . startsWith (  \" class    \"  )  )     {", "if    (  ( line . endsWith (  \"  {  \"  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  \" invalid   struct   definition :    failed   to   parse   class   opening   bracket    [  \"     +    line )     +     \"  ]  \"  )  )  ;", "}", "String [  ]    tokens    =    line . substring (  5  ,     (  ( line . length (  )  )     -     1  )  )  . trim (  )  . split (  \"  \\  \\ s +  \"  )  ;", "if    (  (  ( tokens . length )     =  =     2  )     &  &     (  \" only _ fqn \"  . equals ( tokens [  1  ]  )  )  )     {", "onlyFQNJavaClassName    =    true ;", "} else", "if    (  ( tokens . length )     !  =     1  )     {", "throw   new   IllegalArgumentException (  (  (  \" invalid   struct   definition :    failed   to   parse   class   name    [  \"     +    line )     +     \"  ]  \"  )  )  ;", "}", "whitelistStructOrigin    =     (  (  (  \"  [  \"     +    filepath )     +     \"  ]  :  [  \"  )     +    number )     +     \"  ]  \"  ;", "javaClassName    =    tokens [  0  ]  ;", "whitelistConstructors    =    new   ArrayList <  >  (  )  ;", "whitelistMethods    =    new   ArrayList <  >  (  )  ;", "whitelistFields    =    new   ArrayList <  >  (  )  ;", "} else", "if    ( line . equals (  \"  }  \"  )  )     {", "if    ( javaClassName    =  =    null )     {", "throw   new   IllegalArgumentException (  \" invalid   struct   definition :    extraneous   closing   bracket \"  )  ;", "}", "whitelistStructs . add ( new   Whitelist . Struct ( whitelistStructOrigin ,    javaClassName ,    onlyFQNJavaClassName ,    whitelistConstructors ,    whitelistMethods ,    whitelistFields )  )  ;", "whitelistStructOrigin    =    null ;", "javaClassName    =    null ;", "onlyFQNJavaClassName    =    false ;", "whitelistConstructors    =    null ;", "whitelistMethods    =    null ;", "whitelistFields    =    null ;", "} else    {", "String   origin    =     (  (  (  \"  [  \"     +    filepath )     +     \"  ]  :  [  \"  )     +    number )     +     \"  ]  \"  ;", "if    ( javaClassName    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  \" invalid   object   definition :    expected   a   class   name    [  \"     +    line )     +     \"  ]  \"  )  )  ;", "}", "if    ( line . startsWith (  \"  (  \"  )  )     {", "if    (  ( line . endsWith (  \"  )  \"  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  \" invalid   constructor   definition :    expected   a   closing   parenthesis    [  \"     +    line )     +     \"  ]  \"  )  )  ;", "}", "String [  ]    tokens    =    line . substring (  1  ,     (  ( line . length (  )  )     -     1  )  )  . replaceAll (  \"  \\  \\ s +  \"  ,     \"  \"  )  . split (  \"  ,  \"  )  ;", "if    (  \"  \"  . equals ( tokens [  0  ]  )  )     {", "tokens    =    new   String [  0  ]  ;", "}", "whitelistConstructors . add ( new   Whitelist . Constructor ( origin ,    asList ( tokens )  )  )  ;", "} else", "if    ( line . contains (  \"  (  \"  )  )     {", "if    (  ( line . endsWith (  \"  )  \"  )  )     =  =    false )     {", "throw   new   IllegalArgumentException (  (  (  \" invalid   method   definition :    expected   a   closing   parenthesis    [  \"     +    line )     +     \"  ]  \"  )  )  ;", "}", "int   parameterIndex    =    line . indexOf (  '  (  '  )  ;", "String [  ]    tokens    =    line . trim (  )  . substring (  0  ,    parameterIndex )  . split (  \"  \\  \\ s +  \"  )  ;", "String   javaMethodName ;", "String   javaAugmentedClassName ;", "if    (  ( tokens . length )     =  =     2  )     {", "javaMethodName    =    tokens [  1  ]  ;", "javaAugmentedClassName    =    null ;", "} else", "if    (  ( tokens . length )     =  =     3  )     {", "javaMethodName    =    tokens [  2  ]  ;", "javaAugmentedClassName    =    tokens [  1  ]  ;", "} else    {", "throw   new   IllegalArgumentException (  (  (  \" invalid   method   definition :    unexpected   format    [  \"     +    line )     +     \"  ]  \"  )  )  ;", "}", "String   painlessReturnTypeName    =    tokens [  0  ]  ;", "tokens    =    line . substring (  ( parameterIndex    +     1  )  ,     (  ( line . length (  )  )     -     1  )  )  . replaceAll (  \"  \\  \\ s +  \"  ,     \"  \"  )  . split (  \"  ,  \"  )  ;", "if    (  \"  \"  . equals ( tokens [  0  ]  )  )     {", "tokens    =    new   String [  0  ]  ;", "}", "whitelistMethods . add ( new   Whitelist . Method ( origin ,    javaAugmentedClassName ,    javaMethodName ,    painlessReturnTypeName ,    asList ( tokens )  )  )  ;", "} else    {", "String [  ]    tokens    =    line . split (  \"  \\  \\ s +  \"  )  ;", "if    (  ( tokens . length )     !  =     2  )     {", "throw   new   IllegalArgumentException (  (  (  \" invalid   field   definition :    unexpected   format    [  \"     +    line )     +     \"  ]  \"  )  )  ;", "}", "whitelistFields . add ( new   Whitelist . Field ( origin ,    tokens [  1  ]  ,    tokens [  0  ]  )  )  ;", "}", "}", "}", "if    ( javaClassName    !  =    null )     {", "throw   new   IllegalArgumentException (  \" invalid   struct   definition :    expected   closing   bracket \"  )  ;", "}", "}    catch    ( Exception   exception )     {", "throw   new   RuntimeException (  (  (  (  (  \" error   in    [  \"     +    filepath )     +     \"  ]    at   line    [  \"  )     +    number )     +     \"  ]  \"  )  ,    exception )  ;", "}", "}", "ClassLoader   loader    =    AccessController . doPrivileged (  (  ( PrivilegedAction < ClassLoader >  )     ( resource :  : getClassLoader )  )  )  ;", "return   new   Whitelist ( loader ,    whitelistStructs )  ;", "}", "METHOD_END"], "methodName": ["loadFromResourceFiles"], "fileName": "org.elasticsearch.painless.spi.WhitelistLoader"}, {"methodBody": ["METHOD_START", "{", "ParseContext . InternalParseContext   parseContext    =    new   ParseContext . InternalParseContext ( Settings . EMPTY ,    mapperService . documentMapperParser (  )  ,    documentMapper ,    null ,    null )  ;", "fieldMapper . process ( query ,    parseContext )  ;", "ParseContext . Document   queryDocument    =    parseContext . doc (  )  ;", "queryDocument . add ( new   StoredField (  \" query _ to _ string \"  ,    query . toString (  )  )  )  ;", "docs . add ( queryDocument )  ;", "queries . add ( query )  ;", "}", "METHOD_END"], "methodName": ["addQuery"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "int   numClauses    =    randomIntBetween (  1  ,     (  1     <  <     ( randomIntBetween (  2  ,     4  )  )  )  )  ;", "int   numShouldClauses    =     0  ;", "boolean   onlyShouldClauses    =    rarely (  )  ;", "for    ( int   i    =     0  ;    i    <    numClauses ;    i +  +  )     {", "Occur   occur ;", "if    ( onlyShouldClauses )     {", "occur    =    Occur . SHOULD ;", "if    ( randomBoolean (  )  )     {", "String   field    =    randomFrom ( fields )  ;", "builder . add ( new   TermQuery ( new   Term ( field ,    randomFrom ( content . get ( field )  )  )  )  ,    occur )  ;", "} else    {", "builder . add ( intFieldType . termQuery ( randomFrom ( intValues )  ,    null )  ,    occur )  ;", "}", "} else", "if    (  ( rarely (  )  )     &  &     ( depth    <  =     3  )  )     {", "occur    =    randomFrom ( asList ( Occur . FILTER ,    Occur . MUST ,    Occur . SHOULD )  )  ;", "builder . add ( createRandomBooleanQuery (  ( depth    +     1  )  ,    fields ,    content ,    intFieldType ,    intValues )  ,    occur )  ;", "} else", "if    ( rarely (  )  )     {", "if    ( randomBoolean (  )  )     {", "occur    =    randomFrom ( asList ( Occur . FILTER ,    Occur . MUST ,    Occur . SHOULD )  )  ;", "if    ( randomBoolean (  )  )     {", "builder . add ( new   TermQuery ( new   Term (  \" unknown _ field \"  ,    randomAlphaOfLength (  8  )  )  )  ,    occur )  ;", "} else    {", "builder . add ( intFieldType . termQuery ( randomFrom ( intValues )  ,    null )  ,    occur )  ;", "}", "} else", "if    ( randomBoolean (  )  )     {", "String   field    =    randomFrom ( fields )  ;", "builder . add ( new   TermQuery ( new   Term ( field ,    randomFrom ( content . get ( field )  )  )  )  ,     ( occur    =    Occur . MUST _ NOT )  )  ;", "} else    {", "builder . add ( intFieldType . termQuery ( randomFrom ( intValues )  ,    null )  ,     ( occur    =    Occur . MUST _ NOT )  )  ;", "}", "} else    {", "if    ( randomBoolean (  )  )     {", "occur    =    randomFrom ( asList ( Occur . FILTER ,    Occur . MUST ,    Occur . SHOULD )  )  ;", "if    ( randomBoolean (  )  )     {", "String   field    =    randomFrom ( fields )  ;", "builder . add ( new   TermQuery ( new   Term ( field ,    randomFrom ( content . get ( field )  )  )  )  ,    occur )  ;", "} else    {", "builder . add ( intFieldType . termQuery ( randomFrom ( intValues )  ,    null )  ,    occur )  ;", "}", "} else    {", "builder . add ( new   TermQuery ( new   Term (  \" unknown _ field \"  ,    randomAlphaOfLength (  8  )  )  )  ,     ( occur    =    Occur . MUST _ NOT )  )  ;", "}", "}", "if    ( occur    =  =     ( Occur . SHOULD )  )     {", "numShouldClauses +  +  ;", "}", "}", "builder . setMinimumNumberShouldMatch ( randomIntBetween (  0  ,    numShouldClauses )  )  ;", "return   builder . build (  )  ;", "}", "METHOD_END"], "methodName": ["createRandomBooleanQuery"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "directoryReader . close (  )  ;", "directory . close (  )  ;", "}", "METHOD_END"], "methodName": ["deinit"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "boolean   requireScore    =    randomBoolean (  )  ;", "IndexSearcher   percolateSearcher    =    memoryIndex . createSearcher (  )  ;", "Query   percolateQuery    =    fieldType . percolateQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ,    percolateSearcher ,    CURRENT )  ;", "Query   query    =     ( requireScore )     ?    percolateQuery    :    new   ConstantScoreQuery ( percolateQuery )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  0  0  )  ;", "Query   controlQuery    =    new    . ControlQuery ( memoryIndex ,    queryStore )  ;", "controlQuery    =     ( requireScore )     ?    controlQuery    :    new   ConstantScoreQuery ( controlQuery )  ;", "TopDocs   controlTopDocs    =    shardSearcher . search ( controlQuery ,     1  0  0  )  ;", "try    {", "assertThat ( topDocs . totalHits ,    equalTo ( controlTopDocs . totalHits )  )  ;", "assertThat ( topDocs . scoreDocs . length ,    equalTo ( controlTopDocs . scoreDocs . length )  )  ;", "for    ( int   j    =     0  ;    j    <     ( topDocs . scoreDocs . length )  ;    j +  +  )     {", "assertThat ( topDocs . scoreDocs [ j ]  . doc ,    equalTo ( controlTopDocs . scoreDocs [ j ]  . doc )  )  ;", "assertThat ( topDocs . scoreDocs [ j ]  . score ,    equalTo ( controlTopDocs . scoreDocs [ j ]  . score )  )  ;", "if    ( requireScore )     {", "Explanation   explain 1     =    shardSearcher . explain ( query ,    topDocs . scoreDocs [ j ]  . doc )  ;", "Explanation   explain 2     =    shardSearcher . explain ( controlQuery ,    controlTopDocs . scoreDocs [ j ]  . doc )  ;", "assertThat ( explain 1  . isMatch (  )  ,    equalTo ( explain 2  . isMatch (  )  )  )  ;", "assertThat ( explain 1  . getValue (  )  ,    equalTo ( explain 2  . getValue (  )  )  )  ;", "}", "}", "}    catch    ( AssertionError   ae )     {", "logger . error (  \" topDocs . totalHits =  {  }  \"  ,    topDocs . totalHits )  ;", "logger . error (  \" controlTopDocs . totalHits =  {  }  \"  ,    controlTopDocs . totalHits )  ;", "logger . error (  \" topDocs . scoreDocs . length =  {  }  \"  ,    topDocs . scoreDocs . length )  ;", "logger . error (  \" controlTopDocs . scoreDocs . length =  {  }  \"  ,    controlTopDocs . scoreDocs . length )  ;", "for    ( int   i    =     0  ;    i    <     ( topDocs . scoreDocs . length )  ;    i +  +  )     {", "logger . error (  \" topDocs . scoreDocs [  {  }  ]  . doc =  {  }  \"  ,    i ,    topDocs . scoreDocs [ i ]  . doc )  ;", "logger . error (  \" topDocs . scoreDocs [  {  }  ]  . score =  {  }  \"  ,    i ,    topDocs . scoreDocs [ i ]  . score )  ;", "}", "for    ( int   i    =     0  ;    i    <     ( controlTopDocs . scoreDocs . length )  ;    i +  +  )     {", "logger . error (  \" controlTopDocs . scoreDocs [  {  }  ]  . doc =  {  }  \"  ,    i ,    controlTopDocs . scoreDocs [ i ]  . doc )  ;", "logger . error (  \" controlTopDocs . scoreDocs [  {  }  ]  . score =  {  }  \"  ,    i ,    controlTopDocs . scoreDocs [ i ]  . score )  ;", "String   queryToString    =    shardSearcher . doc ( controlTopDocs . scoreDocs [ i ]  . doc )  . get (  \" query _ to _ string \"  )  ;", "logger . error (  \" controlTopDocs . scoreDocs [  {  }  ]  . query _ to _ string =  {  }  \"  ,    i ,    queryToString )  ;", "TermsEnum   tenum    =    MultiFields . getFields ( shardSearcher . getIndexReader (  )  )  . terms ( fieldType . queryTermsField . name (  )  )  . iterator (  )  ;", "StringBuilder   builder    =    new   StringBuilder (  )  ;", "for    ( BytesRef   term    =    tenum . next (  )  ;    term    !  =    null ;    term    =    tenum . next (  )  )     {", "PostingsEnum   penum    =    tenum . postings ( null )  ;", "if    (  ( penum . advance ( controlTopDocs . scoreDocs [ i ]  . doc )  )     =  =     ( controlTopDocs . scoreDocs [ i ]  . doc )  )     {", "builder . append ( term . utf 8 ToString (  )  )  . append (  '  ,  '  )  ;", "}", "}", "logger . error (  \" controlTopDocs . scoreDocs [  {  }  ]  . query _ terms _ field =  {  }  \"  ,    i ,    builder . toString (  )  )  ;", "NumericDocValues   numericValues    =    MultiDocValues . getNumericValues ( shardSearcher . getIndexReader (  )  ,    fieldType . minimumShouldMatchField . name (  )  )  ;", "boolean   exact    =    numericValues . advanceExact ( controlTopDocs . scoreDocs [ i ]  . doc )  ;", "if    ( exact )     {", "logger . error (  \" controlTopDocs . scoreDocs [  {  }  ]  . minimum _ should _ match _ field =  {  }  \"  ,    i ,    numericValues . longValue (  )  )  ;", "} else    {", "logger . error (  \" controlTopDocs . scoreDocs [  {  }  ]  . minimum _ should _ match _ field =  [ NO _ VALUE ]  \"  ,    i )  ;", "}", "}", "throw   ae ;", "}", "}", "METHOD_END"], "methodName": ["duelRun"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "IndexSearchereSearcher    =    memoryIndex . createSearcher (  )  ;", "QueryeQuery    =    fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  , eSearcher ,    CURRENT )  ;", "return   shardSearcher . searcheQuery ,     1  0  )  ;", "}", "METHOD_END"], "methodName": ["executeQuery"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "directory    =    newDirectory (  )  ;", "IndexWriterConfig   config    =    new   IndexWriterConfig ( new   WhitespaceAnalyzer (  )  )  ;", "config . setMergePolicy ( INSTANCE )  ;", "indexWriter    =    new   IndexWriter ( directory ,    config )  ;", "String   indexName    =     \" test \"  ;", "IndexService   indexService    =    createIndex ( indexName ,    EMPTY )  ;", "mapperService    =    indexService . mapperService (  )  ;", "String   mapper    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" int _ field \"  )  . field (  \" type \"  ,     \" integer \"  )  . endObject (  )  . startObject (  \" long _ field \"  )  . field (  \" type \"  ,     \" long \"  )  . endObject (  )  . startObject (  \" half _ float _ field \"  )  . field (  \" type \"  ,     \" half _ float \"  )  . endObject (  )  . startObject (  \" float _ field \"  )  . field (  \" type \"  ,     \" float \"  )  . endObject (  )  . startObject (  \" double _ field \"  )  . field (  \" type \"  ,     \" double \"  )  . endObject (  )  . startObject (  \" ip _ field \"  )  . field (  \" type \"  ,     \" ip \"  )  . endObject (  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" keyword \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "documentMapper    =    mapperService . merge (  \" type \"  ,    new   CompressedXContent ( mapper )  ,    MAPPING _ UPDATE )  ;", "String   queryField    =     \" query _ field \"  ;", "String   Mapper    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject ( queryField )  . field (  \" type \"  ,     \"  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "mapperService . merge (  \" type \"  ,    new   CompressedXContent ( Mapper )  ,    MAPPING _ UPDATE )  ;", "fieldMapper    =     (  ( PercolatorFieldMapper )     ( mapperService . documentMapper (  \" type \"  )  . mappers (  )  . getMapper ( queryField )  )  )  ;", "fieldType    =     (  ( PercolatorFieldMapper . FieldType )     ( fieldMapper . fieldType (  )  )  )  ;", "queries    =    new   ArrayList (  )  ;", "queryStore    =     (    ctx )     -  >     (    docId )     -  >    this . queries . get ( docId )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "final   int   numClauses    =    randomIntBetween (  1  ,     4  )  ;", "final   boolean   onlyShouldClauses    =    randomBoolean (  )  ;", "final   BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "int   numShouldClauses    =     0  ;", "for    ( int   i    =     0  ;    i    <    numClauses ;    i +  +  )     {", "Query   subQuery ;", "if    (  ( randomBoolean (  )  )     &  &     ( depth    <  =     3  )  )     {", "subQuery    =    randomBQ (  ( depth    +     1  )  ,    stringValues ,    ranges ,    intFieldType )  ;", "} else", "if    ( randomBoolean (  )  )     {", "int [  ]    range    =    randomFrom ( ranges )  ;", "subQuery    =    intFieldType . rangeQuery ( range [  0  ]  ,    range [  1  ]  ,    true ,    true ,    null ,    null ,    null ,    null )  ;", "} else    {", "subQuery    =    new   TermQuery ( new   Term (  \" string _ field \"  ,    randomFrom ( stringValues )  )  )  ;", "}", "Occur   occur ;", "if    ( onlyShouldClauses )     {", "occur    =    Occur . SHOULD ;", "} else    {", "occur    =    randomFrom ( Arrays . asList ( FILTER ,    MUST ,    SHOULD )  )  ;", "}", "if    ( occur    =  =     ( Occur . SHOULD )  )     {", "numShouldClauses +  +  ;", "}", "builder . add ( subQuery ,    occur )  ;", "}", "builder . setMinimumNumberShouldMatch ( randomIntBetween (  0  ,    numShouldClauses )  )  ;", "return   builder . build (  )  ;", "}", "METHOD_END"], "methodName": ["randomBQ"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "int   numFields    =    randomIntBetween (  1  ,     3  )  ;", "Map < String ,    List < String >  >    stringContent    =    new   HashMap <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    numFields ;    i +  +  )     {", "int   numTokens    =    randomIntBetween (  1  ,     6  4  )  ;", "List < String >    values    =    new   ArrayList <  >  (  )  ;", "for    ( int   j    =     0  ;    j    <    numTokens ;    j +  +  )     {", "values . add ( randomAlphaOfLength (  8  )  )  ;", "}", "stringContent . put (  (  \" field \"     +    i )  ,    values )  ;", "}", "List < String >    stringFields    =    new   ArrayList <  >  ( stringContent . keySet (  )  )  ;", "int   numValues    =    randomIntBetween (  1  6  ,     6  4  )  ;", "List < Integer >    intValues    =    new   ArrayList <  >  ( numValues )  ;", "for    ( int   j    =     0  ;    j    <    numValues ;    j +  +  )     {", "intValues . add ( randomInt (  )  )  ;", "}", "Collections . sort ( intValues )  ;", "MappedFieldType   intFieldType    =    mapperService . documentMapper (  \" type \"  )  . mappers (  )  . getMapper (  \" int _ field \"  )  . fieldType (  )  ;", "List < Supplier < Query >  >    queryFunctions    =    new   ArrayList <  >  (  )  ;", "queryFunctions . add ( MatchNoDocsQuery :  : new )  ;", "queryFunctions . add ( MatchAllDocsQuery :  : new )  ;", "queryFunctions . add (  (  )     -  >    new   TermQuery ( new   Term (  \" unknown _ field \"  ,     \" value \"  )  )  )  ;", "String   field 1     =    randomFrom ( stringFields )  ;", "queryFunctions . add (  (  )     -  >    new   TermQuery ( new   Term ( field 1  ,    randomFrom ( stringContent . get ( field 1  )  )  )  )  )  ;", "String   field 2     =    randomFrom ( stringFields )  ;", "queryFunctions . add (  (  )     -  >    new   TermQuery ( new   Term ( field 2  ,    randomFrom ( stringContent . get ( field 2  )  )  )  )  )  ;", "queryFunctions . add (  (  )     -  >    intFieldType . termQuery ( randomFrom ( intValues )  ,    null )  )  ;", "queryFunctions . add (  (  )     -  >    intFieldType . termsQuery ( Arrays . asList ( randomFrom ( intValues )  ,    randomFrom ( intValues )  )  ,    null )  )  ;", "queryFunctions . add (  (  )     -  >    intFieldType . rang ( intValues . get (  4  )  ,    intValues . get (  (  ( intValues . size (  )  )     -     4  )  )  ,    true ,    true ,    ShapeRelation . WITHIN ,    null ,    null ,    null )  )  ;", "queryFunctions . add (  (  )     -  >    new   TermInSetQuery ( field 1  ,    new   BytesRef ( randomFrom ( stringContent . get ( field 1  )  )  )  ,    new   BytesRef ( randomFrom ( stringContent . get ( field 1  )  )  )  )  )  ;", "queryFunctions . add (  (  )     -  >    new   TermInSetQuery ( field 2  ,    new   BytesRef ( randomFrom ( stringContent . get ( field 1  )  )  )  ,    new   BytesRef ( randomFrom ( stringContent . get ( field 1  )  )  )  )  )  ;", "int   numRandomBoolQueries    =     1  0  0  0  ;", "for    ( int   i    =     0  ;    i    <    numRandomBoolQueries ;    i +  +  )     {", "queryFunctions . add (  (  )     -  >    createRandomBooleanQuery (  1  ,    stringFields ,    stringContent ,    intFieldType ,    intValues )  )  ;", "}", "queryFunctions . add (  (  )     -  >     {", "int   numClauses    =    randomIntBetween (  1  ,     (  1     <  <     ( randomIntBetween (  2  ,     4  )  )  )  )  ;", "List < Query >    clauses    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    numClauses ;    i +  +  )     {", "String   field    =    randomFrom ( stringFields )  ;", "clauses . add ( new   TermQuery ( new   Term ( field ,    randomFrom ( stringContent . get ( field )  )  )  )  )  ;", "}", "return   new   DisjunctionMaxQuery ( clauses ,     0  .  0  1 F )  ;", "}  )  ;", "queryFunctions . add (  (  )     -  >     {", "Float   minScore    =     ( randomBoolean (  )  )     ?    null    :     (  ( float )     ( randomIntBetween (  1  ,     1  0  0  0  )  )  )  ;", "Query   innerQuery ;", "if    ( randomBoolean (  )  )     {", "innerQuery    =    new   TermQuery ( new   Term ( field 1  ,    randomFrom ( stringContent . get ( field 1  )  )  )  )  ;", "} else    {", "innerQuery    =    new   Phras ( field 1  ,    randomFrom ( stringContent . get ( field 1  )  )  ,    randomFrom ( stringContent . get ( field 1  )  )  )  ;", "}", "return   new   FunctionScor ( innerQuery ,    minScore ,     1  .  0 F )  ;", "}  )  ;", "List < ParseContext . Document >    documents    =    new   ArrayList <  >  (  )  ;", "for    ( Supplier < Query >    queryFunction    :    queryFunctions )     {", "Query   query    =    queryFunction . get (  )  ;", "addQuery ( query ,    documents )  ;", "}", "indexWriter . addDocuments ( documents )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "Document   document    =    new   Document (  )  ;", "for    ( Map . Entry < String ,    List < String >  >    entry    :    stringContent . entrySet (  )  )     {", "String   value    =    entry . getValue (  )  . stream (  )  . collect ( Collectors . joining (  \"     \"  )  )  ;", "document . add ( new   TextField ( entry . getKey (  )  ,    value ,    Store . NO )  )  ;", "}", "for    ( Integer   intValue    :    intValues )     {", "List < Field >    numberFields    =    INTEGER . createFields (  \" int _ field \"  ,    intValue ,    true ,    true ,    false )  ;", "for    ( Field   numberField    :    numberFields )     {", "document . add ( numberField )  ;", "}", "}", "MemoryIndex   memoryIndex    =    MemoryIndex . fromDocument ( document ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "}", "METHOD_END"], "methodName": ["testDuel"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < String >    stringValues    =    new   ArrayList <  >  (  )  ;", "stringValues . add (  \" value 1  \"  )  ;", "stringValues . add (  \" value 2  \"  )  ;", "stringValues . add (  \" value 3  \"  )  ;", "MappedFieldType   intFieldType    =    mapperService . documentMapper (  \" type \"  )  . mappers (  )  . getMapper (  \" int _ field \"  )  . fieldType (  )  ;", "List < int [  ]  >    ranges    =    new   ArrayList <  >  (  )  ;", "ranges . add ( new   int [  ]  {     -  5  ,     5     }  )  ;", "ranges . add ( new   int [  ]  {     0  ,     1  0     }  )  ;", "ranges . add ( new   int [  ]  {     1  5  ,     5  0     }  )  ;", "List < ParseContext . Document >    documents    =    new   ArrayList <  >  (  )  ;", "{", "addQuery ( new   TermQuery ( new   Term (  \" string _ field \"  ,    randomFrom ( stringValues )  )  )  ,    documents )  ;", "}", "{", "addQuery ( new   Phras (  0  ,     \" string _ field \"  ,    stringValues . toArray ( new   String [  0  ]  )  )  ,    documents )  ;", "}", "{", "int [  ]    range    =    randomFrom ( ranges )  ;", "Query   rang    =    intFieldType . rang ( range [  0  ]  ,    range [  1  ]  ,    true ,    true ,    null ,    null ,    null ,    null )  ;", "addQuery ( rang ,    documents )  ;", "}", "{", "int   numBooleanQueries    =    randomIntBetween (  1  ,     5  )  ;", "for    ( int   i    =     0  ;    i    <    numBooleanQueries ;    i +  +  )     {", "Query   randomBQ    =    randomBQ (  1  ,    stringValues ,    ranges ,    intFieldType )  ;", "addQuery ( randomBQ ,    documents )  ;", "}", "}", "{", "addQuery ( new   MatchNoDocsQuery (  )  ,    documents )  ;", "}", "{", "addQuery ( new   MatchAllDocsQuery (  )  ,    documents )  ;", "}", "indexWriter . addDocuments ( documents )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "Document   document    =    new   Document (  )  ;", "for    ( String   value    :    stringValues )     {", "document . add ( new   TextField (  \" string _ field \"  ,    value ,    Store . NO )  )  ;", "logger . info (  (  \" Test   with   document :     {  }  \"     +    document )  )  ;", "MemoryIndex   memoryIndex    =    MemoryIndex . fromDocument ( document ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "}", "for    ( int [  ]    range    :    ranges )     {", "List < Field >    numberFields    =    INTEGER . createFields (  \" int _ field \"  ,    between ( range [  0  ]  ,    range [  1  ]  )  ,    true ,    true ,    false )  ;", "for    ( Field   numberField    :    numberFields )     {", "document . add ( numberField )  ;", "}", "logger . info (  (  \" Test   with   document :     {  }  \"     +    document )  )  ;", "MemoryIndex   memoryIndex    =    MemoryIndex . fromDocument ( document ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "}", "}", "METHOD_END"], "methodName": ["testDuel2"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < Function < String ,    Query >  >    queryFunctions    =    new   ArrayList <  >  (  )  ;", "queryFunctions . add (  (    id )     -  >    new   PrefixQuery ( new   Term (  \" field \"  ,    id )  )  )  ;", "queryFunctions . add (  (    id )     -  >    new   WildcardQuery ( new   Term (  \" field \"  ,     ( id    +     \"  *  \"  )  )  )  )  ;", "queryFunctions . add (  (    id )     -  >    new   CustomQuery ( new   Term (  \" field \"  ,    id )  )  )  ;", "queryFunctions . add (  (    id )     -  >    new   SpanTermQuery ( new   Term (  \" field \"  ,    id )  )  )  ;", "queryFunctions . add (  (    id )     -  >    new   TermQuery ( new   Term (  \" field \"  ,    id )  )  )  ;", "queryFunctions . add (  (    id )     -  >     {", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "return   builder . build (  )  ;", "}  )  ;", "queryFunctions . add (  (    id )     -  >     {", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,    id )  )  ,    Occur . MUST )  ;", "if    ( randomBoolean (  )  )     {", "builder . add ( new   MatchNoDocsQuery (  \" no   reason \"  )  ,    Occur . MUST _ NOT )  ;", "}", "if    ( randomBoolean (  )  )     {", "builder . add ( new   CustomQuery ( new   Term (  \" field \"  ,    id )  )  ,    Occur . MUST )  ;", "}", "return   builder . build (  )  ;", "}  )  ;", "queryFunctions . add (  (    id )     -  >     {", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,    id )  )  ,    Occur . SHOULD )  ;", "if    ( randomBoolean (  )  )     {", "builder . add ( new   MatchNoDocsQuery (  \" no   reason \"  )  ,    Occur . MUST _ NOT )  ;", "}", "if    ( randomBoolean (  )  )     {", "builder . add ( new   CustomQuery ( new   Term (  \" field \"  ,    id )  )  ,    Occur . SHOULD )  ;", "}", "return   builder . build (  )  ;", "}  )  ;", "queryFunctions . add (  (    id )     -  >     {", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    Occur . MUST )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    Occur . MUST )  ;", "if    ( randomBoolean (  )  )     {", "builder . add ( new   MatchNoDocsQuery (  \" no   reason \"  )  ,    Occur . MUST _ NOT )  ;", "} else", "if    ( randomBoolean (  )  )     {", "builder . add ( new   MatchAllDocsQuery (  )  ,    Occur . MUST _ NOT )  ;", "}", "return   builder . build (  )  ;", "}  )  ;", "queryFunctions . add (  (    id )     -  >     {", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    Occur . SHOULD )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    Occur . SHOULD )  ;", "if    ( randomBoolean (  )  )     {", "builder . add ( new   MatchNoDocsQuery (  \" no   reason \"  )  ,    Occur . MUST _ NOT )  ;", "} else", "if    ( randomBoolean (  )  )     {", "builder . add ( new   MatchAllDocsQuery (  )  ,    Occur . MUST _ NOT )  ;", "}", "return   builder . build (  )  ;", "}  )  ;", "queryFunctions . add (  (    id )     -  >     {", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    Occur . SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,    id )  )  ,    Occur . SHOULD )  ;", "if    ( randomBoolean (  )  )     {", "builder . add ( new   MatchAllDocsQuery (  )  ,    Occur . SHOULD )  ;", "}", "if    ( randomBoolean (  )  )     {", "builder . setMinimumNumberShouldMatch (  2  )  ;", "}", "return   builder . build (  )  ;", "}  )  ;", "queryFunctions . add (  (    id )     -  >     {", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . setMinimumNumberShouldMatch ( randomIntBetween (  0  ,     4  )  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,    id )  )  ,    Occur . SHOULD )  ;", "builder . add ( new   CustomQuery ( new   Term (  \" field \"  ,    id )  )  ,    Occur . SHOULD )  ;", "return   builder . build (  )  ;", "}  )  ;", "queryFunctions . add (  (    id )     -  >    new   MatchAllDocsQuery (  )  )  ;", "queryFunctions . add (  (    id )     -  >    new   MatchNoDocsQuery (  \" no   reason   at   all \"  )  )  ;", "int   numDocs    =    randomIntBetween ( queryFunctions . size (  )  ,     (  ( queryFunctions . size (  )  )     *     3  )  )  ;", "List < ParseContext . Document >    documents    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "String   id    =    Integer . toString ( i )  ;", "Query   query    =    queryFunctions . get (  ( i    %     ( queryFunctions . size (  )  )  )  )  . apply ( id )  ;", "addQuery ( query ,    documents )  ;", "}", "indexWriter . addDocuments ( documents )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "String   id    =    Integer . toString ( i )  ;", "Iterable <  ?    extends   IndexableField >    doc    =    Collections . singleton ( new   StringField (  \" field \"  ,    id ,    Store . NO )  )  ;", "MemoryIndex   memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "}", "Iterable <  ?    extends   IndexableField >    doc    =    Collections . singleton ( new   StringField (  \" field \"  ,     \" value \"  ,    Store . NO )  )  ;", "MemoryIndex   memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "memoryIndex    =    new   MemoryIndex (  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "}", "METHOD_END"], "methodName": ["testDuelIdBased"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < ParseContext . Document >    documents    =    new   ArrayList <  >  (  )  ;", "int   lowerInt    =    randomIntBetween (  0  ,     2  5  6  )  ;", "int   upperInt    =    lowerInt    +     ( randomIntBetween (  0  ,     3  2  )  )  ;", "addQuery ( IntPoint . newRangeQuery (  \" int _ field \"  ,    lowerInt ,    upperInt )  ,    documents )  ;", "long   lowerLong    =    randomIntBetween (  0  ,     2  5  6  )  ;", "long   upperLong    =    lowerLong    +     ( randomIntBetween (  0  ,     3  2  )  )  ;", "addQuery ( LongPoint . newRangeQuery (  \" long _ field \"  ,    lowerLong ,    upperLong )  ,    documents )  ;", "float   lowerHalfFloat    =    randomIntBetween (  0  ,     2  5  6  )  ;", "float   upperHalfFloat    =    lowerHalfFloat    +     ( randomIntBetween (  0  ,     3  2  )  )  ;", "addQuery ( HalfFloatPoint . newRangeQuery (  \" half _ float _ field \"  ,    lowerHalfFloat ,    upperHalfFloat )  ,    documents )  ;", "float   lowerFloat    =    randomIntBetween (  0  ,     2  5  6  )  ;", "float   upperFloat    =    lowerFloat    +     ( randomIntBetween (  0  ,     3  2  )  )  ;", "addQuery ( FloatPoint . newRangeQuery (  \" float _ field \"  ,    lowerFloat ,    upperFloat )  ,    documents )  ;", "double   lowerDouble    =    randomDoubleBetween (  0  ,     2  5  6  ,    true )  ;", "double   upperDouble    =    lowerDouble    +     ( randomDoubleBetween (  0  ,     3  2  ,    true )  )  ;", "addQuery ( DoublePoint . newRangeQuery (  \" double _ field \"  ,    lowerDouble ,    upperDouble )  ,    documents )  ;", "int   lowerIpPart    =    randomIntBetween (  0  ,     2  5  5  )  ;", "int   upperIpPart    =    randomIntBetween ( lowerIpPart ,     2  5  5  )  ;", "addQuery ( InetAddressPoint . newRangeQuery (  \" ip _ field \"  ,    forString (  (  \"  1  9  2  .  1  6  8  .  1  .  \"     +    lowerIpPart )  )  ,    forString (  (  \"  1  9  2  .  1  6  8  .  1  .  \"     +    upperIpPart )  )  )  ,    documents )  ;", "indexWriter . addDocuments ( documents )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "int   randomInt    =    randomIntBetween ( lowerInt ,    upperInt )  ;", "Iterable <  ?    extends   IndexableField >    doc    =    Collections . singleton ( new   IntPoint (  \" int _ field \"  ,    randomInt )  )  ;", "MemoryIndex   memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "TopDocs   result    =    execu ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "assertThat ( result . scoreDocs . length ,    equalTo (  1  )  )  ;", "assertThat ( result . scoreDocs [  0  ]  . doc ,    equalTo (  0  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "doc    =    Collections . singleton ( new   IntPoint (  \" int _ field \"  ,    randomInt (  )  )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "long   randomLong    =    randomIntBetween (  (  ( int )     ( lowerLong )  )  ,     (  ( int )     ( upperLong )  )  )  ;", "doc    =    Collections . singleton ( new   LongPoint (  \" long _ field \"  ,    randomLong )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "result    =    execu ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "assertThat ( result . scoreDocs . length ,    equalTo (  1  )  )  ;", "assertThat ( result . scoreDocs [  0  ]  . doc ,    equalTo (  1  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "doc    =    Collections . singleton ( new   LongPoint (  \" long _ field \"  ,    randomLong (  )  )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "float   randomHalfFloat    =    randomIntBetween (  (  ( int )     ( lowerHalfFloat )  )  ,     (  ( int )     ( upperHalfFloat )  )  )  ;", "doc    =    Collections . singleton ( new   HalfFloatPoint (  \" half _ float _ field \"  ,    randomHalfFloat )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "result    =    execu ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "assertThat ( result . scoreDocs . length ,    equalTo (  1  )  )  ;", "assertThat ( result . scoreDocs [  0  ]  . doc ,    equalTo (  2  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "doc    =    Collections . singleton ( new   HalfFloatPoint (  \" half _ float _ field \"  ,    randomFloat (  )  )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "float   randomFloat    =    randomIntBetween (  (  ( int )     ( lowerFloat )  )  ,     (  ( int )     ( upperFloat )  )  )  ;", "doc    =    Collections . singleton ( new   FloatPoint (  \" float _ field \"  ,    randomFloat )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "result    =    execu ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "assertThat ( result . scoreDocs . length ,    equalTo (  1  )  )  ;", "assertThat ( result . scoreDocs [  0  ]  . doc ,    equalTo (  3  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "doc    =    Collections . singleton ( new   FloatPoint (  \" float _ field \"  ,    randomFloat (  )  )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "double   randomDouble    =    randomDoubleBetween ( lowerDouble ,    upperDouble ,    true )  ;", "doc    =    Collections . singleton ( new   DoublePoint (  \" double _ field \"  ,    randomDouble )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "result    =    execu ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "assertThat ( result . scoreDocs . length ,    equalTo (  1  )  )  ;", "assertThat ( result . scoreDocs [  0  ]  . doc ,    equalTo (  4  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "doc    =    Collections . singleton ( new   DoublePoint (  \" double _ field \"  ,    randomFloat (  )  )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "doc    =    Collections . singleton ( new   InetAddressPoint (  \" ip _ field \"  ,    forString (  (  \"  1  9  2  .  1  6  8  .  1  .  \"     +     ( randomIntBetween ( lowerIpPart ,    upperIpPart )  )  )  )  )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "result    =    execu ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "assertThat ( result . scoreDocs . length ,    equalTo (  1  )  )  ;", "assertThat ( result . scoreDocs [  0  ]  . doc ,    equalTo (  5  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "doc    =    Collections . singleton ( new   InetAddressPoint (  \" ip _ field \"  ,    forString (  (  \"  1  9  2  .  1  6  8  .  1  .  \"     +     ( randomIntBetween (  0  ,     2  5  5  )  )  )  )  )  )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( doc ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "}", "METHOD_END"], "methodName": ["testDuelRangeQueries"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < ParseContext . Document >    documents    =    new   ArrayList <  >  (  )  ;", "CommonTermsQuery   commonTermsQuery    =    new   CommonTermsQuery ( Occur . SHOULD ,    Occur . SHOULD ,     1  2  8  )  ;", "commonTermsQuery . add ( new   Term (  \" field \"  ,     \" quick \"  )  )  ;", "commonTermsQuery . add ( new   Term (  \" field \"  ,     \" brown \"  )  )  ;", "commonTermsQuery . add ( new   Term (  \" field \"  ,     \" fox \"  )  )  ;", "addQuery ( commonTermsQuery ,    documents )  ;", "BlendedTermQuery   blendedTermQuery    =    BlendedTermQuery . dismaxBlendedQuery ( new   Term [  ]  {    new   Term (  \" field \"  ,     \" quick \"  )  ,    new   Term (  \" field \"  ,     \" brown \"  )  ,    new   Term (  \" field \"  ,     \" fox \"  )     }  ,     1  .  0 F )  ;", "addQuery ( blendedTermQuery ,    documents )  ;", "SpanNearQuery   spanNearQuery    =    new   SpanNearQuery . Builder (  \" field \"  ,    true )  . addClause ( new   SpanTermQuery ( new   Term (  \" field \"  ,     \" quick \"  )  )  )  . addClause ( new   SpanTermQuery ( new   Term (  \" field \"  ,     \" brown \"  )  )  )  . addClause ( new   SpanTermQuery ( new   Term (  \" field \"  ,     \" fox \"  )  )  )  . build (  )  ;", "addQuery ( spanNearQuery ,    documents )  ;", "SpanNearQuery   spanNearQuery 2     =    new   SpanNearQuery . Builder (  \" field \"  ,    true )  . addClause ( new   SpanTermQuery ( new   Term (  \" field \"  ,     \" the \"  )  )  )  . addClause ( new   SpanTermQuery ( new   Term (  \" field \"  ,     \" lazy \"  )  )  )  . addClause ( new   SpanTermQuery ( new   Term (  \" field \"  ,     \" doc \"  )  )  )  . build (  )  ;", "SpanOrQuery   spanOrQuery    =    new   SpanOrQuery ( spanNearQuery ,    spanNearQuery 2  )  ;", "addQuery ( spanOrQuery ,    documents )  ;", "SpanNotQuery   spanNotQuery    =    new   SpanNotQuery ( spanNearQuery ,    spanNearQuery )  ;", "addQuery ( spanNotQuery ,    documents )  ;", "long   lowerLong    =    randomIntBetween (  0  ,     2  5  6  )  ;", "long   upperLong    =    lowerLong    +     ( randomIntBetween (  0  ,     3  2  )  )  ;", "addQuery ( LongPoint . newRangeQuery (  \" long _ field \"  ,    lowerLong ,    upperLong )  ,    documents )  ;", "indexWriter . addDocuments ( documents )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "Document   document    =    new   Document (  )  ;", "document . add ( new   TextField (  \" field \"  ,     \" the   quick   brown   fox   jumps   over   the   lazy   dog \"  ,    Store . NO )  )  ;", "long   randomLong    =    randomIntBetween (  (  ( int )     ( lowerLong )  )  ,     (  ( int )     ( upperLong )  )  )  ;", "document . add ( new   LongPoint (  \" long _ field \"  ,    randomLong )  )  ;", "MemoryIndex   memoryIndex    =    MemoryIndex . fromDocument ( document ,    new   WhitespaceAnalyzer (  )  )  ;", "duelRun ( queryStore ,    memoryIndex ,    shardSearcher )  ;", "}", "METHOD_END"], "methodName": ["testDuelSpecificQueries"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < ParseContext . Document >    docs    =    new   ArrayList <  >  (  )  ;", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "BooleanQuery . Builder   builder 1     =    new   BooleanQuery . Builder (  )  ;", "builder 1  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 1  \"  )  )  ,    MUST )  ;", "builder 1  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  ;", "builder . add ( builder 1  . build (  )  ,    MUST )  ;", "BooleanQuery . Builder   builder 2     =    new   BooleanQuery . Builder (  )  ;", "builder 2  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  ;", "builder 2  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    MUST )  ;", "builder . add ( builder 2  . build (  )  ,    MUST )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "builder    =    new   BooleanQuery . Builder (  )  . setMinimumNumberShouldMatch (  2  )  ;", "builder 1     =    new   BooleanQuery . Builder (  )  ;", "builder 1  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 1  \"  )  )  ,    MUST )  ;", "builder 1  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  ;", "builder . add ( builder 1  . build (  )  ,    SHOULD )  ;", "builder 2     =    new   BooleanQuery . Builder (  )  ;", "builder 2  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  ;", "builder 2  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    MUST )  ;", "builder . add ( builder 2  . build (  )  ,    SHOULD )  ;", "BooleanQuery . Builder   builder 3     =    new   BooleanQuery . Builder (  )  ;", "builder 3  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    MUST )  ;", "builder 3  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 4  \"  )  )  ,    MUST )  ;", "builder . add ( builder 3  . build (  )  ,    SHOULD )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "indexWriter . addDocuments ( docs )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "Version   v    =    Version . CURRENT ;", "List < BytesReference >    sources    =    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" value 1    value 2    value 3  \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexSearchereSearcher    =    memoryIndex . createSearcher (  )  ;", "PercolateQuery   query    =     (  ( PercolateQuery )     ( fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    sources , eSearcher ,    v )  )  )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  0  ,    new   Sort ( SortField . FIELD _ DOC )  ,    true ,    true )  ;", "assertEquals (  2 L ,    topDocs . totalHits )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "assertEquals (  1  ,    topDocs . scoreDocs [  1  ]  . doc )  ;", "}", "METHOD_END"], "methodName": ["testDuplicatedClauses"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < ParseContext . Document >    docs    =    new   ArrayList <  >  (  )  ;", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . setMinimumNumberShouldMatch (  3  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 1  \"  )  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 4  \"  )  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 5  \"  )  )  ,    SHOULD )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "indexWriter . addDocuments ( docs )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "Version   v    =    Version . CURRENT ;", "List < BytesReference >    sources    =    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" value 1    value 4    value 5  \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexSearchereSearcher    =    memoryIndex . createSearcher (  )  ;", "PercolateQuery   query    =     (  ( PercolateQuery )     ( fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    sources , eSearcher ,    v )  )  )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  0  ,    new   Sort ( SortField . FIELD _ DOC )  ,    true ,    true )  ;", "assertEquals (  1 L ,    topDocs . totalHits )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" value 1    value 2  \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "eSearcher    =    memoryIndex . createSearcher (  )  ;", "query    =     (  ( PercolateQuery )     ( fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    sources , eSearcher ,    v )  )  )  ;", "topDocs    =    shardSearcher . search ( query ,     1  0  ,    new   Sort ( SortField . FIELD _ DOC )  ,    true ,    true )  ;", "assertEquals (  1 L ,    topDocs . totalHits )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" value 3  \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "eSearcher    =    memoryIndex . createSearcher (  )  ;", "query    =     (  ( PercolateQuery )     ( fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    sources , eSearcher ,    v )  )  )  ;", "topDocs    =    shardSearcher . search ( query ,     1  0  ,    new   Sort ( SortField . FIELD _ DOC )  ,    true ,    true )  ;", "assertEquals (  1 L ,    topDocs . totalHits )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "}", "METHOD_END"], "methodName": ["testDuplicatedClauses2"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < ParseContext . Document >    docs    =    new   ArrayList <  >  (  )  ;", "addQuery ( new   FunctionScoreQuery ( new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ,    null ,     1  .  0 F )  ,    docs )  ;", "addQuery ( new   FunctionScoreQuery ( new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ,     1  0  .  0 F ,     1  .  0 F )  ,    docs )  ;", "addQuery ( new   FunctionScoreQuery ( new   MatchAllDocsQuery (  )  ,    null ,     1  .  0 F )  ,    docs )  ;", "addQuery ( new   FunctionScoreQuery ( new   MatchAllDocsQuery (  )  ,     1  0  .  0 F ,     1  .  0 F )  ,    docs )  ;", "indexWriter . addDocuments ( docs )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" value \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexSearchereSearcher    =    memoryIndex . createSearcher (  )  ;", "PercolateQuery   query    =     (  ( PercolateQuery )     ( fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  , eSearcher ,    CURRENT )  )  )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  0  ,    new   Sort ( SortField . FIELD _ DOC )  ,    true ,    true )  ;", "assertEquals (  2 L ,    topDocs . totalHits )  ;", "assertEquals (  2  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "assertEquals (  2  ,    topDocs . scoreDocs [  1  ]  . doc )  ;", "}", "METHOD_END"], "methodName": ["testFunctionScoreQuery"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < ParseContext . Document >    docs    =    new   ArrayList <  >  (  )  ;", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . setMinimumNumberShouldMatch (  2  )  ;", "BooleanQuery . Builder   builder 1     =    new   BooleanQuery . Builder (  )  ;", "builder 1  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 1  \"  )  )  ,    FILTER )  ;", "builder . add ( builder 1  . build (  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST _ NOT )  ;", "builder . add ( IntPoint . newRangeQuery (  \" int _ field \"  ,     0  ,     5  )  ,    SHOULD )  ;", "builder . add ( IntPoint . newRangeQuery (  \" int _ field \"  ,     6  ,     1  0  )  ,    SHOULD )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "indexWriter . addDocuments ( docs )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "Version   v    =    Version . CURRENT ;", "List < BytesReference >    sources    =    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ;", "Document   document    =    new   Document (  )  ;", "document . add ( new   IntPoint (  \" int _ field \"  ,     4  )  )  ;", "document . add ( new   IntPoint (  \" int _ field \"  ,     7  )  )  ;", "MemoryIndex   memoryIndex    =    MemoryIndex . fromDocument ( document ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexSearchereSearcher    =    memoryIndex . createSearcher (  )  ;", "PercolateQuery   query    =     (  ( PercolateQuery )     ( fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    sources , eSearcher ,    v )  )  )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  0  ,    new   Sort ( SortField . FIELD _ DOC )  ,    true ,    true )  ;", "assertEquals (  1 L ,    topDocs . totalHits )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "}", "METHOD_END"], "methodName": ["testMsmAndRanges_disjunction"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < ParseContext . Document >    docs    =    new   ArrayList <  >  (  )  ;", "addQuery ( new   MatchAllDocsQuery (  )  ,    docs )  ;", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 1  \"  )  )  ,    MUST )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST _ NOT )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    SHOULD )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "indexWriter . addDocuments ( docs )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" value 1  \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexSearchereSearcher    =    memoryIndex . createSearcher (  )  ;", "PercolateQuery   query    =     (  ( PercolateQuery )     ( fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  , eSearcher ,    CURRENT )  )  )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  0  ,    new   Sort ( SortField . FIELD _ DOC )  ,    true ,    true )  ;", "assertEquals (  3 L ,    topDocs . totalHits )  ;", "assertEquals (  3  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "assertEquals (  1  ,    topDocs . scoreDocs [  1  ]  . doc )  ;", "assertEquals (  4  ,    topDocs . scoreDocs [  2  ]  . doc )  ;", "topDocs    =    shardSearcher . search ( new   ConstantScoreQuery ( query )  ,     1  0  )  ;", "assertEquals (  3 L ,    topDocs . totalHits )  ;", "assertEquals (  3  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "assertEquals (  1  ,    topDocs . scoreDocs [  1  ]  . doc )  ;", "assertEquals (  4  ,    topDocs . scoreDocs [  2  ]  . doc )  ;", "}", "METHOD_END"], "methodName": ["testPercolateMatchAll"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < ParseContext . Document >    docs    =    new   ArrayList <  >  (  )  ;", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 1  \"  )  )  ,    MUST )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    MUST )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    MUST )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 4  \"  )  )  ,    MUST )  ;", "addQuery ( builder . build (  )  ,    docs )  ;", "indexWriter . addDocuments ( docs )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "Version   v    =    Version . CURRENT ;", "try    ( RAMDirectory   directory    =    new   RAMDirectory (  )  )     {", "try    ( IndexWriter   iw    =    new   IndexWriter ( directory ,    newIndexWriterConfig (  )  )  )     {", "List < Document >    documents    =    new   ArrayList <  >  (  )  ;", "Document   document    =    new   Document (  )  ;", "document . add ( new   StringField (  \" field \"  ,     \" value 1  \"  ,    Store . NO )  )  ;", "document . add ( new   StringField (  \" field \"  ,     \" value 2  \"  ,    Store . NO )  )  ;", "documents . add ( document )  ;", "document    =    new   Document (  )  ;", "document . add ( new   StringField (  \" field \"  ,     \" value 5  \"  ,    Store . NO )  )  ;", "document . add ( new   StringField (  \" field \"  ,     \" value 6  \"  ,    Store . NO )  )  ;", "documents . add ( document )  ;", "document    =    new   Document (  )  ;", "document . add ( new   StringField (  \" field \"  ,     \" value 3  \"  ,    Store . NO )  )  ;", "document . add ( new   StringField (  \" field \"  ,     \" value 4  \"  ,    Store . NO )  )  ;", "documents . add ( document )  ;", "iw . addDocuments ( documents )  ;", "}", "try    ( IndexReader   ir    =    DirectoryReader . open ( directory )  )     {", "IndexSearcher   percolateSearcher    =    new   IndexSearcher ( ir )  ;", "PercolateQuery   query    =     (  ( PercolateQuery )     ( fieldType . percolateQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ,    percolateSearcher ,    v )  )  )  ;", "BooleanQuery   c    =     (  ( BooleanQuery )     ( query . getCandidateMatchesQuery (  )  )  )  ;", "assertThat ( c . clauses (  )  . get (  0  )  . getQuery (  )  ,    instanceOf ( CoveringQuery . class )  )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  0  )  ;", "assertEquals (  2 L ,    topDocs . totalHits )  ;", "assertEquals (  2  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "assertEquals (  2  ,    topDocs . scoreDocs [  1  ]  . doc )  ;", "topDocs    =    shardSearcher . search ( new   ConstantScoreQuery ( query )  ,     1  0  )  ;", "assertEquals (  2 L ,    topDocs . totalHits )  ;", "assertEquals (  2  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "assertEquals (  2  ,    topDocs . scoreDocs [  1  ]  . doc )  ;", "}", "}", "try    ( RAMDirectory   directory    =    new   RAMDirectory (  )  )     {", "try    ( IndexWriter   iw    =    new   IndexWriter ( directory ,    newIndexWriterConfig (  )  )  )     {", "Document   document    =    new   Document (  )  ;", "for    ( int   i    =     0  ;    i    <     1  0  2  4  ;    i +  +  )     {", "int   fieldNumber    =     2     +    i ;", "document . add ( new   StringField (  \" field \"  ,     (  \" value \"     +    fieldNumber )  ,    Store . NO )  )  ;", "}", "iw . addDocument ( document )  ;", "}", "try    ( IndexReader   ir    =    DirectoryReader . open ( directory )  )     {", "IndexSearcher   percolateSearcher    =    new   IndexSearcher ( ir )  ;", "PercolateQuery   query    =     (  ( PercolateQuery )     ( fieldType . percolateQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ,    percolateSearcher ,    v )  )  )  ;", "BooleanQuery   c    =     (  ( BooleanQuery )     ( query . getCandidateMatchesQuery (  )  )  )  ;", "assertThat ( c . clauses (  )  . get (  0  )  . getQuery (  )  ,    instanceOf ( TermInSetQuery . class )  )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  0  )  ;", "assertEquals (  2 L ,    topDocs . totalHits )  ;", "assertEquals (  2  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  1  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "assertEquals (  2  ,    topDocs . scoreDocs [  1  ]  . doc )  ;", "topDocs    =    shardSearcher . search ( new   ConstantScoreQuery ( query )  ,     1  0  )  ;", "assertEquals (  2 L ,    topDocs . totalHits )  ;", "assertEquals (  2  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  1  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "assertEquals (  2  ,    topDocs . scoreDocs [  1  ]  . doc )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testPercolateSmallAndLargeDocument"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < ParseContext . Document >    docs    =    new   ArrayList <  >  (  )  ;", "addQuery ( IntPoint . newRangeQuery (  \" int _ field \"  ,     0  ,     5  )  ,    docs )  ;", "addQuery ( LongPoint . newRangeQuery (  \" long _ field \"  ,     5 L ,     1  0 L )  ,    docs )  ;", "addQuery ( HalfFloatPoint . newRangeQuery (  \" half _ float _ field \"  ,     1  0  ,     1  5  )  ,    docs )  ;", "addQuery ( FloatPoint . newRangeQuery (  \" float _ field \"  ,     1  5  ,     2  0  )  ,    docs )  ;", "addQuery ( DoublePoint . newRangeQuery (  \" double _ field \"  ,     2  0  ,     2  5  )  ,    docs )  ;", "addQuery ( InetAddressPoint . newRangeQuery (  \" ip _ field \"  ,    forString (  \"  1  9  2  .  1  6  8  .  0  .  1  \"  )  ,    forString (  \"  1  9  2  .  1  6  8  .  0  .  1  0  \"  )  )  ,    docs )  ;", "indexWriter . addDocuments ( docs )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "shardSearcher . setQueryCache ( null )  ;", "Version   v    =    Version . V _  6  _  1  _  0  ;", "MemoryIndex   memoryIndex    =    MemoryIndex . fromDocument ( Collections . singleton ( new   IntPoint (  \" int _ field \"  ,     3  )  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexSearchereSearcher    =    memoryIndex . createSearcher (  )  ;", "Query   query    =    fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  , eSearcher ,    v )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  )  ;", "assertEquals (  1 L ,    topDocs . totalHits )  ;", "assertEquals (  1  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  0  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( Collections . singleton ( new   LongPoint (  \" long _ field \"  ,     7 L )  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "eSearcher    =    memoryIndex . createSearcher (  )  ;", "query    =    fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  , eSearcher ,    v )  ;", "topDocs    =    shardSearcher . search ( query ,     1  )  ;", "assertEquals (  1 L ,    topDocs . totalHits )  ;", "assertEquals (  1  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  1  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( Collections . singleton ( new   HalfFloatPoint (  \" half _ float _ field \"  ,     1  2  )  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "eSearcher    =    memoryIndex . createSearcher (  )  ;", "query    =    fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  , eSearcher ,    v )  ;", "topDocs    =    shardSearcher . search ( query ,     1  )  ;", "assertEquals (  1 L ,    topDocs . totalHits )  ;", "assertEquals (  1  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  2  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( Collections . singleton ( new   FloatPoint (  \" float _ field \"  ,     1  7  )  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "eSearcher    =    memoryIndex . createSearcher (  )  ;", "query    =    fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  , eSearcher ,    v )  ;", "topDocs    =    shardSearcher . search ( query ,     1  )  ;", "assertEquals (  1  ,    topDocs . totalHits )  ;", "assertEquals (  1  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  3  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( Collections . singleton ( new   DoublePoint (  \" double _ field \"  ,     2  1  )  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "eSearcher    =    memoryIndex . createSearcher (  )  ;", "query    =    fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  , eSearcher ,    v )  ;", "topDocs    =    shardSearcher . search ( query ,     1  )  ;", "assertEquals (  1  ,    topDocs . totalHits )  ;", "assertEquals (  1  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  4  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "memoryIndex    =    MemoryIndex . fromDocument ( Collections . singleton ( new   InetAddressPoint (  \" ip _ field \"  ,    forString (  \"  1  9  2  .  1  6  8  .  0  .  4  \"  )  )  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "eSearcher    =    memoryIndex . createSearcher (  )  ;", "query    =    fieldTypeeQuery (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  , eSearcher ,    v )  ;", "topDocs    =    shardSearcher . search ( query ,     1  )  ;", "assertEquals (  1  ,    topDocs . totalHits )  ;", "assertEquals (  1  ,    topDocs . scoreDocs . length )  ;", "assertEquals (  5  ,    topDocs . scoreDocs [  0  ]  . doc )  ;", "}", "METHOD_END"], "methodName": ["testRangeQueries"], "fileName": "org.elasticsearch.percolator.CandidateQueryTests"}, {"methodBody": ["METHOD_START", "{", "return   candidateMatchesQuery ;", "}", "METHOD_END"], "methodName": ["getCandidateMatchesQuery"], "fileName": "org.elasticsearch.percolator.PercolateQuery"}, {"methodBody": ["METHOD_START", "{", "return   documents ;", "}", "METHOD_END"], "methodName": ["getDocuments"], "fileName": "org.elasticsearch.percolator.PercolateQuery"}, {"methodBody": ["METHOD_START", "{", "return   name ;", "}", "METHOD_END"], "methodName": ["getName"], "fileName": "org.elasticsearch.percolator.PercolateQuery"}, {"methodBody": ["METHOD_START", "{", "return   percolatorIndexSearcher ;", "}", "METHOD_END"], "methodName": ["getPercolatorIndexSearcher"], "fileName": "org.elasticsearch.percolator.PercolateQuery"}, {"methodBody": ["METHOD_START", "{", "return   queryStore ;", "}", "METHOD_END"], "methodName": ["getQueryStore"], "fileName": "org.elasticsearch.percolator.PercolateQuery"}, {"methodBody": ["METHOD_START", "{", "RAMDirectory   ramDirectory    =    new   RAMDirectory (  )  ;", "try    ( IndexWriter   indexWriter    =    new   IndexWriter ( ramDirectory ,    new   IndexWriterConfig ( analyzer )  )  )     {", "Iterable < ParseContext . Document >    iterable    =     (  )     -  >    docs . stream (  )  . map ( ParsedDocument :  : docs )  . flatMap ( Collection :  : stream )  . iterator (  )  ;", "indexWriter . addDocuments ( iterable )  ;", "DirectoryReader   directoryReader    =    DirectoryReader . open ( indexWriter )  ;", "assert    ( directoryReader . leaves (  )  . size (  )  )     =  =     1     :     (  \" Expected   single   leaf ,    but   got    [  \"     +     ( directoryReader . leaves (  )  . size (  )  )  )     +     \"  ]  \"  ;", "final   IndexSearcher   slowSearcher    =    new   IndexSearcher ( directoryReader )     {", "@ Override", "public   Weight   createNormalizedWeight ( Query   query ,    boolean   needsScores )    throws   IOException    {", "BooleanQuery . Builder   bq    =    new   BooleanQuery . Builder (  )  ;", "bq . add ( query ,    MUST )  ;", "bq . add ( Queries . newNestedFilter (  )  ,    MUST _ NOT )  ;", "return   super . createNormalizedWeight ( bq . build (  )  ,    needsScores )  ;", "}", "}  ;", "slowSearcher . setQueryCache ( null )  ;", "return   slowSearcher ;", "}    catch    ( IOException   e )     {", "throw   new   EException (  \" Failed   to   create   index   for   percolator   with   nested   document    \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["createMultiDocumentSearcher"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "Version   indexVersion    =    context . indexVersionCreated (  )  ;", "NamedWriteableRegistry   registry    =    context . getWriteableRegistry (  )  ;", "return    (    ctx )     -  >     {", "LeafReader   leafReader    =    ctx . reader (  )  ;", "BinaryDocValues   binaryDocValues    =    leafReader . getBinaryDocValues ( queryBuilderFieldType . name (  )  )  ;", "if    ( binaryDocValues    =  =    null )     {", "return    (    docId )     -  >    null ;", "}", "if    ( indexVersion . onOrAfter ( V _  6  _  0  _  0  _ beta 2  )  )     {", "return    (    docId )     -  >     {", "if    ( binaryDocValues . advanceExact ( docId )  )     {", "BytesRef   qbSource    =    binaryDocValues . binaryValue (  )  ;", "try    ( InputStream   in    =    new   ByteArrayInputStream ( qbSource . bytes ,    qbSource . offset ,    qbSource . length )  )     {", "try    ( StreamInput   input    =    new   NamedWriteableAwareStreamInput ( new   InputStreamStreamInput ( in ,    qbSource . length )  ,    registry )  )     {", "input . setVersion ( indexVersion )  ;", "int   numValues    =    input . readVInt (  )  ;", "assert   numValues    =  =     1  ;", "int   valueLength    =    input . readVInt (  )  ;", "assert   valueLength    >     0  ;", "queryBuilder    =    input . readNamedWriteable (  . class )  ;", "assert    ( in . read (  )  )     =  =     (  -  1  )  ;", "return   PercolatorFieldMapper . toQuery ( context ,    mapUnmappedFieldsAsString ,    queryBuilder )  ;", "}", "}", "} else    {", "return   null ;", "}", "}  ;", "} else    {", "return    (    docId )     -  >     {", "if    ( binaryDocValues . advanceExact ( docId )  )     {", "BytesRef   qbSource    =    binaryDocValues . binaryValue (  )  ;", "if    ( qbSource . length    >     0  )     {", "XContent   xContent    =    PercolatorFieldMapper . QUERY _ BUILDER _ CONTENT _ TYPE . xContent (  )  ;", "try    ( XContentParser   sourceParser    =    xContent . createParser ( context . getXContentRegistry (  )  ,    LoggingDeprecationHandler . INSTANCE ,    qbSource . bytes ,    qbSource . offset ,    qbSource . length )  )     {", "return   parseQuery ( context ,    mapUnmappedFieldsAsString ,    sourceParser )  ;", "}", "} else    {", "return   null ;", "}", "} else    {", "return   null ;", "}", "}  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["createStore"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "float   boost    =    AbstractQueryBuilder . DEFAULT _ BOOST ;", "String   field    =    null ;", "String   name    =    null ;", "String   documentType    =    null ;", "String   indexedDocumentIndex    =    null ;", "String   indexedDocumentType    =    null ;", "String   indexedDocumentId    =    null ;", "String   indexedDocumentRouting    =    null ;", "String   indexedDocumentPreference    =    null ;", "Long   indexedDocumentVersion    =    null ;", "List < BytesReference >    documents    =    new   ArrayList <  >  (  )  ;", "String   queryName    =    null ;", "String   currentFieldName    =    null ;", "boolean   documentsSpecified    =    false ;", "boolean   documentSpecified    =    false ;", "XContentParser . Token   token ;", "while    (  ( token    =    parser . nextToken (  )  )     !  =     ( Token . END _ OBJECT )  )     {", "if    ( token    =  =     ( Token . FIELD _ NAME )  )     {", "currentFieldName    =    parser . currentName (  )  ;", "} else", "if    ( token    =  =     ( Token . START _ ARRAY )  )     {", "if    (  . DOCUMENTS _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "if    ( documentSpecified )     {", "throw   new   IllegalArgumentException (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    Either   specified    [ document ]    or    [ documents ]  ,    not   both \"  )  )  ;", "}", "documentsSpecified    =    true ;", "while    (  ( token    =    parser . nextToken (  )  )     !  =     ( Token . END _ ARRAY )  )     {", "if    ( token    =  =     ( Token . START _ OBJECT )  )     {", "try    ( XContentBuilder   builder    =    jsonBuilder (  )  )     {", "builder . copyCurrentStructure ( parser )  ;", "builder . flush (  )  ;", "documents . add ( BytesReference . bytes ( builder )  )  ;", "}", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    query   does   not   support    [  \"  )     +    token )     +     \"  ]  \"  )  )  ;", "}", "}", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    query   does   not   field   name    [  \"  )     +    currentFieldName )     +     \"  ]  \"  )  )  ;", "}", "} else", "if    ( token    =  =     ( Token . START _ OBJECT )  )     {", "if    (  . DOCUMENT _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "if    ( documentsSpecified )     {", "throw   new   IllegalArgumentException (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    Either   specified    [ document ]    or    [ documents ]  ,    not   both \"  )  )  ;", "}", "documentSpecified    =    true ;", "try    ( XContentBuilder   builder    =    jsonBuilder (  )  )     {", "builder . copyCurrentStructure ( parser )  ;", "builder . flush (  )  ;", "documents . add ( BytesReference . bytes ( builder )  )  ;", "}", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    query   does   not   support   field   name    [  \"  )     +    currentFieldName )     +     \"  ]  \"  )  )  ;", "}", "} else", "if    (  ( token . isValue (  )  )     |  |     ( token    =  =     ( Token . VALUE _ NULL )  )  )     {", "if    (  . QUERY _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "field    =    parser . text (  )  ;", "} else", "if    (  . NAME _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "name    =    parser . textOrNull (  )  ;", "} else", "if    (  . DOCUMENT _ TYPE _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "documentType    =    parser . textOrNull (  )  ;", "} else", "if    (  . INDEXED _ DOCUMENT _ FIELD _ INDEX . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "indexedDocumentIndex    =    parser . text (  )  ;", "} else", "if    (  . INDEXED _ DOCUMENT _ FIELD _ TYPE . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "indexedDocumentType    =    parser . text (  )  ;", "} else", "if    (  . INDEXED _ DOCUMENT _ FIELD _ ID . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "indexedDocumentId    =    parser . text (  )  ;", "} else", "if    (  . INDEXED _ DOCUMENT _ FIELD _ ROUTING . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "indexedDocumentRouting    =    parser . text (  )  ;", "} else", "if    (  . INDEXED _ DOCUMENT _ FIELD _ PREFERENCE . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "indexedDocumentPreference    =    parser . text (  )  ;", "} else", "if    (  . INDEXED _ DOCUMENT _ FIELD _ VERSION . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "indexedDocumentVersion    =    parser . longValue (  )  ;", "} else", "if    ( AbstractQueryBuilder . BOOST _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "boost    =    parser . floatValue (  )  ;", "} else", "if    ( AbstractQueryBuilder . NAME _ FIELD . match ( currentFieldName ,    parser . getDeprecationHandler (  )  )  )     {", "queryName    =    parser . text (  )  ;", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    query   does   not   support    [  \"  )     +    currentFieldName )     +     \"  ]  \"  )  )  ;", "}", "} else    {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     (  (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    query   does   not   support    [  \"  )     +    token )     +     \"  ]  \"  )  )  ;", "}", "}", "queryBuilder ;", "if    (  ( documents . isEmpty (  )  )     =  =    false )     {", "queryBuilder    =    new    ( field ,    documentType ,    documents ,    XContentType . JSON )  ;", "} else", "if    ( indexedDocumentId    !  =    null )     {", "queryBuilder    =    new    ( field ,    documentType ,    indexedDocumentIndex ,    indexedDocumentType ,    indexedDocumentId ,    indexedDocumentRouting ,    indexedDocumentPreference ,    indexedDocumentVersion )  ;", "} else    {", "throw   new   IllegalArgumentException (  (  (  \"  [  \"     +     (  . NAME )  )     +     \"  ]    query ,    nothing   to   percolate \"  )  )  ;", "}", "if    ( name    !  =    null )     {", "queryBuilder . setName ( name )  ;", "}", "queryBuilder . queryName ( queryName )  ;", "queryBuilder . boost ( boost )  ;", "return   queryBuilder ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   documentType ;", "}", "METHOD_END"], "methodName": ["getDocumentType"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   documents ;", "}", "METHOD_END"], "methodName": ["getDocuments"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   field ;", "}", "METHOD_END"], "methodName": ["getField"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   documentXContentType ;", "}", "METHOD_END"], "methodName": ["getXContentType"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "this . name    =    name ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setName"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "return   new   QueryShardContext ( shardContext )     {", "@ Override", "public   BitSetProducer   bitsetFilter ( Query   query )     {", "return    (    context )     -  >     {", "final   IndexReaderContext   topLevelContext    =    ReaderUtil . getTopLevelContext ( context )  ;", "final   IndexSearcher   searcher    =    new   IndexSearcher ( topLevelContext )  ;", "searcher . setQueryCache ( null )  ;", "final   Weight   weight    =    searcher . createNormalizedWeight ( query ,    false )  ;", "final   Scorer   s    =    weight . scorer ( context )  ;", "if    ( s    !  =    null )     {", "return   new   BitDocIdSet ( BitSet . of ( s . iterator (  )  ,    context . reader (  )  . maxDoc (  )  )  )  . bits (  )  ;", "} else    {", "return   null ;", "}", "}  ;", "}", "@ Override", "@ SuppressWarnings (  \" unchecked \"  )", "public    < IFD   extends   IndexFieldData <  ?  >  >    IFD   getForField ( MappedFieldType   fieldType )     {", "IndexFieldData .    builder    =    fieldType . fielddata ( shardContext . getFullyQualifiedIndexName (  )  )  ;", "IndexFieldDataCache   cache    =    new   IndexFieldDataCache . None (  )  ;", "CircuitBreakerService   circuitBreaker    =    new   NoneCircuitBreakerService (  )  ;", "return    (  ( IFD )     ( builder . build ( shardContext . getIndexSettings (  )  ,    fieldType ,    cache ,    circuitBreaker ,    shardContext . getMapperService (  )  )  )  )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["wrap"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "if    ( indexedDocument )     {", "documentSource    =    Collections . singletonList (  . randomSource ( new   HashSet <  >  (  )  )  )  ;", "} else    {", "int   numDocs    =    randomIntBetween (  1  ,     8  )  ;", "documentSource    =    new   ArrayList ( numDocs )  ;", "Set < String >    usedFields    =    new   HashSet <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "documentSource . add (  . randomSource ( usedFields )  )  ;", "}", "}", "PercolateQueryBuilder   queryBuilder ;", "if    ( indexedDocument )     {", "indexedDocumentIndex    =    randomAlphaOfLength (  4  )  ;", "indexedDocumentType    =     \" doc \"  ;", "indexedDocumentId    =    randomAlphaOfLength (  4  )  ;", "indexedDocumentRouting    =    randomAlphaOfLength (  4  )  ;", "indexedDocumentPreference    =    randomAlphaOfLength (  4  )  ;", "indexedDocumentVersion    =     (  ( long )     ( randomIntBetween (  0  ,    Integer . MAX _ VALUE )  )  )  ;", "queryBuilder    =    new   PercolateQueryBuilder (  . queryField ,     . docType ,    indexedDocumentIndex ,    indexedDocumentType ,    indexedDocumentId ,    indexedDocumentRouting ,    indexedDocumentPreference ,    indexedDocumentVersion )  ;", "} else    {", "queryBuilder    =    new   PercolateQueryBuilder (  . queryField ,     . docType ,    documentSource ,    XContentType . JSON )  ;", "}", "if    ( randomBoolean (  )  )     {", "queryBuilder . setName ( randomAlphaOfLength (  4  )  )  ;", "}", "return   queryBuilder ;", "}", "METHOD_END"], "methodName": ["doCreateTestQueryBuilder"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "try    {", "Map < String ,     ?  >    source ;", "boolean   duplicateField ;", "do    {", "duplicateField    =    false ;", "source    =    RandomDocumentPicks . randomSource ( random (  )  )  ;", "for    ( String   field    :    source . keySet (  )  )     {", "if    (  ( usedFields . add ( field )  )     =  =    false )     {", "duplicateField    =    true ;", "break ;", "}", "}", "}    while    ( duplicateField    )  ;", "XContent   xContent    =    XContentFactory . json (  )  ;", "xContent . map ( source )  ;", "return   BytesReference . bytes ( xContent )  ;", "}    catch    ( IOException   e )     {", "throw   new   UncheckedIOException ( e )  ;", "}", "}", "METHOD_END"], "methodName": ["randomSource"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    parseQuery (  (  (  \"  {  \\  \" percolate \\  \"     :     {     \\  \" document \\  \"  :     {  }  ,     \\  \" documents \\  \"  :     [  {  }  ,     {  }  ]  ,     \\  \" field \\  \"  :  \\  \"  \"     +     ( PercolateQueryBuilderTests . queryField )  )     +     \"  \\  \"  }  }  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testBothDocumentAndDocumentsSpecified"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "int   numDocs    =    randomIntBetween (  2  ,     8  )  ;", "List < ParsedDocument >    docs    =    new   ArrayList <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "docs . add ( new   ParsedDocument ( null ,    null ,     \"  _ id \"  ,     \"  _ type \"  ,    null ,    Collections . singletonList ( new   ParseContext . Document (  )  )  ,    null ,    null ,    null )  )  ;", "}", "Analyzer   analyzer    =    new   WhitespaceAnalyzer (  )  ;", "IndexSearcher   indexSearcher    =     . createMultiDocumentSearcher ( analyzer ,    docs )  ;", "assertThat ( indexSearcher . getIndexReader (  )  . numDocs (  )  ,    equalTo ( numDocs )  )  ;", "Query   query    =    new   MatchAllDocsQuery (  )  ;", "BooleanQuery   result    =     (  ( BooleanQuery )     ( indexSearcher . createNormalizedWeight ( query ,    true )  . getQuery (  )  )  )  ;", "assertThat ( result . clauses (  )  . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( result . clauses (  )  . get (  0  )  . getQuery (  )  ,    sameInstance ( query )  )  ;", "assertThat ( result . clauses (  )  . get (  0  )  . getOccur (  )  ,    equalTo ( MUST )  )  ;", "assertThat ( result . clauses (  )  . get (  1  )  . getOccur (  )  ,    equalTo ( MUST _ NOT )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateMultiDocumentSearcher"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "int   numNestedDocs    =    randomIntBetween (  2  ,     8  )  ;", "List < ParseContext . Document >    docs    =    new   ArrayList <  >  ( numNestedDocs )  ;", "for    ( int   i    =     0  ;    i    <    numNestedDocs ;    i +  +  )     {", "docs . add ( new   ParseContext . Document (  )  )  ;", "}", "Collection < ParsedDocument >    parsedDocument    =    Collections . singleton ( new   ParsedDocument ( null ,    null ,     \"  _ id \"  ,     \"  _ type \"  ,    null ,    docs ,    null ,    null ,    null )  )  ;", "Analyzer   analyzer    =    new   WhitespaceAnalyzer (  )  ;", "IndexSearcher   indexSearcher    =     . createMultiDocumentSearcher ( analyzer ,    parsedDocument )  ;", "assertThat ( indexSearcher . getIndexReader (  )  . numDocs (  )  ,    equalTo ( numNestedDocs )  )  ;", "Query   query    =    new   MatchAllDocsQuery (  )  ;", "BooleanQuery   result    =     (  ( BooleanQuery )     ( indexSearcher . createNormalizedWeight ( query ,    true )  . getQuery (  )  )  )  ;", "assertThat ( result . clauses (  )  . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( result . clauses (  )  . get (  0  )  . getQuery (  )  ,    sameInstance ( query )  )  ;", "assertThat ( result . clauses (  )  . get (  0  )  . getOccur (  )  ,    equalTo ( MUST )  )  ;", "assertThat ( result . clauses (  )  . get (  1  )  . getOccur (  )  ,    equalTo ( MUST _ NOT )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateNestedDocumentSearcher"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "QueryShardContext   queryShardContext    =    createShardContext (  )  ;", "QueryBuilder   queryBuilder    =    parseQuery (  (  (  \"  {  \\  \" percolate \\  \"     :     {     \\  \" document \\  \"  :     {  }  ,     \\  \" field \\  \"  :  \\  \"  \"     +     (  . queryField )  )     +     \"  \\  \"  }  }  \"  )  )  ;", "queryBuilder . toQuery ( queryShardContext )  ;", "}", "METHOD_END"], "methodName": ["testFromJsonNoDocumentType"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "indexedDocumentExists    =    false ;", "pqb    =    doCreateTestQueryBuilder ( true )  ;", "ResourceNotFoundException   e    =    expectThrows ( ResourceNotFoundException . class ,     (  )     -  >    rewriteAndFetch ( pqb ,    createShardContext (  )  )  )  ;", "String   expectedString    =     (  (  (  (  (  \" indexed   document    [  \"     +     ( indexedDocumentIndex )  )     +     \"  /  \"  )     +     ( indexedDocumentType )  )     +     \"  /  \"  )     +     ( indexedDocumentId )  )     +     \"  ]    couldn ' t   be   found \"  ;", "assertThat ( e . getMessage (  )  ,    equalTo ( expectedString )  )  ;", "}", "METHOD_END"], "methodName": ["testIndexedDocumentDoesNotExist"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "new    ( null ,    new   BytesArray (  \"  {  }  \"  )  ,    XContentType . JSON )  ;", "}  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    is   a   required   argument \"  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new    (  \"  _ field \"  ,     \"  _ document _ type \"  ,    null ,    null )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ document ]    is   a   required   argument \"  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "new    ( null ,    null ,     \"  _ index \"  ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null )  ;", "}  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ field ]    is   a   required   argument \"  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "new    (  \"  _ field \"  ,     \"  _ document _ type \"  ,    null ,     \"  _ type \"  ,     \"  _ id \"  ,    null ,    null ,    null )  ;", "}  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ index ]    is   a   required   argument \"  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "new    (  \"  _ field \"  ,     \"  _ document _ type \"  ,     \"  _ index \"  ,    null ,     \"  _ id \"  ,    null ,    null ,    null )  ;", "}  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ type ]    is   a   required   argument \"  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "new    (  \"  _ field \"  ,     \"  _ document _ type \"  ,     \"  _ index \"  ,     \"  _ type \"  ,    null ,    null ,    null ,    null )  ;", "}  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \"  [ id ]    is   a   required   argument \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testRequiredParameters"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "final   byte [  ]    data    =    Base 6  4  . getDecoder (  )  . decode (  \" P 4 AAAAAFZmllbGQEdHlwZQAAAAAAAA 5  7 ImZvbyI 6 ImJhciJ 9 AAAAAA =  =  \"  )  ;", "final   Version   version    =    randomFrom ( V _  5  _  0  _  0  ,    V _  5  _  0  _  1  ,    V _  5  _  0  _  2  ,    V _  5  _  1  _  1  ,    V _  5  _  1  _  2  ,    V _  5  _  2  _  0  )  ;", "try    ( StreamInput   in    =    StreamInput . wrap ( data )  )     {", "in . setVersion ( version )  ;", "queryBuilder    =    new    ( in )  ;", "assertEquals (  \" type \"  ,    queryBuilder . getDocumentType (  )  )  ;", "assertEquals (  \" field \"  ,    queryBuilder . getField (  )  )  ;", "assertEquals (  \"  {  \\  \" foo \\  \"  :  \\  \" bar \\  \"  }  \"  ,    queryBuilder . getDocuments (  )  . iterator (  )  . next (  )  . utf 8 ToString (  )  )  ;", "assertEquals ( JSON ,    queryBuilder . getXContentType (  )  )  ;", "try    ( BytesStreamOutput   out    =    new   BytesStreamOutput (  )  )     {", "out . setVersion ( version )  ;", "queryBuilder . writeTo ( out )  ;", "assertArrayEquals ( data ,    out . bytes (  )  . toBytesRef (  )  . bytes )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testSerializationBwc"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "QueryBuilder   builder    =    doCreateTestQueryBuilder ( true )  ;", "QueryBuilder   queryBuilder    =    Rewriteable . rewrite ( builder ,    createShardContext (  )  )  ;", "IllegalStateException   ise    =    expectThrows ( IllegalStateException . class ,     (  )     -  >    queryBuilder . writeTo ( new   BytesStreamOutput (  1  0  )  )  )  ;", "assertEquals ( ise . getMessage (  )  ,     \" supplier   must   be   null ,    can ' t   serialize   suppliers ,    missing   a   rewriteAndFetch ?  \"  )  ;", "builder    =    rewriteAndFetch ( builder ,    createShardContext (  )  )  ;", "builder . writeTo ( new   BytesStreamOutput (  1  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testSerializationFailsUnlessFetched"], "fileName": "org.elasticsearch.percolator.PercolateQueryBuilderTests"}, {"methodBody": ["METHOD_START", "{", "directoryReader . close (  )  ;", "directory . close (  )  ;", "}", "METHOD_END"], "methodName": ["destroy"], "fileName": "org.elasticsearch.percolator.PercolateQueryTests"}, {"methodBody": ["METHOD_START", "{", "directory    =    newDirectory (  )  ;", "IndexWriterConfig   config    =    new   IndexWriterConfig ( new   WhitespaceAnalyzer (  )  )  ;", "config . setMergePolicy ( INSTANCE )  ;", "indexWriter    =    new   apache . lucene . index . IndexWriter ( directory ,    config )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.percolator.PercolateQueryTests"}, {"methodBody": ["METHOD_START", "{", "List < Iterable <  ?    extends   IndexableField >  >    docs    =    new   ArrayList <  >  (  )  ;", "List < Query >    queries    =    new   ArrayList <  >  (  )  ;", ". QueryStore   queryStore    =     (    ctx )     -  >    queries :  : get ;", "queries . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" fox \"  )  )  )  ;", "docs . add ( Collections . singleton ( new   StringField (  \" select \"  ,     \" a \"  ,    Store . NO )  )  )  ;", "SpanNearQuery . Builder   snp    =    new   SpanNearQuery . Builder (  \" field \"  ,    true )  ;", "snp . addClause ( new   SpanTermQuery ( new   Term (  \" field \"  ,     \" jumps \"  )  )  )  ;", "snp . addClause ( new   SpanTermQuery ( new   Term (  \" field \"  ,     \" lazy \"  )  )  )  ;", "snp . addClause ( new   SpanTermQuery ( new   Term (  \" field \"  ,     \" dog \"  )  )  )  ;", "snp . setSlop (  2  )  ;", "queries . add ( snp . build (  )  )  ;", "docs . add ( Collections . singleton ( new   StringField (  \" select \"  ,     \" b \"  ,    Store . NO )  )  )  ;", "PhraseQuery . Builder   pq 1     =    new   PhraseQuery . Builder (  )  ;", "pq 1  . add ( new   Term (  \" field \"  ,     \" quick \"  )  )  ;", "pq 1  . add ( new   Term (  \" field \"  ,     \" brown \"  )  )  ;", "pq 1  . add ( new   Term (  \" field \"  ,     \" jumps \"  )  )  ;", "pq 1  . setSlop (  1  )  ;", "queries . add ( pq 1  . build (  )  )  ;", "docs . add ( Collections . singleton ( new   StringField (  \" select \"  ,     \" b \"  ,    Store . NO )  )  )  ;", "BooleanQuery . Builder   bq 1     =    new   BooleanQuery . Builder (  )  ;", "bq 1  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" quick \"  )  )  ,    MUST )  ;", "bq 1  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" brown \"  )  )  ,    MUST )  ;", "bq 1  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" fox \"  )  )  ,    MUST )  ;", "queries . add ( bq 1  . build (  )  )  ;", "docs . add ( Collections . singleton ( new   StringField (  \" select \"  ,     \" b \"  ,    Store . NO )  )  )  ;", "indexWriter . addDocuments ( docs )  ;", "indexWriter . close (  )  ;", "directoryReader    =    DirectoryReader . open ( directory )  ;", "IndexSearcher   shardSearcher    =    newSearcher ( directoryReader )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" the   quick   brown   fox   jumps   over   the   lazy   dog \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexSearcher   percolateSearcher    =    memoryIndex . createSearcher (  )  ;", "Query   query    =    new   ConstantScoreQuery ( new    (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \" a \"  )  )  ,    new   TermQuery ( new   Term (  \" select \"  ,     \" a \"  )  )  ,    percolateSearcher ,    new   MatchNoDocsQuery (  \"  \"  )  )  )  ;", "TopDocs   topDocs    =    shardSearcher . search ( query ,     1  0  )  ;", "assertThat ( topDocs . totalHits ,    equalTo (  1 L )  )  ;", "assertThat ( topDocs . scoreDocs . length ,    equalTo (  1  )  )  ;", "assertThat ( topDocs . scoreDocs [  0  ]  . doc ,    equalTo (  0  )  )  ;", "Explanation   explanation    =    shardSearcher . explain ( query ,     0  )  ;", "assertThat ( explanation . isMatch (  )  ,    is ( true )  )  ;", "assertThat ( explanation . getValue (  )  ,    equalTo ( topDocs . scoreDocs [  0  ]  . score )  )  ;", "query    =    new   ConstantScoreQuery ( new    (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \" b \"  )  )  ,    new   TermQuery ( new   Term (  \" select \"  ,     \" b \"  )  )  ,    percolateSearcher ,    new   MatchNoDocsQuery (  \"  \"  )  )  )  ;", "topDocs    =    shardSearcher . search ( query ,     1  0  )  ;", "assertThat ( topDocs . totalHits ,    equalTo (  3 L )  )  ;", "assertThat ( topDocs . scoreDocs . length ,    equalTo (  3  )  )  ;", "assertThat ( topDocs . scoreDocs [  0  ]  . doc ,    equalTo (  1  )  )  ;", "explanation    =    shardSearcher . explain ( query ,     1  )  ;", "assertThat ( explanation . isMatch (  )  ,    is ( true )  )  ;", "assertThat ( explanation . getValue (  )  ,    equalTo ( topDocs . scoreDocs [  0  ]  . score )  )  ;", "assertThat ( topDocs . scoreDocs [  1  ]  . doc ,    equalTo (  2  )  )  ;", "explanation    =    shardSearcher . explain ( query ,     2  )  ;", "assertThat ( explanation . isMatch (  )  ,    is ( true )  )  ;", "assertThat ( explanation . getValue (  )  ,    equalTo ( topDocs . scoreDocs [  1  ]  . score )  )  ;", "assertThat ( topDocs . scoreDocs [  2  ]  . doc ,    equalTo (  3  )  )  ;", "explanation    =    shardSearcher . explain ( query ,     2  )  ;", "assertThat ( explanation . isMatch (  )  ,    is ( true )  )  ;", "assertThat ( explanation . getValue (  )  ,    equalTo ( topDocs . scoreDocs [  2  ]  . score )  )  ;", "query    =    new   ConstantScoreQuery ( new    (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \" c \"  )  )  ,    new   MatchAllDocsQuery (  )  ,    percolateSearcher ,    new   MatchAllDocsQuery (  )  )  )  ;", "topDocs    =    shardSearcher . search ( query ,     1  0  )  ;", "assertThat ( topDocs . totalHits ,    equalTo (  4 L )  )  ;", "query    =    new    (  \"  _ name \"  ,    queryStore ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ,    new   TermQuery ( new   Term (  \" select \"  ,     \" b \"  )  )  ,    percolateSearcher ,    new   MatchNoDocsQuery (  \"  \"  )  )  ;", "topDocs    =    shardSearcher . search ( query ,     1  0  )  ;", "assertThat ( topDocs . totalHits ,    equalTo (  3 L )  )  ;", "assertThat ( topDocs . scoreDocs . length ,    equalTo (  3  )  )  ;", "assertThat ( topDocs . scoreDocs [  0  ]  . doc ,    equalTo (  3  )  )  ;", "explanation    =    shardSearcher . explain ( query ,     3  )  ;", "assertThat ( explanation . isMatch (  )  ,    is ( true )  )  ;", "assertThat ( explanation . getValue (  )  ,    equalTo ( topDocs . scoreDocs [  0  ]  . score )  )  ;", "assertThat ( explanation . getDetails (  )  ,    arrayWithSize (  1  )  )  ;", "assertThat ( topDocs . scoreDocs [  1  ]  . doc ,    equalTo (  2  )  )  ;", "explanation    =    shardSearcher . explain ( query ,     2  )  ;", "assertThat ( explanation . isMatch (  )  ,    is ( true )  )  ;", "assertThat ( explanation . getValue (  )  ,    equalTo ( topDocs . scoreDocs [  1  ]  . score )  )  ;", "assertThat ( explanation . getDetails (  )  ,    arrayWithSize (  1  )  )  ;", "assertThat ( topDocs . scoreDocs [  2  ]  . doc ,    equalTo (  1  )  )  ;", "explanation    =    shardSearcher . explain ( query ,     1  )  ;", "assertThat ( explanation . isMatch (  )  ,    is ( true )  )  ;", "assertThat ( explanation . getValue (  )  ,    equalTo ( topDocs . scoreDocs [  2  ]  . score )  )  ;", "assertThat ( explanation . getDetails (  )  ,    arrayWithSize (  1  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolateQuery"], "fileName": "org.elasticsearch.percolator.PercolateQueryTests"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.percolator.PercolatorClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "if    ( indexVersion . onOrAfter ( V _  6  _  0  _  0  _ beta 2  )  )     {", "try    ( ByteArrayOutputStream   stream    =    new   ByteArrayOutputStream (  )  )     {", "try    ( OutputStreamStreamOutput   out    =    new   OutputStreamStreamOutput ( stream )  )     {", "out . setVersion ( indexVersion )  ;", "out . writeNamedWriteable ( queryBuilder )  ;", "byte [  ]    queryBuilderAsBytes    =    stream . toByteArray (  )  ;", "qbField . parse ( context . createExternalValueContext ( queryBuilderAsBytes )  )  ;", "}", "}", "} else    {", "try    ( XContentBuilder   builder    =    XContentFactory . contentBuilder (  . QUERY _ BUILDER _ CONTENT _ TYPE )  )     {", "queryBuilder . toXContent ( builder ,    new   MapParams ( Collections . emptyMap (  )  )  )  ;", "builder . flush (  )  ;", "byte [  ]    queryBuilderAsBytes    =    BytesReference . toBytes ( BytesReference . bytes ( builder )  )  ;", "context . doc (  )  . add ( new   Field ( qbField . name (  )  ,    queryBuilderAsBytes ,    qbField . fieldType (  )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["createQueryBuilderField"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapper"}, {"methodBody": ["METHOD_START", "{", "assert    ( minEncoded . length )     =  =     ( maxEncoded . length )  ;", "byte [  ]    bytes    =    new   byte [  ( BinaryRange . BYTES )     *     2  ]  ;", "BytesRef   fieldAsBytesRef    =    new   BytesRef ( rangeName )  ;", "MurmurHash 3  . Hash 1  2  8    hash    =    new   MurmurHash 3  . Hash 1  2  8  (  )  ;", "MurmurHash 3  . hash 1  2  8  ( fieldAsBytesRef . bytes ,    fieldAsBytesRef . offset ,    fieldAsBytesRef . length ,     0  ,    hash )  ;", "ByteBuffer   bb    =    ByteBuffer . wrap ( bytes )  ;", "bb . putLong ( hash . h 1  )  . putLong ( hash . h 2  )  . putLong ( hash . h 1  )  . putLong ( hash . h 2  )  ;", "assert    ( bb . position (  )  )     =  =     ( bb . limit (  )  )  ;", "int   offset    =     ( BinaryRange . BYTES )     -     ( minEncoded . length )  ;", "System . arraycopy ( minEncoded ,     0  ,    bytes ,    offset ,    minEncoded . length )  ;", "System . arraycopy ( maxEncoded ,     0  ,    bytes ,     (  ( BinaryRange . BYTES )     +    offset )  ,    maxEncoded . length )  ;", "return   bytes ;", "}", "METHOD_END"], "methodName": ["encodeRange"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   PercolatorFieldMapper . INDEX _ MAP _ UNMAPPED _ FIELDS _ AS _ TEXT _ SETTING . get ( indexSettings )  ;", "}", "METHOD_END"], "methodName": ["getMapUnmappedFieldAsText"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   mapUnmappedFieldAsText ;", "}", "METHOD_END"], "methodName": ["isMapUnmappedFieldAsText"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapper"}, {"methodBody": ["METHOD_START", "{", "return   PercolatorFieldMapper . toQuery ( context ,    mapUnmappedFieldsAsString ,    PercolatorFieldMapper . parseQueryBuilder ( parser ,    parser . getTokenLocation (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["parseQuery"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapper"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   parseInnerQueryBuilder ( parser )  ;", "}    catch    ( IOException   e )     {", "throw   new   common . ParsingException ( location ,     \" Failed   to   parse \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["parseQueryBuilder"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapper"}, {"methodBody": ["METHOD_START", "{", "ParseContext . Document   doc    =    context . doc (  )  ;", ". FieldType   pft    =     (  (  . FieldType )     ( this . fieldType (  )  )  )  ;", "QueryAnalyzer . Result   result ;", "try    {", "Version   indexVersion    =    context . mapperService (  )  . getIndexSettings (  )  . getIndexVersionCreated (  )  ;", "result    =    QueryAnalyzer . analyze ( query ,    indexVersion )  ;", "}    catch    ( QueryAnalyzer . UnsupportedQueryException   e )     {", "doc . add ( new   Field ( pft . extractionResultField . name (  )  ,     . EXTRACTION _ FAILED ,    extractionResultField . fieldType (  )  )  )  ;", "return ;", "}", "for    ( QueryAnalyzer . QueryExtraction   extraction    :    result . extractions )     {", "if    (  ( extraction . term )     !  =    null )     {", "BytesRefBuilder   builder    =    new   BytesRefBuilder (  )  ;", "builder . append ( new   BytesRef ( extraction . field (  )  )  )  ;", "builder . append (  . FIELD _ VALUE _ SEPARATOR )  ;", "builder . append ( extraction . bytes (  )  )  ;", "doc . add ( new   Field ( queryTermsField . name (  )  ,    builder . toBytesRef (  )  ,    queryTermsField . fieldType (  )  )  )  ;", "} else", "if    (  ( extraction . range )     !  =    null )     {", "byte [  ]    min    =    extraction . range . lowerPoint ;", "byte [  ]    max    =    extraction . range . upperPoint ;", "doc . add ( new   BinaryRange ( rangeFieldMapper . name (  )  ,     . encodeRange ( extraction . range . fieldName ,    min ,    max )  )  )  ;", "}", "}", "Version   indexVersionCreated    =    context . mapperService (  )  . getIndexSettings (  )  . getIndexVersionCreated (  )  ;", "if    ( result . matchAllDocs )     {", "doc . add ( new   Field ( extractionResultField . name (  )  ,     . EXTRACTION _ FAILED ,    extractionResultField . fieldType (  )  )  )  ;", "if    ( result . verified )     {", "doc . add ( new   Field ( extractionResultField . name (  )  ,     . EXTRACTION _ COMPLETE ,    extractionResultField . fieldType (  )  )  )  ;", "}", "} else", "if    ( result . verified )     {", "doc . add ( new   Field ( extractionResultField . name (  )  ,     . EXTRACTION _ COMPLETE ,    extractionResultField . fieldType (  )  )  )  ;", "} else    {", "doc . add ( new   Field ( extractionResultField . name (  )  ,     . EXTRACTION _ PARTIAL ,    extractionResultField . fieldType (  )  )  )  ;", "}", "List < IndexableField >    fields    =    new   ArrayList <  >  (  1  )  ;", "createFieldNamesField ( context ,    fields )  ;", "for    ( IndexableField   field    :    fields )     {", "context . doc (  )  . add ( field )  ;", "}", "if    ( indexVersionCreated . onOrAfter ( V _  6  _  1  _  0  )  )     {", "doc . add ( new   NumericDocValuesField ( minimumShouldMatchFieldMapper . name (  )  ,    result . minimumShouldMatch )  )  ;", "}", "}", "METHOD_END"], "methodName": ["processQuery"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapper"}, {"methodBody": ["METHOD_START", "{", "context . setAllowUnmappedFields ( false )  ;", "context . setMapUnmappedFieldAsString ( mapUnmappedFieldsAsString )  ;", "return   queryBuilder . toQuery ( context )  ;", "}", "METHOD_END"], "methodName": ["toQuery"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapper"}, {"methodBody": ["METHOD_START", "{", "if    ( queryBuilder . getName (  )  . equals (  \" has _ child \"  )  )     {", "throw   new   IllegalArgumentException (  \" the    [ has _ child ]    query   is   unsupported   inside   a   percolator   query \"  )  ;", "} else", "if    ( queryBuilder . getName (  )  . equals (  \" has _ parent \"  )  )     {", "throw   new   IllegalArgumentException (  \" the    [ has _ parent ]    query   is   unsupported   inside   a   percolator   query \"  )  ;", "} else", "if    ( queryBuilder   instanceof   BoolQueryBuilder )     {", "BoolQueryBuilder   boolQueryBuilder    =     (  ( BoolQueryBuilder )     ( queryBuilder )  )  ;", "List < QueryBuilder >    clauses    =    new   ArrayList <  >  (  )  ;", "clauses . addAll ( boolQueryBuilder . filter (  )  )  ;", "clauses . addAll ( boolQueryBuilder . must (  )  )  ;", "clauses . addAll ( boolQueryBuilder . mustNot (  )  )  ;", "clauses . addAll ( boolQueryBuilder . should (  )  )  ;", "for    ( QueryBuilder   clause    :    clauses )     {", ". verifyQuery ( clause )  ;", "}", "} else", "if    ( queryBuilder   instanceof   ConstantScoreQueryBuilder )     {", ". verifyQuery (  (  ( ConstantScoreQueryBuilder )     ( queryBuilder )  )  . innerQuery (  )  )  ;", "} else", "if    ( queryBuilder   instanceof   FunctionScoreQueryBuilder )     {", ". verifyQuery (  (  ( FunctionScoreQueryBuilder )     ( queryBuilder )  )  . query (  )  )  ;", "} else", "if    ( queryBuilder   instanceof   BoostingQueryBuilder )     {", ". verifyQuery (  (  ( BoostingQueryBuilder )     ( queryBuilder )  )  . negativeQuery (  )  )  ;", ". verifyQuery (  (  ( BoostingQueryBuilder )     ( queryBuilder )  )  . positiveQuery (  )  )  ;", "} else", "if    ( queryBuilder   instanceof   DisMaxQueryBuilder )     {", "DisMaxQueryBuilder   disMaxQueryBuilder    =     (  ( DisMaxQueryBuilder )     ( queryBuilder )  )  ;", "for    ( QueryBuilder   innerQueryBuilder    :    disMaxQueryBuilder . innerQueries (  )  )     {", ". verifyQuery ( innerQueryBuilder )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["verifyQuery"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapper"}, {"methodBody": ["METHOD_START", "{", "fieldName    =    randomAlphaOfLength (  4  )  ;", "String   percolatorMapper    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" doc \"  )  . startObject (  \" properties \"  )  . startObject ( fieldName )  . field (  \" type \"  ,     \" percolator \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "mapperService . merge (  \" doc \"  ,    new   CompressedXContent ( percolatorMapper )  ,    MAPPING _ UPDATE )  ;", "fieldType    =     (  (  . FieldType )     ( mapperService . fullName ( fieldName )  )  )  ;", "}", "METHOD_END"], "methodName": ["addQueryFieldMappings"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "try    ( InputStream   in    =    new   ByteArrayInputStream ( actual . bytes ,    actual . offset ,    actual . length )  )     {", "try    ( StreamInput   input    =    new   common . io . stream . NamedWriteableAwareStreamInput ( new   InputStreamStreamInput ( in )  ,    writableRegistry (  )  )  )     {", "input . readVInt (  )  ;", "input . readVInt (  )  ;", "QueryBuilder   queryBuilder    =    input . readNamedWriteable ( QueryBuilder . class )  ;", "assertThat ( queryBuilder ,    equalTo ( expected )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["assertQueryBuilder"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "indexService    =    createIndex (  \" test \"  )  ;", "mService    =    indexService . mService (  )  ;", "String   m    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" doc \"  )  . startObject (  \"  _ field _ names \"  )  . field (  \" enabled \"  ,    false )  . endObject (  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . startObject (  \" field 1  \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . startObject (  \" field 2  \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . startObject (  \"  _ field 3  \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . startObject (  \" field 4  \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . startObject (  \" number _ field 1  \"  )  . field (  \" type \"  ,     \" integer \"  )  . endObject (  )  . startObject (  \" number _ field 2  \"  )  . field (  \" type \"  ,     \" long \"  )  . endObject (  )  . startObject (  \" number _ field 3  \"  )  . field (  \" type \"  ,     \" long \"  )  . endObject (  )  . startObject (  \" number _ field 4  \"  )  . field (  \" type \"  ,     \" half _ float \"  )  . endObject (  )  . startObject (  \" number _ field 5  \"  )  . field (  \" type \"  ,     \" float \"  )  . endObject (  )  . startObject (  \" number _ field 6  \"  )  . field (  \" type \"  ,     \" double \"  )  . endObject (  )  . startObject (  \" number _ field 7  \"  )  . field (  \" type \"  ,     \" ip \"  )  . endObject (  )  . startObject (  \" date _ field \"  )  . field (  \" type \"  ,     \" date \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "mService . merge (  \" doc \"  ,    new   CompressedXContent ( m )  ,    MAPPING _ UPDATE )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "return   Arrays . copyOfRange ( source ,    offset ,     ( offset    +    length )  )  ;", "}", "METHOD_END"], "methodName": ["subByteArray"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "IndexService   indexService    =    createIndex (  \" test 1  \"  ,    EMPTY )  ;", "MapperService   mapperService    =    indexService . mapperService (  )  ;", "String   Mapper    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" doc \"  )  . startObject (  \" properties \"  )  . startObject ( fieldName )  . field (  \" type \"  ,     \"  \"  )  . field (  \" index \"  ,     \" no \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "MapperParsingException   e    =    expectThrows ( MapperParsingException . class ,     (  )     -  >    mapperService . merge (  \" doc \"  ,    new   CompressedXContent ( Mapper )  ,    MapperService . MergeReason . MAPPING _ UPDATE )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  (  (  \" Mapping   definition   for    [  \"     +     ( fieldName )  )     +     \"  ]    has   unsupported   parameters :        [ index    :    no ]  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testAllowNoAdditionalSettings"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex ( false )  ;", "StringBuilder   text    =    new   StringBuilder (  )  ;", "for    ( int   i    =     0  ;    i    <     1  0  2  2  ;    i +  +  )     {", "text . append ( i )  . append (  '     '  )  ;", "}", "memoryIndex . addField (  \" field 1  \"  ,    text . toString (  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   LongPoint (  \" field 2  \"  ,     1  0 L )  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexReader   indexReader    =    memoryIndex . createSearcher (  )  . getIndexReader (  )  ;", "Tuple < BooleanQuery ,    Boolean >    t    =    fieldType . createCandidateQuery ( indexReader ,    CURRENT )  ;", "assertTrue ( t . v 2  (  )  )  ;", "assertEquals (  2  ,    t . v 1  (  )  . clauses (  )  . size (  )  )  ;", "assertThat ( t . v 1  (  )  . clauses (  )  . get (  0  )  . getQuery (  )  ,    instanceOf ( CoveringQuery . class )  )  ;", "assertThat ( t . v 1  (  )  . clauses (  )  . get (  1  )  . getQuery (  )  ,    instanceOf ( TermQuery . class )  )  ;", "memoryIndex . addField (  \" field 2  \"  ,     \" value \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "indexReader    =    memoryIndex . createSearcher (  )  . getIndexReader (  )  ;", "t    =    fieldType . createCandidateQuery ( indexReader ,    CURRENT )  ;", "assertFalse ( t . v 2  (  )  )  ;", "assertEquals (  3  ,    t . v 1  (  )  . clauses (  )  . size (  )  )  ;", "TermInSetQuery   terms    =     (  ( TermInSetQuery )     ( t . v 1  (  )  . clauses (  )  . get (  0  )  . getQuery (  )  )  )  ;", "assertEquals (  1  0  2  3  ,    terms . getTermData (  )  . size (  )  )  ;", "assertThat ( t . v 1  (  )  . clauses (  )  . get (  1  )  . getQuery (  )  . toString (  )  ,    containsString (  (  ( fieldName )     +     \"  . range _ field :  < ranges :  \"  )  )  )  ;", "assertThat ( t . v 1  (  )  . clauses (  )  . get (  2  )  . getQuery (  )  . toString (  )  ,    containsString (  (  ( fieldName )     +     \"  . extraction _ result : failed \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateCandidateQuery"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex ( false )  ;", "memoryIndex . addField (  \" field 1  \"  ,     \" value 1  \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexReader   indexReader    =    memoryIndex . createSearcher (  )  . getIndexReader (  )  ;", "Tuple < BooleanQuery ,    Boolean >    t    =    fieldType . createCandidateQuery ( indexReader ,    CURRENT )  ;", "assertTrue ( t . v 2  (  )  )  ;", "assertEquals (  2  ,    t . v 1  (  )  . clauses (  )  . size (  )  )  ;", "assertThat ( t . v 1  (  )  . clauses (  )  . get (  0  )  . getQuery (  )  ,    instanceOf ( CoveringQuery . class )  )  ;", "assertThat ( t . v 1  (  )  . clauses (  )  . get (  1  )  . getQuery (  )  ,    instanceOf ( TermQuery . class )  )  ;", "t    =    fieldType . createCandidateQuery ( indexReader ,    V _  6  _  0  _  0  )  ;", "assertTrue ( t . v 2  (  )  )  ;", "assertEquals (  2  ,    t . v 1  (  )  . clauses (  )  . size (  )  )  ;", "assertThat ( t . v 1  (  )  . clauses (  )  . get (  0  )  . getQuery (  )  ,    instanceOf ( TermInSetQuery . class )  )  ;", "assertThat ( t . v 1  (  )  . clauses (  )  . get (  1  )  . getQuery (  )  ,    instanceOf ( TermQuery . class )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateCandidateQuery_oldIndex"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "QueryBuilder   qb    =    boolQuery (  )  . must ( boolQuery (  )  . must ( termQuery (  \" field \"  ,     \" value 1  \"  )  )  . must ( termQuery (  \" field \"  ,     \" value 2  \"  )  )  )  . must ( boolQuery (  )  . must ( termQuery (  \" field \"  ,     \" value 2  \"  )  )  . must ( termQuery (  \" field \"  ,     \" value 3  \"  )  )  )  ;", "ParsedDocument   doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field ( fieldName ,    qb )  . endObject (  )  )  ,    JSON )  )  ;", "List < String >    values    =    Arrays . stream ( doc . rootDoc (  )  . getFields ( fieldType . queryTermsField . name (  )  )  )  . map (  (    f )     -  >    f . binaryValue (  )  . utf 8 ToString (  )  )  . sorted (  )  . collect ( Collectors . toList (  )  )  ;", "assertThat ( values . size (  )  ,    equalTo (  3  )  )  ;", "assertThat ( values . get (  0  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 1  \"  )  )  ;", "assertThat ( values . get (  1  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 2  \"  )  )  ;", "assertThat ( values . get (  2  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 3  \"  )  )  ;", "int   msm    =    doc . rootDoc (  )  . getFields ( fieldType . minimumShouldMatchField . name (  )  )  [  0  ]  . numericValue (  )  . intValue (  )  ;", "assertThat ( msm ,    equalTo (  2  )  )  ;", "qb    =    boolQuery (  )  . must ( boolQuery (  )  . must ( termQuery (  \" field \"  ,     \" value 1  \"  )  )  . must ( termQuery (  \" field \"  ,     \" value 2  \"  )  )  )  . must ( boolQuery (  )  . must ( termQuery (  \" field \"  ,     \" value 2  \"  )  )  . must ( termQuery (  \" field \"  ,     \" value 3  \"  )  )  )  . must ( boolQuery (  )  . must ( termQuery (  \" field \"  ,     \" value 3  \"  )  )  . must ( termQuery (  \" field \"  ,     \" value 4  \"  )  )  )  . must ( boolQuery (  )  . should ( termQuery (  \" field \"  ,     \" value 4  \"  )  )  . should ( termQuery (  \" field \"  ,     \" value 5  \"  )  )  )  ;", "doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field ( fieldName ,    qb )  . endObject (  )  )  ,    JSON )  )  ;", "values    =    Arrays . stream ( doc . rootDoc (  )  . getFields ( fieldType . queryTermsField . name (  )  )  )  . map (  (    f )     -  >    f . binaryValue (  )  . utf 8 ToString (  )  )  . sorted (  )  . collect ( Collectors . toList (  )  )  ;", "assertThat ( values . size (  )  ,    equalTo (  5  )  )  ;", "assertThat ( values . get (  0  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 1  \"  )  )  ;", "assertThat ( values . get (  1  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 2  \"  )  )  ;", "assertThat ( values . get (  2  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 3  \"  )  )  ;", "assertThat ( values . get (  3  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 4  \"  )  )  ;", "assertThat ( values . get (  4  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 5  \"  )  )  ;", "msm    =    doc . rootDoc (  )  . getFields ( fieldType . minimumShouldMatchField . name (  )  )  [  0  ]  . numericValue (  )  . intValue (  )  ;", "assertThat ( msm ,    equalTo (  2  )  )  ;", "qb    =    boolQuery (  )  . minimumShouldMatch (  3  )  . should ( boolQuery (  )  . should ( termQuery (  \" field \"  ,     \" value 1  \"  )  )  . should ( termQuery (  \" field \"  ,     \" value 2  \"  )  )  )  . should ( boolQuery (  )  . should ( termQuery (  \" field \"  ,     \" value 2  \"  )  )  . should ( termQuery (  \" field \"  ,     \" value 3  \"  )  )  )  . should ( boolQuery (  )  . should ( termQuery (  \" field \"  ,     \" value 3  \"  )  )  . should ( termQuery (  \" field \"  ,     \" value 4  \"  )  )  )  . should ( boolQuery (  )  . should ( termQuery (  \" field \"  ,     \" value 4  \"  )  )  . should ( termQuery (  \" field \"  ,     \" value 5  \"  )  )  )  ;", "doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field ( fieldName ,    qb )  . endObject (  )  )  ,    JSON )  )  ;", "values    =    Arrays . stream ( doc . rootDoc (  )  . getFields ( fieldType . queryTermsField . name (  )  )  )  . map (  (    f )     -  >    f . binaryValue (  )  . utf 8 ToString (  )  )  . sorted (  )  . collect ( Collectors . toList (  )  )  ;", "assertThat ( values . size (  )  ,    equalTo (  5  )  )  ;", "assertThat ( values . get (  0  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 1  \"  )  )  ;", "assertThat ( values . get (  1  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 2  \"  )  )  ;", "assertThat ( values . get (  2  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 3  \"  )  )  ;", "assertThat ( values . get (  3  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 4  \"  )  )  ;", "assertThat ( values . get (  4  )  ,    equalTo (  \" field \\ u 0  0  0  0 value 5  \"  )  )  ;", "msm    =    doc . rootDoc (  )  . getFields ( fieldType . minimumShouldMatchField . name (  )  )  [  0  ]  . numericValue (  )  . intValue (  )  ;", "assertThat ( msm ,    equalTo (  1  )  )  ;", "}", "METHOD_END"], "methodName": ["testDuplicatedClauses"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type 1  \"  )  . startObject (  \" properties \"  )  . startObject (  \"  \"  )  . field (  \" type \"  ,     \" percolator \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "DocumentMapperParser   parser    =    mapperService . documentMapperParser (  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    parser . parse (  \" type 1  \"  ,    new   CompressedXContent ( mapping )  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" name   cannot   be   empty   string \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmptyName"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "int   iters    =    randomIntBetween (  3  2  ,     2  5  6  )  ;", "for    ( int   i    =     0  ;    i    <    iters ;    i +  +  )     {", "int   encodingType    =    randomInt (  1  )  ;", "final   int   randomFrom    =    randomInt (  )  ;", "final   byte [  ]    encodedFrom ;", "switch    ( encodingType )     {", "case    0     :", "encodedFrom    =    new   byte [ Integer . BYTES ]  ;", "IntPoint . encodeDimension ( randomFrom ,    encodedFrom ,     0  )  ;", "break ;", "case    1     :", "encodedFrom    =    new   byte [ Long . BYTES ]  ;", "LongPoint . encodeDimension ( randomFrom ,    encodedFrom ,     0  )  ;", "break ;", "default    :", "throw   new   AssertionError (  (  (  \" unexpected   encoding   type    [  \"     +    encodingType )     +     \"  ]  \"  )  )  ;", "}", "final   int   randomTo    =    randomIntBetween ( randomFrom ,    Integer . MAX _ VALUE )  ;", "final   byte [  ]    encodedTo ;", "switch    ( encodingType )     {", "case    0     :", "encodedTo    =    new   byte [ Integer . BYTES ]  ;", "IntPoint . encodeDimension ( randomTo ,    encodedTo ,     0  )  ;", "break ;", "case    1     :", "encodedTo    =    new   byte [ Long . BYTES ]  ;", "LongPoint . encodeDimension ( randomTo ,    encodedTo ,     0  )  ;", "break ;", "default    :", "throw   new   AssertionError (  (  (  \" unexpected   encoding   type    [  \"     +    encodingType )     +     \"  ]  \"  )  )  ;", "}", "String   fieldName    =    randomAlphaOfLength (  5  )  ;", "byte [  ]    result    =    PercolatorFieldMapper . encodeRange ( fieldName ,    encodedFrom ,    encodedTo )  ;", "assertEquals (  3  2  ,    result . length )  ;", "BytesRef   fieldAsBytesRef    =    new   BytesRef ( fieldName )  ;", "MurmurHash 3  . Hash 1  2  8    hash    =    new   MurmurHash 3  . Hash 1  2  8  (  )  ;", "MurmurHash 3  . hash 1  2  8  ( fieldAsBytesRef . bytes ,    fieldAsBytesRef . offset ,    fieldAsBytesRef . length ,     0  ,    hash )  ;", "switch    ( encodingType )     {", "case    0     :", "assertEquals ( hash . h 1  ,    ByteBuffer . wrap (  . subByteArray ( result ,     0  ,     8  )  )  . getLong (  )  )  ;", "assertEquals ( randomFrom ,    IntPoint . decodeDimension (  . subByteArray ( result ,     1  2  ,     4  )  ,     0  )  )  ;", "assertEquals ( hash . h 1  ,    ByteBuffer . wrap (  . subByteArray ( result ,     1  6  ,     8  )  )  . getLong (  )  )  ;", "assertEquals ( randomTo ,    IntPoint . decodeDimension (  . subByteArray ( result ,     2  8  ,     4  )  ,     0  )  )  ;", "break ;", "case    1     :", "assertEquals ( hash . h 1  ,    ByteBuffer . wrap (  . subByteArray ( result ,     0  ,     8  )  )  . getLong (  )  )  ;", "assertEquals ( randomFrom ,    LongPoint . decodeDimension (  . subByteArray ( result ,     8  ,     8  )  ,     0  )  )  ;", "assertEquals ( hash . h 1  ,    ByteBuffer . wrap (  . subByteArray ( result ,     1  6  ,     8  )  )  . getLong (  )  )  ;", "assertEquals ( randomTo ,    LongPoint . decodeDimension (  . subByteArray ( result ,     2  4  ,     8  )  ,     0  )  )  ;", "break ;", "default    :", "throw   new   AssertionError (  (  (  \" unexpected   encoding   type    [  \"     +    encodingType )     +     \"  ]  \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testEncodeRange"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "BooleanQuery . Builder   bq    =    new   BooleanQuery . Builder (  )  ;", "Query   rangeQuery 1     =    mapperService . documentMapper (  \" doc \"  )  . mappers (  )  . getMapper (  \" number _ field 1  \"  )  . fieldType (  )  . rangeQuery (  1  0  ,     2  0  ,    true ,    true ,    null ,    null ,    null ,    null )  ;", "bq . add ( rangeQuery 1  ,    MUST )  ;", "Query   rangeQuery 2     =    mapperService . documentMapper (  \" doc \"  )  . mappers (  )  . getMapper (  \" number _ field 1  \"  )  . fieldType (  )  . rangeQuery (  1  5  ,     2  0  ,    true ,    true ,    null ,    null ,    null ,    null )  ;", "bq . add ( rangeQuery 2  ,    MUST )  ;", "DocumentMapper   documentMapper    =    mapperService . documentMapper (  \" doc \"  )  ;", "fieldMapper    =     (  (  )     ( documentMapper . mappers (  )  . getMapper ( fieldName )  )  )  ;", "ParseContext . InternalParseContext   parseContext    =    new   ParseContext . InternalParseContext ( Settings . EMPTY ,    mapperService . documentMapperParser (  )  ,    documentMapper ,    null ,    null )  ;", "fieldMapper . processQuery ( bq . build (  )  ,    parseContext )  ;", "ParseContext . Document   document    =    parseContext . doc (  )  ;", ". FieldType   fieldType    =     (  (  . FieldType )     ( fieldMapper . fieldType (  )  )  )  ;", "assertThat ( document . getField ( fieldType . extractionResultField . name (  )  )  . stringValue (  )  ,    equalTo (  . EXTRACTION _ PARTIAL )  )  ;", "List < IndexableField >    fields    =    new   ArrayList ( Arrays . asList ( document . getFields ( fieldType . rangeField . name (  )  )  )  )  ;", "fields . sort ( Comparator . comparing ( IndexableField :  : binaryValue )  )  ;", "assertThat ( fields . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( IntPoint . decodeDimension ( fields . get (  0  )  . binaryValue (  )  . bytes ,     1  2  )  ,    equalTo (  1  0  )  )  ;", "assertThat ( IntPoint . decodeDimension ( fields . get (  0  )  . binaryValue (  )  . bytes ,     2  8  )  ,    equalTo (  2  0  )  )  ;", "assertThat ( IntPoint . decodeDimension ( fields . get (  1  )  . binaryValue (  )  . bytes ,     1  2  )  ,    equalTo (  1  5  )  )  ;", "assertThat ( IntPoint . decodeDimension ( fields . get (  1  )  . binaryValue (  )  . bytes ,     2  8  )  ,    equalTo (  2  0  )  )  ;", "fields    =    new   ArrayList ( Arrays . asList ( document . getFields ( fieldType . minimumShouldMatchField . name (  )  )  )  )  ;", "assertThat ( fields . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( fields . get (  0  )  . numericValue (  )  ,    equalTo (  1 L )  )  ;", "bq    =    new   BooleanQuery . Builder (  )  ;", "bq . add ( rangeQuery 1  ,    MUST )  ;", "rangeQuery 2     =    mapperService . documentMapper (  \" doc \"  )  . mappers (  )  . getMapper (  \" number _ field 2  \"  )  . fieldType (  )  . rangeQuery (  1  5  ,     2  0  ,    true ,    true ,    null ,    null ,    null ,    null )  ;", "bq . add ( rangeQuery 2  ,    MUST )  ;", "parseContext    =    new   ParseContext . InternalParseContext ( Settings . EMPTY ,    mapperService . documentMapperParser (  )  ,    documentMapper ,    null ,    null )  ;", "fieldMapper . processQuery ( bq . build (  )  ,    parseContext )  ;", "document    =    parseContext . doc (  )  ;", "assertThat ( document . getField ( fieldType . extractionResultField . name (  )  )  . stringValue (  )  ,    equalTo (  . EXTRACTION _ PARTIAL )  )  ;", "fields    =    new   ArrayList ( Arrays . asList ( document . getFields ( fieldType . rangeField . name (  )  )  )  )  ;", "fields . sort ( Comparator . comparing ( IndexableField :  : binaryValue )  )  ;", "assertThat ( fields . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( IntPoint . decodeDimension ( fields . get (  0  )  . binaryValue (  )  . bytes ,     1  2  )  ,    equalTo (  1  0  )  )  ;", "assertThat ( IntPoint . decodeDimension ( fields . get (  0  )  . binaryValue (  )  . bytes ,     2  8  )  ,    equalTo (  2  0  )  )  ;", "assertThat ( LongPoint . decodeDimension ( fields . get (  1  )  . binaryValue (  )  . bytes ,     8  )  ,    equalTo (  1  5 L )  )  ;", "assertThat ( LongPoint . decodeDimension ( fields . get (  1  )  . binaryValue (  )  . bytes ,     2  4  )  ,    equalTo (  2  0 L )  )  ;", "fields    =    new   ArrayList ( Arrays . asList ( document . getFields ( fieldType . minimumShouldMatchField . name (  )  )  )  )  ;", "assertThat ( fields . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( fields . get (  0  )  . numericValue (  )  ,    equalTo (  2 L )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractRanges"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "BooleanQuery . Builder   bq    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \" field \"  ,     \" term 1  \"  )  )  ;", "bq . add ( termQuery 1  ,    SHOULD )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( new   Term (  \" field \"  ,     \" term 2  \"  )  )  ;", "bq . add ( termQuery 2  ,    SHOULD )  ;", "DocumentMapper   documentMapper    =    mapperService . documentMapper (  \" doc \"  )  ;", "fieldMapper    =     (  (  )     ( documentMapper . mappers (  )  . getMapper ( fieldName )  )  )  ;", "ParseContext . InternalParseContext   parseContext    =    new   ParseContext . InternalParseContext ( Settings . EMPTY ,    mapperService . documentMapperParser (  )  ,    documentMapper ,    null ,    null )  ;", "fieldMapper . processQuery ( bq . build (  )  ,    parseContext )  ;", "ParseContext . Document   document    =    parseContext . doc (  )  ;", ". FieldType   fieldType    =     (  (  . FieldType )     ( fieldMapper . fieldType (  )  )  )  ;", "assertThat ( document . getField ( fieldType . extractionResultField . name (  )  )  . stringValue (  )  ,    equalTo (  . EXTRACTION _ COMPLETE )  )  ;", "List < IndexableField >    fields    =    new   ArrayList ( Arrays . asList ( document . getFields ( fieldType . queryTermsField . name (  )  )  )  )  ;", "fields . sort ( Comparator . comparing ( IndexableField :  : binaryValue )  )  ;", "assertThat ( fields . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( fields . get (  0  )  . binaryValue (  )  . utf 8 ToString (  )  ,    equalTo (  \" field \\ u 0  0  0  0 term 1  \"  )  )  ;", "assertThat ( fields . get (  1  )  . binaryValue (  )  . utf 8 ToString (  )  ,    equalTo (  \" field \\ u 0  0  0  0 term 2  \"  )  )  ;", "fields    =    new   ArrayList ( Arrays . asList ( document . getFields ( fieldType . minimumShouldMatchField . name (  )  )  )  )  ;", "assertThat ( fields . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( fields . get (  0  )  . numericValue (  )  ,    equalTo (  1 L )  )  ;", "bq    =    new   BooleanQuery . Builder (  )  ;", "bq . add ( termQuery 1  ,    MUST )  ;", "bq . add ( termQuery 2  ,    MUST )  ;", "parseContext    =    new   ParseContext . InternalParseContext ( Settings . EMPTY ,    mapperService . documentMapperParser (  )  ,    documentMapper ,    null ,    null )  ;", "fieldMapper . processQuery ( bq . build (  )  ,    parseContext )  ;", "document    =    parseContext . doc (  )  ;", "assertThat ( document . getField ( fieldType . extractionResultField . name (  )  )  . stringValue (  )  ,    equalTo (  . EXTRACTION _ COMPLETE )  )  ;", "fields    =    new   ArrayList ( Arrays . asList ( document . getFields ( fieldType . queryTermsField . name (  )  )  )  )  ;", "fields . sort ( Comparator . comparing ( IndexableField :  : binaryValue )  )  ;", "assertThat ( fields . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( fields . get (  0  )  . binaryValue (  )  . utf 8 ToString (  )  ,    equalTo (  \" field \\ u 0  0  0  0 term 1  \"  )  )  ;", "assertThat ( fields . get (  1  )  . binaryValue (  )  . utf 8 ToString (  )  ,    equalTo (  \" field \\ u 0  0  0  0 term 2  \"  )  )  ;", "fields    =    new   ArrayList ( Arrays . asList ( document . getFields ( fieldType . minimumShouldMatchField . name (  )  )  )  )  ;", "assertThat ( fields . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( fields . get (  0  )  . numericValue (  )  ,    equalTo (  2 L )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractTerms"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex ( false )  ;", "memoryIndex . addField (  \" field 1  \"  ,     \" the   quick   brown   fox   jumps   over   the   lazy   dog \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField (  \" field 2  \"  ,     \" some   more   text \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField (  \"  _ field 3  \"  ,     \" unhide   me \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField (  \" field 4  \"  ,     \"  1  2  3  \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   LongPoint (  \" number _ field 2  \"  ,     1  0 L )  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexReader   indexReader    =    memoryIndex . createSearcher (  )  . getIndexReader (  )  ;", "Tuple < List < BytesRef >  ,    Map < String ,    List < byte [  ]  >  >  >    t    =    fieldType . extractTermsAndRanges ( indexReader )  ;", "assertEquals (  1  ,    t . v 2  (  )  . size (  )  )  ;", "Map < String ,    List < byte [  ]  >  >    rangesMap    =    t . v 2  (  )  ;", "assertEquals (  1  ,    rangesMap . size (  )  )  ;", "List < byte [  ]  >    range    =    rangesMap . get (  \" number _ field 2  \"  )  ;", "assertNotNull ( range )  ;", "assertEquals (  1  0  ,    LongPoint . decodeDimension ( range . get (  0  )  ,     0  )  )  ;", "assertEquals (  1  0  ,    LongPoint . decodeDimension ( range . get (  1  )  ,     0  )  )  ;", "List < BytesRef >    terms    =    t . v 1  (  )  ;", "terms . sort ( BytesRef :  : compareTo )  ;", "assertEquals (  1  4  ,    terms . size (  )  )  ;", "assertEquals (  \"  _ field 3  \\ u 0  0  0  0 me \"  ,    terms . get (  0  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \"  _ field 3  \\ u 0  0  0  0 unhide \"  ,    terms . get (  1  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 1  \\ u 0  0  0  0 brown \"  ,    terms . get (  2  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 1  \\ u 0  0  0  0 dog \"  ,    terms . get (  3  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 1  \\ u 0  0  0  0 fox \"  ,    terms . get (  4  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 1  \\ u 0  0  0  0 jumps \"  ,    terms . get (  5  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 1  \\ u 0  0  0  0 lazy \"  ,    terms . get (  6  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 1  \\ u 0  0  0  0 over \"  ,    terms . get (  7  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 1  \\ u 0  0  0  0 quick \"  ,    terms . get (  8  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 1  \\ u 0  0  0  0 the \"  ,    terms . get (  9  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 2  \\ u 0  0  0  0 more \"  ,    terms . get (  1  0  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 2  \\ u 0  0  0  0 some \"  ,    terms . get (  1  1  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 2  \\ u 0  0  0  0 text \"  ,    terms . get (  1  2  )  . utf 8 ToString (  )  )  ;", "assertEquals (  \" field 4  \\ u 0  0  0  0  1  2  3  \"  ,    terms . get (  1  3  )  . utf 8 ToString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractTermsAndRanges"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "TermRangeQuery   query    =    new   TermRangeQuery (  \" field 1  \"  ,    new   BytesRef (  \" a \"  )  ,    new   BytesRef (  \" z \"  )  ,    true ,    true )  ;", "DocumentMapper   documentMapper    =    mapperService . documentMapper (  \" doc \"  )  ;", "fieldMapper    =     (  (  )     ( documentMapper . mappers (  )  . getMapper ( fieldName )  )  )  ;", "ParseContext . InternalParseContext   parseContext    =    new   ParseContext . InternalParseContext ( Settings . EMPTY ,    mapperService . documentMapperParser (  )  ,    documentMapper ,    null ,    null )  ;", "fieldMapper . processQuery ( query ,    parseContext )  ;", "ParseContext . Document   document    =    parseContext . doc (  )  ;", ". FieldType   fieldType    =     (  (  . FieldType )     ( fieldMapper . fieldType (  )  )  )  ;", "assertThat ( document . getFields (  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( document . getField ( fieldType . extractionResultField . name (  )  )  . stringValue (  )  ,    equalTo (  . EXTRACTION _ FAILED )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractTermsAndRanges_failed"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex ( false )  ;", "memoryIndex . addField ( new   IntPoint (  \" number _ field 1  \"  ,     1  0  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   LongPoint (  \" number _ field 2  \"  ,     2  0 L )  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   LongPoint (  \" number _ field 3  \"  ,     3  0 L )  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   HalfFloatPoint (  \" number _ field 4  \"  ,     3  0  .  0 F )  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   FloatPoint (  \" number _ field 5  \"  ,     4  0  .  0 F )  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   DoublePoint (  \" number _ field 6  \"  ,     5  0  .  0 F )  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   InetAddressPoint (  \" number _ field 7  \"  ,    InetAddresses . forString (  \"  1  9  2  .  1  6  8  .  1  .  1  2  \"  )  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   InetAddressPoint (  \" number _ field 7  \"  ,    InetAddresses . forString (  \"  1  9  2  .  1  6  8  .  1  .  2  0  \"  )  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "memoryIndex . addField ( new   InetAddressPoint (  \" number _ field 7  \"  ,    InetAddresses . forString (  \"  1  9  2  .  1  6  8  .  1  .  2  4  \"  )  )  ,    new   WhitespaceAnalyzer (  )  )  ;", "IndexReader   indexReader    =    memoryIndex . createSearcher (  )  . getIndexReader (  )  ;", "Tuple < List < BytesRef >  ,    Map < String ,    List < byte [  ]  >  >  >    t    =    fieldType . extractTermsAndRanges ( indexReader )  ;", "assertEquals (  0  ,    t . v 1  (  )  . size (  )  )  ;", "Map < String ,    List < byte [  ]  >  >    rangesMap    =    t . v 2  (  )  ;", "assertEquals (  7  ,    rangesMap . size (  )  )  ;", "List < byte [  ]  >    range    =    rangesMap . get (  \" number _ field 1  \"  )  ;", "assertNotNull ( range )  ;", "assertEquals (  1  0  ,    IntPoint . decodeDimension ( range . get (  0  )  ,     0  )  )  ;", "assertEquals (  1  0  ,    IntPoint . decodeDimension ( range . get (  1  )  ,     0  )  )  ;", "range    =    rangesMap . get (  \" number _ field 2  \"  )  ;", "assertNotNull ( range )  ;", "assertEquals (  2  0 L ,    LongPoint . decodeDimension ( range . get (  0  )  ,     0  )  )  ;", "assertEquals (  2  0 L ,    LongPoint . decodeDimension ( range . get (  1  )  ,     0  )  )  ;", "range    =    rangesMap . get (  \" number _ field 3  \"  )  ;", "assertNotNull ( range )  ;", "assertEquals (  3  0 L ,    LongPoint . decodeDimension ( range . get (  0  )  ,     0  )  )  ;", "assertEquals (  3  0 L ,    LongPoint . decodeDimension ( range . get (  1  )  ,     0  )  )  ;", "range    =    rangesMap . get (  \" number _ field 4  \"  )  ;", "assertNotNull ( range )  ;", "assertEquals (  3  0  .  0 F ,    HalfFloatPoint . decodeDimension ( range . get (  0  )  ,     0  )  ,     0  .  0 F )  ;", "assertEquals (  3  0  .  0 F ,    HalfFloatPoint . decodeDimension ( range . get (  1  )  ,     0  )  ,     0  .  0 F )  ;", "range    =    rangesMap . get (  \" number _ field 5  \"  )  ;", "assertNotNull ( range )  ;", "assertEquals (  4  0  .  0 F ,    FloatPoint . decodeDimension ( range . get (  0  )  ,     0  )  ,     0  .  0 F )  ;", "assertEquals (  4  0  .  0 F ,    FloatPoint . decodeDimension ( range . get (  1  )  ,     0  )  ,     0  .  0 F )  ;", "range    =    rangesMap . get (  \" number _ field 6  \"  )  ;", "assertNotNull ( range )  ;", "assertEquals (  5  0  .  0  ,    DoublePoint . decodeDimension ( range . get (  0  )  ,     0  )  ,     0  .  0  )  ;", "assertEquals (  5  0  .  0  ,    DoublePoint . decodeDimension ( range . get (  1  )  ,     0  )  ,     0  .  0  )  ;", "range    =    rangesMap . get (  \" number _ field 7  \"  )  ;", "assertNotNull ( range )  ;", "assertEquals ( InetAddresses . forString (  \"  1  9  2  .  1  6  8  .  1  .  1  2  \"  )  ,    InetAddressPoint . decode ( range . get (  0  )  )  )  ;", "assertEquals ( InetAddresses . forString (  \"  1  9  2  .  1  6  8  .  1  .  2  4  \"  )  ,    InetAddressPoint . decode ( range . get (  1  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractTermsAndRanges_numberFields"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "PhraseQuery   phraseQuery    =    new   PhraseQuery (  \" field \"  ,     \" term \"  )  ;", "DocumentMapper   documentMapper    =    mapperService . documentMapper (  \" doc \"  )  ;", "fieldMapper    =     (  (  )     ( documentMapper . mappers (  )  . getMapper ( fieldName )  )  )  ;", "ParseContext . InternalParseContext   parseContext    =    new   ParseContext . InternalParseContext ( Settings . EMPTY ,    mapperService . documentMapperParser (  )  ,    documentMapper ,    null ,    null )  ;", "fieldMapper . processQuery ( phraseQuery ,    parseContext )  ;", "ParseContext . Document   document    =    parseContext . doc (  )  ;", ". FieldType   fieldType    =     (  (  . FieldType )     ( fieldMapper . fieldType (  )  )  )  ;", "assertThat ( document . getFields (  )  . size (  )  ,    equalTo (  3  )  )  ;", "assertThat ( document . getFields (  )  . get (  0  )  . binaryValue (  )  . utf 8 ToString (  )  ,    equalTo (  \" field \\ u 0  0  0  0 term \"  )  )  ;", "assertThat ( document . getField ( fieldType . extractionResultField . name (  )  )  . stringValue (  )  ,    equalTo (  . EXTRACTION _ PARTIAL )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractTermsAndRanges_partial"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "XContentBuilder   query    =    jsonBuilder (  )  ;", "query . startObject (  )  ;", "query . startObject (  \" script \"  )  ;", "if    ( randomBoolean (  )  )     {", "query . field (  \" script \"  ,     \" return   true \"  )  ;", "} else    {", "query . startObject (  \" script \"  )  ;", "query . field (  \" source \"  ,     \" return   true \"  )  ;", "query . endObject (  )  ;", "}", "query . endObject (  )  ;", "query . endObject (  )  ;", "ParsedDocument   doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . rawField ( fieldName ,    new   common . bytes . BytesArray ( Strings . toString ( query )  )  . streamInput (  )  ,    query . contentType (  )  )  . endObject (  )  )  ,    JSON )  )  ;", "BytesRef   querySource    =    doc . rootDoc (  )  . getFields ( fieldType . queryBuilderField . name (  )  )  [  0  ]  . binaryValue (  )  ;", "try    ( InputStream   in    =    new   ByteArrayInputStream ( querySource . bytes ,    querySource . offset ,    querySource . length )  )     {", "try    ( StreamInput   input    =    new   common . io . stream . NamedWriteableAwareStreamInput ( new   InputStreamStreamInput ( in )  ,    writableRegistry (  )  )  )     {", "input . readVInt (  )  ;", "input . readVInt (  )  ;", "ScriptQueryBuilder   queryBuilder    =     (  ( ScriptQueryBuilder )     ( input . readNamedWriteable ( QueryBuilder . class )  )  )  ;", "assertEquals ( DEFAULT _ SCRIPT _ LANG ,    queryBuilder . script (  )  . getLang (  )  )  ;", "}", "}", "query    =    jsonBuilder (  )  ;", "query . startObject (  )  ;", "query . startObject (  \" function _ score \"  )  ;", "query . startArray (  \" functions \"  )  ;", "query . startObject (  )  ;", "query . startObject (  \" script _ score \"  )  ;", "if    ( randomBoolean (  )  )     {", "query . field (  \" script \"  ,     \" return   true \"  )  ;", "} else    {", "query . startObject (  \" script \"  )  ;", "query . field (  \" source \"  ,     \" return   true \"  )  ;", "query . endObject (  )  ;", "}", "query . endObject (  )  ;", "query . endObject (  )  ;", "query . endArray (  )  ;", "query . endObject (  )  ;", "query . endObject (  )  ;", "doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . rawField ( fieldName ,    new   common . bytes . BytesArray ( Strings . toString ( query )  )  . streamInput (  )  ,    query . contentType (  )  )  . endObject (  )  )  ,    JSON )  )  ;", "querySource    =    doc . rootDoc (  )  . getFields ( fieldType . queryBuilderField . name (  )  )  [  0  ]  . binaryValue (  )  ;", "try    ( InputStream   in    =    new   ByteArrayInputStream ( querySource . bytes ,    querySource . offset ,    querySource . length )  )     {", "try    ( StreamInput   input    =    new   common . io . stream . NamedWriteableAwareStreamInput ( new   InputStreamStreamInput ( in )  ,    writableRegistry (  )  )  )     {", "input . readVInt (  )  ;", "input . readVInt (  )  ;", "FunctionScoreQueryBuilder   queryBuilder    =     (  ( FunctionScoreQueryBuilder )     ( input . readNamedWriteable ( QueryBuilder . class )  )  )  ;", "ScriptScoreFunctionBuilder   function    =     (  ( ScriptScoreFunctionBuilder )     ( queryBuilder . filterFunctionBuilders (  )  [  0  ]  . getScoreFunction (  )  )  )  ;", "assertEquals ( DEFAULT _ SCRIPT _ LANG ,    function . getScript (  )  . getLang (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testImplicitlySetDefaultScriptLang"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   typeName    =     \" doc \"  ;", "String   Mapper    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject ( typeName )  . startObject (  \"  _ field _ names \"  )  . field (  \" enabled \"  ,    false )  . endObject (  )  . startObject (  \" properties \"  )  . startObject (  \" query _ field 1  \"  )  . field (  \" type \"  ,     \"  \"  )  . endObject (  )  . startObject (  \" query _ field 2  \"  )  . field (  \" type \"  ,     \"  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "mapperService . merge ( typeName ,    new   CompressedXContent ( Mapper )  ,    MAPPING _ UPDATE )  ;", "QueryBuilder   queryBuilder    =    matchQuery (  \" field \"  ,     \" value \"  )  ;", "ParsedDocument   doc    =    mapperService . documentMapper ( typeName )  . parse ( SourceToParse . source (  \" test \"  ,    typeName ,     \"  1  \"  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" query _ field 1  \"  ,    queryBuilder )  . field (  \" query _ field 2  \"  ,    queryBuilder )  . endObject (  )  )  ,    JSON )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields (  )  . size (  )  ,    equalTo (  1  4  )  )  ;", "BytesRef   queryBuilderAsBytes    =    doc . rootDoc (  )  . getField (  \" query _ field 1  . query _ builder _ field \"  )  . binaryValue (  )  ;", "assertQueryBuilder ( queryBuilderAsBytes ,    queryBuilder )  ;", "queryBuilderAsBytes    =    doc . rootDoc (  )  . getField (  \" query _ field 2  . query _ builder _ field \"  )  . binaryValue (  )  ;", "assertQueryBuilder ( queryBuilderAsBytes ,    queryBuilder )  ;", "}", "METHOD_END"], "methodName": ["testMultiplePercolatorFields"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "String   typeName    =     \" doc \"  ;", "String   Mapper    =    Strings . toString ( XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject ( typeName )  . startObject (  \"  _ field _ names \"  )  . field (  \" enabled \"  ,    false )  . endObject (  )  . startObject (  \" properties \"  )  . startObject (  \" object _ field \"  )  . field (  \" type \"  ,     \" object \"  )  . startObject (  \" properties \"  )  . startObject (  \" query _ field \"  )  . field (  \" type \"  ,     \"  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "mapperService . merge ( typeName ,    new   CompressedXContent ( Mapper )  ,    MAPPING _ UPDATE )  ;", "QueryBuilder   queryBuilder    =    matchQuery (  \" field \"  ,     \" value \"  )  ;", "ParsedDocument   doc    =    mapperService . documentMapper ( typeName )  . parse ( SourceToParse . source (  \" test \"  ,    typeName ,     \"  1  \"  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . startObject (  \" object _ field \"  )  . field (  \" query _ field \"  ,    queryBuilder )  . endObject (  )  . endObject (  )  )  ,    JSON )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields (  )  . size (  )  ,    equalTo (  1  0  )  )  ;", "BytesRef   queryBuilderAsBytes    =    doc . rootDoc (  )  . getField (  \" object _ field . query _ field . query _ builder _ field \"  )  . binaryValue (  )  ;", "assertQueryBuilder ( queryBuilderAsBytes ,    queryBuilder )  ;", "doc    =    mapperService . documentMapper ( typeName )  . parse ( SourceToParse . source (  \" test \"  ,    typeName ,     \"  1  \"  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . startArray (  \" object _ field \"  )  . startObject (  )  . field (  \" query _ field \"  ,    queryBuilder )  . endObject (  )  . endArray (  )  . endObject (  )  )  ,    JSON )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields (  )  . size (  )  ,    equalTo (  1  0  )  )  ;", "queryBuilderAsBytes    =    doc . rootDoc (  )  . getField (  \" object _ field . query _ field . query _ builder _ field \"  )  . binaryValue (  )  ;", "assertQueryBuilder ( queryBuilderAsBytes ,    queryBuilder )  ;", "MapperParsingException   e    =    expectThrows ( MapperParsingException . class ,     (  )     -  >     {", "mapperService . documentMapper ( typeName )  . parse ( SourceToParse . source (  \" test \"  ,    typeName ,     \"  1  \"  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . startArray (  \" object _ field \"  )  . startObject (  )  . field (  \" query _ field \"  ,    queryBuilder )  . endObject (  )  . startObject (  )  . field (  \" query _ field \"  ,    queryBuilder )  . endObject (  )  . endArray (  )  . endObject (  )  )  ,    XContentType . JSON )  )  ;", "}  )  ;", "assertThat ( e . getCause (  )  ,    instanceOf ( IllegalArgumentException . class )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    equalTo (  \" a   document   can   only   contain   one      query \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testNestedPercolatorField"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "QueryBuilder   queryBuilder    =    termQuery (  \" field \"  ,     \" value \"  )  ;", "ParsedDocument   doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field ( fieldName ,    queryBuilder )  . endObject (  )  )  ,    JSON )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . queryTermsField . name (  )  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . queryTermsField . name (  )  )  [  0  ]  . binaryValue (  )  . utf 8 ToString (  )  ,    equalTo (  \" field \\ u 0  0  0  0 value \"  )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . queryBuilderField . name (  )  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . extractionResultField . name (  )  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . extractionResultField . name (  )  )  [  0  ]  . stringValue (  )  ,    equalTo (  . EXTRACTION _ COMPLETE )  )  ;", "BytesRef   qbSource    =    doc . rootDoc (  )  . getFields ( fieldType . queryBuilderField . name (  )  )  [  0  ]  . binaryValue (  )  ;", "assertQueryBuilder ( qbSource ,    queryBuilder )  ;", "queryBuilder    =    rangeQuery (  \" field \"  )  . from (  \" a \"  )  . to (  \" z \"  )  ;", "doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field ( fieldName ,    queryBuilder )  . endObject (  )  )  ,    JSON )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . extractionResultField . name (  )  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . extractionResultField . name (  )  )  [  0  ]  . stringValue (  )  ,    equalTo (  . EXTRACTION _ FAILED )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . queryTermsField . name (  )  )  . length ,    equalTo (  0  )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . queryBuilderField . name (  )  )  . length ,    equalTo (  1  )  )  ;", "qbSource    =    doc . rootDoc (  )  . getFields ( fieldType . queryBuilderField . name (  )  )  [  0  ]  . binaryValue (  )  ;", "assertQueryBuilder ( qbSource ,    queryBuilder )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorFieldMapper"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "MapperParsingException   exception    =    expectThrows ( MapperParsingException . class ,     (  )     -  >     {", "mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field ( fieldName ,    termQuery (  \" unmapped _ field \"  ,     \" value \"  )  )  . endObject (  )  )  ,    XContentType . JSON )  )  ;", "}  )  ;", "assertThat ( exception . getCause (  )  ,    instanceOf ( QueryShardException . class )  )  ;", "assertThat ( exception . getCause (  )  . getMessage (  )  ,    equalTo (  \" No   field   mapping   can   be   found   for   the   field   with   name    [ unmapped _ field ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorFieldMapperUnMappedField"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "ParsedDocument   doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . endObject (  )  )  ,    JSON )  )  ;", "assertThat ( doc . rootDoc (  )  . getFields ( fieldType . queryBuilderField . name (  )  )  . length ,    equalTo (  0  )  )  ;", "try    {", "mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . nullField ( fieldName )  . endObject (  )  )  ,    JSON )  )  ;", "}    catch    ( MapperParsingException   e )     {", "assertThat ( e . getDetailedMessage (  )  ,    containsString (  \" query   malformed ,    must   start   with   start _ object \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testPercolatorFieldMapper_noQuery"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "client (  )  . prepareIndex (  \" remote \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" field \"  ,     \" value \"  )  . get (  )  ;", "QueryBuilder   queryBuilder    =    termsLookupQuery (  \" field \"  ,    new   TermsLookup (  \" remote \"  ,     \" doc \"  ,     \"  1  \"  ,     \" field \"  )  )  ;", "ParsedDocument   doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field ( fieldName ,    queryBuilder )  . endObject (  )  )  ,    JSON )  )  ;", "BytesRef   qbSource    =    doc . rootDoc (  )  . getFields ( fieldType . queryBuilderField . name (  )  )  [  0  ]  . binaryValue (  )  ;", "QueryShardContext   shardContext    =    indexService . newQueryShardContext ( randomInt (  2  0  )  ,    null ,     (  )     -  >     {", "throw   new   UnsupportedOperationException (  )  ;", "}  ,    null )  ;", "PlainActionFuture < QueryBuilder >    future    =    new   PlainActionFuture (  )  ;", "Rewriteable . rewriteAndFetch ( queryBuilder ,    shardContext ,    future )  ;", "assertQueryBuilder ( qbSource ,    future . get (  )  )  ;", "}", "METHOD_END"], "methodName": ["testQueryWithRewrite"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "addQueryFieldMappings (  )  ;", "QueryBuilder [  ]    queries    =    new   QueryBuilder [  ]  {    termQuery (  \" field \"  ,     \" value \"  )  ,    matchAllQuery (  )  ,    matchQuery (  \" field \"  ,     \" value \"  )  ,    matchPhraseQuery (  \" field \"  ,     \" value \"  )  ,    prefixQuery (  \" field \"  ,     \" v \"  )  ,    wildcardQuery (  \" field \"  ,     \" v *  \"  )  ,    rangeQuery (  \" number _ field 2  \"  )  . gte (  0  )  . lte (  9  )  ,    rangeQuery (  \" date _ field \"  )  . from (  \"  2  0  1  5  -  0  1  -  0  1 T 0  0  :  0  0  \"  )  . to (  \"  2  0  1  5  -  0  1  -  0  1 T 0  0  :  0  0  \"  )     }  ;", "for    ( QueryBuilder   query    :    queries )     {", "ParsedDocument   doc    =    mapperService . documentMapper (  \" doc \"  )  . parse ( SourceToParse . source (  \" test \"  ,     \" doc \"  ,     \"  1  \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field ( fieldName ,    query )  . endObject (  )  )  ,    JSON )  )  ;", "BytesRef   qbSource    =    doc . rootDoc (  )  . getFields ( fieldType . queryBuilderField . name (  )  )  [  0  ]  . binaryValue (  )  ;", "assertQueryBuilder ( qbSource ,    query )  ;", "}", "}", "METHOD_END"], "methodName": ["testStoringQueries"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "RangeQueryBuilder   rangeQuery 1     =    new   RangeQueryBuilder (  \" field \"  )  . from (  \"  2  0  1  6  -  0  1  -  0  1  |  |  / D \"  )  . to (  \"  2  0  1  7  -  0  1  -  0  1  |  |  / D \"  )  ;", "RangeQueryBuilder   rangeQuery 2     =    new   RangeQueryBuilder (  \" field \"  )  . from (  \"  2  0  1  6  -  0  1  -  0  1  |  |  / D \"  )  . to (  \" now \"  )  ;", ". verifyQuery ( rangeQuery 1  )  ;", ". verifyQuery ( rangeQuery 2  )  ;", "HasChildQueryBuilder   hasChildQuery    =    new   HasChildQueryBuilder (  \"  _ type \"  ,    new   MatchAllQueryBuilder (  )  ,    ScoreMode . None )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . verifyQuery ( new   BoolQueryBuilder (  )  . must ( hasChildQuery )  )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . verifyQuery ( new   DisMaxQueryBuilder (  )  . add ( hasChildQuery )  )  )  ;", ". verifyQuery ( new   ConstantScoreQueryBuilder ( rangeQuery 1  )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . verifyQuery ( new   ConstantScoreQueryBuilder ( hasChildQuery )  )  )  ;", ". verifyQuery ( new   BoostingQueryBuilder ( rangeQuery 1  ,    new   MatchAllQueryBuilder (  )  )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . verifyQuery ( new   BoostingQueryBuilder ( hasChildQuery ,    new   MatchAllQueryBuilder (  )  )  )  )  ;", ". verifyQuery ( new   FunctionScoreQueryBuilder ( rangeQuery 1  ,    new   RandomScoreFunctionBuilder (  )  )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . verifyQuery ( new   FunctionScoreQueryBuilder ( hasChildQuery ,    new   RandomScoreFunctionBuilder (  )  )  )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . verifyQuery ( hasChildQuery )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . verifyQuery ( new   BoolQueryBuilder (  )  . must ( hasChildQuery )  )  )  ;", "HasParentQueryBuilder   hasParentQuery    =    new   HasParentQueryBuilder (  \"  _ type \"  ,    new   MatchAllQueryBuilder (  )  ,    false )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . verifyQuery ( hasParentQuery )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . verifyQuery ( new   BoolQueryBuilder (  )  . must ( hasParentQuery )  )  )  ;", "}", "METHOD_END"], "methodName": ["testUnsupportedQueries"], "fileName": "org.elasticsearch.percolator.PercolatorFieldMapperTests"}, {"methodBody": ["METHOD_START", "{", "SubSearchContext   subSearchContext    =    new   SubSearchContext ( context )  ;", "subSearchContext . highlight ( new   search . fetch . subphase . highlight . SearchContextHighlight ( context . highlight (  )  . fields (  )  )  )  ;", "subSearchContext . highlight (  )  . globalForceSource ( true )  ;", "subSearchContext . lookup (  )  . source (  )  . setSegmentAndDocument ( leafReaderContext ,    docId )  ;", "subSearchContext . lookup (  )  . source (  )  . setSource ( source )  ;", "return   subSearchContext ;", "}", "METHOD_END"], "methodName": ["createSubSearchContext"], "fileName": "org.elasticsearch.percolator.PercolatorHighlightSubFetchPhase"}, {"methodBody": ["METHOD_START", "{", "return    (  ( context . highlight (  )  )     !  =    null )     &  &     (  ( PercolatorHighlightSubFetchPhase . locatePercolatorQuery ( context . query (  )  )  . isEmpty (  )  )     =  =    false )  ;", "}", "METHOD_END"], "methodName": ["hitsExecutionNeeded"], "fileName": "org.elasticsearch.percolator.PercolatorHighlightSubFetchPhase"}, {"methodBody": ["METHOD_START", "{", "if    ( query   instanceof   PercolateQuery )     {", "return   Collections . singletonList (  (  ( PercolateQuery )     ( query )  )  )  ;", "} else", "if    ( query   instanceof   BooleanQuery )     {", "List < PercolateQuery >    percolateQueries    =    new   ArrayList <  >  (  )  ;", "for    ( BooleanClause   clause    :     (  ( BooleanQuery )     ( query )  )  . clauses (  )  )     {", "List < PercolateQuery >    result    =     . locatePercolatorQuery ( clause . getQuery (  )  )  ;", "if    (  ( result . isEmpty (  )  )     =  =    false )     {", "percolateQueries . addAll ( result )  ;", "}", "}", "return   percolateQueries ;", "} else", "if    ( query   instanceof   DisjunctionMaxQuery )     {", "List < PercolateQuery >    percolateQueries    =    new   ArrayList <  >  (  )  ;", "for    ( Query   disjunct    :     (  ( DisjunctionMaxQuery )     ( query )  )  . getDisjuncts (  )  )     {", "List < PercolateQuery >    result    =     . locatePercolatorQuery ( disjunct )  ;", "if    (  ( result . isEmpty (  )  )     =  =    false )     {", "percolateQueries . addAll ( result )  ;", "}", "}", "return   percolateQueries ;", "} else", "if    ( query   instanceof   ConstantScoreQuery )     {", "return    . locatePercolatorQuery (  (  ( ConstantScoreQuery )     ( query )  )  . getQuery (  )  )  ;", "} else", "if    ( query   instanceof   BoostQuery )     {", "return    . locatePercolatorQuery (  (  ( BoostQuery )     ( query )  )  . getQuery (  )  )  ;", "} else", "if    ( query   instanceof   FunctionScoreQuery )     {", "return    . locatePercolatorQuery (  (  ( FunctionScoreQuery )     ( query )  )  . getSubQuery (  )  )  ;", "}", "return   Collections . emptyList (  )  ;", "}", "METHOD_END"], "methodName": ["locatePercolatorQuery"], "fileName": "org.elasticsearch.percolator.PercolatorHighlightSubFetchPhase"}, {"methodBody": ["METHOD_START", "{", "PercolateQuery   percolateQuery    =    new   PercolateQuery (  \"  _ name \"  ,     (    ctx )     -  >    null ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ,    new   MatchAllDocsQuery (  )  ,    Mockito . mock ( IndexSearcher . class )  ,    new   MatchAllDocsQuery (  )  )  ;", "subFetchPhase    =    new    ( Settings . EMPTY ,    Collections . emptyMap (  )  )  ;", "SearchContext   searchContext    =    Mockito . mock ( SearchContext . class )  ;", "Mockito . when ( searchContext . highlight (  )  )  . thenReturn ( new   SearchContextHighlight ( Collections . emptyList (  )  )  )  ;", "Mockito . when ( searchContext . query (  )  )  . thenReturn ( new   MatchAllDocsQuery (  )  )  ;", "assertThat ( subFetchPhase . hitsExecutionNeeded ( searchContext )  ,    is ( false )  )  ;", "Mockito . when ( searchContext . query (  )  )  . thenReturn ( percolateQuery )  ;", "assertThat ( subFetchPhase . hitsExecutionNeeded ( searchContext )  ,    is ( true )  )  ;", "}", "METHOD_END"], "methodName": ["testHitsExecutionNeeded"], "fileName": "org.elasticsearch.percolator.PercolatorHighlightSubFetchPhaseTests"}, {"methodBody": ["METHOD_START", "{", "PercolateQuery   percolateQuery    =    new   PercolateQuery (  \"  _ name \"  ,     (    ctx )     -  >    null ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ,    new   MatchAllDocsQuery (  )  ,    Mockito . mock ( IndexSearcher . class )  ,    new   MatchAllDocsQuery (  )  )  ;", "assertThat (  . locatePercolatorQuery ( new   MatchAllDocsQuery (  )  )  . size (  )  ,    equalTo (  0  )  )  ;", "BooleanQuery . Builder   bq    =    new   BooleanQuery . Builder (  )  ;", "bq . add ( new   MatchAllDocsQuery (  )  ,    FILTER )  ;", "assertThat (  . locatePercolatorQuery ( bq . build (  )  )  . size (  )  ,    equalTo (  0  )  )  ;", "bq . add ( percolateQuery ,    FILTER )  ;", "assertThat (  . locatePercolatorQuery ( bq . build (  )  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat (  . locatePercolatorQuery ( bq . build (  )  )  . get (  0  )  ,    sameInstance ( percolateQuery )  )  ;", "ConstantScoreQuery   constantScoreQuery    =    new   ConstantScoreQuery ( new   MatchAllDocsQuery (  )  )  ;", "assertThat (  . locatePercolatorQuery ( constantScoreQuery )  . size (  )  ,    equalTo (  0  )  )  ;", "constantScoreQuery    =    new   ConstantScoreQuery ( percolateQuery )  ;", "assertThat (  . locatePercolatorQuery ( constantScoreQuery )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat (  . locatePercolatorQuery ( constantScoreQuery )  . get (  0  )  ,    sameInstance ( percolateQuery )  )  ;", "BoostQuery   boostQuery    =    new   BoostQuery ( new   MatchAllDocsQuery (  )  ,     1  .  0 F )  ;", "assertThat (  . locatePercolatorQuery ( boostQuery )  . size (  )  ,    equalTo (  0  )  )  ;", "boostQuery    =    new   BoostQuery ( percolateQuery ,     1  .  0 F )  ;", "assertThat (  . locatePercolatorQuery ( boostQuery )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat (  . locatePercolatorQuery ( boostQuery )  . get (  0  )  ,    sameInstance ( percolateQuery )  )  ;", "FunctionScoreQuery   functionScoreQuery    =    new   FunctionScoreQuery ( new   MatchAllDocsQuery (  )  ,    new   RandomScoreFunction (  0  ,     0  ,    null )  )  ;", "assertThat (  . locatePercolatorQuery ( functionScoreQuery )  . size (  )  ,    equalTo (  0  )  )  ;", "functionScoreQuery    =    new   FunctionScoreQuery ( percolateQuery ,    new   RandomScoreFunction (  0  ,     0  ,    null )  )  ;", "assertThat (  . locatePercolatorQuery ( functionScoreQuery )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat (  . locatePercolatorQuery ( functionScoreQuery )  . get (  0  )  ,    sameInstance ( percolateQuery )  )  ;", "DisjunctionMaxQuery   disjunctionMaxQuery    =    new   DisjunctionMaxQuery ( Collections . singleton ( new   MatchAllDocsQuery (  )  )  ,     1  .  0 F )  ;", "assertThat (  . locatePercolatorQuery ( disjunctionMaxQuery )  . size (  )  ,    equalTo (  0  )  )  ;", "disjunctionMaxQuery    =    new   DisjunctionMaxQuery ( Arrays . asList ( percolateQuery ,    new   MatchAllDocsQuery (  )  )  ,     1  .  0 F )  ;", "assertThat (  . locatePercolatorQuery ( disjunctionMaxQuery )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat (  . locatePercolatorQuery ( disjunctionMaxQuery )  . get (  0  )  ,    sameInstance ( percolateQuery )  )  ;", "PercolateQuery   percolateQuery 2     =    new   PercolateQuery (  \"  _ name \"  ,     (    ctx )     -  >    null ,    Collections . singletonList ( new   BytesArray (  \"  {  }  \"  )  )  ,    new   MatchAllDocsQuery (  )  ,    Mockito . mock ( IndexSearcher . class )  ,    new   MatchAllDocsQuery (  )  )  ;", "bq    =    new   BooleanQuery . Builder (  )  ;", "bq . add ( new   MatchAllDocsQuery (  )  ,    FILTER )  ;", "assertThat (  . locatePercolatorQuery ( bq . build (  )  )  . size (  )  ,    equalTo (  0  )  )  ;", "bq . add ( percolateQuery ,    FILTER )  ;", "bq . add ( percolateQuery 2  ,    FILTER )  ;", "assertThat (  . locatePercolatorQuery ( bq . build (  )  )  . size (  )  ,    equalTo (  2  )  )  ;", "assertThat (  . locatePercolatorQuery ( bq . build (  )  )  . get (  0  )  ,    sameInstance ( percolateQuery )  )  ;", "assertThat (  . locatePercolatorQuery ( bq . build (  )  )  . get (  1  )  ,    sameInstance ( percolateQuery 2  )  )  ;", "}", "METHOD_END"], "methodName": ["testLocatePercolatorQuery"], "fileName": "org.elasticsearch.percolator.PercolatorHighlightSubFetchPhaseTests"}, {"methodBody": ["METHOD_START", "{", "int   slot    =     0  ;", "int [  ]    rootDocsBySlot    =    new   int [ rootDocs . cardinality (  )  ]  ;", "BitSetIteriter =    new   BitSetIterrootDocs ,     0  )  ;", "for    ( int   rootDocId    =    iternextDoc (  )  ;    rootDocId    !  =     ( NO _ MORE _ DOCS )  ;    rootDocId    =    iternextDoc (  )  )     {", "rootDocsBySlot [  ( slot +  +  )  ]     =    rootDocId ;", "}", "return   rootDocsBySlot ;", "}", "METHOD_END"], "methodName": ["buildRootDocsSlots"], "fileName": "org.elasticsearch.percolator.PercolatorMatchedSlotSubFetchPhase"}, {"methodBody": ["METHOD_START", "{", "IntStream   stream    =    Arrays . stream ( topDocs . scoreDocs )  . mapToInt (  (    scoreDoc )     -  >    scoreDoc . doc )  ;", "if    ( rootDocsBySlot    !  =    null )     {", "stream    =    stream . map (  (    docId )     -  >    Arrays . binaryS ( rootDocsBySlot ,    docId )  )  ;", "}", "return   stream ;", "}", "METHOD_END"], "methodName": ["convertTopDocsToSlots"], "fileName": "org.elasticsearch.percolator.PercolatorMatchedSlotSubFetchPhase"}, {"methodBody": ["METHOD_START", "{", "List < PercolateQuery >    percolateQueries    =    PercolatorHighlightSubFetchPhase . locatePercolatorQuery ( mainQuery )  ;", "if    ( percolateQueries . isEmpty (  )  )     {", "return ;", "}", "boolean   singlePercolateQuery    =     ( percolateQueries . size (  )  )     =  =     1  ;", "for    ( PercolateQuery   percolateQuery    :    percolateQueries )     {", "String   fieldName    =     ( singlePercolateQuery )     ?     . FIELD _ NAME _ PREFIX    :     (  (  . FIELD _ NAME _ PREFIX )     +     \"  _  \"  )     +     ( percolateQuery . getName (  )  )  ;", "IndexSearcher   percolatorIndexSearcher    =    percolateQuery . getPercolatorIndexSearcher (  )  ;", "final   Version   version    =    Version . V _  6  _  0  _  0  ;", "Weight   weight    =    percolatorIndexSearcher . createNormalizedWeight ( Queries . newNonNestedFilter ( version )  ,    false )  ;", "Scorer   s    =    weight . scorer ( percolatorIndexSearcher . getIndexReader (  )  . leaves (  )  . get (  0  )  )  ;", "int   memoryIndexMaxDoc    =    percolatorIndexSearcher . getIndexReader (  )  . maxDoc (  )  ;", "BitSet   rootDocs    =    BitSet . of ( s . iterator (  )  ,    memoryIndexMaxDoc )  ;", "int [  ]    rootDocsBySlot    =    null ;", "boolean   hasNestedDocs    =     ( rootDocs . cardinality (  )  )     !  =     ( percolatorIndexSearcher . getIndexReader (  )  . numDocs (  )  )  ;", "if    ( hasNestedDocs )     {", "rootDocsBySlot    =     . buildRootDocsSlots ( rootDocs )  ;", "}", "PercolateQuery . QueryStore   queryStore    =    percolateQuery . getQueryStore (  )  ;", "List < LeafReaderContext >    ctxs    =    indexSearcher . getIndexReader (  )  . leaves (  )  ;", "for    ( SearchHit   hit    :    hits )     {", "LeafReaderContext   ctx    =    ctxs . get ( ReaderUtil . subIndex ( hit . docId (  )  ,    ctxs )  )  ;", "int   segmentDocId    =     ( hit . docId (  )  )     -     ( ctx . docBase )  ;", "Query   query    =    queryStore . getQueries ( ctx )  . apply ( segmentDocId )  ;", "if    ( query    =  =    null )     {", "continue ;", "}", "TopDocs   topDocs    =    percolatorIndexSearcher . search ( query ,    memoryIndexMaxDoc ,    new   Sort ( SortField . FIELD _ DOC )  )  ;", "if    (  ( topDocs . totalHits )     =  =     0  )     {", "continue ;", "}", "Map < String ,    DocumentField >    fields    =    hit . fieldsOrNull (  )  ;", "if    ( fields    =  =    null )     {", "fields    =    new   HashMap (  )  ;", "hit . fields ( fields )  ;", "}", "IntStream   slots    =     . convertTopDocsToSlots ( topDocs ,    rootDocsBySlot )  ;", "fields . put ( fieldName ,    new   DocumentField ( fieldName ,    slots . boxed (  )  . collect ( Collectors . toList (  )  )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["innerHitsExecute"], "fileName": "org.elasticsearch.percolator.PercolatorMatchedSlotSubFetchPhase"}, {"methodBody": ["METHOD_START", "{", "ScoreDoc [  ]    scoreDocs    =    new   ScoreDoc [ randomInt (  1  2  8  )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( scoreDocs . length )  ;    i +  +  )     {", "scoreDocs [ i ]     =    new   ScoreDoc ( i ,     1  .  0 F )  ;", "}", "TopDocs   topDocs    =    new   TopDocs ( scoreDocs . length ,    scoreDocs ,     1  .  0 F )  ;", "IntStream   stream    =     . convertTopDocsToSlots ( topDocs ,    null )  ;", "int [  ]    result    =    stream . toArray (  )  ;", "assertEquals ( scoreDocs . length ,    result . length )  ;", "for    ( int   i    =     0  ;    i    <     ( scoreDocs . length )  ;    i +  +  )     {", "assertEquals ( scoreDocs [ i ]  . doc ,    result [ i ]  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConvertTopDocsToSlots"], "fileName": "org.elasticsearch.percolator.PercolatorMatchedSlotSubFetchPhaseTests"}, {"methodBody": ["METHOD_START", "{", "ScoreDoc [  ]    scoreDocs    =    new   ScoreDoc [  5  ]  ;", "scoreDocs [  0  ]     =    new   ScoreDoc (  2  ,     1  .  0 F )  ;", "scoreDocs [  1  ]     =    new   ScoreDoc (  5  ,     1  .  0 F )  ;", "scoreDocs [  2  ]     =    new   ScoreDoc (  8  ,     1  .  0 F )  ;", "scoreDocs [  3  ]     =    new   ScoreDoc (  1  1  ,     1  .  0 F )  ;", "scoreDocs [  4  ]     =    new   ScoreDoc (  1  4  ,     1  .  0 F )  ;", "TopDocs   topDocs    =    new   TopDocs ( scoreDocs . length ,    scoreDocs ,     1  .  0 F )  ;", "FixedBitSet   bitSet    =    new   FixedBitSet (  1  5  )  ;", "bitSet . set (  2  )  ;", "bitSet . set (  5  )  ;", "bitSet . set (  8  )  ;", "bitSet . set (  1  1  )  ;", "bitSet . set (  1  4  )  ;", "int [  ]    rootDocsBySlot    =     . buildRootDocsSlots ( bitSet )  ;", "int [  ]    result    =     . convertTopDocsToSlots ( topDocs ,    rootDocsBySlot )  . toArray (  )  ;", "assertEquals ( scoreDocs . length ,    result . length )  ;", "assertEquals (  0  ,    result [  0  ]  )  ;", "assertEquals (  1  ,    result [  1  ]  )  ;", "assertEquals (  2  ,    result [  2  ]  )  ;", "assertEquals (  3  ,    result [  3  ]  )  ;", "assertEquals (  4  ,    result [  4  ]  )  ;", "}", "METHOD_END"], "methodName": ["testConvertTopDocsToSlots_nestedDocs"], "fileName": "org.elasticsearch.percolator.PercolatorMatchedSlotSubFetchPhaseTests"}, {"methodBody": ["METHOD_START", "{", "try    ( Directory   directory    =    newDirectory (  )  )     {", "try    ( RandomIndexWriter   indexWriter    =    new   RandomIndexWriter ( random (  )  ,    directory )  )     {", "Document   document    =    new   Document (  )  ;", "indexWriter . addDocument ( document )  ;", "}", "try    ( DirectoryReader   reader    =    DirectoryReader . open ( directory )  )     {", "IndexSearcher   indexSearcher    =    new   IndexSearcher ( reader )  ;", "{", "SearchHit [  ]    hits    =    new   SearchHit [  ]  {    new   SearchHit (  0  )     }  ;", "PercolateQuery . QueryStore   queryStore    =     (    ctx )     -  >     (    docId )     -  >    new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" value \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "PercolateQuery   percolateQuery    =    new   PercolateQuery (  \"  _ name \"  ,    queryStore ,    Collections . emptyList (  )  ,    new   MatchAllDocsQuery (  )  ,    memoryIndex . createSearcher (  )  ,    new   MatchNoDocsQuery (  )  )  ;", ". innerHitsExecute ( percolateQuery ,    indexSearcher ,    hits )  ;", "assertNotNull ( hits [  0  ]  . field (  . FIELD _ NAME _ PREFIX )  )  ;", "assertEquals (  0  ,     (  ( int )     ( hits [  0  ]  . field (  . FIELD _ NAME _ PREFIX )  . getValue (  )  )  )  )  ;", "}", "{", "SearchHit [  ]    hits    =    new   SearchHit [  ]  {    new   SearchHit (  0  )     }  ;", "PercolateQuery . QueryStore   queryStore    =     (    ctx )     -  >     (    docId )     -  >    new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" value 1  \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "PercolateQuery   percolateQuery    =    new   PercolateQuery (  \"  _ name \"  ,    queryStore ,    Collections . emptyList (  )  ,    new   MatchAllDocsQuery (  )  ,    memoryIndex . createSearcher (  )  ,    new   MatchNoDocsQuery (  )  )  ;", ". innerHitsExecute ( percolateQuery ,    indexSearcher ,    hits )  ;", "assertNull ( hits [  0  ]  . field (  . FIELD _ NAME _ PREFIX )  )  ;", "}", "{", "SearchHit [  ]    hits    =    new   SearchHit [  ]  {    new   SearchHit (  0  )     }  ;", "PercolateQuery . QueryStore   queryStore    =     (    ctx )     -  >     (    docId )     -  >    null ;", "MemoryIndex   memoryIndex    =    new   MemoryIndex (  )  ;", "memoryIndex . addField (  \" field \"  ,     \" value \"  ,    new   WhitespaceAnalyzer (  )  )  ;", "PercolateQuery   percolateQuery    =    new   PercolateQuery (  \"  _ name \"  ,    queryStore ,    Collections . emptyList (  )  ,    new   MatchAllDocsQuery (  )  ,    memoryIndex . createSearcher (  )  ,    new   MatchNoDocsQuery (  )  )  ;", ". innerHitsExecute ( percolateQuery ,    indexSearcher ,    hits )  ;", "assertNull ( hits [  0  ]  . field (  . FIELD _ NAME _ PREFIX )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["testHitsExecute"], "fileName": "org.elasticsearch.percolator.PercolatorMatchedSlotSubFetchPhaseTests"}, {"methodBody": ["METHOD_START", "{", "String   queryFieldName    =    randomAlphaOfLength (  8  )  ;", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test 1  \"  )  . addMapping (  \" type \"  ,    queryFieldName ,     \" type =  \"  ,     \" field \"  ,     \" type = keyword \"  )  )  ;", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test 2  \"  )  . addMapping (  \" type \"  ,    queryFieldName ,     \" type =  \"  ,     \" second _ query _ field \"  ,     \" type =  \"  ,     \" field \"  ,     \" type = keyword \"  )  )  ;", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test 3  \"  )  . addMapping (  \" type \"  ,    jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" keyword \"  )  . endObject (  )  . startObject (  \" object _ field \"  )  . field (  \" type \"  ,     \" object \"  )  . startObject (  \" properties \"  )  . startObject ( queryFieldName )  . field (  \" type \"  ,     \"  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testManyPercolatorFields"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   mapping    =    XContentFactory . jsonBuilder (  )  ;", "mapping . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" query \"  )  . field (  \" type \"  ,     \"  \"  )  . endObject (  )  . startObject (  \" companyname \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . startObject (  \" employee \"  )  . field (  \" type \"  ,     \" nested \"  )  . startObject (  \" properties \"  )  . startObject (  \" name \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  ;", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" employee \"  ,    mapping )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" employee \"  ,     \" q 1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    QueryBuilders . nestedQuery (  \" employee \"  ,    QueryBuilders . matchQuery (  \" employee . name \"  ,     \" virginia   potts \"  )  . operator ( AND )  ,    Avg )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" employee \"  ,     \" q 2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    QueryBuilders . matchQuery (  \" employee . name \"  ,     \" virginia \"  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" companyname \"  ,     \" stark \"  )  . startArray (  \" employee \"  )  . startObject (  )  . field (  \" name \"  ,     \" virginia   potts \"  )  . endObject (  )  . startObject (  )  . field (  \" name \"  ,     \" tony   stark \"  )  . endObject (  )  . endArray (  )  . endObject (  )  )  ,    XContentType . JSON )  )  . addSort (  \"  _ doc \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" q 1  \"  )  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" companyname \"  ,     \" notstark \"  )  . startArray (  \" employee \"  )  . startObject (  )  . field (  \" name \"  ,     \" virginia   stark \"  )  . endObject (  )  . startObject (  )  . field (  \" name \"  ,     \" tony   stark \"  )  . endObject (  )  . endArray (  )  . endObject (  )  )  ,    XContentType . JSON )  )  . addSort (  \"  _ doc \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     0  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" companyname \"  ,     \" notstark \"  )  . endObject (  )  )  ,    XContentType . JSON )  )  . addSort (  \"  _ doc \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     0  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    Arrays . asList ( BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" companyname \"  ,     \" stark \"  )  . startArray (  \" employee \"  )  . startObject (  )  . field (  \" name \"  ,     \" virginia   potts \"  )  . endObject (  )  . startObject (  )  . field (  \" name \"  ,     \" tony   stark \"  )  . endObject (  )  . endArray (  )  . endObject (  )  )  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" companyname \"  ,     \" stark \"  )  . startArray (  \" employee \"  )  . startObject (  )  . field (  \" name \"  ,     \" peter   parker \"  )  . endObject (  )  . startObject (  )  . field (  \" name \"  ,     \" virginia   potts \"  )  . endObject (  )  . endArray (  )  . endObject (  )  )  )  ,    XContentType . JSON )  )  . addSort (  \"  _ doc \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \" q 1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getFields (  )  . get (  \"  _  _ document _ slot \"  )  . getValues (  )  ,    equalTo ( Arrays . asList (  0  ,     1  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolateQueryWithNestedDocuments"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" type \"  ,     \" field 1  \"  ,     \" type = geo _ point \"  ,     \" field 2  \"  ,     \" type = geo _ shape \"  ,     \" query \"  ,     \" type = percolator \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    geoDistanceQuery (  \" field 1  \"  )  . point (  5  2  .  1  8  ,     4  .  3  8  )  . distance (  5  0  ,    KILOMETERS )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    geoBoundingBoxQuery (  \" field 1  \"  )  . setCorners (  5  2  .  3  ,     4  .  4  ,     5  2  .  1  ,     4  .  6  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    geoPolygonQuery (  \" field 1  \"  ,    Arrays . asList ( new   GeoPoint (  5  2  .  1  ,     4  .  4  )  ,    new   GeoPoint (  5  2  .  3  ,     4  .  5  )  ,    new   GeoPoint (  5  2  .  1  ,     4  .  6  )  )  )  )  . endObject (  )  )  . get (  )  ;", "refresh (  )  ;", "BytesReference   source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . startObject (  \" field 1  \"  )  . field (  \" lat \"  ,     5  2  .  2  )  . field (  \" lon \"  ,     4  .  5  1  )  . endObject (  )  . endObject (  )  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     3  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  2  )  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorGeoQueries"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" type \"  ,     \" field 1  \"  ,     \" type = keyword \"  ,     \" field 2  \"  ,     \" type = keyword \"  ,     \" query \"  ,     \" type = percolator \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchAllQuery (  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchQuery (  \" field 1  \"  ,     \" value \"  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    boolQuery (  )  . must ( matchQuery (  \" field 1  \"  ,     \" value \"  )  )  . must ( matchQuery (  \" field 2  \"  ,     \" value \"  )  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "BytesReference   source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . endObject (  )  )  ;", "logger . info (  \" percolating   empty   doc \"  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" value \"  )  . endObject (  )  )  ;", "logger . info (  \" percolating   doc   with    1    field \"  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     2  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getFields (  )  . get (  \"  _ percolator _ document _ slot \"  )  . getValue (  )  ,    equalTo (  0  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getFields (  )  . get (  \"  _ percolator _ document _ slot \"  )  . getValue (  )  ,    equalTo (  0  )  )  ;", "source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" value \"  )  . field (  \" field 2  \"  ,     \" value \"  )  . endObject (  )  )  ;", "logger . info (  \" percolating   doc   with    2    fields \"  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     3  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getFields (  )  . get (  \"  _ percolator _ document _ slot \"  )  . getValue (  )  ,    equalTo (  0  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getFields (  )  . get (  \"  _ percolator _ document _ slot \"  )  . getValue (  )  ,    equalTo (  0  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  2  )  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  2  )  . getFields (  )  . get (  \"  _ percolator _ document _ slot \"  )  . getValue (  )  ,    equalTo (  0  )  )  ;", "logger . info (  \" percolating   doc   with    2    fields \"  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    Arrays . asList ( BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" value \"  )  . endObject (  )  )  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" value \"  )  . field (  \" field 2  \"  ,     \" value \"  )  . endObject (  )  )  )  ,    XContentType . JSON )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     3  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getFields (  )  . get (  \"  _ percolator _ document _ slot \"  )  . getValues (  )  ,    equalTo ( Arrays . asList (  0  ,     1  )  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getFields (  )  . get (  \"  _ percolator _ document _ slot \"  )  . getValues (  )  ,    equalTo ( Arrays . asList (  0  ,     1  )  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  2  )  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  2  )  . getFields (  )  . get (  \"  _ percolator _ document _ slot \"  )  . getValues (  )  ,    equalTo ( Arrays . asList (  1  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorQuery"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" type \"  ,     \" field 1  \"  ,     \" type = keyword \"  ,     \" field 2  \"  ,     \" type = keyword \"  ,     \" query \"  ,     \" type = percolator \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchAllQuery (  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchQuery (  \" field 1  \"  ,     \" value \"  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    boolQuery (  )  . must ( matchQuery (  \" field 1  \"  ,     \" value \"  )  )  . must ( matchQuery (  \" field 2  \"  ,     \" value \"  )  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  4  \"  )  . setSource (  \"  {  }  \"  ,    JSON )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  5  \"  )  . setSource (  \" field 1  \"  ,     \" value \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  6  \"  )  . setSource (  \" field 1  \"  ,     \" value \"  ,     \" field 2  \"  ,     \" value \"  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "logger . info (  \" percolating   empty   doc \"  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,     \" test \"  ,     \" type \"  ,     \"  1  \"  ,    null ,    null ,    null )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "logger . info (  \" percolating   doc   with    1    field \"  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,     \" test \"  ,     \" type \"  ,     \"  5  \"  ,    null ,    null ,    null )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     2  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "logger . info (  \" percolating   doc   with    2    fields \"  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,     \" test \"  ,     \" type \"  ,     \"  6  \"  ,    null ,    null ,    null )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     3  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  2  )  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorQueryExistingDocument"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" type \"  ,     \"  _ source \"  ,     \" enabled = false \"  ,     \" field 1  \"  ,     \" type = keyword \"  ,     \" query \"  ,     \" type = percolator \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchAllQuery (  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource (  \"  {  }  \"  ,    JSON )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "logger . info (  \" percolating   empty   doc   with   source   disabled \"  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >     {", "client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,     \" test \"  ,     \" type \"  ,     \"  1  \"  ,    null ,    null ,    null )  )  . get (  )  ;", "}  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" source   disabled \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorQueryExistingDocumentSourceDisabled"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" type \"  ,     \" field 1  \"  ,     \" type = text \"  ,     \" query \"  ,     \" type = percolator \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchQuery (  \" field 1  \"  ,     \" b \"  )  )  . field (  \" a \"  ,     \" b \"  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchQuery (  \" field 1  \"  ,     \" c \"  )  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    boolQuery (  )  . must ( matchQuery (  \" field 1  \"  ,     \" b \"  )  )  . must ( matchQuery (  \" field 1  \"  ,     \" c \"  )  )  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  4  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchAllQuery (  )  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  5  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" c \"  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "MultiSearchResponse   response    =    client (  )  . prepareMultiSearch (  )  . add ( client (  )  . prepareSearch (  \" test \"  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" b \"  )  . endObject (  )  )  ,    XContentType . JSON )  )  )  . add ( client (  )  . prepareSearch (  \" test \"  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( yamlBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" c \"  )  . endObject (  )  )  ,    XContentType . YAML )  )  )  . add ( client (  )  . prepareSearch (  \" test \"  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( smileBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" b   c \"  )  . endObject (  )  )  ,    XContentType . SMILE )  )  )  . add ( client (  )  . prepareSearch (  \" test \"  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" d \"  )  . endObject (  )  )  ,    XContentType . JSON )  )  )  . add ( client (  )  . prepareSearch (  \" test \"  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,     \" test \"  ,     \" type \"  ,     \"  5  \"  ,    null ,    null ,    null )  )  )  . add ( client (  )  . prepareSearch (  \" test \"  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,     \" test \"  ,     \" type \"  ,     \"  6  \"  ,    null ,    null ,    null )  )  )  . get (  )  ;", "MultiSearchResponse . Item   item    =    response . getResponses (  )  [  0  ]  ;", "assertHitCount ( item . getResponse (  )  ,     2 L )  ;", "assertSearchHits ( item . getResponse (  )  ,     \"  1  \"  ,     \"  4  \"  )  ;", "assertThat ( item . getFailureMessage (  )  ,    nullValue (  )  )  ;", "item    =    response . getResponses (  )  [  1  ]  ;", "assertHitCount ( item . getResponse (  )  ,     2 L )  ;", "assertSearchHits ( item . getResponse (  )  ,     \"  2  \"  ,     \"  4  \"  )  ;", "assertThat ( item . getFailureMessage (  )  ,    nullValue (  )  )  ;", "item    =    response . getResponses (  )  [  2  ]  ;", "assertHitCount ( item . getResponse (  )  ,     4 L )  ;", "assertSearchHits ( item . getResponse (  )  ,     \"  1  \"  ,     \"  2  \"  ,     \"  3  \"  ,     \"  4  \"  )  ;", "assertThat ( item . getFailureMessage (  )  ,    nullValue (  )  )  ;", "item    =    response . getResponses (  )  [  3  ]  ;", "assertHitCount ( item . getResponse (  )  ,     1 L )  ;", "assertSearchHits ( item . getResponse (  )  ,     \"  4  \"  )  ;", "assertThat ( item . getFailureMessage (  )  ,    nullValue (  )  )  ;", "item    =    response . getResponses (  )  [  4  ]  ;", "assertHitCount ( item . getResponse (  )  ,     2 L )  ;", "assertSearchHits ( item . getResponse (  )  ,     \"  2  \"  ,     \"  4  \"  )  ;", "assertThat ( item . getFailureMessage (  )  ,    nullValue (  )  )  ;", "item    =    response . getResponses (  )  [  5  ]  ;", "assertThat ( item . getResponse (  )  ,    nullValue (  )  )  ;", "assertThat ( item . getFailureMessage (  )  ,    notNullValue (  )  )  ;", "assertThat ( item . getFailureMessage (  )  ,    containsString (  \"  [ test / type /  6  ]    couldn ' t   be   found \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorQueryViaMultiSearch"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "StringBuilder   fieldMapping    =    new   StringBuilder (  \" type = text \"  )  . append (  \"  , store =  \"  )  . append ( randomBoolean (  )  )  ;", "if    ( randomBoolean (  )  )     {", "fieldMapping . append (  \"  , term _ vector = with _ positions _ offsets \"  )  ;", "} else", "if    ( randomBoolean (  )  )     {", "fieldMapping . append (  \"  , index _ options = offsets \"  )  ;", "}", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" type \"  ,     \" field 1  \"  ,    fieldMapping ,     \" query \"  ,     \" type =  \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchQuery (  \" field 1  \"  ,     \" brown   fox \"  )  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchQuery (  \" field 1  \"  ,     \" lazy   dog \"  )  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    termQuery (  \" field 1  \"  ,     \" jumps \"  )  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  4  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    termQuery (  \" field 1  \"  ,     \" dog \"  )  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  5  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    termQuery (  \" field 1  \"  ,     \" fox \"  )  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "BytesReference   document    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" The   quick   brown   fox   jumps   over   the   lazy   dog \"  )  . endObject (  )  )  ;", "SearchResponse   searchResponse    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    document ,    XContentType . JSON )  )  . highlighter ( new   HighlightBuilder (  )  . field (  \" field 1  \"  )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( searchResponse ,     5  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getHighlightFields (  )  . get (  \" field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" The   quick    < em > brown <  / em >     < em > fox <  / em >    jumps   over   the   lazy   dog \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getHighlightFields (  )  . get (  \" field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" The   quick   brown   fox   jumps   over   the    < em > lazy <  / em >     < em > dog <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  2  )  . getHighlightFields (  )  . get (  \" field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" The   quick   brown   fox    < em > jumps <  / em >    over   the   lazy   dog \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  3  )  . getHighlightFields (  )  . get (  \" field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" The   quick   brown   fox   jumps   over   the   lazy    < em > dog <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  4  )  . getHighlightFields (  )  . get (  \" field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" The   quick   brown    < em > fox <  / em >    jumps   over   the   lazy   dog \"  )  )  ;", "BytesReference   document 1     =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" The   quick   brown   fox   jumps \"  )  . endObject (  )  )  ;", "BytesReference   document 2     =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" over   the   lazy   dog \"  )  . endObject (  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  )  . setQuery ( boolQuery (  )  . should ( new   PercolateQueryBuilder (  \" query \"  ,    document 1  ,    XContentType . JSON )  . setName (  \" query 1  \"  )  )  . should ( new   PercolateQueryBuilder (  \" query \"  ,    document 2  ,    XContentType . JSON )  . setName (  \" query 2  \"  )  )  )  . highlighter ( new   HighlightBuilder (  )  . field (  \" field 1  \"  )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "logger . info (  \" searchResponse =  {  }  \"  ,    searchResponse )  ;", "assertHitCount ( searchResponse ,     5  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getHighlightFields (  )  . get (  \" query 1  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" The   quick    < em > brown <  / em >     < em > fox <  / em >    jumps \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getHighlightFields (  )  . get (  \" query 2  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" over   the    < em > lazy <  / em >     < em > dog <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  2  )  . getHighlightFields (  )  . get (  \" query 1  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" The   quick   brown   fox    < em > jumps <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  3  )  . getHighlightFields (  )  . get (  \" query 2  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" over   the   lazy    < em > dog <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  4  )  . getHighlightFields (  )  . get (  \" query 1  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" The   quick   brown    < em > fox <  / em >    jumps \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    Arrays . asList ( BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" dog \"  )  . endObject (  )  )  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" fox \"  )  . endObject (  )  )  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" jumps \"  )  . endObject (  )  )  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" brown   fox \"  )  . endObject (  )  )  )  ,    XContentType . JSON )  )  . highlighter ( new   HighlightBuilder (  )  . field (  \" field 1  \"  )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( searchResponse ,     5  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getFields (  )  . get (  \"  _  _ document _ slot \"  )  . getValues (  )  ,    equalTo ( Arrays . asList (  1  ,     3  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getHighlightFields (  )  . get (  \"  1  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > fox <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getHighlightFields (  )  . get (  \"  3  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > brown <  / em >     < em > fox <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getFields (  )  . get (  \"  _  _ document _ slot \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  0  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getHighlightFields (  )  . get (  \"  0  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > dog <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  2  )  . getFields (  )  . get (  \"  _  _ document _ slot \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  2  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  2  )  . getHighlightFields (  )  . get (  \"  2  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > jumps <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  3  )  . getFields (  )  . get (  \"  _  _ document _ slot \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  0  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  3  )  . getHighlightFields (  )  . get (  \"  0  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > dog <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  4  )  . getFields (  )  . get (  \"  _  _ document _ slot \"  )  . getValues (  )  ,    equalTo ( Arrays . asList (  1  ,     3  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  4  )  . getHighlightFields (  )  . get (  \"  1  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > fox <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  4  )  . getHighlightFields (  )  . get (  \"  3  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" brown    < em > fox <  / em >  \"  )  )  ;", "searchResponse    =    client (  )  . prepareSearch (  )  . setQuery ( boolQuery (  )  . should ( new   PercolateQueryBuilder (  \" query \"  ,    Arrays . asList ( BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" dog \"  )  . endObject (  )  )  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" fox \"  )  . endObject (  )  )  )  ,    XContentType . JSON )  . setName (  \" query 1  \"  )  )  . should ( new   PercolateQueryBuilder (  \" query \"  ,    Arrays . asList ( BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" jumps \"  )  . endObject (  )  )  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" brown   fox \"  )  . endObject (  )  )  )  ,    XContentType . JSON )  . setName (  \" query 2  \"  )  )  )  . highlighter ( new   HighlightBuilder (  )  . field (  \" field 1  \"  )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "logger . info (  \" searchResponse =  {  }  \"  ,    searchResponse )  ;", "assertHitCount ( searchResponse ,     5  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getFields (  )  . get (  \"  _  _ document _ slot _ query 1  \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  1  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getFields (  )  . get (  \"  _  _ document _ slot _ query 2  \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  1  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getHighlightFields (  )  . get (  \" query 1  _  1  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > fox <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  0  )  . getHighlightFields (  )  . get (  \" query 2  _  1  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > brown <  / em >     < em > fox <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getFields (  )  . get (  \"  _  _ document _ slot _ query 1  \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  0  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  1  )  . getHighlightFields (  )  . get (  \" query 1  _  0  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > dog <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  2  )  . getFields (  )  . get (  \"  _  _ document _ slot _ query 2  \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  0  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  2  )  . getHighlightFields (  )  . get (  \" query 2  _  0  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > jumps <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  3  )  . getFields (  )  . get (  \"  _  _ document _ slot _ query 1  \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  0  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  3  )  . getHighlightFields (  )  . get (  \" query 1  _  0  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > dog <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  4  )  . getFields (  )  . get (  \"  _  _ document _ slot _ query 1  \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  1  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  4  )  . getFields (  )  . get (  \"  _  _ document _ slot _ query 2  \"  )  . getValues (  )  ,    equalTo ( Collections . singletonList (  1  )  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  4  )  . getHighlightFields (  )  . get (  \" query 1  _  1  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \"  < em > fox <  / em >  \"  )  )  ;", "assertThat ( searchResponse . getHits (  )  . getAt (  4  )  . getHighlightFields (  )  . get (  \" query 2  _  1  _ field 1  \"  )  . fragments (  )  [  0  ]  . string (  )  ,    equalTo (  \" brown    < em > fox <  / em >  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorQueryWithHighlighting"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" type \"  ,     \" field 1  \"  ,     \" type = long \"  ,     \" field 2  \"  ,     \" type = double \"  ,     \" field 3  \"  ,     \" type = ip \"  ,     \" field 4  \"  ,     \" type = date \"  ,     \" query \"  ,     \" type = percolator \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    rangeQuery (  \" field 1  \"  )  . from (  1  0  )  . to (  1  2  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    rangeQuery (  \" field 1  \"  )  . from (  2  0  )  . to (  2  2  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    boolQuery (  )  . must ( rangeQuery (  \" field 1  \"  )  . from (  1  0  )  . to (  1  2  )  )  . must ( rangeQuery (  \" field 1  \"  )  . from (  1  2  )  . to (  1  4  )  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  4  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    rangeQuery (  \" field 2  \"  )  . from (  1  0  )  . to (  1  2  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  5  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    rangeQuery (  \" field 2  \"  )  . from (  2  0  )  . to (  2  2  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  6  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    boolQuery (  )  . must ( rangeQuery (  \" field 2  \"  )  . from (  1  0  )  . to (  1  2  )  )  . must ( rangeQuery (  \" field 2  \"  )  . from (  1  2  )  . to (  1  4  )  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  7  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    rangeQuery (  \" field 3  \"  )  . from (  \"  1  9  2  .  1  6  8  .  1  .  0  \"  )  . to (  \"  1  9  2  .  1  6  8  .  1  .  5  \"  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  8  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    rangeQuery (  \" field 3  \"  )  . from (  \"  1  9  2  .  1  6  8  .  1  .  2  0  \"  )  . to (  \"  1  9  2  .  1  6  8  .  1  .  3  0  \"  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  9  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    boolQuery (  )  . must ( rangeQuery (  \" field 3  \"  )  . from (  \"  1  9  2  .  1  6  8  .  1  .  0  \"  )  . to (  \"  1  9  2  .  1  6  8  .  1  .  5  \"  )  )  . must ( rangeQuery (  \" field 3  \"  )  . from (  \"  1  9  2  .  1  6  8  .  1  .  5  \"  )  . to (  \"  1  9  2  .  1  6  8  .  1  .  1  0  \"  )  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  0  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    boolQuery (  )  . must ( rangeQuery (  \" field 4  \"  )  . from (  \"  2  0  1  0  -  0  1  -  0  1  \"  )  . to (  \"  2  0  1  8  -  0  1  -  0  1  \"  )  )  . must ( rangeQuery (  \" field 4  \"  )  . from (  \"  2  0  1  0  -  0  1  -  0  1  \"  )  . to (  \" now \"  )  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "BytesReference   source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     1  2  )  . endObject (  )  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . get (  )  ;", "logger . info (  \" response =  {  }  \"  ,    response )  ;", "assertHitCount ( response ,     2  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     1  1  )  . endObject (  )  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 2  \"  ,     1  2  )  . endObject (  )  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     2  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  6  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 2  \"  ,     1  1  )  . endObject (  )  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 3  \"  ,     \"  1  9  2  .  1  6  8  .  1  .  5  \"  )  . endObject (  )  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     2  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  9  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  7  \"  )  )  ;", "source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 3  \"  ,     \"  1  9  2  .  1  6  8  .  1  .  4  \"  )  . endObject (  )  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  7  \"  )  )  ;", "source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 4  \"  ,     \"  2  0  1  6  -  0  5  -  1  5  \"  )  . endObject (  )  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  0  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorRangeQueries"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" type \"  ,     \" field 1  \"  ,     \" type = text \"  ,     \" field 2  \"  ,     \" type = text \"  ,     \" query \"  ,     \" type = percolator \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    commonTermsQuery (  \" field 1  \"  ,     \" quick   brown   fox \"  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    multiMatchQuery (  \" quick   brown   fox \"  ,     \" field 1  \"  ,     \" field 2  \"  )  . type ( CROSS _ FIELDS )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    spanNearQuery ( spanTermQuery (  \" field 1  \"  ,     \" quick \"  )  ,     0  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" brown \"  )  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" fox \"  )  )  . inOrder ( true )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  4  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    spanNotQuery ( spanNearQuery ( spanTermQuery (  \" field 1  \"  ,     \" quick \"  )  ,     0  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" brown \"  )  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" fox \"  )  )  . inOrder ( true )  ,    spanNearQuery ( spanTermQuery (  \" field 1  \"  ,     \" the \"  )  ,     0  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" lazy \"  )  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" dog \"  )  )  . inOrder ( true )  )  . dist (  2  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  5  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    spanNotQuery ( spanNearQuery ( spanTermQuery (  \" field 1  \"  ,     \" quick \"  )  ,     0  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" brown \"  )  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" fox \"  )  )  . inOrder ( true )  ,    spanNearQuery ( spanTermQuery (  \" field 1  \"  ,     \" the \"  )  ,     0  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" lazy \"  )  )  . addClause ( spanTermQuery (  \" field 1  \"  ,     \" dog \"  )  )  . inOrder ( true )  )  . dist (  3  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "BytesReference   source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" the   quick   brown   fox   jumps   over   the   lazy   dog \"  )  . field (  \" field 2  \"  ,     \" the   quick   brown   fox   falls   down   into   the   well \"  )  . endObject (  )  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    source ,    XContentType . JSON )  )  . addSort (  \"  _ id \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     4  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getScore (  )  ,    equalTo ( Float . NaN )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  1  )  . getScore (  )  ,    equalTo ( Float . NaN )  )  ;", "assertThat ( response . getHits (  )  . getAt (  2  )  . getId (  )  ,    equalTo (  \"  3  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  2  )  . getScore (  )  ,    equalTo ( Float . NaN )  )  ;", "assertThat ( response . getHits (  )  . getAt (  3  )  . getId (  )  ,    equalTo (  \"  4  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  3  )  . getScore (  )  ,    equalTo ( Float . NaN )  )  ;", "}", "METHOD_END"], "methodName": ["testPercolatorSpecificQueries"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" type \"  ,     \" field \"  ,     \" type = text , position _ increment _ gap =  5  \"  ,     \" query \"  ,     \" type = percolator \"  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    new   MatchPhraseQueryBuilder (  \" field \"  ,     \" brown   fox \"  )  . slop (  4  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    new   MatchPhraseQueryBuilder (  \" field \"  ,     \" brown   fox \"  )  . slop (  5  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    new   BytesArray (  \"  {  \\  \" field \\  \"     :     [  \\  \" brown \\  \"  ,     \\  \" fox \\  \"  ]  }  \"  )  ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testTakePositionOffsetGapIntoAccount"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "String   queryFieldName    =    randomAlphaOfLength (  8  )  ;", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test 1  \"  )  . addMapping (  \" type \"  ,    queryFieldName ,     \" type =  \"  ,     \" field \"  ,     \" type = keyword \"  )  )  ;", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test 2  \"  )  . addMapping (  \" type \"  ,    jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" field \"  )  . field (  \" type \"  ,     \" keyword \"  )  . endObject (  )  . startObject (  \" object _ field \"  )  . field (  \" type \"  ,     \" object \"  )  . startObject (  \" properties \"  )  . startObject ( queryFieldName )  . field (  \" type \"  ,     \"  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  )  ;", "client (  )  . prepareIndex (  \" test 1  \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field ( queryFieldName ,    matchQuery (  \" field \"  ,     \" value \"  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test 2  \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . startObject (  \" object _ field \"  )  . field ( queryFieldName ,    matchQuery (  \" field \"  ,     \" value \"  )  )  . endObject (  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "BytesReference   source    =    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     \" value \"  )  . endObject (  )  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder ( queryFieldName ,    source ,    XContentType . JSON )  )  . setIndices (  \" test 1  \"  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getType (  )  ,    equalTo (  \" type \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getIndex (  )  ,    equalTo (  \" test 1  \"  )  )  ;", "response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  (  \" object _ field .  \"     +    queryFieldName )  ,    source ,    XContentType . JSON )  )  . setIndices (  \" test 2  \"  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getId (  )  ,    equalTo (  \"  1  \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getType (  )  ,    equalTo (  \" type \"  )  )  ;", "assertThat ( response . getHits (  )  . getAt (  0  )  . getIndex (  )  ,    equalTo (  \" test 2  \"  )  )  ;", "MapperParsingException   e    =    expectThrows ( MapperParsingException . class ,     (  )     -  >     {", "client (  )  . prepareIndex (  \" test 2  \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . startArray (  \" object _ field \"  )  . startObject (  )  . field ( queryFieldName ,    matchQuery (  \" field \"  ,     \" value \"  )  )  . endObject (  )  . startObject (  )  . field ( queryFieldName ,    matchQuery (  \" field \"  ,     \" value \"  )  )  . endObject (  )  . endArray (  )  . endObject (  )  )  . get (  )  ;", "}  )  ;", "assertThat ( e . getCause (  )  ,    instanceOf ( IllegalArgumentException . class )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    equalTo (  \" a   document   can   only   contain   one      query \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testWithMultiplePercolatorFields"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchIT"}, {"methodBody": ["METHOD_START", "{", "Settings . Builder   settings    =    Settings . builder (  )  . put (  \" index . percolator . map _ unmapped _ fields _ as _ text \"  ,    true )  ;", "createIndex (  \" test \"  ,    settings . build (  )  ,     \" query \"  ,     \" query \"  ,     \" type = percolator \"  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" query \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    matchQuery (  \" field 1  \"  ,     \" value \"  )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" test \"  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" value \"  )  . endObject (  )  )  ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertSearchHits ( response ,     \"  1  \"  )  ;", "}", "METHOD_END"], "methodName": ["testMapUnmappedFieldAsText"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchTests"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   mapping    =    XContentFactory . jsonBuilder (  )  ;", "mapping . startObject (  )  ;", "{", "mapping . startObject (  \" properties \"  )  ;", "{", "mapping . startObject (  \" query \"  )  ;", "mapping . field (  \" type \"  ,     \"  \"  )  ;", "mapping . endObject (  )  ;", "}", "{", "mapping . startObject (  \" companyname \"  )  ;", "mapping . field (  \" type \"  ,     \" text \"  )  ;", "mapping . endObject (  )  ;", "}", "{", "mapping . startObject (  \" employees \"  )  ;", "mapping . field (  \" type \"  ,     \" nested \"  )  ;", "{", "mapping . startObject (  \" properties \"  )  ;", "{", "mapping . startObject (  \" name \"  )  ;", "mapping . field (  \" type \"  ,     \" text \"  )  ;", "mapping . field (  \" fielddata \"  ,    true )  ;", "mapping . endObject (  )  ;", "}", "mapping . endObject (  )  ;", "}", "mapping . endObject (  )  ;", "}", "mapping . endObject (  )  ;", "}", "mapping . endObject (  )  ;", "createIndex (  \" test \"  ,    client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" employee \"  ,    mapping )  )  ;", "Script   script    =    new   Script ( ScriptType . INLINE ,    MockScriptPlugin . NAME ,     \" use _ fielddata _ please \"  ,    Collections . emptyMap (  )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" employee \"  ,     \" q 1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    QueryBuilders . nestedQuery (  \" employees \"  ,    QueryBuilders . scriptQuery ( script )  ,    Avg )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "XContentBuilder   doc    =    jsonBuilder (  )  ;", "doc . startObject (  )  ;", "{", "doc . field (  \" companyname \"  ,     \" stark \"  )  ;", "doc . startArray (  \" employees \"  )  ;", "{", "doc . startObject (  )  ;", "doc . field (  \" name \"  ,     \" virginia _ potts \"  )  ;", "doc . endObject (  )  ;", "}", "{", "doc . startObject (  )  ;", "doc . field (  \" name \"  ,     \" tony _ stark \"  )  ;", "doc . endObject (  )  ;", "}", "doc . endArray (  )  ;", "}", "doc . endObject (  )  ;", "for    ( int   i    =     0  ;    i    <     3  2  ;    i +  +  )     {", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( doc )  ,    XContentType . JSON )  )  . addSort (  \"  _ doc \"  ,    ASC )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "}", "long   fieldDataSize    =    client (  )  . admin (  )  . cluster (  )  . prepareClusterStats (  )  . get (  )  . getIndicesStats (  )  . getFieldData (  )  . getMemorySizeInBytes (  )  ;", "assertEquals (  \" The      works   with   in - memory   index   and   therefor   shouldn ' t   use   field - data   cache \"  ,     0 L ,    fieldDataSize )  ;", "}", "METHOD_END"], "methodName": ["testPercolateQueryWithNestedDocuments_doLeakFieldDataCacheEntries"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchTests"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   mapping    =    XContentFactory . jsonBuilder (  )  ;", "mapping . startObject (  )  . startObject (  \" properties \"  )  . startObject (  \" companyname \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . startObject (  \" query \"  )  . field (  \" type \"  ,     \"  \"  )  . endObject (  )  . startObject (  \" employee \"  )  . field (  \" type \"  ,     \" nested \"  )  . startObject (  \" properties \"  )  . startObject (  \" name \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  ;", "createIndex (  \" test \"  ,    client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . setSettings ( Settings . builder (  )  . put ( INDEX _ LOAD _ RANDOM _ ACCESS _ FILTERS _ EAGERLY _ SETTING . getKey (  )  ,    false )  )  . addMapping (  \" employee \"  ,    mapping )  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" employee \"  ,     \" q 1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    QueryBuilders . nestedQuery (  \" employee \"  ,    matchQuery (  \" employee . name \"  ,     \" virginia   potts \"  )  . operator ( AND )  ,    Avg )  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "for    ( int   i    =     0  ;    i    <     3  2  ;    i +  +  )     {", "SearchResponse   response    =    client (  )  . prepareSearch (  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( XContentFactory . jsonBuilder (  )  . startObject (  )  . field (  \" companyname \"  ,     \" stark \"  )  . startArray (  \" employee \"  )  . startObject (  )  . field (  \" name \"  ,     \" virginia   potts \"  )  . endObject (  )  . startObject (  )  . field (  \" name \"  ,     \" tony   stark \"  )  . endObject (  )  . endArray (  )  . endObject (  )  )  ,    XContentType . JSON )  )  . addSort (  \"  _ doc \"  ,    ASC )  . setSize (  0  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "}", "long   bitsetSize    =    client (  )  . admin (  )  . cluster (  )  . prepareClusterStats (  )  . get (  )  . getIndicesStats (  )  . getSegments (  )  . getBitsetMemoryInBytes (  )  ;", "assertEquals (  \" The      works   with   in - memory   index   and   therefor   shouldn ' t   use   bitset   cache \"  ,     0 L ,    bitsetSize )  ;", "}", "METHOD_END"], "methodName": ["testPercolateQueryWithNestedDocuments_doNotLeakBitsetCacheEntries"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchTests"}, {"methodBody": ["METHOD_START", "{", "client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" index \"  )  . addMapping (  \" type \"  ,     \" query \"  ,     \" type = percolator \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" index \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" query \"  ,    QueryBuilders . scriptQuery ( new   script . Script ( ScriptType . INLINE ,    NAME ,     \"  1  =  =  1  \"  ,    Collections . emptyMap (  )  )  )  )  . endObject (  )  )  . setRefreshPolicy ( IMMEDIATE )  . execute (  )  . actionGet (  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" index \"  )  . setQuery ( new   PercolateQueryBuilder (  \" query \"  ,    BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" field 1  \"  ,     \" b \"  )  . endObject (  )  )  ,    XContentType . JSON )  )  . get (  )  ;", "assertHitCount ( response ,     1  )  ;", "assertSearchHits ( response ,     \"  1  \"  )  ;", "}", "METHOD_END"], "methodName": ["testPercolateScriptQuery"], "fileName": "org.elasticsearch.percolator.PercolatorQuerySearchTests"}, {"methodBody": ["METHOD_START", "{", "Class <  ?  >    queryClass    =    query . getClass (  )  ;", "if    ( queryClass . isAnonymousClass (  )  )     {", "queryClass    =    queryClass . getSuperclass (  )  ;", "}", "BiFunction < Query ,    Version ,     . Result >    queryProcessor    =     . queryProcessors . get ( queryClass )  ;", "if    ( queryProcessor    !  =    null )     {", "return   queryProcessor . apply ( query ,    indexVersion )  ;", "} else    {", "throw   new    . UnsupportedQueryException ( query )  ;", "}", "}", "METHOD_END"], "methodName": ["analyze"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "Set <  . QueryExtraction >    terms    =     (  ( BlendedTermQuery )     ( query )  )  . getTerms (  )  . stream (  )  . map (  . QueryExtraction :  : new )  . collect ( Collectors . toSet (  )  )  ;", "return   new    . Result ( true ,    terms ,    Math . min (  1  ,    terms . size (  )  )  )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["blendedTermQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "BooleanQuery   bq    =     (  ( BooleanQuery )     ( query )  )  ;", "int   minimumShouldMatch    =    bq . getMinimumNumberShouldMatch (  )  ;", "List < Query >    requiredClauses    =    new   ArrayList <  >  (  )  ;", "List < Query >    optionalClauses    =    new   ArrayList <  >  (  )  ;", "boolean   hasProhibitedClauses    =    false ;", "for    ( BooleanClause   clause    :    bq . clauses (  )  )     {", "if    ( clause . isRequired (  )  )     {", "requiredClauses . add ( clause . getQuery (  )  )  ;", "} else", "if    ( clause . isProhibited (  )  )     {", "hasProhibitedClauses    =    true ;", "} else    {", "assert    ( clause . getOccur (  )  )     =  =     ( SHOULD )  ;", "optionalClauses . add ( clause . getQuery (  )  )  ;", "}", "}", "if    (  ( minimumShouldMatch    >     ( optionalClauses . size (  )  )  )     |  |     (  ( requiredClauses . isEmpty (  )  )     &  &     ( optionalClauses . isEmpty (  )  )  )  )     {", "return   new    . Result ( false ,    Collections . emptySet (  )  ,     0  )  ;", "}", "if    (  ( requiredClauses . size (  )  )     >     0  )     {", "if    ( minimumShouldMatch    >     0  )     {", "BooleanQuery . Builder   minShouldMatchQuery    =    new   BooleanQuery . Builder (  )  ;", "minShouldMatchQuery . setMinimumNumberShouldMatch ( minimumShouldMatch )  ;", "for    ( Query   q    :    optionalClauses )     {", "minShouldMatchQuery . add ( q ,    SHOULD )  ;", "}", "requiredClauses . add ( minShouldMatchQuery . build (  )  )  ;", "optionalClauses . clear (  )  ;", "minimumShouldMatch    =     0  ;", "} else    {", "optionalClauses . clear (  )  ;", "}", "}", ". Result   result ;", "if    (  ( requiredClauses . size (  )  )     >     0  )     {", "assert   optionalClauses . isEmpty (  )  ;", "assert   minimumShouldMatch    =  =     0  ;", "result    =     . handleConjunctionQuery ( requiredClauses ,    version )  ;", "} else    {", "assert   requiredClauses . isEmpty (  )  ;", "if    ( minimumShouldMatch    =  =     0  )     {", "minimumShouldMatch    =     1  ;", "}", "result    =     . handleDisjunctionQuery ( optionalClauses ,    minimumShouldMatch ,    version )  ;", "}", "if    ( hasProhibitedClauses )     {", "result    =    result . unverify (  )  ;", "}", "return   result ;", "}  ;", "}", "METHOD_END"], "methodName": ["booleanQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "Query   wrappedQuery    =     (  ( BoostQuery )     ( query )  )  . getQuery (  )  ;", "return    . analyze ( wrappedQuery ,    version )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["boostQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "Set <  . QueryExtraction >    terms    =     (  ( CommonTermsQuery )     ( query )  )  . getTerms (  )  . stream (  )  . map (  . QueryExtraction :  : new )  . collect ( Collectors . toSet (  )  )  ;", "return   new    . Result ( false ,    terms ,    Math . min (  1  ,    terms . size (  )  )  )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["commonTermsQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    boosts )     -  >     {", "Query   wrappedQuery    =     (  ( ConstantScoreQuery )     ( query )  )  . getQuery (  )  ;", "return    . analyze ( wrappedQuery ,    boosts )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["constantScoreQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "List < Query >    disjuncts    =     (  ( DisjunctionMaxQuery )     ( query )  )  . getDisjuncts (  )  ;", "if    ( disjuncts . isEmpty (  )  )     {", "return   new    . Result ( false ,    Collections . emptySet (  )  ,     0  )  ;", "} else    {", "return    . handleDisjunctionQuery ( disjuncts ,     1  ,    version )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["disjunctionMaxQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "FunctionScoreQuery   functionScoreQuery    =     (  ( FunctionScoreQuery )     ( query )  )  ;", ". Result   result    =     . analyze ( functionScoreQuery . getSubQuery (  )  ,    version )  ;", "boolean   verified    =     ( result . verified )     &  &     (  ( functionScoreQuery . getMinScore (  )  )     =  =    null )  ;", "if    ( result . matchAllDocs )     {", "return   new    . Result ( result . matchAllDocs ,    verified )  ;", "} else    {", "return   new    . Result ( verified ,    result . extractions ,    result . minimumShouldMatch )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["functionScoreQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "if    ( conjunctions . isEmpty (  )  )     {", "throw   new   IllegalArgumentException (  \" Must   have   at   least   on   conjunction   sub   result \"  )  ;", "}", "if    ( version . onOrAfter ( V _  6  _  1  _  0  )  )     {", "for    (  . Result   subResult    :    conjunctions )     {", "if    ( subResult . isMatchNoDocs (  )  )     {", "return   subResult ;", "}", "}", "int   msm    =     0  ;", "boolean   verified    =    true ;", "boolean   matchAllDocs    =    true ;", "boolean   hasDuplicateTerms    =    false ;", "Set <  . QueryExtraction >    extractions    =    new   HashSet <  >  (  )  ;", "Set < String >    seenRangeFields    =    new   HashSet <  >  (  )  ;", "for    (  . Result   result    :    conjunctions )     {", "int   resultMsm    =    result . minimumShouldMatch ;", "for    (  . QueryExtraction   queryExtraction    :    result . extractions )     {", "if    (  ( queryExtraction . range )     !  =    null )     {", "if    ( seenRangeFields . add ( queryExtraction . range . fieldName )  )     {", "resultMsm    =     1  ;", "} else    {", "resultMsm    =     0  ;", "}", "}", "if    ( extractions . contains ( queryExtraction )  )     {", "resultMsm    =     0  ;", "verified    =    false ;", "break ;", "}", "}", "msm    +  =    resultMsm ;", "if    (  (  ( result . verified )     =  =    false )     |  |     (  ( result . minimumShouldMatch )     <     ( result . extractions . size (  )  )  )  )     {", "verified    =    false ;", "}", "matchAllDocs    &  =    result . matchAllDocs ;", "extractions . addAll ( result . extractions )  ;", "}", "if    ( matchAllDocs )     {", "return   new    . Result ( matchAllDocs ,    verified )  ;", "} else    {", "return   new    . Result ( verified ,    extractions ,     ( hasDuplicateTerms    ?     1     :    msm )  )  ;", "}", "} else    {", ". Result   bestClause    =    null ;", "for    (  . Result   result    :    conjunctions )     {", "bestClause    =     . selectBestResult ( result ,    bestClause )  ;", "}", "return   bestClause ;", "}", "}", "METHOD_END"], "methodName": ["handleConjunction"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "QueryAnalyzer . UnsupportedQueryException   uqe    =    null ;", "List < QueryAnalyzer . Result >    results    =    new   ArrayList ( conjunctions . size (  )  )  ;", "boolean   success    =    false ;", "for    ( Query   query    :    conjunctions )     {", "try    {", "QueryAnalyzer . Result   subResult    =    QueryAnalyzer . analyze ( query ,    version )  ;", "if    ( subResult . isMatchNoDocs (  )  )     {", "return   subResult ;", "}", "results . add ( subResult )  ;", "success    =    true ;", "}    catch    ( QueryAnalyzer . UnsupportedQueryException   e )     {", "uqe    =    e ;", "}", "}", "if    ( success    =  =    false )     {", "if    ( uqe    !  =    null )     {", "throw   uqe ;", "} else    {", "return   new   QueryAnalyzer . Result ( true ,    Collections . emptySet (  )  ,     0  )  ;", "}", "}", "QueryAnalyzer . Result   result    =    QueryAnalyzer . handleConjunction ( results ,    version )  ;", "if    ( uqe    !  =    null )     {", "result    =    result . unverify (  )  ;", "}", "return   result ;", "}", "METHOD_END"], "methodName": ["handleConjunctionQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "List < Integer >    clauses    =    new   ArrayList <  >  ( disjunctions . size (  )  )  ;", "boolean   verified ;", "if    ( version . before ( V _  6  _  1  _  0  )  )     {", "verified    =    requiredShouldClauses    <  =     1  ;", "} else    {", "verified    =    true ;", "}", "int   numMatchAllClauses    =     0  ;", "boolean   hasRangeExtractions    =    false ;", "boolean   hasDuplicateTerms    =    false ;", "Set <  . QueryExtraction >    terms    =    new   HashSet <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( disjunctions . size (  )  )  ;    i +  +  )     {", ". Result   subResult    =    disjunctions . get ( i )  ;", "if    (  (  (  ( subResult . verified )     =  =    false )     |  |     (  ( subResult . minimumShouldMatch )     >     1  )  )     |  |     (  (  ( subResult . extractions . size (  )  )     >     1  )     &  &     ( requiredShouldClauses    >     1  )  )  )     {", "verified    =    false ;", "}", "if    ( subResult . matchAllDocs )     {", "numMatchAllClauses +  +  ;", "}", "int   resultMsm    =    subResult . minimumShouldMatch ;", "for    (  . QueryExtraction   extraction    :    subResult . extractions )     {", "if    (  ( terms . add ( extraction )  )     =  =    false )     {", "verified    =    false ;", "hasDuplicateTerms    =    true ;", "}", "}", "if    ( hasRangeExtractions    =  =    false )     {", "hasRangeExtractions    =    subResult . extractions . stream (  )  . anyMatch (  (    qe )     -  >     ( qe . range )     !  =    null )  ;", "}", "clauses . add ( resultMsm )  ;", "}", "boolean   matchAllDocs    =     ( numMatchAllClauses    >     0  )     &  &     ( numMatchAllClauses    >  =    requiredShouldClauses )  ;", "int   msm    =     0  ;", "if    (  ( version . onOrAfter ( V _  6  _  1  _  0  )  )     &  &     ( hasRangeExtractions    =  =    false )  )     {", "clauses    =    clauses . stream (  )  . filter (  (    val )     -  >    val    >     0  )  . sorted (  )  . collect ( Collectors . toList (  )  )  ;", "if    ( hasDuplicateTerms )     {", "msm    =    clauses . get (  0  )  ;", "} else    {", "int   limit    =    Math . min ( clauses . size (  )  ,    Math . max (  1  ,    requiredShouldClauses )  )  ;", "for    ( int   i    =     0  ;    i    <    limit ;    i +  +  )     {", "msm    +  =    clauses . get ( i )  ;", "}", "}", "} else    {", "msm    =     1  ;", "}", "if    ( matchAllDocs )     {", "return   new    . Result ( matchAllDocs ,    verified )  ;", "} else    {", "return   new    . Result ( verified ,    terms ,    msm )  ;", "}", "}", "METHOD_END"], "methodName": ["handleDisjunction"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "List < QueryAnalyzer . Result >    subResults    =    new   ArrayList <  >  (  )  ;", "for    ( Query   query    :    disjunctions )     {", "QueryAnalyzer . Result   subResult    =    QueryAnalyzer . analyze ( query ,    version )  ;", "subResults . add ( subResult )  ;", "}", "return   QueryAnalyzer . handleDisjunction ( subResults ,    requiredShouldClauses ,    version )  ;", "}", "METHOD_END"], "methodName": ["handleDisjunctionQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "IndexOrDocValuesQuery   indexOrDocValuesQuery    =     (  ( IndexOrDocValuesQuery )     ( query )  )  ;", "return    . analyze ( indexOrDocValuesQuery . getIndexQuery (  )  ,    version )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["indexOrDocValuesQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >    new   QueryAnalyzer . Result ( true ,    true )  ;", "}", "METHOD_END"], "methodName": ["matchAllDocsQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >    new   QueryAnalyzer . Result ( true ,    Collections . emptySet (  )  ,     0  )  ;", "}", "METHOD_END"], "methodName": ["matchNoDocsQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( extractions . stream (  )  . filter (  (    queryExtraction )     -  >     ( queryExtraction . term )     !  =    null )  . count (  )  )     =  =     0  )     &  &     (  ( extractions . stream (  )  . filter (  (    queryExtraction )     -  >     ( queryExtraction . range )     !  =    null )  . count (  )  )     >     0  )  )     {", "return   Integer . MIN _ VALUE ;", "}", "int   min    =    Integer . MAX _ VALUE ;", "for    (  . QueryExtraction   qt    :    extractions )     {", "if    (  ( qt . term )     !  =    null )     {", "min    =    Math . min ( min ,    qt . bytes (  )  . length )  ;", "}", "}", "return   min ;", "}", "METHOD_END"], "methodName": ["minTermLength"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "Term [  ]  [  ]    terms    =     (  ( MultiPhraseQuery )     ( query )  )  . getTermArrays (  )  ;", "if    (  ( terms . length )     =  =     0  )     {", "return   new    . Result ( true ,    Collections . emptySet (  )  ,     0  )  ;", "}", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "for    ( Term [  ]    termArr    :    terms )     {", "BooleanQuery . Builder   subBuilder    =    new   BooleanQuery . Builder (  )  ;", "for    ( Term   term    :    termArr )     {", "subBuilder . add ( new   TermQuery ( term )  ,    SHOULD )  ;", "}", "builder . add ( subBuilder . build (  )  ,    FILTER )  ;", "}", "return    . booleanQuery (  )  . apply ( builder . build (  )  ,    version )  . unverify (  )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["multiPhraseQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "Term [  ]    terms    =     (  ( PhraseQuery )     ( query )  )  . getTerms (  )  ;", "if    (  ( terms . length )     =  =     0  )     {", "return   new    . Result ( true ,    Collections . emptySet (  )  ,     0  )  ;", "}", "if    ( version . onOrAfter ( V _  6  _  1  _  0  )  )     {", "Set <  . QueryExtraction >    extractions    =    Arrays . stream ( terms )  . map (  . QueryExtraction :  : new )  . collect ( Collectors . toSet (  )  )  ;", "return   new    . Result ( false ,    extractions ,    extractions . size (  )  )  ;", "} else    {", "Term   longestTerm    =    terms [  0  ]  ;", "for    ( Term   term    :    terms )     {", "if    (  ( longestTerm . bytes (  )  . length )     <     ( term . bytes (  )  . length )  )     {", "longestTerm    =    term ;", "}", "}", "return   new    . Result ( false ,    Collections . singleton ( new    . QueryExtraction ( longestTerm )  )  ,     1  )  ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["phraseQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "PointRangeQuery   pointRangeQuery    =     (  ( PointRangeQuery )     ( query )  )  ;", "if    (  ( pointRangeQuery . getNumDims (  )  )     !  =     1  )     {", "throw   new    . UnsupportedQueryException ( query )  ;", "}", "byte [  ]    lowerPoint    =    pointRangeQuery . getLowerPoint (  )  ;", "byte [  ]    upperPoint    =    pointRangeQuery . getUpperPoint (  )  ;", "if    (  ( new   BytesRef ( lowerPoint )  . compareTo ( new   BytesRef ( upperPoint )  )  )     >     0  )     {", "return   new    . Result ( true ,    Collections . emptySet (  )  ,     0  )  ;", "}", "byte [  ]    interval    =    new   byte [  1  6  ]  ;", "NumericUtils . subtract (  1  6  ,     0  ,     . prepad ( upperPoint )  ,     . prepad ( lowerPoint )  ,    interval )  ;", "return   new    . Result ( false ,    Collections . singleton ( new    . QueryExtraction ( new    . Range ( pointRangeQuery . getField (  )  ,    lowerPoint ,    upperPoint ,    interval )  )  )  ,     1  )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["pointRangeQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "int   offset    =     ( BinaryRange . BYTES )     -     ( original . length )  ;", "byte [  ]    result    =    new   byte [ BinaryRange . BYTES ]  ;", "System . arraycopy ( original ,     0  ,    result ,    offset ,    original . length )  ;", "return   result ;", "}", "METHOD_END"], "methodName": ["prepad"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "assert    ( result 1     !  =    null )     |  |     ( result 2     !  =    null )  ;", "if    ( result 1     =  =    null )     {", "return   result 2  ;", "} else", "if    ( result 2     =  =    null )     {", "return   result 1  ;", "} else", "if    ( result 1  . matchAllDocs )     {", ". Result   result    =    result 2  ;", "if    (  ( result 1  . verified )     =  =    false )     {", "result    =    result . unverify (  )  ;", "}", "return   result ;", "} else", "if    ( result 2  . matchAllDocs )     {", ". Result   result    =    result 1  ;", "if    (  ( result 2  . verified )     =  =    false )     {", "result    =    result . unverify (  )  ;", "}", "return   result ;", "} else    {", "boolean   onlyRangeBasedExtractions    =    true ;", "for    (  . QueryExtraction   clause    :    result 1  . extractions )     {", "if    (  ( clause . term )     !  =    null )     {", "onlyRangeBasedExtractions    =    false ;", "break ;", "}", "}", "for    (  . QueryExtraction   clause    :    result 2  . extractions )     {", "if    (  ( clause . term )     !  =    null )     {", "onlyRangeBasedExtractions    =    false ;", "break ;", "}", "}", "if    ( onlyRangeBasedExtractions )     {", "BytesRef   extraction 1 SmallestRange    =     . smallestRange ( result 1  . extractions )  ;", "BytesRef   extraction 2 SmallestRange    =     . smallestRange ( result 2  . extractions )  ;", "if    ( extraction 1 SmallestRange    =  =    null )     {", "return   result 2  . unverify (  )  ;", "} else", "if    ( extraction 2 SmallestRange    =  =    null )     {", "return   result 1  . unverify (  )  ;", "}", "if    (  ( extraction 1 SmallestRange . compareTo ( extraction 2 SmallestRange )  )     <  =     0  )     {", "return   result 1  . unverify (  )  ;", "} else    {", "return   result 2  . unverify (  )  ;", "}", "} else    {", "int   extraction 1 ShortestTerm    =     . minTermLength ( result 1  . extractions )  ;", "int   extraction 2 ShortestTerm    =     . minTermLength ( result 2  . extractions )  ;", "if    ( extraction 1 ShortestTerm    >  =    extraction 2 ShortestTerm )     {", "return   result 1  . unverify (  )  ;", "} else    {", "return   result 2  . unverify (  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["selectBestResult"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "BytesRef   min    =    null ;", "for    (  . QueryExtraction   qt    :    terms )     {", "if    (  ( qt . range )     !  =    null )     {", "if    (  ( min    =  =    null )     |  |     (  ( qt . range . interval . compareTo ( min )  )     <     0  )  )     {", "min    =    qt . range . interval ;", "}", "}", "}", "return   min ;", "}", "METHOD_END"], "methodName": ["smallestRange"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", ". Result   result    =     . analyze (  (  ( SpanFirstQuery )     ( query )  )  . getMatch (  )  ,    version )  ;", "return   new    . Result ( false ,    result . extractions ,    result . minimumShouldMatch )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["spanFirstQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "SpanNearQuery   spanNearQuery    =     (  ( SpanNearQuery )     ( query )  )  ;", "if    ( version . onOrAfter ( V _  6  _  1  _  0  )  )     {", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "for    ( SpanQuery   clause    :    spanNearQuery . getClauses (  )  )     {", "builder . add ( clause ,    FILTER )  ;", "}", "return    . booleanQuery (  )  . apply ( builder . build (  )  ,    version )  . unverify (  )  ;", "} else    {", ". Result   bestClause    =    null ;", "for    ( SpanQuery   clause    :    spanNearQuery . getClauses (  )  )     {", ". Result   temp    =     . analyze ( clause ,    version )  ;", "bestClause    =     . selectBestResult ( temp ,    bestClause )  ;", "}", "return   bestClause ;", "}", "}  ;", "}", "METHOD_END"], "methodName": ["spanNearQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", ". Result   result    =     . analyze (  (  ( SpanNotQuery )     ( query )  )  . getInclude (  )  ,    version )  ;", "return   new    . Result ( false ,    result . extractions ,    result . minimumShouldMatch )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["spanNotQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "SpanOrQuery   spanOrQuery    =     (  ( SpanOrQuery )     ( query )  )  ;", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "for    ( SpanQuery   clause    :    spanOrQuery . getClauses (  )  )     {", "builder . add ( clause ,    SHOULD )  ;", "}", "return    . booleanQuery (  )  . apply ( builder . build (  )  ,    version )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["spanOrQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "Term   term    =     (  ( SpanTermQuery )     ( query )  )  . getTerm (  )  ;", "return   new    . Result ( true ,    Collections . singleton ( new    . QueryExtraction ( term )  )  ,     1  )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["spanTermQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "Set <  . QueryExtraction >    terms    =     (  ( SynonymQuery )     ( query )  )  . getTerms (  )  . stream (  )  . map (  . QueryExtraction :  : new )  . collect ( Collectors . toSet (  )  )  ;", "return   new    . Result ( true ,    terms ,    Math . min (  1  ,    terms . size (  )  )  )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["synonymQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "TermInSetQuery   termInSetQuery    =     (  ( TermInSetQuery )     ( query )  )  ;", "Set <  . QueryExtraction >    terms    =    new   HashSet <  >  (  )  ;", "PrefixCodedTerms . TermIterator   iterator    =    termInSetQuery . getTermData (  )  . iterator (  )  ;", "for    ( BytesRef   term    =    iterator . next (  )  ;    term    !  =    null ;    term    =    iterator . next (  )  )     {", "terms . add ( new    . QueryExtraction ( new   Term ( iterator . field (  )  ,    term )  )  )  ;", "}", "return   new    . Result ( true ,    terms ,    Math . min (  1  ,    terms . size (  )  )  )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["termInSetQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "TermQuery   termQuery    =     (  ( TermQuery )     ( query )  )  ;", "return   new    . Result ( true ,    Collections . singleton ( new    . QueryExtraction ( termQuery . getTerm (  )  )  )  ,     1  )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["termQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "return    (    query ,    version )     -  >     {", "ESToParentBlockJoinQuery   toParentBlockJoinQuery    =     (  ( ESToParentBlockJoinQuery )     ( query )  )  ;", ". Result   result    =     . analyze ( toParentBlockJoinQuery . getChildQuery (  )  ,    version )  ;", "return   new    . Result ( false ,    result . extractions ,    result . minimumShouldMatch )  ;", "}  ;", "}", "METHOD_END"], "methodName": ["toParentBlockJoinQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzer"}, {"methodBody": ["METHOD_START", "{", "byte [  ]    dest    =    new   byte [ expected . length ]  ;", "consumer . accept ( dest )  ;", "assertArrayEquals ( expected ,    dest )  ;", "}", "METHOD_END"], "methodName": ["assertDimension"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( Arrays . stream ( expected )  . map ( QueryAnalyzer . QueryExtraction :  : new )  . collect ( Collectors . toSet (  )  )  ,    actual )  ;", "}", "METHOD_END"], "methodName": ["assertTermsEqual"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "Set < QueryAnalyzer . QueryExtraction >    queryExtractions    =    new   HashSet <  >  (  )  ;", "for    ( int   interval    :    intervals )     {", "byte [  ]    encodedInterval    =    new   byte [  4  ]  ;", "IntPoint . encodeDimension ( interval ,    encodedInterval ,     0  )  ;", "queryExtractions . add ( new   QueryAnalyzer . QueryExtraction ( new   QueryAnalyzer . Range (  \"  _ field \"  ,    null ,    null ,    encodedInterval )  )  )  ;", "}", "for    ( String   value    :    values )     {", "queryExtractions . add ( new   QueryAnalyzer . QueryExtraction ( new   Term (  \"  _ field \"  ,    value )  )  )  ;", "}", "return   queryExtractions ;", "}", "METHOD_END"], "methodName": ["terms"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  )  ;", "builder . add ( termQuery 2  ,    SHOULD )  ;", "TermQuery   termQuery 3     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )  )  ;", "builder . add ( termQuery 3  ,    MUST )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Must   clause   is   exact ,    so   this   is   a   verified   candidate   match \"  ,    result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  1  )  )  ;", "List < QueryAnalyzer . QueryExtraction >    extractions    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( extractions . get (  0  )  . term ,    equalTo ( new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )  )  )  ;", "builder . setMinimumNumberShouldMatch (  1  )  ;", "result    =    QueryAnalyzer . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Must   clause   is   exact ,    but   m _ s _ m   is    1    so   one   should   clause   must   match   too \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", ". assertTermsEqual ( result . extractions ,    termQuery 1  . getTerm (  )  ,    termQuery 2  . getTerm (  )  ,    termQuery 3  . getTerm (  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "BooleanQuery . Builder   innerBuilder    =    new   BooleanQuery . Builder (  )  ;", "innerBuilder . setMinimumNumberShouldMatch (  2  )  ;", "innerBuilder . add ( termQuery 1  ,    SHOULD )  ;", "innerBuilder . add ( termQuery 2  ,    SHOULD )  ;", "builder . add ( innerBuilder . build (  )  ,    MUST )  ;", "builder . add ( termQuery 3  ,    MUST )  ;", "result    =    QueryAnalyzer . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Verified ,    because   m _ s _ m   is   specified   in   an   inner   clause   and   not   top   level   clause \"  ,    result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  3  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  3  )  )  ;", "extractions    =    new   ArrayList <  >  ( result . extractions )  ;", "extractions . sort ( Comparator . comparing (  (    key )     -  >    key . term )  )  ;", "assertThat ( extractions . get (  0  )  . term ,    equalTo ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  )  ;", "assertThat ( extractions . get (  1  )  . term ,    equalTo ( new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  )  )  ;", "assertThat ( extractions . get (  2  )  . term ,    equalTo ( new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( innerBuilder . build (  )  ,    SHOULD )  ;", "builder . add ( termQuery 3  ,    MUST )  ;", "result    =    QueryAnalyzer . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Verified ,    because   m _ s _ m   is   specified   in   an   inner   clause   and   not   top   level   clause \"  ,    result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  1  )  )  ;", "extractions    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( extractions . get (  0  )  . term ,    equalTo ( new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testBooleanQueryWithMustAndShouldClauses"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", ". Result   result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . matchAllDocs ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "result    =     . analyze ( new   DisjunctionMaxQuery ( Collections . emptyList (  )  ,     0  .  0 F )  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . matchAllDocs ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmptyQueries"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  )  ;", "builder . add ( termQuery 2  ,    SHOULD )  ;", ". Result   result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" All   clauses   are   exact ,    so   candidate   matches   are   verified \"  ,    result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "PhraseQuery   phraseQuery 1     =    new   PhraseQuery (  \"  _ field \"  ,     \"  _ term 1  \"  ,     \"  _ term 2  \"  )  ;", "builder . add ( phraseQuery 1  ,    SHOULD )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Clause   isn ' t   exact ,    so   candidate   matches   are   not   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( phraseQuery 1  ,    SHOULD )  ;", "PhraseQuery   phraseQuery 2     =    new   PhraseQuery (  \"  _ field \"  ,     \"  _ term 3  \"  ,     \"  _ term 4  \"  )  ;", "builder . add ( phraseQuery 2  ,    SHOULD )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" No   clause   is   exact ,    so   candidate   matches   are   not   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,    MUST _ NOT )  ;", "builder . add ( termQuery 2  ,    SHOULD )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" There   is   a   must _ not   clause ,    so   candidate   matches   are   not   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "int   msm    =    randomIntBetween (  2  ,     3  )  ;", "builder . setMinimumNumberShouldMatch ( msm )  ;", "TermQuery   termQuery 3     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "builder . add ( termQuery 2  ,    SHOULD )  ;", "builder . add ( termQuery 3  ,    SHOULD )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Minimum   match   has   not   impact   on   whether   the   result   is   verified \"  ,    result . verified ,    is ( true )  )  ;", "assertThat (  \" msm   is   at   least   two   so   result . minimumShouldMatch   should    2    too \"  ,    result . minimumShouldMatch ,    equalTo ( msm )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,     ( randomBoolean (  )     ?    Occur . MUST    :    Occur . FILTER )  )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Also   required   clauses   are   taken   into   account   whether   the   result   is   verified \"  ,    result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,     ( randomBoolean (  )     ?    Occur . MUST    :    Occur . FILTER )  )  ;", "builder . add ( termQuery 2  ,     ( randomBoolean (  )     ?    Occur . MUST    :    Occur . FILTER )  )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Also   required   clauses   are   taken   into   account   whether   the   result   is   verified \"  ,    result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,     ( randomBoolean (  )     ?    Occur . MUST    :    Occur . FILTER )  )  ;", "builder . add ( termQuery 2  ,    MUST _ NOT )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Prohibited   clause ,    so   candidate   matches   are   not   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,     ( randomBoolean (  )     ?    Occur . MUST    :    Occur . FILTER )  )  ;", "builder . add ( termQuery 2  ,    MUST _ NOT )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Prohibited   clause ,    so   candidate   matches   are   not   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  . add ( new   BooleanQuery . Builder (  )  . add ( termQuery 1  ,    FILTER )  . add ( termQuery 2  ,    FILTER )  . build (  )  ,    Occur . SHOULD )  . add ( termQuery 3  ,    Occur . SHOULD )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Inner   clause   that   is   not   a   pure   disjunction ,    so   candidate   matches   are   not   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  . add ( new   BooleanQuery . Builder (  )  . add ( termQuery 1  ,    Occur . SHOULD )  . add ( termQuery 2  ,    Occur . SHOULD )  . build (  )  ,    Occur . SHOULD )  . add ( termQuery 3  ,    Occur . SHOULD )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Inner   clause   that   is   a   pure   disjunction ,    so   candidate   matches   are   verified \"  ,    result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  . add ( new   BooleanQuery . Builder (  )  . add ( termQuery 1  ,    Occur . SHOULD )  . add ( termQuery 2  ,    Occur . SHOULD )  . build (  )  ,    MUST )  . add ( termQuery 3  ,    FILTER )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Disjunctions   of   conjunctions   can ' t   be   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  . add ( new   BooleanQuery . Builder (  )  . add ( termQuery 1  ,    MUST )  . add ( termQuery 2  ,    FILTER )  . build (  )  ,    Occur . SHOULD )  . add ( termQuery 3  ,    Occur . SHOULD )  ;", "result    =     . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat (  \" Conjunctions   of   disjunctions   can ' t   be   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "}", "METHOD_END"], "methodName": ["testExactMatch_booleanQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "Term [  ]    termsArr    =    new   Term [  ]  {    new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  ,    new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )     }  ;", "BlendedTermQuery   commonTermsQuery    =    BlendedTermQuery . dismaxBlendedQuery ( termsArr ,     1  .  0 F )  ;", ". Result   result    =     . analyze ( commonTermsQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  0  )  . text (  )  ,    equalTo (  \"  _ term 1  \"  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  1  )  . text (  )  ,    equalTo (  \"  _ term 2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_blendedTermQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \" term 0  \"  )  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "PhraseQuery   phraseQuery    =    new   PhraseQuery (  \"  _ field \"  ,     \" term 1  \"  ,     \" term 2  \"  )  ;", "builder . add ( phraseQuery ,    SHOULD )  ;", "BooleanQuery . Builder   subBuilder    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( new   Term (  \"  _ field 1  \"  ,     \" term 4  \"  )  )  ;", "subBuilder . add ( termQuery 2  ,    MUST )  ;", "TermQuery   termQuery 3     =    new   TermQuery ( new   Term (  \"  _ field 3  \"  ,     \" term 5  \"  )  )  ;", "subBuilder . add ( termQuery 3  ,    MUST )  ;", "builder . add ( subBuilder . build (  )  ,    SHOULD )  ;", "BooleanQuery   booleanQuery    =    builder . build (  )  ;", ". Result   result    =     . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat (  \" Should   clause   with   phrase   query   isn ' t   verified ,    so   entire   query   can ' t   be   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  5  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  0  ]  . field (  )  )  )  ;", "assertThat ( terms . get (  1  )  . bytes (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  0  ]  . bytes (  )  )  )  ;", "assertThat ( terms . get (  2  )  . field (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  1  ]  . field (  )  )  )  ;", "assertThat ( terms . get (  2  )  . bytes (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  1  ]  . bytes (  )  )  )  ;", "assertThat ( terms . get (  3  )  . field (  )  ,    equalTo ( termQuery 2  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  3  )  . bytes (  )  ,    equalTo ( termQuery 2  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  4  )  . field (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  4  )  . bytes (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . bytes (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_booleanQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term \"  )  )  ;", "builder . add ( termQuery 1  ,    MUST _ NOT )  ;", "PhraseQuery   phraseQuery    =    new   PhraseQuery (  \"  _ field \"  ,     \"  _ term 1  \"  ,     \" term 2  \"  )  ;", "builder . add ( phraseQuery ,    SHOULD )  ;", "BooleanQuery   booleanQuery    =    builder . build (  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", ". assertTermsEqual ( result . extractions ,    phraseQuery . getTerms (  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,    MUST _ NOT )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "booleanQuery    =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", ". assertTermsEqual ( result . extractions )  ;", "result    =    QueryAnalyzer . analyze ( booleanQuery ,    V _  6  _  0  _  0  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", ". assertTermsEqual ( result . extractions )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_booleanQueryWithMustNot"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . setMinimumNumberShouldMatch (  2  )  ;", "Term   term 1     =    new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( term 1  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "Term   term 2     =    new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( term 2  )  ;", "builder . add ( termQuery 2  ,    SHOULD )  ;", "Term   term 3     =    new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )  ;", "TermQuery   termQuery 3     =    new   TermQuery ( term 3  )  ;", "builder . add ( termQuery 3  ,    SHOULD )  ;", "BooleanQuery   booleanQuery    =    builder . build (  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", ". assertTermsEqual ( result . extractions ,    term 1  ,    term 2  ,    term 3  )  ;", "builder    =    new   BooleanQuery . Builder (  )  . add ( new   BooleanQuery . Builder (  )  . add ( termQuery 1  ,    Occur . SHOULD )  . add ( termQuery 2  ,    Occur . SHOULD )  . build (  )  ,    Occur . SHOULD )  . add ( termQuery 3  ,    Occur . SHOULD )  . setMinimumNumberShouldMatch (  2  )  ;", "booleanQuery    =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", ". assertTermsEqual ( result . extractions ,    term 1  ,    term 2  ,    term 3  )  ;", "Term   term 4     =    new   Term (  \"  _ field \"  ,     \"  _ term 4  \"  )  ;", "TermQuery   termQuery 4     =    new   TermQuery ( term 4  )  ;", "builder    =    new   BooleanQuery . Builder (  )  . add ( new   BooleanQuery . Builder (  )  . add ( termQuery 1  ,    MUST )  . add ( termQuery 2  ,    FILTER )  . build (  )  ,    Occur . SHOULD )  . add ( new   BooleanQuery . Builder (  )  . add ( termQuery 3  ,    MUST )  . add ( termQuery 4  ,    FILTER )  . build (  )  ,    Occur . SHOULD )  ;", "booleanQuery    =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", ". assertTermsEqual ( result . extractions ,    term 1  ,    term 2  ,    term 3  ,    term 4  )  ;", "Term   term 5     =    new   Term (  \"  _ field \"  ,     \"  _ term 5  \"  )  ;", "TermQuery   termQuery 5     =    new   TermQuery ( term 5  )  ;", "builder . add ( termQuery 5  ,    Occur . SHOULD )  ;", "booleanQuery    =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    term 1  ,    term 2  ,    term 3  ,    term 4  ,    term 5  )  ;", "builder . setMinimumNumberShouldMatch (  2  )  ;", "booleanQuery    =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  3  )  )  ;", ". assertTermsEqual ( result . extractions ,    term 1  ,    term 2  ,    term 3  ,    term 4  ,    term 5  )  ;", "builder . setMinimumNumberShouldMatch (  3  )  ;", "booleanQuery    =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  5  )  )  ;", ". assertTermsEqual ( result . extractions ,    term 1  ,    term 2  ,    term 3  ,    term 4  ,    term 5  )  ;", "builder    =    new   BooleanQuery . Builder (  )  . add ( new   BooleanQuery . Builder (  )  . add ( termQuery 1  ,    Occur . SHOULD )  . add ( termQuery 2  ,    Occur . SHOULD )  . build (  )  ,    Occur . SHOULD )  . add ( new   BooleanQuery . Builder (  )  . setMinimumNumberShouldMatch (  1  )  . build (  )  ,    Occur . SHOULD )  . setMinimumNumberShouldMatch (  2  )  ;", "booleanQuery    =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( booleanQuery ,    CURRENT )  ;", "assertFalse ( result . verified )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_booleanQuery_msm"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . setMinimumNumberShouldMatch (  2  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  )  ;", "builder . add ( termQuery 2  ,    SHOULD )  ;", "TermQuery   termQuery 3     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )  )  ;", "builder . add ( termQuery 3  ,    SHOULD )  ;", "BooleanQuery   booleanQuery    =    builder . build (  )  ;", ". Result   result    =     . analyze ( booleanQuery ,    V _  6  _  0  _  0  )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    extractions    =    new   ArrayList <  >  ( result . extractions )  ;", "extractions . sort ( Comparator . comparing (  (    extraction )     -  >    extraction . term )  )  ;", "assertThat ( extractions . size (  )  ,    equalTo (  3  )  )  ;", "assertThat ( extractions . get (  0  )  . term ,    equalTo ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  )  ;", "assertThat ( extractions . get (  1  )  . term ,    equalTo ( new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  )  )  ;", "assertThat ( extractions . get (  2  )  . term ,    equalTo ( new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_booleanQuery_msm_pre6dot1"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  )  ;", "builder . add ( termQuery 2  ,    SHOULD )  ;", "BooleanQuery . Builder   subBuilder    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 3     =    new   TermQuery ( new   Term (  \"  _ field 1  \"  ,     \"  _ term \"  )  )  ;", "subBuilder . add ( termQuery 3  ,    SHOULD )  ;", "TermQuery   termQuery 4     =    new   TermQuery ( new   Term (  \"  _ field 3  \"  ,     \"  _ long _ term \"  )  )  ;", "subBuilder . add ( termQuery 4  ,    SHOULD )  ;", "builder . add ( subBuilder . build (  )  ,    SHOULD )  ;", "BooleanQuery   booleanQuery    =    builder . build (  )  ;", ". Result   result    =     . analyze ( booleanQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  4  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo ( termQuery 2  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  1  )  . bytes (  )  ,    equalTo ( termQuery 2  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  2  )  . field (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  2  )  . bytes (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  3  )  . field (  )  ,    equalTo ( termQuery 4  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  3  )  . bytes (  )  ,    equalTo ( termQuery 4  . getTerm (  )  . bytes (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_booleanQuery_onlyShould"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term \"  )  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "PhraseQuery   phraseQuery    =    new   PhraseQuery (  \"  _ field \"  ,     \"  _ term 1  \"  ,     \" term 2  \"  )  ;", "builder . add ( phraseQuery ,    SHOULD )  ;", "BooleanQuery . Builder   subBuilder    =    new   BooleanQuery . Builder (  )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( new   Term (  \"  _ field 1  \"  ,     \"  _ term \"  )  )  ;", "subBuilder . add ( termQuery 2  ,    MUST )  ;", "TermQuery   termQuery 3     =    new   TermQuery ( new   Term (  \"  _ field 3  \"  ,     \"  _ long _ term \"  )  )  ;", "subBuilder . add ( termQuery 3  ,    MUST )  ;", "builder . add ( subBuilder . build (  )  ,    SHOULD )  ;", "BooleanQuery   booleanQuery    =    builder . build (  )  ;", ". Result   result    =     . analyze ( booleanQuery ,    V _  6  _  0  _  0  )  ;", "assertThat (  \" Should   clause   with   phrase   query   isn ' t   verified ,    so   entire   query   can ' t   be   verified \"  ,    result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  3  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  0  ]  . field (  )  )  )  ;", "assertThat ( terms . get (  1  )  . bytes (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  0  ]  . bytes (  )  )  )  ;", "assertThat ( terms . get (  2  )  . field (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  2  )  . bytes (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . bytes (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_booleanQuery_pre6dot1"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term \"  )  )  ;", "BoostQuery   constantScoreQuery    =    new   BoostQuery ( termQuery 1  ,     1  .  0 F )  ;", ". Result   result    =     . analyze ( constantScoreQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( terms . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . bytes (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_boostQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "CommonTermsQuery   commonTermsQuery    =    new   CommonTermsQuery ( Occur . SHOULD ,    Occur . SHOULD ,     1  0  0  )  ;", "commonTermsQuery . add ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  ;", "commonTermsQuery . add ( new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  )  ;", ". Result   result    =     . analyze ( commonTermsQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  0  )  . text (  )  ,    equalTo (  \"  _ term 1  \"  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  1  )  . text (  )  ,    equalTo (  \"  _ term 2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_commonTermsQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term \"  )  )  ;", "ConstantScoreQuery   constantScoreQuery    =    new   ConstantScoreQuery ( termQuery 1  )  ;", ". Result   result    =     . analyze ( constantScoreQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( terms . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . bytes (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_constantScoreQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  )  ;", "TermQuery   termQuery 3     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )  )  ;", "TermQuery   termQuery 4     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term 4  \"  )  )  ;", "DisjunctionMaxQuery   disjunctionMaxQuery    =    new   DisjunctionMaxQuery ( Arrays . asList ( termQuery 1  ,    termQuery 2  ,    termQuery 3  ,    termQuery 4  )  ,     0  .  1 F )  ;", ". Result   result    =     . analyze ( disjunctionMaxQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  4  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo ( termQuery 2  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  1  )  . bytes (  )  ,    equalTo ( termQuery 2  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  2  )  . field (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  2  )  . bytes (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  3  )  . field (  )  ,    equalTo ( termQuery 4  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  3  )  . bytes (  )  ,    equalTo ( termQuery 4  . getTerm (  )  . bytes (  )  )  )  ;", "disjunctionMaxQuery    =    new   DisjunctionMaxQuery ( Arrays . asList ( termQuery 1  ,    termQuery 2  ,    termQuery 3  ,    new   PhraseQuery (  \"  _ field \"  ,     \"  _ term 4  \"  )  )  ,     0  .  1 F )  ;", "result    =     . analyze ( disjunctionMaxQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  4  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  ,    equalTo ( termQuery 1  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo ( termQuery 2  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  1  )  . bytes (  )  ,    equalTo ( termQuery 2  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  2  )  . field (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  2  )  . bytes (  )  ,    equalTo ( termQuery 3  . getTerm (  )  . bytes (  )  )  )  ;", "assertThat ( terms . get (  3  )  . field (  )  ,    equalTo ( termQuery 4  . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  3  )  . bytes (  )  ,    equalTo ( termQuery 4  . getTerm (  )  . bytes (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_disjunctionMaxQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   BooleanQuery . Builder (  )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 1  \"  )  )  ,    MUST )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  . build (  )  ,    MUST )  ;", "builder . add ( new   BooleanQuery . Builder (  )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    MUST )  . build (  )  ,    MUST )  ;", "builder . add ( new   BooleanQuery . Builder (  )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    MUST )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 4  \"  )  )  ,    MUST )  . build (  )  ,    MUST )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . matchAllDocs ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \" field \"  ,     \" value 1  \"  )  ,    new   Term (  \" field \"  ,     \" value 2  \"  )  ,    new   Term (  \" field \"  ,     \" value 3  \"  )  ,    new   Term (  \" field \"  ,     \" value 4  \"  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  . setMinimumNumberShouldMatch (  2  )  ;", "builder . add ( new   BooleanQuery . Builder (  )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 1  \"  )  )  ,    MUST )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  . build (  )  ,    SHOULD )  ;", "builder . add ( new   BooleanQuery . Builder (  )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 2  \"  )  )  ,    MUST )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    MUST )  . build (  )  ,    SHOULD )  ;", "builder . add ( new   BooleanQuery . Builder (  )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 3  \"  )  )  ,    MUST )  . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value 4  \"  )  )  ,    MUST )  . build (  )  ,    SHOULD )  ;", "result    =    QueryAnalyzer . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . matchAllDocs ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \" field \"  ,     \" value 1  \"  )  ,    new   Term (  \" field \"  ,     \" value 2  \"  )  ,    new   Term (  \" field \"  ,     \" value 3  \"  )  ,    new   Term (  \" field \"  ,     \" value 4  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_duplicatedClauses"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( new   MatchAllDocsQuery (  )  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ,    MUST )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "result    =    QueryAnalyzer . analyze ( builder . build (  )  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . matchAllDocs ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \" field \"  ,     \" value \"  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "BooleanQuery   bq 1     =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( bq 1  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST _ NOT )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST )  ;", "BooleanQuery   bq 2     =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( bq 2  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "BooleanQuery   bq 3     =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( bq 3  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    MUST _ NOT )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "BooleanQuery   bq 4     =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( bq 4  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ,    SHOULD )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "BooleanQuery   bq 5     =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( bq 5  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ,    SHOULD )  ;", "builder . setMinimumNumberShouldMatch (  2  )  ;", "BooleanQuery   bq 6     =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( bq 6  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . matchAllDocs ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \" field \"  ,     \" value \"  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "builder . add ( new   MatchAllDocsQuery (  )  ,    SHOULD )  ;", "builder . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ,    SHOULD )  ;", "builder . setMinimumNumberShouldMatch (  2  )  ;", "BooleanQuery   bq 7     =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( bq 7  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_matchAllDocsQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( new   MatchNoDocsQuery (  \" sometimes   there   is   no   reason   at   all \"  )  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertEquals (  0  ,    result . extractions . size (  )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "BooleanQuery . Builder   bq    =    new   BooleanQuery . Builder (  )  ;", "bq . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ,    MUST )  ;", "bq . add ( new   MatchNoDocsQuery (  \" sometimes   there   is   no   reason   at   all \"  )  ,    MUST )  ;", "result    =    QueryAnalyzer . analyze ( bq . build (  )  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertEquals (  0  ,    result . extractions . size (  )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "bq    =    new   BooleanQuery . Builder (  )  ;", "bq . add ( new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ,    SHOULD )  ;", "bq . add ( new   MatchNoDocsQuery (  \" sometimes   there   is   no   reason   at   all \"  )  ,    SHOULD )  ;", "result    =    QueryAnalyzer . analyze ( bq . build (  )  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \" field \"  ,     \" value \"  )  )  ;", "DisjunctionMaxQuery   disjunctionMaxQuery    =    new   DisjunctionMaxQuery ( Arrays . asList ( new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ,    new   MatchNoDocsQuery (  \" sometimes   there   is   no   reason   at   all \"  )  )  ,     1  .  0 F )  ;", "result    =    QueryAnalyzer . analyze ( disjunctionMaxQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \" field \"  ,     \" value \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_matchNoDocsQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "MultiPhraseQuery   multiPhraseQuery    =    new   MultiPhraseQuery . Builder (  )  . add ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  . add ( new   Term [  ]  {    new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  ,    new   Term (  \"  _ field \"  ,     \"  _ term 3  \"  )     }  )  . add ( new   Term [  ]  {    new   Term (  \"  _ field \"  ,     \"  _ term 4  \"  )  ,    new   Term (  \"  _ field \"  ,     \"  _ term 5  \"  )     }  )  . add ( new   Term [  ]  {    new   Term (  \"  _ field \"  ,     \"  _ term 6  \"  )     }  )  . build (  )  ;", ". Result   result    =     . analyze ( multiPhraseQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  4  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  6  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  . utf 8 ToString (  )  ,    equalTo (  \"  _ term 1  \"  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  1  )  . bytes (  )  . utf 8 ToString (  )  ,    equalTo (  \"  _ term 2  \"  )  )  ;", "assertThat ( terms . get (  2  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  2  )  . bytes (  )  . utf 8 ToString (  )  ,    equalTo (  \"  _ term 3  \"  )  )  ;", "assertThat ( terms . get (  3  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  3  )  . bytes (  )  . utf 8 ToString (  )  ,    equalTo (  \"  _ term 4  \"  )  )  ;", "assertThat ( terms . get (  4  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  4  )  . bytes (  )  . utf 8 ToString (  )  ,    equalTo (  \"  _ term 5  \"  )  )  ;", "assertThat ( terms . get (  5  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  5  )  . bytes (  )  . utf 8 ToString (  )  ,    equalTo (  \"  _ term 6  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_multiPhraseQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "MultiPhraseQuery   multiPhraseQuery    =    new   MultiPhraseQuery . Builder (  )  . add ( new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  )  . add ( new   Term [  ]  {    new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  ,    new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )     }  )  . build (  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( multiPhraseQuery ,    CURRENT )  ;", "assertFalse ( result . matchAllDocs )  ;", "assertFalse ( result . verified )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \"  _ field \"  ,     \"  _ term 1  \"  )  ,    new   Term (  \"  _ field \"  ,     \"  _ term 2  \"  )  )  ;", "assertEquals (  1  ,    result . minimumShouldMatch )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_multiPhraseQuery_dups"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "MultiPhraseQuery   multiPhraseQuery    =    new   MultiPhraseQuery . Builder (  )  . add ( new   Term (  \"  _ field \"  ,     \"  _ long _ term \"  )  )  . add ( new   Term [  ]  {    new   Term (  \"  _ field \"  ,     \"  _ long _ term \"  )  ,    new   Term (  \"  _ field \"  ,     \"  _ term \"  )     }  )  . add ( new   Term [  ]  {    new   Term (  \"  _ field \"  ,     \"  _ long _ term \"  )  ,    new   Term (  \"  _ field \"  ,     \"  _ very _ long _ term \"  )     }  )  . add ( new   Term [  ]  {    new   Term (  \"  _ field \"  ,     \"  _ very _ long _ term \"  )     }  )  . build (  )  ;", ". Result   result    =     . analyze ( multiPhraseQuery ,    V _  6  _  0  _  0  )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( terms . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  . utf 8 ToString (  )  ,    equalTo (  \"  _ very _ long _ term \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_multiPhraseQuery_pre6dot1"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "PhraseQuery   phraseQuery    =    new   PhraseQuery (  \"  _ field \"  ,     \"  _ term 1  \"  ,     \" term 2  \"  )  ;", ". Result   result    =     . analyze ( phraseQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  0  ]  . field (  )  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  0  ]  . bytes (  )  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  1  ]  . field (  )  )  )  ;", "assertThat ( terms . get (  1  )  . bytes (  )  ,    equalTo ( phraseQuery . getTerms (  )  [  1  ]  . bytes (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_phraseQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "SpanTermQuery   spanTermQuery 1     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ short _ term \"  )  )  ;", "SpanFirstQuery   spanFirstQuery    =    new   SpanFirstQuery ( spanTermQuery 1  ,     2  0  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( spanFirstQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    spanTermQuery 1  . getTerm (  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_spanFirstQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "SpanTermQuery   spanTermQuery 1     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ short _ term \"  )  )  ;", "SpanTermQuery   spanTermQuery 2     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ very _ long _ term \"  )  )  ;", "SpanNearQuery   spanNearQuery    =    new   SpanNearQuery . Builder (  \"  _ field \"  ,    true )  . addClause ( spanTermQuery 1  )  . addClause ( spanTermQuery 2  )  . build (  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( spanNearQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", ". assertTermsEqual ( result . extractions ,    spanTermQuery 1  . getTerm (  )  ,    spanTermQuery 2  . getTerm (  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_spanNearQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "SpanTermQuery   spanTermQuery 1     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ short _ term \"  )  )  ;", "SpanTermQuery   spanTermQuery 2     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ very _ long _ term \"  )  )  ;", "SpanNearQuery   spanNearQuery    =    new   SpanNearQuery . Builder (  \"  _ field \"  ,    true )  . addClause ( spanTermQuery 1  )  . addClause ( spanTermQuery 2  )  . build (  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( spanNearQuery ,    V _  6  _  0  _  0  )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    spanTermQuery 2  . getTerm (  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_spanNearQuery_pre6dot1"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "SpanTermQuery   spanTermQuery 1     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ short _ term \"  )  )  ;", "SpanTermQuery   spanTermQuery 2     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ very _ long _ term \"  )  )  ;", "SpanNotQuery   spanNotQuery    =    new   SpanNotQuery ( spanTermQuery 1  ,    spanTermQuery 2  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( spanNotQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    spanTermQuery 1  . getTerm (  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_spanNotQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "SpanTermQuery   spanTermQuery 1     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ short _ term \"  )  )  ;", "SpanTermQuery   spanTermQuery 2     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ very _ long _ term \"  )  )  ;", "SpanOrQuery   spanOrQuery    =    new   SpanOrQuery ( spanTermQuery 1  ,    spanTermQuery 2  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( spanOrQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    spanTermQuery 1  . getTerm (  )  ,    spanTermQuery 2  . getTerm (  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_spanOrQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "SpanTermQuery   spanTermQuery 1     =    new   SpanTermQuery ( new   Term (  \"  _ field \"  ,     \"  _ short _ term \"  )  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( spanTermQuery 1  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    spanTermQuery 1  . getTerm (  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_spanTermQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "TermQuery   termQuery    =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term \"  )  )  ;", ". Result   result    =     . analyze ( termQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( terms . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo ( termQuery . getTerm (  )  . field (  )  )  )  ;", "assertThat ( terms . get (  0  )  . bytes (  )  ,    equalTo ( termQuery . getTerm (  )  . bytes (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_termQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "TermInSetQuery   termsQuery    =    new   TermInSetQuery (  \"  _ field \"  ,    new   BytesRef (  \"  _ term 1  \"  )  ,    new   BytesRef (  \"  _ term 2  \"  )  )  ;", ". Result   result    =     . analyze ( termsQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List <  . QueryExtraction >    terms    =    new   ArrayList <  >  ( result . extractions )  ;", "terms . sort ( Comparator . comparing (  (    qt )     -  >    qt . term )  )  ;", "assertThat ( terms . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( terms . get (  0  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  0  )  . text (  )  ,    equalTo (  \"  _ term 1  \"  )  )  ;", "assertThat ( terms . get (  1  )  . field (  )  ,    equalTo (  \"  _ field \"  )  )  ;", "assertThat ( terms . get (  1  )  . text (  )  ,    equalTo (  \"  _ term 2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_termsQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "TermRangeQuery   termRangeQuery    =    new   TermRangeQuery (  \"  _ field \"  ,    null ,    null ,    true ,    false )  ;", ". UnsupportedQueryException   e    =    expectThrows (  . UnsupportedQueryException . class ,     (  )     -  >    analyze ( termRangeQuery ,    Version . CURRENT )  )  ;", "assertThat ( e . getUnsupportedQuery (  )  ,    sameInstance ( termRangeQuery )  )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term \"  )  )  ;", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,    SHOULD )  ;", "builder . add ( termRangeQuery ,    SHOULD )  ;", "BooleanQuery   bq    =    builder . build (  )  ;", "e    =    expectThrows (  . UnsupportedQueryException . class ,     (  )     -  >    analyze ( bq ,    Version . CURRENT )  )  ;", "assertThat ( e . getUnsupportedQuery (  )  ,    sameInstance ( termRangeQuery )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_unsupportedQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "TermRangeQuery   unsupportedQuery    =    new   TermRangeQuery (  \"  _ field \"  ,    null ,    null ,    true ,    false )  ;", "TermQuery   termQuery 1     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ term \"  )  )  ;", "BooleanQuery . Builder   builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,    MUST )  ;", "builder . add ( unsupportedQuery ,    MUST )  ;", "BooleanQuery   bq 1     =    builder . build (  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( bq 1  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    termQuery 1  . getTerm (  )  )  ;", "TermQuery   termQuery 2     =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ longer _ term \"  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( termQuery 1  ,    MUST )  ;", "builder . add ( termQuery 2  ,    MUST )  ;", "builder . add ( unsupportedQuery ,    MUST )  ;", "bq 1     =    builder . build (  )  ;", "result    =    QueryAnalyzer . analyze ( bq 1  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", ". assertTermsEqual ( result . extractions ,    termQuery 1  . getTerm (  )  ,    termQuery 2  . getTerm (  )  )  ;", "builder    =    new   BooleanQuery . Builder (  )  ;", "builder . add ( unsupportedQuery ,    MUST )  ;", "builder . add ( unsupportedQuery ,    MUST )  ;", "BooleanQuery   bq 2     =    builder . build (  )  ;", "QueryAnalyzer . UnsupportedQueryException   e    =    expectThrows ( QueryAnalyzer . UnsupportedQueryException . class ,     (  )     -  >    analyze ( bq 2  ,    Version . CURRENT )  )  ;", "assertThat ( e . getUnsupportedQuery (  )  ,    sameInstance ( unsupportedQuery )  )  ;", "}", "METHOD_END"], "methodName": ["testExtractQueryMetadata_unsupportedQueryInBoolQueryWithMustClauses"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "TermQuery   termQuery    =    new   TermQuery ( new   Term (  \"  _ field \"  ,     \"  _ value \"  )  )  ;", "FunctionScoreQuery   functionScoreQuery    =    new   FunctionScoreQuery ( termQuery ,    new   RandomScoreFunction (  0  ,     0  ,    null )  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( functionScoreQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \"  _ field \"  ,     \"  _ value \"  )  )  ;", "functionScoreQuery    =    new   FunctionScoreQuery ( termQuery ,    new   RandomScoreFunction (  0  ,     0  ,    null )  ,    CombineFunction . MULTIPLY ,     1  .  0 F ,     1  0  .  0 F )  ;", "result    =    QueryAnalyzer . analyze ( functionScoreQuery ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \"  _ field \"  ,     \"  _ value \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFunctionScoreQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "MatchAllDocsQuery   innerQuery    =    new   MatchAllDocsQuery (  )  ;", "FunctionScoreQuery   functionScoreQuery 1     =    new   FunctionScoreQuery ( innerQuery ,    new   RandomScoreFunction (  0  ,     0  ,    null )  )  ;", ". Result   result    =     . analyze ( functionScoreQuery 1  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . extractions . isEmpty (  )  ,    is ( true )  )  ;", "FunctionScoreQuery   functionScoreQuery 2     =    new   FunctionScoreQuery ( innerQuery ,    new   RandomScoreFunction (  0  ,     0  ,    null )  ,    CombineFunction . MULTIPLY ,     1  .  0 F ,     1  0  .  0 F )  ;", "result    =     . analyze ( functionScoreQuery 2  ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( false )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . matchAllDocs ,    is ( true )  )  ;", "assertThat ( result . extractions . isEmpty (  )  ,    is ( true )  )  ;", "}", "METHOD_END"], "methodName": ["testFunctionScoreQuery_withMatchAll"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "Query   query    =    new   IndexOrDocValuesQuery ( IntPoint . newRangeQuery (  \"  _ field \"  ,     1  0  ,     2  0  )  ,    SortedNumericDocValuesField . newSlowRangeQuery (  \"  _ field \"  ,     1  0  ,     2  0  )  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( query ,    CURRENT )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List < QueryAnalyzer . QueryExtraction >    ranges    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( ranges . size (  )  ,    equalTo (  1  )  )  ;", "assertNull ( ranges . get (  0  )  . term )  ;", "assertEquals (  \"  _ field \"  ,    ranges . get (  0  )  . range . fieldName )  ;", ". assertDimension ( ranges . get (  0  )  . range . lowerPoint ,     (    bytes )     -  >    IntPoint . encodeDimension (  1  0  ,    bytes ,     0  )  )  ;", ". assertDimension ( ranges . get (  0  )  . range . upperPoint ,     (    bytes )     -  >    IntPoint . encodeDimension (  2  0  ,    bytes ,     0  )  )  ;", "}", "METHOD_END"], "methodName": ["testIndexOrDocValuesQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "Query   query    =    IntPoint . newRangeQuery (  \"  _ field \"  ,     1  0  ,     2  0  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( query ,    CURRENT )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "List < QueryAnalyzer . QueryExtraction >    ranges    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( ranges . size (  )  ,    equalTo (  1  )  )  ;", "assertNull ( ranges . get (  0  )  . term )  ;", "assertEquals (  \"  _ field \"  ,    ranges . get (  0  )  . range . fieldName )  ;", ". assertDimension ( ranges . get (  0  )  . range . lowerPoint ,     (    bytes )     -  >    IntPoint . encodeDimension (  1  0  ,    bytes ,     0  )  )  ;", ". assertDimension ( ranges . get (  0  )  . range . upperPoint ,     (    bytes )     -  >    IntPoint . encodeDimension (  2  0  ,    bytes ,     0  )  )  ;", "query    =    LongPoint . newRangeQuery (  \"  _ field \"  ,     1  0 L ,     2  1 L )  ;", "result    =    QueryAnalyzer . analyze ( query ,    CURRENT )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertFalse ( result . verified )  ;", "ranges    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( ranges . size (  )  ,    equalTo (  1  )  )  ;", "assertNull ( ranges . get (  0  )  . term )  ;", "assertEquals (  \"  _ field \"  ,    ranges . get (  0  )  . range . fieldName )  ;", ". assertDimension ( ranges . get (  0  )  . range . lowerPoint ,     (    bytes )     -  >    LongPoint . encodeDimension (  1  0 L ,    bytes ,     0  )  )  ;", ". assertDimension ( ranges . get (  0  )  . range . upperPoint ,     (    bytes )     -  >    LongPoint . encodeDimension (  2  1 L ,    bytes ,     0  )  )  ;", "query    =    HalfFloatPoint . newRangeQuery (  \"  _ field \"  ,     1  0  .  0 F ,     2  0  .  0 F )  ;", "result    =    QueryAnalyzer . analyze ( query ,    CURRENT )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertFalse ( result . verified )  ;", "ranges    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( ranges . size (  )  ,    equalTo (  1  )  )  ;", "assertNull ( ranges . get (  0  )  . term )  ;", "assertEquals (  \"  _ field \"  ,    ranges . get (  0  )  . range . fieldName )  ;", ". assertDimension ( ranges . get (  0  )  . range . lowerPoint ,     (    bytes )     -  >    HalfFloatPoint . encodeDimension (  1  0  .  0 F ,    bytes ,     0  )  )  ;", ". assertDimension ( ranges . get (  0  )  . range . upperPoint ,     (    bytes )     -  >    HalfFloatPoint . encodeDimension (  2  0  .  0 F ,    bytes ,     0  )  )  ;", "query    =    FloatPoint . newRangeQuery (  \"  _ field \"  ,     1  0  .  0 F ,     2  0  .  0 F )  ;", "result    =    QueryAnalyzer . analyze ( query ,    CURRENT )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertFalse ( result . verified )  ;", "ranges    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( ranges . size (  )  ,    equalTo (  1  )  )  ;", "assertNull ( ranges . get (  0  )  . term )  ;", "assertEquals (  \"  _ field \"  ,    ranges . get (  0  )  . range . fieldName )  ;", ". assertDimension ( ranges . get (  0  )  . range . lowerPoint ,     (    bytes )     -  >    FloatPoint . encodeDimension (  1  0  .  0 F ,    bytes ,     0  )  )  ;", ". assertDimension ( ranges . get (  0  )  . range . upperPoint ,     (    bytes )     -  >    FloatPoint . encodeDimension (  2  0  .  0 F ,    bytes ,     0  )  )  ;", "query    =    DoublePoint . newRangeQuery (  \"  _ field \"  ,     1  0  .  0  ,     2  0  .  0  )  ;", "result    =    QueryAnalyzer . analyze ( query ,    CURRENT )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertFalse ( result . verified )  ;", "ranges    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( ranges . size (  )  ,    equalTo (  1  )  )  ;", "assertNull ( ranges . get (  0  )  . term )  ;", "assertEquals (  \"  _ field \"  ,    ranges . get (  0  )  . range . fieldName )  ;", ". assertDimension ( ranges . get (  0  )  . range . lowerPoint ,     (    bytes )     -  >    DoublePoint . encodeDimension (  1  0  .  0  ,    bytes ,     0  )  )  ;", ". assertDimension ( ranges . get (  0  )  . range . upperPoint ,     (    bytes )     -  >    DoublePoint . encodeDimension (  2  0  .  0  ,    bytes ,     0  )  )  ;", "query    =    InetAddressPoint . newRangeQuery (  \"  _ field \"  ,    InetAddresses . forString (  \"  1  9  2  .  1  6  8  .  1  .  0  \"  )  ,    InetAddresses . forString (  \"  1  9  2  .  1  6  8  .  1  .  2  5  5  \"  )  )  ;", "result    =    QueryAnalyzer . analyze ( query ,    CURRENT )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertFalse ( result . verified )  ;", "ranges    =    new   ArrayList <  >  ( result . extractions )  ;", "assertThat ( ranges . size (  )  ,    equalTo (  1  )  )  ;", "assertNull ( ranges . get (  0  )  . term )  ;", "assertEquals (  \"  _ field \"  ,    ranges . get (  0  )  . range . fieldName )  ;", "assertArrayEquals ( ranges . get (  0  )  . range . lowerPoint ,    InetAddressPoint . encode ( InetAddresses . forString (  \"  1  9  2  .  1  6  8  .  1  .  0  \"  )  )  )  ;", "assertArrayEquals ( ranges . get (  0  )  . range . upperPoint ,    InetAddressPoint . encode ( InetAddresses . forString (  \"  1  9  2  .  1  6  8  .  1  .  2  5  5  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testPointRangeQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   boolQuery    =    new   BooleanQuery . Builder (  )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    SHOULD )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 2  \"  ,     1  0  ,     1  5  )  ,    SHOULD )  ;", ". Result   result    =     . analyze ( boolQuery . build (  )  ,    CURRENT )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  2  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 2  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "assertEquals (  \"  _ field 1  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  1  )  . range . fieldName )  ;", "boolQuery    =    new   BooleanQuery . Builder (  )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    FILTER )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 2  \"  ,     1  0  ,     1  5  )  ,    FILTER )  ;", "result    =     . analyze ( boolQuery . build (  )  ,    CURRENT )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  2  )  )  ;", "assertEquals (  2  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 2  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "assertEquals (  \"  _ field 1  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  1  )  . range . fieldName )  ;", "boolQuery    =    new   BooleanQuery . Builder (  )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    FILTER )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     1  5  )  ,    FILTER )  ;", "result    =     . analyze ( boolQuery . build (  )  ,    CURRENT )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  2  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 1  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "assertEquals (  \"  _ field 1  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  1  )  . range . fieldName )  ;", "boolQuery    =    new   BooleanQuery . Builder (  )  . setMinimumNumberShouldMatch (  2  )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    SHOULD )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 2  \"  ,     1  0  ,     1  5  )  ,    SHOULD )  ;", "result    =     . analyze ( boolQuery . build (  )  ,    CURRENT )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  2  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 2  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "assertEquals (  \"  _ field 1  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  1  )  . range . fieldName )  ;", "boolQuery    =    new   BooleanQuery . Builder (  )  . setMinimumNumberShouldMatch (  2  )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    SHOULD )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     1  5  )  ,    SHOULD )  ;", "result    =     . analyze ( boolQuery . build (  )  ,    CURRENT )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  2  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 1  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "assertEquals (  \"  _ field 1  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  1  )  . range . fieldName )  ;", "}", "METHOD_END"], "methodName": ["testPointRangeQuerySelectRanges"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "BooleanQuery . Builder   boolQuery    =    new   BooleanQuery . Builder (  )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    FILTER )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 2  \"  ,     1  0  ,     1  5  )  ,    FILTER )  ;", ". Result   result    =     . analyze ( boolQuery . build (  )  ,    V _  6  _  0  _  0  )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  1  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 2  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "boolQuery    =    new   BooleanQuery . Builder (  )  ;", "boolQuery . add ( LongPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    FILTER )  ;", "boolQuery . add ( IntPoint . newRangeQuery (  \"  _ field 2  \"  ,     1  0  ,     1  5  )  ,    FILTER )  ;", "result    =     . analyze ( boolQuery . build (  )  ,    V _  6  _  0  _  0  )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  1  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 2  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "boolQuery    =    new   BooleanQuery . Builder (  )  ;", "boolQuery . add ( DoublePoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    FILTER )  ;", "boolQuery . add ( DoublePoint . newRangeQuery (  \"  _ field 2  \"  ,     1  0  ,     1  5  )  ,    FILTER )  ;", "result    =     . analyze ( boolQuery . build (  )  ,    V _  6  _  0  _  0  )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  1  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 2  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "boolQuery    =    new   BooleanQuery . Builder (  )  ;", "boolQuery . add ( DoublePoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    FILTER )  ;", "boolQuery . add ( FloatPoint . newRangeQuery (  \"  _ field 2  \"  ,     1  0  ,     1  5  )  ,    FILTER )  ;", "result    =     . analyze ( boolQuery . build (  )  ,    V _  6  _  0  _  0  )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  1  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 2  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "boolQuery    =    new   BooleanQuery . Builder (  )  ;", "boolQuery . add ( HalfFloatPoint . newRangeQuery (  \"  _ field 1  \"  ,     1  0  ,     2  0  )  ,    FILTER )  ;", "boolQuery . add ( HalfFloatPoint . newRangeQuery (  \"  _ field 2  \"  ,     1  0  ,     1  5  )  ,    FILTER )  ;", "result    =     . analyze ( boolQuery . build (  )  ,    V _  6  _  0  _  0  )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  1  ,    result . extractions . size (  )  )  ;", "assertEquals (  \"  _ field 2  \"  ,    new   ArrayList <  >  ( result . extractions )  . get (  0  )  . range . fieldName )  ;", "}", "METHOD_END"], "methodName": ["testPointRangeQuerySelectShortestRange"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "Query   query    =    IntPoint . newRangeQuery (  \"  _ field \"  ,     2  0  ,     1  0  )  ;", ". Result   result    =     . analyze ( query ,    CURRENT )  ;", "assertTrue ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . size (  )  ,    equalTo (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testPointRangeQuery_lowerUpperReversed"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "Set < QueryAnalyzer . QueryExtraction >    queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  0  ]  ,     \"  1  2  \"  ,     \"  1  2  3  4  \"  ,     \"  1  2  3  4  5  \"  )  ;", "QueryAnalyzer . Result   result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 1  ,     1  )  ;", "Set < QueryAnalyzer . QueryExtraction >    queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  0  ]  ,     \"  1  2  3  \"  ,     \"  1  2  3  4  \"  ,     \"  1  2  3  4  5  \"  )  ;", "QueryAnalyzer . Result   result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame ( queryTerms 2  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1  ,     2  ,     3     }  )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 1  ,     1  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {     2  ,     3  ,     4     }  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame ( queryTerms 1  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {     4  ,     5  ,     6     }  )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 1  ,     1  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1  ,     2  ,     3     }  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame ( queryTerms 2  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1  ,     2  ,     3     }  ,     \"  1  2  3  \"  ,     \"  4  5  6  \"  )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 1  ,     1  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {     2  ,     3  ,     4     }  ,     \"  1  2  3  \"  ,     \"  4  5  6  \"  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame ( queryTerms 1  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1  0     }  )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 1  ,     1  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1     }  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame ( queryTerms 2  ,    result . extractions )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1  0     }  ,     \"  1  2  3  \"  )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 1  ,     1  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1     }  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame ( queryTerms 1  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1  0     }  ,     \"  1  \"  ,     \"  1  2  3  \"  )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 1  ,     1  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1     }  ,     \"  1  \"  ,     \"  2  \"  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame ( queryTerms 1  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1  ,     2  ,     3     }  ,     \"  1  2  3  \"  ,     \"  4  5  6  \"  )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 1  ,     1  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {     2  ,     3  ,     4     }  ,     \"  1  \"  ,     \"  4  5  6  \"  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame (  \" Ignoring   ranges ,    so   then   prefer   queryTerms 1  ,    because   it   has   the   longest   shortest   term \"  ,    queryTerms 1  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {        }  )  ;", "result 1     =    new   QueryAnalyzer . Result ( false ,    queryTerms 1  ,     0  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {        }  )  ;", "result 2     =    new   QueryAnalyzer . Result ( false ,    queryTerms 2  ,     0  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame (  \" In   case   query   extractions   are   empty \"  ,    queryTerms 2  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1     }  )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 1  ,     1  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {        }  )  ;", "result 2     =    new   QueryAnalyzer . Result ( false ,    queryTerms 2  ,     0  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame (  \" In   case   query   a   single   extraction   is   empty \"  ,    queryTerms 1  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {        }  )  ;", "result 1     =    new   QueryAnalyzer . Result ( false ,    queryTerms 1  ,     0  )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1     }  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame (  \" In   case   query   a   single   extraction   is   empty \"  ,    queryTerms 2  ,    result . extractions )  ;", "assertFalse ( result . verified )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    true )  ;", "queryTerms 2     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1     }  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame (  \" Conjunction   with   a   match _ all \"  ,    result 2  ,    result )  ;", "assertTrue ( result . verified )  ;", "queryTerms 1     =    QueryAnalyzerTests . terms ( new   int [  ]  {     1     }  )  ;", "result 1     =    new   QueryAnalyzer . Result ( true ,    queryTerms 2  ,     1  )  ;", "result 2     =    new   QueryAnalyzer . Result ( true ,    true )  ;", "result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "assertSame (  \" Conjunction   with   a   match _ all \"  ,    result 1  ,    result )  ;", "assertTrue ( result . verified )  ;", "}", "METHOD_END"], "methodName": ["testSelectBestResult"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "SynonymQuery   query    =    new   SynonymQuery (  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . analyze ( query ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  0  )  )  ;", "assertThat ( result . extractions . isEmpty (  )  ,    is ( true )  )  ;", "query    =    new   SynonymQuery ( new   Term (  \"  _ field \"  ,     \"  _ value 1  \"  )  ,    new   Term (  \"  _ field \"  ,     \"  _ value 2  \"  )  )  ;", "result    =    QueryAnalyzer . analyze ( query ,    CURRENT )  ;", "assertThat ( result . verified ,    is ( true )  )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", ". assertTermsEqual ( result . extractions ,    new   Term (  \"  _ field \"  ,     \"  _ value 1  \"  )  ,    new   Term (  \"  _ field \"  ,     \"  _ value 2  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSynonymQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "TermQuery   termQuery    =    new   TermQuery ( new   Term (  \" field \"  ,     \" value \"  )  )  ;", "QueryBitSetProducer   queryBitSetProducer    =    new   QueryBitSetProducer ( new   TermQuery ( new   Term (  \"  _ type \"  ,     \" child \"  )  )  )  ;", "ESToParentBlockJoinQuery   query    =    new   ESToParentBlockJoinQuery ( termQuery ,    queryBitSetProducer ,    ScoreMode . None ,     \" child \"  )  ;", ". Result   result    =     . analyze ( query ,    CURRENT )  ;", "assertFalse ( result . verified )  ;", "assertThat ( result . minimumShouldMatch ,    equalTo (  1  )  )  ;", "assertEquals (  1  ,    result . extractions . size (  )  )  ;", "assertNull ( result . extractions . toArray ( new    . QueryExtraction [  0  ]  )  [  0  ]  . range )  ;", "assertEquals ( new   Term (  \" field \"  ,     \" value \"  )  ,    result . extractions . toArray ( new    . QueryExtraction [  0  ]  )  [  0  ]  . term )  ;", "}", "METHOD_END"], "methodName": ["testToParentBlockJoinQuery"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "Query   query 1     =    LatLonPoint . newBoxQuery (  \"  _ field \"  ,     0  ,     1  ,     0  ,     1  )  ;", "expectThrows (  . UnsupportedQueryException . class ,     (  )     -  >    analyze ( query 1  ,    Version . CURRENT )  )  ;", "Query   query 2     =    LongPoint . newRangeQuery (  \"  _ field \"  ,    new   long [  ]  {     0  ,     0  ,     0     }  ,    new   long [  ]  {     1  ,     1  ,     1     }  )  ;", "expectThrows (  . UnsupportedQueryException . class ,     (  )     -  >    analyze ( query 2  ,    Version . CURRENT )  )  ;", "}", "METHOD_END"], "methodName": ["testTooManyPointDimensions"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "Set < QueryAnalyzer . QueryExtraction >    terms 1     =    new   HashSet <  >  (  )  ;", "int   shortestTerms 1 Length    =    Integer . MAX _ VALUE ;", "int   sumTermLength    =    randomIntBetween (  1  ,     1  2  8  )  ;", "while    ( sumTermLength    >     0  )     {", "int   length    =    randomInt ( sumTermLength )  ;", "shortestTerms 1 Length    =    Math . min ( shortestTerms 1 Length ,    length )  ;", "terms 1  . add ( new   QueryAnalyzer . QueryExtraction ( new   Term (  \" field \"  ,    randomAlphaOfLength ( length )  )  )  )  ;", "sumTermLength    -  =    length ;", "}", "Set < QueryAnalyzer . QueryExtraction >    terms 2     =    new   HashSet <  >  (  )  ;", "int   shortestTerms 2 Length    =    Integer . MAX _ VALUE ;", "sumTermLength    =    randomIntBetween (  1  ,     1  2  8  )  ;", "while    ( sumTermLength    >     0  )     {", "int   length    =    randomInt ( sumTermLength )  ;", "shortestTerms 2 Length    =    Math . min ( shortestTerms 2 Length ,    length )  ;", "terms 2  . add ( new   QueryAnalyzer . QueryExtraction ( new   Term (  \" field \"  ,    randomAlphaOfLength ( length )  )  )  )  ;", "sumTermLength    -  =    length ;", "}", "QueryAnalyzer . Result   result 1     =    new   QueryAnalyzer . Result ( true ,    terms 1  ,     1  )  ;", "QueryAnalyzer . Result   result 2     =    new   QueryAnalyzer . Result ( true ,    terms 2  ,     1  )  ;", "QueryAnalyzer . Result   result    =    QueryAnalyzer . selectBestResult ( result 1  ,    result 2  )  ;", "Set < QueryAnalyzer . QueryExtraction >    expected    =     ( shortestTerms 1 Length    >  =    shortestTerms 2 Length )     ?    terms 1     :    terms 2  ;", "assertThat ( result . extractions ,    sameInstance ( expected )  )  ;", "}", "METHOD_END"], "methodName": ["testselectBestResult_random"], "fileName": "org.elasticsearch.percolator.QueryAnalyzerTests"}, {"methodBody": ["METHOD_START", "{", "try    ( Directory   directory    =    newDirectory (  )  )     {", "TermQueryBuilder [  ]    queryBuilders    =    new   TermQueryBuilder [ randomIntBetween (  1  ,     1  6  )  ]  ;", "IndexWriterConfig   config    =    new   IndexWriterConfig ( new   WhitespaceAnalyzer (  )  )  ;", "config . setMergePolicy ( INSTANCE )  ;", "Settings   settings    =    Settings . builder (  )  . put ( SETTING _ VERSION _ CREATED ,    CURRENT )  . build (  )  ;", "BinaryFieldMapper   fieldMapper    =    PercolatorFieldMapper . Builder . createQueryBuilderFieldBuilder ( new   index . mapper . Mapper . BuilderContext ( settings ,    new   ContentPath (  0  )  )  )  ;", "Version   version    =     ( randomBoolean (  )  )     ?    Version . V _  5  _  6  _  0     :    Version . V _  6  _  0  _  0  _ beta 2  ;", "try    ( IndexWriter   indexWriter    =    new   IndexWriter ( directory ,    config )  )     {", "for    ( int   i    =     0  ;    i    <     ( queryBuilders . length )  ;    i +  +  )     {", "queryBuilders [ i ]     =    new   TermQueryBuilder ( randomAlphaOfLength (  4  )  ,    randomAlphaOfLength (  8  )  )  ;", "ParseContext   parseContext    =    mock ( ParseContext . class )  ;", "ParseContext . Document   document    =    new   ParseContext . Document (  )  ;", "when ( parseContext . doc (  )  )  . thenReturn ( document )  ;", "PercolatorFieldMapper . createQueryBuilderField ( version ,    fieldMapper ,    queryBuilders [ i ]  ,    parseContext )  ;", "indexWriter . addDocument ( document )  ;", "}", "}", "QueryShardContext   queryShardContext    =    mock ( QueryShardContext . class )  ;", "when ( queryShardContext . indexVersionCreated (  )  )  . thenReturn ( version )  ;", "when ( queryShardContext . getWriteableRegistry (  )  )  . thenReturn ( writableRegistry (  )  )  ;", "when ( queryShardContext . getXContentRegistry (  )  )  . thenReturn ( xContentRegistry (  )  )  ;", "when ( queryShardContext . getForField ( fieldMapper . fieldType (  )  )  )  . thenReturn ( new   index . fielddata . plain . BytesBinaryDVIndexFieldData ( new   Index (  \" index \"  ,     \" uuid \"  )  ,    fieldMapper . name (  )  )  )  ;", "PercolateQuery . QueryStore   queryStore    =    PercolateQueryBuilder . createStore ( fieldMapper . fieldType (  )  ,    queryShardContext ,    false )  ;", "try    ( IndexReader   indexReader    =    DirectoryReader . open ( directory )  )     {", "LeafReaderContext   leafContext    =    indexReader . leaves (  )  . get (  0  )  ;", "CheckedFunction < Integer ,    Query ,    IOException >    queries    =    queryStore . getQueries ( leafContext )  ;", "assertEquals ( queryBuilders . length ,    leafContext . reader (  )  . numDocs (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( queryBuilders . length )  ;    i +  +  )     {", "TermQuery   query    =     (  ( TermQuery )     ( queries . apply ( i )  )  )  ;", "assertEquals ( queryBuilders [ i ]  . fieldName (  )  ,    query . getTerm (  )  . field (  )  )  ;", "assertEquals ( queryBuilders [ i ]  . value (  )  ,    query . getTerm (  )  . text (  )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["testStoringQueryBuilders"], "fileName": "org.elasticsearch.percolator.QueryBuilderStoreTests"}, {"methodBody": ["METHOD_START", "{", "try    ( XContentBuilder   builder    =    jsonBuilder (  )  )     {", "builder . startObject (  )  ;", "{", "builder . field (  \" type \"  ,    type )  ;", "builder . startObject (  \" settings \"  )  ;", "{", "settings . toXContent ( builder ,    EMPTY _ PARAMS )  ;", "}", "builder . endObject (  )  ;", "}", "builder . endObject (  )  ;", "return   new   apache . http . nio . entity . NStringEntity ( Strings . toString ( builder )  ,    ContentType . APPLICATION _ JSON )  ;", "}", "}", "METHOD_END"], "methodName": ["buildRepositorySettings"], "fileName": "org.elasticsearch.repositories.url.RepositoryURLClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.repositories.url.RepositoryURLClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "Response   clusterSettingsResponse    =    client (  )  . performRequest (  \" GET \"  ,     (  \"  /  _ cluster / settings ? include _ defaults = true \"     +     \"  & filter _ path = defaults . path . repo , defaults . repositories . url . allowed _ urls \"  )  )  ;", "Map < String ,    Object >    clusterSettings    =    entityAsMap ( clusterSettingsResponse )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "List < String >    pathRepos    =     (  ( List < String >  )     ( XContentMapValues . extractValue (  \" defaults . path . repo \"  ,    clusterSettings )  )  )  ;", "assertThat ( pathRepos ,    notNullValue (  )  )  ;", "assertThat ( pathRepos ,    hasSize (  1  )  )  ;", "final   String   pathRepo    =    pathRepos . get (  0  )  ;", "final   URI   pathRepoUri    =    PathUtils . get ( pathRepo )  . toUri (  )  . normalize (  )  ;", "Response   createFsRepositoryResponse    =    client (  )  . performRequest (  \" PUT \"  ,     \"  _ snapshot / repository - fs \"  ,    Collections . emptyMap (  )  ,     . buildRepositorySettings ( TYPE ,    Settings . builder (  )  . put (  \" location \"  ,    pathRepo )  . build (  )  )  )  ;", "assertThat ( createFsRepositoryResponse . getStatusLine (  )  . getStatusCode (  )  ,    equalTo ( OK . getStatus (  )  )  )  ;", "Response   createFileRepositoryResponse    =    client (  )  . performRequest (  \" PUT \"  ,     \"  _ snapshot / repository - file \"  ,    Collections . emptyMap (  )  ,     . buildRepositorySettings ( URLRepository . TYPE ,    Settings . builder (  )  . put (  \" url \"  ,    pathRepoUri . toString (  )  )  . build (  )  )  )  ;", "assertThat ( createFileRepositoryResponse . getStatusLine (  )  . getStatusCode (  )  ,    equalTo ( OK . getStatus (  )  )  )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "List < String >    allowedUrls    =     (  ( List < String >  )     ( XContentMapValues . extractValue (  \" defaults . repositories . url . allowed _ urls \"  ,    clusterSettings )  )  )  ;", "for    ( String   allowedUrl    :    allowedUrls )     {", "try    {", "InetAddress   inetAddress    =    InetAddress . getByName ( new   URL ( allowedUrl )  . getHost (  )  )  ;", "if    (  ( inetAddress . isAnyLocalAddress (  )  )     |  |     ( inetAddress . isLoopbackAddress (  )  )  )     {", "Response   createUrlRepositoryResponse    =    client (  )  . performRequest (  \" PUT \"  ,     \"  _ snapshot / repository - url \"  ,    Collections . emptyMap (  )  ,     . buildRepositorySettings ( URLRepository . TYPE ,    Settings . builder (  )  . put (  \" url \"  ,    allowedUrl )  . build (  )  )  )  ;", "assertThat ( createUrlRepositoryResponse . getStatusLine (  )  . getStatusCode (  )  ,    equalTo ( OK . getStatus (  )  )  )  ;", "break ;", "}", "}    catch    ( Exception   e )     {", "logger . debug (  \" Failed   to   resolve   inet   address   for   allowed   URL    [  {  }  ]  ,    skipping \"  ,    allowedUrl )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["registerRepositories"], "fileName": "org.elasticsearch.repositories.url.RepositoryURLClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "final   InetSocketAddress   inetSocketAddress    =     (  ( InetSocketAddress )     ( address )  )  ;", "if    (  ( inetSocketAddress . getAddress (  )  )    instanceof   Inet 6 Address )     {", "ren    (  (  \"  [  \"     +     ( inetSocketAddress . getHostString (  )  )  )     +     \"  ]  :  \"  )     +     ( inetSocketAddress . getPort (  )  )  ;", "} else    {", "ren    (  ( inetSocketAddress . getHostString (  )  )     +     \"  :  \"  )     +     ( inetSocketAddress . getPort (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["addressToString"], "fileName": "org.elasticsearch.repositories.url.URLFixture"}, {"methodBody": ["METHOD_START", "{", "return   Paths . get ( dir )  ;", "}", "METHOD_END"], "methodName": ["dir"], "fileName": "org.elasticsearch.repositories.url.URLFixture"}, {"methodBody": ["METHOD_START", "{", "if    (  ( args    =  =    null )     |  |     (  ( args . length )     !  =     2  )  )     {", "throw   new   IllegalArgumentException (  \"     < working   directory >     < repository   directory >  \"  )  ;", "}", "final   InetSocketAddress   socketAddress    =    new   InetSocketAddress ( InetAddress . getLoopbackAddress (  )  ,     0  )  ;", "final   HttpServer   httpServer    =    MockHttpServer . createHttp ( socketAddress ,     0  )  ;", "try    {", "final   Path   workingDirectory    =     . dir ( args [  0  ]  )  ;", ". writeFile ( workingDirectory ,     \" pid \"  ,    ManagementFactory . getRuntimeMXBean (  )  . getName (  )  . split (  \"  @  \"  )  [  0  ]  )  ;", "final   String   addressAndPort    =     . addressToString ( httpServer . getAddress (  )  )  ;", ". writeFile ( workingDirectory ,     \" ports \"  ,    addressAndPort )  ;", "final   String   url    =     \" http :  /  /  \"     +    addressAndPort ;", "httpServer . createContext (  \"  /  \"  ,    new    . ResponseHandler (  . dir ( args [  1  ]  )  )  )  ;", "httpServer . start (  )  ;", "Thread . sleep ( Long . MAX _ VALUE )  ;", "}    finally    {", "httpServer . stop (  0  )  ;", "}", "}", "METHOD_END"], "methodName": ["main"], "fileName": "org.elasticsearch.repositories.url.URLFixture"}, {"methodBody": ["METHOD_START", "{", "final   Path   tempPidFile    =    Files . createTempFile ( dir ,    null ,    null )  ;", "Files . write ( tempPidFile ,    Collections . singleton ( content )  )  ;", "Files . move ( tempPidFile ,    dir . resolve ( fileName )  ,    StandardCopyOption . ATOMIC _ MOVE )  ;", "}", "METHOD_END"], "methodName": ["writeFile"], "fileName": "org.elasticsearch.repositories.url.URLFixture"}, {"methodBody": ["METHOD_START", "{", "String   protocol    =    url . getProtocol (  )  ;", "if    ( protocol    =  =    null )     {", "throw   new   RepositoryException ( getMetadata (  )  . name (  )  ,     (  (  \" unknown   url   protocol   from   URL    [  \"     +    url )     +     \"  ]  \"  )  )  ;", "}", "for    ( String   supportedProtocol    :    supportedProtocols )     {", "if    ( supportedProtocol . equals ( protocol )  )     {", "try    {", "if    ( URIPattern . match ( urlWhiteList ,    url . toURI (  )  )  )     {", "return   url ;", "}", "}    catch    ( URISyntaxException   ex )     {", "logger . warn (  \" cannot   parse   the   specified   url    [  {  }  ]  \"  ,    url )  ;", "throw   new   RepositoryException ( getMetadata (  )  . name (  )  ,     (  (  \" cannot   parse   the   specified   url    [  \"     +    url )     +     \"  ]  \"  )  )  ;", "}", "URL   normalizedUrl    =    environment . resolveRepoURL ( url )  ;", "if    ( normalizedUrl    =  =    null )     {", "String   logMessage    =     \" The   specified   url    [  {  }  ]    doesn ' t   start   with   any   repository   paths   specified   by   the    \"     +     \" path . repo   setting   or   by    {  }    setting :     [  {  }  ]     \"  ;", "logger . warn ( logMessage ,    url ,    URLRepository . ALLOWED _ URLS _ SETTING . getKey (  )  ,    environment . repoFiles (  )  )  ;", "String   exceptionMessage    =     (  (  \" file   url    [  \"     +    url )     +     \"  ]    doesn ' t   match   any   of   the   locations   specified   by   path . repo   or    \"  )     +     ( URLRepository . ALLOWED _ URLS _ SETTING . getKey (  )  )  ;", "throw   new   RepositoryException ( getMetadata (  )  . name (  )  ,    exceptionMessage )  ;", "}", "return   normalizedUrl ;", "}", "}", "throw   new   RepositoryException ( getMetadata (  )  . name (  )  ,     (  (  (  (  \" unsupported   url   protocol    [  \"     +    protocol )     +     \"  ]    from   URL    [  \"  )     +    url )     +     \"  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["checkURL"], "fileName": "org.elasticsearch.repositories.url.URLRepository"}, {"methodBody": ["METHOD_START", "{", "try    {", "return   new   URL ( s )  ;", "}    catch    ( MalformedURLException   e )     {", "throw   new   IllegalArgumentException (  \" Unable   to   parse   URL   y   setting \"  ,    e )  ;", "}", "}", "METHOD_END"], "methodName": ["parseURL"], "fileName": "org.elasticsearch.repositories.url.URLRepository"}, {"methodBody": ["METHOD_START", "{", "String   repoPath    =    createTempDir (  )  . resolve (  \" repository \"  )  . toUri (  )  . toURL (  )  . toString (  )  ;", "Settings   baseSettings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put ( URLRepository . REPOSITORIES _ URL _ SETTING . getKey (  )  ,    repoPath )  . build (  )  ;", "RepositoryMetaData   repositoryMetaData    =    new   RepositoryMetaData (  \" url \"  ,    URLRepository . TYPE ,    baseSettings )  ;", "try    {", "new   URLRepository ( repositoryMetaData ,    TestEnvironment . newEnvironment ( baseSettings )  ,    new   NamedXContentRegistry ( Collections . emptyList (  )  )  )  ;", "fail (  \" RepositoryException   should   have   been   thrown .  \"  )  ;", "}    catch    ( RepositoryException   e )     {", "String   msg    =     (  \"  [ url ]    file   url    [  \"     +    repoPath )     +     \"  ]    doesn ' t   match   any   of   the   locations   specified   by   path . repo   or   allowed _ urls \"  ;", "assertEquals ( msg ,    e . getMessage (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testIfNotWhiteListedMustSetRepoURL"], "fileName": "org.elasticsearch.repositories.url.URLRepositoryTests"}, {"methodBody": ["METHOD_START", "{", "Path   directory    =    createTempDir (  )  ;", "String   repoPath    =    directory . resolve (  \" repository \"  )  . toUri (  )  . toURL (  )  . toString (  )  ;", "Settings   baseSettings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put ( PATH _ REPO _ SETTING . getKey (  )  ,    directory . toString (  )  )  . put (  . REPOSITORIES _ URL _ SETTING . getKey (  )  ,    repoPath )  . put (  . SUPPORTED _ PROTOCOLS _ SETTING . getKey (  )  ,     \" http , https \"  )  . build (  )  ;", "RepositoryMetaData   repositoryMetaData    =    new   RepositoryMetaData (  \" url \"  ,     . TYPE ,    baseSettings )  ;", "try    {", "new    ( repositoryMetaData ,    TestEnvironment . newEnvironment ( baseSettings )  ,    new   NamedXContentRegistry ( Collections . emptyList (  )  )  )  ;", "fail (  \" RepositoryException   should   have   been   thrown .  \"  )  ;", "}    catch    ( RepositoryException   e )     {", "assertEquals (  (  (  \"  [ url ]    unsupported   url   protocol    [ file ]    from   URL    [  \"     +    repoPath )     +     \"  ]  \"  )  ,    e . getMessage (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMustBeSupportedProtocol"], "fileName": "org.elasticsearch.repositories.url.URLRepositoryTests"}, {"methodBody": ["METHOD_START", "{", "String   repoPath    =    createTempDir (  )  . resolve (  \" repository \"  )  . toUri (  )  . toURL (  )  . toString (  )  ;", "Settings   baseSettings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  . ALLOWED _ URLS _ SETTING . getKey (  )  ,    repoPath )  . put (  . REPOSITORIES _ URL _ SETTING . getKey (  )  ,    repoPath )  . build (  )  ;", "RepositoryMetaData   repositoryMetaData    =    new   RepositoryMetaData (  \" url \"  ,     . TYPE ,    baseSettings )  ;", "new    ( repositoryMetaData ,    TestEnvironment . newEnvironment ( baseSettings )  ,    new   NamedXContentRegistry ( Collections . emptyList (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testWhiteListingRepoURL"], "fileName": "org.elasticsearch.repositories.url.URLRepositoryTests"}, {"methodBody": ["METHOD_START", "{", "Client   client    =    client (  )  ;", "logger . info (  \"  -  -  >       creating   repository \"  )  ;", "Path   repositoryLocation    =    randomRepoPath (  )  ;", "assertAcked ( client . admin (  )  . cluster (  )  . preparePutRepository (  \" test - repo \"  )  . setType ( TYPE )  . setSettings ( Settings . builder (  )  . put ( LOCATION _ SETTING . getKey (  )  ,    repositoryLocation )  . put ( COMPRESS _ SETTING . getKey (  )  ,    randomBoolean (  )  )  . put ( CHUNK _ SIZE _ SETTING . getKey (  )  ,    randomIntBetween (  1  0  0  ,     1  0  0  0  )  ,    BYTES )  )  )  ;", "createIndex (  \" test - idx \"  )  ;", "ensureGreen (  )  ;", "logger . info (  \"  -  -  >    indexing   some   data \"  )  ;", "for    ( int   i    =     0  ;    i    <     1  0  0  ;    i +  +  )     {", "index (  \" test - idx \"  ,     \" doc \"  ,    Integer . toString ( i )  ,     \" foo \"  ,     (  \" bar \"     +    i )  )  ;", "}", "refresh (  )  ;", "assertThat ( client . prepareSearch (  \" test - idx \"  )  . setSize (  0  )  . get (  )  . getHits (  )  . getTotalHits (  )  ,    equalTo (  1  0  0 L )  )  ;", "logger . info (  \"  -  -  >    snapshot \"  )  ;", "Createponse   createponse    =    client . admin (  )  . cluster (  )  . prepareCreateSnapshot (  \" test - repo \"  ,     \" test - snap \"  )  . setWaitForCompletion ( true )  . setIndices (  \" test - idx \"  )  . get (  )  ;", "assertThat ( createponse . getSnapshotInfo (  )  . successfulShards (  )  ,    greaterThan (  0  )  )  ;", "int   actualTotalShards    =    createponse . getSnapshotInfo (  )  . totalShards (  )  ;", "assertThat ( createponse . getSnapshotInfo (  )  . successfulShards (  )  ,    equalTo ( actualTotalShards )  )  ;", "SnapshotState   state    =    client . admin (  )  . cluster (  )  . prepareGetSnapshots (  \" test - repo \"  )  . setSnapshots (  \" test - snap \"  )  . get (  )  . getSnapshots (  )  . get (  0  )  . state (  )  ;", "assertThat ( state ,    equalTo ( SUCCESS )  )  ;", "logger . info (  \"  -  -  >    delete   index \"  )  ;", "cluster (  )  . wipeIndices (  \" test - idx \"  )  ;", "logger . info (  \"  -  -  >    create   read - only   URL   repository \"  )  ;", "assertAcked ( client . admin (  )  . cluster (  )  . preparePutRepository (  \" url - repo \"  )  . setType ( URLRepository . TYPE )  . setSettings ( Settings . builder (  )  . put ( URLRepository . URL _ SETTING . getKey (  )  ,    repositoryLocation . toUri (  )  . toURL (  )  . toString (  )  )  . put (  \" list _ directories \"  ,    randomBoolean (  )  )  )  )  ;", "logger . info (  \"  -  -  >    restore   index   after   deletion \"  )  ;", "Restoreponse   restoreponse    =    client . admin (  )  . cluster (  )  . prepareRestoreSnapshot (  \" url - repo \"  ,     \" test - snap \"  )  . setWaitForCompletion ( true )  . setIndices (  \" test - idx \"  )  . execute (  )  . actionGet (  )  ;", "assertThat ( restoreponse . getRestoreInfo (  )  . totalShards (  )  ,    greaterThan (  0  )  )  ;", "assertThat ( client . prepareSearch (  \" test - idx \"  )  . setSize (  0  )  . get (  )  . getHits (  )  . getTotalHits (  )  ,    equalTo (  1  0  0 L )  )  ;", "logger . info (  \"  -  -  >    list   available   shapshots \"  )  ;", "GetSnapshotsResponse   getSnapshotsResponse    =    client . admin (  )  . cluster (  )  . prepareGetSnapshots (  \" url - repo \"  )  . get (  )  ;", "assertThat ( getSnapshotsResponse . getSnapshots (  )  ,    notNullValue (  )  )  ;", "assertThat ( getSnapshotsResponse . getSnapshots (  )  . size (  )  ,    equalTo (  1  )  )  ;", "logger . info (  \"  -  -  >    delete   snapshot \"  )  ;", "Deleteponse   deleteponse    =    client . admin (  )  . cluster (  )  . prepareDeleteSnapshot (  \" test - repo \"  ,     \" test - snap \"  )  . get (  )  ;", "assertAcked ( deleteponse )  ;", "logger . info (  \"  -  -  >    list   available   shapshot   again ,    no   snapshots   should   be   returned \"  )  ;", "getSnapshotsResponse    =    client . admin (  )  . cluster (  )  . prepareGetSnapshots (  \" url - repo \"  )  . get (  )  ;", "assertThat ( getSnapshotsResponse . getSnapshots (  )  ,    notNullValue (  )  )  ;", "assertThat ( getSnapshotsResponse . getSnapshots (  )  . size (  )  ,    equalTo (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testUrlRepository"], "fileName": "org.elasticsearch.repositories.url.URLSnapshotRestoreTests"}, {"methodBody": ["METHOD_START", "{", "final   Response   response    =    client (  )  . performRequest (  \" GET \"  ,     \"  /  _ nodes / settings \"  ,    Collections . emptyMap (  )  )  ;", "final   ObjectPath   objectPath    =    ObjectPath . createFromResponse ( response )  ;", "final   Map < String ,    Object >    map    =    objectPath . evaluate (  \" nodes \"  )  ;", "int   maxMaxInitialLineLength    =    Integer . MIN _ VALUE ;", "final   Setting < ByteSizeValue >    httpMaxInitialLineLength    =    HttpTransportSettings . SETTING _ HTTP _ MAX _ INITIAL _ LINE _ LENGTH ;", "final   String   key    =    httpMaxInitialLineLength . getKey (  )  . substring (  \" http .  \"  . length (  )  )  ;", "for    ( Map . Entry < String ,    Object >    entry    :    map . entrySet (  )  )     {", "@ SuppressWarnings (  \" unchecked \"  )", "final   Map < String ,    Object >    settings    =     (  ( Map < String ,    Object >  )     (  (  ( Map < String ,    Object >  )     ( entry . getValue (  )  )  )  . get (  \" settings \"  )  )  )  ;", "final   int   maxIntialLineLength ;", "if    ( settings . containsKey (  \" http \"  )  )     {", "@ SuppressWarnings (  \" unchecked \"  )", "final   Map < String ,    Object >    httpSettings    =     (  ( Map < String ,    Object >  )     ( settings . get (  \" http \"  )  )  )  ;", "if    ( httpSettings . containsKey ( key )  )     {", "maxIntialLineLength    =    ByteSizeValue . parseBytesSizeValue (  (  ( String )     ( httpSettings . get ( key )  )  )  ,    key )  . bytesAsInt (  )  ;", "} else    {", "maxIntialLineLength    =    httpMaxInitialLineLength . getDefault ( EMPTY )  . bytesAsInt (  )  ;", "}", "} else    {", "maxIntialLineLength    =    httpMaxInitialLineLength . getDefault ( EMPTY )  . bytesAsInt (  )  ;", "}", "maxMaxInitialLineLength    =    Math . max ( maxMaxInitialLineLength ,    maxIntialLineLength )  ;", "}", "final   String   path    =     \"  /  \"     +     ( new   String ( new   byte [ maxMaxInitialLineLength ]  ,    Charset . forName (  \" UTF -  8  \"  )  )  . replace (  '  \\ u 0  0  0  0  '  ,     ' a '  )  )  ;", "final   ResponseException   e    =    expectThrows ( ResponseException . class ,     (  )     -  >    client (  )  . performRequest ( randomFrom (  \" GET \"  ,     \" POST \"  ,     \" PUT \"  )  ,    path ,    Collections . emptyMap (  )  )  )  ;", "assertThat ( e . getResponse (  )  . getStatusLine (  )  . getStatusCode (  )  ,    equalTo ( RestStatus . BAD _ REQUEST . getStatus (  )  )  )  ;", "assertThat ( e ,    hasToString ( containsString (  \" too _ long _ frame _ exception \"  )  )  )  ;", "assertThat ( e ,    hasToString ( matches (  \" An   HTTP   line   is   larger   than    \\  \\ d +    bytes \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testBadRequest"], "fileName": "org.elasticsearch.rest.Netty4BadRequestIT"}, {"methodBody": ["METHOD_START", "{", "final   BasicHeader   header    =    new   BasicHeader (  \" Content - Type \"  ,     \"  \\ t \"  )  ;", "final   ResponseException   e    =    expectThrows ( ResponseException . class ,     (  )     -  >    client (  )  . perform (  \" GET \"  ,     \"  /  _ cluster / settings \"  ,    header )  )  ;", "final   Response   response    =    e . getResponse (  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    equalTo (  4  0  0  )  )  ;", "final   ObjectPath   objectPath    =    ObjectPath . createFromResponse ( response )  ;", "final   Map < String ,    Object >    map    =    objectPath . evaluate (  \" error \"  )  ;", "assertThat ( map . get (  \" type \"  )  ,    equalTo (  \" content _ type _ header _ exception \"  )  )  ;", "assertThat ( map . get (  \" reason \"  )  ,    equalTo (  \" IllegalArgumentException :    invalid   Content - Type   header    [  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidHeaderValue"], "fileName": "org.elasticsearch.rest.Netty4BadRequestIT"}, {"methodBody": ["METHOD_START", "{", "final   ResponseException   e    =    expectThrows ( ResponseException . class ,     (  )     -  >    client (  )  . performRequest (  \" GET \"  ,     \"  /  _ cluster / settings \"  ,    Collections . singletonMap (  \" pretty \"  ,     \" neither - true - nor - false \"  )  )  )  ;", "final   Response   response    =    e . getResponse (  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    equalTo (  4  0  0  )  )  ;", "final   ObjectPath   objectPath    =    ObjectPath . createFromResponse ( response )  ;", "final   Map < String ,    Object >    map    =    objectPath . evaluate (  \" error \"  )  ;", "assertThat ( map . get (  \" type \"  )  ,    equalTo (  \" illegal _ argument _ exception \"  )  )  ;", "assertThat ( map . get (  \" reason \"  )  ,    equalTo (  \" Failed   to   parse   value    [ neither - true - nor - false ]    as   only    [ true ]    or    [ false ]    are   allowed .  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidParameterValue"], "fileName": "org.elasticsearch.rest.Netty4BadRequestIT"}, {"methodBody": ["METHOD_START", "{", "createTestDoc (  \" test \"  ,     \" test \"  )  ;", "}", "METHOD_END"], "methodName": ["createTestDoc"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "try    ( XContentBuilder   builder    =    jsonBuilder (  )  )     {", "builder . startObject (  )  ;", "{", "builder . field (  \" test \"  ,     \" test \"  )  ;", "}", "builder . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  (  (  (  (  \"  /  \"     +    indexName )     +     \"  /  \"  )     +    typeName )     +     \"  /  \"  )     +     \"  1  \"  )  ,    Collections . emptyMap (  )  ,    new   apache . http . entity . StringEntity ( Strings . toString ( builder )  ,    ContentType . APPLICATION _ JSON )  )  ;", "}", "}", "METHOD_END"], "methodName": ["createTestDoc"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "Response   response    =    client (  )  . performRequest (  \" HEAD \"  ,    url ,    params )  ;", "assertEquals ( expectedStatusCode ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "assertThat ( Integer . valueOf ( response . geter (  \" Content - Length \"  )  )  ,    matcher )  ;", "assertNull (  (  (  \" HEAD   requests   shouldn ' t   have   a   response   body   but    \"     +    url )     +     \"    did \"  )  ,    response . getEntity (  )  )  ;", "}", "METHOD_END"], "methodName": ["headTestCase"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "headTestCase ( url ,    params ,    RestStatus . OK . getStatus (  )  ,    matcher )  ;", "}", "METHOD_END"], "methodName": ["headTestCase"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "createTestDoc (  )  ;", "headTestCase (  \"  /  _ alias / test _ alias \"  ,    Collections . eMap (  )  ,    RestStatus . NOT _ FOUND . getStatus (  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  / test /  _ alias / test _ alias \"  ,    Collections . eMap (  )  ,    RestStatus . NOT _ FOUND . getStatus (  )  ,    greaterThan (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testAliasDoesNotExist"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "createTestDoc (  )  ;", "try    ( XContentBuilder   builder    =    jsonBuilder (  )  )     {", "builder . startObject (  )  ;", "{", "builder . startArray (  \" actions \"  )  ;", "{", "builder . startObject (  )  ;", "{", "builder . startObject (  \" add \"  )  ;", "{", "builder . field (  \" index \"  ,     \" test \"  )  ;", "builder . field (  \" alias \"  ,     \" test _ alias \"  )  ;", "}", "builder . endObject (  )  ;", "}", "builder . endObject (  )  ;", "}", "builder . endArray (  )  ;", "}", "builder . endObject (  )  ;", "client (  )  . performRequest (  \" POST \"  ,     \"  _ aliases \"  ,    Collections . emptyMap (  )  ,    new   apache . http . entity . StringEntity ( Strings . toString ( builder )  ,    ContentType . APPLICATION _ JSON )  )  ;", "headTestCase (  \"  /  _ alias / test _ alias \"  ,    Collections . emptyMap (  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  / test /  _ alias / test _ alias \"  ,    Collections . emptyMap (  )  ,    greaterThan (  0  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testAliasExists"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "createTestDoc (  )  ;", "headTestCase (  \"  / test / test /  1  \"  ,    Collections . eMap (  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  / test / test /  1  \"  ,    Collections . singletonMap (  \" pretty \"  ,     \" true \"  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  / test / test /  2  \"  ,    Collections . eMap (  )  ,    RestStatus . NOT _ FOUND . getStatus (  )  ,    greaterThan (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testDocumentExists"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "headTestCase (  \"  / index - not - found - exception \"  ,    Collections . emptyMap (  )  ,    RestStatus . NOT _ FOUND . getStatus (  )  ,    greaterThan (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testException"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "createTestDoc (  )  ;", "headTestCase (  \"  / test / test /  1  /  _ source \"  ,    Collections . eMap (  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  / test / test /  2  /  _ source \"  ,    Collections . eMap (  )  ,    RestStatus . NOT _ FOUND . getStatus (  )  ,    equalTo (  0  )  )  ;", "try    ( XContentBuilder   builder    =    jsonBuilder (  )  )     {", "builder . startObject (  )  ;", "{", "builder . startObject (  \" mappings \"  )  ;", "{", "builder . startObject (  \" test - no - source \"  )  ;", "{", "builder . startObject (  \"  _ source \"  )  ;", "{", "builder . field (  \" enabled \"  ,    false )  ;", "}", "builder . endObject (  )  ;", "}", "builder . endObject (  )  ;", "}", "builder . endObject (  )  ;", "}", "builder . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     \"  / test - no - source \"  ,    Collections . eMap (  )  ,    new   StringEntity ( Strings . toString ( builder )  ,    ContentType . APPLICATION _ JSON )  )  ;", "createTestDoc (  \" test - no - source \"  ,     \" test - no - source \"  )  ;", "headTestCase (  \"  / test - no - source / test - no - source /  1  /  _ source \"  ,    Collections . eMap (  )  ,    RestStatus . NOT _ FOUND . getStatus (  )  ,    equalTo (  0  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testGetSourceAction"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "headTestCase (  \"  /  \"  ,    Collections . emptyMap (  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  /  \"  ,    Collections . singletonMap (  \" pretty \"  ,     \"  \"  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  /  \"  ,    Collections . singletonMap (  \" pretty \"  ,     \" true \"  )  ,    greaterThan (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testHeadRoot"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "createTestDoc (  )  ;", "headTestCase (  \"  / test \"  ,    Collections . eMap (  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  / test \"  ,    Collections . singletonMap (  \" pretty \"  ,     \" true \"  )  ,    greaterThan (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testIndexExists"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "try    ( XContentBuilder   builder    =    jsonBuilder (  )  )     {", "builder . startObject (  )  ;", "{", "builder . array (  \" index _ patterns \"  ,     \"  *  \"  )  ;", "builder . startObject (  \" settings \"  )  ;", "{", "builder . field (  \" number _ of _ replicas \"  ,     0  )  ;", "}", "builder . endObject (  )  ;", "}", "builder . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ template / template \"  ,    Collections . emptyMap (  )  ,    new   apache . http . entity . StringEntity ( Strings . toString ( builder )  ,    ContentType . APPLICATION _ JSON )  )  ;", "headTestCase (  \"  /  _ template / template \"  ,    Collections . emptyMap (  )  ,    greaterThan (  0  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testTemplateExists"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "createTestDoc (  )  ;", "headTestCase (  \"  / test /  _ mapping / does - not - exist \"  ,    Collections . eMap (  )  ,    RestStatus . NOT _ FOUND . getStatus (  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  / text /  _ mapping / test , does - not - exist \"  ,    Collections . eMap (  )  ,    RestStatus . NOT _ FOUND . getStatus (  )  ,    greaterThan (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testTypeDoesNotExist"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "createTestDoc (  )  ;", "headTestCase (  \"  / test /  _ mapping / test \"  ,    Collections . eMap (  )  ,    greaterThan (  0  )  )  ;", "headTestCase (  \"  / test /  _ mapping / test \"  ,    Collections . singletonMap (  \" pretty \"  ,     \" true \"  )  ,    greaterThan (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testTypeExists"], "fileName": "org.elasticsearch.rest.Netty4HeadBodyIsEmptyIT"}, {"methodBody": ["METHOD_START", "{", "switch    ( method )     {", "case    . GETVALUE _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MIN )  ;", "case    . ISEMPTY _ METHOD    :", "return   new   EmptyMemberValueSource ( fieldData )  ;", "case    . SIZE _ METHOD    :", "return   new   CountMethodValueSource ( fieldData )  ;", "case    . MINIMUM _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MIN )  ;", "case    . MAXIMUM _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MAX )  ;", "case    . AVERAGE _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . AVG )  ;", "case    . MEDIAN _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MEDIAN )  ;", "case    . SUM _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . SUM )  ;", "case    . COUNT _ METHOD    :", "return   new   CountMethodValueSource ( fieldData )  ;", "case    . GET _ YEAR _ METHOD    :", "return   new   DateMethodValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    Calendar . YEAR )  ;", "case    . GET _ MONTH _ METHOD    :", "return   new   DateMethodValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    Calendar . MONTH )  ;", "case    . GET _ DAY _ OF _ MONTH _ METHOD    :", "return   new   DateMethodValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    Calendar . DAY _ OF _ MONTH )  ;", "case    . GET _ HOUR _ OF _ DAY _ METHOD    :", "return   new   DateMethodValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    Calendar . HOUR _ OF _ DAY )  ;", "case    . GET _ MINUTES _ METHOD    :", "return   new   DateMethodValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    Calendar . MINUTE )  ;", "case    . GET _ SECONDS _ METHOD    :", "return   new   DateMethodValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    Calendar . SECOND )  ;", "default    :", "throw   new   IllegalArgumentException (  (  (  (  (  \" Member   method    [  \"     +    method )     +     \"  ]    does   not   exist   for   date   field    [  \"  )     +    fieldName )     +     \"  ]  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getMethod"], "fileName": "org.elasticsearch.script.expression.DateField"}, {"methodBody": ["METHOD_START", "{", "switch    ( variable )     {", "case    . VALUE _ VARIABLE    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MIN )  ;", "case    . EMPTY _ VARIABLE    :", "return   new   EmptyMemberValueSource ( fieldData )  ;", "case    . LENGTH _ VARIABLE    :", "return   new   CountMethodValueSource ( fieldData )  ;", "default    :", "throw   new   IllegalArgumentException (  (  (  (  (  \" Member   variable    [  \"     +    variable )     +     \"  ]    does   not   exist   for   date   field    [  \"  )     +    fieldName )     +     \"  ]  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getVariable"], "fileName": "org.elasticsearch.script.expression.DateField"}, {"methodBody": ["METHOD_START", "{", "switch    ( method )     {", "case    . GETCENTURY _ OF _ ERA _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getCenturyOfEra )  ;", "case    . GETDAY _ OF _ MONTH _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getDayOfMonth )  ;", "case    . GETDAY _ OF _ WEEK _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getDayOfWeek )  ;", "case    . GETDAY _ OF _ YEAR _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getDayOfYear )  ;", "case    . GETERA _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getEra )  ;", "case    . GETHOUR _ OF _ DAY _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getHourOfDay )  ;", "case    . GETMILLIS _ OF _ DAY _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getMillisOfDay )  ;", "case    . GETMILLIS _ OF _ SECOND _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getMillisOfSecond )  ;", "case    . GETMINUTE _ OF _ DAY _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getMinuteOfDay )  ;", "case    . GETMINUTE _ OF _ HOUR _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getMinuteOfHour )  ;", "case    . GETMONTH _ OF _ YEAR _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getMonthOfYear )  ;", "case    . GETSECOND _ OF _ DAY _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getSecondOfDay )  ;", "case    . GETSECOND _ OF _ MINUTE _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getSecondOfMinute )  ;", "case    . GETWEEK _ OF _ WEEK _ YEAR _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getWeekOfWeekyear )  ;", "case    . GETWEEK _ YEAR _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getWeekyear )  ;", "case    . GETYEAR _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getYear )  ;", "case    . GETYEAR _ OF _ CENTURY _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getYearOfCentury )  ;", "case    . GETYEAR _ OF _ ERA _ METHOD    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    method ,    ReadableDateTime :  : getYearOfEra )  ;", "default    :", "throw   new   IllegalArgumentException (  (  (  (  (  \" Member   method    [  \"     +    method )     +     \"  ]    does   not   exist   for   date   object   on   field    [  \"  )     +    fieldName )     +     \"  ]  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getMethod"], "fileName": "org.elasticsearch.script.expression.DateObject"}, {"methodBody": ["METHOD_START", "{", "switch    ( variable )     {", "case    . CENTURY _ OF _ ERA _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getCenturyOfEra )  ;", "case    . DAY _ OF _ MONTH _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getDayOfMonth )  ;", "case    . DAY _ OF _ WEEK _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getDayOfWeek )  ;", "case    . DAY _ OF _ YEAR _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getDayOfYear )  ;", "case    . ERA _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getEra )  ;", "case    . HOUR _ OF _ DAY _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getHourOfDay )  ;", "case    . MILLIS _ OF _ DAY _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getMillisOfDay )  ;", "case    . MILLIS _ OF _ SECOND _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getMillisOfSecond )  ;", "case    . MINUTE _ OF _ DAY _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getMinuteOfDay )  ;", "case    . MINUTE _ OF _ HOUR _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getMinuteOfHour )  ;", "case    . MONTH _ OF _ YEAR _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getMonthOfYear )  ;", "case    . SECOND _ OF _ DAY _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getSecondOfDay )  ;", "case    . SECOND _ OF _ MINUTE _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getSecondOfMinute )  ;", "case    . WEEK _ OF _ WEEK _ YEAR _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getWeekOfWeekyear )  ;", "case    . WEEK _ YEAR _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getWeekyear )  ;", "case    . YEAR _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getYear )  ;", "case    . YEAR _ OF _ CENTURY _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getYearOfCentury )  ;", "case    . YEAR _ OF _ ERA _ VARIABLE    :", "return   new   ValueSource ( fieldData ,    MultiValueMode . MIN ,    variable ,    ReadableDateTime :  : getYearOfEra )  ;", "default    :", "throw   new   IllegalArgumentException (  (  (  (  (  \" Member   variable    [  \"     +    variable )     +     \"  ]    does   not   exist   for   date   object   on   field    [  \"  )     +    fieldName )     +     \"  ]  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getVariable"], "fileName": "org.elasticsearch.script.expression.DateObject"}, {"methodBody": ["METHOD_START", "{", "List < String >    stack    =    new   ArrayList <  >  (  )  ;", "stack . add ( portion )  ;", "StringBuilder   pointer    =    new   StringBuilder (  )  ;", "if    ( cause   instanceof   ParseException )     {", "int   offset    =     (  ( ParseException )     ( cause )  )  . getErrorOffset (  )  ;", "for    ( int   i    =     0  ;    i    <    offset ;    i +  +  )     {", "pointer . append (  '     '  )  ;", "}", "}", "pointer . append (  \"  ^  -  -  -  -    HERE \"  )  ;", "stack . add ( pointer . toString (  )  )  ;", "throw   new   ScriptException ( message ,    cause ,    stack ,    source ,     . NAME )  ;", "}", "METHOD_END"], "methodName": ["convertToScriptException"], "fileName": "org.elasticsearch.script.expression.ExpressionScriptEngine"}, {"methodBody": ["METHOD_START", "{", "SearchScript . LeafFactory   searchLeafFactory    =    newSearchScript ( expr ,    lookup ,    vars )  ;", "return    (    ctx )     -  >     {", "SearchScript    =    searchLeafFactory . newInstance ( ctx )  ;", "return   new   FilterScript ( vars ,    lookup ,    ctx )     {", "@ Override", "public   boolean   execute (  )     {", "return    ( runAsDouble (  )  )     !  =     0  .  0  ;", "}", "@ Override", "public   void   setDocument ( int   docid )     {", "setDocument ( docid )  ;", "}", "}  ;", "}  ;", "}", "METHOD_END"], "methodName": ["newFilterScript"], "fileName": "org.elasticsearch.script.expression.ExpressionScriptEngine"}, {"methodBody": ["METHOD_START", "{", "MapperService   mapper    =    lookup . doc (  )  . mapperService (  )  ;", "SimpleBindings   bindings    =    new   SimpleBindings (  )  ;", "ReplaceableConstDoubleValueSource   specialValue    =    null ;", "boolean   needsScores    =    false ;", "for    ( String   variable    :    expr . variables )     {", "try    {", "if    ( variable . equals (  \"  _ score \"  )  )     {", "bindings . add ( new   SortField (  \"  _ score \"  ,    Type . SCORE )  )  ;", "needsScores    =    true ;", "} else", "if    ( variable . equals (  \"  _ value \"  )  )     {", "specialValue    =    new   ReplaceableConstDoubleValueSource (  )  ;", "bindings . add (  \"  _ value \"  ,    specialValue )  ;", "} else", "if    (  ( vars    !  =    null )     &  &     ( vars . containsKey ( variable )  )  )     {", "Object   value    =    vars . get ( variable )  ;", "if    ( value   instanceof   Number )     {", "bindings . add ( variable ,    new   DoubleConstValueSource (  (  ( Number )     ( value )  )  . doubleValue (  )  )  . asDoubleValuesSource (  )  )  ;", "} else    {", "throw   new   ParseException (  (  (  \" Parameter    [  \"     +    variable )     +     \"  ]    must   be   a   numeric   type \"  )  ,     0  )  ;", "}", "} else    {", "String   fieldname    =    null ;", "String   methodname    =    null ;", "String   variablename    =     \" value \"  ;", "boolean   dateAccessor    =    false ;", "VariableContext [  ]    parts    =    parse ( variable )  ;", "if    (  ( parts [  0  ]  . text . equals (  \" doc \"  )  )     =  =    false )     {", "throw   new   ParseException (  (  (  \" Unknown   variable    [  \"     +     ( parts [  0  ]  . text )  )     +     \"  ]  \"  )  ,     0  )  ;", "}", "if    (  (  ( parts . length )     <     2  )     |  |     (  ( parts [  1  ]  . type )     !  =     ( VariableContext . Type . STR _ INDEX )  )  )     {", "throw   new   ParseException (  \" Variable    ' doc '    must   be   used   with   a   specific   field   like :    doc [  ' myfield '  ]  \"  ,     3  )  ;", "} else    {", "fieldname    =    parts [  1  ]  . text ;", "}", "if    (  ( parts . length )     =  =     3  )     {", "if    (  ( parts [  2  ]  . type )     =  =     ( VariableContext . Type . METHOD )  )     {", "methodname    =    parts [  2  ]  . text ;", "} else", "if    (  ( parts [  2  ]  . type )     =  =     ( VariableContext . Type . MEMBER )  )     {", "variablename    =    parts [  2  ]  . text ;", "} else    {", "throw   new   IllegalArgumentException (  \" Only   member   variables   or   member   methods   may   be   accessed   on   a   field   when   not   accessing   the   field   directly \"  )  ;", "}", "}", "if    (  ( parts . length )     >     3  )     {", "if    (  (  ( parts . length )     =  =     4  )     &  &     (  (  \" date \"  . equals ( parts [  2  ]  . text )  )     |  |     (  \" getDate \"  . equals ( parts [  2  ]  . text )  )  )  )     {", "if    (  ( parts [  3  ]  . type )     =  =     ( VariableContext . Type . METHOD )  )     {", "methodname    =    parts [  3  ]  . text ;", "dateAccessor    =    true ;", "} else", "if    (  ( parts [  3  ]  . type )     =  =     ( VariableContext . Type . MEMBER )  )     {", "variablename    =    parts [  3  ]  . text ;", "dateAccessor    =    true ;", "}", "}", "if    (  ! dateAccessor )     {", "throw   new   IllegalArgumentException (  (  (  \" Variable    [  \"     +    variable )     +     \"  ]    does   not   follow   an   allowed   format   of   either   doc [  ' field '  ]    or   doc [  ' field '  ]  . method (  )  \"  )  )  ;", "}", "}", "index . mapper . MappedFieldType   fieldType    =    mapper . fullName ( fieldname )  ;", "if    ( fieldType    =  =    null )     {", "throw   new   ParseException (  (  (  \" Field    [  \"     +    fieldname )     +     \"  ]    does   not   exist   in   mappings \"  )  ,     5  )  ;", "}", "index . fielddata . IndexFieldData <  ?  >    fieldData    =    lookup . doc (  )  . getForField ( fieldType )  ;", "final   ValueSource   valueSource ;", "if    ( fieldType   instanceof   index . mapper . GeoPointFieldMapper . GeoPointFieldType )     {", "if    ( methodname    =  =    null )     {", "valueSource    =    GeoField . getVariable ( fieldData ,    fieldname ,    variablename )  ;", "} else    {", "valueSource    =    GeoField . getMethod ( fieldData ,    fieldname ,    methodname )  ;", "}", "} else", "if    ( fieldType   instanceof   index . mapper . DateFieldMapper . DateFieldType )     {", "if    ( dateAccessor )     {", "if    ( methodname    =  =    null )     {", "valueSource    =    DateObject . getVariable ( fieldData ,    fieldname ,    variablename )  ;", "} else    {", "valueSource    =    DateObject . getMethod ( fieldData ,    fieldname ,    methodname )  ;", "}", "} else    {", "if    ( methodname    =  =    null )     {", "valueSource    =    DateField . getVariable ( fieldData ,    fieldname ,    variablename )  ;", "} else    {", "valueSource    =    DateField . getMethod ( fieldData ,    fieldname ,    methodname )  ;", "}", "}", "} else", "if    ( fieldData   instanceof   index . fielddata . IndexNumericFieldData )     {", "if    ( methodname    =  =    null )     {", "valueSource    =    NumericField . getVariable ( fieldData ,    fieldname ,    variablename )  ;", "} else    {", "valueSource    =    NumericField . getMethod ( fieldData ,    fieldname ,    methodname )  ;", "}", "} else    {", "throw   new   ParseException (  (  (  \" Field    [  \"     +    fieldname )     +     \"  ]    must   be   numeric ,    date ,    or   geopoint \"  )  ,     5  )  ;", "}", "needsScores    |  =    valueSource . getSortField ( false )  . needsScores (  )  ;", "bindings . add ( variable ,    valueSource . asDoubleValuesSource (  )  )  ;", "}", "}    catch    ( Exception   e )     {", "throw   convertToScriptException (  \" link   error \"  ,    expr . sourceText ,    variable ,    e )  ;", "}", "}", "return   new   ExpressionSearchScript ( expr ,    bindings ,    specialValue ,    needsScores )  ;", "}", "METHOD_END"], "methodName": ["newSearchScript"], "fileName": "org.elasticsearch.script.expression.ExpressionScriptEngine"}, {"methodBody": ["METHOD_START", "{", "SearchScript . Factory   factory    =    service . compile ( null ,    expression ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "return   factory . newFactory ( Collections . emptyMap (  )  ,    lookup )  ;", "}", "METHOD_END"], "methodName": ["compile"], "fileName": "org.elasticsearch.script.expression.ExpressionTests"}, {"methodBody": ["METHOD_START", "{", "ScriptException   e    =    expectThrows ( ScriptException . class ,     (  )     -  >     {", "compile (  \" doc [  ' d '  ]  . value    *     *  @  #  )  (  @  $  *  @  #  $     +     4  \"  )  ;", "}  )  ;", "assertTrue (  (  ( e . getCause (  )  )    instanceof   ParseException )  )  ;", "}", "METHOD_END"], "methodName": ["testCompileError"], "fileName": "org.elasticsearch.script.expression.ExpressionTests"}, {"methodBody": ["METHOD_START", "{", "ScriptException   e    =    expectThrows ( ScriptException . class ,     (  )     -  >     {", "compile (  \" doc [  ' e '  ]  . value    *     5  \"  )  ;", "}  )  ;", "assertTrue (  (  ( e . getCause (  )  )    instanceof   ParseException )  )  ;", "}", "METHOD_END"], "methodName": ["testLinkError"], "fileName": "org.elasticsearch.script.expression.ExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertFalse ( compile (  \"  1  .  2  \"  )  . needs _ score (  )  )  ;", "assertFalse ( compile (  \" doc [  ' d '  ]  . value \"  )  . needs _ score (  )  )  ;", "assertTrue ( compile (  \"  1  /  _ score \"  )  . needs _ score (  )  )  ;", "assertTrue ( compile (  \" doc [  ' d '  ]  . value    *     _ score \"  )  . needs _ score (  )  )  ;", "}", "METHOD_END"], "methodName": ["testNeedsScores"], "fileName": "org.elasticsearch.script.expression.ExpressionTests"}, {"methodBody": ["METHOD_START", "{", "switch    ( method )     {", "case    . ISEMPTY _ METHOD    :", "return   new   GeoEmptyValueSource ( fieldData )  ;", "case    . GETLAT _ METHOD    :", "return   new   GeoLatitudeValueSource ( fieldData )  ;", "case    . GETLON _ METHOD    :", "return   new   GeoLongitudeValueSource ( fieldData )  ;", "default    :", "throw   new   IllegalArgumentException (  (  (  (  (  \" Member   method    [  \"     +    method )     +     \"  ]    does   not   exist   for   geo   field    [  \"  )     +    fieldName )     +     \"  ]  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getMethod"], "fileName": "org.elasticsearch.script.expression.GeoField"}, {"methodBody": ["METHOD_START", "{", "switch    ( variable )     {", "case    . EMPTY _ VARIABLE    :", "return   new   GeoEmptyValueSource ( fieldData )  ;", "case    . LAT _ VARIABLE    :", "return   new   GeoLatitudeValueSource ( fieldData )  ;", "case    . LON _ VARIABLE    :", "return   new   GeoLongitudeValueSource ( fieldData )  ;", "default    :", "throw   new   IllegalArgumentException (  (  (  (  (  \" Member   variable    [  \"     +    variable )     +     \"  ]    does   not   exist   for   geo   field    [  \"  )     +    fieldName )     +     \"  ]  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getVariable"], "fileName": "org.elasticsearch.script.expression.GeoField"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.script.expression.LangExpressionClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "ensureGreen (  \" test \"  )  ;", "Map < String ,    Object >    paramsMap    =    new   HashMap <  >  (  )  ;", "assert    (  ( params . length )     %     2  )     =  =     0  ;", "for    ( int   i    =     0  ;    i    <     ( params . length )  ;    i    +  =     2  )     {", "paramsMap . put ( params [ i ]  . toString (  )  ,    params [  ( i    +     1  )  ]  )  ;", "}", "SearchRequestBuilder   req    =    client (  )  . prepareSearch (  )  . setIndices (  \" test \"  )  ;", "req . setQuery ( QueryBuilders . matchAllQuery (  )  )  . addSort ( SortBuilders . fieldSort (  \"  _ id \"  )  . order ( ASC )  )  . addScriptField (  \" foo \"  ,    new   Script ( ScriptType . INLINE ,     \" expression \"  ,    script ,    paramsMap )  )  ;", "return   req ;", "}", "METHOD_END"], "methodName": ["buildRequest"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  \" test \"  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     4  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "SResponse   rsp    =    buildRequest (  \" doc [  ' foo '  ]     +     1  \"  )  . get (  )  ;", "assertEquals (  1  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  5  .  0  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testBasic"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  \" test \"  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     4  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "SResponse   rsp    =    buildRequest (  \" doc [  ' foo '  ]  . value    +     1  \"  )  . get (  )  ;", "assertEquals (  1  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  5  .  0  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testBasicUsingDotValue"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   xContentBuilder    =    XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" doc \"  )  . startObject (  \" properties \"  )  . startObject (  \" vip \"  )  . field (  \" type \"  ,     \" boolean \"  )  ;", "xContentBuilder . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  ;", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,    xContentBuilder )  )  ;", "ensureGreen (  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" price \"  ,     1  .  0  ,     \" vip \"  ,    true )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" price \"  ,     2  .  0  ,     \" vip \"  ,    false )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  3  \"  )  . setSource (  \" price \"  ,     2  .  0  ,     \" vip \"  ,    false )  )  ;", "SResponse   rsp    =    buildRequest (  \" doc [  ' vip '  ]  . value \"  )  . get (  )  ;", "assertSResponse ( rsp )  ;", "assertEquals (  3  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  1  .  0  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "assertEquals (  0  .  0  ,    rsp . getHits (  )  . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "assertEquals (  0  .  0  ,    rsp . getHits (  )  . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' vip '  ]  . empty    ?     1     :     0  \"  )  . get (  )  ;", "assertSResponse ( rsp )  ;", "assertEquals (  3  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  0  .  0  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "assertEquals (  0  .  0  ,    rsp . getHits (  )  . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "assertEquals (  1  .  0  ,    rsp . getHits (  )  . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' vip '  ]     ?    doc [  ' price '  ]  /  2     :    doc [  ' price '  ]  \"  )  . get (  )  ;", "assertSResponse ( rsp )  ;", "assertEquals (  3  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  0  .  5  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "assertEquals (  2  .  0  ,    rsp . getHits (  )  . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "assertEquals (  2  .  0  ,    rsp . getHits (  )  . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testBoolean"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" x \"  ,     1  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "try    {", "buildRequest (  \" garbage %  @  #  %  @  \"  )  . get (  )  ;", "fail (  \" Expected      compilation   failure \"  )  ;", "}    catch    ( SearchPhaseExecutionException   e )     {", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   ScriptException \"  )  ,    e . toString (  )  . contains (  \" ScriptException \"  )  ,    equalTo ( true )  )  ;", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   compilation   failure \"  )  ,    e . toString (  )  . contains (  \" compile   error \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCompileFailure"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "ElasticsearchAssertions . assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,     \" date 0  \"  ,     \" type = date \"  ,     \" date 1  \"  ,     \" type = date \"  )  )  ;", "ensureGreen (  \" test \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" date 0  \"  ,     \"  2  0  1  5  -  0  4  -  2  8 T 0  4  :  0  2  :  0  7 Z \"  ,     \" date 1  \"  ,     \"  1  9  8  5  -  0  9  -  0  1 T 2  3  :  1  1  :  0  1 Z \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" date 0  \"  ,     \"  2  0  1  3  -  1  2  -  2  5 T 1  1  :  5  6  :  4  5 Z \"  ,     \" date 1  \"  ,     \"  1  9  8  3  -  1  0  -  1  3 T 2  3  :  1  5  :  0  0 Z \"  )  )  ;", "SearchResponse   rsp    =    buildRequest (  \" doc [  ' date 0  '  ]  . getSeconds (  )     -    doc [  ' date 0  '  ]  . getMinutes (  )  \"  )  . get (  )  ;", "assertEquals (  2  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "SearchHits   hits    =    rsp . getHits (  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  (  -  1  1  .  0  )  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' date 0  '  ]  . getHourOfDay (  )     +    doc [  ' date 1  '  ]  . getDayOfMonth (  )  \"  )  . get (  )  ;", "assertEquals (  2  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  2  4  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' date 1  '  ]  . getMonth (  )     +     1  \"  )  . get (  )  ;", "assertEquals (  2  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  9  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  1  0  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' date 1  '  ]  . getYear (  )  \"  )  . get (  )  ;", "assertEquals (  2  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  1  9  8  5  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  1  9  8  3  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testDateMethods"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "ElasticsearchAssertions . assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,     \" date 0  \"  ,     \" type = date \"  ,     \" date 1  \"  ,     \" type = date \"  )  )  ;", "ensureGreen (  \" test \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" date 0  \"  ,     \"  2  0  1  5  -  0  4  -  2  8 T 0  4  :  0  2  :  0  7 Z \"  ,     \" date 1  \"  ,     \"  1  9  8  5  -  0  9  -  0  1 T 2  3  :  1  1  :  0  1 Z \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" date 0  \"  ,     \"  2  0  1  3  -  1  2  -  2  5 T 1  1  :  5  6  :  4  5 Z \"  ,     \" date 1  \"  ,     \"  1  9  8  3  -  1  0  -  1  3 T 2  3  :  1  5  :  0  0 Z \"  )  )  ;", "SearchResponse   rsp    =    buildRequest (  \" doc [  ' date 0  '  ]  . date . secondOfMinute    -    doc [  ' date 0  '  ]  . date . minuteOfHour \"  )  . get (  )  ;", "assertEquals (  2  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "SearchHits   hits    =    rsp . getHits (  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  (  -  1  1  .  0  )  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' date 0  '  ]  . date . getHourOfDay (  )     +    doc [  ' date 1  '  ]  . date . dayOfMonth \"  )  . get (  )  ;", "assertEquals (  2  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  2  4  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' date 1  '  ]  . date . monthOfYear    +     1  \"  )  . get (  )  ;", "assertEquals (  2  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  1  0  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  1  1  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' date 1  '  ]  . date . year \"  )  . get (  )  ;", "assertEquals (  2  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  1  9  8  5  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  1  9  8  3  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testDateObjectMethods"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     5  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "try    {", "buildRequest (  \" doc \"  )  . get (  )  ;", "fail (  \" Expected   doc   variable   without   field   to   cause   execution   failure \"  )  ;", "}    catch    ( SPhaseExecutionException   e )     {", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   ScriptException \"  )  ,    e . toString (  )  . contains (  \" ScriptException \"  )  ,    equalTo ( true )  )  ;", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   a   missing   specific   field   error \"  )  ,    e . toString (  )  . contains (  \" must   be   used   with   a   specific   field \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDocWithoutField"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   creates   classes   directly ,    cannot   run   with   security   manager \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "vars . put (  \" a \"  ,     2  .  5  )  ;", "vars . put (  \" b \"  ,     3  )  ;", "vars . put (  \" xyz \"  ,     (  -  1  )  )  ;", "Expression   expr    =    JavascriptCompiler . compile (  \" a + b + xyz \"  )  ;", "ExpressionExecutableScript   ees    =    new   ExpressionExecutableScript ( expr ,    vars )  ;", "assertEquals (  (  ( Double )     ( ees . run (  )  )  )  ,     4  .  5  ,     0  .  0  0  1  )  ;", "ees . setNextVar (  \" b \"  ,     (  -  2  .  5  )  )  ;", "assertEquals (  (  ( Double )     ( ees . run (  )  )  )  ,     (  -  1  )  ,     0  .  0  0  1  )  ;", "ees . setNextVar (  \" a \"  ,     (  -  2  .  5  )  )  ;", "ees . setNextVar (  \" b \"  ,     (  -  2  .  5  )  )  ;", "ees . setNextVar (  \" xyz \"  ,     (  -  2  .  5  )  )  ;", "assertEquals (  (  ( Double )     ( ees . run (  )  )  )  ,     (  -  7  .  5  )  ,     0  .  0  0  1  )  ;", "String   message ;", "try    {", "vars    =    new   HashMap <  >  (  )  ;", "vars . put (  \" a \"  ,     1  )  ;", "ees    =    new   ExpressionExecutableScript ( expr ,    vars )  ;", "ees . run (  )  ;", "fail (  \" An   incorrect   number   of   variables   were   allowed   to   be   used   in   an    \"  )  ;", "}    catch    ( GeneralScriptException   se )     {", "message    =    se . getMessage (  )  ;", "assertThat (  ( message    +     \"    should   have   contained   number   of   variables \"  )  ,    message . contains (  \" number   of   variables \"  )  ,    equalTo ( true )  )  ;", "}", "try    {", "vars    =    new   HashMap <  >  (  )  ;", "vars . put (  \" a \"  ,     1  )  ;", "vars . put (  \" b \"  ,     3  )  ;", "vars . put (  \" c \"  ,     (  -  1  )  )  ;", "ees    =    new   ExpressionExecutableScript ( expr ,    vars )  ;", "ees . run (  )  ;", "fail (  \" A   variable   was   allowed   to   be   set   that   does   not   exist   in   the    \"  )  ;", "}    catch    ( GeneralScriptException   se )     {", "message    =    se . getMessage (  )  ;", "assertThat (  ( message    +     \"    should   have   contained   does   not   exist   in \"  )  ,    message . contains (  \" does   not   exist   in \"  )  ,    equalTo ( true )  )  ;", "}", "try    {", "vars    =    new   HashMap <  >  (  )  ;", "vars . put (  \" a \"  ,     1  )  ;", "vars . put (  \" b \"  ,     3  )  ;", "vars . put (  \" xyz \"  ,     \" hello \"  )  ;", "ees    =    new   ExpressionExecutableScript ( expr ,    vars )  ;", "ees . run (  )  ;", "fail (  \" A   non - number   was   allowed   to   be   use   in   the    \"  )  ;", "}    catch    ( GeneralScriptException   se )     {", "message    =    se . getMessage (  )  ;", "assertThat (  ( message    +     \"    should   have   contained   process   numbers \"  )  ,    message . contains (  \" process   numbers \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testExecutableScripts"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  \" test \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     1  .  0  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" foo \"  ,     0  .  0  )  )  ;", "SearchRequestBuilder   builder    =    buildRequest (  \" doc [  ' foo '  ]  . value \"  )  ;", "Script   script    =    new   Script ( ScriptType . INLINE ,     \"  \"  ,     \" doc [  ' foo '  ]  . value \"  ,    Collections . emptyMap (  )  )  ;", "builder . setQuery ( QueryBuilders . boolQuery (  )  . filter ( QueryBuilders . scriptQuery ( script )  )  )  ;", "SearchResponse   rsp    =    builder . get (  )  ;", "assertSearchResponse ( rsp )  ;", "assertEquals (  1  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  1  .  0  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testFilterScript"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  \" test \"  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     4  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "SResponse   rsp    =    buildRequest (  \" doc [  ' foo '  ]     +    abs (  1  )  \"  )  . get (  )  ;", "assertSResponse ( rsp )  ;", "assertEquals (  1  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  5  .  0  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testFunction"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   xContentBuilder    =    XContentFactory . jsonBuilder (  )  . startObject (  )  . startObject (  \" type 1  \"  )  . startObject (  \" properties \"  )  . startObject (  \" location \"  )  . field (  \" type \"  ,     \" geo _ point \"  )  ;", "xContentBuilder . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  ;", "assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" type 1  \"  ,    xContentBuilder )  )  ;", "ensureGreen (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type 1  \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" name \"  ,     \" test \"  )  . startObject (  \" location \"  )  . field (  \" lat \"  ,     6  1  .  5  2  4  )  . field (  \" lon \"  ,     1  0  5  .  3  1  8  8  )  . endObject (  )  . endObject (  )  )  . execute (  )  . actionGet (  )  ;", "refresh (  )  ;", "SResponse   rsp    =    buildRequest (  \" doc [  ' location '  ]  . lat \"  )  . get (  )  ;", "assertSResponse ( rsp )  ;", "assertEquals (  1  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  6  1  .  5  2  4  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' location '  ]  . lon \"  )  . get (  )  ;", "assertSResponse ( rsp )  ;", "assertEquals (  1  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  1  0  5  .  3  1  8  8  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' location '  ]  . empty    ?     1     :     0  \"  )  . get (  )  ;", "assertSResponse ( rsp )  ;", "assertEquals (  1  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  0  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     1  .  0  )  ;", "rsp    =    buildRequest (  \" haversin (  3  8  .  9  0  7  2  ,     7  7  .  0  3  6  9  ,    doc [  ' location '  ]  . lat ,    doc [  ' location '  ]  . lon )  \"  )  . get (  )  ;", "assertSResponse ( rsp )  ;", "assertEquals (  1  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  3  1  7  0  .  0  ,    rsp . getHits (  )  . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     5  0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testGeo"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "ElasticsearchAssertions . assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,     \" double \"  ,     \" type = double \"  )  )  ;", "ensureGreen (  \" test \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" double \"  ,     \"  1  7  8  0  0  0  0  0  0  .  0  \"  )  )  ;", "try    {", "buildRequest (  \" doc [  ' double '  ]  . getYear (  )  \"  )  . get (  )  ;", "fail (  )  ;", "}    catch    ( SearchPhaseExecutionException   e )     {", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   IllegalArgumentException \"  )  ,    e . toString (  )  . contains (  \" IllegalArgumentException \"  )  ,    equalTo ( true )  )  ;", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   does   not   exist   for   numeric   field \"  )  ,    e . toString (  )  . contains (  \" does   not   exist   for   numeric   field \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testInvalidDateMethodCall"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     5  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "try    {", "buildRequest (  \" doc [  ' foo '  ]  . bogus \"  )  . get (  )  ;", "fail (  \" Expected   bogus   field   member   to   cause   execution   failure \"  )  ;", "}    catch    ( SPhaseExecutionException   e )     {", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   ScriptException \"  )  ,    e . toString (  )  . contains (  \" ScriptException \"  )  ,    equalTo ( true )  )  ;", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   member   variable    [ bogus ]    does   not   exist \"  )  ,    e . toString (  )  . contains (  \" Member   variable    [ bogus ]    does   not   exist \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testInvalidFieldMember"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     5  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "try    {", "buildRequest (  \" bogus \"  )  . get (  )  ;", "fail (  \" Expected   bogus   variable   to   cause   execution   failure \"  )  ;", "}    catch    ( SPhaseExecutionException   e )     {", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   ScriptException \"  )  ,    e . toString (  )  . contains (  \" ScriptException \"  )  ,    equalTo ( true )  )  ;", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   unknown   variable   error \"  )  ,    e . toString (  )  . contains (  \" Unknown   variable \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testInvalidGlobalVariable"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "try    {", "createIndex (  \" test _ index \"  )  ;", "ensureGreen (  \" test _ index \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test _ index \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" text _ field \"  ,     \" text \"  )  )  ;", "UpdateRequestBuilder   urb    =    client (  )  . prepareUpdate (  )  . setIndex (  \" test _ index \"  )  ;", "urb . setType (  \" doc \"  )  ;", "urb . setId (  \"  1  \"  )  ;", "urb . setScript ( new   Script ( ScriptType . INLINE ,    ExpressionScriptEngine . NAME ,     \"  0  \"  ,    Collections . emptyMap (  )  )  )  ;", "urb . get (  )  ;", "fail (  \" Expression   scripts   should   not   be   allowed   to   run   as   update   scripts .  \"  )  ;", "}    catch    ( Exception   e )     {", "String   message    =    e . getMessage (  )  ;", "assertThat (  ( message    +     \"    should   have   contained   failed   to   execute \"  )  ,    message . contains (  \" failed   to   execute \"  )  ,    equalTo ( true )  )  ;", "message    =    e . getCause (  )  . getMessage (  )  ;", "assertThat (  ( message    +     \"    should   have   contained   not   supported \"  )  ,    message . contains (  \" not   supported \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testInvalidUpdateScript"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  \" test \"  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" x \"  ,     4  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "try    {", "buildRequest (  \" doc [  ' bogus '  ]  \"  )  . get (  )  ;", "fail (  \" Expected   missing   field   to   cause   failure \"  )  ;", "}    catch    ( SPhaseExecutionException   e )     {", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   ScriptException \"  )  ,    e . toString (  )  . contains (  \" ScriptException \"  )  ,    equalTo ( true )  )  ;", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   missing   field   error \"  )  ,    e . toString (  )  . contains (  \" does   not   exist   in   mappings \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMissingField"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "ElasticsearchAssertions . assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,     \" double 0  \"  ,     \" type = double \"  ,     \" double 1  \"  ,     \" type = double \"  ,     \" double 2  \"  ,     \" type = double \"  )  )  ;", "ensureGreen (  \" test \"  )  ;", "Map < String ,    Object >    doc 1     =    new   HashMap <  >  (  )  ;", "doc 1  . put (  \" double 0  \"  ,    new   Double [  ]  {     5  .  0  ,     1  .  0  ,     1  .  5     }  )  ;", "doc 1  . put (  \" double 1  \"  ,    new   Double [  ]  {     1  .  2  ,     2  .  4     }  )  ;", "doc 1  . put (  \" double 2  \"  ,     3  .  0  )  ;", "Map < String ,    Object >    doc 2     =    new   HashMap <  >  (  )  ;", "doc 2  . put (  \" double 0  \"  ,     5  .  0  )  ;", "doc 2  . put (  \" double 1  \"  ,     3  .  0  )  ;", "Map < String ,    Object >    doc 3     =    new   HashMap <  >  (  )  ;", "doc 3  . put (  \" double 0  \"  ,    new   Double [  ]  {     5  .  0  ,     1  .  0  ,     1  .  5  ,     -  1  .  5     }  )  ;", "doc 3  . put (  \" double 1  \"  ,     4  .  0  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource ( doc 1  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource ( doc 2  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  3  \"  )  . setSource ( doc 3  )  )  ;", "SearchResponse   rsp    =    buildRequest (  \" doc [  ' double 0  '  ]  . count (  )     +    doc [  ' double 1  '  ]  . count (  )  \"  )  . get (  )  ;", "assertSearchResponse ( rsp )  ;", "SearchHits   hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  2  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' double 0  '  ]  . sum (  )  \"  )  . get (  )  ;", "assertSearchResponse ( rsp )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  7  .  5  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  6  .  0  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' double 0  '  ]  . avg (  )     +    doc [  ' double 1  '  ]  . avg (  )  \"  )  . get (  )  ;", "assertSearchResponse ( rsp )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  4  .  3  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  8  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  5  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' double 0  '  ]  . median (  )  \"  )  . get (  )  ;", "assertSearchResponse ( rsp )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  1  .  5  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  1  .  2  5  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' double 0  '  ]  . min (  )  \"  )  . get (  )  ;", "assertSearchResponse ( rsp )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  1  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  (  -  1  .  5  )  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' double 0  '  ]  . max (  )  \"  )  . get (  )  ;", "assertSearchResponse ( rsp )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' double 0  '  ]  . sum (  )  / doc [  ' double 0  '  ]  . count (  )  \"  )  . get (  )  ;", "assertSearchResponse ( rsp )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  2  .  5  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  1  .  5  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' double 2  '  ]  . count (  )  \"  )  . get (  )  ;", "assertSearchResponse ( rsp )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  1  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  0  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  0  .  0  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "rsp    =    buildRequest (  \" doc [  ' double 2  '  ]  . empty    ?     5  .  0     :     2  .  0  \"  )  . get (  )  ;", "assertSearchResponse ( rsp )  ;", "hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  2  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testMultiValueMethods"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" text \"  ,     \" this   is   not   a   number \"  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "try    {", "buildRequest (  \" doc [  ' text . keyword '  ]  \"  )  . get (  )  ;", "fail (  \" Expected   text   field   to   cause   execution   failure \"  )  ;", "}    catch    ( SPhaseExecutionException   e )     {", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   ScriptException \"  )  ,    e . toString (  )  . contains (  \" ScriptException \"  )  ,    equalTo ( true )  )  ;", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   non - numeric   field   error \"  )  ,    e . toString (  )  . contains (  \" must   be   numeric \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testNonNumericField"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" x \"  ,     1  )  . setRefreshPolicy ( IMMEDIATE )  . get (  )  ;", "try    {", "buildRequest (  \" a \"  ,     \" a \"  ,     \" astring \"  )  . get (  )  ;", "fail (  \" Expected   string   parameter   to   cause   failure \"  )  ;", "}    catch    ( SPhaseExecutionException   e )     {", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   ScriptException \"  )  ,    e . toString (  )  . contains (  \" ScriptException \"  )  ,    equalTo ( true )  )  ;", "assertThat (  (  ( e . toString (  )  )     +     \" should   have   contained   non - numeric   parameter   error \"  )  ,    e . toString (  )  . contains (  \" must   be   a   numeric   type \"  )  ,    equalTo ( true )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testNonNumericParam"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  \" test \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" x \"  ,     1  0  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" x \"  ,     3  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  3  \"  )  . setSource (  \" x \"  ,     5  )  )  ;", "String       =     \" doc [  ' x '  ]     *    a    +    b    +     (  ( c    +    doc [  ' x '  ]  )     >     5  0  0  0  0  0  0  0  0  9     ?     1     :     0  )  \"  ;", "SearchResponse   rsp    =    buildRequest (  ,     \" a \"  ,     2  ,     \" b \"  ,     3  .  5  ,     \" c \"  ,     5  0  0  0  0  0  0  0  0  0 L )  . get (  )  ;", "SearchHits   hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  2  4  .  5  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  9  .  5  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  1  3  .  5  ,    hits . getAt (  2  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testParams"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" agg _ index \"  )  ;", "ensureGreen (  \" agg _ index \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" agg _ index \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" one \"  ,     1  .  0  ,     \" two \"  ,     2  .  0  ,     \" three \"  ,     3  .  0  ,     \" four \"  ,     4  .  0  )  ,    client (  )  . prepareIndex (  \" agg _ index \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" one \"  ,     2  .  0  ,     \" two \"  ,     2  .  0  ,     \" three \"  ,     3  .  0  ,     \" four \"  ,     4  .  0  )  ,    client (  )  . prepareIndex (  \" agg _ index \"  ,     \" doc \"  ,     \"  3  \"  )  . setSource (  \" one \"  ,     3  .  0  ,     \" two \"  ,     2  .  0  ,     \" three \"  ,     3  .  0  ,     \" four \"  ,     4  .  0  )  ,    client (  )  . prepareIndex (  \" agg _ index \"  ,     \" doc \"  ,     \"  4  \"  )  . setSource (  \" one \"  ,     4  .  0  ,     \" two \"  ,     2  .  0  ,     \" three \"  ,     3  .  0  ,     \" four \"  ,     4  .  0  )  ,    client (  )  . prepareIndex (  \" agg _ index \"  ,     \" doc \"  ,     \"  5  \"  )  . setSource (  \" one \"  ,     5  .  0  ,     \" two \"  ,     2  .  0  ,     \" three \"  ,     3  .  0  ,     \" four \"  ,     4  .  0  )  )  ;", "SearchResponse   response    =    client (  )  . prepareSearch (  \" agg _ index \"  )  . addAggregation ( AggregationBuilders . histogram (  \" histogram \"  )  . field (  \" one \"  )  . interval (  2  )  . subAggregation ( AggregationBuilders . sum (  \" twoSum \"  )  . field (  \" two \"  )  )  . subAggregation ( AggregationBuilders . sum (  \" threeSum \"  )  . field (  \" three \"  )  )  . subAggregation ( AggregationBuilders . sum (  \" fourSum \"  )  . field (  \" four \"  )  )  . subAggregation ( bucketScript (  \" totalSum \"  ,    new   Script ( ScriptType . INLINE ,    ExpressionScriptEngine . NAME ,     \"  _ value 0     +     _ value 1     +     _ value 2  \"  ,    Collections . emptyMap (  )  )  ,     \" twoSum \"  ,     \" threeSum \"  ,     \" fourSum \"  )  )  )  . execute (  )  . actionGet (  )  ;", "Histogram   histogram    =    response . getAggregations (  )  . get (  \" histogram \"  )  ;", "assertThat ( histogram ,    notNullValue (  )  )  ;", "assertThat ( histogram . getName (  )  ,    equalTo (  \" histogram \"  )  )  ;", "List <  ?    extends   Histogram . Bucket >    buckets    =    histogram . getBuckets (  )  ;", "for    ( int   bucketCount    =     0  ;    bucketCount    <     ( buckets . size (  )  )  ;     +  + bucketCount )     {", "Histogram . Bucket   bucket    =    buckets . get ( bucketCount )  ;", "if    (  ( bucket . getDocCount (  )  )     =  =     1  )     {", "SimpleValue   seriesArithmetic    =    bucket . getAggregations (  )  . get (  \" totalSum \"  )  ;", "assertThat ( seriesArithmetic ,    notNullValue (  )  )  ;", "double   seriesArithmeticValue    =    seriesArithmetic . value (  )  ;", "assertEquals (  9  .  0  ,    seriesArithmeticValue ,     0  .  0  0  1  )  ;", "} else", "if    (  ( bucket . getDocCount (  )  )     =  =     2  )     {", "SimpleValue   seriesArithmetic    =    bucket . getAggregations (  )  . get (  \" totalSum \"  )  ;", "assertThat ( seriesArithmetic ,    notNullValue (  )  )  ;", "double   seriesArithmeticValue    =    seriesArithmetic . value (  )  ;", "assertEquals (  1  8  .  0  ,    seriesArithmeticValue ,     0  .  0  0  1  )  ;", "} else    {", "fail (  \" Incorrect   number   of   documents   in   a   bucket   in   the   histogram .  \"  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testPipelineAggregationScript"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  \" test \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" text \"  ,     \" hello   goodbye \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" text \"  ,     \" hello   hello   hello   goodbye \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  3  \"  )  . setSource (  \" text \"  ,     \" hello   hello   goodebye \"  )  )  ;", "ScoreFunctionBuilder <  ?  >    score    =    ScoreFunctionBuilders . scriptFunction ( new   Script ( ScriptType . INLINE ,     \" expression \"  ,     \"  1     /     _ score \"  ,    Collections . emptyMap (  )  )  )  ;", "SearchRequestBuilder   req    =    client (  )  . prepareSearch (  )  . setIndices (  \" test \"  )  ;", "req . setQuery ( QueryBuilders . functionScoreQuery ( QueryBuilders . termQuery (  \" text \"  ,     \" hello \"  )  ,    score )  . boostMode ( REPLACE )  )  ;", "req . setSearchType ( DFS _ QUERY _ THEN _ FETCH )  ;", "SearchResponse   rsp    =    req . get (  )  ;", "assertSearchResponse ( rsp )  ;", "SearchHits   hits    =    rsp . getHits (  )  ;", "assertEquals (  3  ,    hits . getTotalHits (  )  )  ;", "assertEquals (  \"  1  \"  ,    hits . getAt (  0  )  . getId (  )  )  ;", "assertEquals (  \"  3  \"  ,    hits . getAt (  1  )  . getId (  )  )  ;", "assertEquals (  \"  2  \"  ,    hits . getAt (  2  )  . getId (  )  )  ;", "}", "METHOD_END"], "methodName": ["testScore"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "ElasticsearchAssertions . assertAcked ( prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,     \" x \"  ,     \" type = long \"  ,     \" y \"  ,     \" type = long \"  )  )  ;", "ensureGreen (  \" test \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" x \"  ,     4  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" y \"  ,     2  )  )  ;", "SearchResponse   rsp    =    buildRequest (  \" doc [  ' x '  ]     +     1  \"  )  . get (  )  ;", "ElasticsearchAssertions . assertSearchResponse ( rsp )  ;", "SearchHits   hits    =    rsp . getHits (  )  ;", "assertEquals (  2  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "assertEquals (  5  .  0  ,    hits . getAt (  0  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "assertEquals (  1  .  0  ,    hits . getAt (  1  )  . field (  \" foo \"  )  . getValue (  )  ,     0  .  0  )  ;", "}", "METHOD_END"], "methodName": ["testSparseField"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  \" test \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" x \"  ,     5  ,     \" y \"  ,     1  .  2  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" x \"  ,     1  0  ,     \" y \"  ,     1  .  4  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  3  \"  )  . setSource (  \" x \"  ,     1  3  ,     \" y \"  ,     1  .  8  )  )  ;", "SearchRequestBuilder   req    =    client (  )  . prepareSearch (  )  . setIndices (  \" test \"  )  ;", "req . setQuery ( QueryBuilders . matchAllQuery (  )  )  . addAggregation ( AggregationBuilders . stats (  \" int _ agg \"  )  . field (  \" x \"  )  . script ( new   Script ( ScriptType . INLINE ,    ExpressionScriptEngine . NAME ,     \"  _ value    *     3  \"  ,    Collections . emptyMap (  )  )  )  )  . addAggregation ( AggregationBuilders . stats (  \" double _ agg \"  )  . field (  \" y \"  )  . script ( new   Script ( ScriptType . INLINE ,    ExpressionScriptEngine . NAME ,     \"  _ value    -     1  .  1  \"  ,    Collections . emptyMap (  )  )  )  )  . addAggregation ( AggregationBuilders . stats (  \" const _ agg \"  )  . field (  \" x \"  )  . script ( new   Script ( ScriptType . INLINE ,    ExpressionScriptEngine . NAME ,     \"  3  .  0  \"  ,    Collections . emptyMap (  )  )  )  )  ;", "SearchResponse   rsp    =    req . get (  )  ;", "assertEquals (  3  ,    rsp . getHits (  )  . getTotalHits (  )  )  ;", "Stats   stats    =    rsp . getAggregations (  )  . get (  \" int _ agg \"  )  ;", "assertEquals (  3  9  .  0  ,    stats . getMax (  )  ,     1  .  0 E -  4  )  ;", "assertEquals (  1  5  .  0  ,    stats . getMin (  )  ,     1  .  0 E -  4  )  ;", "stats    =    rsp . getAggregations (  )  . get (  \" double _ agg \"  )  ;", "assertEquals (  0  .  7  ,    stats . getMax (  )  ,     1  .  0 E -  4  )  ;", "assertEquals (  0  .  1  ,    stats . getMin (  )  ,     1  .  0 E -  4  )  ;", "stats    =    rsp . getAggregations (  )  . get (  \" const _ agg \"  )  ;", "assertThat ( stats . getMax (  )  ,    equalTo (  3  .  0  )  )  ;", "assertThat ( stats . getMin (  )  ,    equalTo (  3  .  0  )  )  ;", "assertThat ( stats . getAvg (  )  ,    equalTo (  3  .  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testSpecialValueVariable"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . indices (  )  . prepareCreate (  \" test \"  )  . addMapping (  \" doc \"  ,     \" text \"  ,     \" type = keyword \"  )  . get (  )  )  ;", "ensureGreen (  \" test \"  )  ;", "indexRandom ( true ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" text \"  ,     \" hello \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  2  \"  )  . setSource (  \" text \"  ,     \" goodbye \"  )  ,    client (  )  . prepareIndex (  \" test \"  ,     \" doc \"  ,     \"  3  \"  )  . setSource (  \" text \"  ,     \" hello \"  )  )  ;", "SearchRequestBuilder   req    =    client (  )  . prepareSearch (  )  . setIndices (  \" test \"  )  ;", "req . setQuery ( QueryBuilders . matchAllQuery (  )  )  . addAggregation ( AggregationBuilders . terms (  \" term _ agg \"  )  . field (  \" text \"  )  . script ( new   Script ( ScriptType . INLINE ,    ExpressionScriptEngine . NAME ,     \"  _ value \"  ,    Collections . emptyMap (  )  )  )  )  ;", "String   message ;", "try    {", "SearchResponse   rsp    =    req . get (  )  ;", "assertThat ( rsp . getShardFailures (  )  . length ,    greaterThan (  0  )  )  ;", "message    =    rsp . getShardFailures (  )  [  0  ]  . reason (  )  ;", "}    catch    ( SearchPhaseExecutionException   e )     {", "message    =    e . toString (  )  ;", "}", "assertThat (  ( message    +     \" should   have   contained   ScriptException \"  )  ,    message . contains (  \" ScriptException \"  )  ,    equalTo ( true )  )  ;", "assertThat (  ( message    +     \" should   have   contained   text   variable   error \"  )  ,    message . contains (  \" text   variable \"  )  ,    equalTo ( true )  )  ;", "}", "METHOD_END"], "methodName": ["testStringSpecialValueVariable"], "fileName": "org.elasticsearch.script.expression.MoreExpressionTests"}, {"methodBody": ["METHOD_START", "{", "switch    ( method )     {", "case    . GETVALUE _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MIN )  ;", "case    . ISEMPTY _ METHOD    :", "return   new   EmptyMemberValueSource ( fieldData )  ;", "case    . SIZE _ METHOD    :", "return   new   CountMethodValueSource ( fieldData )  ;", "case    . MINIMUM _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MIN )  ;", "case    . MAXIMUM _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MAX )  ;", "case    . AVERAGE _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . AVG )  ;", "case    . MEDIAN _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MEDIAN )  ;", "case    . SUM _ METHOD    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . SUM )  ;", "case    . COUNT _ METHOD    :", "return   new   CountMethodValueSource ( fieldData )  ;", "default    :", "throw   new   IllegalArgumentException (  (  (  (  (  \" Member   method    [  \"     +    method )     +     \"  ]    does   not   exist   for   numeric   field    [  \"  )     +    fieldName )     +     \"  ]  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getMethod"], "fileName": "org.elasticsearch.script.expression.NumericField"}, {"methodBody": ["METHOD_START", "{", "switch    ( variable )     {", "case    . VALUE _ VARIABLE    :", "return   new   FieldDataValueSource ( fieldData ,    MultiValueMode . MIN )  ;", "case    . EMPTY _ VARIABLE    :", "return   new   EmptyMemberValueSource ( fieldData )  ;", "case    . LENGTH _ VARIABLE    :", "return   new   CountMethodValueSource ( fieldData )  ;", "default    :", "throw   new   IllegalArgumentException (  (  (  (  (  (  \" Member   variable    [  \"     +    variable )     +     \"  ]    does   not   exist   for    \"  )     +     \" numeric   field    [  \"  )     +    fieldName )     +     \"  ]  .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["getVariable"], "fileName": "org.elasticsearch.script.expression.NumericField"}, {"methodBody": ["METHOD_START", "{", "fv . setValue ( v )  ;", "}", "METHOD_END"], "methodName": ["setValue"], "fileName": "org.elasticsearch.script.expression.ReplaceableConstDoubleValueSource"}, {"methodBody": ["METHOD_START", "{", "this . value    =    value ;", "}", "METHOD_END"], "methodName": ["setValue"], "fileName": "org.elasticsearch.script.expression.ReplaceableConstDoubleValues"}, {"methodBody": ["METHOD_START", "{", "client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \" script 1  \"  )  . setContent ( new   BytesArray (  \"  {  \\  \" script \\  \"  :     {  \\  \" lang \\  \"  :     \\  \" expression \\  \"  ,     \\  \" source \\  \"  :     \\  \"  2  \\  \"  }     }  \"  )  ,    JSON )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" scriptTest \"  ,     \"  1  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo \\  \"  }  \"  ,    JSON )  . get (  )  ;", "try    {", "client (  )  . prepareUpdate (  \" test \"  ,     \" scriptTest \"  ,     \"  1  \"  )  . setScript ( new   Script ( ScriptType . STORED ,    null ,     \" script 1  \"  ,    Collections . emptyMap (  )  )  )  . get (  )  ;", "fail (  \" update   script   should   have   been   rejected \"  )  ;", "}    catch    ( Exception   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \" failed   to   execute   script \"  )  )  ;", "assertThat ( e . getCause (  )  . getMessage (  )  ,    containsString (  \" scripts   of   type    [ stored ]  ,    operation    [ update ]    and   lang    [ expression ]    are   not   supported \"  )  )  ;", "}", "try    {", "client (  )  . prepareSearch (  )  . setSource ( new   SearchSourceBuilder (  )  . scriptField (  \" test 1  \"  ,    new   Script ( ScriptType . STORED ,    null ,     \" script 1  \"  ,    Collections . emptyMap (  )  )  )  )  . setIndices (  \" test \"  )  . setTypes (  \" scriptTest \"  )  . get (  )  ;", "fail (  \" search   script   should   have   been   rejected \"  )  ;", "}    catch    ( Exception   e )     {", "assertThat ( e . toString (  )  ,    containsString (  \" cannot   execute   scripts   using    [ search ]    context \"  )  )  ;", "}", "try    {", "client (  )  . prepareSearch (  \" test \"  )  . setSource ( new   SearchSourceBuilder (  )  . aggregation ( AggregationBuilders . terms (  \" test \"  )  . script ( new   Script ( ScriptType . STORED ,    null ,     \" script 1  \"  ,    Collections . emptyMap (  )  )  )  )  )  . get (  )  ;", "}    catch    ( Exception   e )     {", "assertThat ( e . toString (  )  ,    containsString (  \" cannot   execute   scripts   using    [ aggs ]    context \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testAllOpsDisabledIndexedScripts"], "fileName": "org.elasticsearch.script.expression.StoredExpressionTests"}, {"methodBody": ["METHOD_START", "{", "Supplier < CustomMustacheFactory . Encoder >    supplier    =    CustomMustacheFactory . ENCODERS . get ( mimeType )  ;", "if    ( supplier    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  \" No   encoder   found   for   MIME   type    [  \"     +    mimeType )     +     \"  ]  \"  )  )  ;", "}", "return   supplier . get (  )  ;", "}", "METHOD_END"], "methodName": ["createEncoder"], "fileName": "org.elasticsearch.script.mustache.CustomMustacheFactory"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    CustomMustacheFactory . createEncoder ( null )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" No   encoder   found   for   MIME   type    [ null ]  \"  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    CustomMustacheFactory . createEncoder (  \"  \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" No   encoder   found   for   MIME   type    [  ]  \"  )  )  ;", "e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    CustomMustacheFactory . createEncoder (  \" test \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" No   encoder   found   for   MIME   type    [ test ]  \"  )  )  ;", "assertThat ( CustomMustacheFactory . createEncoder ( CustomMustacheFactory . JSON _ MIME _ TYPE _ WITH _ CHARSET )  ,    instanceOf ( CustomMustacheFactory . JsonEscapeEncoder . class )  )  ;", "assertThat ( CustomMustacheFactory . createEncoder ( CustomMustacheFactory . JSON _ MIME _ TYPE )  ,    instanceOf ( CustomMustacheFactory . JsonEscapeEncoder . class )  )  ;", "assertThat ( CustomMustacheFactory . createEncoder ( CustomMustacheFactory . PLAIN _ TEXT _ MIME _ TYPE )  ,    instanceOf ( CustomMustacheFactory . DefaultEncoder . class )  )  ;", "assertThat ( CustomMustacheFactory . createEncoder ( CustomMustacheFactory . X _ WWW _ FORM _ URLENCODED _ MIME _ TYPE )  ,    instanceOf ( CustomMustacheFactory . UrlEncoder . class )  )  ;", "}", "METHOD_END"], "methodName": ["testCreateEncoder"], "fileName": "org.elasticsearch.script.mustache.CustomMustacheFactoryTests"}, {"methodBody": ["METHOD_START", "{", "final   ScriptEngine   engine    =    new   MustacheScriptEngine (  )  ;", "final   Map < String ,    String >    params    =    Collections . singletonMap ( CONTENT _ TYPE _ OPTION ,     . PLAIN _ TEXT _ MIME _ TYPE )  ;", "TemplateScript . Factory   compiled    =    engine . compile ( null ,     \"  {  \\  \" field \\  \"  :     \\  \"  {  { value }  }  \\  \"  }  \"  ,    CONTEXT ,    params )  ;", "TemplateScript   executable    =    compiled . newInstance ( Collections . singletonMap (  \" value \"  ,     \" a    \\  \" value \\  \"  \"  )  )  ;", "assertThat ( executable . execute (  )  ,    equalTo (  \"  {  \\  \" field \\  \"  :     \\  \" a    \\  \" value \\  \"  \\  \"  }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaultEncoder"], "fileName": "org.elasticsearch.script.mustache.CustomMustacheFactoryTests"}, {"methodBody": ["METHOD_START", "{", "final   ScriptEngine   engine    =    new   MustacheScriptEngine (  )  ;", "final   Map < String ,    String >    params    =     ( randomBoolean (  )  )     ?    Collections . singletonMap ( CONTENT _ TYPE _ OPTION ,     . JSON _ MIME _ TYPE )     :    Collections . emptyMap (  )  ;", "TemplateScript . Factory   compiled    =    engine . compile ( null ,     \"  {  \\  \" field \\  \"  :     \\  \"  {  { value }  }  \\  \"  }  \"  ,    CONTEXT ,    params )  ;", "TemplateScript   executable    =    compiled . newInstance ( Collections . singletonMap (  \" value \"  ,     \" a    \\  \" value \\  \"  \"  )  )  ;", "assertThat ( executable . execute (  )  ,    equalTo (  \"  {  \\  \" field \\  \"  :     \\  \" a    \\  \\  \\  \" value \\  \\  \\  \"  \\  \"  }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testJsonEscapeEncoder"], "fileName": "org.elasticsearch.script.mustache.CustomMustacheFactoryTests"}, {"methodBody": ["METHOD_START", "{", "final   ScriptEngine   engine    =    new   MustacheScriptEngine (  )  ;", "final   Map < String ,    String >    params    =    Collections . singletonMap ( CONTENT _ TYPE _ OPTION ,     . X _ WWW _ FORM _ URLENCODED _ MIME _ TYPE )  ;", "TemplateScript . Factory   compiled    =    engine . compile ( null ,     \"  {  \\  \" field \\  \"  :     \\  \"  {  { value }  }  \\  \"  }  \"  ,    CONTEXT ,    params )  ;", "TemplateScript   executable    =    compiled . newInstance ( Collections . singletonMap (  \" value \"  ,     \" tilde ~    AND   date :  [  2  0  1  6    FROM *  ]  \"  )  )  ;", "assertThat ( executable . execute (  )  ,    equalTo (  \"  {  \\  \" field \\  \"  :     \\  \" tilde %  7 E + AND + date %  3 A %  5 B 2  0  1  6  + FROM *  %  5 D \\  \"  }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUrlEncoder"], "fileName": "org.elasticsearch.script.mustache.CustomMustacheFactoryTests"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.script.mustache.LangMustacheClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" msearch \"  )  ;", "final   int   numDocs    =    randomIntBetween (  1  0  ,     1  0  0  )  ;", "IndexRequestBuilder [  ]    indexRequestBuilders    =    new   IndexRequestBuilder [ numDocs ]  ;", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "indexRequestBuilders [ i ]     =    client (  )  . prepareIndex (  \" msearch \"  ,     \" test \"  ,    String . valueOf ( i )  )  . setSource (  \" odd \"  ,     (  ( i    %     2  )     =  =     0  )  ,     \" group \"  ,     ( i    %     3  )  )  ;", "}", "indexRandom ( true ,    indexRequestBuilders )  ;", "final   String   template    =    Strings . toString ( jsonBuilder (  )  . startObject (  )  . startObject (  \" query \"  )  . startObject (  \"  {  { query _ type }  }  \"  )  . field (  \"  {  { field _ name }  }  \"  ,     \"  {  { field _ value }  }  \"  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "Request   multiRequest    =    new   Request (  )  ;", "SearchTemplateRequest   search 1     =    new   SearchTemplateRequest (  )  ;", "search 1  . setRequest ( new   SearchRequest (  \" msearch \"  )  )  ;", "search 1  . setScriptType ( INLINE )  ;", "search 1  . setScript ( template )  ;", "Map < String ,    Object >    params 1     =    new   HashMap <  >  (  )  ;", "params 1  . put (  \" query _ type \"  ,     \" match \"  )  ;", "params 1  . put (  \" field _ name \"  ,     \" odd \"  )  ;", "params 1  . put (  \" field _ value \"  ,    true )  ;", "search 1  . setScriptParams ( params 1  )  ;", "multiRequest . add ( search 1  )  ;", "SearchTemplateRequest   search 2     =    new   SearchTemplateRequest (  )  ;", "search 2  . setRequest ( new   SearchRequest (  \" msearch \"  )  )  ;", "search 2  . setScriptType ( INLINE )  ;", "search 2  . setScript ( template )  ;", "search 2  . setSimulate ( true )  ;", "Map < String ,    Object >    params 2     =    new   HashMap <  >  (  )  ;", "params 2  . put (  \" query _ type \"  ,     \" match _ phrase _ prefix \"  )  ;", "params 2  . put (  \" field _ name \"  ,     \" message \"  )  ;", "params 2  . put (  \" field _ value \"  ,     \" quick   brown   f \"  )  ;", "search 2  . setScriptParams ( params 2  )  ;", "multiRequest . add ( search 2  )  ;", "SearchTemplateRequest   search 3     =    new   SearchTemplateRequest (  )  ;", "search 3  . setRequest ( new   SearchRequest (  \" msearch \"  )  )  ;", "search 3  . setScriptType ( INLINE )  ;", "search 3  . setScript ( template )  ;", "search 3  . setSimulate ( false )  ;", "Map < String ,    Object >    params 3     =    new   HashMap <  >  (  )  ;", "params 3  . put (  \" query _ type \"  ,     \" term \"  )  ;", "params 3  . put (  \" field _ name \"  ,     \" odd \"  )  ;", "params 3  . put (  \" field _ value \"  ,     \" false \"  )  ;", "search 3  . setScriptParams ( params 3  )  ;", "multiRequest . add ( search 3  )  ;", "SearchTemplateRequest   search 4     =    new   SearchTemplateRequest (  )  ;", "search 4  . setRequest ( new   SearchRequest (  \" unknown \"  )  )  ;", "search 4  . setScriptType ( INLINE )  ;", "search 4  . setScript ( template )  ;", "Map < String ,    Object >    params 4     =    new   HashMap <  >  (  )  ;", "params 4  . put (  \" query _ type \"  ,     \" match \"  )  ;", "params 4  . put (  \" field _ name \"  ,     \" group \"  )  ;", "params 4  . put (  \" field _ value \"  ,     \" test \"  )  ;", "search 4  . setScriptParams ( params 4  )  ;", "multiRequest . add ( search 4  )  ;", "SearchTemplateRequest   search 5     =    new   SearchTemplateRequest (  )  ;", "search 5  . setRequest ( new   SearchRequest (  \" msearch \"  )  )  ;", "search 5  . setScriptType ( INLINE )  ;", "search 5  . setScript (  \"  {  {  !    ignore   me    }  }  {  \\  \" query \\  \"  :  {  \\  \" terms \\  \"  :  {  \\  \" group \\  \"  :  [  {  {  # groups }  }  {  {  .  }  }  ,  {  {  / groups }  }  ]  }  }  }  \"  )  ;", "search 5  . setSimulate ( true )  ;", "Map < String ,    Object >    params 5     =    new   HashMap <  >  (  )  ;", "params 5  . put (  \" groups \"  ,    Arrays . asList (  1  ,     2  ,     3  )  )  ;", "search 5  . setScriptParams ( params 5  )  ;", "multiRequest . add ( search 5  )  ;", "Response   response    =    client (  )  . execute ( Action . INSTANCE ,    multiRequest )  . get (  )  ;", "assertThat ( response . getResponses (  )  ,    arrayWithSize (  5  )  )  ;", "Response . Item   response 1     =    response . getResponses (  )  [  0  ]  ;", "assertThat ( response 1  . isFailure (  )  ,    is ( false )  )  ;", "SearchTemplateResponse   searchTemplateResponse 1     =    response 1  . getResponse (  )  ;", "assertThat ( searchTemplateResponse 1  . hasResponse (  )  ,    is ( true )  )  ;", "assertHitCount ( searchTemplateResponse 1  . getResponse (  )  ,     (  ( numDocs    /     2  )     +     ( numDocs    %     2  )  )  )  ;", "assertThat ( searchTemplateResponse 1  . getSource (  )  . utf 8 ToString (  )  ,    equalTo (  \"  {  \\  \" query \\  \"  :  {  \\  \" match \\  \"  :  {  \\  \" odd \\  \"  :  \\  \" true \\  \"  }  }  }  \"  )  )  ;", "Response . Item   response 2     =    response . getResponses (  )  [  1  ]  ;", "assertThat ( response 2  . isFailure (  )  ,    is ( false )  )  ;", "SearchTemplateResponse   searchTemplateResponse 2     =    response 2  . getResponse (  )  ;", "assertThat ( searchTemplateResponse 2  . hasResponse (  )  ,    is ( false )  )  ;", "assertThat ( searchTemplateResponse 2  . getSource (  )  . utf 8 ToString (  )  ,    equalTo (  \"  {  \\  \" query \\  \"  :  {  \\  \" match _ phrase _ prefix \\  \"  :  {  \\  \" message \\  \"  :  \\  \" quick   brown   f \\  \"  }  }  }  \"  )  )  ;", "Response . Item   response 3     =    response . getResponses (  )  [  2  ]  ;", "assertThat ( response 3  . isFailure (  )  ,    is ( false )  )  ;", "SearchTemplateResponse   searchTemplateResponse 3     =    response 3  . getResponse (  )  ;", "assertThat ( searchTemplateResponse 3  . hasResponse (  )  ,    is ( true )  )  ;", "assertHitCount ( searchTemplateResponse 3  . getResponse (  )  ,     ( numDocs    /     2  )  )  ;", "assertThat ( searchTemplateResponse 3  . getSource (  )  . utf 8 ToString (  )  ,    equalTo (  \"  {  \\  \" query \\  \"  :  {  \\  \" term \\  \"  :  {  \\  \" odd \\  \"  :  \\  \" false \\  \"  }  }  }  \"  )  )  ;", "Response . Item   response 4     =    response . getResponses (  )  [  3  ]  ;", "assertThat ( response 4  . isFailure (  )  ,    is ( true )  )  ;", "assertThat ( response 4  . getFailure (  )  ,    instanceOf ( IndexNotFoundException . class )  )  ;", "assertThat ( response 4  . getFailure (  )  . getMessage (  )  ,    equalTo (  \" no   such   index \"  )  )  ;", "Response . Item   response 5     =    response . getResponses (  )  [  4  ]  ;", "assertThat ( response 5  . isFailure (  )  ,    is ( false )  )  ;", "SearchTemplateResponse   searchTemplateResponse 5     =    response 5  . getResponse (  )  ;", "assertThat ( searchTemplateResponse 5  . hasResponse (  )  ,    is ( false )  )  ;", "assertThat ( searchTemplateResponse 5  . getSource (  )  . utf 8 ToString (  )  ,    equalTo (  \"  {  \\  \" query \\  \"  :  {  \\  \" terms \\  \"  :  {  \\  \" group \\  \"  :  [  1  ,  2  ,  3  ,  ]  }  }  }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasic"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "requests . add ( request )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "requests . add ( request . request (  )  )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "return   indicesOptions ;", "}", "METHOD_END"], "methodName": ["indicesOptions"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "this . indicesOptions    =    indicesOptions ;", "return   this ;", "}", "METHOD_END"], "methodName": ["indicesOptions"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "return   maxConcurrentSearchRequests ;", "}", "METHOD_END"], "methodName": ["maxConcurrentSearchRequests"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "if    ( maxConcurrentSearchRequests    <     1  )     {", "throw   new   IllegalArgumentException (  \" maxConcurrentSearchRequests   must   be   positive \"  )  ;", "}", "this . maxConcurrentSearchRequests    =    maxConcurrentSearchRequests ;", "return   this ;", "}", "METHOD_END"], "methodName": ["maxConcurrentSearchRequests"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "return   this . requests ;", "}", "METHOD_END"], "methodName": ["requests"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( request . getRequest (  )  . indicesOptions (  )  )     =  =     ( IndicesOptions . strictExpandOpenAndForbidClosed (  )  )  )     &  &     (  ( request (  )  . indicesOptions (  )  )     !  =     ( IndicesOptions . strictExpandOpenAndForbidClosed (  )  )  )  )     {", "request . getRequest (  )  . indicesOptions ( request (  )  . indicesOptions (  )  )  ;", "}", "super . request . add ( request )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( request . request (  )  . getRequest (  )  . indicesOptions (  )  )     =  =     ( IndicesOptions . strictExpandOpenAndForbidClosed (  )  )  )     &  &     (  ( request (  )  . indicesOptions (  )  )     !  =     ( IndicesOptions . strictExpandOpenAndForbidClosed (  )  )  )  )     {", "request . request (  )  . getRequest (  )  . indicesOptions ( request (  )  . indicesOptions (  )  )  ;", "}", "super . request . add ( request )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "request (  )  . indicesOptions ( indicesOptions )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setIndicesOptions"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "request (  )  . maxConcurrentSearchRequests ( maxConcurrentSearchRequests )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setMaxConcurrentSearchRequests"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "MultiSearchTemplateRequest   request    =    new   MultiSearchTemplateRequest (  )  ;", "request . maxConcurrentSearchRequests ( randomIntBetween (  1  ,    Integer . MAX _ VALUE )  )  ;", "expectThrows ( IllegalArgumentException . class ,     (  )     -  >    request . maxConcurrentSearchRequests ( randomIntBetween ( Integer . MIN _ VALUE ,     0  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testMaxConcurrentSearchRequests"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "byte [  ]    data    =    StreamsUtils . copyToBytesFromClasspath (  \"  / org / elasticsearch / script / mustache / simple - msearch - template . json \"  )  ;", "RestRequest   restRequest    =    new   Builder ( xContentRegistry (  )  )  . withContent ( new   BytesArray ( data )  ,    JSON )  . build (  )  ;", "request    =    RestMultiSearchTemplateAction . parseRequest ( restRequest ,    true )  ;", "assertThat ( request . requests (  )  . size (  )  ,    equalTo (  3  )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . indices (  )  [  0  ]  ,    equalTo (  \" test 0  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . indices (  )  [  1  ]  ,    equalTo (  \" test 1  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . indices (  )  ,    arrayContaining (  \" test 0  \"  ,     \" test 1  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . requestCache (  )  ,    equalTo ( true )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . preference (  )  ,    nullValue (  )  )  ;", "assertThat ( request . requests (  )  . get (  1  )  . getRequest (  )  . indices (  )  [  0  ]  ,    equalTo (  \" test 2  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  1  )  . getRequest (  )  . indices (  )  [  1  ]  ,    equalTo (  \" test 3  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  1  )  . getRequest (  )  . types (  )  [  0  ]  ,    equalTo (  \" type 1  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  1  )  . getRequest (  )  . requestCache (  )  ,    nullValue (  )  )  ;", "assertThat ( request . requests (  )  . get (  1  )  . getRequest (  )  . preference (  )  ,    equalTo (  \"  _ local \"  )  )  ;", "assertThat ( request . requests (  )  . get (  2  )  . getRequest (  )  . indices (  )  [  0  ]  ,    equalTo (  \" test 4  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  2  )  . getRequest (  )  . indices (  )  [  1  ]  ,    equalTo (  \" test 1  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  2  )  . getRequest (  )  . types (  )  [  0  ]  ,    equalTo (  \" type 2  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  2  )  . getRequest (  )  . types (  )  [  1  ]  ,    equalTo (  \" type 1  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  2  )  . getRequest (  )  . routing (  )  ,    equalTo (  \"  1  2  3  \"  )  )  ;", "assertNotNull ( request . requests (  )  . get (  0  )  . getScript (  )  )  ;", "assertNotNull ( request . requests (  )  . get (  1  )  . getScript (  )  )  ;", "assertNotNull ( request . requests (  )  . get (  2  )  . getScript (  )  )  ;", "assertEquals ( INLINE ,    request . requests (  )  . get (  0  )  . getScriptType (  )  )  ;", "assertEquals ( INLINE ,    request . requests (  )  . get (  1  )  . getScriptType (  )  )  ;", "assertEquals ( INLINE ,    request . requests (  )  . get (  2  )  . getScriptType (  )  )  ;", "assertEquals (  \"  {  \\  \" query \\  \"  :  {  \\  \" match _  {  { template }  }  \\  \"  :  {  }  }  }  \"  ,    request . requests (  )  . get (  0  )  . getScript (  )  )  ;", "assertEquals (  \"  {  \\  \" query \\  \"  :  {  \\  \" match _  {  { template }  }  \\  \"  :  {  }  }  }  \"  ,    request . requests (  )  . get (  1  )  . getScript (  )  )  ;", "assertEquals (  \"  {  \\  \" query \\  \"  :  {  \\  \" match _  {  { template }  }  \\  \"  :  {  }  }  }  \"  ,    request . requests (  )  . get (  2  )  . getScript (  )  )  ;", "assertEquals (  1  ,    request . requests (  )  . get (  0  )  . getScriptParams (  )  . size (  )  )  ;", "assertEquals (  1  ,    request . requests (  )  . get (  1  )  . getScriptParams (  )  . size (  )  )  ;", "assertEquals (  1  ,    request . requests (  )  . get (  2  )  . getScriptParams (  )  . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseRequest"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "final   String   content    =     \"  {  \\  \" index \\  \"  :  [  \\  \" test 0  \\  \"  ,     \\  \" test 1  \\  \"  ]  ,     \\  \" request _ cache \\  \"  :    true }  \\ r \\ n \"     +     \"  {  \\  \" source \\  \"  :     {  \\  \" query \\  \"     :     {  \\  \" match _  {  { template }  }  \\  \"     :  {  }  }  }  ,     \\  \" params \\  \"  :     {  \\  \" template \\  \"  :     \\  \" all \\  \"     }     }  \\ r \\ n \"  ;", "RestRequest   restRequest    =    new   Builder ( xContentRegistry (  )  )  . withContent ( new   BytesArray ( content )  ,    JSON )  . build (  )  ;", "request    =    RestMultiSearchTemplateAction . parseRequest ( restRequest ,    true )  ;", "assertThat ( request . requests (  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . indices (  )  [  0  ]  ,    equalTo (  \" test 0  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . indices (  )  [  1  ]  ,    equalTo (  \" test 1  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . indices (  )  ,    arrayContaining (  \" test 0  \"  ,     \" test 1  \"  )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . requestCache (  )  ,    equalTo ( true )  )  ;", "assertThat ( request . requests (  )  . get (  0  )  . getRequest (  )  . preference (  )  ,    nullValue (  )  )  ;", "assertNotNull ( request . requests (  )  . get (  0  )  . getScript (  )  )  ;", "assertEquals ( INLINE ,    request . requests (  )  . get (  0  )  . getScriptType (  )  )  ;", "assertEquals (  \"  {  \\  \" query \\  \"  :  {  \\  \" match _  {  { template }  }  \\  \"  :  {  }  }  }  \"  ,    request . requests (  )  . get (  0  )  . getScript (  )  )  ;", "assertEquals (  1  ,    request . requests (  )  . get (  0  )  . getScriptParams (  )  . size (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseWithCarriageReturn"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "return   this . items ;", "}", "METHOD_END"], "methodName": ["getResponses"], "fileName": "org.elasticsearch.script.mustache.MultiSearchTemplateResponse"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( options    =  =    null )     |  |     ( options . isEmpty (  )  )  )     |  |     (  ( options . containsKey ( CONTENT _ TYPE _ OPTION )  )     =  =    false )  )     {", "return   new   CustomFactory (  )  ;", "}", "return   new   CustomFactory ( options . get ( CONTENT _ TYPE _ OPTION )  )  ;", "}", "METHOD_END"], "methodName": ["createMustacheFactory"], "fileName": "org.elasticsearch.script.mustache.MustacheScriptEngine"}, {"methodBody": ["METHOD_START", "{", "String   string    =    randomRealisticUnicodeOfCodepointLengthBetween (  0  ,     1  0  )  ;", "for    ( int   i    =     0  ;    i    <     ( string . length (  )  )  ;    i +  +  )     {", "if    (  . isEscapeChar ( string . charAt ( i )  )  )     {", "return   string . substring (  0  ,    i )  ;", "}", "}", "return   string ;", "}", "METHOD_END"], "methodName": ["getChars"], "fileName": "org.elasticsearch.script.mustache.MustacheScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "switch    ( c )     {", "case    '  \"  '     :", "case    '  \\  \\  '     :", "return   true ;", "}", "if    ( c    <     '  /  '  )", "return   true ;", "return   false ;", "}", "METHOD_END"], "methodName": ["isEscapeChar"], "fileName": "org.elasticsearch.script.mustache.MustacheScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "qe    =    new   MustacheScriptEngine (  )  ;", "factory    =    new   CustomMustacheFactory (  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.script.mustache.MustacheScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "{", "StringWriter   writer    =    new   StringWriter (  )  ;", "factory . encode (  \" hello    \\ n   world \"  ,    writer )  ;", "assertThat ( writer . toString (  )  ,    equalTo (  \" hello    \\  \\ n   world \"  )  )  ;", "}", "{", "StringWriter   writer    =    new   StringWriter (  )  ;", "factory . encode (  \"  \\ n \"  ,    writer )  ;", "assertThat ( writer . toString (  )  ,    equalTo (  \"  \\  \\ n \"  )  )  ;", "}", "Character [  ]    specialChars    =    new   Character [  ]  {     '  \\  \"  '  ,     '  \\  \\  '  ,     '  \\ u 0  0  0  0  '  ,     '  \\ u 0  0  0  1  '  ,     '  \\ u 0  0  0  2  '  ,     '  \\ u 0  0  0  3  '  ,     '  \\ u 0  0  0  4  '  ,     '  \\ u 0  0  0  5  '  ,     '  \\ u 0  0  0  6  '  ,     '  \\ u 0  0  0  7  '  ,     '  \\ b '  ,     '  \\ t '  ,     '  \\ u 0  0  0 b '  ,     '  \\ f '  ,     '  \\ u 0  0  0 e '  ,     '  \\ u 0  0  0 f '  ,     '  \\ u 0  0  1 f '     }  ;", "String [  ]    escapedChars    =    new   String [  ]  {     \"  \\  \\  \\  \"  \"  ,     \"  \\  \\  \\  \\  \"  ,     \"  \\  \\ u 0  0  0  0  \"  ,     \"  \\  \\ u 0  0  0  1  \"  ,     \"  \\  \\ u 0  0  0  2  \"  ,     \"  \\  \\ u 0  0  0  3  \"  ,     \"  \\  \\ u 0  0  0  4  \"  ,     \"  \\  \\ u 0  0  0  5  \"  ,     \"  \\  \\ u 0  0  0  6  \"  ,     \"  \\  \\ u 0  0  0  7  \"  ,     \"  \\  \\ u 0  0  0  8  \"  ,     \"  \\  \\ u 0  0  0  9  \"  ,     \"  \\  \\ u 0  0  0 B \"  ,     \"  \\  \\ u 0  0  0 C \"  ,     \"  \\  \\ u 0  0  0 E \"  ,     \"  \\  \\ u 0  0  0 F \"  ,     \"  \\  \\ u 0  0  1 F \"     }  ;", "int   iters    =    scaledRandomIntBetween (  1  0  0  ,     1  0  0  0  )  ;", "for    ( int   i    =     0  ;    i    <    iters ;    i +  +  )     {", "int   rounds    =    scaledRandomIntBetween (  1  ,     2  0  )  ;", "StringWriter   expect    =    new   StringWriter (  )  ;", "StringWriter   writer    =    new   StringWriter (  )  ;", "for    ( int   j    =     0  ;    j    <    rounds ;    j +  +  )     {", "String   s    =    getChars (  )  ;", "writer . write ( s )  ;", "expect . write ( s )  ;", "int   charIndex    =    randomInt (  7  )  ;", "writer . append ( specialChars [ charIndex ]  )  ;", "expect . append ( escapedChars [ charIndex ]  )  ;", "}", "StringWriter   target    =    new   StringWriter (  )  ;", "factory . encode ( writer . toString (  )  ,    target )  ;", "assertThat ( expect . toString (  )  ,    equalTo ( target . toString (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testEscapeJson"], "fileName": "org.elasticsearch.script.mustache.MustacheScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "String   templateString    =     \"  {  \"     +     (  (  (  (  (  \"        \\  \" source \\  \"     :     \\  \"  {     \\  \\  \\  \" match _  {  {  # use _ it }  }  {  { template }  }  {  {  / use _ it }  }  \\  \\  \\  \"  :  {  }     }  \\  \"  ,  \"     +     \"        \\  \" params \\  \"  :  {  \"  )     +     \"              \\  \" template \\  \"  :  \\  \" all \\  \"  ,  \"  )     +     \"              \\  \" use _ it \\  \"  :    true \"  )     +     \"        }  \"  )     +     \"  }  \"  )  ;", "XContentParser   parser    =    createParser ( jsonXContent ,    templateString )  ;", "Script    =    Script . parse ( parser )  ;", "TemplateScript . Factory   compiled    =    qe . compile ( null ,    getIdOrCode (  )  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "TemplateScript   TemplateScript    =    compiled . newInstance ( getParams (  )  )  ;", "assertThat ( TemplateScript . execute (  )  ,    equalTo (  \"  {     \\  \" match _ all \\  \"  :  {  }     }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseTemplateAsSingleStringWithConditionalClause"], "fileName": "org.elasticsearch.script.mustache.MustacheScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "String   templateString    =     \"  {  \"     +     (  (  \"  \\  \" source \\  \"  :  {  \\  \" match _  {  { template }  }  \\  \"  :     {  }  }  ,  \"     +     \"  \\  \" params \\  \"  :  {  \\  \" template \\  \"  :  \\  \" all \\  \"  }  \"  )     +     \"  }  \"  )  ;", "XContentParser   parser    =    createParser ( jsonXContent ,    templateString )  ;", "Script    =    Script . parse ( parser )  ;", "TemplateScript . Factory   compiled    =    qe . compile ( null ,    getIdOrCode (  )  ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "TemplateScript   TemplateScript    =    compiled . newInstance ( getParams (  )  )  ;", "assertThat ( TemplateScript . execute (  )  ,    equalTo (  \"  {  \\  \" match _ all \\  \"  :  {  }  }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimple"], "fileName": "org.elasticsearch.script.mustache.MustacheScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    compileParams    =    Collections . singletonMap (  \" content _ type \"  ,     \" application / json \"  )  ;", "{", "String   template    =     \" GET    _     {  \\  \" query \\  \"  :     \"     +     (  (  (  \"  {  \\  \" boosting \\  \"  :     {  \"     +     \"  \\  \" positive \\  \"  :     {  \\  \" match \\  \"  :     {  \\  \" body \\  \"  :     \\  \" gift \\  \"  }  }  ,  \"  )     +     \"  \\  \" negative \\  \"  :     {  \\  \" term \\  \"  :     {  \\  \" body \\  \"  :     {  \\  \" value \\  \"  :     \\  \" solr \\  \"  }  \"  )     +     \"  }  }  ,     \\  \" negative _ boost \\  \"  :     {  { boost _ val }  }     }     }  }  \"  )  ;", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "vars . put (  \" boost _ val \"  ,     \"  0  .  3  \"  )  ;", "String   o    =    qe . compile ( null ,    template ,    CONTEXT ,    compileParams )  . newInstance ( vars )  . execute (  )  ;", "assertEquals (  (  \" GET    _     {  \\  \" query \\  \"  :     {  \\  \" boosting \\  \"  :     {  \\  \" positive \\  \"  :     {  \\  \" match \\  \"  :     {  \\  \" body \\  \"  :     \\  \" gift \\  \"  }  }  ,  \"     +     \"  \\  \" negative \\  \"  :     {  \\  \" term \\  \"  :     {  \\  \" body \\  \"  :     {  \\  \" value \\  \"  :     \\  \" solr \\  \"  }  }  }  ,     \\  \" negative _ boost \\  \"  :     0  .  3     }     }  }  \"  )  ,    o )  ;", "}", "{", "String   template    =     \" GET    _     {  \\  \" query \\  \"  :     \"     +     (  (  (  \"  {  \\  \" boosting \\  \"  :     {  \"     +     \"  \\  \" positive \\  \"  :     {  \\  \" match \\  \"  :     {  \\  \" body \\  \"  :     \\  \" gift \\  \"  }  }  ,  \"  )     +     \"  \\  \" negative \\  \"  :     {  \\  \" term \\  \"  :     {  \\  \" body \\  \"  :     {  \\  \" value \\  \"  :     \\  \"  {  { body _ val }  }  \\  \"  }  \"  )     +     \"  }  }  ,     \\  \" negative _ boost \\  \"  :     {  { boost _ val }  }     }     }  }  \"  )  ;", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "vars . put (  \" boost _ val \"  ,     \"  0  .  3  \"  )  ;", "vars . put (  \" body _ val \"  ,     \"  \\  \" quick   brown \\  \"  \"  )  ;", "String   o    =    qe . compile ( null ,    template ,    CONTEXT ,    compileParams )  . newInstance ( vars )  . execute (  )  ;", "assertEquals (  (  \" GET    _     {  \\  \" query \\  \"  :     {  \\  \" boosting \\  \"  :     {  \\  \" positive \\  \"  :     {  \\  \" match \\  \"  :     {  \\  \" body \\  \"  :     \\  \" gift \\  \"  }  }  ,  \"     +     \"  \\  \" negative \\  \"  :     {  \\  \" term \\  \"  :     {  \\  \" body \\  \"  :     {  \\  \" value \\  \"  :     \\  \"  \\  \\  \\  \" quick   brown \\  \\  \\  \"  \\  \"  }  }  }  ,     \\  \" negative _ boost \\  \"  :     0  .  3     }     }  }  \"  )  ,    o )  ;", "}", "}", "METHOD_END"], "methodName": ["testSimpleParameterReplace"], "fileName": "org.elasticsearch.script.mustache.MustacheScriptEngineTests"}, {"methodBody": ["METHOD_START", "{", "String   result    =    compile ( script )  . newInstance ( vars )  . execute (  )  ;", "assertThat ( result ,    matcher )  ;", "}", "METHOD_END"], "methodName": ["assertScript"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "assertThat (  \" cannot   compile   null   or   empty   script \"  ,    script ,    not ( isEmptyOrNullString (  )  )  )  ;", "return   engine . compile ( null ,    script ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "}", "METHOD_END"], "methodName": ["compile"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "String   template    =     \"  {  { data .  0  }  }     {  { data .  1  }  }  \"  ;", "TemplateSFactory   factory    =    engine . compile ( null ,    template ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "Object   data    =    randomFrom ( new   String [  ]  {     \" foo \"  ,     \" bar \"     }  ,    Arrays . asList (  \" foo \"  ,     \" bar \"  )  )  ;", "vars . put (  \" data \"  ,    data )  ;", "assertThat ( factory . newInstance ( vars )  . execute (  )  ,    equalTo (  \" foo   bar \"  )  )  ;", "Set < String >    setData    =    new   HashSet <  >  (  )  ;", "setData . add (  \" foo \"  )  ;", "setData . add (  \" bar \"  )  ;", "vars . put (  \" data \"  ,    setData )  ;", "String   output    =    factory . newInstance ( vars )  . execute (  )  ;", "assertThat ( output ,    both ( containsString (  \" foo \"  )  )  . and ( containsString (  \" bar \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testArrayAccess"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "String   template    =     \"  {  { data .  0  .  0  }  }     {  { data .  0  .  1  }  }  \"  ;", "TemplateSFactory   factory    =    engine . compile ( null ,    template ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "Object   data    =    randomFrom ( new   String [  ]  [  ]  {    new   String [  ]  {     \" foo \"  ,     \" bar \"     }     }  ,    Collections . singletonList ( new   String [  ]  {     \" foo \"  ,     \" bar \"     }  )  ,    Collections . singleton ( new   String [  ]  {     \" foo \"  ,     \" bar \"     }  )  )  ;", "vars . put (  \" data \"  ,    data )  ;", "assertThat ( factory . newInstance ( vars )  . execute (  )  ,    equalTo (  \" foo   bar \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testArrayInArrayAccess"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "String   template    =     \" GET    _ search    {  \\  \" query \\  \"  :     \"     +     (  (  (  \"  {  \\  \" boosting \\  \"  :     {  \"     +     \"  \\  \" positive \\  \"  :     {  \\  \" match \\  \"  :     {  \\  \" body \\  \"  :     \\  \" gift \\  \"  }  }  ,  \"  )     +     \"  \\  \" negative \\  \"  :     {  \\  \" term \\  \"  :     {  \\  \" body \\  \"  :     {  \\  \" value \\  \"  :     \\  \" solr \\  \"  }  \"  )     +     \"  }  }  ,     \\  \" negative _ boost \\  \"  :     {  { boost _ val }  }     }     }  }  \"  )  ;", "Map < String ,    Object >    params    =    Collections . singletonMap (  \" boost _ val \"  ,     \"  0  .  2  \"  )  ;", "TemplateScript . Factory   factory    =    engine . compile ( null ,    template ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "TemplateScript   result    =    factory . newInstance ( params )  ;", "assertEquals (  \"    templating   broken \"  ,     (  \" GET    _ search    {  \\  \" query \\  \"  :     {  \\  \" boosting \\  \"  :     {  \\  \" positive \\  \"  :     {  \\  \" match \\  \"  :     {  \\  \" body \\  \"  :     \\  \" gift \\  \"  }  }  ,  \"     +     \"  \\  \" negative \\  \"  :     {  \\  \" term \\  \"  :     {  \\  \" body \\  \"  :     {  \\  \" value \\  \"  :     \\  \" solr \\  \"  }  }  }  ,     \\  \" negative _ boost \\  \"  :     0  .  2     }     }  }  \"  )  ,    result . execute (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBasics"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   builder    =    jsonBuilder (  )  . startObject (  )  . startArray (  \" people \"  )  . startObject (  )  . field (  \" name \"  ,     \" John   Smith \"  )  . startArray (  \" emails \"  )  . value (  \" john @ smith . com \"  )  . value (  \" john . smith @ email . com \"  )  . value (  \" jsmith @ email . com \"  )  . endArray (  )  . endObject (  )  . startObject (  )  . field (  \" name \"  ,     \" John   Doe \"  )  . startArray (  \" emails \"  )  . value (  \" john @ doe . com \"  )  . value (  \" john . doe @ email . com \"  )  . value (  \" jdoe @ email . com \"  )  . endArray (  )  . endObject (  )  . endArray (  )  . endObject (  )  ;", "Map < String ,    Object >    ctx    =    Collections . singletonMap (  \" ctx \"  ,    XContentHelper . convertToMap ( BytesReference . bytes ( builder )  ,    false ,    builder . contentType (  )  )  . v 2  (  )  )  ;", "assertS (  \"  {  {  # join }  } ctx . people .  0  . emails {  {  / join }  }  \"  ,    ctx ,    equalTo (  \" john @ smith . com , john . smith @ email . com , jsmith @ email . com \"  )  )  ;", "assertS (  \"  {  {  # join }  } ctx . people .  1  . emails {  {  / join }  }  \"  ,    ctx ,    equalTo (  \" john @ doe . com , john . doe @ email . com , jdoe @ email . com \"  )  )  ;", "assertS (  \"  {  {  # ctx . people }  } to :     {  {  # join }  } emails {  {  / join }  }  ;  {  {  / ctx . people }  }  \"  ,    ctx ,    equalTo (  \" to :    john @ smith . com , john . smith @ email . com , jsmith @ email . com ; to :    john @ doe . com , john . doe @ email . com , jdoe @ email . com ;  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmbeddedArrayJoin"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   builder    =    jsonBuilder (  )  . startObject (  )  . startArray (  \" bulks \"  )  . startObject (  )  . field (  \" index \"  ,     \" index -  1  \"  )  . field (  \" type \"  ,     \" type -  1  \"  )  . field (  \" id \"  ,     1  )  . endObject (  )  . startObject (  )  . field (  \" index \"  ,     \" index -  2  \"  )  . field (  \" type \"  ,     \" type -  2  \"  )  . field (  \" id \"  ,     2  )  . endObject (  )  . endArray (  )  . endObject (  )  ;", "Map < String ,    Object >    ctx    =    Collections . singletonMap (  \" ctx \"  ,    XContentHelper . convertToMap ( BytesReference . bytes ( builder )  ,    false ,    builder . contentType (  )  )  . v 2  (  )  )  ;", "assertS (  \"  {  {  # ctx . bulks }  }  {  {  # toJson }  }  .  {  {  / toJson }  }  {  {  / ctx . bulks }  }  \"  ,    ctx ,    equalTo (  \"  {  \\  \" index \\  \"  :  \\  \" index -  1  \\  \"  ,  \\  \" id \\  \"  :  1  ,  \\  \" type \\  \"  :  \\  \" type -  1  \\  \"  }  {  \\  \" index \\  \"  :  \\  \" index -  2  \\  \"  ,  \\  \" id \\  \"  :  2  ,  \\  \" type \\  \"  :  \\  \" type -  2  \\  \"  }  \"  )  )  ;", "assertS (  \"  {  {  # ctx . bulks }  }  <  {  {  # toJson }  } id {  {  / toJson }  }  >  {  {  / ctx . bulks }  }  \"  ,    ctx ,    equalTo (  \"  <  1  >  <  2  >  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testEmbeddedToJSON"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    params    =    Collections . singletonMap (  \" params \"  ,    Arrays . asList (  1  ,     2  ,     3  ,     4  )  )  ;", "assertS (  \"  {  {  # join   delimiter =  '  '  }  } params {  {  / join   delimiter =  '  '  }  }  \"  ,    params ,    equalTo (  \"  1  2  3  4  \"  )  )  ;", "assertS (  \"  {  {  # join   delimiter =  '  ,  '  }  } params {  {  / join   delimiter =  '  ,  '  }  }  \"  ,    params ,    equalTo (  \"  1  ,  2  ,  3  ,  4  \"  )  )  ;", "assertS (  \"  {  {  # join   delimiter =  '  /  '  }  } params {  {  / join   delimiter =  '  /  '  }  }  \"  ,    params ,    equalTo (  \"  1  /  2  /  3  /  4  \"  )  )  ;", "assertS (  \"  {  {  # join   delimiter =  '    and    '  }  } params {  {  / join   delimiter =  '    and    '  }  }  \"  ,    params ,    equalTo (  \"  1    and    2    and    3    and    4  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testJoinWithCustomDelimiter"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    params    =    Collections . singletonMap (  \" terms \"  ,    Arrays . asList ( Collections . singletonMap (  \" term \"  ,     \" foo \"  )  ,    Collections . singletonMap (  \" term \"  ,     \" bar \"  )  )  )  ;", "assertS (  \"  {  {  # join }  }  {  {  # toJson }  } terms {  {  / toJson }  }  {  {  / join }  }  \"  ,    params ,    equalTo (  \"  [  {  \\  \" term \\  \"  :  \\  \" foo \\  \"  }  ,  {  \\  \" term \\  \"  :  \\  \" bar \\  \"  }  ]  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testJoinWithToJson"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "String   template    =     \"  {  { data .  0  . key }  }     {  { data .  1  . key }  }  \"  ;", "TemplateSFactory   factory    =    engine . compile ( null ,    template ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "Object   data    =    randomFrom ( new   Object [  ]  {    Collections . singletonMap (  \" key \"  ,     \" foo \"  )  ,    Collections . singletonMap (  \" key \"  ,     \" bar \"  )     }  ,    Arrays . asList ( Collections . singletonMap (  \" key \"  ,     \" foo \"  )  ,    Collections . singletonMap (  \" key \"  ,     \" bar \"  )  )  )  ;", "vars . put (  \" data \"  ,    data )  ;", "assertThat ( factory . newInstance ( vars )  . execute (  )  ,    equalTo (  \" foo   bar \"  )  )  ;", "Set < Object >    setData    =    new   HashSet <  >  (  )  ;", "setData . add ( Collections . singletonMap (  \" key \"  ,     \" foo \"  )  )  ;", "setData . add ( Collections . singletonMap (  \" key \"  ,     \" bar \"  )  )  ;", "vars . put (  \" data \"  ,    setData )  ;", "String   output    =    factory . newInstance ( vars )  . execute (  )  ;", "assertThat ( output ,    both ( containsString (  \" foo \"  )  )  . and ( containsString (  \" bar \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testMapInArrayAccess"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    human 0     =    new   HashMap <  >  (  )  ;", "human 0  . put (  \" age \"  ,     4  2  )  ;", "human 0  . put (  \" name \"  ,     \" John   Smith \"  )  ;", "human 0  . put (  \" height \"  ,     1  .  8  4  )  ;", "Map < String ,    Object >    human 1     =    new   HashMap <  >  (  )  ;", "human 1  . put (  \" age \"  ,     2  7  )  ;", "human 1  . put (  \" name \"  ,     \" Dave   Smith \"  )  ;", "human 1  . put (  \" height \"  ,     1  .  7  1  )  ;", "Map < String ,    Object >    humans    =    new   HashMap <  >  (  )  ;", "humans . put (  \" first \"  ,    human 0  )  ;", "humans . put (  \" second \"  ,    human 1  )  ;", "Map < String ,    Object >    ctx    =    Collections . singletonMap (  \" ctx \"  ,    humans )  ;", "assertS (  \"  {  {  # toJson }  }  .  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  (  \"  {  \\  \" ctx \\  \"  :  {  \\  \" first \\  \"  :  {  \\  \" name \\  \"  :  \\  \" John   Smith \\  \"  ,  \\  \" age \\  \"  :  4  2  ,  \\  \" height \\  \"  :  1  .  8  4  }  ,  \\  \" second \\  \"  :  \"     +     \"  {  \\  \" name \\  \"  :  \\  \" Dave   Smith \\  \"  ,  \\  \" age \\  \"  :  2  7  ,  \\  \" height \\  \"  :  1  .  7  1  }  }  }  \"  )  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  (  \"  {  \\  \" first \\  \"  :  {  \\  \" name \\  \"  :  \\  \" John   Smith \\  \"  ,  \\  \" age \\  \"  :  4  2  ,  \\  \" height \\  \"  :  1  .  8  4  }  ,  \\  \" second \\  \"  :  \"     +     \"  {  \\  \" name \\  \"  :  \\  \" Dave   Smith \\  \"  ,  \\  \" age \\  \"  :  2  7  ,  \\  \" height \\  \"  :  1  .  7  1  }  }  \"  )  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx . first {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  {  \\  \" name \\  \"  :  \\  \" John   Smith \\  \"  ,  \\  \" age \\  \"  :  4  2  ,  \\  \" height \\  \"  :  1  .  8  4  }  \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx . second {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  {  \\  \" name \\  \"  :  \\  \" Dave   Smith \\  \"  ,  \\  \" age \\  \"  :  2  7  ,  \\  \" height \\  \"  :  1  .  7  1  }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultipleMapsToJSON"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "String   template    =     \"  {  {  # toJson }  } ctx {  {  / toJson }  }  \"  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     \" value \"  )  ,    equalTo (  \" value \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     \"  \"  )  ,    equalTo (  \"  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,    true )  ,    equalTo (  \" true \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     4  2  )  ,    equalTo (  \"  4  2  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     4  2 L )  ,    equalTo (  \"  4  2  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     4  2  .  5 F )  ,    equalTo (  \"  4  2  .  5  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,    null )  ,    equalTo (  \"  \"  )  )  ;", "template    =     \"  {  {  # toJson }  }  .  {  {  / toJson }  }  \"  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     \" value \"  )  ,    equalTo (  \"  {  \\  \" ctx \\  \"  :  \\  \" value \\  \"  }  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     \"  \"  )  ,    equalTo (  \"  {  \\  \" ctx \\  \"  :  \\  \"  \\  \"  }  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,    true )  ,    equalTo (  \"  {  \\  \" ctx \\  \"  : true }  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     4  2  )  ,    equalTo (  \"  {  \\  \" ctx \\  \"  :  4  2  }  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     4  2 L )  ,    equalTo (  \"  {  \\  \" ctx \\  \"  :  4  2  }  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,     4  2  .  5 F )  ,    equalTo (  \"  {  \\  \" ctx \\  \"  :  4  2  .  5  }  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" ctx \"  ,    null )  ,    equalTo (  \"  {  \\  \" ctx \\  \"  : null }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testPrimitiveToJSON"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "String   template    =     \"  {  {  # join }  } array {  {  / join }  }  \"  ;", "assertS ( template ,    Collections . singletonMap (  \" array \"  ,    new   String [  ]  {     \" one \"  ,     \" two \"  ,     \" three \"     }  )  ,    equalTo (  \" one , two , three \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" array \"  ,    new   int [  ]  {     1  ,     2  ,     3     }  )  ,    equalTo (  \"  1  ,  2  ,  3  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" array \"  ,    new   long [  ]  {     1 L ,     2 L ,     3 L    }  )  ,    equalTo (  \"  1  ,  2  ,  3  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" array \"  ,    new   double [  ]  {     1  .  5  ,     2  .  5  ,     3  .  5     }  )  ,    equalTo (  \"  1  .  5  ,  2  .  5  ,  3  .  5  \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" array \"  ,    new   boolean [  ]  {    true ,    false ,    true    }  )  ,    equalTo (  \" true , false , true \"  )  )  ;", "assertS ( template ,    Collections . singletonMap (  \" array \"  ,    new   boolean [  ]  {    true ,    false ,    true    }  )  ,    equalTo (  \" true , false , true \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimpleArrayJoin"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "String [  ]    array    =    new   String [  ]  {     \" one \"  ,     \" two \"  ,     \" three \"     }  ;", "Map < String ,    Object >    ctx    =    Collections . singletonMap (  \" array \"  ,    array )  ;", "assertS (  \"  {  {  # toJson }  }  .  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  {  \\  \" array \\  \"  :  [  \\  \" one \\  \"  ,  \\  \" two \\  \"  ,  \\  \" three \\  \"  ]  }  \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } array {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  [  \\  \" one \\  \"  ,  \\  \" two \\  \"  ,  \\  \" three \\  \"  ]  \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } array .  0  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \" one \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } array .  1  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \" two \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } array .  2  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \" three \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } array . size {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  3  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimpleArrayToJSON"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "List < String >    list    =    Arrays . asList (  \" one \"  ,     \" two \"  ,     \" three \"  )  ;", "Map < String ,    Object >    ctx    =    Collections . singletonMap (  \" ctx \"  ,    list )  ;", "assertS (  \"  {  {  # toJson }  }  .  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  {  \\  \" ctx \\  \"  :  [  \\  \" one \\  \"  ,  \\  \" two \\  \"  ,  \\  \" three \\  \"  ]  }  \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  [  \\  \" one \\  \"  ,  \\  \" two \\  \"  ,  \\  \" three \\  \"  ]  \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx .  0  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \" one \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx .  1  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \" two \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx .  2  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \" three \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx . size {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  3  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimpleListToJSON"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    human 0     =    new   HashMap <  >  (  )  ;", "human 0  . put (  \" age \"  ,     4  2  )  ;", "human 0  . put (  \" name \"  ,     \" John   Smith \"  )  ;", "human 0  . put (  \" height \"  ,     1  .  8  4  )  ;", "Map < String ,    Object >    ctx    =    Collections . singletonMap (  \" ctx \"  ,    human 0  )  ;", "assertS (  \"  {  {  # toJson }  }  .  {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  {  \\  \" ctx \\  \"  :  {  \\  \" name \\  \"  :  \\  \" John   Smith \\  \"  ,  \\  \" age \\  \"  :  4  2  ,  \\  \" height \\  \"  :  1  .  8  4  }  }  \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \"  {  \\  \" name \\  \"  :  \\  \" John   Smith \\  \"  ,  \\  \" age \\  \"  :  4  2  ,  \\  \" height \\  \"  :  1  .  8  4  }  \"  )  )  ;", "assertS (  \"  {  {  # toJson }  } ctx . name {  {  / toJson }  }  \"  ,    ctx ,    equalTo (  \" John   Smith \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimpleMapToJSON"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "String [  ]    randomArrayValues    =    generateRandomStringArray (  1  0  ,     2  0  ,    false )  ;", "List < String >    randomList    =    Arrays . asList ( generateRandomStringArray (  1  0  ,     2  0  ,    false )  )  ;", "String   template    =     \"  {  { data . array . size }  }     {  { data . list . size }  }  \"  ;", "TemplateSFactory   factory    =    engine . compile ( null ,    template ,    CONTEXT ,    Collections . emptyMap (  )  )  ;", "Map < String ,    Object >    data    =    new   HashMap <  >  (  )  ;", "data . put (  \" array \"  ,    randomArrayValues )  ;", "data . put (  \" list \"  ,    randomList )  ;", "Map < String ,    Object >    vars    =    new   HashMap <  >  (  )  ;", "vars . put (  \" data \"  ,    data )  ;", "String   expectedString    =    String . format ( Locale . ROOT ,     \"  % s    % s \"  ,    randomArrayValues . length ,    randomList . size (  )  )  ;", "assertThat ( factory . newInstance ( vars )  . execute (  )  ,    equalTo ( expectedString )  )  ;", "}", "METHOD_END"], "methodName": ["testSizeAccessForCollectionsAndArrays"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    String >    urls    =    new   HashMap <  >  (  )  ;", "urls . put (  \" https :  /  / www . co \"  ,     \" https %  3 A %  2 F %  2 Fwww . co \"  )  ;", "urls . put (  \"  < logstash -  { now / d }  >  \"  ,     \"  %  3 Clogstash -  %  7 Bnow %  2 Fd %  7 D %  3 E \"  )  ;", "urls . put (  \"  ? query =  ( foo : A   OR   baz : B )    AND   title :  / joh ? n ( ath [ oa ] n )  /    AND   date :  {  *    TO    2  0  1  2  -  0  1  }  \"  ,     \"  %  3 Fquery %  3 D %  2  8 foo %  3 AA + OR + baz %  3 AB %  2  9  + AND + title %  3 A %  2 Fjoh %  3 Fn %  2  8 ath %  5 Boa %  5 Dn %  2  9  %  2 F + AND + date %  3 A %  7 B *  + TO +  2  0  1  2  -  0  1  %  7 D \"  )  ;", "for    ( Map . Entry < String ,    String >    url    :    urls . entrySet (  )  )     {", "assertScript (  \"  {  {  # url }  }  {  { params }  }  {  {  / url }  }  \"  ,    Collections . singletonMap (  \" params \"  ,    url . getKey (  )  )  ,    equalTo ( url . getValue (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testUrlEncoder"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    params    =    Collections . singletonMap (  \" emails \"  ,    Arrays . asList (  \" john @ smith . com \"  ,     \" john . smith @ email . com \"  ,     \" jsmith @ email . com \"  )  )  ;", "assertS (  \"  ? query =  {  {  # url }  }  {  {  # join }  } emails {  {  / join }  }  {  {  / url }  }  \"  ,    params ,    equalTo (  \"  ? query = john %  4  0 smith . com %  2 Cjohn . smith %  4  0 email . com %  2 Cjsmith %  4  0 email . com \"  )  )  ;", "params    =    Collections . singletonMap (  \" indices \"  ,    new   String [  ]  {     \"  < logstash -  { now / d -  2 d }  >  \"  ,     \"  < logstash -  { now / d -  1 d }  >  \"  ,     \"  < logstash -  { now / d }  >  \"     }  )  ;", "assertS (  \"  {  {  # url }  } https :  /  / localhost :  9  2  0  0  /  {  {  # join }  } indices {  {  / join }  }  /  _ stats {  {  / url }  }  \"  ,    params ,    equalTo (  (  \" https %  3 A %  2 F %  2 Flocalhost %  3 A 9  2  0  0  %  2 F %  3 Clogstash -  %  7 Bnow %  2 Fd -  2 d %  7 D \"     +     \"  %  3 E %  2 C %  3 Clogstash -  %  7 Bnow %  2 Fd -  1 d %  7 D %  3 E %  2 C %  3 Clogstash -  %  7 Bnow %  2 Fd %  7 D %  3 E %  2 F _ stats \"  )  )  )  ;", "params    =    Collections . singletonMap (  \" fibonacci \"  ,    new   int [  ]  {     1  ,     1  ,     2  ,     3  ,     5  ,     8  ,     1  3  ,     2  1  ,     3  4  ,     5  5     }  )  ;", "assertS (  \"  {  {  # url }  }  {  {  # join   delimiter =  '  +  '  }  } fibonacci {  {  / join   delimiter =  '  +  '  }  }  {  {  / url }  }  \"  ,    params ,    equalTo (  \"  1  %  2 B 1  %  2 B 2  %  2 B 3  %  2 B 5  %  2 B 8  %  2 B 1  3  %  2 B 2  1  %  2 B 3  4  %  2 B 5  5  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testUrlEncoderWithJoin"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "assertScript (  \"  {  {  # url }  }  {  { index }  }  {  {  / url }  }  \"  ,    Collections . singletonMap (  \" index \"  ,     \"  < logstash -  { now / d { YYYY . MM . dd |  +  1  2  :  0  0  }  }  >  \"  )  ,    equalTo (  \"  %  3 Clogstash -  %  7 Bnow %  2 Fd %  7 BYYYY . MM . dd %  7 C %  2 B 1  2  %  3 A 0  0  %  7 D %  7 D %  3 E \"  )  )  ;", "final   String   random    =    randomAlphaOfLength (  1  0  )  ;", "assertScript (  \"  {  {  # url }  } prefix _  {  { s }  }  {  {  / url }  }  \"  ,    Collections . singletonMap (  \" s \"  ,    random )  ,    equalTo (  (  \" prefix _  \"     +     ( URLEncoder . encode ( random ,    StandardCharsets . UTF _  8  . name (  )  )  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testUrlEncoderWithParam"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "MustacheException   e    =    expectThrows ( MustacheException . class ,     (  )     -  >    compile (  \"  {  {  # join }  }  {  {  / join }  }  \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" Mustache   function    [ join ]    must   contain   one   and   only   one   identifier \"  )  )  ;", "e    =    expectThrows ( MustacheException . class ,     (  )     -  >    compile (  \"  {  {  # join   delimiter =  ' a '  }  }  {  {  / join   delimiter =  ' b '  }  }  \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" Mismatched   start / end   tags \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testsUnsupportedTagsJoin"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "MustacheException   e    =    expectThrows ( MustacheException . class ,     (  )     -  >    compile (  \"  {  {  # toJson }  }  {  { foo }  }  {  { bar }  }  {  {  / toJson }  }  \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" Mustache   function    [ toJson ]    must   contain   one   and   only   one   identifier \"  )  )  ;", "e    =    expectThrows ( MustacheException . class ,     (  )     -  >    compile (  \"  {  {  # toJson }  }  {  {  / toJson }  }  \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" Mustache   function    [ toJson ]    must   contain   one   and   only   one   identifier \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testsUnsupportedTagsToJson"], "fileName": "org.elasticsearch.script.mustache.MustacheTests"}, {"methodBody": ["METHOD_START", "{", "MultiSearchTemplateRequest   multiRequest    =    new   MultiSearchTemplateRequest (  )  ;", "if    ( restRequest . hasParam (  \" max _ concurrent _ searches \"  )  )     {", "multiRequest . maxConcurrentSearchRequests ( restRequest . paramAsInt (  \" max _ concurrent _ searches \"  ,     0  )  )  ;", "}", "RestMultiSearchAction . parseMultiLineRequest ( restRequest ,    multiRequest . indicesOptions (  )  ,    allowExplicitIndex ,     (    searchRequest ,    bytes )     -  >     {", "SearchTemplateRequest   searchTemplateRequest    =    Rest . parse ( bytes )  ;", "if    (  ( searchTemplateRequest . getScript (  )  )     !  =    null )     {", "searchTemplateRequest . setRequest ( searchRequest )  ;", "multiRequest . add ( searchTemplateRequest )  ;", "} else    {", "throw   new   IllegalArgumentException (  \" Malformed   search   template \"  )  ;", "}", "}  )  ;", "return   multiRequest ;", "}", "METHOD_END"], "methodName": ["parseRequest"], "fileName": "org.elasticsearch.script.mustache.RestMultiSearchTemplateAction"}, {"methodBody": ["METHOD_START", "{", "return   RestSearchTemplateAction . PARSER . parse ( parser ,    new   SearchTemplateRequest (  )  ,    null )  ;", "}", "METHOD_END"], "methodName": ["parse"], "fileName": "org.elasticsearch.script.mustache.RestSearchTemplateAction"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" text \"  ,     \" value 1  \"  )  . endObject (  )  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" text \"  ,     \" value 2  \"  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \"  1 a \"  )  . setContent ( new   BytesArray (  (  \"  {  \"     +     (  (  (  (  (  (  \"  \\  \" template \\  \"  :  {  \"     +     \"                                                  \\  \" query \\  \"  :  {  \"  )     +     \"                                                           \\  \" match \\  \"  :  {  \"  )     +     \"                                                              \\  \" theField \\  \"     :     \\  \"  {  { fieldParam }  }  \\  \"  }  \"  )     +     \"                       }  \"  )     +     \"  }  \"  )     +     \"  }  \"  )  )  )  ,    JSON )  )  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \"  2  \"  )  . setContent ( new   BytesArray (  (  \"  {  \"     +     (  (  (  (  (  (  \"  \\  \" template \\  \"  :  {  \"     +     \"                                                  \\  \" query \\  \"  :  {  \"  )     +     \"                                                           \\  \" match \\  \"  :  {  \"  )     +     \"                                                              \\  \" theField \\  \"     :     \\  \"  {  { fieldParam }  }  \\  \"  }  \"  )     +     \"                       }  \"  )     +     \"  }  \"  )     +     \"  }  \"  )  )  )  ,    JSON )  )  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \"  3  \"  )  . setContent ( new   BytesArray (  (  \"  {  \"     +     (  (  (  (  \"  \\  \" template \\  \"  :  {  \"     +     \"                                         \\  \" match \\  \"  :  {  \"  )     +     \"                                                              \\  \" theField \\  \"     :     \\  \"  {  { fieldParam }  }  \\  \"  }  \"  )     +     \"                       }  \"  )     +     \"  }  \"  )  )  )  ,    JSON )  )  ;", "BulkRequestBuilder   bulkRequestBuilder    =    client (  )  . prepareBulk (  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo    2  \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo    3  \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  4  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo    4  \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  5  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" bar \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "Map < String ,    Object >    templateParams    =    new   HashMap <  >  (  )  ;", "templateParams . put (  \" fieldParam \"  ,     \" foo \"  )  ;", "Response   searchResponse    =    new   RequestBuilder ( client (  )  )  . setRequest ( new   SearchRequest (  )  . indices (  \" test \"  )  . types (  \" type \"  )  )  . setScript (  \"  1 a \"  )  . setScriptType ( STORED )  . setScriptParams ( templateParams )  . get (  )  ;", "assertHitCount ( searchResponse . getResponse (  )  ,     4  )  ;", "expectThrows ( ResourceNotFoundException . class ,     (  )     -  >    new   RequestBuilder ( client (  )  )  . setRequest ( new   SearchRequest (  )  . indices (  \" test \"  )  . types (  \" type \"  )  )  . setScript (  \"  1  0  0  0  \"  )  . setScriptType ( ScriptType . STORED )  . setScriptParams ( templateParams )  . get (  )  )  ;", "templateParams . put (  \" fieldParam \"  ,     \" bar \"  )  ;", "searchResponse    =    new   RequestBuilder ( client (  )  )  . setRequest ( new   SearchRequest (  \" test \"  )  . types (  \" type \"  )  )  . setScript (  \"  2  \"  )  . setScriptType ( STORED )  . setScriptParams ( templateParams )  . get (  )  ;", "assertHitCount ( searchResponse . getResponse (  )  ,     1  )  ;", "}", "METHOD_END"], "methodName": ["testIndexedTemplate"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \" testTemplate \"  )  . setContent ( new   BytesArray (  (  \"  {  \"     +     (  (  (  (  (  (  \"  \\  \" template \\  \"  :  {  \"     +     \"                                                  \\  \" query \\  \"  :  {  \"  )     +     \"                                                           \\  \" match \\  \"  :  {  \"  )     +     \"                                                              \\  \" theField \\  \"     :     \\  \"  {  { fieldParam }  }  \\  \"  }  \"  )     +     \"                       }  \"  )     +     \"  }  \"  )     +     \"  }  \"  )  )  )  ,    JSON )  )  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \" testTemplate \"  )  . setContent ( new   BytesArray (  (  \"  {  \"     +     (  (  (  (  (  (  \"  \\  \" template \\  \"  :  {  \"     +     \"                                                  \\  \" query \\  \"  :  {  \"  )     +     \"                                                           \\  \" match \\  \"  :  {  \"  )     +     \"                                                              \\  \" theField \\  \"     :     \\  \"  {  { fieldParam }  }  \\  \"  }  \"  )     +     \"                       }  \"  )     +     \"  }  \"  )     +     \"  }  \"  )  )  )  ,    JSON )  )  ;", "GetStoredScriptResponse   getResponse    =    client (  )  . admin (  )  . cluster (  )  . prepareGetStoredScript (  \" testTemplate \"  )  . get (  )  ;", "assertNotNull ( getResponse . getSource (  )  )  ;", "BulkRequestBuilder   bulkRequestBuilder    =    client (  )  . prepareBulk (  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo    2  \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo    3  \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  4  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo    4  \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  5  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" bar \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "Map < String ,    Object >    templateParams    =    new   HashMap <  >  (  )  ;", "templateParams . put (  \" fieldParam \"  ,     \" foo \"  )  ;", "Response   searchResponse    =    new   RequestBuilder ( client (  )  )  . setRequest ( new   SearchRequest (  \" test \"  )  . types (  \" type \"  )  )  . setScript (  \" testTemplate \"  )  . setScriptType ( STORED )  . setScriptParams ( templateParams )  . get (  )  ;", "assertHitCount ( searchResponse . getResponse (  )  ,     4  )  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . prepareDeleteStoredScript (  \" testTemplate \"  )  )  ;", "getResponse    =    client (  )  . admin (  )  . cluster (  )  . prepareGetStoredScript (  \" testTemplate \"  )  . get (  )  ;", "assertNull ( getResponse . getSource (  )  )  ;", "}", "METHOD_END"], "methodName": ["testIndexedTemplateClient"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" testindex \"  )  ;", "ensureGreen (  \" testindex \"  )  ;", "client (  )  . prepareIndex (  \" testindex \"  ,     \" test \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" searchtext \"  ,     \" dev 1  \"  )  . endObject (  )  )  . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "int   iterations    =    randomIntBetween (  2  ,     1  1  )  ;", "for    ( int   i    =     1  ;    i    <    iterations ;    i +  +  )     {", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \" git 0  1  \"  )  . setContent ( new   BytesArray (  (  \"  {  \\  \" template \\  \"  :  {  \\  \" query \\  \"  :     {  \\  \" match _ phrase _ prefix \\  \"  :     {  \\  \" searchtext \\  \"  :     {  \\  \" query \\  \"  :     \\  \"  {  { P _ Keyword 1  }  }  \\  \"  ,  \"     +     \"  \\  \" slop \\  \"  :     -  1  }  }  }  }  }  \"  )  )  ,    JSON )  )  ;", "GetStoredScriptResponse   getResponse    =    client (  )  . admin (  )  . cluster (  )  . prepareGetStoredScript (  \" git 0  1  \"  )  . get (  )  ;", "assertNotNull ( getResponse . getSource (  )  )  ;", "Map < String ,    Object >    templateParams    =    new   HashMap <  >  (  )  ;", "templateParams . put (  \" P _ Keyword 1  \"  ,     \" dev \"  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    new   RequestBuilder ( client (  )  )  . setRequest ( new   SearchRequest (  \" testindex \"  )  . types (  \" test \"  )  )  . setScript (  \" git 0  1  \"  )  . setScriptType ( ScriptType . STORED )  . setScriptParams ( templateParams )  . get (  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \" No   negative   slop   allowed \"  )  )  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \" git 0  1  \"  )  . setContent ( new   BytesArray (  (  \"  {  \\  \" query \\  \"  :     {  \\  \" match _ phrase _ prefix \\  \"  :     {  \\  \" searchtext \\  \"  :     {  \\  \" query \\  \"  :     \\  \"  {  { P _ Keyword 1  }  }  \\  \"  ,  \"     +     \"  \\  \" slop \\  \"  :     0  }  }  }  }  \"  )  )  ,    JSON )  )  ;", "Response   searchResponse    =    new   RequestBuilder ( client (  )  )  . setRequest ( new   SearchRequest (  \" testindex \"  )  . types (  \" test \"  )  )  . setScript (  \" git 0  1  \"  )  . setScriptType ( STORED )  . setScriptParams ( templateParams )  . get (  )  ;", "assertHitCount ( searchResponse . getResponse (  )  ,     1  )  ;", "}", "}", "METHOD_END"], "methodName": ["testIndexedTemplateOverwrite"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "String   multiQuery    =     \"  {  \\  \" query \\  \"  :  {  \\  \" terms \\  \"  :  {  \\  \" theField \\  \"  :  [  \\  \"  {  {  # fieldParam }  }  \\  \"  ,  \\  \"  {  {  .  }  }  \\  \"  ,  \\  \"  {  {  / fieldParam }  }  \\  \"  ]  }  }  }  \"  ;", "assertAcked ( client (  )  . admin (  )  . cluster (  )  . preparePutStoredScript (  )  . setId (  \"  4  \"  )  . setContent ( BytesReference . bytes ( jsonBuilder (  )  . startObject (  )  . field (  \" template \"  ,    multiQuery )  . endObject (  )  )  ,    JSON )  )  ;", "BulkRequestBuilder   bulkRequestBuilder    =    client (  )  . prepareBulk (  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  1  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  2  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo    2  \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  3  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo    3  \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  4  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" foo    4  \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . add ( client (  )  . prepareIndex (  \" test \"  ,     \" type \"  ,     \"  5  \"  )  . setSource (  \"  {  \\  \" theField \\  \"  :  \\  \" bar \\  \"  }  \"  ,    JSON )  )  ;", "bulkRequestBuilder . get (  )  ;", "client (  )  . admin (  )  . indices (  )  . prepareRefresh (  )  . get (  )  ;", "Map < String ,    Object >    arrayTemplateParams    =    new   HashMap <  >  (  )  ;", "String [  ]    fieldParams    =    new   String [  ]  {     \" foo \"  ,     \" bar \"     }  ;", "arrayTemplateParams . put (  \" fieldParam \"  ,    fieldParams )  ;", "Response   searchResponse    =    new   RequestBuilder ( client (  )  )  . setRequest ( new   SearchRequest (  \" test \"  )  . types (  \" type \"  )  )  . setScript (  \"  4  \"  )  . setScriptType ( STORED )  . setScriptParams ( arrayTemplateParams )  . get (  )  ;", "assertHitCount ( searchResponse . getResponse (  )  ,     5  )  ;", "}", "METHOD_END"], "methodName": ["testIndexedTemplateWithArray"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "String   query    =     \"  {     \\  \" query \\  \"  :     {  \\  \" match _ all \\  \"  :     {  }  }  ,     \\  \" size \\  \"     :     \\  \"  {  { my _ size }  }  \\  \"        }  \"  ;", "SearchRequest   searchRequest    =    new   SearchRequest (  )  ;", "searchRequest . indices (  \"  _ all \"  )  ;", "expectThrows ( Exception . class ,     (  )     -  >    new   RequestBuilder ( client (  )  )  . setRequest ( searchRequest )  . setScript ( query )  . setScriptType ( ScriptType . INLINE )  . setScriptParams (  ( randomBoolean (  )     ?    null    :    Collections . emptyMap (  )  )  )  . get (  )  )  ;", "Response   searchResponse    =    new   RequestBuilder ( client (  )  )  . setRequest ( searchRequest )  . setScript ( query )  . setScriptType ( INLINE )  . setScriptParams ( Collections . singletonMap (  \" my _ size \"  ,     1  )  )  . get (  )  ;", "assertThat ( searchResponse . getResponse (  )  . getHits (  )  . getHits (  )  . length ,    equalTo (  1  )  )  ;", "}", "METHOD_END"], "methodName": ["testSearchRequestFail"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "SearchRequest   searchRequest    =    new   SearchRequest (  )  ;", "searchRequest . indices (  \"  _ all \"  )  ;", "String   query    =     \"  {  \"     +     (  (  (  (  \"        \\  \" source \\  \"     :     \\  \"  {     \\  \\  \\  \" size \\  \\  \\  \"  :     \\  \\  \\  \"  {  { size }  }  \\  \\  \\  \"  ,     \\  \\  \\  \" query \\  \\  \\  \"  :  {  \\  \\  \\  \" match _ all \\  \\  \\  \"  :  {  }  }  }  \\  \"  ,  \"     +     \"        \\  \" params \\  \"  :  {  \"  )     +     \"              \\  \" size \\  \"  :     1  \"  )     +     \"        }  \"  )     +     \"  }  \"  )  ;", "Request   request    =    RestAction . parse ( createParser ( jsonXContent ,    query )  )  ;", "request . setRequest ( searchRequest )  ;", "Response   searchResponse    =    client (  )  . execute ( Action . INSTANCE ,    request )  . get (  )  ;", "assertThat ( searchResponse . getResponse (  )  . getHits (  )  . getHits (  )  . length ,    equalTo (  1  )  )  ;", "}", "METHOD_END"], "methodName": ["testTemplateQueryAsEscapedString"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "SearchRequest   searchRequest    =    new   SearchRequest (  )  ;", "searchRequest . indices (  \"  _ all \"  )  ;", "String   templateString    =     \"  {  \"     +     (  (  (  (  (  \"        \\  \" source \\  \"     :     \\  \"  {     {  {  # use _ size }  }     \\  \\  \\  \" size \\  \\  \\  \"  :     \\  \\  \\  \"  {  { size }  }  \\  \\  \\  \"  ,     {  {  / use _ size }  }     \\  \\  \\  \" query \\  \\  \\  \"  :  {  \\  \\  \\  \" match _ all \\  \\  \\  \"  :  {  }  }  }  \\  \"  ,  \"     +     \"        \\  \" params \\  \"  :  {  \"  )     +     \"              \\  \" size \\  \"  :     1  ,  \"  )     +     \"              \\  \" use _ size \\  \"  :    true \"  )     +     \"        }  \"  )     +     \"  }  \"  )  ;", "Request   request    =    RestAction . parse ( createParser ( jsonXContent ,    templateString )  )  ;", "request . setRequest ( searchRequest )  ;", "Response   searchResponse    =    client (  )  . execute ( Action . INSTANCE ,    request )  . get (  )  ;", "assertThat ( searchResponse . getResponse (  )  . getHits (  )  . getHits (  )  . length ,    equalTo (  1  )  )  ;", "}", "METHOD_END"], "methodName": ["testTemplateQueryAsEscapedStringStartingWithConditionalClause"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "SearchRequest   searchRequest    =    new   SearchRequest (  )  ;", "searchRequest . indices (  \"  _ all \"  )  ;", "String   templateString    =     \"  {  \"     +     (  (  (  (  (  \"        \\  \" source \\  \"     :     \\  \"  {     \\  \\  \\  \" query \\  \\  \\  \"  :  {  \\  \\  \\  \" match _ all \\  \\  \\  \"  :  {  }  }     {  {  # use _ size }  }  ,     \\  \\  \\  \" size \\  \\  \\  \"  :     \\  \\  \\  \"  {  { size }  }  \\  \\  \\  \"     {  {  / use _ size }  }     }  \\  \"  ,  \"     +     \"        \\  \" params \\  \"  :  {  \"  )     +     \"              \\  \" size \\  \"  :     1  ,  \"  )     +     \"              \\  \" use _ size \\  \"  :    true \"  )     +     \"        }  \"  )     +     \"  }  \"  )  ;", "Request   request    =    RestAction . parse ( createParser ( jsonXContent ,    templateString )  )  ;", "request . setRequest ( searchRequest )  ;", "Response   searchResponse    =    client (  )  . execute ( Action . INSTANCE ,    request )  . get (  )  ;", "assertThat ( searchResponse . getResponse (  )  . getHits (  )  . getHits (  )  . length ,    equalTo (  1  )  )  ;", "}", "METHOD_END"], "methodName": ["testTemplateQueryAsEscapedStringWithConditionalClauseAtEnd"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateIT"}, {"methodBody": ["METHOD_START", "{", "return   request ;", "}", "METHOD_END"], "methodName": ["getRequest"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "return   script ;", "}", "METHOD_END"], "methodName": ["getScript"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "return   scriptParams ;", "}", "METHOD_END"], "methodName": ["getScriptParams"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "return   scriptType ;", "}", "METHOD_END"], "methodName": ["getScriptType"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "return   explain ;", "}", "METHOD_END"], "methodName": ["isExplain"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "return   profile ;", "}", "METHOD_END"], "methodName": ["isProfile"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "return   simulate ;", "}", "METHOD_END"], "methodName": ["isSimulate"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "this . explain    =    explain ;", "}", "METHOD_END"], "methodName": ["setExplain"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "this . profile    =    profile ;", "}", "METHOD_END"], "methodName": ["setProfile"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "this . request    =    request ;", "}", "METHOD_END"], "methodName": ["setRequest"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "this . script    =    script ;", "}", "METHOD_END"], "methodName": ["setScript"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "this . scriptParams    =    scriptParams ;", "}", "METHOD_END"], "methodName": ["setScriptParams"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "this . scriptType    =    scriptType ;", "}", "METHOD_END"], "methodName": ["setScriptType"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "this . simulate    =    simulate ;", "}", "METHOD_END"], "methodName": ["setSimulate"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequest"}, {"methodBody": ["METHOD_START", "{", "request . setExplain ( explain )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setExplain"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "request . setProfile ( profile )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setProfile"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "request . setRequest ( searchRequest )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setRequest"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "request . setScript ( script )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setScript"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "request . setScriptParams ( scriptParams )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setScriptParams"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "request . setScriptType ( scriptType )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setScriptType"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "request . setSimulate ( simulate )  ;", "return   this ;", "}", "METHOD_END"], "methodName": ["setSimulate"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestBuilder"}, {"methodBody": ["METHOD_START", "{", "assertNotNull ( s )  ;", "return   createParser ( jsonXContent ,    s . rece (  \"  '  \"  ,     \"  \\  \"  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["newParser"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "String   source    =     \"  {  \"     +     (  (  (  (  (  (  (  (  (  (  (  \"              \\  ' source \\  '     :     {  \\ n \"     +     \"              \\  ' query \\  '  :     {  \\ n \"  )     +     \"                    \\  ' terms \\  '  :     {  \\ n \"  )     +     \"                          \\  ' status \\  '  :     [  \\ n \"  )     +     \"                                \\  '  {  {  # status }  }  \\  '  ,  \\ n \"  )     +     \"                                \\  '  {  {  .  }  }  \\  '  ,  \\ n \"  )     +     \"                                \\  '  {  {  / status }  }  \\  '  \\ n \"  )     +     \"                          ]  \\ n \"  )     +     \"                    }  \\ n \"  )     +     \"              }  \\ n \"  )     +     \"        }  \"  )     +     \"  }  \"  )  ;", "request    =    RestSearchTemplateAction . parse ( newParser ( source )  )  ;", "assertThat ( request . getScript (  )  ,    equalTo (  \"  {  \\  \" query \\  \"  :  {  \\  \" terms \\  \"  :  {  \\  \" status \\  \"  :  [  \\  \"  {  {  # status }  }  \\  \"  ,  \\  \"  {  {  .  }  }  \\  \"  ,  \\  \"  {  {  / status }  }  \\  \"  ]  }  }  }  \"  )  )  ;", "assertThat ( request . getScriptType (  )  ,    equalTo ( INLINE )  )  ;", "assertThat ( request . getScriptParams (  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseInlineTemplate"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "String   source    =     \"  {  \\  ' source \\  '     :     \\  '  {  \\  \\  \\  \" query \\  \\  \\  \"  :  {  \\  \\  \\  \" bool \\  \\  \\  \"  :  {  \\  \\  \\  \" must \\  \\  \\  \"  :  {  \\  \\  \\  \" match \\  \\  \\  \"  :  {  \\  \\  \\  \" foo \\  \\  \\  \"  :  \\  \\  \\  \"  {  { text }  }  \\  \\  \\  \"  }  }  }  }  }  \\  '  }  \"  ;", "request    =    RestSearchTemplateAction . parse ( newParser ( source )  )  ;", "assertThat ( request . getScript (  )  ,    equalTo (  \"  {  \\  \" query \\  \"  :  {  \\  \" bool \\  \"  :  {  \\  \" must \\  \"  :  {  \\  \" match \\  \"  :  {  \\  \" foo \\  \"  :  \\  \"  {  { text }  }  \\  \"  }  }  }  }  }  \"  )  )  ;", "assertThat ( request . getScriptType (  )  ,    equalTo ( INLINE )  )  ;", "assertThat ( request . getScriptParams (  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseInlineTemplateAsString"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "String   source    =     \"  {  \\  ' source \\  '     :     \\  '  {  \\  \\  \\  \" query \\  \\  \\  \"  :  {  \\  \\  \\  \" match \\  \\  \\  \"  :  {  \\  \\  \\  \"  {  { field }  }  \\  \\  \\  \"  :  \\  \\  \\  \"  {  { value }  }  \\  \\  \\  \"  }  }  }  \\  '  ,     \"     +     \"  ' params '  :     {  ' status '  :     [  ' pending '  ,     ' published '  ]  }  }  \"  ;", "request    =    RestSearchTemplateAction . parse ( newParser ( source )  )  ;", "assertThat ( request . getScript (  )  ,    equalTo (  \"  {  \\  \" query \\  \"  :  {  \\  \" match \\  \"  :  {  \\  \"  {  { field }  }  \\  \"  :  \\  \"  {  { value }  }  \\  \"  }  }  }  \"  )  )  ;", "assertThat ( request . getScriptType (  )  ,    equalTo ( INLINE )  )  ;", "assertThat ( request . getScriptParams (  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( request . getScriptParams (  )  ,    hasKey (  \" status \"  )  )  ;", "assertThat (  (  ( List < String >  )     ( request . getScriptParams (  )  . get (  \" status \"  )  )  )  ,    hasItems (  \" pending \"  ,     \" published \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseInlineTemplateAsStringWithParams"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "String   source    =     \"  {  \"     +     (  (  (  (  (  (  (  (  (  \"              ' source '     :     {  \"     +     \"                    ' query '  :     {     ' match '     :     {     '  {  { my _ field }  }  '     :     '  {  { my _ value }  }  '     }     }  ,  \"  )     +     \"                    ' size '     :     '  {  { my _ size }  }  '  \"  )     +     \"              }  ,  \"  )     +     \"              ' params '     :     {  \"  )     +     \"                          ' my _ field '     :     ' foo '  ,  \"  )     +     \"                          ' my _ value '     :     ' bar '  ,  \"  )     +     \"                          ' my _ size '     :     5  \"  )     +     \"              }  \"  )     +     \"  }  \"  )  ;", "request    =    RestSearchTemplateAction . parse ( newParser ( source )  )  ;", "assertThat ( request . getScript (  )  ,    equalTo (  \"  {  \\  \" query \\  \"  :  {  \\  \" match \\  \"  :  {  \\  \"  {  { my _ field }  }  \\  \"  :  \\  \"  {  { my _ value }  }  \\  \"  }  }  ,  \\  \" size \\  \"  :  \\  \"  {  { my _ size }  }  \\  \"  }  \"  )  )  ;", "assertThat ( request . getScriptType (  )  ,    equalTo ( INLINE )  )  ;", "assertThat ( request . getScriptParams (  )  . size (  )  ,    equalTo (  3  )  )  ;", "assertThat ( request . getScriptParams (  )  ,    hasEntry (  \" my _ field \"  ,     \" foo \"  )  )  ;", "assertThat ( request . getScriptParams (  )  ,    hasEntry (  \" my _ value \"  ,     \" bar \"  )  )  ;", "assertThat ( request . getScriptParams (  )  ,    hasEntry (  \" my _ size \"  ,     5  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseInlineTemplateWithParams"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "String   source    =     \"  {  ' id '     :     ' storedTemplate '  }  \"  ;", "request    =    RestSearchTemplateAction . parse ( newParser ( source )  )  ;", "assertThat ( request . getScript (  )  ,    equalTo (  \" storedTemplate \"  )  )  ;", "assertThat ( request . getScriptType (  )  ,    equalTo ( STORED )  )  ;", "assertThat ( request . getScriptParams (  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseStoredTemplate"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "String   source    =     \"  {  ' id '     :     ' another _ template '  ,     ' params '     :     {  ' bar '  :     ' foo '  }  }  \"  ;", "request    =    RestSearchTemplateAction . parse ( newParser ( source )  )  ;", "assertThat ( request . getScript (  )  ,    equalTo (  \" another _ template \"  )  )  ;", "assertThat ( request . getScriptType (  )  ,    equalTo ( STORED )  )  ;", "assertThat ( request . getScriptParams (  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat ( request . getScriptParams (  )  ,    hasEntry (  \" bar \"  ,     \" foo \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseStoredTemplateWithParams"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "expectThrows ( XContentParseException . class ,     (  )     -  >    RestSearchTemplateAction . parse ( newParser (  \"  {  ' id '     :     ' another _ temp    }  \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseWrongTemplate"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateRequestTests"}, {"methodBody": ["METHOD_START", "{", "return   response ;", "}", "METHOD_END"], "methodName": ["getResponse"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateResponse"}, {"methodBody": ["METHOD_START", "{", "return   source ;", "}", "METHOD_END"], "methodName": ["getSource"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateResponse"}, {"methodBody": ["METHOD_START", "{", "return    ( response )     !  =    null ;", "}", "METHOD_END"], "methodName": ["hasResponse"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateResponse"}, {"methodBody": ["METHOD_START", "{", "this . response    =    searchResponse ;", "}", "METHOD_END"], "methodName": ["setResponse"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateResponse"}, {"methodBody": ["METHOD_START", "{", "this . source    =    source ;", "}", "METHOD_END"], "methodName": ["setSource"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateResponse"}, {"methodBody": ["METHOD_START", "{", "ResponseException   responseException    =    expectThrows ( ResponseException . class ,     (  )     -  >    client (  )  . performRequest (  ( randomBoolean (  )     ?     \" POST \"     :     \" GET \"  )  ,     \"  /  _ msearch / template \"  )  )  ;", "assertEquals (  4  0  0  ,    responseException . getResponse (  )  . getStatusLine (  )  . getStatusCode (  )  )  ;", "assertThat ( responseException . getMessage (  )  ,    containsString (  \" request   body   or   source   parameter   is   required \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testMultiSearchTemplateMissingBody"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateWithoutContentIT"}, {"methodBody": ["METHOD_START", "{", "ResponseException   responseException    =    expectThrows ( ResponseException . class ,     (  )     -  >    client (  )  . performRequest (  ( randomBoolean (  )     ?     \" POST \"     :     \" GET \"  )  ,     \"  /  _ search / template \"  )  )  ;", "assertEquals (  4  0  0  ,    responseException . getResponse (  )  . getStatusLine (  )  . getStatusCode (  )  )  ;", "assertThat ( responseException . getMessage (  )  ,    containsString (  \" request   body   or   source   parameter   is   required \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testSearchTemplateMissingBody"], "fileName": "org.elasticsearch.script.mustache.SearchTemplateWithoutContentIT"}, {"methodBody": ["METHOD_START", "{", "Script   script    =    new   Script ( searchTemplateRequest . getScriptType (  )  ,     (  ( searchTemplateRequest . getScriptType (  )  )     =  =     ( ScriptType . STORED )     ?    null    :    TransportSearchTemplateAction . TEMPLATE _ LANG )  ,    searchTemplateRequest . getScript (  )  ,     (  ( searchTemplateRequest . getScriptParams (  )  )     =  =    null    ?    Collections . emptyMap (  )     :    searchTemplateRequest . getScriptParams (  )  )  )  ;", "TemplateScript   compiledScript    =    scriptService . compile ( script ,    CONTEXT )  . newInstance ( script . getParams (  )  )  ;", "String   source    =    compiledScript . execute (  )  ;", "response . setSource ( new   BytesArray ( source )  )  ;", "SearchRequest   searchRequest    =    searchTemplateRequest . getRequest (  )  ;", "if    ( searchTemplateRequest . isSimulate (  )  )     {", "return   null ;", "}", "try    ( XContentParser   parser    =    XContentFactory . xContent ( JSON )  . createParser ( xContentRegistry ,    INSTANCE ,    source )  )     {", "SearchSourceBuilder   builder    =    SearchSourceBuilder . searchSource (  )  ;", "builder . parseXContent ( parser ,    false )  ;", "builder . explain ( searchTemplateRequest . isExplain (  )  )  ;", "builder . profile ( searchTemplateRequest . isProfile (  )  )  ;", "searchRequest . source ( builder )  ;", "}", "return   searchRequest ;", "}", "METHOD_END"], "methodName": ["convert"], "fileName": "org.elasticsearch.script.mustache.TransportSearchTemplateAction"}, {"methodBody": ["METHOD_START", "{", "return   new   MatrixStatsAggregationBuilder ( name )  ;", "}", "METHOD_END"], "methodName": ["matrixStats"], "fileName": "org.elasticsearch.search.aggregations.MatrixStatsAggregationBuilders"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.search.aggregations.matrix.MatrixStatsClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "for    ( int   n    =     0  ;    n    <     ( numObs )  ;     +  + n )     {", "fieldA . add ( randomDouble (  )  )  ;", "fieldB . add ( randomDouble (  )  )  ;", "}", "actual . compute ( fieldA ,    fieldB )  ;", "}", "METHOD_END"], "methodName": ["createStats"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.BaseMatrixStatsTestCase"}, {"methodBody": ["METHOD_START", "{", "createStats (  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.BaseMatrixStatsTestCase"}, {"methodBody": ["METHOD_START", "{", "return   results ;", "}", "METHOD_END"], "methodName": ["getResults"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.InternalMatrixStats"}, {"methodBody": ["METHOD_START", "{", "return   stats ;", "}", "METHOD_END"], "methodName": ["getStats"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.InternalMatrixStats"}, {"methodBody": ["METHOD_START", "{", "return   this . multiValueMode ;", "}", "METHOD_END"], "methodName": ["multiValueMode"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "this . multiValueMode    =    multiValueMode ;", "return   this ;", "}", "METHOD_END"], "methodName": ["multiValueMode"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "MappedFieldType   ft    =    new   NumberFieldType ( NumberType . DOUBLE )  ;", "ft . setName (  \" field \"  )  ;", "try    ( Directory   directory    =    newDirectory (  )  ; RandomIndexWriter   indexWriter    =    new   RandomIndexWriter ( random (  )  ,    directory )  )     {", "if    ( randomBoolean (  )  )     {", "indexWriter . addDocument ( Collections . singleton ( new   StringField (  \" another _ field \"  ,     \" value \"  ,    Store . NO )  )  )  ;", "}", "try    ( IndexReader   reader    =    indexWriter . getReader (  )  )     {", "IndexSearcher   searcher    =    new   IndexSearcher ( reader )  ;", "ionBuilder   aggBuilder    =    new   ionBuilder (  \" my _ agg \"  )  . fields ( Collections . singletonList (  \" field \"  )  )  ;", "InternalMatrixStats   stats    =    search ( searcher ,    new   MatchAllDocsQuery (  )  ,    aggBuilder ,    ft )  ;", "assertNull ( stats . getStats (  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testNoData"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "String   fieldA    =     \" a \"  ;", "MappedFieldType   ftA    =    new   NumberFieldType ( NumberType . DOUBLE )  ;", "ftA . setName ( fieldA )  ;", "String   fieldB    =     \" b \"  ;", "MappedFieldType   ftB    =    new   NumberFieldType ( NumberType . DOUBLE )  ;", "ftB . setName ( fieldB )  ;", "try    ( Directory   directory    =    newDirectory (  )  ; RandomIndexWriter   indexWriter    =    new   RandomIndexWriter ( random (  )  ,    directory )  )     {", "int   numDocs    =    scaledRandomIntBetween (  8  1  9  2  ,     1  6  3  8  4  )  ;", "Double [  ]    fieldAValues    =    new   Double [ numDocs ]  ;", "Double [  ]    fieldBValues    =    new   Double [ numDocs ]  ;", "for    ( int   docId    =     0  ;    docId    <    numDocs ;    docId +  +  )     {", "Document   document    =    new   Document (  )  ;", "fieldAValues [ docId ]     =    randomDouble (  )  ;", "document . add ( new   SortedNumericDocValuesField ( fieldA ,    NumericUtils . doubleToSortableLong ( fieldAValues [ docId ]  )  )  )  ;", "fieldBValues [ docId ]     =    randomDouble (  )  ;", "document . add ( new   SortedNumericDocValuesField ( fieldB ,    NumericUtils . doubleToSortableLong ( fieldBValues [ docId ]  )  )  )  ;", "indexWriter . addDocument ( document )  ;", "}", "MultiPassStats   multiPassStats    =    new   MultiPassStats ( fieldA ,    fieldB )  ;", "multiPassStats . computeStats ( Arrays . asList ( fieldAValues )  ,    Arrays . asList ( fieldBValues )  )  ;", "try    ( IndexReader   reader    =    indexWriter . getReader (  )  )     {", "IndexSearcher   searcher    =    new   IndexSearcher ( reader )  ;", "ionBuilder   aggBuilder    =    new   ionBuilder (  \" my _ agg \"  )  . fields ( Arrays . asList ( fieldA ,    fieldB )  )  ;", "InternalMatrixStats   stats    =    search ( searcher ,    new   MatchAllDocsQuery (  )  ,    aggBuilder ,    ftA ,    ftB )  ;", "multiPassStats . assertNearlyEqual ( new   MatrixStatsResults ( stats . getStats (  )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testTwoFields"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsAggregatorTests"}, {"methodBody": ["METHOD_START", "{", "if    ( field    =  =    null )     {", "throw   new   IllegalArgumentExcep (  \" field   name   cannot   be   null \"  )  ;", "}", "if    (  ( map . containsKey ( field )  )     =  =    false )     {", "throw   new   IllegalArgumentExcep (  (  (  \" field    \"     +    field )     +     \"    does   not   exist \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkField"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "final   double   nM 1     =     ( results . docCount )     -     1  .  0  ;", "for    ( String   fieldName    :    results . means . keySet (  )  )     {", "final   double   var    =    results . variances . get ( fieldName )  ;", "results . skewness . put ( fieldName ,     (  (  ( Math . sqrt ( results . docCount )  )     *     ( results . skewness . get ( fieldName )  )  )     /     ( Math . pow ( var ,     1  .  5  )  )  )  )  ;", "results . kurtosis . put ( fieldName ,     (  (  (  ( double )     ( results . docCount )  )     *     ( results . kurtosis . get ( fieldName )  )  )     /     ( var    *    var )  )  )  ;", "results . variances . put ( fieldName ,     (  ( results . variances . get ( fieldName )  )     /    nM 1  )  )  ;", "}", "double   cor ;", "for    ( Map . Entry < String ,    HashMap < String ,    Double >  >    row    :    results . covariances . entrySet (  )  )     {", "final   String   rowName    =    row . getKey (  )  ;", "final   HashMap < String ,    Double >    covRow    =    row . getValue (  )  ;", "final   HashMap < String ,    Double >    corRow    =    new   HashMap <  >  (  )  ;", "for    ( Map . Entry < String ,    Double >    col    :    covRow . entrySet (  )  )     {", "final   String   colName    =    col . getKey (  )  ;", "covRow . put ( colName ,     (  ( covRow . get ( colName )  )     /    nM 1  )  )  ;", "if    (  (  ( results . variances . get ( rowName )  )     =  =     0  .  0  )     |  |     (  ( results . variances . get ( colName )  )     =  =     0  .  0  )  )     {", "cor    =    Double . NaN ;", "} else    {", "final   double   corDen    =     ( Math . sqrt ( results . variances . get ( rowName )  )  )     *     ( Math . sqrt ( results . variances . get ( colName )  )  )  ;", "cor    =     ( covRow . get ( colName )  )     /    corDen ;", "}", "corRow . put ( colName ,    cor )  ;", "}", "results . covariances . put ( rowName ,    covRow )  ;", "correlation . put ( rowName ,    corRow )  ;", "}", "}", "METHOD_END"], "methodName": ["compute"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "if    ( fieldX . equals ( fieldY )  )     {", "return    1  .  0  ;", "}", "return    . getValFromUpperTriangularMatrix ( correlation ,    fieldX ,    fieldY )  ;", "}", "METHOD_END"], "methodName": ["getCorrelation"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( correlation )  ;", "}", "METHOD_END"], "methodName": ["getCorrelations"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "if    ( fieldX . equals ( fieldY )  )     {", "checkField ( fieldX ,    results . variances )  ;", "return   results . variances . get ( fieldX )  ;", "}", "return    . getValFromUpperTriangularMatrix ( results . covariances ,    fieldX ,    fieldY )  ;", "}", "METHOD_END"], "methodName": ["getCovariance"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( results . covariances )  ;", "}", "METHOD_END"], "methodName": ["getCovariances"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "return   results . docCount ;", "}", "METHOD_END"], "methodName": ["getDocCount"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "if    (  ( results . counts . containsKey ( field )  )     =  =    false )     {", "return    0  ;", "}", "return   results . counts . get ( field )  ;", "}", "METHOD_END"], "methodName": ["getFieldCount"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( results . counts )  ;", "}", "METHOD_END"], "methodName": ["getFieldCounts"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( results . kurtosis )  ;", "}", "METHOD_END"], "methodName": ["getKurtosis"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "checkField ( field ,    results . kurtosis )  ;", "return   results . kurtosis . get ( field )  ;", "}", "METHOD_END"], "methodName": ["getKurtosis"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "checkField ( field ,    results . means )  ;", "return   results . means . get ( field )  ;", "}", "METHOD_END"], "methodName": ["getMean"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( results . means )  ;", "}", "METHOD_END"], "methodName": ["getMeans"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( results . skewness )  ;", "}", "METHOD_END"], "methodName": ["getSkewness"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "checkField ( field ,    results . skewness )  ;", "return   results . skewness . get ( field )  ;", "}", "METHOD_END"], "methodName": ["getSkewness"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "if    (  (  ( map . containsKey ( fieldX )  )     =  =    false )     &  &     (  ( map . containsKey ( fieldY )  )     =  =    false )  )     {", "throw   new   IllegalArgumentExcep (  (  (  (  (  \" neither   field    \"     +    fieldX )     +     \"    nor    \"  )     +    fieldY )     +     \"    exist \"  )  )  ;", "} else", "if    ( map . containsKey ( fieldX )  )     {", "if    ( map . get ( fieldX )  . containsKey ( fieldY )  )     {", "return   map . get ( fieldX )  . get ( fieldY )  ;", "} else    {", "return   map . get ( fieldY )  . get ( fieldX )  ;", "}", "} else", "if    ( map . containsKey ( fieldY )  )     {", "return   map . get ( fieldY )  . get ( fieldX )  ;", "}", "throw   new   IllegalArgumentExcep (  (  (  (  \" Coefficient   not   computed   between   fields :     \"     +    fieldX )     +     \"    and    \"  )     +    fieldY )  )  ;", "}", "METHOD_END"], "methodName": ["getValFromUpperTriangularMatrix"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "checkField ( field ,    results . variances )  ;", "return   results . variances . get ( field )  ;", "}", "METHOD_END"], "methodName": ["getVariance"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "return   Collections . unmodifiableMap ( results . variances )  ;", "}", "METHOD_END"], "methodName": ["getVariances"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MatrixStatsResults"}, {"methodBody": ["METHOD_START", "{", "assertEquals ( count ,    stats . getDocCount (  )  )  ;", "assertEquals ( count ,    stats . getFieldCount ( fieldAKey )  )  ;", "assertEquals ( count ,    stats . getFieldCount ( fieldBKey )  )  ;", "assertTrue (  . nearlyEqual ( means . get ( fieldAKey )  ,    stats . getMean ( fieldAKey )  ,     1  .  0 E -  7  )  )  ;", "assertTrue (  . nearlyEqual ( means . get ( fieldBKey )  ,    stats . getMean ( fieldBKey )  ,     1  .  0 E -  7  )  )  ;", "assertTrue (  . nearlyEqual ( variances . get ( fieldAKey )  ,    stats . getVariance ( fieldAKey )  ,     1  .  0 E -  7  )  )  ;", "assertTrue (  . nearlyEqual ( variances . get ( fieldBKey )  ,    stats . getVariance ( fieldBKey )  ,     1  .  0 E -  7  )  )  ;", "assertTrue (  . nearlyEqual ( skewness . get ( fieldAKey )  ,    stats . getSkewness ( fieldAKey )  ,     1  .  0 E -  4  )  )  ;", "assertTrue (  . nearlyEqual ( skewness . get ( fieldBKey )  ,    stats . getSkewness ( fieldBKey )  ,     1  .  0 E -  4  )  )  ;", "assertTrue (  . nearlyEqual ( kurtosis . get ( fieldAKey )  ,    stats . getKurtosis ( fieldAKey )  ,     1  .  0 E -  4  )  )  ;", "assertTrue (  . nearlyEqual ( kurtosis . get ( fieldBKey )  ,    stats . getKurtosis ( fieldBKey )  ,     1  .  0 E -  4  )  )  ;", "assertTrue (  . nearlyEqual ( covariances . get ( fieldAKey )  . get ( fieldBKey )  ,    stats . getCovariance ( fieldAKey ,    fieldBKey )  ,     1  .  0 E -  7  )  )  ;", "assertTrue (  . nearlyEqual ( covariances . get ( fieldBKey )  . get ( fieldAKey )  ,    stats . getCovariance ( fieldBKey ,    fieldAKey )  ,     1  .  0 E -  7  )  )  ;", "assertTrue (  . nearlyEqual ( correlations . get ( fieldAKey )  . get ( fieldBKey )  ,    stats . getCorrelation ( fieldAKey ,    fieldBKey )  ,     1  .  0 E -  7  )  )  ;", "assertTrue (  . nearlyEqual ( correlations . get ( fieldBKey )  . get ( fieldAKey )  ,    stats . getCorrelation ( fieldBKey ,    fieldAKey )  ,     1  .  0 E -  7  )  )  ;", "}", "METHOD_END"], "methodName": ["assertNearlyEqual"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MultiPassStats"}, {"methodBody": ["METHOD_START", "{", "count    =    fieldA . size (  )  ;", "double   meanA    =     0  .  0  ;", "double   meanB    =     0  .  0  ;", "for    ( int   n    =     0  ;    n    <     ( count )  ;     +  + n )     {", "meanA    +  =    fieldA . get ( n )  ;", "meanB    +  =    fieldB . get ( n )  ;", "}", "means . put ( fieldAKey ,     ( meanA    /     ( count )  )  )  ;", "means . put ( fieldBKey ,     ( meanB    /     ( count )  )  )  ;", "double   dA ;", "double   dB ;", "double   skewA    =     0  .  0  ;", "double   skewB    =     0  .  0  ;", "double   kurtA    =     0  .  0  ;", "double   kurtB    =     0  .  0  ;", "double   varA    =     0  .  0  ;", "double   varB    =     0  .  0  ;", "double   cVar    =     0  .  0  ;", "for    ( int   n    =     0  ;    n    <     ( count )  ;     +  + n )     {", "dA    =     ( fieldA . get ( n )  )     -     ( means . get ( fieldAKey )  )  ;", "varA    +  =    dA    *    dA ;", "skewA    +  =     ( dA    *    dA )     *    dA ;", "kurtA    +  =     (  ( dA    *    dA )     *    dA )     *    dA ;", "dB    =     ( fieldB . get ( n )  )     -     ( means . get ( fieldBKey )  )  ;", "varB    +  =    dB    *    dB ;", "skewB    +  =     ( dB    *    dB )     *    dB ;", "kurtB    +  =     (  ( dB    *    dB )     *    dB )     *    dB ;", "cVar    +  =    dA    *    dB ;", "}", "variances . put ( fieldAKey ,     ( varA    /     (  ( count )     -     1  )  )  )  ;", "final   double   stdA    =    Math . sqrt ( variances . get ( fieldAKey )  )  ;", "variances . put ( fieldBKey ,     ( varB    /     (  ( count )     -     1  )  )  )  ;", "final   double   stdB    =    Math . sqrt ( variances . get ( fieldBKey )  )  ;", "skewness . put ( fieldAKey ,     ( skewA    /     (  (  (  ( count )     -     1  )     *     ( variances . get ( fieldAKey )  )  )     *    stdA )  )  )  ;", "skewness . put ( fieldBKey ,     ( skewB    /     (  (  (  ( count )     -     1  )     *     ( variances . get ( fieldBKey )  )  )     *    stdB )  )  )  ;", "kurtosis . put ( fieldAKey ,     ( kurtA    /     (  (  (  ( count )     -     1  )     *     ( variances . get ( fieldAKey )  )  )     *     ( variances . get ( fieldAKey )  )  )  )  )  ;", "kurtosis . put ( fieldBKey ,     ( kurtB    /     (  (  (  ( count )     -     1  )     *     ( variances . get ( fieldBKey )  )  )     *     ( variances . get ( fieldBKey )  )  )  )  )  ;", "final   HashMap < String ,    Double >    fieldACovar    =    new   HashMap <  >  (  2  )  ;", "fieldACovar . put ( fieldAKey ,     1  .  0  )  ;", "cVar    /  =     ( count )     -     1  ;", "fieldACovar . put ( fieldBKey ,    cVar )  ;", "covariances . put ( fieldAKey ,    fieldACovar )  ;", "final   HashMap < String ,    Double >    fieldBCovar    =    new   HashMap <  >  (  2  )  ;", "fieldBCovar . put ( fieldAKey ,    cVar )  ;", "fieldBCovar . put ( fieldBKey ,     1  .  0  )  ;", "covariances . put ( fieldBKey ,    fieldBCovar )  ;", "final   HashMap < String ,    Double >    fieldACorr    =    new   HashMap <  >  (  )  ;", "fieldACorr . put ( fieldAKey ,     1  .  0  )  ;", "double   corr    =    covariances . get ( fieldAKey )  . get ( fieldBKey )  ;", "corr    /  =    stdA    *    stdB ;", "fieldACorr . put ( fieldBKey ,    corr )  ;", "correlput ( fieldAKey ,    fieldACorr )  ;", "final   HashMap < String ,    Double >    fieldBCorr    =    new   HashMap <  >  (  )  ;", "fieldBCorr . put ( fieldAKey ,    corr )  ;", "fieldBCorr . put ( fieldBKey ,     1  .  0  )  ;", "correlput ( fieldBKey ,    fieldBCorr )  ;", "}", "METHOD_END"], "methodName": ["computeStats"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MultiPassStats"}, {"methodBody": ["METHOD_START", "{", "final   double   absA    =    Math . abs ( a )  ;", "final   double   absB    =    Math . abs ( b )  ;", "final   double   diff    =    Math . abs (  ( a    -    b )  )  ;", "if    ( a    =  =    b )     {", "return   true ;", "} else", "if    (  (  ( a    =  =     0  )     |  |     ( b    =  =     0  )  )     |  |     ( diff    <     ( Double . MIN _ NORMAL )  )  )     {", "return   diff    <     ( epsilon    *     ( Double . MIN _ NORMAL )  )  ;", "} else    {", "return    ( diff    /     ( Math . min (  ( absA    +    absB )  ,    Double . MAX _ VALUE )  )  )     <    epsilon ;", "}", "}", "METHOD_END"], "methodName": ["nearlyEqual"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.MultiPassStats"}, {"methodBody": ["METHOD_START", "{", "if    ( fieldName    =  =    null )     {", "throw   new   IllegalArgumentExcep (  \" field   name   cannot   be   null \"  )  ;", "}", "if    (  ( values . containsKey ( fieldName )  )     =  =    false )     {", "throw   new   IllegalArgumentExcep (  (  (  \" field    \"     +    fieldName )     +     \"    does   not   exist \"  )  )  ;", "}", "return   values . get ( fieldName )  ;", "}", "METHOD_END"], "methodName": ["checkedGet"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.ParsedMatrixStats"}, {"methodBody": ["METHOD_START", "{", "ParsedMatrixStats   aggregation    =    ParsedMatrixStats . PARSER . parse ( parser ,    null )  ;", "aggregation . setName ( name )  ;", "return   aggregation ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.ParsedMatrixStats"}, {"methodBody": ["METHOD_START", "{", "this . docCount    =    docCount ;", "}", "METHOD_END"], "methodName": ["setDocCount"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.ParsedMatrixStats"}, {"methodBody": ["METHOD_START", "{", "if    ( fieldNames    =  =    null )     {", "throw   new   IllegalArgumentException (  \" Cannot   add   stati   without   field   names .  \"  )  ;", "} else", "if    ( fieldVals    =  =    null )     {", "throw   new   IllegalArgumentException (  \" Cannot   add   stati   without   field   values .  \"  )  ;", "} else", "if    (  ( fieldNames . length )     !  =     ( fieldVals . length )  )     {", "throw   new   IllegalArgumentException (  \" Number   of   field   values   do   not   match   number   of   field   names .  \"  )  ;", "}", "+  +  ( docCount )  ;", "String   fieldName ;", "double   fieldValue ;", "double   m 1  ;", "double   m 2  ;", "double   m 3  ;", "double   m 4  ;", "double   d ;", "double   dn ;", "double   dn 2  ;", "double   t 1  ;", "final   HashMap < String ,    Double >    deltas    =    new   HashMap <  >  (  )  ;", "for    ( int   i    =     0  ;    i    <     ( fieldNames . length )  ;     +  + i )     {", "fieldName    =    fieldNames [ i ]  ;", "fieldValue    =    fieldVals [ i ]  ;", "counts . put ( fieldName ,     (  1     +     ( counts . containsKey ( fieldName )     ?    counts . get ( fieldName )     :     0  )  )  )  ;", "fieldSum . put ( fieldName ,     ( fieldValue    +     ( fieldSum . containsKey ( fieldName )     ?    fieldSum . get ( fieldName )     :     0  )  )  )  ;", "deltas . put ( fieldName ,     (  ( fieldValue    *     ( docCount )  )     -     ( fieldSum . get ( fieldName )  )  )  )  ;", "if    (  ( means . containsKey ( fieldName )  )     =  =    true )     {", "m 1     =    means . get ( fieldName )  ;", "d    =    fieldValue    -    m 1  ;", "means . put ( fieldName ,     ( m 1     +     ( d    /     ( docCount )  )  )  )  ;", "dn    =    d    /     ( docCount )  ;", "t 1     =     ( d    *    dn )     *     (  ( docCount )     -     1  )  ;", "m 2     =    variances . get ( fieldName )  ;", "variances . put ( fieldName ,     ( m 2     +    t 1  )  )  ;", "m 3     =    skewness . get ( fieldName )  ;", "skewness . put ( fieldName ,     ( m 3     +     (  (  ( t 1     *    dn )     *     (  ( docCount )     -     2  .  0  )  )     -     (  (  3  .  0     *    dn )     *    m 2  )  )  )  )  ;", "dn 2     =    dn    *    dn ;", "m 4     =     (  (  ( t 1     *    dn 2  )     *     (  (  (  ( docCount )     *     ( docCount )  )     -     (  3  .  0     *     ( docCount )  )  )     +     3  .  0  )  )     +     (  (  6  .  0     *    dn 2  )     *    m 2  )  )     -     (  (  4  .  0     *    dn )     *    m 3  )  ;", "kurtosis . put ( fieldName ,     (  ( kurtosis . get ( fieldName )  )     +    m 4  )  )  ;", "} else    {", "means . put ( fieldName ,    fieldValue )  ;", "variances . put ( fieldName ,     0  .  0  )  ;", "skewness . put ( fieldName ,     0  .  0  )  ;", "kurtosis . put ( fieldName ,     0  .  0  )  ;", "}", "}", "this . updateCovariance ( fieldNames ,    deltas )  ;", "}", "METHOD_END"], "methodName": ["add"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.RunningStats"}, {"methodBody": ["METHOD_START", "{", "counts    =    new   HashMap <  >  (  )  ;", "fieldSum    =    new   HashMap <  >  (  )  ;", "means    =    new   HashMap <  >  (  )  ;", "skewness    =    new   HashMap <  >  (  )  ;", "kurtosis    =    new   HashMap <  >  (  )  ;", "covariances    =    new   HashMap <  >  (  )  ;", "variances    =    new   HashMap <  >  (  )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.RunningStats"}, {"methodBody": ["METHOD_START", "{", "if    ( other    =  =    null )     {", "return ;", "} else", "if    (  ( this . docCount )     =  =     0  )     {", "for    ( Map . Entry < String ,    Double >    fs    :    other . meaentrySet (  )  )     {", "final   String   fieldName    =    fs . getKey (  )  ;", "this . meaput ( fieldName ,    fs . getValue (  )  . doubleValue (  )  )  ;", "this . counts . put ( fieldName ,    other . counts . get ( fieldName )  . longValue (  )  )  ;", "this . fieldSum . put ( fieldName ,    other . fieldSum . get ( fieldName )  . doubleValue (  )  )  ;", "this . variances . put ( fieldName ,    other . variances . get ( fieldName )  . doubleValue (  )  )  ;", "this . skewness . put ( fieldName ,    other . skewness . get ( fieldName )  . doubleValue (  )  )  ;", "this . kurtosis . put ( fieldName ,    other . kurtosis . get ( fieldName )  . doubleValue (  )  )  ;", "if    (  ( other . covariances . contaiey ( fieldName )  )     =  =    true )     {", "this . covariances . put ( fieldName ,    other . covariances . get ( fieldName )  )  ;", "}", "this . docCount    =    other . docCount ;", "}", "return ;", "}", "final   double   nA    =    docCount ;", "final   double   nB    =    other . docCount ;", "docCount    +  =    other . docCount ;", "final   HashMap < String ,    Double >    deltas    =    new   HashMap <  >  (  )  ;", "double   meanA ;", "double   varA ;", "double   skewA ;", "double   kurtA ;", "double   meanB ;", "double   varB ;", "double   skewB ;", "double   kurtB ;", "double   d ;", "double   d 2  ;", "double   d 3  ;", "double   d 4  ;", "double   n 2  ;", "double   nA 2  ;", "double   nB 2  ;", "double   newSkew ;", "double   nk ;", "for    ( Map . Entry < String ,    Double >    fs    :    other . meaentrySet (  )  )     {", "final   String   fieldName    =    fs . getKey (  )  ;", "meanA    =    meaget ( fieldName )  ;", "varA    =    variances . get ( fieldName )  ;", "skewA    =    skewness . get ( fieldName )  ;", "kurtA    =    kurtosis . get ( fieldName )  ;", "meanB    =    other . meaget ( fieldName )  ;", "varB    =    other . variances . get ( fieldName )  ;", "skewB    =    other . skewness . get ( fieldName )  ;", "kurtB    =    other . kurtosis . get ( fieldName )  ;", "counts . put ( fieldName ,     (  ( counts . get ( fieldName )  )     +     ( other . counts . get ( fieldName )  )  )  )  ;", "meaput ( fieldName ,     (  (  ( nA    *     ( meaget ( fieldName )  )  )     +     ( nB    *     ( other . meaget ( fieldName )  )  )  )     /     ( nA    +    nB )  )  )  ;", "deltas . put ( fieldName ,     (  (  ( other . fieldSum . get ( fieldName )  )     /    nB )     -     (  ( fieldSum . get ( fieldName )  )     /    nA )  )  )  ;", "fieldSum . put ( fieldName ,     (  ( fieldSum . get ( fieldName )  )     +     ( other . fieldSum . get ( fieldName )  )  )  )  ;", "d    =    meanB    -    meanA ;", "d 2     =    d    *    d ;", "d 3     =    d    *    d 2  ;", "d 4     =    d 2     *    d 2  ;", "n 2     =     ( docCount )     *     ( docCount )  ;", "nA 2     =    nA    *    nA ;", "nB 2     =    nB    *    nB ;", "variances . put ( fieldName ,     (  ( varA    +    varB )     +     (  (  ( d 2     *    nA )     *     ( other . docCount )  )     /     ( docCount )  )  )  )  ;", "newSkew    =     ( skewA    +    skewB )     +     (  (  (  ( d 3     *    nA )     *    nB )     *     ( nA    -    nB )  )     /    n 2  )  ;", "skewness . put ( fieldName ,     ( newSkew    +     (  (  (  3  .  0     *    d )     *     (  ( nA    *    varB )     -     ( nB    *    varA )  )  )     /     ( docCount )  )  )  )  ;", "nk    =     ( kurtA    +    kurtB )     +     (  (  (  ( d 4     *    nA )     *    nB )     *     (  ( nA 2     -     ( nA    *    nB )  )     +    nB 2  )  )     /     ( n 2     *     ( docCount )  )  )  ;", "kurtosis . put ( fieldName ,     (  ( nk    +     (  (  (  6  .  0     *    d 2  )     *     (  ( nA 2     *    varB )     +     ( nB 2     *    varA )  )  )     /    n 2  )  )     +     (  (  (  4  .  0     *    d )     *     (  ( nA    *    skewB )     -     ( nB    *    skewA )  )  )     /     ( docCount )  )  )  )  ;", "}", "this . mergeCovariance ( other ,    deltas )  ;", "}", "METHOD_END"], "methodName": ["merge"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.RunningStats"}, {"methodBody": ["METHOD_START", "{", "final   double   countA    =     ( docCount )     -     ( other . docCount )  ;", "double   f ;", "double   dR ;", "double   newVal ;", "for    ( Map . Entry < String ,    Double >    fs    :    other . meaentrySet (  )  )     {", "final   String   fieldName    =    fs . getKey (  )  ;", "f    =     ( countA    *     ( other . docCount )  )     /     ( this . docCount )  ;", "dR    =    deltas . get ( fieldName )  ;", "if    ( covariances . contaiey ( fieldName )  )     {", "HashMap < String ,    Double >    cFieldVals    =    covariances . get ( fieldName )  ;", "for    ( String   cFieldName    :    cFieldVals . keySet (  )  )     {", "newVal    =    cFieldVals . get ( cFieldName )  ;", "if    (  ( other . covariances . contaiey ( fieldName )  )     &  &     ( other . covariances . get ( fieldName )  . contaiey ( cFieldName )  )  )     {", "newVal    +  =     ( other . covariances . get ( fieldName )  . get ( cFieldName )  )     +     (  ( f    *    dR )     *     ( deltas . get ( cFieldName )  )  )  ;", "} else    {", "newVal    +  =     ( other . covariances . get ( cFieldName )  . get ( fieldName )  )     +     (  ( f    *    dR )     *     ( deltas . get ( cFieldName )  )  )  ;", "}", "cFieldVals . put ( cFieldName ,    newVal )  ;", "}", "covariances . put ( fieldName ,    cFieldVals )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["mergeCovariance"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.RunningStats"}, {"methodBody": ["METHOD_START", "{", "ArrayList < String >    cFieldNames    =    new   ArrayList <  >  ( Arrays . asList ( fieldNames )  )  ;", "String   fieldName ;", "double   dR ;", "double   newVal ;", "for    ( int   i    =     0  ;    i    <     ( fieldNames . length )  ;     +  + i )     {", "fieldName    =    fieldNames [ i ]  ;", "cFieldNames . remove ( fieldName )  ;", "dR    =    deltas . get ( fieldName )  ;", "HashMap < String ,    Double >    cFieldVals    =     (  ( covariances . get ( fieldName )  )     !  =    null )     ?    covariances . get ( fieldName )     :    new   HashMap <  >  (  )  ;", "for    ( String   cFieldName    :    cFieldNames )     {", "if    (  ( cFieldVals . containsKey ( cFieldName )  )     =  =    true )     {", "newVal    =     ( cFieldVals . get ( cFieldName )  )     +     (  (  (  1  .  0     /     (  ( docCount )     *     (  ( docCount )     -     1  .  0  )  )  )     *    dR )     *     ( deltas . get ( cFieldName )  )  )  ;", "cFieldVals . put ( cFieldName ,    newVal )  ;", "} else    {", "cFieldVals . put ( cFieldName ,     0  .  0  )  ;", "}", "}", "if    (  ( cFieldVals . size (  )  )     >     0  )     {", "covariances . put ( fieldName ,    cFieldVals )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["updateCovariance"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.RunningStats"}, {"methodBody": ["METHOD_START", "{", "RunningStats   stats    =    new   RunningStats (  )  ;", "final   String [  ]    fieldNames    =    new   String [  2  ]  ;", "fieldNames [  0  ]     =    BaseMatrixStatsTestCase . fieldAKey ;", "fieldNames [  1  ]     =    BaseMatrixStatsTestCase . fieldBKey ;", "final   double [  ]    fieldVals    =    new   double [  2  ]  ;", "for    ( int   n    =     0  ;    n    <     ( fieldAObs . size (  )  )  ;     +  + n )     {", "fieldVals [  0  ]     =    fieldAObs . get ( n )  ;", "fieldVals [  1  ]     =    fieldBObs . get ( n )  ;", "stats . add ( fieldNames ,    fieldVals )  ;", "}", "return   stats ;", "}", "METHOD_END"], "methodName": ["createRunningStats"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.RunningStatsTests"}, {"methodBody": ["METHOD_START", "{", "int   numShards    =    randomIntBetween (  2  ,     1  0  )  ;", "double   obsPerShard    =    Math . floor (  (  ( numObs )     /    numShards )  )  ;", "int   start    =     0  ;", "stats    =    null ;", "List < Double >    fieldAShard ;", "List < Double >    fieldBShard ;", "for    ( int   s    =     0  ;    s    <     ( numShards    -     1  )  ;    start    =     (  +  + s )     *     (  ( int )     ( obsPerShard )  )  )     {", "fieldAShard    =    fieldA . subList ( start ,     ( start    +     (  ( int )     ( obsPerShard )  )  )  )  ;", "fieldBShard    =    fieldB . subList ( start ,     ( start    +     (  ( int )     ( obsPerShard )  )  )  )  ;", "if    ( stats    =  =    null )     {", "stats    =    create ( fieldAShard ,    fieldBShard )  ;", "} else    {", "stats . merge ( create ( fieldAShard ,    fieldBShard )  )  ;", "}", "}", "stats . merge ( create ( fieldA . subList ( start ,    fieldA . size (  )  )  ,    fieldB . subList ( start ,    fieldB . size (  )  )  )  )  ;", "final   MatrixStatsResults   results    =    new   MatrixStatsResults ( stats )  ;", "actualStats . assertNearlyEqual ( results )  ;", "}", "METHOD_END"], "methodName": ["testMergedStats"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.RunningStatsTests"}, {"methodBody": ["METHOD_START", "{", "final   MatrixStatsResults   results    =    new   MatrixStatsResults ( createRunningStats ( fieldA ,    fieldB )  )  ;", "actualStats . assertNearlyEqual ( results )  ;", "}", "METHOD_END"], "methodName": ["testRunningStats"], "fileName": "org.elasticsearch.search.aggregations.matrix.stats.RunningStatsTests"}, {"methodBody": ["METHOD_START", "{", "return   this . names ;", "}", "METHOD_END"], "methodName": ["fieldNames"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSource"}, {"methodBody": ["METHOD_START", "{", "boolean   needsScores    =    false ;", "for    (    value    :    values )     {", "needsScores    |  =    value . needsScores (  )  ;", "}", "return   needsScores ;", "}", "METHOD_END"], "methodName": ["needsScores"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSource"}, {"methodBody": ["METHOD_START", "{", "ValueType   valueType    =     (  ( this . valueType )     !  =    null )     ?    this . valueType    :    targetValueType ;", "if    ( field    =  =    null )     {", "if    ( script    =  =    null )     {", "ValuesSourceConfig < VS >    config    =    new   ValuesSourceConfig ( ValuesSourceType . ANY )  ;", "return   config . format (  . resolveFormat ( null ,    valueType )  )  ;", "}", "ValuesSourceType   valuesSourceType    =     ( valueType    !  =    null )     ?    valueType . getValuesSourceType (  )     :    this . valuesSourceType ;", "if    (  ( valuesSourceType    =  =    null )     |  |     ( valuesSourceType    =  =     ( ValuesSourceType . ANY )  )  )     {", "valuesSourceType    =    ValuesSourceType . BYTES ;", "}", "ValuesSourceConfig < VS >    config    =    new   ValuesSourceConfig ( valuesSourceType )  ;", "config . missing ( missingMap . get ( field )  )  ;", "return   config . format (  . resolveFormat ( format ,    valueType )  )  ;", "}", "MappedFieldType   fieldType    =    context . smartNameFieldType ( field )  ;", "if    ( fieldType    =  =    null )     {", "ValuesSourceType   valuesSourceType    =     ( valueType    !  =    null )     ?    valueType . getValuesSourceType (  )     :    this . valuesSourceType ;", "ValuesSourceConfig < VS >    config    =    new   ValuesSourceConfig ( valuesSourceType )  ;", "config . missing ( missingMap . get ( field )  )  ;", "config . format (  . resolveFormat ( format ,    valueType )  )  ;", "return   config . unmapped ( true )  ;", "}", "IndexFieldData <  ?  >    indexFieldData    =    context . getForField ( fieldType )  ;", "ValuesSourceConfig < VS >    config ;", "if    (  ( valuesSourceType )     =  =     ( ValuesSourceType . ANY )  )     {", "if    ( indexFieldData   instanceof   IndexNumericFieldData )     {", "config    =    new   ValuesSourceConfig ( ValuesSourceType . NUMERIC )  ;", "} else", "if    ( indexFieldData   instanceof   IndexGeoPointFieldData )     {", "config    =    new   ValuesSourceConfig ( ValuesSourceType . GEOPOINT )  ;", "} else    {", "config    =    new   ValuesSourceConfig ( ValuesSourceType . BYTES )  ;", "}", "} else    {", "config    =    new   ValuesSourceConfig ( valuesSourceType )  ;", "}", "config . fieldContext ( new   FieldContext ( field ,    indexFieldData ,    fieldType )  )  ;", "config . missing ( missingMap . get ( field )  )  ;", "return   config . format ( fieldType . docValueFormat ( format ,    null )  )  ;", "}", "METHOD_END"], "methodName": ["config"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "return   fields ;", "}", "METHOD_END"], "methodName": ["fields"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "if    ( fields    =  =    null )     {", "throw   new   IllegalArgumentExcep (  (  (  \"  [ field ]    must   not   be   null :     [  \"     +     ( name )  )     +     \"  ]  \"  )  )  ;", "}", "this . fields    =    fields ;", "return    (  ( AB )     ( this )  )  ;", "}", "METHOD_END"], "methodName": ["fields"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "return   format ;", "}", "METHOD_END"], "methodName": ["format"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "if    ( format    =  =    null )     {", "throw   new   IllegalArgumentExcep (  (  (  \"  [ format ]    must   not   be   null :     [  \"     +     ( name )  )     +     \"  ]  \"  )  )  ;", "}", "this . format    =    format ;", "return    (  ( AB )     ( this )  )  ;", "}", "METHOD_END"], "methodName": ["format"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "return   missingMap ;", "}", "METHOD_END"], "methodName": ["missingMap"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "if    ( missingMap    =  =    null )     {", "throw   new   IllegalArgumentExcep (  (  (  \"  [ missing ]    must   not   be   null :     [  \"     +     ( name )  )     +     \"  ]  \"  )  )  ;", "}", "this . missingMap    =    missingMap ;", "return    (  ( AB )     ( this )  )  ;", "}", "METHOD_END"], "methodName": ["missingMap"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "fields    =     (  ( ArrayList < String >  )     ( in . readGenericValue (  )  )  )  ;", "valueType    =    in . readOptionalWriteable ( ValueType :  : readFromStream )  ;", "format    =    in . readOptionalString (  )  ;", "missingMap    =    in . readMap (  )  ;", "}", "METHOD_END"], "methodName": ["read"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "HashMap < String ,    ValuesSourceConfig < VS >  >    configs    =    new   HashMap <  >  (  )  ;", "for    ( String   field    :    fields )     {", "ValuesSourceConfig < VS >    config    =    config ( context ,    field ,    null )  ;", "configs . put ( field ,    config )  ;", "}", "return   configs ;", "}", "METHOD_END"], "methodName": ["resolveConfig"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "if    ( valueType    =  =    null )     {", "return   DocFormat . RAW ;", "}", "DocFormat   valueFormat    =    valueType . defaultFormat (  )  ;", "if    (  ( valueFormat   instanceof   DocFormat . Decimal )     &  &     ( format    !  =    null )  )     {", "valueFormat    =    new   DocFormat . Decimal ( format )  ;", "}", "return   valueFormat ;", "}", "METHOD_END"], "methodName": ["resolveFormat"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "return   false ;", "}", "METHOD_END"], "methodName": ["serializeTargetValueType"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "return   valueType ;", "}", "METHOD_END"], "methodName": ["valueType"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "if    ( valueType    =  =    null )     {", "throw   new   IllegalArgumentException (  (  (  \"  [ valueType ]    must   not   be   null :     [  \"     +     ( name )  )     +     \"  ]  \"  )  )  ;", "}", "this . valueType    =    valueType ;", "return    (  ( AB )     ( this )  )  ;", "}", "METHOD_END"], "methodName": ["valueType"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceAggregationBuilder"}, {"methodBody": ["METHOD_START", "{", "XContentParser . Token   token    =    parser . currentToken (  )  ;", "if    ( token    =  =    null )     {", "token    =    parser . nextToken (  )  ;", "}", "if    ( token    =  =     ( Token . FIELD _ NAME )  )     {", "final   String   fieldName    =    parser . currentName (  )  ;", "if    ( missing . containsKey ( fieldName )  )     {", "throw   new   common . ParsingException ( parser . getTokenLocation (  )  ,     (  (  (  (  (  (  \" Missing   field    [  \"     +    fieldName )     +     \"  ]    already   defined   as    [  \"  )     +     ( missing . get ( fieldName )  )  )     +     \"  ]    in    [  \"  )     +    aggregationName )     +     \"  ]  .  \"  )  )  ;", "}", "parser . nextToken (  )  ;", "missing . put ( fieldName ,    parser . objectText (  )  )  ;", "} else    {", "throw   new   common . ParsingException ( parser . getTokenLocation (  )  ,     (  (  (  (  (  (  \" Unexpected   token    \"     +    token )     +     \"     [  \"  )     +    currentFieldName )     +     \"  ]    in    [  \"  )     +    aggregationName )     +     \"  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["parseMissingAndAdd"], "fileName": "org.elasticsearch.search.aggregations.support.MultiValuesSourceParser"}, {"methodBody": ["METHOD_START", "{", "return   buffer . duplicate (  )  ;", "}", "METHOD_END"], "methodName": ["toByteBuf"], "fileName": "org.elasticsearch.transport.netty4.ByteBufBytesReference"}, {"methodBody": ["METHOD_START", "{", "BytesReference   bytesReference    =    newBytesReference ( randomIntBetween (  1  0  ,     (  3     *     ( PAGE _ SIZE )  )  )  )  ;", "BytesRef   bytesRef    =    BytesRef . deepCopyOf ( bytesReference . toBytesRef (  )  )  ;", "ByteBuf   channelBuffer    =    Unpooled . wrappedBuffer ( bytesRef . bytes ,    bytesRef . offset ,    bytesRef . length )  ;", "byteBufBytesReference    =    new    ( channelBuffer ,    bytesRef . length )  ;", "assertEquals ( byteBufBytesReference ,    bytesReference )  ;", "channelBuffer . readInt (  )  ;", "assertEquals ( byteBufBytesReference ,    bytesReference )  ;", "assertEquals ( bytesRef ,    byteBufBytesReference . toBytesRef (  )  )  ;", "BytesRef   unicodeBytes    =    new   BytesRef ( randomUnicodeOfCodepointLength (  1  0  0  )  )  ;", "channelBuffer    =    Unpooled . wrappedBuffer ( unicodeBytes . bytes ,    unicodeBytes . offset ,    unicodeBytes . length )  ;", "byteBufBytesReference    =    new    ( channelBuffer ,    unicodeBytes . length )  ;", "String   utf 8 ToString    =    byteBufBytesReference . utf 8 ToString (  )  ;", "channelBuffer . readInt (  )  ;", "assertEquals ( utf 8 ToString ,    byteBufBytesReference . utf 8 ToString (  )  )  ;", "}", "METHOD_END"], "methodName": ["testImmutable"], "fileName": "org.elasticsearch.transport.netty4.ByteBufBytesReferenceTests"}, {"methodBody": ["METHOD_START", "{", "BytesReference   bytesReference    =    newBytesReference ( randomIntBetween (  1  0  ,     (  3     *     ( PAGE _ SIZE )  )  )  )  ;", "BytesRef   bytesRef    =    bytesReference . toBytesRef (  )  ;", "ByteBuf   channelBuffer    =    Unpooled . wrappedBuffer ( bytesRef . bytes ,    bytesRef . offset ,    bytesRef . length )  ;", "int   numBytesToRead    =    randomIntBetween (  1  ,     5  )  ;", "for    ( int   i    =     0  ;    i    <    numBytesToRead ;    i +  +  )     {", "channelBuffer . readByte (  )  ;", "}", "BytesReference   other    =    Netty 4 Utils . toBytesReference ( channelBuffer )  ;", "BytesReference   slice    =    bytesReference . slice ( numBytesToRead ,     (  ( bytesReference . length (  )  )     -    numBytesToRead )  )  ;", "assertEquals ( other ,    slice )  ;", "assertEquals ( other . slice (  3  ,     1  )  ,    slice . slice (  3  ,     1  )  )  ;", "}", "METHOD_END"], "methodName": ["testSliceOnAdvancedBuffer"], "fileName": "org.elasticsearch.transport.netty4.ByteBufBytesReferenceTests"}, {"methodBody": ["METHOD_START", "{", "int   nBytes    =    Math . min ( available (  )  ,    n )  ;", "buffer . skipBytes ( nBytes )  ;", "return   nBytes ;", "}", "METHOD_END"], "methodName": ["skipBytes"], "fileName": "org.elasticsearch.transport.netty4.ByteBufStreamInput"}, {"methodBody": ["METHOD_START", "{", "final   int   readableBytes    =    arg . readableBytes (  )  ;", "if    ( readableBytes    =  =     0  )     {", "return   super . format ( ctx ,    eventName ,    arg )  ;", "} else", "if    ( readableBytes    >  =     2  )     {", "final   StringBuilder   sb    =    new   StringBuilder (  )  ;", "sb . append ( ctx . channel (  )  . toString (  )  )  ;", "final   int   offset    =    arg . readerIndex (  )  ;", "if    (  (  ( arg . getByte ( offset )  )     =  =     (  ( byte )     (  ' E '  )  )  )     &  &     (  ( arg . getByte (  ( offset    +     1  )  )  )     =  =     (  ( byte )     (  ' S '  )  )  )  )     {", "if    ( readableBytes    =  =     (  ( TcpHeader . MARKER _ BYTES _ SIZE )     +     ( TcpHeader . MESSAGE _ LENGTH _ SIZE )  )  )     {", "final   int   length    =    arg . getInt (  ( offset    +     ( ESLoggingHandler . MESSAGE _ LENGTH _ OFFSET )  )  )  ;", "if    ( length    =  =     ( TcpTransport . PING _ DATA _ SIZE )  )     {", "sb . append (  \"     [ ping ]  \"  )  . append (  '     '  )  . append ( eventName )  . append (  \"  :     \"  )  . append ( readableBytes )  . append (  ' B '  )  ;", "return   sb . toString (  )  ;", "}", "} else", "if    ( readableBytes    >  =     ( TcpHeader . HEADER _ SIZE )  )     {", "final   int   length    =    arg . getInt (  ( offset    +     ( ESLoggingHandler . MESSAGE _ LENGTH _ OFFSET )  )  )  ;", "final   long   requestId    =    arg . getLong (  ( offset    +     ( ESLoggingHandler . REQUEST _ ID _ OFFSET )  )  )  ;", "final   byte   status    =    arg . getByte (  ( offset    +     ( ESLoggingHandler . STATUS _ OFFSET )  )  )  ;", "final   boolean   isRequest    =    TransportStatus . isRequest ( status )  ;", "final   String   type    =     ( isRequest )     ?     \" request \"     :     \" response \"  ;", "final   String   version    =    fromId ( arg . getInt (  ( offset    +     ( ESLoggingHandler . VERSION _ ID _ OFFSET )  )  )  )  . toString (  )  ;", "sb . append (  \"     [ length :     \"  )  . append ( length )  ;", "sb . append (  \"  ,    request   id :     \"  )  . append ( requestId )  ;", "sb . append (  \"  ,    type :     \"  )  . append ( type )  ;", "sb . append (  \"  ,    version :     \"  )  . append ( version )  ;", "if    ( isRequest )     {", "final   int   remaining    =    readableBytes    -     ( ESLoggingHandler . ACTION _ OFFSET )  ;", "final   ByteBuf   slice    =    arg . slice (  ( offset    +     ( ESLoggingHandler . ACTION _ OFFSET )  )  ,    remaining )  ;", "try    ( StreamInput   in    =    in ( status ,    slice ,    remaining )  )     {", "try    ( ThreadContext   context    =    new   ThreadContext ( EMPTY )  )     {", "context . readHeaders ( in )  ;", "}", "sb . append (  \"  ,    action :     \"  )  . append ( in . readString (  )  )  ;", "}", "}", "sb . append (  '  ]  '  )  ;", "sb . append (  '     '  )  . append ( eventName )  . append (  \"  :     \"  )  . append ( readableBytes )  . append (  ' B '  )  ;", "return   sb . toString (  )  ;", "}", "}", "}", "return   super . format ( ctx ,    eventName ,    arg )  ;", "}", "METHOD_END"], "methodName": ["format"], "fileName": "org.elasticsearch.transport.netty4.ESLoggingHandler"}, {"methodBody": ["METHOD_START", "{", "final   ByteBufStreamInput   in    =    new   ByteBufStreamInput ( slice ,    remaining )  ;", "if    ( TStatus . isCompress ( status )  )     {", "final   Compressor   compressor    =    CompressorFactory . compressor ( Netty 4 Utils . toBytesReference ( slice )  )  ;", "return   compressor . streamInput ( in )  ;", "} else    {", "return   in ;", "}", "}", "METHOD_END"], "methodName": ["in"], "fileName": "org.elasticsearch.transport.netty4.ESLoggingHandler"}, {"methodBody": ["METHOD_START", "{", "super . setUp (  )  ;", "appender    =    new   MockLogAppender (  )  ;", "Loggers . addAppender ( Loggers . getLogger (  . class )  ,    appender )  ;", "appender . start (  )  ;", "}", "METHOD_END"], "methodName": ["setUp"], "fileName": "org.elasticsearch.transport.netty4.ESLoggingHandlerIT"}, {"methodBody": ["METHOD_START", "{", "Loggers . removeAppender ( Loggers . getLogger ( ESLoggingHandler . class )  ,    appender )  ;", "appender . stop (  )  ;", "super . tearDown (  )  ;", "}", "METHOD_END"], "methodName": ["tearDown"], "fileName": "org.elasticsearch.transport.netty4.ESLoggingHandlerIT"}, {"methodBody": ["METHOD_START", "{", "final   String   writePattern    =     \"  .  *  \\  \\  [ length :     \\  \\ d +  \"     +     (  (  (  (  \"  ,    request   id :     \\  \\ d +  \"     +     \"  ,    type :    request \"  )     +     \"  ,    version :     .  *  \"  )     +     \"  ,    action :    cluster : monitor / nodes / hot _ threads \\  \\  [ n \\  \\  ]  \\  \\  ]  \"  )     +     \"    WRITE :     \\  \\ d + B \"  )  ;", "final   MockLogAppender . LoggingExpectation   writeExpectation    =    new   MockLogAppender . PatternSeenEventExcpectation (  \" hot   threads   request \"  ,     . class . getCanonicalName (  )  ,    Level . TRACE ,    writePattern )  ;", "final   MockLogAppender . LoggingExpectation   flushExpectation    =    new   MockLogAppender . SeenEventExpectation (  \" flush \"  ,     . class . getCanonicalName (  )  ,    Level . TRACE ,     \"  * FLUSH *  \"  )  ;", "final   String   readPattern    =     \"  .  *  \\  \\  [ length :     \\  \\ d +  \"     +     (  (  (  (  \"  ,    request   id :     \\  \\ d +  \"     +     \"  ,    type :    request \"  )     +     \"  ,    version :     .  *  \"  )     +     \"  ,    action :    cluster : monitor / nodes / hot _ threads \\  \\  [ n \\  \\  ]  \\  \\  ]  \"  )     +     \"    READ :     \\  \\ d + B \"  )  ;", "final   MockLogAppender . LoggingExpectation   readExpectation    =    new   MockLogAppender . PatternSeenEventExcpectation (  \" hot   threads   request \"  ,     . class . getCanonicalName (  )  ,    Level . TRACE ,    readPattern )  ;", "appender . addExpectation ( writeExpectation )  ;", "appender . addExpectation ( flushExpectation )  ;", "appender . addExpectation ( readExpectation )  ;", "client (  )  . admin (  )  . cluster (  )  . nodesHotThreads ( new   NodesHotThreadsRequest (  )  )  . actionGet (  )  ;", "appender . assertAllExpectationsMatched (  )  ;", "}", "METHOD_END"], "methodName": ["testLoggingHandler"], "fileName": "org.elasticsearch.transport.netty4.ESLoggingHandlerIT"}, {"methodBody": ["METHOD_START", "{", "return   openChannelsMetric . count (  )  ;", "}", "METHOD_END"], "methodName": ["numberOfOpenChannels"], "fileName": "org.elasticsearch.transport.netty4.Netty4OpenChannelsHandler"}, {"methodBody": ["METHOD_START", "{", "return   totalChannelsMetric . count (  )  ;", "}", "METHOD_END"], "methodName": ["totalChannels"], "fileName": "org.elasticsearch.transport.netty4.Netty4OpenChannelsHandler"}, {"methodBody": ["METHOD_START", "{", "ThreadPool   threadPool    =    new   TestThreadPool ( getClass (  )  . getName (  )  )  ;", "Settings   settings    =    Settings . builder (  )  . put ( PING _ SCHEDULE . getKey (  )  ,     \"  5 ms \"  )  . put ( PORT . getKey (  )  ,     0  )  . put (  \" cluster . name \"  ,     \" test \"  )  . build (  )  ;", "CircuitBreakerService   circuitBreakerService    =    new   NoneCircuitBreakerService (  )  ;", "NamedWriteableRegistry   registry    =    new   NamedWriteableRegistry ( Collections . emptyList (  )  )  ;", "final   Netty 4 Transport   nettyA    =    new   Netty 4 Transport ( settings ,    threadPool ,    new   NetworkService ( Collections . emptyList (  )  )  ,    BigArrays . NON _ RECYCLING _ INSTANCE ,    registry ,    circuitBreakerService )  ;", "MockTransportService   serviceA    =    new   MockTransportService ( settings ,    nettyA ,    threadPool ,    TransportService . NOOP _ TRANSPORT _ INTERCEPTOR ,    null )  ;", "serviceA . start (  )  ;", "serviceA . acceptIncomingRequests (  )  ;", "final   Netty 4 Transport   nettyB    =    new   Netty 4 Transport ( settings ,    threadPool ,    new   NetworkService ( Collections . emptyList (  )  )  ,    BigArrays . NON _ RECYCLING _ INSTANCE ,    registry ,    circuitBreakerService )  ;", "MockTransportService   serviceB    =    new   MockTransportService ( settings ,    nettyB ,    threadPool ,    TransportService . NOOP _ TRANSPORT _ INTERCEPTOR ,    null )  ;", "serviceB . start (  )  ;", "serviceB . acceptIncomingRequests (  )  ;", "DiscoveryNode   nodeA    =    serviceA . getLocalDiscoNode (  )  ;", "DiscoveryNode   nodeB    =    serviceB . getLocalDiscoNode (  )  ;", "serviceA . connectToNode ( nodeB )  ;", "serviceB . connectToNode ( nodeA )  ;", "assertBusy (  (  )     -  >     {", "assertThat ( nettyA . getPing (  )  . getSuccessfulPings (  )  ,    greaterThan (  1  0  0 L )  )  ;", "assertThat ( nettyB . getPing (  )  . getSuccessfulPings (  )  ,    greaterThan (  1  0  0 L )  )  ;", "}  )  ;", "assertThat ( nettyA . getPing (  )  . getFailedPings (  )  ,    equalTo (  0 L )  )  ;", "assertThat ( nettyB . getPing (  )  . getFailedPings (  )  ,    equalTo (  0 L )  )  ;", "serviceA . registerRequestHandler (  \" sayHello \"  ,    TransportRequest . Empty :  : new ,    GENERIC ,    new   TransportRequestHandler < TransportRequest . Empty >  (  )     {", "@ Override", "public   void   messageReceived ( TransportRequest . Empty   request ,    TransportChannel   channel )     {", "try    {", "channel . sendResponse ( INSTANCE ,    EMPTY )  ;", "}    catch    ( IOException   e )     {", "logger . error (  \" Unexpected   failure \"  ,    e )  ;", "fail ( e . getMessage (  )  )  ;", "}", "}", "}  )  ;", "int   rounds    =    scaledRandomIntBetween (  1  0  0  ,     5  0  0  0  )  ;", "for    ( int   i    =     0  ;    i    <    rounds ;    i +  +  )     {", "serviceB . submitRequest ( nodeA ,     \" sayHello \"  ,    TransportRequest . Empty . INSTANCE ,    TransportRequestOptions . builder (  )  . withCompress ( randomBoolean (  )  )  . build (  )  ,    new   TransportResponseHandler < TransportResponse . Empty >  (  )     {", "@ Override", "public   Empty   newInstance (  )     {", "return   Empty . INSTANCE ;", "}", "@ Override", "public   String   executor (  )     {", "return   Names . GENERIC ;", "}", "@ Override", "public   void   handleResponse ( TransportResponse . Empty   response )     {", "}", "@ Override", "public   void   handleException ( TransportException   exp )     {", "logger . error (  \" Unexpected   failure \"  ,    exp )  ;", "fail (  (  \" got   exception   instead   of   a   response :     \"     +     ( exp . getMessage (  )  )  )  )  ;", "}", "}  )  . txGet (  )  ;", "}", "assertBusy (  (  )     -  >     {", "assertThat ( nettyA . getPing (  )  . getSuccessfulPings (  )  ,    greaterThan (  2  0  0 L )  )  ;", "assertThat ( nettyB . getPing (  )  . getSuccessfulPings (  )  ,    greaterThan (  2  0  0 L )  )  ;", "}  )  ;", "assertThat ( nettyA . getPing (  )  . getFailedPings (  )  ,    equalTo (  0 L )  )  ;", "assertThat ( nettyB . getPing (  )  . getFailedPings (  )  ,    equalTo (  0 L )  )  ;", "Releasables . close ( serviceA ,    serviceB )  ;", "terminate ( threadPool )  ;", "}", "METHOD_END"], "methodName": ["testScheduledPing"], "fileName": "org.elasticsearch.transport.netty4.Netty4ScheduledPingTests"}, {"methodBody": ["METHOD_START", "{", "threadPool    =    new   ThreadPool ( settings )  ;", "NetworkService   networkService    =    new   NetworkService ( Collections . emptyList (  )  )  ;", "BigArrays   bigArrays    =    new   MockBigArrays ( new   MockPageCacheRecycler ( Settings . EMPTY )  ,    new   NoneCircuitBreakerService (  )  )  ;", "nettyTransport    =    new   Netty 4 Transport ( settings ,    threadPool ,    networkService ,    bigArrays ,    new   NamedWriteableRegistry ( Collections . emptyList (  )  )  ,    new   NoneCircuitBreakerService (  )  )  ;", "nettyTransport . start (  )  ;", "TransportAddress [  ]    boundAddresses    =    nettyTransport . boundAddress (  )  . boundAddresses (  )  ;", "TransportAddress   transportAddress    =     (  ( TransportAddress )     ( randomFrom ( boundAddresses )  )  )  ;", "port    =    transportAddress . address (  )  . getPort (  )  ;", "host    =    transportAddress . address (  )  . getAddress (  )  ;", "}", "METHOD_END"], "methodName": ["startThreadPool"], "fileName": "org.elasticsearch.transport.netty4.Netty4SizeHeaderFrameDecoderTests"}, {"methodBody": ["METHOD_START", "{", "nettyTransport . stop (  )  ;", "terminate ( threadPool )  ;", "threadPool    =    null ;", "}", "METHOD_END"], "methodName": ["terminateThreadPool"], "fileName": "org.elasticsearch.transport.netty4.Netty4SizeHeaderFrameDecoderTests"}, {"methodBody": ["METHOD_START", "{", "try    ( Socket   socket    =    new   MockSocket ( host ,    port )  )     {", "socket . getOutputStream (  )  . write (  \" FOOBAR \"  . getBytes ( StandardCharsets . UTF _  8  )  )  ;", "socket . getOutputStream (  )  . flush (  )  ;", "assertThat ( socket . getInputStream (  )  . read (  )  ,    is (  (  -  1  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatNothingIsReturnedForOtherInvalidPackets"], "fileName": "org.elasticsearch.transport.netty4.Netty4SizeHeaderFrameDecoderTests"}, {"methodBody": ["METHOD_START", "{", "String   randomMethod    =    randomFrom (  \" GET \"  ,     \" POST \"  ,     \" PUT \"  ,     \" DELETE \"  ,     \" HEAD \"  ,     \" OPTIONS \"  ,     \" PATCH \"  )  ;", "String   data    =    randomMethod    +     \"     /    HTTP /  1  .  1  \"  ;", "try    ( Socket   socket    =    new   MockSocket ( host ,    port )  )     {", "socket . getOutputStream (  )  . write ( data . getBytes ( StandardCharsets . UTF _  8  )  )  ;", "socket . getOutputStream (  )  . flush (  )  ;", "try    ( BufferedR   r    =    new   BufferedR ( new   InputStreamR ( socket . getInputStream (  )  ,    StandardCharsets . UTF _  8  )  )  )     {", "assertThat ( r . readLine (  )  ,    is (  \" This   is   not   a   HTTP   port \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testThatTextMessageIsReturnedOnHTTPLikeRequest"], "fileName": "org.elasticsearch.transport.netty4.Netty4SizeHeaderFrameDecoderTests"}, {"methodBody": ["METHOD_START", "{", "channel . closeFuture (  )  . addListener (  (    f )     -  >     {", "if    (  ( f . isSuccess (  )  )     =  =    false )     {", "logger . debug (  (  )     -  >    new   ParameterizedMessage (  \" exception   while   closing   channel :     {  }  \"  ,    channel )  ,    f . cause (  )  )  ;", "}", "}  )  ;", "}", "METHOD_END"], "methodName": ["addClosedExceptionLogger"], "fileName": "org.elasticsearch.transport.netty4.Netty4Transport"}, {"methodBody": ["METHOD_START", "{", "final   Bootstrap   bootstrap    =    new   Bootstrap (  )  ;", "bootstrap . group ( new   io . channel . nio . NioEventLoopGroup ( workerCount ,    daemonThreadFactory ( settings ,    TRANSPORT _ CLIENT _ BOSS _ THREAD _ NAME _ PREFIX )  )  )  ;", "bootstrap . channel ( NioSocketChannel . class )  ;", "bootstrap . handler ( getClientChannelInitializer (  )  )  ;", "bootstrap . option ( CONNECT _ TIMEOUT _ MILLIS ,    Math . toIntExact ( defaultConnectionProfile . getConnectTimeout (  )  . millis (  )  )  )  ;", "bootstrap . option ( TCP _ NODELAY ,    TCP _ NO _ DELAY . get ( settings )  )  ;", "bootstrap . option ( SO _ KEEPALIVE ,    TCP _ KEEP _ ALIVE . get ( settings )  )  ;", "final   ByteSizeValue   tcpSendBufferSize    =    TCP _ SEND _ BUFFER _ SIZE . get ( settings )  ;", "if    (  ( tcpSendBufferSize . getBytes (  )  )     >     0  )     {", "bootstrap . option ( SO _ SNDBUF ,    Math . toIntExact ( tcpSendBufferSize . getBytes (  )  )  )  ;", "}", "final   ByteSizeValue   tcpReceiveBufferSize    =    TCP _ RECEIVE _ BUFFER _ SIZE . get ( settings )  ;", "if    (  ( tcpReceiveBufferSize . getBytes (  )  )     >     0  )     {", "bootstrap . option ( SO _ RCVBUF ,    Math . toIntExact ( tcpReceiveBufferSize . getBytes (  )  )  )  ;", "}", "bootstrap . option ( RCVBUF _ ALLOCATOR ,    recvByteBufAllocator )  ;", "final   boolean   reuseAddress    =    TCP _ REUSE _ ADDRESS . get ( settings )  ;", "bootstrap . option ( SO _ REUSEADDR ,    reuseAddress )  ;", "bootstrap . validate (  )  ;", "return   bootstrap ;", "}", "METHOD_END"], "methodName": ["createBootstrap"], "fileName": "org.elasticsearch.transport.netty4.Netty4Transport"}, {"methodBody": ["METHOD_START", "{", "String   name    =    profileSettings . profileName ;", "if    ( logger . isDebugEnabled (  )  )     {", "logger . debug (  (  \" using   profile [  {  }  ]  ,    worker _ count [  {  }  ]  ,     [  {  }  ]  ,    bind _ host [  {  }  ]  ,    publish _ host [  {  }  ]  ,    compress [  {  }  ]  ,     \"     +     \" connect _ timeout [  {  }  ]  ,    connections _ per _ node [  {  }  /  {  }  /  {  }  /  {  }  /  {  }  ]  ,    receive _ predictor [  {  }  -  >  {  }  ]  \"  )  ,    name ,    workerCount ,    profileSettings . OrRange ,    profileSettings . bindHosts ,    profileSettings . publishHosts ,    compress ,    defaultConnectionProfile . getConnectTimeout (  )  ,    defaultConnectionProfile . getNumConnectionsPerType ( RECOVERY )  ,    defaultConnectionProfile . getNumConnectionsPerType ( BULK )  ,    defaultConnectionProfile . getNumConnectionsPerType ( REG )  ,    defaultConnectionProfile . getNumConnectionsPerType ( STATE )  ,    defaultConnectionProfile . getNumConnectionsPerType ( PING )  ,    receivePredictorMin ,    receivePredictorMax )  ;", "}", "final   ThreadFactory   workerFactory    =    daemonThreadFactory ( this . settings ,    TRANSPORT _ SERVER _ WORKER _ THREAD _ NAME _ PREFIX ,    name )  ;", "final   ServerBootstrap   serverBootstrap    =    new   ServerBootstrap (  )  ;", "serverBootstrap . group ( new   NioEventLoopGroup ( workerCount ,    workerFactory )  )  ;", "serverBootstrap . channel ( NioServerSocketChannel . class )  ;", "serverBootstrap . childHandler ( getServerChannelInitializer ( name )  )  ;", "serverBootstrap . childOption ( TCP _ NODELAY ,    profileSettings . tcpNoDelay )  ;", "serverBootstrap . childOption ( SO _ KEEPALIVE ,    profileSettings . tcpKeepAlive )  ;", "if    (  ( profileSettings . sendBufferSize . getBytes (  )  )     !  =     (  -  1  )  )     {", "serverBootstrap . childOption ( SO _ SNDBUF ,    Math . toIntExact ( profileSettings . sendBufferSize . getBytes (  )  )  )  ;", "}", "if    (  ( profileSettings . receiveBufferSize . getBytes (  )  )     !  =     (  -  1  )  )     {", "serverBootstrap . childOption ( SO _ RCVBUF ,    Math . toIntExact ( profileSettings . receiveBufferSize . bytesAsInt (  )  )  )  ;", "}", "serverBootstrap . option ( RCVBUF _ ALLOCATOR ,    recvByteBufAllocator )  ;", "serverBootstrap . childOption ( RCVBUF _ ALLOCATOR ,    recvByteBufAllocator )  ;", "serverBootstrap . option ( SO _ REUSEADDR ,    profileSettings . reuseAddress )  ;", "serverBootstrap . childOption ( SO _ REUSEADDR ,    profileSettings . reuseAddress )  ;", "serverBootstrap . validate (  )  ;", "serverBootstraps . put ( name ,    serverBootstrap )  ;", "}", "METHOD_END"], "methodName": ["createServerBootstrap"], "fileName": "org.elasticsearch.transport.netty4.Netty4Transport"}, {"methodBody": ["METHOD_START", "{", "final   Throwable   unwrapped    =    ExceptionsHelper . unwrap ( cause ,    ElasticsearchException . class )  ;", "final   Throwable   t    =     ( unwrapped    !  =    null )     ?    unwrapped    :    cause ;", "Channel   channel    =    ctx . channel (  )  ;", "onException ( channel . attr (  . CHANNEL _ KEY )  . get (  )  ,     ( t   instanceof   Exception    ?     (  ( Exception )     ( t )  )     :    new   ElasticsearchException ( t )  )  )  ;", "}", "METHOD_END"], "methodName": ["exceptionCaught"], "fileName": "org.elasticsearch.transport.netty4.Netty4Transport"}, {"methodBody": ["METHOD_START", "{", "return   new   Netty 4 Transport . ClientChannelInitializer (  )  ;", "}", "METHOD_END"], "methodName": ["getClientChannelInitializer"], "fileName": "org.elasticsearch.transport.netty4.Netty4Transport"}, {"methodBody": ["METHOD_START", "{", "return   scheduledPing ;", "}", "METHOD_END"], "methodName": ["getPing"], "fileName": "org.elasticsearch.transport.netty4.Netty4Transport"}, {"methodBody": ["METHOD_START", "{", "return   new   Netty 4 Transport . ServerChannelInitializer ( name )  ;", "}", "METHOD_END"], "methodName": ["getServerChannelInitializer"], "fileName": "org.elasticsearch.transport.netty4.Netty4Transport"}, {"methodBody": ["METHOD_START", "{", "Client   transportClient    =    internalCluster (  )  . transportClient (  )  ;", "ClusterHealthResponse   clusterIndexHealths    =    transportClient . admin (  )  . cluster (  )  . prepareHealth (  )  . get (  )  ;", "assertThat ( clusterIndexHealths . getStatus (  )  ,    is ( GREEN )  )  ;", "try    {", "transportClient . filterWithHeader ( Collections . singletonMap (  \" ERROR \"  ,     \" MY   MESSAGE \"  )  )  . admin (  )  . cluster (  )  . prepareHealth (  )  . get (  )  ;", "fail (  \" Expected   exception ,    but   didn ' t   happen \"  )  ;", "}    catch    ( ElasticsearchException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \" MY   MESSAGE \"  )  )  ;", "assertThat (  . channelProfileName ,    is ( DEFAULT _ PROFILE )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatConnectionFailsAsIntended"], "fileName": "org.elasticsearch.transport.netty4.Netty4TransportIT"}, {"methodBody": ["METHOD_START", "{", "NodesInfoResponse   response    =    client (  )  . admin (  )  . cluster (  )  . prepareNodesInfo (  )  . clear (  )  . setTransport ( true )  . get (  )  ;", "for    ( NodeInfo   nodeInfo    :    response . getNodes (  )  )     {", "assertThat ( nodeInfo . getTransport (  )  . getProfileAddresses (  )  . keySet (  )  ,    hasSize (  1  )  )  ;", "assertThat ( nodeInfo . getTransport (  )  . getProfileAddresses (  )  ,    hasKey (  \" client 1  \"  )  )  ;", "BoundTransportAddress   boundTransportAddress    =    nodeInfo . getTransport (  )  . getProfileAddresses (  )  . get (  \" client 1  \"  )  ;", "for    ( TransportAddress   transportAddress    :    boundTransportAddress . boundAddresses (  )  )     {", "assertThat ( transportAddress ,    instanceOf ( TransportAddress . class )  )  ;", "}", "for    ( TransportAddress   transportAddress    :    boundTransportAddress . boundAddresses (  )  )     {", "assertThat ( transportAddress ,    instanceOf ( TransportAddress . class )  )  ;", "assertThat ( transportAddress . address (  )  . getPort (  )  ,    is ( allOf ( greaterThanOrEqualTo (  . randomPort )  ,    lessThanOrEqualTo (  (  (  . randomPort )     +     1  0  )  )  )  )  )  ;", "}", "assertThat ( boundTransportAddress . publishAddress (  )  ,    instanceOf ( TransportAddress . class )  )  ;", "TransportAddress   publishAddress    =    boundTransportAddress . publishAddress (  )  ;", "assertThat ( NetworkAddress . format ( publishAddress . address (  )  . getAddress (  )  )  ,    is (  \"  1  2  7  .  0  .  0  .  7  \"  )  )  ;", "assertThat ( publishAddress . address (  )  . getPort (  )  ,    is (  4  3  2  1  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatInfosAreExposed"], "fileName": "org.elasticsearch.transport.netty4.Netty4TransportMultiPortIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" cluster . name \"  ,    internalCluster (  )  . getClusterName (  )  )  . put ( TRANSPORT _ TYPE _ KEY ,    Netty 4 Plugin . NETTY _ TRANSPORT _ NAME )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "try    ( TransportClient   transportClient    =    new   MockTransportClient ( settings ,    Netty 4 Plugin . class )  )     {", "for    ( int   i    =     0  ;    i    <  =     1  0  ;    i +  +  )     {", "transportClient . addTransportAddress ( new   TransportAddress ( InetAddress . getByName (  \"  1  2  7  .  0  .  0  .  1  \"  )  ,     (  (  . randomPort )     +    i )  )  )  ;", "}", "ClusterHealthResponse   response    =    transportClient . admin (  )  . cluster (  )  . prepareHealth (  )  . get (  )  ;", "assertThat ( response . getStatus (  )  ,    is ( GREEN )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatTransportClientCanConnect"], "fileName": "org.elasticsearch.transport.netty4.Netty4TransportMultiPortIntegrationIT"}, {"methodBody": ["METHOD_START", "{", "if    (  !  ( NetworkUtils . SUPPORTS _ V 6  )  )     {", "return ;", "}", "logger . info (  \"  -  -  >    starting   a   node   on   ipv 4    only \"  )  ;", "Settings   ipv 4 Settings    =    Settings . builder (  )  . put (  \" network . host \"  ,     \"  1  2  7  .  0  .  0  .  1  \"  )  . build (  )  ;", "String   ipv 4 OnlyNode    =    internalCluster (  )  . startNode ( ipv 4 Settings )  ;", "logger . info (  \"  -  -  >    starting   a   node   on   ipv 4    and   ipv 6  \"  )  ;", "Settings   bothSettings    =    Settings . builder (  )  . put (  \" network . host \"  ,     \"  _ local _  \"  )  . build (  )  ;", "internalCluster (  )  . startNode ( bothSettings )  ;", "logger . info (  \"  -  -  >    waiting   for   the   cluster   to   declare   itself   stable \"  )  ;", "ensureStableCluster (  2  )  ;", "logger . info (  \"  -  -  >    checking   if   boundAddress   matching   p   has   same   port \"  )  ;", "NodesInfoResponse   nodesInfoResponse    =    client (  )  . admin (  )  . cluster (  )  . prepareNodesInfo (  )  . get (  )  ;", "for    ( NodeInfo   nodeInfo    :    nodesInfoResponse . getNodes (  )  )     {", "BoundTransportAddress   boundTransportAddress    =    nodeInfo . getTransport (  )  . getAddress (  )  ;", "if    ( nodeInfo . getNode (  )  . getName (  )  . equals ( ipv 4 OnlyNode )  )     {", "assertThat ( boundTransportAddress . boundAddresses (  )  . length ,    equalTo (  1  )  )  ;", "assertThat ( boundTransportAddress . boundAddresses (  )  [  0  ]  . getPort (  )  ,    equalTo ( boundTransportAddress . p (  )  . getPort (  )  )  )  ;", "} else    {", "assertThat ( boundTransportAddress . boundAddresses (  )  . length ,    greaterThan (  1  )  )  ;", "for    ( TransportAddress   boundAddress    :    boundTransportAddress . boundAddresses (  )  )     {", "assertThat ( boundAddress ,    instanceOf ( TransportAddress . class )  )  ;", "TransportAddress   inetBoundAddress    =     (  ( TransportAddress )     ( boundAddress )  )  ;", "if    (  ( inetBoundAddress . address (  )  . getAddress (  )  )    instanceof   Inet 4 Address )     {", "assertThat ( inetBoundAddress . getPort (  )  ,    equalTo ( boundTransportAddress . p (  )  . getPort (  )  )  )  ;", "}", "}", "}", "}", "}", "METHOD_END"], "methodName": ["testDifferentPorts"], "fileName": "org.elasticsearch.transport.netty4.Netty4TransportPublishAddressIT"}, {"methodBody": ["METHOD_START", "{", "IOException   closingExceptions    =    null ;", "final   List < ChannelFuture >    futures    =    new   ArrayList <  >  (  )  ;", "for    ( final   Channel   channel    :    channels )     {", "try    {", "if    (  ( channel    !  =    null )     &  &     ( channel . isOpen (  )  )  )     {", "futures . add ( channel . close (  )  )  ;", "}", "}    catch    ( Exception   e )     {", "if    ( closingExceptions    =  =    null )     {", "closingExceptions    =    new   IOException (  \" failed   to   close   channels \"  )  ;", "}", "closingExceptions . addSuppressed ( e )  ;", "}", "}", "for    ( final   ChannelFuture   future    :    futures )     {", "future . awaitUninterruptibly (  )  ;", "}", "if    ( closingExceptions    !  =    null )     {", "throw   closingExceptions ;", "}", "}", "METHOD_END"], "methodName": ["closeChannels"], "fileName": "org.elasticsearch.transport.netty4.Netty4Utils"}, {"methodBody": ["METHOD_START", "{", "final   Logger   logger    =    ESLoggerFactory . getLogger ( Netty 4 Utils . class )  ;", "final   Optional < Error >    maybeError    =    ExceptionsHelper . maybeError ( cause ,    logger )  ;", "if    ( maybeError . isPresent (  )  )     {", "try    {", "final   String   formatted    =    ExceptionsHelper . formatStackTrace ( Thread . currentThread (  )  . getStackTrace (  )  )  ;", "logger . error (  \" fatal   error   on   the   network   layer \\ n {  }  \"  ,    formatted )  ;", "}    finally    {", "new   Thread (  (  )     -  >     {", "throw   maybeError . get (  )  ;", "}  )  . start (  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["maybeDie"], "fileName": "org.elasticsearch.transport.netty4.Netty4Utils"}, {"methodBody": ["METHOD_START", "{", "final   boolean   set    =    Booleans . parseBoolean ( System . getProperty (  \" es . set . netty . runtime . available . processors \"  ,     \" true \"  )  )  ;", "if    (  ! set )     {", "return ;", "}", "if    (  . isAvailableProcessorsSet . compareAndSet ( false ,    true )  )     {", "NettyRuntime . setAvailableProcessors ( availableProcessors )  ;", "} else", "if    ( availableProcessors    !  =     ( NettyRuntime . availableProcessors (  )  )  )     {", "final   String   message    =    String . format ( ROOT ,     \" available   processors   value    [  % d ]    did   not   match   current   value    [  % d ]  \"  ,    availableProcessors ,    NettyRuntime . availableProcessors (  )  )  ;", "throw   new   IllegalStateException ( message )  ;", "}", "}", "METHOD_END"], "methodName": ["setAvailableProcessors"], "fileName": "org.elasticsearch.transport.netty4.Netty4Utils"}, {"methodBody": ["METHOD_START", "{", "if    (  ( reference . length (  )  )     =  =     0  )     {", "return   Unpooled . EMPTY _ BUFFER ;", "}", "if    ( reference   instanceof   ByteBufBytesReference )     {", "return    (  ( ByteBufBytesReference )     ( reference )  )  . toByteBuf (  )  ;", "} else    {", "final   BytesRefIterator   iterator    =    reference . iterator (  )  ;", "final   List < ByteBuf >    buffers    = w   ArrayList <  >  (  3  )  ;", "try    {", "BytesRef   slice ;", "while    (  ( slice    =    iteratorxt (  )  )     !  =    null )     {", "buffers . add ( Unpooled . wrappedBuffer ( slice . bytes ,    slice . offset ,    slice . length )  )  ;", "}", "final   CompositeByteBuf   composite    =    Unpooled . compositeBuffer ( buffers . size (  )  )  ;", "composite . addCompnts ( true ,    buffers )  ;", "return   composite ;", "}    catch    ( IOException   ex )     {", "throww   AssertionError (  \" no   IO   happens   here \"  ,    ex )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["toByteBuf"], "fileName": "org.elasticsearch.transport.netty4.Netty4Utils"}, {"methodBody": ["METHOD_START", "{", "return   Netty 4 Utils . toBytesReference ( buffer ,    buffer . readableBytes (  )  )  ;", "}", "METHOD_END"], "methodName": ["toBytesReference"], "fileName": "org.elasticsearch.transport.netty4.Netty4Utils"}, {"methodBody": ["METHOD_START", "{", "return   new   ByteBufBytesReference ( buffer ,    size )  ;", "}", "METHOD_END"], "methodName": ["toBytesReference"], "fileName": "org.elasticsearch.transport.netty4.Netty4Utils"}, {"methodBody": ["METHOD_START", "{", "ReleasableBytesStreamOutput   out    =    new   ReleasableBytesStreamOutput ( length ,    bigarrays )  ;", "for    ( int   i    =     0  ;    i    <    length ;    i +  +  )     {", "out . writeByte (  (  ( byte )     ( random (  )  . nextInt (  (  1     <  <     8  )  )  )  )  )  ;", "}", "assertEquals ( out . size (  )  ,    length )  ;", "BytesReference   ref    =    out . bytes (  )  ;", "assertEquals ( ref . length (  )  ,    length )  ;", "if    ( randomBoolean (  )  )     {", "return   new   common . bytes . BytesArray ( ref . toBytesRef (  )  )  ;", "} else", "if    ( randomBoolean (  )  )     {", "BytesRef   bytesRef    =    ref . toBytesRef (  )  ;", "return   Netty 4 Utils . toBytesReference ( io . netty . buffer . Unpooled . wrappedBuffer ( bytesRef . bytes ,    bytesRef . offset ,    bytesRef . length )  )  ;", "} else    {", "return   ref ;", "}", "}", "METHOD_END"], "methodName": ["getRandomizedBytesReference"], "fileName": "org.elasticsearch.transport.netty4.Netty4UtilsTests"}, {"methodBody": ["METHOD_START", "{", "BytesReference   ref    =    getRandomizedBytesReference ( randomIntBetween (  1  ,     (  3     *     ( Netty 4 UtilsTests . PAGE _ SIZE )  )  )  )  ;", "ByteBuf   buffer    =    Netty 4 Utils . toByteBuf ( ref )  ;", "BytesReference   bytesReference    =    Netty 4 Utils . toBytesReference ( buffer )  ;", "if    ( ref   instanceof   ByteBufBytesReference )     {", "assertEquals ( buffer ,     (  ( ByteBufBytesReference )     ( ref )  )  . toByteBuf (  )  )  ;", "} else", "if    (  ( common . bytes . AbstractBytesReferenceTestCase . getNumPages ( ref )  )     >     1  )     {", "assertTrue (  ( buffer   instanceof   io . netty . buffer . CompositeByteBuf )  )  ;", "}", "assertArrayEquals ( BytesReference . toBytes ( ref )  ,    BytesReference . toBytes ( bytesReference )  )  ;", "}", "METHOD_END"], "methodName": ["testToChannelBuffer"], "fileName": "org.elasticsearch.transport.netty4.Netty4UtilsTests"}, {"methodBody": ["METHOD_START", "{", "ByteBuf   buffer    =    Netty 4 Utils . toByteBuf ( getRandomizedBytesReference (  0  )  )  ;", "assertSame ( EMPTY _ BUFFER ,    buffer )  ;", "}", "METHOD_END"], "methodName": ["testToChannelBufferWithEmptyRef"], "fileName": "org.elasticsearch.transport.netty4.Netty4UtilsTests"}, {"methodBody": ["METHOD_START", "{", "BytesReference   ref    =    getRandomizedBytesReference ( randomIntBetween (  1  ,     (  3     *     ( Netty 4 UtilsTests . PAGE _ SIZE )  )  )  )  ;", "int   sliceOffset    =    randomIntBetween (  0  ,    ref . length (  )  )  ;", "int   sliceLength    =    randomIntBetween (  (  ( ref . length (  )  )     -    sliceOffset )  ,     (  ( ref . length (  )  )     -    sliceOffset )  )  ;", "BytesReference   slice    =    ref . slice ( sliceOffset ,    sliceLength )  ;", "ByteBuf   buffer    =    Netty 4 Utils . toByteBuf ( slice )  ;", "BytesReference   bytesReference    =    Netty 4 Utils . toBytesReference ( buffer )  ;", "assertArrayEquals ( BytesReference . toBytes ( slice )  ,    BytesReference . toBytes ( bytesReference )  )  ;", "}", "METHOD_END"], "methodName": ["testToChannelBufferWithSlice"], "fileName": "org.elasticsearch.transport.netty4.Netty4UtilsTests"}, {"methodBody": ["METHOD_START", "{", "BytesReference   ref    =    getRandomizedBytesReference ( randomIntBetween (  1  ,     (  3     *     ( Netty 4 UtilsTests . PAGE _ SIZE )  )  )  )  ;", "int   sliceOffset    =    randomIntBetween (  0  ,    ref . length (  )  )  ;", "int   sliceLength    =    randomIntBetween (  (  ( ref . length (  )  )     -    sliceOffset )  ,     (  ( ref . length (  )  )     -    sliceOffset )  )  ;", "ByteBuf   buffer    =    Netty 4 Utils . toByteBuf ( ref )  ;", "BytesReference   bytesReference    =    Netty 4 Utils . toBytesReference ( buffer )  ;", "assertArrayEquals ( BytesReference . toBytes ( ref . slice ( sliceOffset ,    sliceLength )  )  ,    BytesReference . toBytes ( bytesReference . slice ( sliceOffset ,    sliceLength )  )  )  ;", "}", "METHOD_END"], "methodName": ["testToChannelBufferWithSliceAfter"], "fileName": "org.elasticsearch.transport.netty4.Netty4UtilsTests"}, {"methodBody": ["METHOD_START", "{", "return   channel ;", "}", "METHOD_END"], "methodName": ["getLowLevelChannel"], "fileName": "org.elasticsearch.transport.netty4.NettyTcpChannel"}, {"methodBody": ["METHOD_START", "{", "if    (  ( NetworkUtils . SUPPORTS _ V 6  )     &  &     ( randomBoolean (  )  )  )     {", "host    =     \"  :  :  1  \"  ;", "} else    {", "host    =     \"  1  2  7  .  0  .  0  .  1  \"  ;", "}", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.transport.netty4.NettyTransportMultiPortTests"}, {"methodBody": ["METHOD_START", "{", "BigArrays   bigArrays    =    new   MockBigArrays ( new   MockPageCacheRecycler ( Settings . EMPTY )  ,    new   NoneCircuitBreakerService (  )  )  ;", "TcpTransport   transport    =    new   Netty 4 Transport ( settings ,    threadPool ,    new   NetworkService ( Collections . emptyList (  )  )  ,    bigArrays ,    new   NamedWriteableRegistry ( Collections . emptyList (  )  )  ,    new   NoneCircuitBreakerService (  )  )  ;", "transport . start (  )  ;", "assertThat ( transport . lifecycleState (  )  ,    is ( STARTED )  )  ;", "return   transport ;", "}", "METHOD_END"], "methodName": ["startTransport"], "fileName": "org.elasticsearch.transport.netty4.NettyTransportMultiPortTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" network . host \"  ,    host )  . put ( PORT . getKey (  )  ,     0  )  . put (  \" transport . profiles . client 1  . port \"  ,     0  )  . build (  )  ;", "ThreadPool   threadPool    =    new   TestThreadPool (  \" tst \"  )  ;", "try    ( TcpTransport   transport    =    startTransport ( settings ,    threadPool )  )     {", "assertEquals (  1  ,    transport . profileBoundAddresses (  )  . size (  )  )  ;", "assertEquals (  1  ,    transport . boundAddress (  )  . boundAddresses (  )  . length )  ;", "}    finally    {", "terminate ( threadPool )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatDefaultProfileInheritsFromStandardSettings"], "fileName": "org.elasticsearch.transport.netty4.NettyTransportMultiPortTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" network . host \"  ,    host )  . put ( PORT . getKey (  )  ,     2  2  )  . put (  \" transport . profiles . default . port \"  ,     0  )  . build (  )  ;", "ThreadPool   threadPool    =    new   TestThreadPool (  \" tst \"  )  ;", "try    ( TcpTransport   transport    =    startTransport ( settings ,    threadPool )  )     {", "assertEquals (  0  ,    transport . profileBoundAddresses (  )  . size (  )  )  ;", "assertEquals (  1  ,    transport . boundAddress (  )  . boundAddresses (  )  . length )  ;", "}    finally    {", "terminate ( threadPool )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatDefaultProfilePortOverridesGeneralConfiguration"], "fileName": "org.elasticsearch.transport.netty4.NettyTransportMultiPortTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" network . host \"  ,    host )  . put ( PORT . getKey (  )  ,     2  2  )  . put (  \" transport . profiles . default . port \"  ,     0  )  . put (  \" transport . profiles . client 1  . port \"  ,     0  )  . build (  )  ;", "ThreadPool   threadPool    =    new   TestThreadPool (  \" tst \"  )  ;", "try    ( TcpTransport   transport    =    startTransport ( settings ,    threadPool )  )     {", "assertEquals (  1  ,    transport . profileBoundAddresses (  )  . size (  )  )  ;", "assertEquals (  1  ,    transport . boundAddress (  )  . boundAddresses (  )  . length )  ;", "}    finally    {", "terminate ( threadPool )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatNettyCanBindToMultiplePorts"], "fileName": "org.elasticsearch.transport.netty4.NettyTransportMultiPortTests"}, {"methodBody": ["METHOD_START", "{", "Settings   settings    =    Settings . builder (  )  . put (  \" network . host \"  ,    host )  . put ( PORT . getKey (  )  ,     0  )  . put (  \" transport . profiles . client 1  . whatever \"  ,     \" foo \"  )  . build (  )  ;", "ThreadPool   threadPool    =    new   TestThreadPool (  \" tst \"  )  ;", "try    {", "IllegalStateException   ex    =    expectThrows ( IllegalStateException . class ,     (  )     -  >    startTransport ( settings ,    threadPool )  )  ;", "assertEquals (  \" profile    [ client 1  ]    has   no   port   configured \"  ,    ex . getMessage (  )  )  ;", "}    finally    {", "terminate ( threadPool )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatProfileWithoutPortSettingsFails"], "fileName": "org.elasticsearch.transport.netty4.NettyTransportMultiPortTests"}, {"methodBody": ["METHOD_START", "{", "NamedWriteableRegistry   namedWriteableRegistry    =    new   NamedWriteableRegistry ( Collections . emptyList (  )  )  ;", "Transport   transport    =    new    ( settings ,    threadPool ,    new   NetworkService ( Collections . emptyList (  )  )  ,    BigArrays . NON _ RECYCLING _ INSTANCE ,    namedWriteableRegistry ,    new   NoneCircuitBreakerService (  )  )     {", "@ Override", "protected   Version   executeHandshake ( DiscoveryNode   node ,    TcpChannel   channel ,    TimeValue   timeout )    throws   IOException ,    InterruptedException    {", "if    ( doHandshake )     {", "return   super . executeHandshake ( node ,    channel ,    timeout )  ;", "} else    {", "return   version . minimumCompatibilityVersion (  )  ;", "}", "}", "@ Override", "protected   Version   getCurrentVersion (  )     {", "return   version ;", "}", "}  ;", "MockTransportService   mockTransportService    =    MockTransportService . createNewService ( EMPTY ,    transport ,    version ,    threadPool ,    clusterSettings ,    Collections . emptySet (  )  )  ;", "mockTransportService . start (  )  ;", "return   mockTransportService ;", "}", "METHOD_END"], "methodName": ["nettyFromThreadPool"], "fileName": "org.elasticsearch.transport.netty4.SimpleNetty4TransportTests"}, {"methodBody": ["METHOD_START", "{", "int   port    =    serviceA . boundAddress (  )  . publishAddress (  )  . getPort (  )  ;", "Settings   settings    =    Settings . builder (  )  . put ( NODE _ NAME _ SETTING . getKey (  )  ,     \" foobar \"  )  . put ( TRACE _ LOG _ INCLUDE _ SETTING . getKey (  )  ,     \"  \"  )  . put ( TRACE _ LOG _ EXCLUDE _ SETTING . getKey (  )  ,     \" NOTHING \"  )  . put (  \" tcp . port \"  ,    port )  . build (  )  ;", "ClusterSettings   clusterSettings    =    new   ClusterSettings ( settings ,    ClusterSettings . BUILT _ IN _ CLUSTER _ SETTINGS )  ;", "BindTransportException   bindTransportException    =    expectThrows ( BindTransportException . class ,     (  )     -  >     {", "MockTransportService   ervice    =    nettyFromThreadPool ( settings ,    threadPool ,    Version . CURRENT ,    clusterSettings ,    true )  ;", "try    {", "ervice . start (  )  ;", "}    finally    {", "ervice . stop (  )  ;", "ervice . close (  )  ;", "}", "}  )  ;", "assertEquals (  (  (  \" Failed   to   bind   to    [  \"     +    port )     +     \"  ]  \"  )  ,    bindTransportException . getMessage (  )  )  ;", "}", "METHOD_END"], "methodName": ["testBindUnavailableAddress"], "fileName": "org.elasticsearch.transport.netty4.SimpleNetty4TransportTests"}, {"methodBody": ["METHOD_START", "{", "try    {", "serviceA . connectToNode ( new   cluster . node . DiscoveryNode (  \" C \"  ,    new   TransportAddress ( InetAddress . getByName (  \" localhost \"  )  ,     9  8  7  6  )  ,    Collections . emptyMap (  )  ,    Collections . emptySet (  )  ,    Version . CURRENT )  )  ;", "fail (  \" Expected   ConnectTransportException \"  )  ;", "}    catch    ( ConnectTransportException   e )     {", "assertThat ( e . getMessage (  )  ,    containsString (  \" connect _ exception \"  )  )  ;", "assertThat ( e . getMessage (  )  ,    containsString (  \"  [  1  2  7  .  0  .  0  .  1  :  9  8  7  6  ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConnectException"], "fileName": "org.elasticsearch.transport.netty4.SimpleNetty4TransportTests"}]