[{"methodBody": ["METHOD_START", "{", "final   Response   response    =    client (  )  . performRequest (  \" GET \"  ,     ( index    +     \"  /  _ count \"  )  ,    Collections . singletonMap (  \" preference \"  ,    preference )  )  ;", "assertOK ( response )  ;", "final   int   actualCount    =    Integer . parseInt ( ObjectPath . createFromResponse ( response )  . evaluate (  \" count \"  )  . toString (  )  )  ;", "assertThat ( actualCount ,    equalTo ( expectedCount )  )  ;", "}", "METHOD_END"], "methodName": ["assertCount"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "assertBusy (  (  )     -  >     {", "try    {", "List < Shard >    sh =    buildShindex ,    nodes ,    client )  ;", "Shard   primaryShard    =    shstream (  )  . filter ( Shard :  : isPrimary )  . findFirst (  )  . get (  )  ;", "assertNotNull (  \" failed   to   find   primary   shard \"  ,    primaryShard )  ;", "final   long   expectedGlobalCkp    =    numDocs    -     1  ;", "final   long   expectMaxSeqNo    =    numDocs    -     1  ;", "logger . info (  \" primary   resolved   to   node    {  }  \"  ,    primaryShard . getNode (  )  )  ;", "for    ( Shard   shard    :    sh    {", "final   SeqNoStats   seqNoStats    =    shard . getSeqNoStats (  )  ;", "logger . info (  \" stats   for    {  }  ,    primary    [  {  }  ]  :     [  {  }  ]  \"  ,    shard . getNode (  )  ,    shard . isPrimary (  )  ,    seqNoStats )  ;", "assertThat (  (  (  \" max _ seq   no   on    \"     +     ( shard . getNode (  )  )  )     +     \"    is   wrong \"  )  ,    seqNoStats . getMaxSeqNo (  )  ,    equalTo ( expectMaxSeqNo )  )  ;", "assertThat (  (  (  \" localCheckpoint   no   on    \"     +     ( shard . getNode (  )  )  )     +     \"    is   wrong \"  )  ,    seqNoStats . getLocalCheckpoint (  )  ,    equalTo ( expectMaxSeqNo )  )  ;", "assertThat (  (  (  \" globalCheckpoint   no   on    \"     +     ( shard . getNode (  )  )  )     +     \"    is   wrong \"  )  ,    seqNoStats . getGlobalCheckpoint (  )  ,    equalTo ( expectedGlobalCkp )  )  ;", "}", "}    catch    (    e )     {", "throw   new    < e > AssertionError (  \" unexpected   io   exception \"  )  ;", "}", "}  )  ;", "}", "METHOD_END"], "methodName": ["assertSeqNoOnShards"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "final   Response   response    =    client (  )  . performRequest (  \" GET \"  ,     (  ( index    +     \"  / test /  \"  )     +    docId )  ,    Collections . singletonMap (  \" preference \"  ,    preference )  )  ;", "assertOK ( response )  ;", "final   int   actualVersion    =    Integer . parseInt ( ObjectPath . createFromResponse ( response )  . evaluate (  \"  _ version \"  )  . toString (  )  )  ;", "assertThat (  (  (  (  (  \" version   mismatch   for   doc    [  \"     +    docId )     +     \"  ]    preference    [  \"  )     +    preference )     +     \"  ]  \"  )  ,    actualVersion ,    equalTo ( expectedVersion )  )  ;", "}", "METHOD_END"], "methodName": ["assertVersion"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "Response   response    =    client (  )  . performRequest (  \" GET \"  ,     \"  _ nodes \"  )  ;", "ObjectPath   objectPath    =    ObjectPath . createFromResponse ( response )  ;", "Map < String ,    Object >    nodesAsMap    =    objectPath . evaluate (  \" nodes \"  )  ;", ". Nodes   nodes    =    new    . Nodes (  )  ;", "for    ( String   id    :    nodesAsMap . keySet (  )  )     {", "nodes . add ( new    . Node ( id ,    objectPath . evaluate (  (  (  \" nodes .  \"     +    id )     +     \"  . name \"  )  )  ,    Version . fromString ( objectPath . evaluate (  (  (  \" nodes .  \"     +    id )     +     \"  . version \"  )  )  )  ,    HttpHost . create ( objectPath . evaluate (  (  (  \" nodes .  \"     +    id )     +     \"  . http . publish _ address \"  )  )  )  )  )  ;", "}", "response    =    client (  )  . performRequest (  \" GET \"  ,     \"  _ cluster / state \"  )  ;", "nodes . setMasterNodeId ( ObjectPath . createFromResponse ( response )  . evaluate (  \" master _ node \"  )  )  ;", "return   nodes ;", "}", "METHOD_END"], "methodName": ["buildNodeAndVersions"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "Response   response    =    client . performRequest (  \" GET \"  ,     ( index    +     \"  /  _ stats \"  )  ,    Collections . singletonMap (  \" level \"  ,     \" shards \"  )  )  ;", "List < Object >    shardStats    =    ObjectPath . createFromResponse ( response )  . evaluate (  (  (  \" indices .  \"     +    index )     +     \"  . shards .  0  \"  )  )  ;", "ArrayList <  . Shard >    shards    =    new   ArrayList <  >  (  )  ;", "for    ( Object   shard    :    shardStats )     {", "final   String   nodeId    =    ObjectPath . evaluate ( shard ,     \" routing . node \"  )  ;", "final   Boolean   primary    =    ObjectPath . evaluate ( shard ,     \" routing . primary \"  )  ;", "final    . Node   node    =    nodes . getSafe ( nodeId )  ;", "final   SeqNoStats   seqNoStats ;", "Integer   maxSeqNo    =    ObjectPath . evaluate ( shard ,     \" seq _ no . max _ seq _ no \"  )  ;", "Integer   localCheckpoint    =    ObjectPath . evaluate ( shard ,     \" seq _ no . local _ checkpoint \"  )  ;", "Integer   globalCheckpoint    =    ObjectPath . evaluate ( shard ,     \" seq _ no . global _ checkpoint \"  )  ;", "seqNoStats    =    new   SeqNoStats ( maxSeqNo ,    localCheckpoint ,    globalCheckpoint )  ;", "shards . add ( new    . Shard ( node ,    primary ,    seqNoStats )  )  ;", "}", "return   shards ;", "}", "METHOD_END"], "methodName": ["buildShards"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "indexDocs ( index ,    docId ,     1  )  ;", "Thread [  ]    indexThreads    =    new   Thread [ nUpdates ]  ;", "for    ( int   i    =     0  ;    i    <    nUpdates ;    i +  +  )     {", "indexThreads [ i ]     =    new   Thread (  (  )     -  >     {", "try    {", "indexDocs ( index ,    docId ,     1  )  ;", "}    catch    ( IOException   e )     {", "throw   new   AssertionError (  (  (  \" failed   while   i    [  \"     +     ( e . getMessage (  )  )  )     +     \"  ]  \"  )  )  ;", "}", "}  )  ;", "indexThreads [ i ]  . start (  )  ;", "}", "for    ( Thread   indexThread    :    indexThreads )     {", "indexThread . join (  )  ;", "}", "return   nUpdates    +     1  ;", "}", "METHOD_END"], "methodName": ["indexDocWithConcurrentUpdates"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "final   int   id    =    idStart    +    i ;", "assertOK ( client (  )  . performRequest (  \" PUT \"  ,     (  ( index    +     \"  / test /  \"  )     +    id )  ,    Collections . emptyMap (  )  ,    new   apache . http . entity . StringEntity (  (  (  \"  {  \\  \" test \\  \"  :     \\  \" test _  \"     +     ( randomAsciiOfLength (  2  )  )  )     +     \"  \\  \"  }  \"  )  ,    ContentType . APPLICATION _ JSON )  )  )  ;", "}", "return   numDocs ;", "}", "METHOD_END"], "methodName": ["indexDocs"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "IndexingIT . Nodes   nodes    =    buildNodeAndVersions (  )  ;", "assumeFalse (  \" new   nodes   is   empty \"  ,    nodes . getNewNodes (  )  . isEmpty (  )  )  ;", "logger . info (  \" cluster   discovered :     {  }  \"  ,    nodes . toString (  )  )  ;", "final   List < String >    bwcNamesList    =    nodes . getBWCNodes (  )  . stream (  )  . map ( IndexingIT . Node :  : getNodeName )  . collect ( Collectors . toList (  )  )  ;", "final   String   bwcNames    =    bwcNamesList . stream (  )  . collect ( Collectors . joining (  \"  ,  \"  )  )  ;", "Settings . Builder   settings    =    Settings . builder (  )  . put ( INDEX _ NUMBER _ OF _ SHARDS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ NUMBER _ OF _ REPLICAS _ SETTING . getKey (  )  ,     2  )  . put (  \" index . routing . allocation . include .  _ name \"  ,    bwcNames )  ;", "final   String   index    =     \" indexversionprop \"  ;", "final   int   minUpdates    =     5  ;", "final   int   maxUpdates    =     1  0  ;", "createIndex ( index ,    settings . build (  )  )  ;", "try    ( RestClient   newNodeClient    =    buildClient ( restClientSettings (  )  ,    nodes . getNewNodes (  )  . stream (  )  . map ( IndexingIT . Node :  : getPublishAddress )  . toArray ( HttpHost [  ]  :  : new )  )  )     {", "int   nUpdates    =    randomIntBetween ( minUpdates ,    maxUpdates )  ;", "logger . info (  \" indexing   docs   with    [  {  }  ]    concurrent   updates   initially \"  ,    nUpdates )  ;", "final   int   finalVersionForDoc 1     =    indexDocWithConcurrentUpdates ( index ,     1  ,    nUpdates )  ;", "logger . info (  \" allowing   shards   on   all   nodes \"  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . putNull (  \" index . routing . allocation . include .  _ name \"  )  )  ;", "ensureGreen ( index )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "List < IndexingIT . Shard >    shards    =    buildShards ( index ,    nodes ,    newNodeClient )  ;", "IndexingIT . Shard   primary    =    buildShards ( index ,    nodes ,    newNodeClient )  . stream (  )  . filter ( IndexingIT . Shard :  : isPrimary )  . findFirst (  )  . get (  )  ;", "logger . info (  (  \" primary   resolved   to :     \"     +     ( primary . getNode (  )  . getNodeName (  )  )  )  )  ;", "for    ( IndexingIT . Shard   shard    :    shards )     {", "assertVersion ( index ,     1  ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,    finalVersionForDoc 1  )  ;", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,     1  )  ;", "}", "nUpdates    =    randomIntBetween ( minUpdates ,    maxUpdates )  ;", "logger . info (  \" indexing   docs   with    [  {  }  ]    concurrent   updates   after   allowing   shards   on   all   nodes \"  ,    nUpdates )  ;", "final   int   finalVersionForDoc 2     =    indexDocWithConcurrentUpdates ( index ,     2  ,    nUpdates )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "shards    =    buildShards ( index ,    nodes ,    newNodeClient )  ;", "primary    =    shards . stream (  )  . filter ( IndexingIT . Shard :  : isPrimary )  . findFirst (  )  . get (  )  ;", "logger . info (  (  \" primary   resolved   to :     \"     +     ( primary . getNode (  )  . getNodeName (  )  )  )  )  ;", "for    ( IndexingIT . Shard   shard    :    shards )     {", "assertVersion ( index ,     2  ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,    finalVersionForDoc 2  )  ;", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,     2  )  ;", "}", "primary    =    shards . stream (  )  . filter ( IndexingIT . Shard :  : isPrimary )  . findFirst (  )  . get (  )  ;", "logger . info (  \" moving   primary   to   new   node   by   excluding    {  }  \"  ,    primary . getNode (  )  . getNodeName (  )  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put (  \" index . routing . allocation . exclude .  _ name \"  ,    primary . getNode (  )  . getNodeName (  )  )  )  ;", "ensureGreen ( index )  ;", "nUpdates    =    randomIntBetween ( minUpdates ,    maxUpdates )  ;", "logger . info (  \" indexing   docs   with    [  {  }  ]    concurrent   updates   after   moving   primary \"  ,    nUpdates )  ;", "final   int   finalVersionForDoc 3     =    indexDocWithConcurrentUpdates ( index ,     3  ,    nUpdates )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "shards    =    buildShards ( index ,    nodes ,    newNodeClient )  ;", "for    ( IndexingIT . Shard   shard    :    shards )     {", "assertVersion ( index ,     3  ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,    finalVersionForDoc 3  )  ;", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,     3  )  ;", "}", "logger . info (  \" setting   number   of   replicas   to    0  \"  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put (  \" index . number _ of _ replicas \"  ,     0  )  )  ;", "ensureGreen ( index )  ;", "nUpdates    =    randomIntBetween ( minUpdates ,    maxUpdates )  ;", "logger . info (  \" indexing   doc   with    [  {  }  ]    concurrent   updates   after   setting   number   of   replicas   to    0  \"  ,    nUpdates )  ;", "final   int   finalVersionForDoc 4     =    indexDocWithConcurrentUpdates ( index ,     4  ,    nUpdates )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "shards    =    buildShards ( index ,    nodes ,    newNodeClient )  ;", "for    ( IndexingIT . Shard   shard    :    shards )     {", "assertVersion ( index ,     4  ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,    finalVersionForDoc 4  )  ;", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,     4  )  ;", "}", "logger . info (  \" setting   number   of   replicas   to    1  \"  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put (  \" index . number _ of _ replicas \"  ,     1  )  )  ;", "ensureGreen ( index )  ;", "nUpdates    =    randomIntBetween ( minUpdates ,    maxUpdates )  ;", "logger . info (  \" indexing   doc   with    [  {  }  ]    concurrent   updates   after   setting   number   of   replicas   to    1  \"  ,    nUpdates )  ;", "final   int   finalVersionForDoc 5     =    indexDocWithConcurrentUpdates ( index ,     5  ,    nUpdates )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "shards    =    buildShards ( index ,    nodes ,    newNodeClient )  ;", "for    ( IndexingIT . Shard   shard    :    shards )     {", "assertVersion ( index ,     5  ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,    finalVersionForDoc 5  )  ;", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( shard . getNode (  )  . getNodeName (  )  )  )  ,     5  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testIndexVersionPropagation"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "IndexingIT . Nodes   nodes    =    buildNodeAndVersions (  )  ;", "assumeFalse (  \" new   nodes   is   empty \"  ,    nodes . getNewNodes (  )  . isEmpty (  )  )  ;", "logger . info (  \" cluster   discovered :     {  }  \"  ,    nodes . toString (  )  )  ;", "final   List < String >    bwcNamesList    =    nodes . getBWCNodes (  )  . stream (  )  . map ( IndexingIT . Node :  : getNodeName )  . collect ( Collectors . toList (  )  )  ;", "final   String   bwcNames    =    bwcNamesList . stream (  )  . collect ( Collectors . joining (  \"  ,  \"  )  )  ;", "Settings . Builder   settings    =    Settings . builder (  )  . put ( INDEX _ NUMBER _ OF _ SHARDS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ NUMBER _ OF _ REPLICAS _ SETTING . getKey (  )  ,     2  )  . put (  \" index . routing . allocation . include .  _ name \"  ,    bwcNames )  ;", "final   String   index    =     \" test \"  ;", "createIndex ( index ,    settings . build (  )  )  ;", "try    ( RestClient   newNodeClient    =    buildClient ( restClientSettings (  )  ,    nodes . getNewNodes (  )  . stream (  )  . map ( IndexingIT . Node :  : getPublishAddress )  . toArray ( HttpHost [  ]  :  : new )  )  )     {", "int   numDocs    =     0  ;", "final   int   numberOfInitialDocs    =     1     +     ( randomInt (  5  )  )  ;", "logger . info (  \" indexing    [  {  }  ]    docs   initially \"  ,    numberOfInitialDocs )  ;", "numDocs    +  =    indexDocs ( index ,     0  ,    numberOfInitialDocs )  ;", "assertSeqNoOnShards ( index ,    nodes ,     (  ( nodes . getBWCVersion (  )  . major )     >  =     6     ?    numDocs    :     0  )  ,    newNodeClient )  ;", "logger . info (  \" allowing   shards   on   all   nodes \"  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . putNull (  \" index . routing . allocation . include .  _ name \"  )  )  ;", "ensureGreen ( index )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "for    ( final   String   bwcName    :    bwcNamesList )     {", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +    bwcName )  ,    numDocs )  ;", "}", "final   int   numberOfDocsAfterAllowingShardsOnAllNodes    =     1     +     ( randomInt (  5  )  )  ;", "logger . info (  \" indexing    [  {  }  ]    docs   after   allowing   shards   on   all   nodes \"  ,    numberOfDocsAfterAllowingShardsOnAllNodes )  ;", "numDocs    +  =    indexDocs ( index ,    numDocs ,    numberOfDocsAfterAllowingShardsOnAllNodes )  ;", "assertSeqNoOnShards ( index ,    nodes ,     (  ( nodes . getBWCVersion (  )  . major )     >  =     6     ?    numDocs    :     0  )  ,    newNodeClient )  ;", "IndexingIT . Shard   primary    =    buildShards ( index ,    nodes ,    newNodeClient )  . stream (  )  . filter ( IndexingIT . Shard :  : isPrimary )  . findFirst (  )  . get (  )  ;", "logger . info (  \" moving   primary   to   new   node   by   excluding    {  }  \"  ,    primary . getNode (  )  . getNodeName (  )  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put (  \" index . routing . allocation . exclude .  _ name \"  ,    primary . getNode (  )  . getNodeName (  )  )  )  ;", "ensureGreen ( index )  ;", "int   numDocsOnNewPrimary    =     0  ;", "final   int   numberOfDocsAfterMovingPrimary    =     1     +     ( randomInt (  5  )  )  ;", "logger . info (  \" indexing    [  {  }  ]    docs   after   moving   primary \"  ,    numberOfDocsAfterMovingPrimary )  ;", "numDocsOnNewPrimary    +  =    indexDocs ( index ,    numDocs ,    numberOfDocsAfterMovingPrimary )  ;", "numDocs    +  =    numberOfDocsAfterMovingPrimary ;", "assertSeqNoOnShards ( index ,    nodes ,     (  ( nodes . getBWCVersion (  )  . major )     >  =     6     ?    numDocs    :    numDocsOnNewPrimary )  ,    newNodeClient )  ;", "logger . info (  \" setting   number   of   replicas   to    0  \"  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put (  \" index . number _ of _ replicas \"  ,     0  )  )  ;", "final   int   numberOfDocsAfterDroppingReplicas    =     1     +     ( randomInt (  5  )  )  ;", "logger . info (  \" indexing    [  {  }  ]    docs   after   setting   number   of   replicas   to    0  \"  ,    numberOfDocsAfterDroppingReplicas )  ;", "numDocsOnNewPrimary    +  =    indexDocs ( index ,    numDocs ,    numberOfDocsAfterDroppingReplicas )  ;", "numDocs    +  =    numberOfDocsAfterDroppingReplicas ;", "logger . info (  \" setting   number   of   replicas   to    1  \"  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put (  \" index . number _ of _ replicas \"  ,     1  )  )  ;", "ensureGreen ( index )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "for    ( IndexingIT . Shard   shard    :    buildShards ( index ,    nodes ,    newNodeClient )  )     {", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( shard . node . nodeName )  )  ,    numDocs )  ;", "}", "assertSeqNoOnShards ( index ,    nodes ,     (  ( nodes . getBWCVersion (  )  . major )     >  =     6     ?    numDocs    :    numDocsOnNewPrimary )  ,    newNodeClient )  ;", "}", "}", "METHOD_END"], "methodName": ["testSeqNoCheckpoints"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "IndexingIT . Nodes   nodes    =    buildNodeAndVersions (  )  ;", "assumeFalse (  \" new   nodes   is   empty \"  ,    nodes . getNewNodes (  )  . isEmpty (  )  )  ;", "logger . info (  \" cluster   discovered :     {  }  \"  ,    nodes . toString (  )  )  ;", "String   repoConfig    =    Strings . toString ( JsonXContent . contentBuilder (  )  . startObject (  )  . field (  \" type \"  ,     \" fs \"  )  . startObject (  \" settings \"  )  . field (  \" compress \"  ,    randomBoolean (  )  )  . field (  \" location \"  ,    System . getProperty (  \" tests . path . repo \"  )  )  . endObject (  )  . endObject (  )  )  ;", "assertOK ( client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ snapshot / repo \"  ,    Collections . emptyMap (  )  ,    new   StringEntity ( repoConfig ,    ContentType . APPLICATION _ JSON )  )  )  ;", "String   bwcNames    =    nodes . getBWCNodes (  )  . stream (  )  . map ( IndexingIT . Node :  : getNodeName )  . collect ( Collectors . joining (  \"  ,  \"  )  )  ;", "Settings . Builder   settings    =    Settings . builder (  )  . put ( INDEX _ NUMBER _ OF _ SHARDS _ SETTING . getKey (  )  ,    between (  5  ,     1  0  )  )  . put ( INDEX _ NUMBER _ OF _ REPLICAS _ SETTING . getKey (  )  ,     1  )  . put (  \" index . routing . allocation . include .  _ name \"  ,    bwcNames )  ;", "final   String   index    =     \" test - snapshot - index \"  ;", "createIndex ( index ,    settings . build (  )  )  ;", "indexDocs ( index ,     0  ,    between (  5  0  ,     1  0  0  )  )  ;", "ensureGreen ( index )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "assertOK ( client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ snapshot / repo / bwc - snapshot \"  ,    Collections . singletonMap (  \" wait _ for _ completion \"  ,     \" true \"  )  ,    new   StringEntity (  (  (  \"  {  \\  \" indices \\  \"  :     \\  \"  \"     +    index )     +     \"  \\  \"  }  \"  )  ,    ContentType . APPLICATION _ JSON )  )  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . putNull (  \" index . routing . allocation . include .  _ name \"  )  )  ;", "ensureGreen ( index )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "assertOK ( client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ snapshot / repo / mixed - snapshot \"  ,    Collections . singletonMap (  \" wait _ for _ completion \"  ,     \" true \"  )  ,    new   StringEntity (  (  (  \"  {  \\  \" indices \\  \"  :     \\  \"  \"     +    index )     +     \"  \\  \"  }  \"  )  ,    ContentType . APPLICATION _ JSON )  )  )  ;", "}", "METHOD_END"], "methodName": ["testUpdateSnapshotStatus"], "fileName": "org.elasticsearch.backwards.IndexingIT"}, {"methodBody": ["METHOD_START", "{", "return   createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.backwards.MixedClusterClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   cannot   run   with   security   manager \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "final   PermissionCollection   noPermissions    =    new   Permissions (  )  ;", "final   ESPolicy   policy    =    new   ESPolicy ( Collections . emptyMap (  )  ,    noPermissions ,    Collections . emptyMap (  )  ,    true )  ;", "assertFalse ( policy . implies ( new   ProtectionDomain (  . class . getProtectionDomain (  )  . getCodeSource (  )  ,    noPermissions )  ,    new   SocketPermission (  (  \" localhost :  \"     +     ( randomFrom (  0  ,    randomIntBetween (  4  9  1  5  2  ,     6  5  5  3  5  )  )  )  )  ,     \" listen \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testListen"], "fileName": "org.elasticsearch.bootstrap.ESPolicyUnitTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   cannot   run   with   security   manager \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "Permission   all    =    new   AllPermission (  )  ;", "PermissionCollection   allCollection    =    all . newPermissionCollection (  )  ;", "allCollection . add ( all )  ;", "policy    =    new    ( Collections . emptyMap (  )  ,    allCollection ,    Collections . emptyMap (  )  ,    true )  ;", "PermissionCollection   noPermissions    =    new   Permissions (  )  ;", "assertFalse ( policy . implies ( new   ProtectionDomain ( null ,    noPermissions )  ,    new   FilePermission (  \" foo \"  ,     \" read \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullCodeSource"], "fileName": "org.elasticsearch.bootstrap.ESPolicyUnitTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   cannot   run   with   security   manager \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "PermissionCollection   noPermissions    =    new   Permissions (  )  ;", "policy    =    new    ( Collections . emptyMap (  )  ,    noPermissions ,    Collections . emptyMap (  )  ,    true )  ;", "assertFalse ( policy . implies ( new   ProtectionDomain ( new   CodeSource ( null ,     (  ( Certificate [  ]  )     ( null )  )  )  ,    noPermissions )  ,    new   FilePermission (  \" foo \"  ,     \" read \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testNullLocation"], "fileName": "org.elasticsearch.bootstrap.ESPolicyUnitTests"}, {"methodBody": ["METHOD_START", "{", "if    ( value    =  =    null )     {", "System . clearProperty (  . ES _ ENFORCE _ BOOTSTRAP _ CHECKS )  ;", "} else    {", "System . setProperty (  . ES _ ENFORCE _ BOOTSTRAP _ CHECKS ,    value )  ;", "}", "}", "METHOD_END"], "methodName": ["setEsEnforceBootstrapChecks"], "fileName": "org.elasticsearch.bootstrap.EvilBootstrapChecksTests"}, {"methodBody": ["METHOD_START", "{", "setEsEnforceBootstrapChecks (  \" true \"  )  ;", "final   List < BootstrapCheck >    checks    =    Collections . singletonList (  (    context )     -  >    BootstrapCheck . BootstrapCheckResult . failure (  \" error \"  )  )  ;", "final   Logger   logger    =    mock ( Logger . class )  ;", "final   NodeValidationException   e    =    expectThrows ( NodeValidationException . class ,     (  )     -  >    BootstrapChecks . check ( new   BootstrapContext ( Settings . EMPTY ,    null )  ,    false ,    checks ,    logger )  )  ;", "final   Matcher < String >    allOf    =    allOf ( containsString (  \" bootstrap   checks   failed \"  )  ,    containsString (  \" error \"  )  )  ;", "assertThat ( e ,    hasToString ( allOf )  )  ;", "verify ( logger )  . info (  \" explicitly   enforcing   bootstrap   checks \"  )  ;", "verifyNoMoreInteractions ( logger )  ;", "}", "METHOD_END"], "methodName": ["testEnforceBootstrapChecks"], "fileName": "org.elasticsearch.bootstrap.EvilBootstrapChecksTests"}, {"methodBody": ["METHOD_START", "{", "final   String   value    =    randomAlphaOfLength (  8  )  ;", "setEsEnforce ( value )  ;", "final   boolean   enforceLimits    =    randomBoolean (  )  ;", "final   IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >     . check ( new   BootstrapContext ( Settings . EMPTY ,    null )  ,    enforceLimits ,    emptyList (  )  ,     \" testInvalidValue \"  )  )  ;", "final   Matcher < String >    matcher    =    containsString (  (  (  \"  [ es . enforce . bootstrap . checks ]    must   be    [ true ]    but   was    [  \"     +    value )     +     \"  ]  \"  )  )  ;", "assertThat ( e ,    hasToString ( matcher )  )  ;", "}", "METHOD_END"], "methodName": ["testInvalidValue"], "fileName": "org.elasticsearch.bootstrap.EvilBootstrapChecksTests"}, {"methodBody": ["METHOD_START", "{", "setEsEnforceBootstrapChecks ( null )  ;", "final   Logger   logger    =    mock ( Logger . class )  ;", "BootstrapChecks . check ( new   BootstrapContext ( Settings . EMPTY ,    null )  ,    false ,    Collections . emptyList (  )  ,    logger )  ;", "verifyNoMoreInteractions ( logger )  ;", "}", "METHOD_END"], "methodName": ["testNonEnforcedBootstrapChecks"], "fileName": "org.elasticsearch.bootstrap.EvilBootstrapChecksTests"}, {"methodBody": ["METHOD_START", "{", "final   String   pathHome    =    System . getProperty (  \" es . path . home \"  )  ;", "final   String   value    =    randomAlphaOfLength (  1  6  )  ;", "System . setProperty (  \" es . path . home \"  ,    value )  ;", "run ( OK ,    true ,     (    output )     -  >     {", "}  ,     (    foreground ,    pidFile ,    quiet ,    esSettings )     -  >     {", "Settings   settings    =    esSettings . settings (  )  ;", "assertThat ( settings . size (  )  ,    equalTo (  2  )  )  ;", "assertEquals ( value ,    settings . get (  \" path . home \"  )  )  ;", "assertTrue ( settings . keySet (  )  . contains (  \" path . logs \"  )  )  ;", "}  )  ;", "System . clearProperty (  \" es . path . home \"  )  ;", "final   String   commandLineValue    =    randomAlphaOfLength (  1  6  )  ;", "run ( OK ,    true ,     (    output )     -  >     {", "}  ,     (    foreground ,    pidFile ,    quiet ,    esSettings )     -  >     {", "Settings   settings    =    esSettings . settings (  )  ;", "assertThat ( settings . size (  )  ,    equalTo (  2  )  )  ;", "assertEquals ( commandLineValue ,    settings . get (  \" path . home \"  )  )  ;", "assertTrue ( settings . keySet (  )  . contains (  \" path . logs \"  )  )  ;", "}  ,     (  \"  - Epath . home =  \"     +    commandLineValue )  )  ;", "if    ( pathHome    !  =    null )", "System . setProperty (  \" es . path . home \"  ,    pathHome )  ;", "else", "System . clearProperty (  \" es . path . home \"  )  ;", "}", "METHOD_END"], "methodName": ["testPathHome"], "fileName": "org.elasticsearch.bootstrap.EvilElasticsearchCliTests"}, {"methodBody": ["METHOD_START", "{", "if    ( Constants . LINUX )     {", "final   List < String >    lines    =    Files . readAllLines ( PathUtils . get (  \"  / proc / self / limits \"  )  )  ;", "for    ( final   String   line    :    lines )     {", "if    (  ( line    !  =    null )     &  &     ( line . startsWith (  \" Max   file   size \"  )  )  )     {", "final   String [  ]    fields    =    line . split (  \"  \\  \\ s +  \"  )  ;", "final   String   limit    =    fields [  3  ]  ;", "assertThat (  . rlimitToString ( MAX _ FILE _ SIZE )  ,    equalTo ( limit )  )  ;", "return ;", "}", "}", "fail (  \" should   have   read   max   file   size   from    / proc / self / limits \"  )  ;", "} else", "if    ( Constants . MAC _ OS _ X )     {", "assertThat ( MAX _ FILE _ SIZE ,    anyOf ( equalTo ( Long . MIN _ VALUE )  ,    greaterThanOrEqualTo (  0 L )  )  )  ;", "} else    {", "assertThat ( MAX _ FILE _ SIZE ,    equalTo ( Long . MIN _ VALUE )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSetMaxFileSize"], "fileName": "org.elasticsearch.bootstrap.EvilJNANativesTests"}, {"methodBody": ["METHOD_START", "{", "if    ( Constants . LINUX )     {", "final   List < String >    lines    =    Files . readAllLines ( PathUtils . get (  \"  / proc / self / limits \"  )  )  ;", "for    ( final   String   line    :    lines )     {", "if    (  ( line    !  =    null )     &  &     ( line . startsWith (  \" Max   address   space \"  )  )  )     {", "final   String [  ]    fields    =    line . split (  \"  \\  \\ s +  \"  )  ;", "final   String   limit    =    fields [  3  ]  ;", "assertThat (  . rlimitToString ( MAX _ SIZE _ VIRTUAL _ MEMORY )  ,    equalTo ( limit )  )  ;", "return ;", "}", "}", "fail (  \" should   have   read   max   size   virtual   memory   from    / proc / self / limits \"  )  ;", "} else", "if    ( Constants . MAC _ OS _ X )     {", "assertThat ( MAX _ SIZE _ VIRTUAL _ MEMORY ,    anyOf ( equalTo ( Long . MIN _ VALUE )  ,    greaterThanOrEqualTo (  0 L )  )  )  ;", "} else    {", "assertThat ( MAX _ SIZE _ VIRTUAL _ MEMORY ,    equalTo ( Long . MIN _ VALUE )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSetMaxSizeVirtualMemory"], "fileName": "org.elasticsearch.bootstrap.EvilJNANativesTests"}, {"methodBody": ["METHOD_START", "{", "if    ( Constants . LINUX )     {", "final   List < String >    lines    =    Files . readAllLines ( PathUtils . get (  \"  / proc / self / limits \"  )  )  ;", "for    ( final   String   line    :    lines )     {", "if    (  ( line    !  =    null )     &  &     ( line . startsWith (  \" Max   processes \"  )  )  )     {", "final   String [  ]    fields    =    line . split (  \"  \\  \\ s +  \"  )  ;", "final   long   limit    =     (  \" unlimited \"  . equals ( fields [  2  ]  )  )     ?    CLibrary . RLIM _ INFINITY    :    Long . parseLong ( fields [  2  ]  )  ;", "assertThat ( MAX _ NUMBER _ OF _ THREADS ,    equalTo ( limit )  )  ;", "return ;", "}", "}", "fail (  \" should   have   read   max   processes   from    / proc / self / limits \"  )  ;", "} else    {", "assertThat ( MAX _ NUMBER _ OF _ THREADS ,    equalTo (  (  -  1 L )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testSetMaximumNumberOfThreads"], "fileName": "org.elasticsearch.bootstrap.EvilJNANativesTests"}, {"methodBody": ["METHOD_START", "{", "String   target    =    expected . getName (  )  ;", "Set < String >    permissionSet    =    asSet ( expected . getActions (  )  . split (  \"  ,  \"  )  )  ;", "lean   read    =    permissionSet . remove (  \" read \"  )  ;", "lean   readlink    =    permissionSet . remove (  \" readlink \"  )  ;", "lean   write    =    permissionSet . remove (  \" write \"  )  ;", "lean   delete    =    permissionSet . remove (  \" delete \"  )  ;", "lean   execute    =    permissionSet . remove (  \" execute \"  )  ;", "assertTrue (  (  \" unrecognized   permission :     \"     +    permissionSet )  ,    permissionSet . isEmpty (  )  )  ;", "assertEquals ( read ,    actual . implies ( new   FilePermission ( target ,     \" read \"  )  )  )  ;", "assertEquals ( readlink ,    actual . implies ( new   FilePermission ( target ,     \" readlink \"  )  )  )  ;", "assertEquals ( write ,    actual . implies ( new   FilePermission ( target ,     \" write \"  )  )  )  ;", "assertEquals ( delete ,    actual . implies ( new   FilePermission ( target ,     \" delete \"  )  )  )  ;", "assertEquals ( execute ,    actual . implies ( new   FilePermission ( target ,     \" execute \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["assertExactPermissions"], "fileName": "org.elasticsearch.bootstrap.EvilSecurityTests"}, {"methodBody": ["METHOD_START", "{", "String   target    =    path . toString (  )  ;", "assertFalse ( actual . implies ( new   FilePermission ( target ,     \" read \"  )  )  )  ;", "assertFalse ( actual . implies ( new   FilePermission ( target ,     \" readlink \"  )  )  )  ;", "assertFalse ( actual . implies ( new   FilePermission ( target ,     \" we \"  )  )  )  ;", "assertFalse ( actual . implies ( new   FilePermission ( target ,     \" delete \"  )  )  )  ;", "assertFalse ( actual . implies ( new   FilePermission ( target ,     \" execute \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["assertNoPermissions"], "fileName": "org.elasticsearch.bootstrap.EvilSecurityTests"}, {"methodBody": ["METHOD_START", "{", "final   Path   path    =    createTempDir (  )  ;", "final   Path   home    =    path . resolve (  \" home \"  )  ;", "final   Path   data    =    path . resolve (  \" data \"  )  ;", "final   Path   duplicate ;", "if    ( randomBoolean (  )  )     {", "duplicate    =    data ;", "} else    {", "duplicate    =    createTempDir (  )  . toAbsolutePath (  )  . resolve (  \" link \"  )  ;", "Files . createSymbolicLink ( duplicate ,    data )  ;", "}", "final   Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    home . toString (  )  )  . putList ( PATH _ DATA _ SETTING . getKey (  )  ,    data . toString (  )  ,    duplicate . toString (  )  )  . build (  )  ;", "final   Environment   environment    =    TestEnvironment . newEnvironment ( settings )  ;", "final   IllegalStateException   e    =    expectThrows ( IllegalStateException . class ,     (  )     -  >     . createPermissions ( environment )  )  ;", "assertThat ( e ,    hasToString ( containsString (  (  (  (  (  \" path    [  \"     +     ( duplicate . toRealPath (  )  )  )     +     \"  ]    is   duplicated   by    [  \"  )     +    duplicate )     +     \"  ]  \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testDuplicateDataPaths"], "fileName": "org.elasticsearch.bootstrap.EvilSecurityTests"}, {"methodBody": ["METHOD_START", "{", "Path   p    =    createTempDir (  )  ;", "Path   brokenLink    =    p . resolve (  \" brokenLink \"  )  ;", "try    {", "Files . createSymbolicLink ( brokenLink ,    p . resolve (  \" nonexistent \"  )  )  ;", "}    catch    ( UnsupportedOperationException    |    IOException   e )     {", "assumeNoException (  \" test   requires   filesystem   that   supports   symbolic   links \"  ,    e )  ;", "}    catch    ( Exception   e )     {", "assumeNoException (  \" test   cannot   create   symbolic   links   with   security   manager   enabled \"  ,    e )  ;", "}", "try    {", ". ensureDirectoryExists ( brokenLink )  ;", "fail (  \" didn ' t   get   expected   exception \"  )  ;", "}    catch    ( IOException   expected )     {", "}", "}", "METHOD_END"], "methodName": ["testEnsureBrokenSymlink"], "fileName": "org.elasticsearch.bootstrap.EvilSecurityTests"}, {"methodBody": ["METHOD_START", "{", "Path   p    =    createTempDir (  )  ;", "Path   exists    =    p . resolve (  \" exists \"  )  ;", "Files . createDirectory ( exists )  ;", "Path   linkExists    =    p . resolve (  \" linkExists \"  )  ;", "try    {", "Files . createSymbolicLink ( linkExists ,    exists )  ;", "}    catch    ( UnsupportedOperationException    |    IOException   e )     {", "assumeNoException (  \" test   requires   filesystem   that   supports   symbolic   links \"  ,    e )  ;", "}    catch    ( Exception   e )     {", "assumeNoException (  \" test   cannot   create   symbolic   links   with   security   manager   enabled \"  ,    e )  ;", "}", ". ensureDirectoryExists ( linkExists )  ;", "Files . createTempFile ( linkExists ,    null ,    null )  ;", "}", "METHOD_END"], "methodName": ["testEnsureSymlink"], "fileName": "org.elasticsearch.bootstrap.EvilSecurityTests"}, {"methodBody": ["METHOD_START", "{", "Path   path    =    createTempDir (  )  ;", "Path   esHome    =    path . resolve (  \" esHome \"  )  ;", "Settings . Builder   settingsBuilder    =    Settings . builder (  )  ;", "settingsBuilder . put ( PATH _ HOME _ SETTING . getKey (  )  ,    esHome . resolve (  \" home \"  )  . toString (  )  )  ;", "settingsBuilder . putList ( PATH _ DATA _ SETTING . getKey (  )  ,    esHome . resolve (  \" data 1  \"  )  . toString (  )  ,    esHome . resolve (  \" data 2  \"  )  . toString (  )  )  ;", "settingsBuilder . put ( PATH _ SHARED _ DATA _ SETTING . getKey (  )  ,    esHome . resolve (  \" custom \"  )  . toString (  )  )  ;", "settingsBuilder . put ( PATH _ LOGS _ SETTING . getKey (  )  ,    esHome . resolve (  \" logs \"  )  . toString (  )  )  ;", "settingsBuilder . put ( PIDFILE _ SETTING . getKey (  )  ,    esHome . resolve (  \" test . pid \"  )  . toString (  )  )  ;", "Settings   settings    =    settingsBuilder . build (  )  ;", "Path   fakeTmpDir    =    createTempDir (  )  ;", "String   realTmpDir    =    System . getProperty (  \" tmpdir \"  )  ;", "Permissions   permissions ;", "Environment   environment ;", "try    {", "System . setProperty (  \" tmpdir \"  ,    fakeTmpDir . toString (  )  )  ;", "environment    =    new   Environment ( settings ,    esHome . resolve (  \" conf \"  )  )  ;", "permissions    =    Security . createPermissions ( environment )  ;", "}    finally    {", "System . setProperty (  \" tmpdir \"  ,    realTmpDir )  ;", "}", ". assertNoPermissions ( esHome ,    permissions )  ;", ". assertNoPermissions ( esHome . getParent (  )  ,    permissions )  ;", ". assertNoPermissions ( esHome . getParent (  )  . resolve (  \" other \"  )  ,    permissions )  ;", ". assertNoPermissions ( PathUtils . get ( realTmpDir )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( environment . binFile (  )  . toString (  )  ,     \" read , readlink \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( environment . libFile (  )  . toString (  )  ,     \" read , readlink \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( environment . modulesFile (  )  . toString (  )  ,     \" read , readlink \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( environment . configFile (  )  . toString (  )  ,     \" read , readlink \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( environment . pluginsFile (  )  . toString (  )  ,     \" read , readlink \"  )  ,    permissions )  ;", "for    ( Path   dataPath    :    environment . dataFiles (  )  )     {", ". assertExactPermissions ( new   FilePermission ( dataPath . toString (  )  ,     \" read , readlink , write , delete \"  )  ,    permissions )  ;", "}", "for    ( Path   dataPath    :    environment . dataWithClusterFiles (  )  )     {", ". assertExactPermissions ( new   FilePermission ( dataPath . toString (  )  ,     \" read , readlink , write , delete \"  )  ,    permissions )  ;", "}", ". assertExactPermissions ( new   FilePermission ( environment . sharedDataFile (  )  . toString (  )  ,     \" read , readlink , write , delete \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( environment . logsFile (  )  . toString (  )  ,     \" read , readlink , write , delete \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( fakeTmpDir . toString (  )  ,     \" read , readlink , write , delete \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( environment . pidFile (  )  . toString (  )  ,     \" delete \"  )  ,    permissions )  ;", "}", "METHOD_END"], "methodName": ["testEnvironmentPaths"], "fileName": "org.elasticsearch.bootstrap.EvilSecurityTests"}, {"methodBody": ["METHOD_START", "{", "Path   path    =    createTempDir (  )  ;", "Path   esHome    =    path . resolve (  \" esHome \"  )  ;", "Settings . Builder   settingsBuilder    =    Settings . builder (  )  ;", "settingsBuilder . put ( PATH _ HOME _ SETTING . getKey (  )  ,    esHome . toString (  )  )  ;", "Settings   settings    =    settingsBuilder . build (  )  ;", "Path   fakeTmpDir    =    createTempDir (  )  ;", "String   realTmpDir    =    System . getProperty (  \" tmpdir \"  )  ;", "Permissions   permissions ;", "try    {", "System . setProperty (  \" tmpdir \"  ,    fakeTmpDir . toString (  )  )  ;", "Environment   environment    =    TestEnvironment . newEnvironment ( settings )  ;", "permissions    =    Security . createPermissions ( environment )  ;", "}    finally    {", "System . setProperty (  \" tmpdir \"  ,    realTmpDir )  ;", "}", ". assertNoPermissions ( esHome ,    permissions )  ;", ". assertNoPermissions ( esHome . getParent (  )  ,    permissions )  ;", ". assertNoPermissions ( esHome . getParent (  )  . resolve (  \" other \"  )  ,    permissions )  ;", ". assertNoPermissions ( PathUtils . get ( realTmpDir )  ,    permissions )  ;", "}", "METHOD_END"], "methodName": ["testGeneratedPermissions"], "fileName": "org.elasticsearch.bootstrap.EvilSecurityTests"}, {"methodBody": ["METHOD_START", "{", "assumeFalse (  \" windows   does   not   automatically   grant   permission   to   the   target   of   symlinks \"  ,    WINDOWS )  ;", "Path   dir    =    createTempDir (  )  ;", "Path   target    =    dir . resolve (  \" target \"  )  ;", "Files . createDirectory ( target )  ;", "Path   link    =    dir . resolve (  \" link \"  )  ;", "try    {", "Files . createSymbolicLink ( link ,    target )  ;", "}    catch    ( UnsupportedOperationException    |    IOException   e )     {", "assumeNoException (  \" test   requires   filesystem   that   supports   symbolic   links \"  ,    e )  ;", "}    catch    ( SecurityException   e )     {", "assumeNoException (  \" test   cannot   create   symbolic   links   with   security   manager   enabled \"  ,    e )  ;", "}", "Permissions   permissions    =    new   Permissions (  )  ;", "FilePermissionUtils . addDirectoryPath ( permissions ,     \" testing \"  ,    link ,     \" read \"  )  ;", ". assertExactPermissions ( new   FilePermission ( link . toString (  )  ,     \" read \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( link . resolve (  \" foo \"  )  . toString (  )  ,     \" read \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( target . toString (  )  ,     \" read \"  )  ,    permissions )  ;", ". assertExactPermissions ( new   FilePermission ( target . resolve (  \" foo \"  )  . toString (  )  ,     \" read \"  )  ,    permissions )  ;", "}", "METHOD_END"], "methodName": ["testSymlinkPermissions"], "fileName": "org.elasticsearch.bootstrap.EvilSecurityTests"}, {"methodBody": ["METHOD_START", "{", "assumeFalse (  \" This   test   does   not   work   on   Windows \"  ,    WINDOWS )  ;", "Path   esHome    =    createTempDir (  )  . resolve (  \" esHome \"  )  ;", "Settings . Builder   settingsBuilder    =    Settings . builder (  )  ;", "settingsBuilder . put ( PATH _ HOME _ SETTING . getKey (  )  ,    esHome . toString (  )  )  ;", "Settings   settings    =    settingsBuilder . build (  )  ;", "Environment   environment    =    TestEnvironment . newEnvironment ( settings )  ;", "Path   plugin    =    pluginsDirFinder . apply ( environment )  . resolve (  \" test _ plugin \"  )  ;", "Files . createDirectories ( environment . modulesFile (  )  )  ;", "Files . createDirectories ( environment . pluginsFile (  )  )  ;", "Files . createDirectories ( plugin )  ;", "PluginTestUtil . writePluginProperties ( plugin ,     \" description \"  ,     \" test _ plugin \"  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" name \"  ,     \" test _ plugin \"  ,     \" version \"  ,     \"  1  .  8  \"  ,     \" classname \"  ,     \" TestPlugin \"  ,     \" has . native . controller \"  ,     \" true \"  )  ;", "Path   controllerProgram    =    Platforms . nativeControllerPath ( plugin )  ;", "createControllerProgram ( controllerProgram )  ;", "Path   otherPlugin    =    pluginsDirFinder . apply ( environment )  . resolve (  \" other _ plugin \"  )  ;", "Files . createDirectories ( otherPlugin )  ;", "PluginTestUtil . writePluginProperties ( otherPlugin ,     \" description \"  ,     \" other _ plugin \"  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" name \"  ,     \" other _ plugin \"  ,     \" version \"  ,     \"  1  .  8  \"  ,     \" classname \"  ,     \" OtherPlugin \"  ,     \" has . native . controller \"  ,     \" false \"  )  ;", "Spawner   spawner    =    new   Spawner (  )  ;", "spawner . spawnNativePluginControllers ( environment )  ;", "List < Process >    processes    =    spawner . getProcesses (  )  ;", "assertThat ( processes ,    hasSize (  1  )  )  ;", "Process   process    =    processes . get (  0  )  ;", "final   InputStreamReader   in    =    new   InputStreamReader ( process . getInputStream (  )  ,    StandardCharsets . UTF _  8  )  ;", "try    ( BufferedReader   stdoutReader    =    new   BufferedReader ( in )  )     {", "String   line    =    stdoutReader . readLine (  )  ;", "assertEquals (  \" I   am   alive \"  ,    line )  ;", "spawner . close (  )  ;", "assertTrue ( process . waitFor (  1  ,    TimeUnit . SECONDS )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertControllerSpawns"], "fileName": "org.elasticsearch.bootstrap.SpawnerNoBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "final   Path   outputDir    =    outputFile . getParent (  )  ;", "Files . createDirectories ( outputDir )  ;", "Files . write ( outputFile ,     . CONTROLLER _ SOURCE . getBytes ( StandardCharsets . UTF _  8  )  )  ;", "final   PosixFileAttributeView   view    =    Files . getFileAttributeView ( outputFile ,    PosixFileAttributeView . class )  ;", "if    ( view    !  =    null )     {", "final   Set < PosixFilePermission >    perms    =    new   HashSet <  >  (  )  ;", "perms . add ( PosixFilePermission . OWNER _ READ )  ;", "perms . add ( PosixFilePermission . OWNER _ WRITE )  ;", "perms . add ( PosixFilePermission . OWNER _ EXECUTE )  ;", "perms . add ( PosixFilePermission . GROUP _ READ )  ;", "perms . add ( PosixFilePermission . GROUP _ EXECUTE )  ;", "perms . add ( PosixFilePermission . OTHERS _ READ )  ;", "perms . add ( PosixFilePermission . OTHERS _ EXECUTE )  ;", "Files . setPosixFilePermissions ( outputFile ,    perms )  ;", "}", "}", "METHOD_END"], "methodName": ["createControllerProgram"], "fileName": "org.elasticsearch.bootstrap.SpawnerNoBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "assertControllerSpawns ( Environment :  : pluginsFile )  ;", "assertControllerSpawns ( Environment :  : modulesFile )  ;", "}", "METHOD_END"], "methodName": ["testControllerSpawn"], "fileName": "org.elasticsearch.bootstrap.SpawnerNoBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "assumeFalse (  \" This   test   does   not   work   on   Windows \"  ,    WINDOWS )  ;", "Path   esHome    =    createTempDir (  )  . resolve (  \" esHome \"  )  ;", "Settings . Builder   settingsBuilder    =    Settings . builder (  )  ;", "settingsBuilder . put ( PATH _ HOME _ SETTING . getKey (  )  ,    esHome . toString (  )  )  ;", "Settings   settings    =    settingsBuilder . build (  )  ;", "Environment   environment    =    TestEnvironment . newEnvironment ( settings )  ;", "Path   metaPlugin    =    environment . pluginsFile (  )  . resolve (  \" meta _ plugin \"  )  ;", "Files . createDirectories ( environment . modulesFile (  )  )  ;", "Files . createDirectories ( metaPlugin )  ;", "PluginTestUtil . writeMetaPluginProperties ( metaPlugin ,     \" description \"  ,     \" test _ plugin \"  ,     \" name \"  ,     \" meta _ plugin \"  ,     \" plugins \"  ,     \" test _ plugin , other _ plugin \"  )  ;", "Path   plugin    =    metaPlugin . resolve (  \" test _ plugin \"  )  ;", "Files . createDirectories ( plugin )  ;", "PluginTestUtil . writePluginProperties ( plugin ,     \" description \"  ,     \" test _ plugin \"  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" name \"  ,     \" test _ plugin \"  ,     \" version \"  ,     \"  1  .  8  \"  ,     \" classname \"  ,     \" TestPlugin \"  ,     \" has . native . controller \"  ,     \" true \"  )  ;", "Path   controllerProgram    =    Platforms . nativeControllerPath ( plugin )  ;", "createControllerProgram ( controllerProgram )  ;", "Path   otherPlugin    =    metaPlugin . resolve (  \" other _ plugin \"  )  ;", "Files . createDirectories ( otherPlugin )  ;", "PluginTestUtil . writePluginProperties ( otherPlugin ,     \" description \"  ,     \" other _ plugin \"  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" name \"  ,     \" other _ plugin \"  ,     \" version \"  ,     \"  1  .  8  \"  ,     \" classname \"  ,     \" OtherPlugin \"  ,     \" has . native . controller \"  ,     \" false \"  )  ;", "Spawner   spawner    =    new   Spawner (  )  ;", "spawner . spawnNativePluginControllers ( environment )  ;", "List < Process >    processes    =    spawner . getProcesses (  )  ;", "assertThat ( processes ,    hasSize (  1  )  )  ;", "Process   process    =    processes . get (  0  )  ;", "final   InputStreamReader   in    =    new   InputStreamReader ( process . getInputStream (  )  ,    StandardCharsets . UTF _  8  )  ;", "try    ( BufferedReader   stdoutReader    =    new   BufferedReader ( in )  )     {", "String   line    =    stdoutReader . readLine (  )  ;", "assertEquals (  \" I   am   alive \"  ,    line )  ;", "spawner . close (  )  ;", "assertTrue ( process . waitFor (  1  ,    TimeUnit . SECONDS )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testControllerSpawnMetaPlugin"], "fileName": "org.elasticsearch.bootstrap.SpawnerNoBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "Path   esHome    =    createTempDir (  )  . resolve (  \" esHome \"  )  ;", "Settings . Builder   settingsBuilder    =    Settings . builder (  )  ;", "settingsBuilder . put ( PATH _ HOME _ SETTING . getKey (  )  ,    esHome . toString (  )  )  ;", "Settings   settings    =    settingsBuilder . build (  )  ;", "Environment   environment    =    TestEnvironment . newEnvironment ( settings )  ;", "Path   plugin    =    environment . pluginsFile (  )  . resolve (  \" test _ plugin \"  )  ;", "Files . createDirectories ( plugin )  ;", "PluginTestUtil . writePluginProperties ( plugin ,     \" description \"  ,     \" test _ plugin \"  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" name \"  ,     \" test _ plugin \"  ,     \" version \"  ,     \"  1  .  8  \"  ,     \" classname \"  ,     \" TestPlugin \"  ,     \" has . native . controller \"  ,     \" false \"  )  ;", "Path   controllerProgram    =    Platforms . nativeControllerPath ( plugin )  ;", "createControllerProgram ( controllerProgram )  ;", "Spawner   spawner    =    new   Spawner (  )  ;", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    spawner . spawnNativePluginControllers ( environment )  )  ;", "assertThat ( e . getMessage (  )  ,    equalTo (  \" plugin    [ test _ plugin ]    does   not   have   permission   to   fork   native   controller \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testControllerSpawnWithIncorrectDescriptor"], "fileName": "org.elasticsearch.bootstrap.SpawnerNoBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "Path   esHome    =    createTempDir (  )  . resolve (  \" esHome \"  )  ;", "Settings . Builder   settingsBuilder    =    Settings . builder (  )  ;", "settingsBuilder . put ( PATH _ HOME _ SETTING . getKey (  )  ,    esHome . toString (  )  )  ;", "Settings   settings    =    settingsBuilder . build (  )  ;", "Environment   environment    =    TestEnvironment . newEnvironment ( settings )  ;", "Path   plugin    =    environment . pluginsFile (  )  . resolve (  \" a _ plugin \"  )  ;", "Files . createDirectories ( environment . modulesFile (  )  )  ;", "Files . createDirectories ( plugin )  ;", "PluginTestUtil . writePluginProperties ( plugin ,     \" description \"  ,     \" a _ plugin \"  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" version \"  ,    CURRENT . toString (  )  ,     \" name \"  ,     \" a _ plugin \"  ,     \" version \"  ,     \"  1  .  8  \"  ,     \" classname \"  ,     \" APlugin \"  ,     \" has . native . controller \"  ,     \" false \"  )  ;", "try    ( Spawner   spawner    =    new   Spawner (  )  )     {", "spawner . spawnNativePluginControllers ( environment )  ;", "assertThat ( spawner . getProcesses (  )  ,    hasSize (  0  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testNoControllerSpawn"], "fileName": "org.elasticsearch.bootstrap.SpawnerNoBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "final   Path   esHome    =    createTempDir (  )  . resolve (  \" home \"  )  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    esHome . toString (  )  )  . build (  )  ;", "final   Environment   environment    =    TestEnvironment . newEnvironment ( settings )  ;", "Files . createDirectories ( environment . modulesFile (  )  )  ;", "Files . createDirectories ( environment . pluginsFile (  )  )  ;", "final   Path   desktopServicesStore    =    environment . pluginsFile (  )  . resolve (  \"  . DS _ Store \"  )  ;", "Files . createFile ( desktopServicesStore )  ;", "final      spawner    =    new    (  )  ;", "if    ( Constants . MAC _ OS _ X )     {", "spawner . spawnNativePluginControllers ( environment )  ;", "} else    {", "final   FileSystemException   e    =    expectThrows ( FileSystemException . class ,     (  )     -  >    spawner . spawnNativePluginControllers ( environment )  )  ;", "if    ( Constants . WINDOWS )     {", "assertThat ( e ,    instanceOf ( NoSuchFileException . class )  )  ;", "} else    {", "assertThat ( e ,    hasToString ( containsString (  \" Not   a   directory \"  )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testSpawnerHandlingOfDesktopServicesStoreFiles"], "fileName": "org.elasticsearch.bootstrap.SpawnerNoBootstrapTests"}, {"methodBody": ["METHOD_START", "{", "try    {", "Runtime . getRuntime (  )  . exec (  . EXECUTABLE )  ;", "fail (  \" should   not   have   been   able   to   execute !  \"  )  ;", "}    catch    ( Exception   expected )     {", "}", "}", "METHOD_END"], "methodName": ["testNoExecution"], "fileName": "org.elasticsearch.bootstrap.SystemCallFilterTests"}, {"methodBody": ["METHOD_START", "{", "Thread   t    =    new   Thread (  )     {", "@ Override", "public   void   run (  )     {", "try    {", "Runtime . getRuntime (  )  . exec (  . EXECUTABLE )  ;", "fail (  \" should   not   have   been   able   to   execute !  \"  )  ;", "}    catch    ( Exception   expected )     {", "}", "}", "}  ;", "t . start (  )  ;", "t . join (  )  ;", "}", "METHOD_END"], "methodName": ["testNoExecutionFromThread"], "fileName": "org.elasticsearch.bootstrap.SystemCallFilterTests"}, {"methodBody": ["METHOD_START", "{", "QueryBuilderBWCIT . CANDIDATES . add ( new   Object [  ]  {     (  \"  {  \\  \" query \\  \"  :     {  \"     +    querySource )     +     \"  }  }  \"  ,    expectedQb    }  )  ;", "}", "METHOD_END"], "methodName": ["addCandidate"], "fileName": "org.elasticsearch.bwc.QueryBuilderBWCIT"}, {"methodBody": ["METHOD_START", "{", "String   index    =     \" queries \"  ;", "if    ( runningAgainstOldCluster )     {", "XContentBuilder   mappingsAndSettings    =    jsonBuilder (  )  ;", "mappingsAndSettings . startObject (  )  ;", "{", "mappingsAndSettings . startObject (  \" settings \"  )  ;", "mappingsAndSettings . field (  \" number _ of _ shards \"  ,     1  )  ;", "mappingsAndSettings . field (  \" number _ of _ replicas \"  ,     0  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "{", "mappingsAndSettings . startObject (  \" mappings \"  )  ;", "mappingsAndSettings . startObject (  \" doc \"  )  ;", "mappingsAndSettings . startObject (  \" properties \"  )  ;", "{", "mappingsAndSettings . startObject (  \" query \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" percolator \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "{", "mappingsAndSettings . startObject (  \" keyword _ field \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" keyword \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "{", "mappingsAndSettings . startObject (  \" long _ field \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" long \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "Response   rsp    =    client (  )  . performRequest (  \" PUT \"  ,     (  \"  /  \"     +    index )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( mappingsAndSettings )  ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    rsp . getStatusLine (  )  . getStatusCode (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( QueryBuilderBWCIT . CANDIDATES . size (  )  )  ;    i +  +  )     {", "rsp    =    client (  )  . performRequest (  \" PUT \"  ,     (  (  (  \"  /  \"     +    index )     +     \"  / doc /  \"  )     +     ( Integer . toString ( i )  )  )  ,    Collections . emptyMap (  )  ,    new   StringEntity (  (  ( String )     ( QueryBuilderBWCIT . CANDIDATES . get ( i )  [  0  ]  )  )  ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  1  ,    rsp . getStatusLine (  )  . getStatusCode (  )  )  ;", "}", "} else    {", "NamedWriteableRegistry   registry    =    new   NamedWriteableRegistry ( new   search . SearchModule ( Settings . EMPTY ,    false ,    Collections . emptyList (  )  )  . getNamedWriteables (  )  )  ;", "for    ( int   i    =     0  ;    i    <     ( QueryBuilderBWCIT . CANDIDATES . size (  )  )  ;    i +  +  )     {", "QueryBuilder   expectedQueryBuilder    =     (  ( QueryBuilder )     ( QueryBuilderBWCIT . CANDIDATES . get ( i )  [  1  ]  )  )  ;", "Response   rsp    =    client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +    index )     +     \"  /  _ search \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity (  (  (  (  \"  {  \\  \" query \\  \"  :     {  \\  \" ids \\  \"  :     {  \\  \" values \\  \"  :     [  \\  \"  \"     +     ( Integer . toString ( i )  )  )     +     \"  \\  \"  ]  }  }  ,     \"  )     +     \"  \\  \" docvalue _ fields \\  \"     :     [  \\  \" query . query _ builder _ field \\  \"  ]  }  \"  )  ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    rsp . getStatusLine (  )  . getStatusCode (  )  )  ;", "Map <  ?  ,     ?  >    hitRsp    =     (  ( Map <  ?  ,     ?  >  )     (  (  ( List <  ?  >  )     (  (  ( Map <  ?  ,     ?  >  )     ( QueryBuilderBWCIT . toMap ( rsp )  . get (  \" hits \"  )  )  )  . get (  \" hits \"  )  )  )  . get (  0  )  )  )  ;", "String   queryBuilderStr    =     (  ( String )     (  (  ( List <  ?  >  )     (  (  ( Map <  ?  ,     ?  >  )     ( hitRsp . get (  \" fields \"  )  )  )  . get (  \" query . query _ builder _ field \"  )  )  )  . get (  0  )  )  )  ;", "byte [  ]    qbSource    =    Base 6  4  . getDecoder (  )  . decode ( queryBuilderStr )  ;", "try    ( InputStream   in    =    new   ByteArrayInputStream ( qbSource ,     0  ,    qbSource . length )  )     {", "try    ( StreamInput   input    =    new   common . io . stream . NamedWriteableAwareStreamInput ( new   InputStreamStreamInput ( in )  ,    registry )  )     {", "input . setVersion ( oldClusterVersion )  ;", "QueryBuilder   queryBuilder    =    input . readNamedWriteable ( QueryBuilder . class )  ;", "assert    ( in . read (  )  )     =  =     (  -  1  )  ;", "assertEquals ( expectedQueryBuilder ,    queryBuilder )  ;", "}", "}", "}", "}", "}", "METHOD_END"], "methodName": ["testQueryBuilderBWC"], "fileName": "org.elasticsearch.bwc.QueryBuilderBWCIT"}, {"methodBody": ["METHOD_START", "{", "return   XContentHelper . convertToMap ( jsonXContent ,    response ,    false )  ;", "}", "METHOD_END"], "methodName": ["toMap"], "fileName": "org.elasticsearch.bwc.QueryBuilderBWCIT"}, {"methodBody": ["METHOD_START", "{", "return   QueryBuilderBWCIT . toMap ( EntityUtils . toString ( response . getEntity (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["toMap"], "fileName": "org.elasticsearch.bwc.QueryBuilderBWCIT"}, {"methodBody": ["METHOD_START", "{", "final   AtomicBoolean   closed    =    new   AtomicBoolean (  )  ;", "final   boolean   shouldThrow    =    randomBoolean (  )  ;", "final   Command   command    =    new   Command (  \" test - command - shutdown - hook \"  ,     (  )     -  >     {", "}  )     {", "@ Override", "protected   void   execute ( Terminal   terminal ,    OptionSet   options )    throws   Exception    {", "}", "@ Override", "public   void   close (  )    throws   IOException    {", "closed . set ( true )  ;", "if    ( shouldThrow )     {", "throw   new   IOException (  \" fail \"  )  ;", "}", "}", "}  ;", "final   MockTerminal   terminal    =    new   MockTerminal (  )  ;", "command . main ( new   String [  0  ]  ,    terminal )  ;", "assertNotNull ( command . getShutdownHookThread (  )  )  ;", "assertTrue ( Runtime . getRuntime (  )  . removeShutdownHook ( command . getShutdownHookThread (  )  )  )  ;", "command . getShutdownHookThread (  )  . run (  )  ;", "command . getShutdownHookThread (  )  . join (  )  ;", "assertTrue ( closed . get (  )  )  ;", "final   String   output    =    terminal . getOutput (  )  ;", "if    ( shouldThrow )     {", "assertThat ( output ,    containsString (  \" IOException :    fail \"  )  )  ;", "assertThat ( output ,    containsString (  \"  \\ tat    $  1  . close \"  )  )  ;", "} else    {", "assertThat ( output ,    isEmptyString (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testCommandShutdownHook"], "fileName": "org.elasticsearch.cli.EvilCommandTests"}, {"methodBody": ["METHOD_START", "{", "System . clearProperty (  \" es . path . conf \"  )  ;", "}", "METHOD_END"], "methodName": ["clearEsPathConf"], "fileName": "org.elasticsearch.cli.EvilEnvironmentAwareCommandTests"}, {"methodBody": ["METHOD_START", "{", "clearEsPathConf (  )  ;", "class   Test   extends       {", "private   Test ( String   description )     {", "super ( description )  ;", "}", "@ Override", "protected   void   execute ( Terminal   terminal ,    OptionSet   options ,    Environment   env )    throws   Exception    {", "}", "}", "final   Test   command    =    new   Test (  \" test \"  )  ;", "final   UserException   e    =    expectThrows ( UserException . class ,     (  )     -  >    command . mainWithoutErrorHandling ( new   String [  0  ]  ,    new   MockTerminal (  )  )  )  ;", "assertThat ( e ,    hasToString ( containsString (  \" the   system   property    [ es . path . conf ]    must   be   set \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testEsPathConfNotSet"], "fileName": "org.elasticsearch.cli.EvilEnvironmentAwareCommandTests"}, {"methodBody": ["METHOD_START", "{", "IllegalArgumentException   exception    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    IndexMetaData . buildNumberOfShardsSetting (  )  . get ( Settings . builder (  )  . put (  \" index . number _ of _ shards \"  ,     1  0  2  5  )  . build (  )  )  )  ;", "assertEquals (  \" Failed   to   parse   value    [  1  0  2  5  ]    for   setting    [ index . number _ of _ shards ]    must   be    <  =     1  0  2  4  \"  ,    exception . getMessage (  )  )  ;", "Integer   numShards    =    INDEX _ NUMBER _ OF _ SHARDS _ SETTING . get ( Settings . builder (  )  . put (  \" index . number _ of _ shards \"  ,     1  0  0  )  . build (  )  )  ;", "assertEquals (  1  0  0  ,    numShards . intValue (  )  )  ;", "int   limit    =    randomIntBetween (  1  ,     1  0  )  ;", "System . set (  \" es . index . max _ number _ of _ shards \"  ,    Integer . toString ( limit )  )  ;", "try    {", "IllegalArgumentException   e    =    expectThrows ( IllegalArgumentException . class ,     (  )     -  >    IndexMetaData . buildNumberOfShardsSetting (  )  . get ( Settings . builder (  )  . put (  \" index . number _ of _ shards \"  ,     1  1  )  . build (  )  )  )  ;", "assertEquals (  (  \" Failed   to   parse   value    [  1  1  ]    for   setting    [ index . number _ of _ shards ]    must   be    <  =     \"     +    limit )  ,    e . getMessage (  )  )  ;", "}    finally    {", "System . clear (  \" es . index . max _ number _ of _ shards \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMaxNumShards"], "fileName": "org.elasticsearch.cluster.metadata.EvilSystemPropertyTests"}, {"methodBody": ["METHOD_START", "{", "final   Path   configDir    =    getDataPath (  \" config \"  )  ;", "final   String   level    =    randomFrom ( TRACE ,    DEBUG ,    INFO ,    WARN ,    ERROR )  . toString (  )  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" logger . level \"  ,    level )  . build (  )  ;", "final   Environment   environment    =    new   Environment ( settings ,    configDir )  ;", "Logor . configure ( environment )  ;", "final   String   loggerName    =     \" test \"  ;", "final   Logger   logger    =    ESLoggerFactory . getLogger ( loggerName )  ;", "assertThat ( logger . getLevel (  )  . toString (  )  ,    equalTo ( level )  )  ;", "}", "METHOD_END"], "methodName": ["testDefaults"], "fileName": "org.elasticsearch.common.logging.EvilLoggerConfigurationTests"}, {"methodBody": ["METHOD_START", "{", "final   Path   configDir    =    getDataPath (  \" hierarchy \"  )  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "final   Environment   environment    =    new   Environment ( settings ,    configDir )  ;", "Logor . configure ( environment )  ;", "assertThat ( ESLoggerFactory . getLogger (  \" x \"  )  . getLevel (  )  ,    equalTo ( TRACE )  )  ;", "assertThat ( ESLoggerFactory . getLogger (  \" x . y \"  )  . getLevel (  )  ,    equalTo ( DEBUG )  )  ;", "final   Level   level    =    randomFrom ( TRACE ,    DEBUG ,    INFO ,    WARN ,    ERROR )  ;", "Loggers . setLevel ( ESLoggerFactory . getLogger (  \" x \"  )  ,    level )  ;", "assertThat ( ESLoggerFactory . getLogger (  \" x \"  )  . getLevel (  )  ,    equalTo ( level )  )  ;", "assertThat ( ESLoggerFactory . getLogger (  \" x . y \"  )  . getLevel (  )  ,    equalTo ( level )  )  ;", "}", "METHOD_END"], "methodName": ["testHierarchy"], "fileName": "org.elasticsearch.common.logging.EvilLoggerConfigurationTests"}, {"methodBody": ["METHOD_START", "{", "final   Level   rootLevel    =    randomFrom ( TRACE ,    DEBUG ,    INFO ,    WARN ,    ERROR )  ;", "final   Level   fooLevel    =    randomFrom ( TRACE ,    DEBUG ,    INFO ,    WARN ,    ERROR )  ;", "final   Level   barLevel    =    randomFrom ( TRACE ,    DEBUG ,    INFO ,    WARN ,    ERROR )  ;", "final   Path   configDir    =    getDataPath (  \" minimal \"  )  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" logger . level \"  ,    rootLevel . name (  )  )  . put (  \" logger . foo \"  ,    fooLevel . name (  )  )  . put (  \" logger . bar \"  ,    barLevel . name (  )  )  . build (  )  ;", "final   Environment   environment    =    new   Environment ( settings ,    configDir )  ;", "LogConfigurator . configure ( environment )  ;", "final   LoggerContext   ctx    =     (  ( LoggerContext )     ( LogManager . getContext ( false )  )  )  ;", "final      config    =    ctx . get (  )  ;", "final   Map < String ,    LoggerConfig >    loggerConfigs    =    config . getLoggers (  )  ;", "assertThat ( loggerConfigs . size (  )  ,    equalTo (  3  )  )  ;", "assertThat ( loggerConfigs ,    hasKey (  \"  \"  )  )  ;", "assertThat ( loggerConfigs . get (  \"  \"  )  . getLevel (  )  ,    equalTo ( rootLevel )  )  ;", "assertThat ( loggerConfigs ,    hasKey (  \" foo \"  )  )  ;", "assertThat ( loggerConfigs . get (  \" foo \"  )  . getLevel (  )  ,    equalTo ( fooLevel )  )  ;", "assertThat ( loggerConfigs ,    hasKey (  \" bar \"  )  )  ;", "assertThat ( loggerConfigs . get (  \" bar \"  )  . getLevel (  )  ,    equalTo ( barLevel )  )  ;", "assertThat ( ctx . getLogger ( randomAlphaOfLength (  1  6  )  )  . getLevel (  )  ,    equalTo ( rootLevel )  )  ;", "}", "METHOD_END"], "methodName": ["testLoggingLevelsFromSettings"], "fileName": "org.elasticsearch.common.logging.EvilLoggerConfigurationTests"}, {"methodBody": ["METHOD_START", "{", "final   Path   configDir    =    getDataPath (  \" does _ not _ exist \"  )  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "final   Environment   environment    =    new   Environment ( settings ,    configDir )  ;", "UserException   e    =    expectThrows ( UserException . class ,     (  )     -  >    Logor . configure ( environment )  )  ;", "assertThat ( e ,    hasToString ( containsString (  \" no   log 4 j 2  . properties   found ;    tried \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testMissingConfigFile"], "fileName": "org.elasticsearch.common.logging.EvilLoggerConfigurationTests"}, {"methodBody": ["METHOD_START", "{", "final   Level   level    =    ESLoggerFactory . getLogger (  \" test \"  )  . getLevel (  )  ;", "try    {", "final   Path   configDir    =    getDataPath (  \" config \"  )  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "final   Environment   environment    =    new   Environment ( settings ,    configDir )  ;", "LogConfigurator . configure ( environment )  ;", "{", "final   LoggerContext   ctx    =     (  ( LoggerContext )     ( LogManager . getContext ( false )  )  )  ;", "final      config    =    ctx . get (  )  ;", "final   LoggerConfig   loggerConfig    =    config . getLoggerConfig (  \" test \"  )  ;", "final   Appender   appender    =    loggerConfig . getAppenders (  )  . get (  \" console \"  )  ;", "assertThat ( appender ,    notNullValue (  )  )  ;", "}", "{", "final   LoggerContext   ctx    =     (  ( LoggerContext )     ( LogManager . getContext ( false )  )  )  ;", "final      config    =    ctx . get (  )  ;", "final   LoggerConfig   loggerConfig    =    config . getLoggerConfig (  \" second \"  )  ;", "final   Appender   appender    =    loggerConfig . getAppenders (  )  . get (  \" console 2  \"  )  ;", "assertThat ( appender ,    notNullValue (  )  )  ;", "}", "{", "final   LoggerContext   ctx    =     (  ( LoggerContext )     ( LogManager . getContext ( false )  )  )  ;", "final      config    =    ctx . get (  )  ;", "final   LoggerConfig   loggerConfig    =    config . getLoggerConfig (  \" third \"  )  ;", "final   Appender   appender    =    loggerConfig . getAppenders (  )  . get (  \" console 3  \"  )  ;", "assertThat ( appender ,    notNullValue (  )  )  ;", "}", "}    finally    {", "Configurator . setLevel (  \" test \"  ,    level )  ;", "}", "}", "METHOD_END"], "methodName": ["testResolveMultipleConfigs"], "fileName": "org.elasticsearch.common.logging.EvilLoggerConfigurationTests"}, {"methodBody": ["METHOD_START", "{", "final   Path   configDir    =    getDataPath (  \" config \"  )  ;", "final   Settings   settings    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . put (  \" logger . test _ resolve _ order \"  ,     \" TRACE \"  )  . build (  )  ;", "final   Environment   environment    =    new   Environment ( settings ,    configDir )  ;", "Logor . configure ( environment )  ;", "final   String   loggerName    =     \" test _ resolve _ order \"  ;", "final   Logger   logger    =    ESLoggerFactory . getLogger ( loggerName )  ;", "assertTrue ( logger . isTraceEnabled (  )  )  ;", "}", "METHOD_END"], "methodName": ["testResolveOrder"], "fileName": "org.elasticsearch.common.logging.EvilLoggerConfigurationTests"}, {"methodBody": ["METHOD_START", "{", "final   Matcher   matcher    =    Pattern . compile (  \"  \\  \\  [  (  .  *  )  \\  \\  ]  \\  \\  [  (  .  *  )  \\  \\  (  .  *  \\  \\  )  \\  \\  ]     (  .  *  )  \"  )  . matcher ( logLine )  ;", "assertTrue ( logLine ,    matcher . matches (  )  )  ;", "assertThat ( matcher . group (  1  )  ,    equalTo ( level . toString (  )  )  )  ;", "assertThat ( matcher . group (  2  )  ,    RegexMatcher . matches ( location )  )  ;", "assertThat ( matcher . group (  3  )  ,    RegexMatcher . matches ( message )  )  ;", "}", "METHOD_END"], "methodName": ["assertLogLine"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "setupLogging ( config ,    EMPTY )  ;", "}", "METHOD_END"], "methodName": ["setupLogging"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "assert    !  ( PATH _ HOME _ SETTING . exists ( settings )  )  ;", "final   Path   configDir    =    getDataPath ( config )  ;", "final   Settings   mergedSettings    =    Settings . builder (  )  . put ( settings )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toString (  )  )  . build (  )  ;", "final   Environment   environment    =    new   Environment ( mergedSettings ,    configDir )  ;", "LogConfigurator . configure ( environment )  ;", "}", "METHOD_END"], "methodName": ["setupLogging"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "setupLogging (  \" deprecation \"  )  ;", "final   DeprecationLogger   deprecationLogger    =    new   DeprecationLogger ( ESLoggerFactory . getLogger (  \" deprecation \"  )  )  ;", "final   int   numberOfThreads    =    randomIntBetween (  2  ,     4  )  ;", "final   CyclicBarrier   barrier    =    new   CyclicBarrier (  (  1     +    numberOfThreads )  )  ;", "final   List < Thread >    threads    =    new   ArrayList <  >  (  )  ;", "final   int   iterations    =    randomIntBetween (  1  ,     4  )  ;", "for    ( int   i    =     0  ;    i    <    numberOfThreads ;    i +  +  )     {", "final   Thread   thread    =    new   Thread (  (  )     -  >     {", "final   List < Integer >    ids    =    IntStream . range (  0  ,     1  2  8  )  . boxed (  )  . collect ( Collectors . toList (  )  )  ;", "Randomness . shuffle ( ids )  ;", "final   ThreadContext   threadContext    =    new   ThreadContext ( Settings . EMPTY )  ;", "DeprecationLogger . setThreadContext ( threadContext )  ;", "try    {", "barrier . await (  )  ;", "}    catch    ( BrokenBarrierException    |    InterruptedException   e )     {", "throw   new   RuntimeException ( e )  ;", "}", "for    ( int   j    =     0  ;    j    <    iterations ;    j +  +  )     {", "for    ( final   Integer   id    :    ids )     {", "deprecationLogger . deprecatedAndMaybeLog ( Integer . toString ( id )  ,     (  \" This   is   a   maybe   logged   deprecation   message \"     +    id )  )  ;", "}", "}", "final   List < String >    warnings    =    threadContext . getResponseHeaders (  )  . get (  \" Warning \"  )  ;", "final   Set < String >    actualWarningValues    =    warnings . stream (  )  . map ( DeprecationLogger :  : extractWarningValueFromWarningHeader )  . collect ( Collectors . toSet (  )  )  ;", "for    ( int   j    =     0  ;    j    <     1  2  8  ;    j +  +  )     {", "assertThat ( actualWarningValues ,    hasItem ( DeprecationLogger . escapeAndEncode (  (  \" This   is   a   maybe   logged   deprecation   message \"     +    j )  )  )  )  ;", "}", "try    {", "barrier . await (  )  ;", "}    catch    ( BrokenBarrierException    |    InterruptedException   e )     {", "throw   new   RuntimeException ( e )  ;", "}", "}  )  ;", "threads . add ( thread )  ;", "thread . start (  )  ;", "}", "barrier . await (  )  ;", "barrier . await (  )  ;", "final   String   deprecationPath    =     (  (  ( System . getProperty (  \" es . logs . base _ path \"  )  )     +     ( System . getProperty (  \" file . separator \"  )  )  )     +     ( System . getProperty (  \" es . logs . cluster _ name \"  )  )  )     +     \"  _ deprecation . log \"  ;", "final   List < String >    deprecationEvents    =    Files . readAllLines ( PathUtils . get ( deprecationPath )  )  ;", "deprecationEvents . sort ( Comparator . comparingInt (  (    s )     -  >    Integer . parseInt ( s . split (  \" message \"  )  [  1  ]  )  )  )  ;", "assertThat ( deprecationEvents . size (  )  ,    equalTo (  1  2  8  )  )  ;", "for    ( int   i    =     0  ;    i    <     1  2  8  ;    i +  +  )     {", "assertLogLine ( deprecationEvents . get ( i )  ,    WARN ,     \" DeprecationLogger . deprecated \"  ,     (  \" This   is   a   maybe   logged   deprecation   message \"     +    i )  )  ;", "}", "for    ( final   Thread   thread    :    threads )     {", "thread . join (  )  ;", "}", "}", "METHOD_END"], "methodName": ["testConcurrentDeprecationLogger"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "setupLogging (  \" settings \"  )  ;", "final   Setting < Boolean >    setting    =    Setting . boolSetting (  \" deprecated . foo \"  ,    false ,    Deprecated )  ;", "final   Settings   settings    =    Settings . builder (  )  . put (  \" deprecated . foo \"  ,    true )  . build (  )  ;", "final   int   iterations    =    randomIntBetween (  0  ,     1  2  8  )  ;", "for    ( int   i    =     0  ;    i    <    iterations ;    i +  +  )     {", "setting . get ( settings )  ;", "assertSettingDeprecationsAndWarnings ( new   Setting <  ?  >  [  ]  {    setting    }  )  ;", "}", "final   String   deprecationPath    =     (  (  ( System . getProperty (  \" es . logs . base _ path \"  )  )     +     ( System . getProperty (  \" file . separator \"  )  )  )     +     ( System . getProperty (  \" es . logs . cluster _ name \"  )  )  )     +     \"  _ deprecation . log \"  ;", "final   List < String >    deprecationEvents    =    Files . readAllLines ( PathUtils . get ( deprecationPath )  )  ;", "if    ( iterations    >     0  )     {", "assertThat ( deprecationEvents . size (  )  ,    equalTo (  1  )  )  ;", "assertLogLine ( deprecationEvents . get (  0  )  ,    WARN ,     \" DeprecationLogger . deprecated \"  ,     (  \"  \\  \\  [ deprecated . foo \\  \\  ]    setting   was   deprecated   in   Elasticsearch   and   will   be   removed   in   a   future   release !     \"     +     \" See   the   breaking   changes   documentation   for   the   next   major   version .  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDeprecatedSettings"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "setupLogging (  \" deprecation \"  )  ;", "final   DeprecationLogger   deprecationLogger    =    new   DeprecationLogger ( ESLoggerFactory . getLogger (  \" deprecation \"  )  )  ;", "final   int   deprecatedIterations    =    randomIntBetween (  0  ,     2  5  6  )  ;", "for    ( int   i    =     0  ;    i    <    deprecatedIterations ;    i +  +  )     {", "deprecationLogger . deprecated (  \" This   is   a   deprecation   message \"  )  ;", "assertWarnings (  \" This   is   a   deprecation   message \"  )  ;", "}", "final   String   deprecationPath    =     (  (  ( System . getProperty (  \" es . logs . base _ path \"  )  )     +     ( System . getProperty (  \" file . separator \"  )  )  )     +     ( System . getProperty (  \" es . logs . cluster _ name \"  )  )  )     +     \"  _ deprecation . log \"  ;", "final   List < String >    deprecationEvents    =    Files . readAllLines ( PathUtils . get ( deprecationPath )  )  ;", "assertThat ( deprecationEvents . size (  )  ,    equalTo ( deprecatedIterations )  )  ;", "for    ( int   i    =     0  ;    i    <    deprecatedIterations ;    i +  +  )     {", "assertLogLine ( deprecationEvents . get ( i )  ,    WARN ,     \" DeprecationLogger . deprecated \"  ,     \" This   is   a   deprecation   message \"  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDeprecationLogger"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "setupLogging (  \" deprecation \"  )  ;", "final   DeprecationLogger   deprecationLogger    =    new   DeprecationLogger ( ESLoggerFactory . getLogger (  \" deprecation \"  )  )  ;", "final   int   iterations    =    randomIntBetween (  1  ,     1  6  )  ;", "for    ( int   i    =     0  ;    i    <    iterations ;    i +  +  )     {", "deprecationLogger . deprecatedAndMaybeLog (  \" key \"  ,     \" This   is   a   maybe   logged   deprecation   message \"  )  ;", "assertWarnings (  \" This   is   a   maybe   logged   deprecation   message \"  )  ;", "}", "for    ( int   k    =     0  ;    k    <     1  2  8  ;    k +  +  )     {", "for    ( int   i    =     0  ;    i    <    iterations ;    i +  +  )     {", "deprecationLogger . deprecatedAndMaybeLog (  (  \" key \"     +    k )  ,     (  \" This   is   a   maybe   logged   deprecation   message \"     +    k )  )  ;", "assertWarnings (  (  \" This   is   a   maybe   logged   deprecation   message \"     +    k )  )  ;", "}", "}", "for    ( int   i    =     0  ;    i    <    iterations ;    i +  +  )     {", "deprecationLogger . deprecatedAndMaybeLog (  \" key \"  ,     \" This   is   a   maybe   logged   deprecation   message \"  )  ;", "assertWarnings (  \" This   is   a   maybe   logged   deprecation   message \"  )  ;", "}", "final   String   deprecationPath    =     (  (  ( System . getProperty (  \" es . logs . base _ path \"  )  )     +     ( System . getProperty (  \" file . separator \"  )  )  )     +     ( System . getProperty (  \" es . logs . cluster _ name \"  )  )  )     +     \"  _ deprecation . log \"  ;", "final   List < String >    deprecationEvents    =    Files . readAllLines ( PathUtils . get ( deprecationPath )  )  ;", "assertThat ( deprecationEvents . size (  )  ,    equalTo (  (  (  1     +     1  2  8  )     +     1  )  )  )  ;", "assertLogLine ( deprecationEvents . get (  0  )  ,    WARN ,     \" DeprecationLogger . deprecated \"  ,     \" This   is   a   maybe   logged   deprecation   message \"  )  ;", "for    ( int   k    =     0  ;    k    <     1  2  8  ;    k +  +  )     {", "assertLogLine ( deprecationEvents . get (  (  1     +    k )  )  ,    WARN ,     \" DeprecationLogger . deprecated \"  ,     (  \" This   is   a   maybe   logged   deprecation   message \"     +    k )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDeprecationLoggerMaybeLog"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "setupLogging (  \" find _ appender \"  )  ;", "final   Logger   hasConsoleAppender    =    ESLoggerFactory . getLogger (  \" has _ console _ appender \"  )  ;", "final   Appender   testLoggerConsoleAppender    =    Loggers . findAppender ( hasConsoleAppender ,    ConsoleAppender . class )  ;", "assertNotNull ( testLoggerConsoleAppender )  ;", "assertThat ( testLoggerConsoleAppender . getName (  )  ,    equalTo (  \" console \"  )  )  ;", "final   Logger   hasCountingNoOpAppender    =    ESLoggerFactory . getLogger (  \" has _ counting _ no _ op _ appender \"  )  ;", "assertNull ( Loggers . findAppender ( hasCountingNoOpAppender ,    ConsoleAppender . class )  )  ;", "final   Appender   countingNoOpAppender    =    Loggers . findAppender ( hasCountingNoOpAppender ,    CountingNoOpAppender . class )  ;", "assertThat ( countingNoOpAppender . getName (  )  ,    equalTo (  \" counting _ no _ op \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFindAppender"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "setupLogging (  \" location _ info \"  )  ;", "final   Logger   testLogger    =    ESLoggerFactory . getLogger (  \" test \"  )  ;", "testLogger . error (  \" This   is   an   error   message \"  )  ;", "testLogger . warn (  \" This   is   a   warning   message \"  )  ;", "testLogger . info (  \" This   is   an   info   message \"  )  ;", "testLogger . debug (  \" This   is   a   debug   message \"  )  ;", "testLogger . trace (  \" This   is   a   trace   message \"  )  ;", "final   String   path    =     (  (  ( System . getProperty (  \" es . logs . base _ path \"  )  )     +     ( System . getProperty (  \" file . separator \"  )  )  )     +     ( System . getProperty (  \" es . logs . cluster _ name \"  )  )  )     +     \"  . log \"  ;", "final   List < String >    events    =    Files . readAllLines ( PathUtils . get ( path )  )  ;", "assertThat ( events . size (  )  ,    equalTo (  5  )  )  ;", "final   String   location    =     \"  . testLocationInfoTest \"  ;", "assertLogLine ( events . get (  0  )  ,    ERROR ,    location ,     \" This   is   an   error   message \"  )  ;", "assertLogLine ( events . get (  1  )  ,    WARN ,    location ,     \" This   is   a   warning   message \"  )  ;", "assertLogLine ( events . get (  2  )  ,    INFO ,    location ,     \" This   is   an   info   message \"  )  ;", "assertLogLine ( events . get (  3  )  ,    DEBUG ,    location ,     \" This   is   a   debug   message \"  )  ;", "assertLogLine ( events . get (  4  )  ,    TRACE ,    location ,     \" This   is   a   trace   message \"  )  ;", "}", "METHOD_END"], "methodName": ["testLocationInfoTest"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "setupLogging (  \" prefix \"  )  ;", "final   String   prefix    =     ( randomBoolean (  )  )     ?    null    :    randomAlphaOfLength (  1  6  )  ;", "final   Logger   logger    =    Loggers . getLogger (  \" prefix \"  ,    prefix )  ;", "logger . info (  \" test \"  )  ;", "logger . info (  \"  {  }  \"  ,     \" test \"  )  ;", "final   Exception   e    =    new   Exception (  \" exception \"  )  ;", "logger . info ( new   ParameterizedMessage (  \"  {  }  \"  ,     \" test \"  )  ,    e )  ;", "final   String   path    =     (  (  ( System . getProperty (  \" es . logs . base _ path \"  )  )     +     ( System . getProperty (  \" file . separator \"  )  )  )     +     ( System . getProperty (  \" es . logs . cluster _ name \"  )  )  )     +     \"  . log \"  ;", "final   List < String >    events    =    Files . readAllLines ( PathUtils . get ( path )  )  ;", "final   StringWriter   sw    =    new   StringWriter (  )  ;", "final   PrintWriter   pw    =    new   PrintWriter ( sw )  ;", "e . printStackTrace ( pw )  ;", "final   int   stackTraceLength    =    sw . toString (  )  . split ( System . getProperty (  \" line . separator \"  )  )  . length ;", "final   int   expectedLogLines    =     3  ;", "assertThat ( events . size (  )  ,    equalTo (  ( expectedLogLines    +    stackTraceLength )  )  )  ;", "for    ( int   i    =     0  ;    i    <    expectedLogLines ;    i +  +  )     {", "if    ( prefix    =  =    null )     {", "assertThat ( events . get ( i )  ,    startsWith (  \" test \"  )  )  ;", "} else    {", "assertThat ( events . get ( i )  ,    startsWith (  (  (  \"  [  \"     +    prefix )     +     \"  ]    test \"  )  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testPrefixLogger"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "setupLogging (  \" prefix \"  )  ;", "final   int   prefixes    =     1     <  <     1  9  ;", "for    ( int   i    =     0  ;    i    <    prefixes ;    i +  +  )     {", "Loggers . getLogger (  (  \" prefix \"     +    i )  ,     (  \" prefix \"     +    i )  )  ;", "}", "System . gc (  )  ;", "assertThat ( PrefixLogger . markersSize (  )  ,    lessThan ( prefixes )  )  ;", "}", "METHOD_END"], "methodName": ["testPrefixLoggerMarkersCanBeCollected"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "final   Settings . Builder   builder    =    Settings . builder (  )  . put (  \" cluster . name \"  ,    randomAlphaOfLength (  1  6  )  )  ;", "if    ( randomBoolean (  )  )     {", "builder . put (  \" node . name \"  ,    randomAlphaOfLength (  1  6  )  )  ;", "}", "final   Settings   settings    =    builder . build (  )  ;", "setupL (  \" minimal \"  ,    settings )  ;", "assertNotNull ( System . getProperty (  \" es . logs . base _ path \"  )  )  ;", "assertThat ( System . getProperty (  \" es . logs . cluster _ name \"  )  ,    equalTo ( CLUSTER _ NAME _ SETTING . get ( settings )  . value (  )  )  )  ;", "if    ( NODE _ NAME _ SETTING . exists ( settings )  )     {", "assertThat ( System . getProperty (  \" es . logs . node _ name \"  )  ,    equalTo ( NODE _ NAME _ SETTING . get ( settings )  )  )  ;", "} else    {", "assertNull ( System . getProperty (  \" es . logs . node _ name \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testProperties"], "fileName": "org.elasticsearch.common.logging.EvilLoggerTests"}, {"methodBody": ["METHOD_START", "{", "NodeEnvironmentEvilTests . isPosix    =     ( Files . getFileAttributeView ( createTempFile (  )  ,    PosixFileAttributeView . class )  )     !  =    null ;", "}", "METHOD_END"], "methodName": ["checkPosix"], "fileName": "org.elasticsearch.env.NodeEnvironmentEvilTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" posix   filesystem \"  ,    NodeEnvironmentEvilTests . isPosix )  ;", "final   String [  ]    tempPaths    =    tmpPaths (  )  ;", "Path   path    =    PathUtils . get ( randomFrom ( tempPaths )  )  ;", "try    ( PosixPermissionsResetter   attr    =    new   PosixPermissionsResetter ( path )  )     {", "attr . setPermissions ( new   HashSet ( Arrays . asList ( PosixFilePermission . OTHERS _ READ ,    PosixFilePermission . GROUP _ READ ,    PosixFilePermission . OWNER _ READ )  )  )  ;", "Settings   build    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toAbsolutePath (  )  . toString (  )  )  . putList ( PATH _ DATA _ SETTING . getKey (  )  ,    tempPaths )  . build (  )  ;", "IOException   ioException    =    expectThrows ( IOException . class ,     (  )     -  >     {", "new   NodeEnvironment ( build ,    TestEnvironment . newEnvironment ( build )  )  ;", "}  )  ;", "assertTrue ( ioException . getMessage (  )  ,    ioException . getMessage (  )  . startsWith ( path . toString (  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMissingWritePermission"], "fileName": "org.elasticsearch.env.NodeEnvironmentEvilTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" posix   filesystem \"  ,    NodeEnvironmentEvilTests . isPosix )  ;", "final   String [  ]    tempPaths    =    tmpPaths (  )  ;", "Path   path    =    PathUtils . get ( randomFrom ( tempPaths )  )  ;", "Path   fooIndex    =    path . resolve (  \" nodes \"  )  . resolve (  \"  0  \"  )  . resolve ( INDICES _ FOLDER )  . resolve (  \" foo \"  )  ;", "Files . createDirectories ( fooIndex )  ;", "try    ( PosixPermissionsResetter   attr    =    new   PosixPermissionsResetter ( fooIndex )  )     {", "attr . setPermissions ( new   HashSet ( Arrays . asList ( PosixFilePermission . OTHERS _ READ ,    PosixFilePermission . GROUP _ READ ,    PosixFilePermission . OWNER _ READ )  )  )  ;", "Settings   build    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toAbsolutePath (  )  . toString (  )  )  . putList ( PATH _ DATA _ SETTING . getKey (  )  ,    tempPaths )  . build (  )  ;", "IOException   ioException    =    expectThrows ( IOException . class ,     (  )     -  >     {", "new   NodeEnvironment ( build ,    TestEnvironment . newEnvironment ( build )  )  ;", "}  )  ;", "assertTrue ( ioException . getMessage (  )  ,    ioException . getMessage (  )  . startsWith (  \" failed   to   test   writes   in   data   directory \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMissingWritePermissionOnIndex"], "fileName": "org.elasticsearch.env.NodeEnvironmentEvilTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" posix   filesystem \"  ,    NodeEnvironmentEvilTests . isPosix )  ;", "final   String [  ]    tempPaths    =    tmpPaths (  )  ;", "Path   path    =    PathUtils . get ( randomFrom ( tempPaths )  )  ;", "Path   fooIndex    =    path . resolve (  \" nodes \"  )  . resolve (  \"  0  \"  )  . resolve ( INDICES _ FOLDER )  . resolve (  \" foo \"  )  ;", "Path   fooShard    =    fooIndex . resolve (  \"  0  \"  )  ;", "Path   fooShardIndex    =    fooShard . resolve (  \" index \"  )  ;", "Path   fooShardTranslog    =    fooShard . resolve (  \" translog \"  )  ;", "Path   fooShardState    =    fooShard . resolve (  \"  _ state \"  )  ;", "Path   pick    =    randomFrom ( fooShard ,    fooShardIndex ,    fooShardTranslog ,    fooShardState )  ;", "Files . createDirectories ( pick )  ;", "try    ( PosixPermissionsResetter   attr    =    new   PosixPermissionsResetter ( pick )  )     {", "attr . setPermissions ( new   HashSet ( Arrays . asList ( PosixFilePermission . OTHERS _ READ ,    PosixFilePermission . GROUP _ READ ,    PosixFilePermission . OWNER _ READ )  )  )  ;", "Settings   build    =    Settings . builder (  )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    createTempDir (  )  . toAbsolutePath (  )  . toString (  )  )  . putList ( PATH _ DATA _ SETTING . getKey (  )  ,    tempPaths )  . build (  )  ;", "IOException   ioException    =    expectThrows ( IOException . class ,     (  )     -  >     {", "new   NodeEnvironment ( build ,    TestEnvironment . newEnvironment ( build )  )  ;", "}  )  ;", "assertTrue ( ioException . getMessage (  )  ,    ioException . getMessage (  )  . startsWith (  \" failed   to   test   writes   in   data   directory \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testMissingWritePermissionOnShard"], "fileName": "org.elasticsearch.env.NodeEnvironmentEvilTests"}, {"methodBody": ["METHOD_START", "{", "assertGetRequestsContainHeaders ( this . lookupIndex )  ;", "}", "METHOD_END"], "methodName": ["assertGetRequestsContainHeaders"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "List < ContextAndHeaderTransportIT . RequestAndHeaders >    getRequests    =    getRequests ( GetRequest . class )  ;", "assertThat ( getRequests ,    hasSize ( greaterThan (  0  )  )  )  ;", "for    ( ContextAndHeaderTransportIT . RequestAndHeaders   request    :    getRequests )     {", "if    (  !  (  (  ( GetRequest )     ( request . request )  )  . index (  )  . equals ( index )  )  )     {", "continue ;", "}", "assertRequestContainsHeader ( request . request ,    request . headers )  ;", "}", "}", "METHOD_END"], "methodName": ["assertGetRequestsContainHeaders"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "String   msg    =    String . format ( Locale . ROOT ,     \" Expected   header    % s   to   be   in   request    % s \"  ,    ContextAndHeaderTransportIT . CUSTOM _ HEADER ,    request . getClass (  )  . getName (  )  )  ;", "if    ( request   instanceof   IndexRequest )     {", "IndexRequest   indexRequest    =     (  ( IndexRequest )     ( request )  )  ;", "msg    =    String . format ( Locale . ROOT ,     \" Expected   header    % s   to   be   in   index   request    % s /  % s /  % s \"  ,    ContextAndHeaderTransportIT . CUSTOM _ HEADER ,    indexRequest . index (  )  ,    indexRequest . type (  )  ,    indexRequest . id (  )  )  ;", "}", "assertThat ( msg ,    context . containsKey ( ContextAndHeaderTransportIT . CUSTOM _ HEADER )  ,    is ( true )  )  ;", "assertThat ( context . get ( ContextAndHeaderTransportIT . CUSTOM _ HEADER )  . toString (  )  ,    is ( randomHeaderValue )  )  ;", "}", "METHOD_END"], "methodName": ["assertRequestContainsHeader"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "List < ContextAndHeaderTransportIT . RequestAndHeaders >    classRequests    =    getRequests ( clazz )  ;", "for    ( ContextAndHeaderTransportIT . RequestAndHeaders   request    :    classRequests )     {", "assertRequestContainsHeader ( request . request ,    request . headers )  ;", "}", "}", "METHOD_END"], "methodName": ["assertRequestsContainHeader"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "assertRequestsContainHeader ( IndexRequest . class )  ;", "assertRequestsContainHeader ( RefreshRequest . class )  ;", "}", "METHOD_END"], "methodName": ["checkAllRequestsContainHeaders"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "String   mapping    =    Strings . toString ( jsonBuilder (  )  . startObject (  )  . startObject (  \" type \"  )  . startObject (  \" properties \"  )  . startObject (  \" location \"  )  . field (  \" type \"  ,     \" geo _ shape \"  )  . endObject (  )  . startObject (  \" name \"  )  . field (  \" type \"  ,     \" text \"  )  . endObject (  )  . endObject (  )  . endObject (  )  . endObject (  )  )  ;", "Settings   settings    =    Settings . builder (  )  . put ( indexSettings (  )  )  . put ( IndexMetaData . SETTING _ NUMBER _ OF _ SHARDS ,     1  )  . build (  )  ;", "assertAcked ( transportClient (  )  . admin (  )  . indices (  )  . prepareCreate ( lookupIndex )  . setSettings ( settings )  . addMapping (  \" type \"  ,    mapping ,    JSON )  )  ;", "assertAcked ( transportClient (  )  . admin (  )  . indices (  )  . prepareCreate ( queryIndex )  . setSettings ( settings )  . addMapping (  \" type \"  ,    mapping ,    JSON )  )  ;", "ensureGreen ( queryIndex ,    lookupIndex )  ;", ". requests . clear (  )  ;", "}", "METHOD_END"], "methodName": ["createIndices"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "List < ContextAndHeaderTransportIT . RequestAndHeaders >    results    =    new   ArrayList <  >  (  )  ;", "for    ( ContextAndHeaderTransportIT . RequestAndHeaders   request    :    ContextAndHeaderTransportIT . requests )     {", "if    ( request . request . getClass (  )  . equals ( clazz )  )     {", "results . add ( request )  ;", "}", "}", "return   results ;", "}", "METHOD_END"], "methodName": ["getRequests"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "transportClient (  )  . prepareIndex ( lookupIndex ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" name \"  ,     \" Munich   Suburban   Area \"  )  . startObject (  \" location \"  )  . field (  \" type \"  ,     \" polygon \"  )  . startArray (  \" coordinates \"  )  . startArray (  )  . startArray (  )  . value (  1  1  .  3  4  )  . value (  4  8  .  2  5  )  . endArray (  )  . startArray (  )  . value (  1  1  .  6  8  )  . value (  4  8  .  2  5  )  . endArray (  )  . startArray (  )  . value (  1  1  .  6  5  )  . value (  4  8  .  0  6  )  . endArray (  )  . startArray (  )  . value (  1  1  .  3  7  )  . value (  4  8  .  1  3  )  . endArray (  )  . startArray (  )  . value (  1  1  .  3  4  )  . value (  4  8  .  2  5  )  . endArray (  )  . endArray (  )  . endArray (  )  . endObject (  )  . endObject (  )  )  . get (  )  ;", "transportClient (  )  . prepareIndex ( queryIndex ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" name \"  ,     \" Munich   Center \"  )  . startObject (  \" location \"  )  . field (  \" type \"  ,     \" point \"  )  . startArray (  \" coordinates \"  )  . value (  1  1  .  5  7  )  . value (  4  8  .  1  3  )  . endArray (  )  . endObject (  )  . endObject (  )  )  . get (  )  ;", "transportClient (  )  . admin (  )  . indices (  )  . prepareRefresh ( lookupIndex ,    queryIndex )  . get (  )  ;", "GeoShapeQueryBuilder   queryBuilder    =    QueryBuilders . geoShapeQuery (  \" location \"  ,     \"  1  \"  ,     \" type \"  )  . indexedShapeIndex ( lookupIndex )  . indexedShapePath (  \" location \"  )  ;", "SearchResponse   searchResponse    =    transportClient (  )  . prepareSearch ( queryIndex )  . setQuery ( queryBuilder )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertHitCount ( searchResponse ,     1  )  ;", "assertThat (  . requests ,    hasSize ( greaterThan (  0  )  )  )  ;", "assertGetRequestsContainHeaders (  )  ;", "}", "METHOD_END"], "methodName": ["testThatGeoShapeQueryGetRequestContainsContextAndHeaders"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "transportClient (  )  . prepareIndex ( lookupIndex ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" name \"  ,     \" Star   Wars    -    The   new   republic \"  )  . endObject (  )  )  . get (  )  ;", "transportClient (  )  . prepareIndex ( queryIndex ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" name \"  ,     \" Jar   Jar   Binks    -    A   horrible   mistake \"  )  . endObject (  )  )  . get (  )  ;", "transportClient (  )  . prepareIndex ( queryIndex ,     \" type \"  ,     \"  2  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" name \"  ,     \" Star   Wars    -    Return   of   the   jedi \"  )  . endObject (  )  )  . get (  )  ;", "transportClient (  )  . admin (  )  . indices (  )  . prepareRefresh ( lookupIndex ,    queryIndex )  . get (  )  ;", "MoreLikeThisQueryBuilder   moreLikeThisQueryBuilder    =    QueryBuilders . moreLikeThisQuery ( new   String [  ]  {     \" name \"     }  ,    null ,    new   Item [  ]  {    new   Item ( lookupIndex ,     \" type \"  ,     \"  1  \"  )     }  )  . minTermFreq (  1  )  . minDocFreq (  1  )  ;", "SearchResponse   searchResponse    =    transportClient (  )  . prepareSearch ( queryIndex )  . setQuery ( moreLikeThisQueryBuilder )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertHitCount ( searchResponse ,     1  )  ;", "assertRequestsContainHeader ( MultiTermVectorsRequest . class )  ;", "}", "METHOD_END"], "methodName": ["testThatMoreLikeThisQueryMultiTermVectorRequestContainsContextAndHeaders"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "final   String   IRRELEVANT _ HEADER    =     \" SomeIrrelevantHeader \"  ;", "Response   response    =    getRestClient (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( queryIndex )  )     +     \"  /  _ search \"  )  ,    new   BasicHeader (  . CUSTOM _ HEADER ,    randomHeaderValue )  ,    new   BasicHeader ( IRRELEVANT _ HEADER ,    randomHeaderValue )  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    equalTo (  2  0  0  )  )  ;", "List <  . RequestAndHeaders >    searchRequests    =    getRequests ( SearchRequest . class )  ;", "assertThat ( searchRequests ,    hasSize ( greaterThan (  0  )  )  )  ;", "for    (  . RequestAndHeaders   requestAndHeaders    :    searchRequests )     {", "assertThat ( requestAndHeaders . headers . containsKey (  . CUSTOM _ HEADER )  ,    is ( true )  )  ;", "assertThat ( requestAndHeaders . headers . containsKey ( IRRELEVANT _ HEADER )  ,    is ( false )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatRelevantHttpHeadersBecomeRequestHeaders"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "transportClient (  )  . prepareIndex ( lookupIndex ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . array (  \" followers \"  ,     \" foo \"  ,     \" bar \"  ,     \" baz \"  )  . endObject (  )  )  . get (  )  ;", "transportClient (  )  . prepareIndex ( queryIndex ,     \" type \"  ,     \"  1  \"  )  . setSource ( jsonBuilder (  )  . startObject (  )  . field (  \" username \"  ,     \" foo \"  )  . endObject (  )  )  . get (  )  ;", "transportClient (  )  . admin (  )  . indices (  )  . prepareRefresh ( queryIndex ,    lookupIndex )  . get (  )  ;", "TermsLookup   termsLookup    =    new   TermsLookup ( lookupIndex ,     \" type \"  ,     \"  1  \"  ,     \" followers \"  )  ;", "TermsQueryBuilder   termsLookupFilterBuilder    =    QueryBuilders . termsLookupQuery (  \" username \"  ,    termsLookup )  ;", "BoolQueryBuilder   queryBuilder    =    QueryBuilders . boolQuery (  )  . must ( QueryBuilders . matchAllQuery (  )  )  . must ( termsLookupFilterBuilder )  ;", "SearchResponse   searchResponse    =    transportClient (  )  . prepareSearch ( queryIndex )  . setQuery ( queryBuilder )  . get (  )  ;", "assertNoFailures ( searchResponse )  ;", "assertHitCount ( searchResponse ,     1  )  ;", "assertGetRequestsContainHeaders (  )  ;", "}", "METHOD_END"], "methodName": ["testThatTermsLookupGetRequestContainsContextAndHeaders"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "return   internalCluster (  )  . transportClient (  )  . filterWithHeader ( Collections . singletonMap ( ContextAndHeaderTransportIT . CUSTOM _ HEADER ,    randomHeaderValue )  )  ;", "}", "METHOD_END"], "methodName": ["transportClient"], "fileName": "org.elasticsearch.http.ContextAndHeaderTransportIT"}, {"methodBody": ["METHOD_START", "{", "String   corsValue    =     \" http :  /  / localhost :  9  2  0  0  \"  ;", "Response   response    =    getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  \"  ,    new   BasicHeader (  \" User - Agent \"  ,     \" Mozilla   Bar \"  )  ,    new   BasicHeader (  \" Origin \"  ,    corsValue )  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  2  0  0  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Origin \"  )  ,    nullValue (  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Credentials \"  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testCorsSettingDefaultBehaviourDoesNotReturnAnything"], "fileName": "org.elasticsearch.http.CorsNotSetIT"}, {"methodBody": ["METHOD_START", "{", "Response   response    =    getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  \"  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  2  0  0  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Origin \"  )  ,    nullValue (  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Credentials \"  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatOmittingCorsHeaderDoesNotReturnAnything"], "fileName": "org.elasticsearch.http.CorsNotSetIT"}, {"methodBody": ["METHOD_START", "{", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  2  0  0  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Origin \"  )  ,    is ( expectedHeader )  )  ;", "}", "METHOD_END"], "methodName": ["assertResponseWithOriginheader"], "fileName": "org.elasticsearch.http.CorsRegexIT"}, {"methodBody": ["METHOD_START", "{", "try    {", "getRestClient (  )  . performRequest (  \" OPTIONS \"  ,     \"  /  \"  ,    new   BasicHeader (  \" User - Agent \"  ,     \" Mozilla   Bar \"  )  ,    new   BasicHeader (  \" Origin \"  ,     \"  :  /  / evil - host :  9  2  0  0  \"  )  ,    new   BasicHeader (  \" Access - Control - Request - Method \"  ,     \" GET \"  )  )  ;", "fail (  \" request   should   have   failed \"  )  ;", "}    catch    ( ResponseException   e )     {", "Response   response    =    e . getResponse (  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  4  0  3  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Origin \"  )  ,    nullValue (  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Methods \"  )  ,    nullValue (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatPreFlightRequestReturnsNullOnNonMatch"], "fileName": "org.elasticsearch.http.CorsRegexIT"}, {"methodBody": ["METHOD_START", "{", "String   corsValue    =     \" http :  /  / localhost :  9  2  0  0  \"  ;", "Response   response    =    getRestClient (  )  . performRequest (  \" OPTIONS \"  ,     \"  /  \"  ,    new   BasicHeader (  \" User - Agent \"  ,     \" Mozilla   Bar \"  )  ,    new   BasicHeader (  \" Origin \"  ,    corsValue )  ,    new   BasicHeader (  \" Access - Control - Request - Method \"  ,     \" GET \"  )  )  ;", ". assertResponseWithOriginheader ( response ,    corsValue )  ;", "assertNotNull ( response . getHeader (  \" Access - Control - Allow - Methods \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatPreFlightRequestWorksOnMatch"], "fileName": "org.elasticsearch.http.CorsRegexIT"}, {"methodBody": ["METHOD_START", "{", "Response   response    =    getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  \"  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  2  0  0  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Origin \"  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatRegularExpressionIsNotAppliedWithoutCorrectBrowserOnMatch"], "fileName": "org.elasticsearch.http.CorsRegexIT"}, {"methodBody": ["METHOD_START", "{", "try    {", "getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  \"  ,    new   BasicHeader (  \" User - Agent \"  ,     \" Mozilla   Bar \"  )  ,    new   BasicHeader (  \" Origin \"  ,     \"  :  /  / evil - host :  9  2  0  0  \"  )  )  ;", "fail (  \" request   should   have   failed \"  )  ;", "}    catch    ( ResponseException   e )     {", "Response   response    =    e . getResponse (  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  4  0  3  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Origin \"  )  ,    nullValue (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatRegularExpressionReturnsForbiddenOnNonMatch"], "fileName": "org.elasticsearch.http.CorsRegexIT"}, {"methodBody": ["METHOD_START", "{", "String   corsValue    =     \" http :  /  / localhost :  9  2  0  0  \"  ;", "Response   response    =    getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  \"  ,    new   BasicHeader (  \" User - Agent \"  ,     \" Mozilla   Bar \"  )  ,    new   BasicHeader (  \" Origin \"  ,    corsValue )  )  ;", ". assertResponseWithOriginheader ( response ,    corsValue )  ;", "corsValue    =     \" https :  /  / localhost :  9  2  0  0  \"  ;", "response    =    getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  \"  ,    new   BasicHeader (  \" User - Agent \"  ,     \" Mozilla   Bar \"  )  ,    new   BasicHeader (  \" Origin \"  ,    corsValue )  )  ;", ". assertResponseWithOriginheader ( response ,    corsValue )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Credentials \"  )  ,    is (  \" true \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatRegularExpressionWorksOnMatch"], "fileName": "org.elasticsearch.http.CorsRegexIT"}, {"methodBody": ["METHOD_START", "{", "Response   response    =    getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  \"  ,    new   BasicHeader (  \" User - Agent \"  ,     \" Mozilla   Bar \"  )  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  2  0  0  )  )  ;", "assertThat ( response . getHeader (  \" Access - Control - Allow - Origin \"  )  ,    nullValue (  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatSendingNoOriginHeaderReturnsNoAccessControlHeader"], "fileName": "org.elasticsearch.http.CorsRegexIT"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   builder    =    JsonXContent . contentBuilder (  )  ;", "builder . startObject (  )  . startArray (  ( useedField    ?     \" deprecated _ settings \"     :     \" settings \"  )  )  ;", "for    ( Setting < Boolean >    setting    :    settings )     {", "builder . value ( setting . getKey (  )  )  ;", "}", "builder . endArray (  )  . endObject (  )  ;", "return   new   StringEntity ( Strings . toString ( builder )  ,    ContentType . APPLICATION _ JSON )  ;", "}", "METHOD_END"], "methodName": ["buildSettingsRequest"], "fileName": "org.elasticsearch.http.DeprecationHttpIT"}, {"methodBody": ["METHOD_START", "{", "final   boolean   useDeprecatedField    =    randomBoolean (  )  ;", "final   boolean   useNonDeprecatedSetting    =    randomBoolean (  )  ;", "final   List < Setting < Boolean >  >    settings    =    new   ArrayList <  >  (  3  )  ;", "settings . add ( TesteaderRestAction . TEST _ DEPRECATED _ SETTING _ TRUE 1  )  ;", "if    ( randomBoolean (  )  )     {", "settings . add ( TesteaderRestAction . TEST _ DEPRECATED _ SETTING _ TRUE 2  )  ;", "}", "if    ( useNonDeprecatedSetting )     {", "settings . add ( TesteaderRestAction . TEST _ NOT _ DEPRECATED _ SETTING )  ;", "}", "Collections . shuffle ( settings ,    random (  )  )  ;", "Response   response    =    getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  _ test _ cluster / deprecated _ settings \"  ,    Collections . emptyMap (  )  ,    buildSettingsRequest ( settings ,    useDeprecatedField )  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    equalTo ( OK . getStatus (  )  )  )  ;", "final   List < String >    deprecatedWarnings    =    getWarningHeaders ( response . getHeaders (  )  )  ;", "final   List < Matcher < String >  >    headerMatchers    =    new   ArrayList <  >  (  4  )  ;", "headerMatchers . add ( equalTo ( TesteaderRestAction . DEPRECATED _ ENDPOINT )  )  ;", "if    ( useDeprecatedField )     {", "headerMatchers . add ( equalTo ( TesteaderRestAction . DEPRECATED _ USAGE )  )  ;", "}", "for    ( Setting <  ?  >    setting    :    settings )     {", "if    ( setting . isDeprecated (  )  )     {", "headerMatchers . add ( equalTo (  (  (  (  \"  [  \"     +     ( setting . getKey (  )  )  )     +     \"  ]    setting   was   deprecated   in   Elasticsearch   and   will   be   removed   in   a   future   release !     \"  )     +     \" See   the   breaking   changes   documentation   for   the   next   major   version .  \"  )  )  )  ;", "}", "}", "assertThat ( deprecatedWarnings ,    hasSize ( headerMatchers . size (  )  )  )  ;", "for    ( final   String   deprecatedWarning    :    deprecatedWarnings )     {", "assertThat ( deprecatedWarning ,    matches ( DeprecationLogger . WARNING _ HEADER _ PATTERN . pattern (  )  )  )  ;", "}", "final   List < String >    actualWarningValues    =    deprecatedWarnings . stream (  )  . map ( DeprecationLogger :  : extractWarningValueFromWarningHeader )  . collect ( Collectors . toList (  )  )  ;", "for    ( Matcher < String >    headerMatcher    :    headerMatchers )     {", "assertThat ( actualWarningValues ,    hasItem ( headerMatcher )  )  ;", "}", "}", "METHOD_END"], "methodName": ["doTestDeprecationWarningsAppearInHeaders"], "fileName": "org.elasticsearch.http.DeprecationHttpIT"}, {"methodBody": ["METHOD_START", "{", "List < String >    warnings    =    new   ArrayList <  >  (  )  ;", "for    ( Header   header    :    headers )     {", "if    ( header . getName (  )  . equals (  \" Warning \"  )  )     {", "warnings . add ( header . getValue (  )  )  ;", "}", "}", "return   warnings ;", "}", "METHOD_END"], "methodName": ["getWarningHeaders"], "fileName": "org.elasticsearch.http.DeprecationHttpIT"}, {"methodBody": ["METHOD_START", "{", "doTestDeprecationWarningsAppearInHeaders (  )  ;", "doTestDeprecationWarningsAppearInHeaders (  )  ;", "if    ( rarely (  )  )     {", "doTestDeprecationWarningsAppearInHeaders (  )  ;", "}", "}", "METHOD_END"], "methodName": ["testDeprecationHeadersDoNotGetStuck"], "fileName": "org.elasticsearch.http.DeprecationHttpIT"}, {"methodBody": ["METHOD_START", "{", "doTestDeprecationWarningsAppearInHeaders (  )  ;", "}", "METHOD_END"], "methodName": ["testDeprecationWarningsAppearInHeaders"], "fileName": "org.elasticsearch.http.DeprecationHttpIT"}, {"methodBody": ["METHOD_START", "{", "final   String [  ]    indices    =    new   String [ randomIntBetween (  2  ,     5  )  ]  ;", "for    ( int   i    =     0  ;    i    <     ( indices . length )  ;     +  + i )     {", "indices [ i ]     =     \" test \"     +    i ;", "assertTrue ( prepareCreate ( indices [ i ]  )  . setSettings ( Settings . builder (  )  . put (  \" number _ of _ shards \"  ,     1  )  )  . get (  )  . isAcknowledged (  )  )  ;", "int   randomDocCount    =    randomIntBetween (  1  ,     2  )  ;", "for    ( int   j    =     0  ;    j    <    randomDocCount ;     +  + j )     {", "index ( indices [ i ]  ,     \" type \"  ,    Integer . toString ( j )  ,     (  (  \"  {  \\  \" field \\  \"  :  \"     +    j )     +     \"  }  \"  )  )  ;", "}", "}", "refresh ( indices )  ;", "final   String   commaSeparatedIndices    =    Stream . of ( indices )  . collect ( Collectors . joining (  \"  ,  \"  )  )  ;", "final   String   body    =     (  \"  {  \\  \" query \\  \"  :  {  \\  \" bool \\  \"  :  {  \\  \" filter \\  \"  :  [  {  \\  \"  \"     +     ( TestedQueryBuilder . NAME )  )     +     \"  \\  \"  :  {  }  }  ]  }  }  }  \"  ;", "Response   response    =    getRestClient (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +    commaSeparatedIndices )     +     \"  /  _ search \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( body ,    ContentType . APPLICATION _ JSON )  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    equalTo ( OK . getStatus (  )  )  )  ;", "final   List < String >    deprecatedWarnings    =    getWarningHeaders ( response . getHeaders (  )  )  ;", "final   List < Matcher < String >  >    headerMatchers    =    new   ArrayList <  >  ( indices . length )  ;", "for    ( String   index    :    indices )     {", "headerMatchers . add ( containsString ( LoggerMessageFormat . format (  \"  [  {  }  ]    index \"  ,     (  ( Object )     ( index )  )  )  )  )  ;", "}", "assertThat ( deprecatedWarnings ,    hasSize ( headerMatchers . size (  )  )  )  ;", "for    ( Matcher < String >    headerMatcher    :    headerMatchers )     {", "assertThat ( deprecatedWarnings ,    hasItem ( headerMatcher )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testUniqueDeprecationResponsesMergedTogether"], "fileName": "org.elasticsearch.http.DeprecationHttpIT"}, {"methodBody": ["METHOD_START", "{", "ResponseException   e    =    expectThrows ( ResponseException . class ,     (  )     -  >    getRestClient (  )  . performRequest (  \" DELETE \"  ,     \"  /  \"  ,    Collections . singletonMap (  \" error _ trace \"  ,     \" true \"  )  )  )  ;", "Response   response    =    e . getResponse (  )  ;", "assertThat ( response . getHeader (  \" Content - Type \"  )  ,    is (  \" application / json ;    charset = UTF -  8  \"  )  )  ;", "assertThat ( EntityUtils . toString ( e . getResponse (  )  . getEntity (  )  )  ,    containsString (  \"  \\  \" error \\  \"  :  \\  \" error   traces   in   responses   are   d .  \\  \"  \"  )  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  4  0  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatErrorTraceParamReturns400"], "fileName": "org.elasticsearch.http.DetailedErrorsDisabledIT"}, {"methodBody": ["METHOD_START", "{", "try    {", "getRestClient (  )  . performRequest (  \" DELETE \"  ,     \"  /  \"  ,    Collections . singletonMap (  \" error _ trace \"  ,     \" true \"  )  )  ;", "fail (  \" request   should   have   f \"  )  ;", "}    catch    ( ResponseException   e )     {", "Response   response    =    e . getResponse (  )  ;", "assertThat ( response . getHeader (  \" Content - Type \"  )  ,    containsString (  \" application / json \"  )  )  ;", "assertThat ( EntityUtils . toString ( response . getEntity (  )  )  ,    containsString (  (  \"  \\  \" stack _ trace \\  \"  :  \\  \"  [ Validation   F :     1  :    index    /    indices   is   missing ;  ]  ;     \"     +     \" nested :    ActionRequestValidationException [ Validation   F :     1  :  \"  )  )  )  ;", "}", "try    {", "getRestClient (  )  . performRequest (  \" DELETE \"  ,     \"  /  \"  )  ;", "fail (  \" request   should   have   f \"  )  ;", "}    catch    ( ResponseException   e )     {", "Response   response    =    e . getResponse (  )  ;", "assertThat ( response . getHeader (  \" Content - Type \"  )  ,    containsString (  \" application / json ;    charset = UTF -  8  \"  )  )  ;", "assertThat ( EntityUtils . toString ( response . getEntity (  )  )  ,    not ( containsString (  (  \"  \\  \" stack _ trace \\  \"  :  \\  \"  [ Validation   F :     1  :    index    /    indices   is   missing ;  ]  ;     \"     +     \" nested :    ActionRequestValidationException [ Validation   F :     1  :  \"  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testThatErrorTraceWorksByDefault"], "fileName": "org.elasticsearch.http.DetailedErrorsEnabledIT"}, {"methodBody": ["METHOD_START", "{", "RestClient   client    =    client (  )  ;", "Response   response    =    client . performRequest (  \" GET \"  ,     \"  /  \"  ,    new   BasicHeader ( HttpHeaders . ACCEPT _ ENCODING ,     . GZIP _ ENCODING )  )  ;", "assertEquals (  2  0  0  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "assertEquals (  . GZIP _ ENCODING ,    response . getHeader ( CONTENT _ ENCODING )  )  ;", "}", "METHOD_END"], "methodName": ["testCompressesResponseIfRequested"], "fileName": "org.elasticsearch.http.HttpCompressionIT"}, {"methodBody": ["METHOD_START", "{", "RestClient   client    =    client (  )  ;", "Response   response    =    client . performRequest (  \" GET \"  ,     \"  /  \"  )  ;", "assertEquals (  2  0  0  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "assertNull ( response . getHeader ( CONTENT _ ENCODING )  )  ;", "response    =    client . performRequest (  \" POST \"  ,     \"  / company / employees /  1  \"  ,    Collections . emptyMap (  )  ,     . SAMPLE _ DOCUMENT )  ;", "assertEquals (  2  0  1  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "assertNull ( response . getHeader ( CONTENT _ ENCODING )  )  ;", "}", "METHOD_END"], "methodName": ["testUncompressedResponseByDefault"], "fileName": "org.elasticsearch.http.HttpCompressionIT"}, {"methodBody": ["METHOD_START", "{", "if    ( clazz . equals ( MockTcpTransportPlugin . class )  )     {", "return   MockTcpTransportPlugin . MOCK _ TCP _ TRANSPORT _ NAME ;", "} else", "if    ( clazz . equals ( transport . nio . MockNioTransportPlugin . class )  )     {", "return   transport . nio . MockNioTransportPlugin . MOCK _ NIO _ TRANSPORT _ NAME ;", "} else    {", "assert   clazz . equals ( transport . Netty 4 Plugin . class )  ;", "return   transport . Netty 4 Plugin . NETTY _ TRANSPORT _ NAME ;", "}", "}", "METHOD_END"], "methodName": ["getTypeKey"], "fileName": "org.elasticsearch.http.HttpSmokeTestCase"}, {"methodBody": ["METHOD_START", "{", "HttpSmokeTestCase . nodeTransportTypeKey    =    HttpSmokeTestCase . getTypeKey ( randomFrom ( getTestTransportPlugin (  )  ,    Netty 4 Plugin . class )  )  ;", "HttpSmokeTestCase . nodeHttpTypeKey    =    HttpSmokeTestCase . getTypeKey ( Netty 4 Plugin . class )  ;", "HttpSmokeTestCase . clientTypeKey    =    HttpSmokeTestCase . getTypeKey ( randomFrom ( getTestTransportPlugin (  )  ,    Netty 4 Plugin . class )  )  ;", "}", "METHOD_END"], "methodName": ["setUpTransport"], "fileName": "org.elasticsearch.http.HttpSmokeTestCase"}, {"methodBody": ["METHOD_START", "{", "ensureGreen (  )  ;", "try    {", "getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  _ protected \"  )  ;", "fail (  \" request   should   have   failed \"  )  ;", "}    catch    ( Exception   e )     {", "response    =    e . get (  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    equalTo (  4  0  1  )  )  ;", "assertThat ( response . getHeader (  \" Secret \"  )  ,    equalTo (  \" required \"  )  )  ;", "}", "auth    =    getRestClient (  )  . performRequest (  \" GET \"  ,     \"  /  _ protected \"  ,    new   BasicHeader (  \" Secret \"  ,     \" password \"  )  )  ;", "assertThat ( auth . getStatusLine (  )  . getStatusCode (  )  ,    equalTo (  2  0  0  )  )  ;", "assertThat ( auth . getHeader (  \" Secret \"  )  ,    equalTo (  \" granted \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testThatSettingHeadersWorks"], "fileName": "org.elasticsearch.http.ResponseHeaderPluginIT"}, {"methodBody": ["METHOD_START", "{", "client (  )  . performRequest (  \" PUT \"  ,     \"  / testindex \"  )  ;", "try    {", "client (  )  . performRequest (  \" POST \"  ,     \"  / testindex /  _ settings \"  )  ;", "fail (  \" Request   should   have   failed   with    4  0  5    error \"  )  ;", "}    catch    ( Exception   e )     {", "response    =    e . get (  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  4  0  5  )  )  ;", "assertThat ( response . getHeader (  \" Allow \"  )  ,    notNullValue (  )  )  ;", "List < String >    responseAllowHeaderStringArray    =    Arrays . asList ( response . getHeader (  \" Allow \"  )  . split (  \"  ,  \"  )  )  ;", "assertThat ( responseAllowHeaderStringArray ,    containsInAnyOrder (  \" PUT \"  ,     \" GET \"  )  )  ;", "assertThat ( EntityUtils . toString ( response . getEntity (  )  )  ,    containsString (  \" Incorrect   HTTP   method   for   uri    [  / testindex /  _ settings ]    and   method    [ POST ]  ,    allowed :  \"  )  )  ;", "assertThat ( EntityUtils . toString ( response . getEntity (  )  )  ,    containsString (  \" GET \"  )  )  ;", "assertThat ( EntityUtils . toString ( response . getEntity (  )  )  ,    containsString (  \" PUT \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testIndexSettingsPostRequest"], "fileName": "org.elasticsearch.http.RestHttpResponseHeadersIT"}, {"methodBody": ["METHOD_START", "{", "try    {", "client (  )  . performRequest (  \" DELETE \"  ,     \"  /  _ tasks \"  )  ;", "fail (  \" Request   should   have   failed   with    4  0  5    error \"  )  ;", "}    catch    ( Exception   e )     {", "response    =    e . get (  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  4  0  5  )  )  ;", "assertThat ( response . getHeader (  \" Allow \"  )  ,    notNullValue (  )  )  ;", "List < String >    responseAllowHeaderStringArray    =    Arrays . asList ( response . getHeader (  \" Allow \"  )  . split (  \"  ,  \"  )  )  ;", "assertThat ( responseAllowHeaderStringArray ,    containsInAnyOrder (  \" GET \"  )  )  ;", "assertThat ( EntityUtils . toString ( response . getEntity (  )  )  ,    containsString (  \" Incorrect   HTTP   method   for   uri    [  /  _ tasks ]    and   method    [ DELETE ]  ,    allowed :     [ GET ]  \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testUnsupportedMethodResponseHttpHeader"], "fileName": "org.elasticsearch.http.RestHttpResponseHeadersIT"}, {"methodBody": ["METHOD_START", "{", "Response   response    =    client (  )  . performRequest (  \" OPTIONS \"  ,     \"  /  _ tasks \"  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    is (  2  0  0  )  )  ;", "assertThat ( response . getHeader (  \" Allow \"  )  ,    notNullValue (  )  )  ;", "List < String >    responseAllowHeaderStringArray    =    Arrays . asList ( response . getHeader (  \" Allow \"  )  . split (  \"  ,  \"  )  )  ;", "assertThat ( responseAllowHeaderStringArray ,    containsInAnyOrder (  \" GET \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testValidEndpointOptionsResponseHttpHeader"], "fileName": "org.elasticsearch.http.RestHttpResponseHeadersIT"}, {"methodBody": ["METHOD_START", "{", "if    (  ( parser . nextToken (  )  )     !  =     ( Token . END _ OBJECT )  )     {", "throw   new   ParsingException ( parser . getTokenLocation (  )  ,     \"  [  {  }  ]    query   does   not   have   any   fields \"  ,     . NAME )  ;", "}", "return   new    (  )  ;", "}", "METHOD_END"], "methodName": ["fromXContent"], "fileName": "org.elasticsearch.http.TestDeprecatedQueryBuilder"}, {"methodBody": ["METHOD_START", "{", "engine . close (  )  ;", "final   AtomicReference < Throwable >    maybeFatal    =    new   AtomicReference <  >  (  )  ;", "final   CountDownLatch   latch    =    new   CountDownLatch (  1  )  ;", "final   Thread . UncaughtExceptionHandler   uncaughtExceptionHandler    =    Thread . getDefaultUncaughtExceptionHandler (  )  ;", "try    {", "Thread . setDefaultUncaughtExceptionHandler (  (    t ,    e )     -  >     {", "maybeFatal . set ( e )  ;", "latch . countDown (  )  ;", "}  )  ;", "final   AtomicReference < List < SegmentCommitInfo >  >    segmentsReference    =    new   AtomicReference <  >  (  )  ;", "try    ( Engine   e    =    createEngine ( defaultSettings ,    store ,    primaryTranslogDir ,    newMergePolicy (  )  ,     (    directory ,    iwc )     -  >    new   IndexWriter ( directory ,    iwc )     {", "@ Override", "public   void   merge ( final   MergePolicy . OneMerge   merge )    throws   IOException    {", "throw   new   OutOfMemoryError (  \"  6  4  0 K   ought   to   be   enough   for   anybody \"  )  ;", "}", "@ Override", "public   synchronized   MergePolicy . OneMerge   getNextMerge (  )     {", "if    (  ( segmentsReference . get (  )  )     =  =    null )     {", "return   super . getNextMerge (  )  ;", "} else    {", "final   List < SegmentCommitInfo >    segments    =    segmentsReference . getAndSet ( null )  ;", "return   new   MergePolicy . OneMerge ( segments )  ;", "}", "}", "}  ,    null ,    null )  )     {", "final   ParsedDocument   doc 1     =    testParsedDocument (  \"  1  \"  ,    null ,    testDocumentWithTextField (  )  ,    B _  1  ,    null )  ;", "e . index ( indexForDoc ( doc 1  )  )  ;", "e . flush (  )  ;", "final   List < SegmentCommitInfo >    segments    =    StreamSupport . stream ( e . getLastCommittedSegmentInfos (  )  . spliterator (  )  ,    false )  . collect ( Collectors . toList (  )  )  ;", "segmentsReference . set ( segments )  ;", "e . forceMerge ( randomBoolean (  )  ,     0  ,    false ,    false ,    false )  ;", "latch . await (  )  ;", "assertNotNull ( maybeFatal . get (  )  )  ;", "assertThat ( maybeFatal . get (  )  ,    instanceOf ( OutOfMemoryError . class )  )  ;", "assertThat ( maybeFatal . get (  )  ,    hasToString ( containsString (  \"  6  4  0 K   ought   to   be   enough   for   anybody \"  )  )  )  ;", "}", "}    finally    {", "Thread . setDefaultUncaughtExceptionHandler ( uncaughtExceptionHandler )  ;", "}", "}", "METHOD_END"], "methodName": ["testOutOfMemoryErrorWhileMergingIsRethrownAndIsUncaught"], "fileName": "org.elasticsearch.index.engine.EvilInternalEngineTests"}, {"methodBody": ["METHOD_START", "{", "List < RatedDocument >    relevant    =    new   ArrayList <  >  (  )  ;", "for    ( String   doc    :    docs )     {", "relevant . add ( new   RatedDocument (  \" test \"  ,    doc ,     . Rating . RELEVANT . ordinal (  )  )  )  ;", "}", "return   relevant ;", "}", "METHOD_END"], "methodName": ["createRelevant"], "fileName": "org.elasticsearch.index.rankeval.SmokeMultipleTemplatesIT"}, {"methodBody": ["METHOD_START", "{", "createIndex (  \" test \"  )  ;", "ensureGreen (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  1  \"  )  . setSource (  \" text \"  ,     \" berlin \"  ,     \" title \"  ,     \" Berlin ,    Germany \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  2  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  3  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  4  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  5  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  )  . get (  )  ;", "client (  )  . prepareIndex (  \" test \"  ,     \" testtype \"  )  . setId (  \"  6  \"  )  . setSource (  \" text \"  ,     \" amsterdam \"  )  . get (  )  ;", "refresh (  )  ;", "}", "METHOD_END"], "methodName": ["setup"], "fileName": "org.elasticsearch.index.rankeval.SmokeMultipleTemplatesIT"}, {"methodBody": ["METHOD_START", "{", "List < RatedRequest >    specifications    =    new   ArrayList <  >  (  )  ;", "Map < String ,    Object >    ams _ params    =    new   HashMap <  >  (  )  ;", "ams _ params . put (  \" querystring \"  ,     \" amsterdam \"  )  ;", "RatedRequest   amsterdamRequest    =    new   RatedRequest (  \" amsterdam _ query \"  ,     . createRelevant (  \"  2  \"  ,     \"  3  \"  ,     \"  4  \"  ,     \"  5  \"  )  ,    ams _ params ,     . MATCH _ TEMPLATE )  ;", "specifications . add ( amsterdamRequest )  ;", "Map < String ,    Object >    berlin _ params    =    new   HashMap <  >  (  )  ;", "berlin _ params . put (  \" querystring \"  ,     \" berlin \"  )  ;", "RatedRequest   berlinRequest    =    new   RatedRequest (  \" berlin _ query \"  ,     . createRelevant (  \"  1  \"  )  ,    berlin _ params ,     . MATCH _ TEMPLATE )  ;", "specifications . add ( berlinRequest )  ;", "PrecisionAtK   metric    =    new   PrecisionAtK (  )  ;", "ScriptWithId   template    =    new   ScriptWithId (  . MATCH _ TEMPLATE ,    new   Script ( ScriptType . INLINE ,     \" mustache \"  ,     \"  {  \\  \" query \\  \"  :     {  \\  \" match \\  \"  :     {  \\  \" text \\  \"  :     \\  \"  {  { querystring }  }  \\  \"  }  }  }  \"  ,    new   HashMap (  )  )  )  ;", "Set < ScriptWithId >    templates    =    new   HashSet <  >  (  )  ;", "templates . add ( template )  ;", "RankEvalSpec   task    =    new   RankEvalSpec ( specifications ,    metric ,    templates )  ;", "RankEvalRequestBuilder   builder    =    new   RankEvalRequestBuilder ( client (  )  ,    RankEvalAction . INSTANCE ,    new   RankEvalRequest (  )  )  ;", "builder . setRankEvalSpec ( task )  ;", "RankEvalResponse   response    =    client (  )  . execute ( INSTANCE ,    builder . request (  )  . indices (  \" test \"  )  )  . actionGet (  )  ;", "assertEquals (  0  .  9  ,    response . getEvaluationResult (  )  ,    Double . MIN _ VALUE )  ;", "}", "METHOD_END"], "methodName": ["testPrecisionAtRequest"], "fileName": "org.elasticsearch.index.rankeval.SmokeMultipleTemplatesIT"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.index.rankeval.SmokeTestRankEvalWithMustacheYAMLTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "Script   script    =    new   Script ( ScriptType . INLINE ,    DEFAULT _ TEMPLATE _ LANG ,    template ,    Collections . emptyMap (  )  )  ;", "return   scriptService . compile ( script ,    CONTEXT )  ;", "}", "METHOD_END"], "methodName": ["compile"], "fileName": "org.elasticsearch.ingest.AbstractScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "MustacheScriptEngine   engine    =    new   MustacheScriptEngine (  )  ;", "Map < String ,    ScriptEngine >    engines    =    Collections . singletonMap ( engine . getType (  )  ,    engine )  ;", "scriptService    =    new   script . ScriptService ( Settings . EMPTY ,    engines ,    ScriptModule . CORE _ CONTEXTS )  ;", "}", "METHOD_END"], "methodName": ["init"], "fileName": "org.elasticsearch.ingest.AbstractScriptTestCase"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    ingestMap    =    new   HashMap <  >  (  )  ;", "ingestMap . put (  \" timestamp \"  ,     \" bogus _ timestamp \"  )  ;", "document . put (  \"  _ ingest \"  ,    ingestMap )  ;", "ingestDocument    =    new    (  \" index \"  ,     \" type \"  ,     \" id \"  ,    null ,    null ,    null ,    document )  ;", "ingestDocument . setFieldValue ( compile (  \" ingest _ timestamp \"  )  ,    ValueSource . wrap (  \"  {  {  _ ingest . timestamp }  }    and    {  {  _ source .  _ ingest . timestamp }  }  \"  ,    scriptService )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" ingest _ timestamp \"  ,    String . class )  ,    equalTo (  (  ( ingestDocument . getIngestMetadata (  )  . get (  \" timestamp \"  )  )     +     \"    and   bogus _ timestamp \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testAccessIngestMetadataViaTemplate"], "fileName": "org.elasticsearch.ingest.IngestDocumentMustacheIT"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" list 1  \"  ,    Arrays . asList (  \" foo \"  ,     \" bar \"  ,    null )  )  ;", "List < Map < String ,    Object >  >    list    =    new   ArrayList <  >  (  )  ;", "Map < String ,    Object >    value    =    new   HashMap <  >  (  )  ;", "value . put (  \" field \"  ,     \" value \"  )  ;", "list . add ( value )  ;", "list . add ( null )  ;", "document . put (  \" list 2  \"  ,    list )  ;", "ingestDocument    =    new    (  \" index \"  ,     \" type \"  ,     \" id \"  ,    null ,    null ,    null ,    document )  ;", "ingestDocument . setFieldValue ( compile (  \" field 1  \"  )  ,    ValueSource . wrap (  \"  1     {  { list 1  .  0  }  }     {  { list 2  .  0  }  }  \"  ,    scriptService )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" field 1  \"  ,    String . class )  ,    equalTo (  \"  1    foo    { field = value }  \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAccessListMetaDataViaTemplate"], "fileName": "org.elasticsearch.ingest.IngestDocumentMustacheIT"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "Map < String ,    Object >    innerObject    =    new   HashMap <  >  (  )  ;", "innerObject . put (  \" bar \"  ,     \" hello   bar \"  )  ;", "innerObject . put (  \" baz \"  ,     \" hello   baz \"  )  ;", "innerObject . put (  \" qux \"  ,    Collections . singletonMap (  \" fubar \"  ,     \" hello   qux   and   fubar \"  )  )  ;", "document . put (  \" foo \"  ,    innerObject )  ;", "ingestDocument    =    new    (  \" index \"  ,     \" type \"  ,     \" id \"  ,    null ,    null ,    null ,    document )  ;", "ingestDocument . setFieldValue ( compile (  \" field 1  \"  )  ,    ValueSource . wrap (  \"  1     {  { foo . bar }  }     {  { foo . baz }  }     {  { foo . qux . fubar }  }  \"  ,    scriptService )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" field 1  \"  ,    String . class )  ,    equalTo (  \"  1    hello   bar   hello   baz   hello   qux   and   fubar \"  )  )  ;", "ingestDocument . setFieldValue ( compile (  \" field 1  \"  )  ,    ValueSource . wrap (  \"  2     {  {  _ source . foo . bar }  }     {  {  _ source . foo . baz }  }     {  {  _ source . foo . qux . fubar }  }  \"  ,    scriptService )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" field 1  \"  ,    String . class )  ,    equalTo (  \"  2    hello   bar   hello   baz   hello   qux   and   fubar \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAccessMapMetaDataViaTemplate"], "fileName": "org.elasticsearch.ingest.IngestDocumentMustacheIT"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    document    =    new   HashMap <  >  (  )  ;", "document . put (  \" foo \"  ,     \" bar \"  )  ;", "ingestDocument    =    new    (  \" index \"  ,     \" type \"  ,     \" id \"  ,    null ,    null ,    null ,    document )  ;", "ingestDocument . setFieldValue ( compile (  \" field 1  \"  )  ,    ValueSource . wrap (  \"  1     {  { foo }  }  \"  ,    scriptService )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" field 1  \"  ,    String . class )  ,    equalTo (  \"  1    bar \"  )  )  ;", "ingestDocument . setFieldValue ( compile (  \" field 1  \"  )  ,    ValueSource . wrap (  \"  2     {  {  _ source . foo }  }  \"  ,    scriptService )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" field 1  \"  ,    String . class )  ,    equalTo (  \"  2    bar \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testAccessMetaDataViaTemplate"], "fileName": "org.elasticsearch.ingest.IngestDocumentMustacheIT"}, {"methodBody": ["METHOD_START", "{", "IngestDocument   ingestDocument    =    new   IngestDocument (  \" marvel \"  ,     \" type \"  ,     \" id \"  ,    null ,    null ,    null ,    new   HashMap (  )  )  ;", "assertThat ( ingestDocument . hasField (  \" marvel \"  )  ,    is ( false )  )  ;", "ingestDocument . setFieldValue ( compile (  \"  {  {  _ index }  }  \"  )  ,     . wrap (  \"  {  {  _ index }  }  \"  ,    scriptService )  )  ;", "assertThat ( ingestDocument . getFieldValue (  \" marvel \"  ,    String . class )  ,    equalTo (  \" marvel \"  )  )  ;", "ingestDocument . removeField ( compile (  \"  {  { marvel }  }  \"  )  )  ;", "assertThat ( ingestDocument . hasField (  \" index \"  )  ,    is ( false )  )  ;", "}", "METHOD_END"], "methodName": ["testAccessSourceViaTemplate"], "fileName": "org.elasticsearch.ingest.ValueSourceMustacheIT"}, {"methodBody": ["METHOD_START", "{", "Map < String ,    Object >    model    =    new   HashMap <  >  (  )  ;", "model . put (  \" field 1  \"  ,     \" value 1  \"  )  ;", "model . put (  \" field 2  \"  ,    Collections . singletonMap (  \" field 3  \"  ,     \" value 3  \"  )  )  ;", "valueSource    =     . wrap (  \"  {  { field 1  }  }  /  {  { field 2  }  }  /  {  { field 2  . field 3  }  }  \"  ,    scriptService )  ;", "assertThat ( valueSource ,    instanceOf ( TemplatedValue . class )  )  ;", "assertThat ( valueSource . copyAndResolve ( model )  ,    equalTo (  \" value 1  /  { field 3  = value 3  }  / value 3  \"  )  )  ;", "valueSource    =     . wrap ( Arrays . asList (  \"  _ value \"  ,     \"  {  { field 1  }  }  \"  )  ,    scriptService )  ;", "assertThat ( valueSource ,    instanceOf ( ListValue . class )  )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "List < String >    result    =     (  ( List < String >  )     ( valueSource . copyAndResolve ( model )  )  )  ;", "assertThat ( result . size (  )  ,    equalTo (  2  )  )  ;", "assertThat ( result . get (  0  )  ,    equalTo (  \"  _ value \"  )  )  ;", "assertThat ( result . get (  1  )  ,    equalTo (  \" value 1  \"  )  )  ;", "Map < String ,    Object >    map    =    new   HashMap <  >  (  )  ;", "map . put (  \" field 1  \"  ,     \"  {  { field 1  }  }  \"  )  ;", "map . put (  \" field 2  \"  ,    Collections . singletonMap (  \" field 3  \"  ,     \"  {  { field 2  . field 3  }  }  \"  )  )  ;", "map . put (  \" field 4  \"  ,     \"  _ value \"  )  ;", "valueSource    =     . wrap ( map ,    scriptService )  ;", "assertThat ( valueSource ,    instanceOf ( MapValue . class )  )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "Map < String ,    Object >    resultMap    =     (  ( Map < String ,    Object >  )     ( valueSource . copyAndResolve ( model )  )  )  ;", "assertThat ( resultMap . size (  )  ,    equalTo (  3  )  )  ;", "assertThat ( resultMap . get (  \" field 1  \"  )  ,    equalTo (  \" value 1  \"  )  )  ;", "assertThat (  (  ( Map )     ( resultMap . get (  \" field 2  \"  )  )  )  . size (  )  ,    equalTo (  1  )  )  ;", "assertThat (  (  ( Map )     ( resultMap . get (  \" field 2  \"  )  )  )  . get (  \" field 3  \"  )  ,    equalTo (  \" value 3  \"  )  )  ;", "assertThat ( resultMap . get (  \" field 4  \"  )  ,    equalTo (  \"  _ value \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testValueSourceWithTemplates"], "fileName": "org.elasticsearch.ingest.ValueSourceMustacheIT"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   cannot   run   with   security   manager   enabled \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "final   MockTerminal   terminal    =    new   MockTerminal (  )  ;", "terminal . addTextInput (  \" y \"  )  ;", "terminal . addTextInput (  \" n \"  )  ;", "final   Path   policyFile    =    this . getDataPath (  \" security / simple - plugin - security . policy \"  )  ;", "Set < String >    permissions    =     . parsePermissions ( policyFile ,    createTempDir (  )  )  ;", "UserException   e    =    expectThrows ( UserException . class ,     (  )     -  >     . confirmPolicyExceptions ( terminal ,    permissions ,    true ,    false )  )  ;", "assertThat ( e ,    hasToString ( containsString (  \" installation   aborted   by   user \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testDeclineNativeController"], "fileName": "org.elasticsearch.plugins.PluginSecurityTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   cannot   run   with   security   manager   enabled \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "final   MockTerminal   terminal    =    new   MockTerminal (  )  ;", "terminal . addTextInput (  \" y \"  )  ;", "final   Path   policyFile    =    this . getDataPath (  \" security / simple - plugin - security . policy \"  )  ;", "Set < String >    permissions    =     . parsePermissions ( policyFile ,    createTempDir (  )  )  ;", ". confirmPolicyExceptions ( terminal ,    permissions ,    false ,    false )  ;", "final   String   output    =    terminal . getOutput (  )  ;", "assertThat ( output ,    not ( containsString (  \" plugin   forks   a   native   controller \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testDoesNotHaveNativeController"], "fileName": "org.elasticsearch.plugins.PluginSecurityTests"}, {"methodBody": ["METHOD_START", "{", "assertEquals (  \" RuntimePermission   queuePrintJob \"  ,    PluginSecurity . formatPermission ( new   RuntimePermission (  \" queuePrintJob \"  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testFormatSimplePermission"], "fileName": "org.elasticsearch.plugins.PluginSecurityTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   cannot   run   with   security   manager   enabled \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "Path   scratch    =    createTempDir (  )  ;", "Path   testFile    =    this . getDataPath (  \" security / unresolved - plugin - security . policy \"  )  ;", "Set < String >    permissions    =     . parsePermissions ( testFile ,    scratch )  ;", "assertThat ( permissions ,    contains (  \" FakePermission   fakeName \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testFormatUnresolvedPermission"], "fileName": "org.elasticsearch.plugins.PluginSecurityTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   cannot   run   with   security   manager   enabled \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "final   MockTerminal   terminal    =    new   MockTerminal (  )  ;", "terminal . addTextInput (  \" y \"  )  ;", "terminal . addTextInput (  \" y \"  )  ;", "final   Path   policyFile    =    this . getDataPath (  \" security / simple - plugin - security . policy \"  )  ;", "Set < String >    permissions    =     . parsePermissions ( policyFile ,    createTempDir (  )  )  ;", ". confirmPolicyExceptions ( terminal ,    permissions ,    true ,    false )  ;", "final   String   output    =    terminal . getOutput (  )  ;", "assertThat ( output ,    containsString (  \" plugin   forks   a   native   controller \"  )  )  ;", "}", "METHOD_END"], "methodName": ["testHasNativeController"], "fileName": "org.elasticsearch.plugins.PluginSecurityTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   cannot   run   with   security   manager   enabled \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "Path   scratch    =    createTempDir (  )  ;", "Path   testFile    =    this . getDataPath (  \" security / simple - plugin - security . policy \"  )  ;", "Set < String >    actual    =     . parsePermissions ( testFile ,    scratch )  ;", "assertThat ( actual ,    contains (  . formatPermission ( new   RuntimePermission (  \" queuePrintJob \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testParsePermissions"], "fileName": "org.elasticsearch.plugins.PluginSecurityTests"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" test   cannot   run   with   security   manager   enabled \"  ,     (  ( System . getSecurityManager (  )  )     =  =    null )  )  ;", "Path   scratch    =    createTempDir (  )  ;", "Path   testFile    =    this . getDataPath (  \" security / complex - plugin - security . policy \"  )  ;", "Set < String >    actual    =     . parsePermissions ( testFile ,    scratch )  ;", "assertThat ( actual ,    containsInAnyOrder (  . formatPermission ( new   RuntimePermission (  \" getClassLoader \"  )  )  ,     . formatPermission ( new   RuntimePermission (  \" closeClassLoader \"  )  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testParseTwoPermissions"], "fileName": "org.elasticsearch.plugins.PluginSecurityTests"}, {"methodBody": ["METHOD_START", "{", "final   Path   pidFile    =    PathUtils . get ( System . getProperty (  \" pidfile \"  )  )  ;", "final   List < String >    pidFileLines    =    Files . readAllLines ( pidFile )  ;", "assertThat ( pidFileLines ,    hasSize (  1  )  )  ;", "final   int   pid    =    Integer . parseInt ( pidFileLines . get (  0  )  )  ;", "Files . delete ( pidFile )  ;", "IOException   e    =    expectThrows ( IOException . class ,     (  )     -  >    client (  )  . performRequest (  \" GET \"  ,     \"  /  _  \"  )  )  ;", "Matcher < IOException >    failureMatcher    =    instanceOf ( ConnectionClosedException . class )  ;", "if    ( Constants . WINDOWS )     {", "failureMatcher    =    either ( failureMatcher )  . or ( hasToString ( containsString (  \" An   existing   connection   was   forcibly   closed   by   the   remote   host \"  )  )  )  ;", "}", "assertThat ( e ,    failureMatcher )  ;", "assertBusy (  (  )     -  >     {", "final   String   jpsPath    =    PathUtils . get ( System . getProperty (  \" runtime . home \"  )  ,     \" bin / jps \"  )  . toString (  )  ;", "final   Process   process    =    new   ProcessBuilder (  )  . command ( jpsPath )  . start (  )  ;", "assertThat ( process . waitFor (  )  ,    equalTo (  0  )  )  ;", "try    ( InputStream   is    =    process . getInputStream (  )  ; BufferedReader   in    =    new   BufferedReader ( new   InputStreamReader ( is ,     \" UTF -  8  \"  )  )  )     {", "String   line ;", "while    (  ( line    =    in . readLine (  )  )     !  =    null )     {", "final   int   currentPid    =    Integer . parseInt ( line . split (  \"  \\  \\ s +  \"  )  [  0  ]  )  ;", "assertThat ( line ,    pid ,    not ( equalTo ( currentPid )  )  )  ;", "}", "}", "}  )  ;", "final   List < String >    lines    =    Files . readAllLines ( PathUtils . get ( System . getProperty (  \" log \"  )  )  )  ;", "final   Iterator < String >    it    =    lines . iterator (  )  ;", "boolean   fatalErrorOnTheNetworkLayer    =    false ;", "boolean   fatalErrorInThreadExiting    =    false ;", "while    (  ( it . hasNext (  )  )     &  &     (  ( fatalErrorOnTheNetworkLayer    =  =    false )     |  |     ( fatalErrorInThreadExiting    =  =    false )  )  )     {", "final   String   line    =    it . next (  )  ;", "if    ( line . contains (  \" fatal   error   on   the   network   layer \"  )  )     {", "fatalErrorOnTheNetworkLayer    =    true ;", "} else", "if    ( line . matches (  (  \"  .  *  \\  \\  [ ERROR \\  \\  ]  \\  \\  [ o . e . b . ElasticsearchUncaughtExceptionHandler \\  \\  ]     \\  \\  [ node -  0  \\  \\  ]  \"     +     \"    fatal   error   in   thread    \\  \\  [ Thread -  \\  \\ d +  \\  \\  ]  ,    exiting $  \"  )  )  )     {", "fatalErrorInThreadExiting    =    true ;", "assertTrue ( it . hasNext (  )  )  ;", "assertThat ( it . next (  )  ,    equalTo (  \" OutOfMemoryError :    die   with   dignity \"  )  )  ;", "}", "}", "assertTrue ( fatalErrorOnTheNetworkLayer )  ;", "assertTrue ( fatalErrorInThreadExiting )  ;", "}", "METHOD_END"], "methodName": ["testDieWithDignity"], "fileName": "org.elasticsearch.qa.die_with_dignity.DieWithDignityIT"}, {"methodBody": ["METHOD_START", "{", "final   Response   response    =    client (  )  . performRequest (  \" GET \"  ,     \"  /  \"  )  ;", "assertThat ( response . getStatusLine (  )  . getStatusCode (  )  ,    equalTo (  2  0  0  )  )  ;", "final   ObjectPath   objectPath    =    ObjectPath . createFromResponse ( response )  ;", "final   String   VersionString    =    objectPath . evaluate (  \" version . number \"  )  . toString (  )  ;", "final   Version   Version    =    Version . fromString ( VersionString )  ;", "final   String   luceneVersionString    =    objectPath . evaluate (  \" version . lucene _ version \"  )  . toString (  )  ;", "final   Version   luceneVersion    =    parse ( luceneVersionString )  ;", "assertThat ( Version . luceneVersion ,    equalTo ( luceneVersion )  )  ;", "}", "METHOD_END"], "methodName": ["testLuceneVersionConstant"], "fileName": "org.elasticsearch.qa.verify_version_constants.VerifyVersionConstantsIT"}, {"methodBody": ["METHOD_START", "{", "{", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchException . class ,     (  )     -  >    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" index \"  ,     \" remote 1  : index \"  )  )  )  ;", "ElasticsearchException   rootCause    =     (  ( ElasticsearchException )     ( exception . getRootCause (  )  )  )  ;", "assertThat ( rootCause . getMessage (  )  ,    containsString (  \" connect _ exception \"  )  )  ;", "}", "{", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchException . class ,     (  )     -  >    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" remote 1  : index \"  )  )  )  ;", "ElasticsearchException   rootCause    =     (  ( ElasticsearchException )     ( exception . getRootCause (  )  )  )  ;", "assertThat ( rootCause . getMessage (  )  ,    containsString (  \" connect _ exception \"  )  )  ;", "}", "{", "ElasticsearchException   exception    =    expectThrows ( ElasticsearchException . class ,     (  )     -  >    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" remote 1  : index \"  )  . scroll (  \"  1 m \"  )  )  )  ;", "ElasticsearchException   rootCause    =     (  ( ElasticsearchException )     ( exception . getRootCause (  )  )  )  ;", "assertThat ( rootCause . getMessage (  )  ,    containsString (  \" connect _ exception \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["assertSearchConnectFailure"], "fileName": "org.elasticsearch.search.CrossClusterSearchUnavailableClusterIT"}, {"methodBody": ["METHOD_START", "{", "String   requestBody ;", "try    ( XContentBuilder   builder    =    JsonXContent . contentBuilder (  )  )     {", "builder . startObject (  )  ;", "{", "builder . startObject (  \" persistent \"  )  ;", "{", "builder . startObject (  \" remote . remote 1  \"  )  ;", "{", "for    ( Map . Entry < String ,    Object >    entry    :    settings . entrySet (  )  )     {", "builder . field ( entry . getKey (  )  ,    entry . getValue (  )  )  ;", "}", "}", "builder . endObject (  )  ;", "}", "builder . endObject (  )  ;", "}", "builder . endObject (  )  ;", "requestBody    =    Strings . toString ( builder )  ;", "}", "return   new   NStringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  ;", "}", "METHOD_END"], "methodName": ["buildUpdateSettingsRequestBody"], "fileName": "org.elasticsearch.search.CrossClusterSearchUnavailableClusterIT"}, {"methodBody": ["METHOD_START", "{", "CrossClusterSearchUnavailableClusterIT . restHighLevelClient . close (  )  ;", "CrossClusterSearchUnavailableClusterIT . restHighLevelClient    =    null ;", "}", "METHOD_END"], "methodName": ["cleanupClient"], "fileName": "org.elasticsearch.search.CrossClusterSearchUnavailableClusterIT"}, {"methodBody": ["METHOD_START", "{", "super . initClient (  )  ;", "if    (  (  . restHighLevelClient )     =  =    null )     {", ". restHighLevelClient    =    new    . HighLevelClient ( client (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["initHighLevelClient"], "fileName": "org.elasticsearch.search.CrossClusterSearchUnavailableClusterIT"}, {"methodBody": ["METHOD_START", "{", "boolean   success    =    false ;", "final   Settings   s    =    Settings . builder (  )  . put (  \" node . name \"  ,    id )  . build (  )  ;", "ClusterName   clusterName    =    CLUSTER _ NAME _ SETTING . get ( s )  ;", "MockTransportService   newService    =    MockTransportService . createNewService ( s ,    version ,    threadPool ,    null )  ;", "try    {", "newService . registerRequestHandler ( NAME ,    SAME ,    ShardsRequest :  : new ,     (    request ,    channel )     -  >     {", "channel . sendResponse ( new   ShardsResponse ( new   ShardsGroup [  0  ]  ,    knownNodes . toArray ( new   DiscoveryNode [  0  ]  )  ,    Collections . emptyMap (  )  )  )  ;", "}  )  ;", "newService . registerRequestHandler ( ClusterStateAction . NAME ,    SAME ,    ClusterStateRequest :  : new ,     (    request ,    channel )     -  >     {", "DiscoveryNodes . Builder   builder    =    DiscoveryNodes . builder (  )  ;", "for    ( DiscoveryNode   node    :    knownNodes )     {", "builder . add ( node )  ;", "}", "ClusterState   build    =    ClusterState . builder ( clusterName )  . nodes ( builder . build (  )  )  . build (  )  ;", "channel . sendResponse ( new   ClusterStateResponse ( clusterName ,    build ,     0 L )  )  ;", "}  )  ;", "newService . start (  )  ;", "newService . acceptIncomingRequests (  )  ;", "success    =    true ;", "return   newService ;", "}    finally    {", "if    ( success    =  =    false )     {", "newService . close (  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["startTransport"], "fileName": "org.elasticsearch.search.CrossClusterSearchUnavailableClusterIT"}, {"methodBody": ["METHOD_START", "{", "try    ( MockTransportService   remoteTransport    =    CrossClusterSearchUnavailableClusterIT . startTransport (  \" node 0  \"  ,    new   CopyOnWriteArrayList (  )  ,    CURRENT ,    threadPool )  )     {", "DiscoveryNode   remoteNode    =    remoteTransport . getLocalDiscoNode (  )  ;", "CrossClusterSearchUnavailableClusterIT . updateRemoteClusterSettings ( Collections . singletonMap (  \" seeds \"  ,    remoteNode . getAddress (  )  . toString (  )  )  )  ;", "for    ( int   i    =     0  ;    i    <     1  0  ;    i +  +  )     {", "CrossClusterSearchUnavailableClusterIT . restHighLevelClient . index ( new   IndexRequest (  \" index \"  ,     \" doc \"  ,    String . valueOf ( i )  )  . source (  \" field \"  ,     \" value \"  )  )  ;", "}", "Response   refreshResponse    =    client (  )  . performRequest (  \" POST \"  ,     \"  / index /  _ refresh \"  )  ;", "assertEquals (  2  0  0  ,    refreshResponse . getStatusLine (  )  . getStatusCode (  )  )  ;", "{", "SearchResponse   response    =    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" index \"  )  )  ;", "assertSame ( EMPTY ,    response . getClusters (  )  )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . totalHits )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . getHits (  )  . length )  ;", "}", "{", "SearchResponse   response    =    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" index \"  ,     \" remote 1  : index \"  )  )  ;", "assertEquals (  2  ,    response . getClusters (  )  . getTotal (  )  )  ;", "assertEquals (  2  ,    response . getClusters (  )  . getSuccessful (  )  )  ;", "assertEquals (  0  ,    response . getClusters (  )  . getSkipped (  )  )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . totalHits )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . getHits (  )  . length )  ;", "}", "{", "SearchResponse   response    =    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" remote 1  : index \"  )  )  ;", "assertEquals (  1  ,    response . getClusters (  )  . getTotal (  )  )  ;", "assertEquals (  1  ,    response . getClusters (  )  . getSuccessful (  )  )  ;", "assertEquals (  0  ,    response . getClusters (  )  . getSkipped (  )  )  ;", "assertEquals (  0  ,    response . getHits (  )  . totalHits )  ;", "}", "{", "SearchResponse   response    =    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" index \"  ,     \" remote 1  : index \"  )  . scroll (  \"  1 m \"  )  )  ;", "assertEquals (  2  ,    response . getClusters (  )  . getTotal (  )  )  ;", "assertEquals (  2  ,    response . getClusters (  )  . getSuccessful (  )  )  ;", "assertEquals (  0  ,    response . getClusters (  )  . getSkipped (  )  )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . totalHits )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . getHits (  )  . length )  ;", "String   scrollId    =    response . getScrollId (  )  ;", "SearchResponse   scrollResponse    =    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . searchScroll ( new   SearchScrollRequest ( scrollId )  )  ;", "assertSame ( EMPTY ,    scrollResponse . getClusters (  )  )  ;", "assertEquals (  1  0  ,    scrollResponse . getHits (  )  . totalHits )  ;", "assertEquals (  0  ,    scrollResponse . getHits (  )  . getHits (  )  . length )  ;", "}", "remoteTransport . close (  )  ;", "CrossClusterSearchUnavailableClusterIT . updateRemoteClusterSettings ( Collections . singletonMap (  \" skip _ unavailable \"  ,    true )  )  ;", "{", "SearchResponse   response    =    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" index \"  ,     \" remote 1  : index \"  )  )  ;", "assertEquals (  2  ,    response . getClusters (  )  . getTotal (  )  )  ;", "assertEquals (  1  ,    response . getClusters (  )  . getSuccessful (  )  )  ;", "assertEquals (  1  ,    response . getClusters (  )  . getSkipped (  )  )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . totalHits )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . getHits (  )  . length )  ;", "}", "{", "SearchResponse   response    =    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" remote 1  : index \"  )  )  ;", "assertEquals (  1  ,    response . getClusters (  )  . getTotal (  )  )  ;", "assertEquals (  0  ,    response . getClusters (  )  . getSuccessful (  )  )  ;", "assertEquals (  1  ,    response . getClusters (  )  . getSkipped (  )  )  ;", "assertEquals (  0  ,    response . getHits (  )  . totalHits )  ;", "}", "{", "SearchResponse   response    =    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . search ( new   SearchRequest (  \" index \"  ,     \" remote 1  : index \"  )  . scroll (  \"  1 m \"  )  )  ;", "assertEquals (  2  ,    response . getClusters (  )  . getTotal (  )  )  ;", "assertEquals (  1  ,    response . getClusters (  )  . getSuccessful (  )  )  ;", "assertEquals (  1  ,    response . getClusters (  )  . getSkipped (  )  )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . totalHits )  ;", "assertEquals (  1  0  ,    response . getHits (  )  . getHits (  )  . length )  ;", "String   scrollId    =    response . getScrollId (  )  ;", "SearchResponse   scrollResponse    =    CrossClusterSearchUnavailableClusterIT . restHighLevelClient . searchScroll ( new   SearchScrollRequest ( scrollId )  )  ;", "assertSame ( EMPTY ,    scrollResponse . getClusters (  )  )  ;", "assertEquals (  1  0  ,    scrollResponse . getHits (  )  . totalHits )  ;", "assertEquals (  0  ,    scrollResponse . getHits (  )  . getHits (  )  . length )  ;", "}", "CrossClusterSearchUnavailableClusterIT . updateRemoteClusterSettings ( Collections . singletonMap (  \" skip _ unavailable \"  ,    false )  )  ;", "CrossClusterSearchUnavailableClusterIT . assertSearchConnectFailure (  )  ;", "Map < String ,    Object >    map    =    new   HashMap <  >  (  )  ;", "map . put (  \" seeds \"  ,    null )  ;", "map . put (  \" skip _ unavailable \"  ,    null )  ;", "CrossClusterSearchUnavailableClusterIT . updateRemoteClusterSettings ( map )  ;", "}", "}", "METHOD_END"], "methodName": ["testSearchSkipUnavailable"], "fileName": "org.elasticsearch.search.CrossClusterSearchUnavailableClusterIT"}, {"methodBody": ["METHOD_START", "{", "try    ( MockTransportService   remoteTransport    =    CrossClusterSearchUnavailableClusterIT . startTransport (  \" node 0  \"  ,    new   CopyOnWriteArrayList (  )  ,    CURRENT ,    threadPool )  )     {", "DiscoveryNode   remoteNode    =    remoteTransport . getLocalDiscoNode (  )  ;", "{", "HttpEntity   clusterSettingsEntity    =    CrossClusterSearchUnavailableClusterIT . buildUpdateSettingsRequestBody ( Collections . singletonMap (  \" skip _ unavailable \"  ,    randomBoolean (  )  )  )  ;", "ResponseException   responseException    =    expectThrows ( ResponseException . class ,     (  )     -  >    client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ cluster / settings \"  ,    Collections . emptyMap (  )  ,    clusterSettingsEntity )  )  ;", "assertEquals (  4  0  0  ,    responseException . getResponse (  )  . getStatusLine (  )  . getStatusCode (  )  )  ;", "assertThat ( responseException . getMessage (  )  ,    containsString (  (  \" Missing   required   setting    [ search . remote . remote 1  . seeds ]     \"     +     \" for   setting    [ search . remote . remote 1  . skip _ unavailable ]  \"  )  )  )  ;", "}", "Map < String ,    Object >    settingsMap    =    new   HashMap <  >  (  )  ;", "settingsMap . put (  \" seeds \"  ,    remoteNode . getAddress (  )  . toString (  )  )  ;", "settingsMap . put (  \" skip _ unavailable \"  ,    randomBoolean (  )  )  ;", "CrossClusterSearchUnavailableClusterIT . updateRemoteClusterSettings ( settingsMap )  ;", "{", "HttpEntity   clusterSettingsEntity    =    CrossClusterSearchUnavailableClusterIT . buildUpdateSettingsRequestBody ( Collections . singletonMap (  \" seeds \"  ,    null )  )  ;", "ResponseException   responseException    =    expectThrows ( ResponseException . class ,     (  )     -  >    client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ cluster / settings \"  ,    Collections . emptyMap (  )  ,    clusterSettingsEntity )  )  ;", "assertEquals (  4  0  0  ,    responseException . getResponse (  )  . getStatusLine (  )  . getStatusCode (  )  )  ;", "assertThat ( responseException . getMessage (  )  ,    containsString (  (  \" Missing   required   setting    [ search . remote . remote 1  . seeds ]     \"     +     \" for   setting    [ search . remote . remote 1  . skip _ unavailable ]  \"  )  )  )  ;", "}", "if    ( randomBoolean (  )  )     {", "CrossClusterSearchUnavailableClusterIT . updateRemoteClusterSettings ( Collections . singletonMap (  \" skip _ unavailable \"  ,    null )  )  ;", "CrossClusterSearchUnavailableClusterIT . updateRemoteClusterSettings ( Collections . singletonMap (  \" seeds \"  ,    null )  )  ;", "} else    {", "Map < String ,    Object >    nullMap    =    new   HashMap <  >  (  )  ;", "nullMap . put (  \" seeds \"  ,    null )  ;", "nullMap . put (  \" skip _ unavailable \"  ,    null )  ;", "CrossClusterSearchUnavailableClusterIT . updateRemoteClusterSettings ( nullMap )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testSkipUnavailableDependsOnSeeds"], "fileName": "org.elasticsearch.search.CrossClusterSearchUnavailableClusterIT"}, {"methodBody": ["METHOD_START", "{", "HttpEntity   clusterSettingsEntity    =    CrossClusterSearchUnavailableClusterIT . buildUpdateSettingsRequestBody ( settings )  ;", "Response   response    =    client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ cluster / settings \"  ,    Collections . emptyMap (  )  ,    clusterSettingsEntity )  ;", "assertEquals (  2  0  0  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "}", "METHOD_END"], "methodName": ["updateRemoteClusterSettings"], "fileName": "org.elasticsearch.search.CrossClusterSearchUnavailableClusterIT"}, {"methodBody": ["METHOD_START", "{", "doClean (  )  ;", "}", "METHOD_END"], "methodName": ["cleanIndex"], "fileName": "org.elasticsearch.smoketest.ESSmokeClientTestCase"}, {"methodBody": ["METHOD_START", "{", "doClean (  )  ;", "index    =     \" qa -  - test - client -  \"     +     ( randomAsciiOfLength (  1  0  )  . toLowerCase ( Locale . getDefault (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["defineIndexName"], "fileName": "org.elasticsearch.smoketest.ESSmokeClientTestCase"}, {"methodBody": ["METHOD_START", "{", "if    (  ( ESSmokeClientTestCase . client )     !  =    null )     {", "try    {", "ESSmokeClientTestCase . client . admin (  )  . indices (  )  . prepareDelete ( index )  . get (  )  ;", "}    catch    ( Exception   e )     {", "}", "}", "}", "METHOD_END"], "methodName": ["doClean"], "fileName": "org.elasticsearch.smoketest.ESSmokeClientTestCase"}, {"methodBody": ["METHOD_START", "{", "if    (  ( ESSmokeClientTestCase . client )     =  =    null )     {", "try    {", "ESSmokeClientTestCase . client    =    ESSmokeClientTestCase . startClient (  )  ;", "}    catch    ( IOException   e )     {", "ESSmokeClientTestCase . logger . error (  \" can   not   start   the   client \"  ,    e )  ;", "}", "assertThat ( ESSmokeClientTestCase . client ,    notNullValue (  )  )  ;", "}", "return   ESSmokeClientTestCase . client ;", "}", "METHOD_END"], "methodName": ["getClient"], "fileName": "org.elasticsearch.smoketest.ESSmokeClientTestCase"}, {"methodBody": ["METHOD_START", "{", "ESSmokeClientTestCase . clusterAddresses    =    System . getProperty ( ESSmokeClientTestCase . TESTS _ CLUSTER )  ;", "if    (  (  ( ESSmokeClientTestCase . clusterAddresses )     =  =    null )     |  |     ( ESSmokeClientTestCase . clusterAddresses . isEmpty (  )  )  )     {", "fail (  (  (  \" Must   specify    \"     +     ( ESSmokeClientTestCase . TESTS _ CLUSTER )  )     +     \"    for   smoke   client   test \"  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["initializeSettings"], "fileName": "org.elasticsearch.smoketest.ESSmokeClientTestCase"}, {"methodBody": ["METHOD_START", "{", "String [  ]    stringAddresses    =    ESSmokeClientTestCase . clusterAddresses . split (  \"  ,  \"  )  ;", "TransportAddress [  ]    transportAddresses    =    new   TransportAddress [ stringAddresses . length ]  ;", "int   i    =     0  ;", "for    ( String   stringAddress    :    stringAddresses )     {", "URL   url    =    new   URL (  (  \" http :  /  /  \"     +    stringAddress )  )  ;", "InetAddress   inetAddress    =    InetAddress . getByName ( url . getHost (  )  )  ;", "transportAddresses [  ( i +  +  )  ]     =    new   TransportAddress ( new   InetSocketAddress ( inetAddress ,    url . getPort (  )  )  )  ;", "}", "return   ESSmokeClientTestCase . startClient ( createTempDir (  )  ,    transportAddresses )  ;", "}", "METHOD_END"], "methodName": ["startClient"], "fileName": "org.elasticsearch.smoketest.ESSmokeClientTestCase"}, {"methodBody": ["METHOD_START", "{", "Settings . Builder   builder    =    Settings . builder (  )  . put (  \" node . name \"  ,     (  \" qa _ smoke _ client _  \"     +     ( ESSmokeClientTestCase . counter . getAndIncrement (  )  )  )  )  . put (  \" client . transport . ignore _ cluster _ name \"  ,    true )  . put ( PATH _ HOME _ SETTING . getKey (  )  ,    tempDir )  ;", "final   Collection < Class <  ?    extends   Plugin >  >    plugins ;", "boolean   usNio    =    random (  )  . nextBoolean (  )  ;", "String   transportKey ;", "Class <  ?    extends   Plugin >    transportPlugin ;", "if    ( usNio )     {", "transportKey    =    MockNioTransportPlugin . MOCK _ NIO _ TRANSPORT _ NAME ;", "transportPlugin    =    MockNioTransportPlugin . class ;", "} else    {", "transportKey    =    MockTcpTransportPlugin . MOCK _ TCP _ TRANSPORT _ NAME ;", "transportPlugin    =    MockTcpTransportPlugin . class ;", "}", "if    ( random (  )  . nextBoolean (  )  )     {", "builder . put ( TRANSPORT _ TYPE _ KEY ,    transportKey )  ;", "plugins    =    Collections . singleton ( transportPlugin )  ;", "} else    {", "plugins    =    Collections . emptyList (  )  ;", "}", "TransportClient   client    =    new   PreBuiltTransportClient ( builder . build (  )  ,    plugins )  . addTransportAddresses ( transportAddresses )  ;", "ESSmokeClientTestCase . logger . info (  \"  -  -  >    Elasticsearch   Java   TransportClient   started \"  )  ;", "Exception   clientException    =    null ;", "try    {", "ClusterHealthResponse   health    =    client . admin (  )  . cluster (  )  . prepareHealth (  )  . get (  )  ;", "ESSmokeClientTestCase . logger . info (  \"  -  -  >    connected   to    [  {  }  ]    cluster   which   is   running    [  {  }  ]    node ( s )  .  \"  ,    health . getClusterName (  )  ,    health . getNumberOfNodes (  )  )  ;", "}    catch    ( Exception   e )     {", "clientException    =    e ;", "}", "assumeNoException (  (  \" Sounds   like   your   cluster   is   not   running   at    \"     +     ( ESSmokeClientTestCase . clusterAddresses )  )  ,    clientException )  ;", "return   client ;", "}", "METHOD_END"], "methodName": ["startClient"], "fileName": "org.elasticsearch.smoketest.ESSmokeClientTestCase"}, {"methodBody": ["METHOD_START", "{", "if    (  ( ESSmokeClientTestCase . client )     !  =    null )     {", "ESSmokeClientTestCase . client . close (  )  ;", "ESSmokeClientTestCase . client    =    null ;", "}", "}", "METHOD_END"], "methodName": ["stopTransportClient"], "fileName": "org.elasticsearch.smoketest.ESSmokeClientTestCase"}, {"methodBody": ["METHOD_START", "{", "int   oldEsPort    =    Integer . parseInt ( System . getProperty ( portPropertyName )  )  ;", "try    ( RestClient   oldEs    =    RestClient . builder ( new   HttpHost (  \"  1  2  7  .  0  .  0  .  1  \"  ,    oldEsPort )  )  . build (  )  )     {", "try    {", "HttpEntity   entity    =    new   StringEntity (  \"  {  \\  \" settings \\  \"  :  {  \\  \" number _ of _ shards \\  \"  :     1  }  }  \"  ,    ContentType . APPLICATION _ JSON )  ;", "oldEs . performRequest (  \" PUT \"  ,     \"  / test \"  ,    Collections . singletonMap (  \" refresh \"  ,     \" true \"  )  ,    entity )  ;", "entity    =    new   StringEntity (  \"  {  \\  \" test \\  \"  :  \\  \" test \\  \"  }  \"  ,    ContentType . APPLICATION _ JSON )  ;", "oldEs . performRequest (  \" PUT \"  ,     \"  / test / doc / testdoc 1  \"  ,    Collections . singletonMap (  \" refresh \"  ,     \" true \"  )  ,    entity )  ;", "oldEs . performRequest (  \" PUT \"  ,     \"  / test / doc / testdoc 2  \"  ,    Collections . singletonMap (  \" refresh \"  ,     \" true \"  )  ,    entity )  ;", "oldEs . performRequest (  \" PUT \"  ,     \"  / test / doc / testdoc 3  \"  ,    Collections . singletonMap (  \" refresh \"  ,     \" true \"  )  ,    entity )  ;", "oldEs . performRequest (  \" PUT \"  ,     \"  / test / doc / testdoc 4  \"  ,    Collections . singletonMap (  \" refresh \"  ,     \" true \"  )  ,    entity )  ;", "oldEs . performRequest (  \" PUT \"  ,     \"  / test / doc / testdoc 5  \"  ,    Collections . singletonMap (  \" refresh \"  ,     \" true \"  )  ,    entity )  ;", "entity    =    new   StringEntity (  (  (  (  (  (  (  (  (  (  \"  {  \\ n \"     +     (  (  (  (  \"        \\  \" source \\  \"  :  {  \\ n \"     +     \"              \\  \" index \\  \"  :     \\  \" test \\  \"  ,  \\ n \"  )     +     \"              \\  \" size \\  \"  :     1  ,  \\ n \"  )     +     \"              \\  \" remote \\  \"  :     {  \\ n \"  )     +     \"                    \\  \" host \\  \"  :     \\  \" http :  /  /  1  2  7  .  0  .  0  .  1  :  \"  )  )     +    oldEsPort )     +     \"  \\  \"  \\ n \"  )     +     \"              }  \\ n \"  )     +     \"        }  ,  \\ n \"  )     +     \"        \\  \" dest \\  \"  :     {  \\ n \"  )     +     \"              \\  \" index \\  \"  :     \\  \" test \\  \"  \\ n \"  )     +     \"        }  \\ n \"  )     +     \"  }  \"  )  ,    ContentType . APPLICATION _ JSON )  ;", "Map < String ,    String >    params    =    new   TreeMap <  >  (  )  ;", "params . put (  \" refresh \"  ,     \" true \"  )  ;", "params . put (  \" pretty \"  ,     \" true \"  )  ;", "if    ( requestsPerSecond    !  =    null )     {", "params . put (  \" requests _ per _ second \"  ,    requestsPerSecond )  ;", "}", "client (  )  . performRequest (  \" POST \"  ,     \"  /  _ r \"  ,    params ,    entity )  ;", "Response   response    =    client (  )  . performRequest (  \" POST \"  ,     \" test /  _ search \"  ,    Collections . singletonMap (  \" pretty \"  ,     \" true \"  )  )  ;", "String   result    =    EntityUtils . toString ( response . getEntity (  )  )  ;", "assertThat ( result ,    containsString (  \"  \\  \"  _ id \\  \"     :     \\  \" testdoc 1  \\  \"  \"  )  )  ;", "}    finally    {", "try    {", "oldEs . performRequest (  \" DELETE \"  ,     \"  / test \"  )  ;", "}    catch    ( ResponseException   e )     {", "if    (  ( e . getResponse (  )  . getStatusLine (  )  . getStatusCode (  )  )     =  =     4  0  4  )     {", "logger . warn (  \" old   index   not   deleted   because   it   doesn ' t   exist \"  )  ;", "} else    {", "logger . error (  \" failed   to   remove   old   index \"  ,    e )  ;", "fail (  \" failed   to   remove   old   index ,    see   log \"  )  ;", "}", "}", "}", "}", "}", "METHOD_END"], "methodName": ["oldEsTestCase"], "fileName": "org.elasticsearch.smoketest.ReindexFromOldRemoteIT"}, {"methodBody": ["METHOD_START", "{", "oldEsTestCase (  \" es 0  9  0  . port \"  ,    null )  ;", "}", "METHOD_END"], "methodName": ["testEs090"], "fileName": "org.elasticsearch.smoketest.ReindexFromOldRemoteIT"}, {"methodBody": ["METHOD_START", "{", "oldEsTestCase (  \" es 0  9  0  . port \"  ,     \"  1  1  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEs090WithFunnyThrottle"], "fileName": "org.elasticsearch.smoketest.ReindexFromOldRemoteIT"}, {"methodBody": ["METHOD_START", "{", "oldEsTestCase (  \" es 1  . port \"  ,    null )  ;", "}", "METHOD_END"], "methodName": ["testEs1"], "fileName": "org.elasticsearch.smoketest.ReindexFromOldRemoteIT"}, {"methodBody": ["METHOD_START", "{", "oldEsTestCase (  \" es 1  . port \"  ,     \"  1  1  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEs1WithFunnyThrottle"], "fileName": "org.elasticsearch.smoketest.ReindexFromOldRemoteIT"}, {"methodBody": ["METHOD_START", "{", "oldEsTestCase (  \" es 2  . port \"  ,    null )  ;", "}", "METHOD_END"], "methodName": ["testEs2"], "fileName": "org.elasticsearch.smoketest.ReindexFromOldRemoteIT"}, {"methodBody": ["METHOD_START", "{", "oldEsTestCase (  \" es 2  . port \"  ,     \"  1  1  \"  )  ;", "}", "METHOD_END"], "methodName": ["testEs2WithFunnyThrottle"], "fileName": "org.elasticsearch.smoketest.ReindexFromOldRemoteIT"}, {"methodBody": ["METHOD_START", "{", "final   Client   client    =    ESSmokeClientTestCase . getClient (  )  ;", "client . prepareIndex ( index ,     \" doc \"  ,     \"  1  \"  )  . setSource (  \" foo \"  ,     \" bar \"  )  . get (  )  ;", "client . admin (  )  . indices (  )  . prepareRefresh ( index )  . get (  )  ;", "final   SearchResponse   searchResponse    =    client . prepareSearch ( index )  . get (  )  ;", "assertThat ( searchResponse . getHits (  )  . getTotalHits (  )  ,    is (  1 L )  )  ;", "}", "METHOD_END"], "methodName": ["testPutDocument"], "fileName": "org.elasticsearch.smoketest.SmokeTestClientIT"}, {"methodBody": ["METHOD_START", "{", "final   Client   client    =    ESSmokeClientTestCase . getClient (  )  ;", "final   ClusterHealthResponse   health    =    client . admin (  )  . cluster (  )  . prepareHealth (  )  . setWaitForYellowStatus (  )  . get (  )  ;", "final   String   clusterName    =    health . getClusterName (  )  ;", "final   int   numberOfNodes    =    health . getNumberOfNodes (  )  ;", "assertThat (  (  (  \" cluster    [  \"     +    clusterName )     +     \"  ]    should   have   at   least    1    node \"  )  ,    numberOfNodes ,    greaterThan (  0  )  )  ;", "}", "METHOD_END"], "methodName": ["testSimpleClient"], "fileName": "org.elasticsearch.smoketest.SmokeTestClientIT"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.smoketest.SmokeTestIngestDisabledClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.smoketest.SmokeTestIngestWithAllDepsClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.smoketest.SmokeTestMultiNodeClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.smoketest.SmokeTestPluginsClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "return   ESClientYamlSuiteTestCase . createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.smoketest.SmokeTestReindexWithPainlessClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "final   AtomicReference < Throwable >    throwableReference    =    new   AtomicReference <  >  (  )  ;", "final   Thread . UncaughtExceptionHandler   uncaughtExceptionHandler    =    Thread . getDefaultUncaughtExceptionHandler (  )  ;", "final   CountDownLatch   uncaughtExceptionHandlerLatch    =    new   CountDownLatch (  1  )  ;", "try    {", "Thread . setDefaultUncaughtExceptionHandler (  (    t ,    e )     -  >     {", "assertTrue ( expectThrowable )  ;", "throwableReference . set ( e )  ;", "uncaughtExceptionHandlerLatch . countDown (  )  ;", "}  )  ;", "final   CountDownLatch   supplierLatch    =    new   CountDownLatch (  1  )  ;", "t . generic (  )  . submit (  (  )     -  >     {", "try    {", "runnable . run (  )  ;", "}    finally    {", "supplierLatch . countDown (  )  ;", "}", "}  )  ;", "supplierLatch . await (  )  ;", "if    ( expectThrowable )     {", "uncaughtExceptionHandlerLatch . await (  )  ;", "}", "consumer . accept ( Optional . ofNullable ( throwableReference . get (  )  )  )  ;", "}    finally    {", "Thread . setDefaultUncaughtExceptionHandler ( uncaughtExceptionHandler )  ;", "}", "}", "METHOD_END"], "methodName": ["runExecutionExceptionTest"], "fileName": "org.elasticsearch.threadpool.EvilThreadPoolTests"}, {"methodBody": ["METHOD_START", "{", "threadPool    =    new   TestThreadPool ( EvilThreadPoolTests . class . getName (  )  )  ;", "}", "METHOD_END"], "methodName": ["setUpThreadPool"], "fileName": "org.elasticsearch.threadpool.EvilThreadPoolTests"}, {"methodBody": ["METHOD_START", "{", "terminate ( threadPool )  ;", "}", "METHOD_END"], "methodName": ["tearDownThreadPool"], "fileName": "org.elasticsearch.threadpool.EvilThreadPoolTests"}, {"methodBody": ["METHOD_START", "{", "runExecutionExceptionTest (  (  )     -  >     {", "throw   new   Error (  \" future   error \"  )  ;", "}  ,    true ,     (    o )     -  >     {", "assertTrue ( o . isPresent (  )  )  ;", "assertThat ( o . get (  )  ,    instanceOf ( Error . class )  )  ;", "assertThat ( o . get (  )  ,    hasToString ( containsString (  \" future   error \"  )  )  )  ;", "}  )  ;", "runExecutionExceptionTest (  (  )     -  >     {", "throw   new   IllegalStateException (  \" future   exception \"  )  ;", "}  ,    false ,     (    o )     -  >    assertFalse ( o . isPresent (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["testExecutionException"], "fileName": "org.elasticsearch.threadpool.EvilThreadPoolTests"}, {"methodBody": ["METHOD_START", "{", "logger . info (  \"  -  -  >    testing    _ all   search \"  )  ;", "Map < String ,    Object >    searchRsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  )  )  ;", ". assertNoFailures ( searchRsp )  ;", "int   totalHits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    searchRsp )  )  )  ;", "assertEquals ( count ,    totalHits )  ;", "Map <  ?  ,     ?  >    bestHit    =     (  ( Map <  ?  ,     ?  >  )     (  (  ( List <  ?  >  )     ( XContentMapValues . extractValue (  \" hits . hits \"  ,    searchRsp )  )  )  . get (  0  )  )  )  ;", "String   stringValue    =     (  ( String )     ( XContentMapValues . extractValue (  \"  _ source . string \"  ,    bestHit )  )  )  ;", "assertNotNull ( stringValue )  ;", "String   type    =     (  ( String )     ( bestHit . get (  \"  _ type \"  )  )  )  ;", "String   id    =     (  ( String )     ( bestHit . get (  \"  _ id \"  )  )  )  ;", "String   requestBody    =     \"  {     \\  \" query \\  \"  :     {     \\  \" match _ all \\  \"     :     {  }     }  }  \"  ;", "String   explanation    =     . toStr ( client (  )  . performRequest (  \" GET \"  ,     (  (  (  (  (  \"  /  \"     +     ( index )  )     +     \"  /  \"  )     +    type )     +     \"  /  \"  )     +    id )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  )  ;", "assertFalse (  (  \" Could   not   find   payload   boost   in   explanation \\ n \"     +    explanation )  ,    explanation . contains (  \" payloadBoost \"  )  )  ;", "searchRsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . singletonMap (  \" explain \"  ,     \" true \"  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  )  ;", ". assertNoFailures ( searchRsp )  ;", "totalHits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    searchRsp )  )  )  ;", "assertEquals ( count ,    totalHits )  ;", "}", "METHOD_END"], "methodName": ["assertAllSearchWorks"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   requestBody    =     \"  {     \\  \" aggs \\  \"  :     {     \\  \" histo \\  \"     :     {  \\  \" histogram \\  \"     :     {  \\  \" field \\  \"  :     \\  \" int \\  \"  ,     \\  \" interval \\  \"  :     1  0  }  }     }  }  \"  ;", "Map <  ?  ,     ?  >    searchRsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  )  ;", ". assertNoFailures ( searchRsp )  ;", "List <  ?  >    histoBuckets    =     (  ( List <  ?  >  )     ( XContentMapValues . extractValue (  \" aggregations . histo . buckets \"  ,    searchRsp )  )  )  ;", "long   totalCount    =     0  ;", "for    ( Object   entry    :    histoBuckets )     {", "Map <  ?  ,     ?  >    bucket    =     (  ( Map <  ?  ,     ?  >  )     ( entry )  )  ;", "totalCount    +  =     (  ( Integer )     ( bucket . get (  \" doc _ count \"  )  )  )  ;", "}", "int   totalHits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    searchRsp )  )  )  ;", "assertEquals ( totalHits ,    totalCount )  ;", "requestBody    =     \"  {     \\  \" aggs \\  \"  :     {     \\  \" bool _ terms \\  \"     :     {  \\  \" terms \\  \"     :     {  \\  \" field \\  \"  :     \\  \" bool \\  \"  }  }     }  }  \"  ;", "searchRsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  )  ;", "List <  ?  >    termsBuckets    =     (  ( List <  ?  >  )     ( XContentMapValues . extractValue (  \" aggregations . bool _ terms . buckets \"  ,    searchRsp )  )  )  ;", "totalCount    =     0  ;", "for    ( Object   entry    :    termsBuckets )     {", "Map <  ?  ,     ?  >    bucket    =     (  ( Map <  ?  ,     ?  >  )     ( entry )  )  ;", "totalCount    +  =     (  ( Integer )     ( bucket . get (  \" doc _ count \"  )  )  )  ;", "}", "totalHits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    searchRsp )  )  )  ;", "assertEquals ( totalHits ,    totalCount )  ;", "}", "METHOD_END"], "methodName": ["assertBasicAggregationWorks"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "logger . info (  \"  -  -  >    testing   basic   search \"  )  ;", "Map < String ,    Object >    response    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  )  )  ;", ". assertNoFailures ( response )  ;", "int   numDocs    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    response )  )  )  ;", "logger . info (  \" Found    {  }    in   old   index \"  ,    numDocs )  ;", "assertEquals ( count ,    numDocs )  ;", "logger . info (  \"  -  -  >    testing   basic   search   with   sort \"  )  ;", "String   searchRequestBody    =     \"  {     \\  \" sort \\  \"  :     [  {     \\  \" int \\  \"     :     \\  \" asc \\  \"     }  ]  }  \"  ;", "response    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( searchRequestBody ,    ContentType . APPLICATION _ JSON )  )  )  ;", ". assertNoFailures ( response )  ;", "numDocs    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    response )  )  )  ;", "assertEquals ( count ,    numDocs )  ;", "logger . info (  \"  -  -  >    testing   exists   filter \"  )  ;", "searchRequestBody    =     \"  {     \\  \" query \\  \"  :     {     \\  \" exists \\  \"     :     {  \\  \" field \\  \"  :     \\  \" string \\  \"  }     }  }  \"  ;", "response    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( searchRequestBody ,    ContentType . APPLICATION _ JSON )  )  )  ;", ". assertNoFailures ( response )  ;", "numDocs    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    response )  )  )  ;", "assertEquals ( count ,    numDocs )  ;", "searchRequestBody    =     \"  {     \\  \" query \\  \"  :     {     \\  \" exists \\  \"     :     {  \\  \" field \\  \"  :     \\  \" field . with . dots \\  \"  }     }  }  \"  ;", "response    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( searchRequestBody ,    ContentType . APPLICATION _ JSON )  )  )  ;", ". assertNoFailures ( response )  ;", "numDocs    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    response )  )  )  ;", "assertEquals ( count ,    numDocs )  ;", "}", "METHOD_END"], "methodName": ["assertBasicSearchWorks"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "int   failed    =     (  ( int )     ( XContentMapValues . extractValue (  \"  _ shards . failed \"  ,    response )  )  )  ;", "assertEquals (  0  ,    failed )  ;", "}", "METHOD_END"], "methodName": ["assertNoFailures"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   requestBody    =     \"  {     \\  \" index \\  \"  :     {     \\  \" refresh _ interval \\  \"     :     -  1     }  }  \"  ;", "Response   response    =    client (  )  . performRequest (  \" PUT \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ settings \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "requestBody    =     \"  {     \\  \" query \\  \"  :     {     \\  \" match _ all \\  \"     :     {  }     }  }  \"  ;", "Map < String ,    Object >    searchRsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  )  ;", "Map <  ?  ,     ?  >    hit    =     (  ( Map <  ?  ,     ?  >  )     (  (  ( List <  ?  >  )     ( XContentMapValues . extractValue (  \" hits . hits \"  ,    searchRsp )  )  )  . get (  0  )  )  )  ;", "String   docId    =     (  ( String )     ( hit . get (  \"  _ id \"  )  )  )  ;", "requestBody    =     \"  {     \\  \" doc \\  \"     :     {     \\  \" foo \\  \"  :     \\  \" bar \\  \"  }  }  \"  ;", "response    =    client (  )  . performRequest (  \" POST \"  ,     (  (  (  (  \"  /  \"     +     ( index )  )     +     \"  / doc /  \"  )     +    docId )     +     \"  /  _ update \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "Map < String ,    Object >    getRsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  (  \"  /  \"     +     ( index )  )     +     \"  / doc /  \"  )     +    docId )  )  )  ;", "Map <  ?  ,     ?  >    source    =     (  ( Map <  ?  ,     ?  >  )     ( getRsp . get (  \"  _ source \"  )  )  )  ;", "assertTrue (  (  \" doc   does   not   contain    ' foo '    key :     \"     +    source )  ,    source . containsKey (  \" foo \"  )  )  ;", "requestBody    =     \"  {     \\  \" index \\  \"  :     {     \\  \" refresh _ interval \\  \"     :     \\  \"  1 s \\  \"     }  }  \"  ;", "response    =    client (  )  . performRequest (  \" PUT \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ settings \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "}", "METHOD_END"], "methodName": ["assertRealtimeGetWorks"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   requestBody    =     \"  {     \\  \" query \\  \"  :     {     \\  \" match _ all \\  \"     :     {  }     }  ,     \\  \" size \\  \"  :     1  0  0  ,     \\  \" stored _ fields \\  \"  :     \\  \" binary \\  \"  }  \"  ;", "Map < String ,    Object >    rsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  )  ;", "int   totalCount    =     (  ( Integer )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    rsp )  )  )  ;", "assertEquals ( count ,    totalCount )  ;", "List <  ?  >    hits    =     (  ( List <  ?  >  )     ( XContentMapValues . extractValue (  \" hits . hits \"  ,    rsp )  )  )  ;", "assertEquals (  1  0  0  ,    hits . size (  )  )  ;", "for    ( Object   hit    :    hits )     {", "Map <  ?  ,     ?  >    hitRsp    =     (  ( Map <  ?  ,     ?  >  )     ( hit )  )  ;", "List <  ?  >    values    =     (  ( List <  ?  >  )     ( XContentMapValues . extractValue (  \" fields . binary \"  ,    hitRsp )  )  )  ;", "assertEquals (  1  ,    values . size (  )  )  ;", "String   value    =     (  ( String )     ( values . get (  0  )  )  )  ;", "byte [  ]    binaryValue    =    Base 6  4  . getDecoder (  )  . decode ( value )  ;", "assertEquals (  (  (  \" Unexpected   string   length    [  \"     +    value )     +     \"  ]  \"  )  ,     1  6  ,    binaryValue . length )  ;", "}", "}", "METHOD_END"], "methodName": ["assertStoredBinaryFields"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   response    =    FullClusterRestartIT . toStr ( client (  )  . performRequest (  \" GET \"  ,     (  \"  /  _ snapshot / repo /  \"     +    snapshotName )  ,    listSnapshotVerboseParams (  )  )  )  ;", "Map < String ,    Object >    map    =    FullClusterRestartIT . toMap ( response )  ;", "assertEquals ( response ,    Collections . singletonList ( snapshotName )  ,    XContentMapValues . extractValue (  \" snapshots . snapshot \"  ,    map )  )  ;", "assertEquals ( response ,    Collections . singletonList (  \" SUCCESS \"  )  ,    XContentMapValues . extractValue (  \" snapshots . state \"  ,    map )  )  ;", "assertEquals ( response ,    Collections . singletonList ( tookOnVersion . toString (  )  )  ,    XContentMapValues . extractValue (  \" snapshots . version \"  ,    map )  )  ;", "HttpEntity   clearRoutingSetting    =    new   StringEntity (  \"  {  \\  \" persistent \\  \"  :  {  \\  \" cluster . routing . allocation . exclude . test _ attr \\  \"  :    null }  }  \"  ,    ContentType . APPLICATION _ JSON )  ;", "client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ cluster / settings \"  ,    Collections . emptyMap (  )  ,    clearRoutingSetting )  ;", "client (  )  . performRequest (  \" DELETE \"  ,     \"  /  _ template / test _ template \"  ,    Collections . emptyMap (  )  ,    clearRoutingSetting )  ;", "XContentBuilder   restoreCommand    =    JsonXContent . contentBuilder (  )  . startObject (  )  ;", "restoreCommand . field (  \" include _ global _ state \"  ,    true )  ;", "restoreCommand . field (  \" indices \"  ,    index )  ;", "restoreCommand . field (  \" rename _ pattern \"  ,    index )  ;", "restoreCommand . field (  \" rename _ replacement \"  ,     (  \" restored _  \"     +     ( index )  )  )  ;", "restoreCommand . endObject (  )  ;", "client (  )  . performRequest (  \" POST \"  ,     (  (  \"  /  _ snapshot / repo /  \"     +    snapshotName )     +     \"  /  _ restore \"  )  ,    Collections . singletonMap (  \" wait _ for _ completion \"  ,     \" true \"  )  ,    new   StringEntity ( Strings . toString ( restoreCommand )  ,    ContentType . APPLICATION _ JSON )  )  ;", "String   countResponse    =    FullClusterRestartIT . toStr ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  / restored _  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . singletonMap (  \" size \"  ,     \"  0  \"  )  )  )  ;", "assertThat ( countResponse ,    containsString (  (  \"  \\  \" total \\  \"  :  \"     +    count )  )  )  ;", "int   extras    =    between (  1  ,     1  0  0  )  ;", "StringBuilder   bulk    =    new   StringBuilder (  )  ;", "for    ( int   i    =     0  ;    i    <    extras ;    i +  +  )     {", "bulk . append (  \"  {  \\  \" index \\  \"  :  {  \\  \"  _ id \\  \"  :  \\  \"  \"  )  . append (  ( count    +    i )  )  . append (  \"  \\  \"  }  }  \\ n \"  )  ;", "bulk . append (  \"  {  \\  \" test \\  \"  :  \\  \" test \\  \"  }  \\ n \"  )  ;", "}", "client (  )  . performRequest (  \" POST \"  ,     (  (  \"  / restored _  \"     +     ( index )  )     +     \"  / doc /  _ bulk \"  )  ,    Collections . singletonMap (  \" refresh \"  ,     \" true \"  )  ,    new   StringEntity ( bulk . toString (  )  ,    ContentType . APPLICATION _ JSON )  )  ;", "countResponse    =    FullClusterRestartIT . toStr ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  / restored _  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . singletonMap (  \" size \"  ,     \"  0  \"  )  )  )  ;", "assertThat ( countResponse ,    containsString (  (  \"  \\  \" total \\  \"  :  \"     +     ( count    +    extras )  )  )  )  ;", "client (  )  . performRequest (  \" DELETE \"  ,     \"  / restored _  *  \"  )  ;", "map    =    FullClusterRestartIT . toMap ( client (  )  . performRequest (  \" GET \"  ,     \"  /  _ cluster / settings \"  ,    Collections . singletonMap (  \" flat _ settings \"  ,     \" true \"  )  )  )  ;", "Map < String ,    Object >    expected    =    new   HashMap <  >  (  )  ;", "expected . put (  \" transient \"  ,    Collections . emptyMap (  )  )  ;", "expected . put (  \" persistent \"  ,    Collections . singletonMap (  \" cluster . routing . allocation . exclude . test _ attr \"  ,    oldClusterVersion . toString (  )  )  )  ;", "if    (  ( expected . equals ( map )  )     =  =    false )     {", "NotEqualMessageBuilder   builder    =    new   NotEqualMessageBuilder (  )  ;", "builder . compareMaps ( map ,    expected )  ;", "fail (  (  \" settings   don \\  ' t   match :  \\ n \"     +     ( builder . toString (  )  )  )  )  ;", "}", "map    =    FullClusterRestartIT . toMap ( client (  )  . performRequest (  \" GET \"  ,     \"  /  _ template / test _ template \"  )  )  ;", "expected    =    new   HashMap <  >  (  )  ;", "if    (  ( runningAgainstOldCluster )     &  &     ( oldClusterVersion . before ( V _  6  _  0  _  0  _ beta 1  )  )  )     {", "expected . put (  \" template \"  ,     \" evil _  *  \"  )  ;", "} else    {", "expected . put (  \" index _ patterns \"  ,    Collections . singletonList (  \" evil _  *  \"  )  )  ;", "}", "expected . put (  \" settings \"  ,    Collections . singletonMap (  \" index \"  ,    Collections . singletonMap (  \" number _ of _ shards \"  ,     \"  1  \"  )  )  )  ;", "expected . put (  \" mappings \"  ,    Collections . singletonMap (  \" doc \"  ,    Collections . singletonMap (  \"  _ source \"  ,    Collections . singletonMap (  \" enabled \"  ,    true )  )  )  )  ;", "expected . put (  \" order \"  ,     0  )  ;", "Map < String ,    Object >    aliases    =    new   HashMap <  >  (  )  ;", "aliases . put (  \" alias 1  \"  ,    Collections . emptyMap (  )  )  ;", "aliases . put (  \" alias 2  \"  ,    Collections . singletonMap (  \" filter \"  ,    Collections . singletonMap (  \" term \"  ,    Collections . singletonMap (  \" version \"  ,    tookOnVersion . toString (  )  )  )  )  )  ;", "expected . put (  \" aliases \"  ,    aliases )  ;", "expected    =    Collections . singletonMap (  \" test _ template \"  ,    expected )  ;", "if    ( false    =  =     ( expected . equals ( map )  )  )     {", "NotEqualMessageBuilder   builder    =    new   NotEqualMessageBuilder (  )  ;", "builder . compareMaps ( map ,    expected )  ;", "fail (  (  \" template   doesn \\  ' t   match :  \\ n \"     +     ( builder . toString (  )  )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["checkSnapshot"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "return   Integer . parseInt ( loadInfoDocument (  \" count \"  )  )  ;", "}", "METHOD_END"], "methodName": ["countOfIndexedRandomDocuments"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "Response   response    =    client . performRequest (  \" GET \"  ,     ( index    +     \"  /  _ stats \"  )  ,    Collections . singletonMap (  \" level \"  ,     \" shards \"  )  )  ;", "List < String >    no =    new   ArrayList <  >  (  )  ;", "List < Object >    shardStats    =    ObjectPath . createFromResponse ( response )  . evaluate (  (  (  \" indices .  \"     +    index )     +     \"  . shards .  0  \"  )  )  ;", "for    ( Object   shard    :    shardStats )     {", "final   String   nodeId    =    ObjectPath . evaluate ( shard ,     \" routing . node \"  )  ;", "noadd ( nodeId )  ;", "}", "return   no", "}", "METHOD_END"], "methodName": ["dataNodes"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "logger . info (  \" Indexing    {  }    random   documents \"  ,    count )  ;", "for    ( int   i    =     0  ;    i    <    count ;    i +  +  )     {", "logger . debug (  \" Indexing   document    [  {  }  ]  \"  ,    i )  ;", "client (  )  . performRequest (  \" POST \"  ,     (  (  (  \"  /  \"     +     ( index )  )     +     \"  / doc /  \"  )     +    i )  ,    Collections . emptyMap (  )  ,    new   apache . http . entity . StringEntity ( Strings . toString ( docSupplier . apply ( i )  )  ,    ContentType . APPLICATION _ JSON )  )  ;", "if    ( rarely (  )  )     {", "refresh (  )  ;", "}", "if    ( flushAllowed    &  &     ( rarely (  )  )  )     {", "logger . debug (  \" Flushing    [  {  }  ]  \"  ,    index )  ;", "client (  )  . performRequest (  \" POST \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ flush \"  )  )  ;", "}", "}", "if    ( saveInfo )     {", "saveInfoDocument (  \" count \"  ,    Integer . toString ( count )  )  ;", "}", "}", "METHOD_END"], "methodName": ["indexRandomDocuments"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "if    (  ( runningAgainstOldCluster )     &  &     ( oldClusterVersion . before ( V _  5  _  5  _  0  )  )  )     {", "return   Collections . emptyMap (  )  ;", "}", "return   Collections . singletonMap (  \" verbose \"  ,     \" true \"  )  ;", "}", "METHOD_END"], "methodName": ["listSnapshotVerboseParams"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   doc    =    FullClusterRestartIT . toStr ( client (  )  . performRequest (  \" GET \"  ,     (  (  (  \"  / info / doc /  \"     +     ( index )  )     +     \"  _  \"  )     +    type )  ,    Collections . singletonMap (  \" filter _ path \"  ,     \"  _ source \"  )  )  )  ;", "Matcher   m    =    Pattern . compile (  \"  \\  \" value \\  \"  :  \\  \"  (  .  +  )  \\  \"  \"  )  . matcher ( doc )  ;", "assertTrue ( doc ,    m . find (  )  )  ;", "return   m . group (  1  )  ;", "}", "METHOD_END"], "methodName": ["loadInfoDocument"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "return   randomFrom ( new   Object [  ]  {     \" off \"  ,     \" no \"  ,     \"  0  \"  ,     0  ,     \" false \"  ,    false ,     \" on \"  ,     \" yes \"  ,     \"  1  \"  ,     1  ,     \" true \"  ,    true    }  )  ;", "}", "METHOD_END"], "methodName": ["randomLenientBoolean"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "logger . debug (  \" Refreshing    [  {  }  ]  \"  ,    index )  ;", "client (  )  . performRequ (  \" POST \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ refresh \"  )  )  ;", "}", "METHOD_END"], "methodName": ["refresh"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "XContentBuilder   infoDoc    =    JsonXContent . contentBuilder (  )  . startObject (  )  ;", "infoDoc . field (  \" value \"  ,    value )  ;", "infoDoc . endObject (  )  ;", "Map < String ,    String >    params    =    Collections . singletonMap (  \" op _ type \"  ,     \" create \"  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  (  (  \"  / info / doc /  \"     +     ( index )  )     +     \"  _  \"  )     +    type )  ,    params ,    new   StringEntity ( Strings . toString ( infoDoc )  ,    ContentType . APPLICATION _ JSON )  )  ;", "}", "METHOD_END"], "methodName": ["saveInfoDocument"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "index    =    getTestName (  )  . toLowerCase ( Locale . ROOT )  ;", "}", "METHOD_END"], "methodName": ["setIndex"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "assumeTrue (  \" Can   only   test   bad   alias   name   if   old   cluster   is   on    5  .  1  .  0    or   before \"  ,    oldClusterVersion . before ( FullClusterRestartIT . VERSION _  5  _  1  _  0  _ UNRELEASED )  )  ;", "int   count ;", "if    ( runningAgainstOldCluster )     {", "XContentBuilder   mappingsAndSettings    =    jsonBuilder (  )  ;", "mappingsAndSettings . startObject (  )  ;", "{", "mappingsAndSettings . startObject (  \" settings \"  )  ;", "mappingsAndSettings . field (  \" number _ of _ shards \"  ,     1  )  ;", "mappingsAndSettings . field (  \" number _ of _ replicas \"  ,     0  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "{", "mappingsAndSettings . startObject (  \" mappings \"  )  ;", "mappingsAndSettings . startObject (  \" doc \"  )  ;", "mappingsAndSettings . startObject (  \" properties \"  )  ;", "{", "mappingsAndSettings . startObject (  \" key \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" keyword \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  \"  /  \"     +     ( index )  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( mappingsAndSettings )  ,    ContentType . APPLICATION _ JSON )  )  ;", "String   aliasName    =     \"  %  2  3  \"     +     ( index )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ alias /  \"  )     +    aliasName )  )  ;", "Response   response    =    client (  )  . performRequest (  \" HEAD \"  ,     (  (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ alias /  \"  )     +    aliasName )  )  ;", "assertEquals (  2  0  0  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "count    =    randomIntBetween (  3  2  ,     1  2  8  )  ;", "indexRandomDocuments ( count ,    true ,    true ,     (    i )     -  >     {", "return   JsonXContent . contentBuilder (  )  . startObject (  )  . field (  \" key \"  ,     \" value \"  )  . endObject (  )  ;", "}  )  ;", "refresh (  )  ;", "} else    {", "count    =    countOfIndexedRandomDocuments (  )  ;", "}", "logger . error (  (  \" clusterState =  \"     +     ( FullClusterRestartIT . toMap ( client (  )  . performRequest (  \" GET \"  ,     \"  /  _ cluster / state \"  ,    Collections . singletonMap (  \" metric \"  ,     \" metadata \"  )  )  )  )  )  )  ;", "String   aliasName    =     \"  %  2  3  \"     +     ( index )  ;", "Map < String ,    Object >    searchRsp    =    FullClusterRestartIT . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +    aliasName )     +     \"  /  _ search \"  )  )  )  ;", "int   totalHits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    searchRsp )  )  )  ;", "assertEquals ( count ,    totalHits )  ;", "if    (  ( runningAgainstOldCluster )     =  =    false )     {", "Response   response    =    client (  )  . performRequest (  \" DELETE \"  ,     (  (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ alias /  \"  )     +    aliasName )  )  ;", "assertEquals (  2  0  0  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "response    =    client (  )  . performRequest (  \" HEAD \"  ,     (  (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ alias /  \"  )     +    aliasName )  )  ;", "assertEquals (  4  0  4  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testAliasWithBadName"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "if    ( runningAgainstOldCluster )     {", "XContentBuilder   mappingsAndSettings    =    jsonBuilder (  )  ;", "mappingsAndSettings . startObject (  )  ;", "mappingsAndSettings . field (  \" template \"  ,    index )  ;", "{", "mappingsAndSettings . startObject (  \" settings \"  )  ;", "mappingsAndSettings . field (  \" number _ of _ shards \"  ,     1  )  ;", "mappingsAndSettings . field (  \" number _ of _ replicas \"  ,     0  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ template / template _  1  \"  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( mappingsAndSettings )  ,    ContentType . APPLICATION _ JSON )  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  \"  /  \"     +     ( index )  )  )  ;", "}", "Map < String ,    Object >    clusterState    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     \"  /  _ cluster / state \"  )  )  ;", "String   clusterName    =     (  ( String )     ( clusterState . get (  \" cluster _ name \"  )  )  )  ;", "assertEquals (  \" full - cluster - restart \"  ,    clusterName )  ;", "String   numberOfShards    =     (  ( String )     ( XContentMapValues . extractValue (  \" metadata . templates . template _  1  . settings . index . number _ of _ shards \"  ,    clusterState )  )  )  ;", "assertEquals (  \"  1  \"  ,    numberOfShards )  ;", "String   numberOfReplicas    =     (  ( String )     ( XContentMapValues . extractValue (  \" metadata . templates . template _  1  . settings . index . number _ of _ replicas \"  ,    clusterState )  )  )  ;", "assertEquals (  \"  0  \"  ,    numberOfReplicas )  ;", "numberOfShards    =     (  ( String )     ( XContentMapValues . extractValue (  (  (  \" metadata . indices .  \"     +     ( index )  )     +     \"  . settings . index . number _ of _ shards \"  )  ,    clusterState )  )  )  ;", "assertEquals (  \"  1  \"  ,    numberOfShards )  ;", "numberOfReplicas    =     (  ( String )     ( XContentMapValues . extractValue (  (  (  \" metadata . indices .  \"     +     ( index )  )     +     \"  . settings . index . number _ of _ replicas \"  )  ,    clusterState )  )  )  ;", "assertEquals (  \"  0  \"  ,    numberOfReplicas )  ;", "Version   version    =    Version . fromId ( Integer . valueOf (  (  ( String )     ( XContentMapValues . extractValue (  (  (  \" metadata . indices .  \"     +     ( index )  )     +     \"  . settings . index . version . created \"  )  ,    clusterState )  )  )  )  )  ;", "assertEquals ( oldClusterVersion ,    version )  ;", "}", "METHOD_END"], "methodName": ["testClusterState"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "final   String   index    =     \" test _ empty _ shard \"  ;", "if    ( runningAgainstOld )     {", "Settings . Builder   settings    =    Settings . builder (  )  . put ( INDEX _ NUMBER _ OF _ SHARDS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ NUMBER _ OF _ REPLICAS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ DELAYED _ NODE _ LEFT _ TIMEOUT _ SETTING . getKey (  )  ,     \"  1  0  0 ms \"  )  . put ( SETTING _ ALLOCATION _ MAX _ RETRY . getKey (  )  ,     \"  0  \"  )  ;", "createIndex ( index ,    settings . build (  )  )  ;", "}", "ensureGreen ( index )  ;", "}", "METHOD_END"], "methodName": ["testEmptyShard"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "if    ( runningAgainstOldCluster )     {", "XContentBuilder   mappingsAndSettings    =    jsonBuilder (  )  ;", "mappingsAndSettings . startObject (  )  ;", "{", "mappingsAndSettings . startObject (  \" settings \"  )  ;", "mappingsAndSettings . field (  \" number _ of _ shards \"  ,     1  )  ;", "mappingsAndSettings . field (  \" number _ of _ replicas \"  ,     1  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  \"  /  \"     +     ( index )  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( mappingsAndSettings )  ,    ContentType . APPLICATION _ JSON )  )  ;", "} else    {", "Response   response    =    client (  )  . performRequest (  \" GET \"  ,     (  ( index )     +     \"  /  _ stats \"  )  ,    Collections . singletonMap (  \" level \"  ,     \" shards \"  )  )  ;", "List < Object >    shardStats    =    ObjectPath . createFromResponse ( response )  . evaluate (  (  (  \" indices .  \"     +     ( index )  )     +     \"  . shards .  0  \"  )  )  ;", "String   globalHistoryUUID    =    null ;", "for    ( Object   shard    :    shardStats )     {", "final   String   nodeId    =    ObjectPath . evaluate ( shard ,     \" routing . node \"  )  ;", "final   Boolean   primary    =    ObjectPath . evaluate ( shard ,     \" routing . primary \"  )  ;", "logger . info (  \" evaluating :     {  }     ,     {  }  \"  ,    ObjectPath . evaluate ( shard ,     \" routing \"  )  ,    ObjectPath . evaluate ( shard ,     \" commit \"  )  )  ;", "String   historyUUID    =    ObjectPath . evaluate ( shard ,     \" commit . user _ data . history _ uuid \"  )  ;", "assertThat (  (  (  (  (  \" no   history   uuid   found   on    \"     +    nodeId )     +     \"     ( primary :     \"  )     +    primary )     +     \"  )  \"  )  ,    historyUUID ,    notNullValue (  )  )  ;", "if    ( globalHistoryUUID    =  =    null )     {", "globalHistoryUUID    =    historyUUID ;", "} else    {", "assertThat (  (  (  (  (  \" history   uuid   mismatch   on    \"     +    nodeId )     +     \"     ( primary :     \"  )     +    primary )     +     \"  )  \"  )  ,    historyUUID ,    equalTo ( globalHistoryUUID )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["testHistoryUUIDIsAdded"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "if    ( runningAgainstOldCluster )     {", "XContentBuilder   mappingsAndSettings    =    jsonBuilder (  )  ;", "mappingsAndSettings . startObject (  )  ;", "{", "mappingsAndSettings . startObject (  \" settings \"  )  ;", "mappingsAndSettings . field (  \" number _ of _ shards \"  ,     1  )  ;", "mappingsAndSettings . field (  \" number _ of _ replicas \"  ,     0  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "{", "mappingsAndSettings . startObject (  \" mappings \"  )  ;", "mappingsAndSettings . startObject (  \" doc \"  )  ;", "mappingsAndSettings . startObject (  \" properties \"  )  ;", "{", "mappingsAndSettings . startObject (  \" field \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" text \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  \"  /  \"     +     ( index )  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( mappingsAndSettings )  ,    ContentType . APPLICATION _ JSON )  )  ;", "int   numDocs    =    randomIntBetween (  2  0  0  0  ,     3  0  0  0  )  ;", "indexRandomDocuments ( numDocs ,    true ,    false ,     (    i )     -  >     {", "return   JsonXContent . contentBuilder (  )  . startObject (  )  . field (  \" field \"  ,     \" value \"  )  . endObject (  )  ;", "}  )  ;", "logger . info (  \" Refreshing    [  {  }  ]  \"  ,    index )  ;", "client (  )  . performRequest (  \" POST \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ refresh \"  )  )  ;", "} else    {", "final   int   numReplicas    =     1  ;", "final   long   startTime    =    System . currentTimeMillis (  )  ;", "logger . debug (  \"  -  -  >    creating    [  {  }  ]    replicas   for   index    [  {  }  ]  \"  ,    numReplicas ,    index )  ;", "String   requestBody    =     (  \"  {     \\  \" index \\  \"  :     {     \\  \" number _ of _ replicas \\  \"     :     \"     +    numReplicas )     +     \"     }  }  \"  ;", "Response   response    =    client (  )  . performRequest (  \" PUT \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ settings \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( requestBody ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    response . getStatusLine (  )  . getStatusCode (  )  )  ;", "Map < String ,    String >    params    =    new   HashMap <  >  (  )  ;", "params . put (  \" timeout \"  ,     \"  2 m \"  )  ;", "params . put (  \" wait _ for _ status \"  ,     \" green \"  )  ;", "params . put (  \" wait _ for _ no _ relocating _ shards \"  ,     \" true \"  )  ;", "params . put (  \" wait _ for _ events \"  ,     \" languid \"  )  ;", "Map < String ,    Object >    healthRsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  \"  /  _ cluster / health /  \"     +     ( index )  )  ,    params )  )  ;", "assertEquals (  \" green \"  ,    healthRsp . get (  \" status \"  )  )  ;", "assertFalse (  (  ( Boolean )     ( healthRsp . get (  \" timed _ out \"  )  )  )  )  ;", "logger . debug (  \"  -  -  >    index    [  {  }  ]    is   green ,    took    [  {  }  ]    ms \"  ,    index ,     (  ( System . currentTimeMillis (  )  )     -    startTime )  )  ;", "Map < String ,    Object >    recoverRsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ recovery \"  )  )  )  ;", "logger . debug (  \"  -  -  >    recovery   status :  \\ n {  }  \"  ,    recoverRsp )  ;", "Set < Integer >    counts    =    new   HashSet <  >  (  )  ;", "for    ( String   node    :    dataNodes ( index ,    client (  )  )  )     {", "Map < String ,    Object >    responseBody    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . singletonMap (  \" preference \"  ,     (  \"  _ only _ nodes :  \"     +    node )  )  )  )  ;", ". assertNoFailures ( responseBody )  ;", "int   hits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    responseBody )  )  )  ;", "counts . add ( hits )  ;", "}", "assertEquals (  \" All   nodes   should   have   a   consistent   number   of   documents \"  ,     1  ,    counts . size (  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testNewReplicasWork"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "int   count ;", "boolean   shouldHaveTranslog ;", "if    ( runningAgainstOldCluster )     {", "count    =    between (  2  0  0  ,     3  0  0  )  ;", "shouldHaveTranslog    =    randomBoolean (  )  ;", "indexRandomDocuments ( count ,    true ,    true ,     (    i )     -  >    jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     \" value \"  )  . endObject (  )  )  ;", "ensureNoInitializingShards (  )  ;", "client (  )  . performRequest (  \" POST \"  ,     \"  /  _ flush \"  )  ;", "if    ( shouldHaveTranslog )     {", "indexRandomDocuments (  ( count    /     1  0  )  ,    false ,    false ,     (    i )     -  >    jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     \" value \"  )  . endObject (  )  )  ;", "}", "saveInfoDocument (  \" should _ have _ translog \"  ,    Boolean . toString ( shouldHaveTranslog )  )  ;", "} else    {", "count    =    countOfIndexedRandomDocuments (  )  ;", "shouldHaveTranslog    =    Booleans . parseBoolean ( loadInfoDocument (  \" should _ have _ translog \"  )  )  ;", "}", "String   countResponse    =     . toStr ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . singletonMap (  \" size \"  ,     \"  0  \"  )  )  )  ;", "assertThat ( countResponse ,    containsString (  (  \"  \\  \" total \\  \"  :  \"     +    count )  )  )  ;", "if    ( false    =  =     ( runningAgainstOldCluster )  )     {", "boolean   restoredFromTranslog    =    false ;", "boolean   foundPrimary    =    false ;", "Map < String ,    String >    params    =    new   HashMap <  >  (  )  ;", "params . put (  \" h \"  ,     \" index , shard , type , stage , translog _ ops _ recovered \"  )  ;", "params . put (  \" s \"  ,     \" index , shard , type \"  )  ;", "String   recoveryResponse    =     . toStr ( client (  )  . performRequest (  \" GET \"  ,     (  \"  /  _ cat / recovery /  \"     +     ( index )  )  ,    params )  )  ;", "for    ( String   line    :    recoveryResponse . split (  \"  \\ n \"  )  )     {", "foundPrimary    =    true ;", "if    (  ( false    =  =     ( line . contains (  \" done \"  )  )  )     &  &     ( line . contains (  \" existing _ store \"  )  )  )     {", "continue ;", "}", "Matcher   m    =    Pattern . compile (  \"  (  \\  \\ d +  )  $  \"  )  . matcher ( line )  ;", "assertTrue ( line ,    m . find (  )  )  ;", "int   translogOps    =    Integer . parseInt ( m . group (  1  )  )  ;", "if    ( translogOps    >     0  )     {", "restoredFromTranslog    =    true ;", "}", "}", "assertTrue (  (  \" expected   to   find   a   primary   but   didn \\  ' t \\ n \"     +    recoveryResponse )  ,    foundPrimary )  ;", "assertEquals (  (  \" mismatch   while   checking   for   translog   recovery \\ n \"     +    recoveryResponse )  ,    shouldHaveTranslog ,    restoredFromTranslog )  ;", "String   currentLuceneVersion    =    luceneVersion . toString (  )  ;", "String   bwcLuceneVersion    =    oldClusterVersion . luceneVersion . toString (  )  ;", "if    ( shouldHaveTranslog    &  &     ( false    =  =     ( currentLuceneVersion . equals ( bwcLuceneVersion )  )  )  )     {", "int   numCurrentVersion    =     0  ;", "int   numBwcVersion    =     0  ;", "params . clear (  )  ;", "params . put (  \" h \"  ,     \" prirep , shard , index , version \"  )  ;", "params . put (  \" s \"  ,     \" prirep , shard , index \"  )  ;", "String   segmentsResponse    =     . toStr ( client (  )  . performRequest (  \" GET \"  ,     (  \"  /  _ cat / segments /  \"     +     ( index )  )  ,    params )  )  ;", "for    ( String   line    :    segmentsResponse . split (  \"  \\ n \"  )  )     {", "if    ( false    =  =     ( line . startsWith (  \" p \"  )  )  )     {", "continue ;", "}", "Matcher   m    =    Pattern . compile (  \"  (  \\  \\ d +  \\  \\  .  \\  \\ d +  \\  \\  .  \\  \\ d +  )  $  \"  )  . matcher ( line )  ;", "assertTrue ( line ,    m . find (  )  )  ;", "String   version    =    m . group (  1  )  ;", "if    ( currentLuceneVersion . equals ( version )  )     {", "numCurrentVersion +  +  ;", "} else", "if    ( bwcLuceneVersion . equals ( version )  )     {", "numBwcVersion +  +  ;", "} else    {", "fail (  (  (  (  (  (  \" expected   version   to   be   one   of    [  \"     +    currentLuceneVersion )     +     \"  ,  \"  )     +    bwcLuceneVersion )     +     \"  ]    but   was    \"  )     +    line )  )  ;", "}", "}", "assertNotEquals (  (  \" expected   at   least    1    current   segment   after   translog   recovery .    segments :  \\ n \"     +    segmentsResponse )  ,     0  ,    numCurrentVersion )  ;", "assertNotEquals (  (  \" expected   at   least    1    old   segment .    segments :  \\ n \"     +    segmentsResponse )  ,     0  ,    numBwcVersion )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testRecovery"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "int   count ;", "if    ( runningAgainstOldCluster )     {", "XContentBuilder   mappingsAndSettings    =    jsonBuilder (  )  ;", "mappingsAndSettings . startObject (  )  ;", "{", "mappingsAndSettings . startObject (  \" settings \"  )  ;", "mappingsAndSettings . field (  \" number _ of _ shards \"  ,     1  )  ;", "mappingsAndSettings . field (  \" number _ of _ replicas \"  ,     0  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "{", "mappingsAndSettings . startObject (  \" mappings \"  )  ;", "mappingsAndSettings . startObject (  \" doc \"  )  ;", "mappingsAndSettings . startObject (  \" properties \"  )  ;", "{", "mappingsAndSettings . startObject (  \" string \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" text \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "{", "mappingsAndSettings . startObject (  \" dots _ in _ field _ names \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" text \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "{", "mappingsAndSettings . startObject (  \" binary \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" binary \"  )  ;", "mappingsAndSettings . field (  \" store \"  ,     \" true \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  \"  /  \"     +     ( index )  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( mappingsAndSettings )  ,    ContentType . APPLICATION _ JSON )  )  ;", "count    =    randomIntBetween (  2  0  0  0  ,     3  0  0  0  )  ;", "byte [  ]    randomByteArray    =    new   byte [  1  6  ]  ;", "random (  )  . nextBytes ( randomByteArray )  ;", "indexRandomDocuments ( count ,    true ,    true ,     (    i )     -  >     {", "return   JsonXContent . contentBuilder (  )  . startObject (  )  . field (  \" string \"  ,    randomAlphaOfLength (  1  0  )  )  . field (  \" int \"  ,    randomInt (  1  0  0  )  )  . field (  \" float \"  ,    randomFloat (  )  )  . field (  \" bool \"  ,     (  ( i    >     0  )     &  &     ( supportsLenientBooleans )     ?    randomLenientBoolean (  )     :    randomBoolean (  )  )  )  . field (  \" field . with . dots \"  ,    randomAlphaOfLength (  1  0  )  )  . field (  \" binary \"  ,    Base 6  4  . getEncoder (  )  . encodeToString ( randomByteArray )  )  . endObject (  )  ;", "}  )  ;", "refresh (  )  ;", "} else    {", "count    =    countOfIndexedRandomDocuments (  )  ;", "}", "Map < String ,    String >    params    =    new   HashMap <  >  (  )  ;", "params . put (  \" timeout \"  ,     \"  2 m \"  )  ;", "params . put (  \" wait _ for _ status \"  ,     \" green \"  )  ;", "params . put (  \" wait _ for _ no _ relocating _ shards \"  ,     \" true \"  )  ;", "params . put (  \" wait _ for _ events \"  ,     \" languid \"  )  ;", "Map < String ,    Object >    healthRsp    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  \"  /  _ cluster / health /  \"     +     ( index )  )  ,    params )  )  ;", "logger . info (  \" health   api   response :     {  }  \"  ,    healthRsp )  ;", "assertEquals (  \" green \"  ,    healthRsp . get (  \" status \"  )  )  ;", "assertFalse (  (  ( Boolean )     ( healthRsp . get (  \" timed _ out \"  )  )  )  )  ;", "assertBasicSearchWorks ( count )  ;", "assertAllSearchWorks ( count )  ;", "assertBasicAggregationWorks (  )  ;", "assertRealtimeGetWorks (  )  ;", "assertStoredBinaryFields ( count )  ;", "}", "METHOD_END"], "methodName": ["testSearch"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   shrunkenIndex    =     ( index )     +     \"  _ shrunk \"  ;", "int   numDocs ;", "if    ( runningAgainstOldCluster )     {", "XContentBuilder   mappingsAndSettings    =    jsonBuilder (  )  ;", "mappingsAndSettings . startObject (  )  ;", "{", "mappingsAndSettings . startObject (  \" mappings \"  )  ;", "mappingsAndSettings . startObject (  \" doc \"  )  ;", "mappingsAndSettings . startObject (  \" properties \"  )  ;", "{", "mappingsAndSettings . startObject (  \" field \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" text \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  \"  /  \"     +     ( index )  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( mappingsAndSettings )  ,    ContentType . APPLICATION _ JSON )  )  ;", "numDocs    =    randomIntBetween (  5  1  2  ,     1  0  2  4  )  ;", "indexRandomDocuments ( numDocs ,    true ,    true ,     (    i )     -  >     {", "return   JsonXContent . contentBuilder (  )  . startObject (  )  . field (  \" field \"  ,     \" value \"  )  . endObject (  )  ;", "}  )  ;", "ensureGreen ( index )  ;", "String   updateSettingsRequestBody    =     \"  {  \\  \" settings \\  \"  :     {  \\  \" index . blocks . write \\  \"  :    true }  }  \"  ;", "Response   rsp    =    client (  )  . performRequest (  \" PUT \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ settings \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( updateSettingsRequestBody ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    rsp . getStatusLine (  )  . getStatusCode (  )  )  ;", "String   shrinkIndexRequestBody    =     \"  {  \\  \" settings \\  \"  :     {  \\  \" index . number _ of _ shards \\  \"  :     1  }  }  \"  ;", "rsp    =    client (  )  . performRequest (  \" PUT \"  ,     (  (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ shrink /  \"  )     +    shrunkenIndex )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( shrinkIndexRequestBody ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    rsp . getStatusLine (  )  . getStatusCode (  )  )  ;", "rsp    =    client (  )  . performRequest (  \" POST \"  ,     \"  /  _ refresh \"  )  ;", "assertEquals (  2  0  0  ,    rsp . getStatusLine (  )  . getStatusCode (  )  )  ;", "} else    {", "numDocs    =    countOfIndexedRandomDocuments (  )  ;", "}", "Map <  ?  ,     ?  >    response    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  )  )  ;", ". assertNoFailures ( response )  ;", "int   totalShards    =     (  ( int )     ( XContentMapValues . extractValue (  \"  _ shards . total \"  ,    response )  )  )  ;", "assertThat ( totalShards ,    greaterThan (  1  )  )  ;", "int   successfulShards    =     (  ( int )     ( XContentMapValues . extractValue (  \"  _ shards . successful \"  ,    response )  )  )  ;", "assertEquals ( totalShards ,    successfulShards )  ;", "int   totalHits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    response )  )  )  ;", "assertEquals ( numDocs ,    totalHits )  ;", "response    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +    shrunkenIndex )     +     \"  /  _ search \"  )  )  )  ;", ". assertNoFailures ( response )  ;", "totalShards    =     (  ( int )     ( XContentMapValues . extractValue (  \"  _ shards . total \"  ,    response )  )  )  ;", "assertEquals (  1  ,    totalShards )  ;", "successfulShards    =     (  ( int )     ( XContentMapValues . extractValue (  \"  _ shards . successful \"  ,    response )  )  )  ;", "assertEquals (  1  ,    successfulShards )  ;", "totalHits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    response )  )  )  ;", "assertEquals ( numDocs ,    totalHits )  ;", "}", "METHOD_END"], "methodName": ["testShrink"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   shrunkenIndex    =     ( index )     +     \"  _ shrunk \"  ;", "int   numDocs ;", "if    ( runningAgainstOldCluster )     {", "XContentBuilder   mappingsAndSettings    =    jsonBuilder (  )  ;", "mappingsAndSettings . startObject (  )  ;", "{", "mappingsAndSettings . startObject (  \" mappings \"  )  ;", "mappingsAndSettings . startObject (  \" doc \"  )  ;", "mappingsAndSettings . startObject (  \" properties \"  )  ;", "{", "mappingsAndSettings . startObject (  \" field \"  )  ;", "mappingsAndSettings . field (  \" type \"  ,     \" text \"  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "mappingsAndSettings . endObject (  )  ;", "}", "mappingsAndSettings . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     (  \"  /  \"     +     ( index )  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( mappingsAndSettings )  ,    ContentType . APPLICATION _ JSON )  )  ;", "numDocs    =    randomIntBetween (  5  1  2  ,     1  0  2  4  )  ;", "indexRandomDocuments ( numDocs ,    true ,    true ,     (    i )     -  >     {", "return   JsonXContent . contentBuilder (  )  . startObject (  )  . field (  \" field \"  ,     \" value \"  )  . endObject (  )  ;", "}  )  ;", "} else    {", "ensureGreen ( index )  ;", "String   updateSettingsRequestBody    =     \"  {  \\  \" settings \\  \"  :     {  \\  \" index . blocks . write \\  \"  :    true }  }  \"  ;", "Response   rsp    =    client (  )  . performRequest (  \" PUT \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ settings \"  )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( updateSettingsRequestBody ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    rsp . getStatusLine (  )  . getStatusCode (  )  )  ;", "String   shrinkIndexRequestBody    =     \"  {  \\  \" settings \\  \"  :     {  \\  \" index . number _ of _ shards \\  \"  :     1  }  }  \"  ;", "rsp    =    client (  )  . performRequest (  \" PUT \"  ,     (  (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ shrink /  \"  )     +    shrunkenIndex )  ,    Collections . emptyMap (  )  ,    new   StringEntity ( shrinkIndexRequestBody ,    ContentType . APPLICATION _ JSON )  )  ;", "assertEquals (  2  0  0  ,    rsp . getStatusLine (  )  . getStatusCode (  )  )  ;", "numDocs    =    countOfIndexedRandomDocuments (  )  ;", "}", "Response   rsp    =    client (  )  . performRequest (  \" POST \"  ,     \"  /  _ refresh \"  )  ;", "assertEquals (  2  0  0  ,    rsp . getStatusLine (  )  . getStatusCode (  )  )  ;", "Map <  ?  ,     ?  >    response    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  )  )  ;", ". assertNoFailures ( response )  ;", "int   totalShards    =     (  ( int )     ( XContentMapValues . extractValue (  \"  _ shards . total \"  ,    response )  )  )  ;", "assertThat ( totalShards ,    greaterThan (  1  )  )  ;", "int   successfulShards    =     (  ( int )     ( XContentMapValues . extractValue (  \"  _ shards . successful \"  ,    response )  )  )  ;", "assertEquals ( totalShards ,    successfulShards )  ;", "int   totalHits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    response )  )  )  ;", "assertEquals ( numDocs ,    totalHits )  ;", "if    (  ( runningAgainstOldCluster )     =  =    false )     {", "response    =     . toMap ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +    shrunkenIndex )     +     \"  /  _ search \"  )  )  )  ;", ". assertNoFailures ( response )  ;", "totalShards    =     (  ( int )     ( XContentMapValues . extractValue (  \"  _ shards . total \"  ,    response )  )  )  ;", "assertEquals (  1  ,    totalShards )  ;", "successfulShards    =     (  ( int )     ( XContentMapValues . extractValue (  \"  _ shards . successful \"  ,    response )  )  )  ;", "assertEquals (  1  ,    successfulShards )  ;", "totalHits    =     (  ( int )     ( XContentMapValues . extractValue (  \" hits . total \"  ,    response )  )  )  ;", "assertEquals ( numDocs ,    totalHits )  ;", "}", "}", "METHOD_END"], "methodName": ["testShrinkAfterUpgrade"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "String   docLocation    =     (  \"  /  \"     +     ( index )  )     +     \"  / doc /  1  \"  ;", "String   doc    =     \"  {  \\  \" test \\  \"  :     \\  \" test \\  \"  }  \"  ;", "if    ( runningAgainstOldCluster )     {", "client (  )  . performRequest (  \" PUT \"  ,    docLocation ,    Collections . singletonMap (  \" refresh \"  ,     \" true \"  )  ,    new   StringEntity ( doc ,    ContentType . APPLICATION _ JSON )  )  ;", "}", "assertThat (  . toStr ( client (  )  . performRequest (  \" GET \"  ,    docLocation )  )  ,    containsString ( doc )  )  ;", "}", "METHOD_END"], "methodName": ["testSingleDoc"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "int   count ;", "if    ( runningAgainstOldCluster )     {", "count    =    between (  2  0  0  ,     3  0  0  )  ;", "indexRandomDocuments ( count ,    true ,    true ,     (    i )     -  >    jsonBuilder (  )  . startObject (  )  . field (  \" field \"  ,     \" value \"  )  . endObject (  )  )  ;", "} else    {", "count    =    countOfIndexedRandomDocuments (  )  ;", "}", "refresh (  )  ;", "String   countResponse    =     . toStr ( client (  )  . performRequest (  \" GET \"  ,     (  (  \"  /  \"     +     ( index )  )     +     \"  /  _ search \"  )  ,    Collections . singletonMap (  \" size \"  ,     \"  0  \"  )  )  )  ;", "assertThat ( countResponse ,    containsString (  (  \"  \\  \" total \\  \"  :  \"     +    count )  )  )  ;", "HttpEntity   routingSetting    =    new   StringEntity (  (  (  \"  {  \\  \" persistent \\  \"  :     {  \\  \" cluster . routing . allocation . exclude . test _ attr \\  \"  :     \\  \"  \"     +     ( oldClusterVersion )  )     +     \"  \\  \"  }  }  \"  )  ,    ContentType . APPLICATION _ JSON )  ;", "client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ cluster / settings \"  ,    Collections . emptyMap (  )  ,    routingSetting )  ;", "XContentBuilder   templateBuilder    =    JsonXContent . contentBuilder (  )  . startObject (  )  ;", "templateBuilder . field (  \" template \"  ,     \" evil _  *  \"  )  ;", "templateBuilder . startObject (  \" settings \"  )  ;", "{", "templateBuilder . field (  \" number _ of _ shards \"  ,     1  )  ;", "}", "templateBuilder . endObject (  )  ;", "templateBuilder . startObject (  \" mappings \"  )  ;", "{", "templateBuilder . startObject (  \" doc \"  )  ;", "{", "templateBuilder . startObject (  \"  _ source \"  )  ;", "{", "templateBuilder . field (  \" enabled \"  ,    true )  ;", "}", "templateBuilder . endObject (  )  ;", "}", "templateBuilder . endObject (  )  ;", "}", "templateBuilder . endObject (  )  ;", "templateBuilder . startObject (  \" aliases \"  )  ;", "{", "templateBuilder . startObject (  \" alias 1  \"  )  . endObject (  )  ;", "templateBuilder . startObject (  \" alias 2  \"  )  ;", "{", "templateBuilder . startObject (  \" filter \"  )  ;", "{", "templateBuilder . startObject (  \" term \"  )  ;", "{", "templateBuilder . field (  \" version \"  ,     ( runningAgainstOldCluster    ?    oldClusterVersion    :    Version . CURRENT )  )  ;", "}", "templateBuilder . endObject (  )  ;", "}", "templateBuilder . endObject (  )  ;", "}", "templateBuilder . endObject (  )  ;", "}", "templateBuilder . endObject (  )  . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ template / test _ template \"  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( templateBuilder )  ,    ContentType . APPLICATION _ JSON )  )  ;", "if    ( runningAgainstOldCluster )     {", "XContentBuilder   repoConfig    =    JsonXContent . contentBuilder (  )  . startObject (  )  ;", "{", "repoConfig . field (  \" type \"  ,     \" fs \"  )  ;", "repoConfig . startObject (  \" settings \"  )  ;", "{", "repoConfig . field (  \" compress \"  ,    randomBoolean (  )  )  ;", "repoConfig . field (  \" location \"  ,    System . getProperty (  \" tests . path . repo \"  )  )  ;", "}", "repoConfig . endObject (  )  ;", "}", "repoConfig . endObject (  )  ;", "client (  )  . performRequest (  \" PUT \"  ,     \"  /  _ snapshot / repo \"  ,    Collections . emptyMap (  )  ,    new   StringEntity ( Strings . toString ( repoConfig )  ,    ContentType . APPLICATION _ JSON )  )  ;", "}", "client (  )  . performRequest (  \" PUT \"  ,     (  \"  /  _ snapshot / repo /  \"     +     ( runningAgainstOldCluster    ?     \" old _ snap \"     :     \" new _ snap \"  )  )  ,    Collections . singletonMap (  \" wait _ for _ completion \"  ,     \" true \"  )  ,    new   StringEntity (  (  (  \"  {  \\  \" indices \\  \"  :     \\  \"  \"     +     ( index )  )     +     \"  \\  \"  }  \"  )  ,    ContentType . APPLICATION _ JSON )  )  ;", "checkSnapshot (  \" old _ snap \"  ,    count ,    oldClusterVersion )  ;", "if    ( false    =  =     ( runningAgainstOldCluster )  )     {", "checkSnapshot (  \" new _ snap \"  ,    count ,    CURRENT )  ;", "}", "}", "METHOD_END"], "methodName": ["testSnapshotRestore"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "return   XContentHelper . convertToMap ( jsonXContent ,    response ,    false )  ;", "}", "METHOD_END"], "methodName": ["toMap"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "return   FullClusterRestartIT . toMap ( EntityUtils . toString ( response . getEntity (  )  )  )  ;", "}", "METHOD_END"], "methodName": ["toMap"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "return   EntityUtils . toString ( response . getEntity (  )  )  ;", "}", "METHOD_END"], "methodName": ["toStr"], "fileName": "org.elasticsearch.upgrades.FullClusterRestartIT"}, {"methodBody": ["METHOD_START", "{", "return   createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.upgrades.MultiClusterSearchYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "final   Response   response    =    client (  )  . performRequest (  \" GET \"  ,     ( index    +     \"  /  _ count \"  )  ,    Collections . singletonMap (  \" preference \"  ,    preference )  )  ;", "assertOK ( response )  ;", "final   int   actualCount    =    Integer . parseInt ( ObjectPath . createFromResponse ( response )  . evaluate (  \" count \"  )  . toString (  )  )  ;", "assertThat ( actualCount ,    equalTo ( expectedCount )  )  ;", "}", "METHOD_END"], "methodName": ["assertCount"], "fileName": "org.elasticsearch.upgrades.RecoveryIT"}, {"methodBody": ["METHOD_START", "{", "PlainActionFuture < Void >    future    =    new   PlainActionFuture (  )  ;", "Thread   background    =    new   Thread ( new   AbstractRunnable (  )     {", "@ Oride", "public   void   onFailure ( Exception   e )     {", "future . onFailure ( e )  ;", "}", "@ Oride", "protected   void   doRun (  )    throws   Exception    {", "indexDocs ( index ,    idStart ,    numDocs )  ;", "future . onResponse ( null )  ;", "}", "}  )  ;", "background . start (  )  ;", "return   future ;", "}", "METHOD_END"], "methodName": ["asyncIndexDocs"], "fileName": "org.elasticsearch.upgrades.RecoveryIT"}, {"methodBody": ["METHOD_START", "{", "Response   response    =    client (  )  . performRequest (  \" GET \"  ,     \"  _ no )  ;", "ObjectPath   objectPath    =    ObjectPath . createFromResponse ( response )  ;", "Map < String ,    Object >    nosMap    =    objectPath . evaluate (  \" no )  ;", "for    ( String   id    :    nosMap . keySet (  )  )     {", "Version   version    =    Version . fromString ( objectPath . evaluate (  (  (  \" no \"     +    id )     +     \"  . version \"  )  )  )  ;", "if    ( versionPredicate . test ( version )  )     {", "return   id ;", "}", "}", "return   null ;", "}", "METHOD_END"], "methodName": ["getNodeId"], "fileName": "org.elasticsearch.upgrades.RecoveryIT"}, {"methodBody": ["METHOD_START", "{", "for    ( int   i    =     0  ;    i    <    numDocs ;    i +  +  )     {", "final   int   id    =    idStart    +    i ;", "assertOK ( client (  )  . performRequest (  \" PUT \"  ,     (  ( index    +     \"  / test /  \"  )     +    id )  ,    Collections . emptyMap (  )  ,    new   apache . http . entity . StringEntity (  (  (  \"  {  \\  \" test \\  \"  :     \\  \" test _  \"     +     ( randomAsciiOfLength (  2  )  )  )     +     \"  \\  \"  }  \"  )  ,    ContentType . APPLICATION _ JSON )  )  )  ;", "}", "return   numDocs ;", "}", "METHOD_END"], "methodName": ["indexDocs"], "fileName": "org.elasticsearch.upgrades.RecoveryIT"}, {"methodBody": ["METHOD_START", "{", "final   String   index    =     \" index _ history _ uuid \"  ;", "if    (  ( clusterType )     =  =     ( RecoveryIT . CLUSTER _ TYPE . OLD )  )     {", "Settings . Builder   settings    =    Settings . builder (  )  . put ( INDEX _ NUMBER _ OF _ SHARDS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ NUMBER _ OF _ REPLICAS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ DELAYED _ NODE _ LEFT _ TIMEOUT _ SETTING . getKey (  )  ,     \"  1  0  0 ms \"  )  ;", "createIndex ( index ,    settings . build (  )  )  ;", "} else", "if    (  ( clusterType )     =  =     ( RecoveryIT . CLUSTER _ TYPE . UPGRADED )  )     {", "ensureGreen ( index )  ;", "client . Response   response    =    client (  )  . performRequest (  \" GET \"  ,     ( index    +     \"  /  _ stats \"  )  ,    singletonMap (  \" level \"  ,     \" shards \"  )  )  ;", "assertOK ( response )  ;", "test . rest . yaml . ObjectPath   objectPath    =    test . rest . yaml . ObjectPath . createFromResponse ( response )  ;", "List < Object >    shardStats    =    objectPath . evaluate (  (  (  \" indices .  \"     +    index )     +     \"  . shards .  0  \"  )  )  ;", "assertThat ( shardStats ,    hasSize (  2  )  )  ;", "String   expectHistoryUUID    =    null ;", "for    ( int   shard    =     0  ;    shard    <     2  ;    shard +  +  )     {", "String   nodeID    =    objectPath . evaluate (  (  (  (  (  \" indices .  \"     +    index )     +     \"  . shards .  0  .  \"  )     +    shard )     +     \"  . routing . node \"  )  )  ;", "String   historyUUID    =    objectPath . evaluate (  (  (  (  (  \" indices .  \"     +    index )     +     \"  . shards .  0  .  \"  )     +    shard )     +     \"  . commit . user _ data . history _ uuid \"  )  )  ;", "assertThat (  (  \" no   history   uuid   found   for   shard   on    \"     +    nodeID )  ,    historyUUID ,    notNullValue (  )  )  ;", "if    ( expectHistoryUUID    =  =    null )     {", "expectHistoryUUID    =    historyUUID ;", "} else    {", "assertThat (  (  \" different   history   uuid   found   for   shard   on    \"     +    nodeID )  ,    historyUUID ,    equalTo ( expectHistoryUUID )  )  ;", "}", "}", "}", "}", "METHOD_END"], "methodName": ["testHistoryUUIDIsGenerated"], "fileName": "org.elasticsearch.upgrades.RecoveryIT"}, {"methodBody": ["METHOD_START", "{", "final   String   index    =     \" recovery _ with _ concurrent _ indexing \"  ;", "Response   response    =    client (  )  . performRequest (  \" GET \"  ,     \"  _ nodes \"  )  ;", "ObjectPath   objectPath    =    ObjectPath . createFromResponse ( response )  ;", "final   Map < String ,    Object >    nodeMap    =    objectPath . evaluate (  \" nodes \"  )  ;", "List < String >    nodes    =    new   ArrayList <  >  ( nodeMap . keySet (  )  )  ;", "switch    ( clusterType )     {", "case   OLD    :", "Settings . Builder   settings    =    Settings . builder (  )  . put ( INDEX _ NUMBER _ OF _ SHARDS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ NUMBER _ OF _ REPLICAS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ DELAYED _ NODE _ LEFT _ TIMEOUT _ SETTING . getKey (  )  ,     \"  1  0  0 ms \"  )  . put ( SETTING _ ALLOCATION _ MAX _ RETRY . getKey (  )  ,     \"  0  \"  )  ;", "createIndex ( index ,    settings . build (  )  )  ;", "indexDocs ( index ,     0  ,     1  0  )  ;", "ensureGreen ( index )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put ( INDEX _ ROUTING _ ALLOCATION _ ENABLE _ SETTING . getKey (  )  ,     \" primaries \"  )  )  ;", "break ;", "case   MIXED    :", "updateIndexSettings ( index ,    Settings . builder (  )  . put ( INDEX _ ROUTING _ ALLOCATION _ ENABLE _ SETTING . getKey (  )  ,     (  ( String )     ( null )  )  )  )  ;", "asyncIndexDocs ( index ,     1  0  ,     5  0  )  . get (  )  ;", "ensureGreen ( index )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( nodes . get (  0  )  )  )  ,     6  0  )  ;", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( nodes . get (  1  )  )  )  ,     6  0  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put ( INDEX _ ROUTING _ ALLOCATION _ ENABLE _ SETTING . getKey (  )  ,     \" primaries \"  )  )  ;", "break ;", "case   UPGRADED    :", "updateIndexSettings ( index ,    Settings . builder (  )  . put ( INDEX _ ROUTING _ ALLOCATION _ ENABLE _ SETTING . getKey (  )  ,     (  ( String )     ( null )  )  )  )  ;", "asyncIndexDocs ( index ,     6  0  ,     5  0  )  . get (  )  ;", "ensureGreen ( index )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( nodes . get (  0  )  )  )  ,     1  1  0  )  ;", "assertCount ( index ,     (  \"  _ only _ nodes :  \"     +     ( nodes . get (  1  )  )  )  ,     1  1  0  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  (  \" unknown   type    \"     +     ( clusterType )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRecoveryWithConcurrentIndexing"], "fileName": "org.elasticsearch.upgrades.RecoveryIT"}, {"methodBody": ["METHOD_START", "{", "final   String   index    =     \" relocation _ with _ concurrent _ indexing \"  ;", "switch    ( clusterType )     {", "case   OLD    :", "Settings . Builder   settings    =    Settings . builder (  )  . put ( INDEX _ NUMBER _ OF _ SHARDS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ NUMBER _ OF _ REPLICAS _ SETTING . getKey (  )  ,     1  )  . put ( INDEX _ DELAYED _ NODE _ LEFT _ TIMEOUT _ SETTING . getKey (  )  ,     \"  1  0  0 ms \"  )  . put ( SETTING _ ALLOCATION _ MAX _ RETRY . getKey (  )  ,     \"  0  \"  )  ;", "createIndex ( index ,    settings . build (  )  )  ;", "indexDocs ( index ,     0  ,     1  0  )  ;", "ensureGreen ( index )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put ( INDEX _ ROUTING _ ALLOCATION _ ENABLE _ SETTING . getKey (  )  ,     \" none \"  )  )  ;", "break ;", "case   MIXED    :", "final   String   newNode    =    getNodeId (  (    v )     -  >    v . equals ( CURRENT )  )  ;", "final   String   oldNode    =    getNodeId (  (    v )     -  >    v . before ( CURRENT )  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put ( INDEX _ NUMBER _ OF _ REPLICAS _ SETTING . getKey (  )  ,     0  )  . put ( INDEX _ ROUTING _ ALLOCATION _ ENABLE _ SETTING . getKey (  )  ,     (  ( String )     ( null )  )  )  . put (  \" index . routing . allocation . include .  _ id \"  ,    oldNode )  )  ;", "ensureGreen ( index )  ;", "ensureNoInitializingShards (  )  ;", "updateIndexSettings ( index ,    Settings . builder (  )  . put (  \" index . routing . allocation . include .  _ id \"  ,    newNode )  )  ;", "asyncIndexDocs ( index ,     1  0  ,     5  0  )  . get (  )  ;", "ensureGreen ( index )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "assertCount ( index ,     (  \"  _ only _ no \"     +    newNode )  ,     6  0  )  ;", "break ;", "case   UPGRADED    :", "updateIndexSettings ( index ,    Settings . builder (  )  . put ( INDEX _ NUMBER _ OF _ REPLICAS _ SETTING . getKey (  )  ,     1  )  . put (  \" index . routing . allocation . include .  _ id \"  ,     (  ( String )     ( null )  )  )  )  ;", "asyncIndexDocs ( index ,     6  0  ,     5  0  )  . get (  )  ;", "ensureGreen ( index )  ;", "assertOK ( client (  )  . performRequest (  \" POST \"  ,     ( index    +     \"  /  _ refresh \"  )  )  )  ;", "Response   response    =    client (  )  . performRequest (  \" GET \"  ,     \"  _ no )  ;", "ObjectPath   objectPath    =    ObjectPath . createFromResponse ( response )  ;", "final   Map < String ,    Object >    nodeMap    =    objectPath . evaluate (  \" no )  ;", "List < String >    no =    new   ArrayList <  >  ( nodeMap . keySet (  )  )  ;", "assertCount ( index ,     (  \"  _ only _ no \"     +     ( noget (  0  )  )  )  ,     1  1  0  )  ;", "assertCount ( index ,     (  \"  _ only _ no \"     +     ( noget (  1  )  )  )  ,     1  1  0  )  ;", "break ;", "default    :", "throw   new   IllegalStateException (  (  \" unknown   type    \"     +     ( clusterType )  )  )  ;", "}", "}", "METHOD_END"], "methodName": ["testRelocationWithConcurrentIndexing"], "fileName": "org.elasticsearch.upgrades.RecoveryIT"}, {"methodBody": ["METHOD_START", "{", "return   createParameters (  )  ;", "}", "METHOD_END"], "methodName": ["parameters"], "fileName": "org.elasticsearch.upgrades.UpgradeClusterClientYamlTestSuiteIT"}, {"methodBody": ["METHOD_START", "{", "try    ( CloseableHttpClient   client    =    HttpClientBuilder . create (  )  . build (  )  )     {", "final   String   str    =    String . format ( Locale . ROOT ,     \" http :  /  / localhost :  % d / wildfly -  % s % s / transport / employees /  1  \"  ,    Integer . parseInt ( System . getProperty (  \" tests . jboss . http . port \"  )  )  ,    CURRENT ,     ( Build . CURRENT . isSnapshot (  )     ?     \"  - SNAPSHOT \"     :     \"  \"  )  )  ;", "final   HttpPut   put    =    new   HttpPut ( new   URI ( str )  )  ;", "final   String   body ;", "try    ( XContentBuilder   builder    =    jsonBuilder (  )  )     {", "builder . startObject (  )  ;", "{", "builder . field (  \" first _ name \"  ,     \" John \"  )  ;", "builder . field (  \" last _ name \"  ,     \" Smith \"  )  ;", "builder . field (  \" age \"  ,     2  5  )  ;", "builder . field (  \" about \"  ,     \" I   love   to   go   rock   climbing \"  )  ;", "builder . startArray (  \" interests \"  )  ;", "{", "builder . value (  \" sports \"  )  ;", "builder . value (  \" music \"  )  ;", "}", "builder . endArray (  )  ;", "}", "builder . endObject (  )  ;", "body    =    Strings . toString ( builder )  ;", "}", "put . setEntity ( new   StringEntity ( body ,    ContentType . APPLICATION _ JSON )  )  ;", "try    ( CloseableHttpResponse   response    =    client . execute ( put )  )     {", "int   status    =    response . getStatusLine (  )  . getStatusCode (  )  ;", "assertThat (  (  (  (  \" expected   a    2  0  1    response   but   got :     \"     +    status )     +     \"     -    body :     \"  )     +     ( EntityUtils . toString ( response . getEntity (  )  )  )  )  ,    status ,    equalTo (  2  0  1  )  )  ;", "}", "final   HttpGet   get    =    new   HttpGet ( new   URI ( str )  )  ;", "try    ( CloseableHttpResponse   response    =    client . execute ( get )  ; XContentParser   parser    =    jsonXContent . createParser ( new   common . xcontent . NamedXContentRegistry ( ClusterModule . getNamedXWriteables (  )  )  ,    THROW _ UNSUPPORTED _ OPERATION ,    response . getEntity (  )  . getContent (  )  )  )     {", "final   Map < String ,    Object >    map    =    parser . map (  )  ;", "assertThat ( map . get (  \" first _ name \"  )  ,    equalTo (  \" John \"  )  )  ;", "assertThat ( map . get (  \" last _ name \"  )  ,    equalTo (  \" Smith \"  )  )  ;", "assertThat ( map . get (  \" age \"  )  ,    equalTo (  2  5  )  )  ;", "assertThat ( map . get (  \" about \"  )  ,    equalTo (  \" I   love   to   go   rock   climbing \"  )  )  ;", "final   Object   interests    =    map . get (  \" interests \"  )  ;", "assertThat ( interests ,    instanceOf ( List . class )  )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "final   List < String >    interestsAsList    =     (  ( List < String >  )     ( interests )  )  ;", "assertThat ( interestsAsList ,    containsInAnyOrder (  \" sports \"  ,     \" music \"  )  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["testTransportClient"], "fileName": "org.elasticsearch.wildfly.WildflyIT"}, {"methodBody": ["METHOD_START", "{", "return   about ;", "}", "METHOD_END"], "methodName": ["getAbout"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "return   age ;", "}", "METHOD_END"], "methodName": ["getAge"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "return   firstName ;", "}", "METHOD_END"], "methodName": ["getFirstName"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "return   interests ;", "}", "METHOD_END"], "methodName": ["getInterests"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "return   lastName ;", "}", "METHOD_END"], "methodName": ["getLastName"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "this . about    =    about ;", "}", "METHOD_END"], "methodName": ["setAbout"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "this . age    =    age ;", "}", "METHOD_END"], "methodName": ["setAge"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "this . firstName    =    firstName ;", "}", "METHOD_END"], "methodName": ["setFirstName"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "this . interests    =    interests ;", "}", "METHOD_END"], "methodName": ["setInterests"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "this . lastName    =    lastName ;", "}", "METHOD_END"], "methodName": ["setLastName"], "fileName": "org.elasticsearch.wildfly.model.Employee"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( id )  ;", "final   GetResponse   response    =    client . prepareGet (  \" megacorp \"  ,     \" employee \"  ,    Long . toString ( id )  )  . get (  )  ;", "if    ( response . isExists (  )  )     {", "final   Map < String ,    Object >    source    =    response . getSource (  )  ;", "final      employee    =    new    (  )  ;", "employee . setFirstName (  (  ( String )     ( source . get (  \" first _ name \"  )  )  )  )  ;", "employee . setLastName (  (  ( String )     ( source . get (  \" last _ name \"  )  )  )  )  ;", "employee . setAge (  (  ( Integer )     ( source . get (  \" age \"  )  )  )  )  ;", "employee . setAbout (  (  ( String )     ( source . get (  \" about \"  )  )  )  )  ;", "@ SuppressWarnings (  \" unchecked \"  )", "final   List < String >    interests    =     (  ( List < String >  )     ( source . get (  \" interests \"  )  )  )  ;", "employee . setInterests ( interests )  ;", "return   Response . ok ( employee )  . build (  )  ;", "} else    {", "return   Response . status ( NOT _ FOUND )  . build (  )  ;", "}", "}", "METHOD_END"], "methodName": ["getEmployeeById"], "fileName": "org.elasticsearch.wildfly.transport.TransportClientEmployeeResource"}, {"methodBody": ["METHOD_START", "{", "Objects . requireNonNull ( id )  ;", "Objects . requireNonNull ( e )  ;", "try    ( XContentBuilder   builder    =    jsonBuilder (  )  )     {", "builder . startObject (  )  ;", "{", "builder . field (  \" first _ name \"  ,    e . getFirstName (  )  )  ;", "builder . field (  \" last _ name \"  ,    e . getLastName (  )  )  ;", "builder . field (  \" age \"  ,    e . getAge (  )  )  ;", "builder . field (  \" about \"  ,    e . getAbout (  )  )  ;", "if    (  ( e . getInterests (  )  )     !  =    null )     {", "builder . startArray (  \" interests \"  )  ;", "{", "for    ( final   String   interest    :    e . getInterests (  )  )     {", "builder . value ( interest )  ;", "}", "}", "builder . endArray (  )  ;", "}", "}", "builder . endObject (  )  ;", "final   IndexResponse   response    =    client . prepareIndex (  \" megacorp \"  ,     \" e \"  ,    Long . toString ( id )  )  . setSource ( builder )  . get (  )  ;", "if    (  ( response . status (  )  . getStatus (  )  )     =  =     2  0  1  )     {", "return   Response . created ( new   URI (  (  \"  / es /  \"     +    id )  )  )  . build (  )  ;", "} else    {", "return   Response . ok (  )  . build (  )  ;", "}", "}", "}", "METHOD_END"], "methodName": ["putEmployeeById"], "fileName": "org.elasticsearch.wildfly.transport.TransportClientEmployeeResource"}, {"methodBody": ["METHOD_START", "{", "final   String   elasticsearchProperties    =    System . getProperty (  \" elasticsearch . properties \"  )  ;", "final   Properties   properties    =    new   Properties (  )  ;", "final   String   transportUri ;", "final   String   clusterName ;", "try    ( InputStream   is    =    Files . newInputStream ( getPath ( elasticsearchProperties )  )  )     {", "properties . load ( is )  ;", "transportUri    =    properties . getProperty (  \" transport . uri \"  )  ;", "clusterName    =    properties . getProperty (  \" cluster . name \"  )  ;", "}", "final   int   lastColon    =    transportUri . lastIndexOf (  '  :  '  )  ;", "final   String   host    =    transportUri . substring (  0  ,    lastColon )  ;", "final   int   port    =    Integer . parseInt ( transportUri . substring (  ( lastColon    +     1  )  )  )  ;", "final   Settings   settings    =    Settings . builder (  )  . put (  \" cluster . name \"  ,    clusterName )  . build (  )  ;", "final   TransportClient   transportClient    =    new   transport . client . PreBuiltTransportClient ( settings ,    Collections . emptyList (  )  )  ;", "transportClient . addTransportAddress ( new   TransportAddress ( InetAddress . getByName ( host )  ,    port )  )  ;", "return   transportClient ;", "}", "METHOD_END"], "methodName": ["createTransportClient"], "fileName": "org.elasticsearch.wildfly.transport.TransportClientProducer"}, {"methodBody": ["METHOD_START", "{", "return   PathUtils . get ( elasticsearchProperties )  ;", "}", "METHOD_END"], "methodName": ["getPath"], "fileName": "org.elasticsearch.wildfly.transport.TransportClientProducer"}]